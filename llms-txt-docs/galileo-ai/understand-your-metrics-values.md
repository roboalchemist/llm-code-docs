# Source: https://docs.galileo.ai/galileo/gen-ai-studio-products/galileo-evaluate/how-to/understand-your-metrics-values.md

# Understanding Metric Values | Galileo Evaluate How-To

> Gain insights into your metric values in Galileo Evaluate with explainability features, including token-level highlighting and generated explanations for better analysis.

Our metrics have explainability built-in, helping you understand which parts of the input or output are leading to certain outcomes. We have two types of explainability: Highlighting and generated Explanations.

## Explainability via Token Highlighting

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/galileo/images/metrics-1.png" width="400" />
</Frame>

When looking at a workflow in the expanded view, some metric values will have an <Icon icon="eye" />icon next to them. Clicking on it will turn token-level highlighting on the input / output section of the node.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/galileo/images/metrics-2.png" width="400" />
</Frame>

The following metrics have token-level highlighting:

| Metric                                                                                                                         | Where to see it                        |
| ------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------- |
| [PII](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/private-identifiable-information)                              | Input or Output into LLM or Chat Nodes |
| [Prompt Perplexity](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/prompt-perplexity)                               | Input into LLM or Chat Node            |
| [Uncertainty](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/uncertainty)                                           | Output of LLM or Chat Node             |
| [Context Adherence (Luna)](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/context-adherence/context-adherence-luna) | Output of LLM or Chat Node             |
| [Chunk Relevance (Luna)](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/chunk-relevance)                            | Output of Retriever Node               |
| [Chunk Utilization (Luna)](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/context-adherence/context-adherence-luna) | Output of Retriever Node               |

## Explainability via Explanations

For metrics powered by [Chainpoll](/galileo/gen-ai-studio-products/galileo-ai-research/chainpoll), we provide an explanation or rationale generated by LLMs. ðŸª„ next to metric values indicate that this metric has an explanation available. This explanation will include the reasoning the model followed to get to its conclusion. To view the explanation, simply hover over the metric value.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/galileo/images/metrics-5.png" width="300" />
</Frame>

The following metrics have generated explanations:

* [*Correctness*](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/correctness)

* [*Context Adherence Plus*](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/completeness/completeness-plus)

* [*Completeness Plus*](/galileo/gen-ai-studio-products/galileo-guardrail-metrics/completeness/completeness-plus)
