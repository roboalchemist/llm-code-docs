.. meta::
   :description: Learn how to use ROCm for AI.
   :keywords: ROCm, AI, machine learning, LLM, usage, tutorial

**************************
Use ROCm for AI
**************************

ROCm is an open-source software platform that enables high-performance computing and machine learning applications. It features the ability to accelerate training, fine-tuning, and inference for AI application development. With ROCm, you can access the full power of AMD GPUs, which can significantly improve the performance and efficiency of AI workloads.

You can use ROCm to perform distributed training, which enables you to train models across multiple GPUs or nodes simultaneously. Additionally, ROCm supports mixed-precision training, which can help reduce the memory and compute requirements of training workloads. For fine-tuning, ROCm provides access to various algorithms and optimization techniques. In terms of inference, ROCm provides several techniques that can help you optimize your models for deployment, such as quantization, GEMM tuning, and optimization with composable kernel.
 
Overall, ROCm can be used to improve the performance and efficiency of your AI applications. With its training, fine-tuning, and inference support, ROCm provides a complete solution for optimizing AI workflows and achieving the optimum results possible on AMD GPUs. 

The AI Developer Hub contains `AMD ROCm tutorials <https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/>`_ for
training, fine-tuning, and inference. It leverages popular machine learning frameworks on AMD GPUs.

In this guide, you'll learn how to use ROCm for AI:

- :doc:`Training <training/index>`

- :doc:`Fine-tuning LLMs <fine-tuning/index>`

- :doc:`Inference <inference/index>`

- :doc:`Inference optimization <inference-optimization/index>`


To learn about ROCm for HPC applications and scientific computing, see
:doc:`../rocm-for-hpc/index`.
