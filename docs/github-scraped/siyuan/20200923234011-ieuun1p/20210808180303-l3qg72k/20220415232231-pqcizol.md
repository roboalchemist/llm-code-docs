<!-- Source: https://github.com/siyuan-note/user-guide-en_US/blob/master/20200923234011-ieuun1p/20210808180303-l3qg72k/20220415232231-pqcizol.sy -->

# Query syntax

## Overview

Global search  <kbd>Ctrl+P</kbd> supports advanced search through query syntax, in order to implement some logical operations, such as the query syntax that contains the keyword `foo` and does not contain the keyword `bar` is `foo NOT bar`.

Before using the query syntax, let's have a general understanding of its composition:

- String: composed of letters, numbers, etc.
- Phrase: composed of strings
- Query: composed of phrases, multiple queries can be combined into a new query through `AND`, `OR` and `NOT`

Below we introduce their details respectively.

## Strings

Strings can be specified in two ways:

- Characters enclosed in English double quotes `"`. If `"` itself needs to be used, it can be escaped by SQL-style (plus a `"`), for example `"foo""bar"""` will hits `foo "bar"`
- Consists of non `AND`, `OR` and `NOT` characters, and these characters must be:
  - All non-ASCII characters, or
  - Belongs to 52 uppercase and lowercase English characters (`A-Za-z`), or
  - Belongs to 10 ASCII numeric characters (`0-9`), or
  - Is an underscore `_`, or
  - Is the replacement character (ASCII 26)

For strings that are not composed of other characters mentioned above, they must be wrapped with `"`, such as strings containing `-`, `*` and other symbols.

## Phrases

Phrases consist of strings, which can be concatenated by `+`. A phrase is composed of some tokens in order, and these tokens are processed by the user's input text through the tokenizer. The tokenizer used by SiYuan is to make Chinese search easy to use (supports single-word search), so the implementation is based on word segmentation ([Tokenizer code](https://github.com/siyuan-note/sqlite-fts5-siyuan-tokenizer)), which means that each Chinese character or English letter will be split into a token. This has some effect on `+` concatenation, so it is recommended not to use `+` to combine multiple phrases if unsure.

## Queries

A query consists of multiple phrases, which can be combined into a new query by the operators `AND`, `OR`, and `NOT`.

| Operator | Function |
|---|---|
| `<query1> AND <query2>` | Matches if both query1 and query2 match |
| `<query1> OR <query2>` | Matches if either query1 or query2 match |
| `<query1> NOT <query2>` | Matches if query1 matches and query2 does not match |

Use parentheses `()` to combine query priorities, for example:

```c3Fs
-- Matches documents that contain at least one instance of either "one" or "two", but do not contain any instances of token "three".
'one OR two NOT three'

-- Match all documents that contain the token "two" but not "three", or contain the token "one".
'one OR (two NOT three)'
```

Multiple phrases separated by spaces use `AND` by default, for example:

```c3Fs
'one two three'         -- 'one AND two AND three'
'three "one two"'       -- 'three AND "one two"'
'NEAR(one two) three'   -- 'NEAR(one two) AND three'
'one OR two three'      -- 'one OR two AND three'

'(one OR two) three'    -- Syntax error!
'func(one two)'         -- Syntax error!
```

## Technical implementation

We implement global search through [SQLite FTS5](https://www.sqlite.org/fts5.html).

The key part of the query statement generated by the system is roughly `MATCH '{content name alias memo}:" + query`, `query` is the user input part, for [column filter](https://www.sqlite.org/fts5 .html#fts5_column_filters) `{content name alias memo}:` is generated by <kbd>Settings</kbd> - <kbd>Search</kbd> - <kbd>Attribute</kbd>.

After knowing these, we can implement the query embedding block through the query syntax, so that the query performance will be better:

In addition to this, the API also supports querying using FTS.

### Case Sensitive

If the <kbd>Settings</kbd> - <kbd>Search</kbd> - <kbd>Case Sensitivity</kbd> option is enabled, the search will be case-sensitive. By default, this option is disabled, that is, insensitive upper and lower case.

Since the tokenizer is case-sensitive, we build two virtual tables to index separately:

- `blocks_fts`: word segmentation by character
- `blocks_fts_case_insensitive`: Convert English letters to lowercase participles

The disadvantage of this is that it increases disk space usage and reduces indexing performance, but there is currently no better solution, so it can only be done first. In addition, Unicode case folding and diacritics are not supported, only English letters are supported ignoring case.

If you have a better implementation, please let us know, thank you very much.
