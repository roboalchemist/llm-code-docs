---
description: Este wiki proporciona el tutorial de ensamblaje y depuraci√≥n para el SO ARM100 y realiza la recopilaci√≥n de datos y entrenamiento dentro de la √∫ltima versi√≥n del framework Lerobot.
title: SoArm en Lerobot
keywords:
- Lerobot
- Huggingface
- Arm
- Robotics
image: https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.webp
slug: /es/lerobot_so100m_new
last_update:
  date: 9/26/2025
  author: LiShanghang
translation:
  skip: [ zh-CN ]
---

# Comenzando con el brazo rob√≥tico SO-ARM100 y SO-ARM101 con LeRobot

:::tip
El mantenimiento de este tutorial ha sido actualizado a la √∫ltima versi√≥n de [lerobot](https://huggingface.co/docs/lerobot/index), si deseas consultar el tutorial de la versi√≥n anterior, por favor haz clic [aqu√≠](https://wiki.seeedstudio.com/es/lerobot_so100m/).
:::

## Introducci√≥n

El [SO-10xARM](https://github.com/TheRobotStudio/SO-ARM100) es un proyecto de brazo rob√≥tico completamente de c√≥digo abierto lanzado por [TheRobotStudio](https://www.therobotstudio.com/). Incluye el brazo seguidor y el brazo rob√≥tico l√≠der, y tambi√©n proporciona archivos detallados de impresi√≥n 3D y gu√≠as de operaci√≥n. [LeRobot](https://github.com/huggingface/lerobot/tree/main) est√° comprometido a proporcionar modelos, conjuntos de datos y herramientas para rob√≥tica del mundo real en PyTorch. Su objetivo es reducir la barrera de entrada de la rob√≥tica, permitiendo que todos contribuyan y se beneficien del intercambio de conjuntos de datos y modelos preentrenados. LeRobot integra metodolog√≠as de vanguardia validadas para aplicaciones del mundo real, centr√°ndose en el aprendizaje por imitaci√≥n. Ha proporcionado un conjunto de modelos preentrenados, conjuntos de datos con demostraciones recopiladas por humanos y entornos de simulaci√≥n, permitiendo a los usuarios comenzar sin la necesidad de ensamblar robots. En las pr√≥ximas semanas, la intenci√≥n es aumentar el soporte para rob√≥tica del mundo real en los robots m√°s rentables y competentes actualmente accesibles.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/sD34HnAkGNc?si=hqKd_sH5Oc9sdcwd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Introducci√≥n del Proyecto

El kit de robot inteligente SO-ARM10x y reComputer Jetson AI combina perfectamente el control de brazo rob√≥tico de alta precisi√≥n con una potente plataforma de computaci√≥n AI, proporcionando una soluci√≥n integral de desarrollo de robots. Este kit est√° basado en la plataforma Jetson Orin o AGX Orin, combinado con el brazo rob√≥tico SO-ARM10x y el framework AI LeRobot, ofreciendo a los usuarios un sistema de robot inteligente aplicable a m√∫ltiples escenarios como educaci√≥n, investigaci√≥n y automatizaci√≥n industrial.
Este wiki proporciona el tutorial de ensamblaje y depuraci√≥n para el SO ARM10x y realiza la recopilaci√≥n de datos y entrenamiento dentro del framework Lerobot.

  <div align="center">
      <img width={800}
      src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/Arm_kit.png" />
  </div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
<a class="get_one_now_item" href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">
            <strong><span><font color={'FFFFFF'} size={"4"}> Obtener Uno Ahora üñ±Ô∏è</font></span></strong>
</a></div>

## Caracter√≠sticas Principales

1. **C√≥digo abierto y bajo costo**: Es una soluci√≥n de brazo rob√≥tico de c√≥digo abierto y bajo costo de [TheRobotStudio](https://github.com/TheRobotStudio/SO-ARM100)
2. **Integraci√≥n con LeRobot**: Dise√±ado para integraci√≥n con la [plataforma LeRobot](https://github.com/huggingface/lerobot)
3. **Abundantes recursos de aprendizaje**: Proporciona recursos de aprendizaje de c√≥digo abierto integrales como gu√≠as de ensamblaje y calibraci√≥n, y tutoriales para pruebas, recopilaci√≥n de datos, entrenamiento y despliegue para ayudar a los usuarios a comenzar r√°pidamente y desarrollar aplicaciones rob√≥ticas.
4. **Compatible con Nvidia**: Despliega este kit de brazo con reComputer Mini J4012 Orin NX 16 GB.
5. **Aplicaci√≥n Multi-Escenario**: Es aplicable a campos como educaci√≥n, investigaci√≥n cient√≠fica, producci√≥n automatizada y rob√≥tica, ayudando a los usuarios a lograr operaciones de robot eficientes y precisas en varias tareas complejas.

## Novedades:

- Optimizaci√≥n del cableado: Comparado con SO-ARM100, SO-ARM101 presenta un cableado mejorado que previene problemas de desconexi√≥n previamente vistos en la articulaci√≥n 3. El nuevo dise√±o de cableado tambi√©n ya no limita el rango de movimiento de las articulaciones.
- Diferentes relaciones de engranajes para el brazo l√≠der: El brazo l√≠der ahora usa motores con relaciones de engranajes optimizadas, mejorando el rendimiento y eliminando la necesidad de cajas de engranajes externas.
- Soporte de nueva funcionalidad: El brazo l√≠der ahora puede seguir al brazo seguidor en tiempo real, lo cual es crucial para la pr√≥xima pol√≠tica de aprendizaje, donde un humano puede intervenir y corregir las acciones del robot.

:::caution

Seeed Studio solo es responsable de la calidad del hardware en s√≠. Los tutoriales se actualizan estrictamente de acuerdo con la documentaci√≥n oficial. Si encuentras problemas de software o problemas de dependencias del entorno que no se pueden resolver, adem√°s de verificar la secci√≥n FAQ al final de este tutorial, por favor reporta el problema oportunamente a la [plataforma LeRobot](https://github.com/huggingface/lerobot) o al [canal Discord de LeRobot](https://discord.gg/8TnwDdjFGU).

:::

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/JrF_ymUvrqc?si=vslu5NNI-ZIzVXLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Especificaciones

<table>
  <thead>
    <tr>
      <th>Tipo</th>
      <th colSpan="2">SO-ARM100</th>
      <th colSpan="2">SO-ARM101</th>
    </tr>
    <tr>
      <th></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">Kit de Brazo</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit-Pro-p-6343.html" target="_blank">Kit de Brazo Pro</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit.html" target="_blank">Kit de Brazo</a></th>
      <th><a href="https://www.seeedstudio.com/SO-ARM100-Low-Cost-AI-Arm-Kit-Pro-p-6343.html" target="_blank">Kit de Brazo Pro</a></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Brazo L√≠der</td>
      <td rowSpan="2">12x motores ST-3215- C001 (7.4V) con relaci√≥n de engranajes 1:345 para todas las articulaciones</td>
      <td rowSpan="2">12x motores ST-3215-C018/ST-3215-C047 (12V) con relaci√≥n de engranajes 1:345 para todas las articulaciones</td>
      <td colSpan="2">
        1x motor ST-3215- C001 (7.4V) con relaci√≥n de engranajes 1:345 solo para la articulaci√≥n 2<br />
        2x motores ST-3215-C044 (7.4V) con relaci√≥n de engranajes 1:191 para las articulaciones 1 y 3<br />
        3x motores ST-3215-C046 (7.4V) con relaci√≥n de engranajes 1:147 para las articulaciones 4, 5 y pinza (articulaci√≥n 6)
      </td>
    </tr>
    <tr>
      <td>Brazo Seguidor</td>
      <td colSpan="2">Igual que SO-ARM100</td>
    </tr>
    <tr>
      <td>Fuente de Alimentaci√≥n</td>
      <td>5.5 mm √ó 2.1 mm DC 5 V 4 A</td>
      <td>5.5 mm √ó 2.1 mm DC 12 V 2 A</td>
      <td>5.5 mm √ó 2.1 mm DC 5 V 4 A</td>
      <td>
        5.5 mm √ó 2.1 mm DC 12 V 2 A (Brazo Seguidor)<br />
        5.5 mm √ó 2.1 mm DC 5 V 4 A (Brazo L√≠der)
      </td>
    </tr>
    <tr>
      <td>Sensor de √Ångulo</td>
      <td colSpan="4">Codificador magn√©tico de 12 bits</td>
    </tr>
    <tr>
      <td>Temperatura de Operaci√≥n Recomendada</td>
      <td colSpan="4">0 ¬∞C a 40 ¬∞C</td>
    </tr>
    <tr>
      <td>Comunicaci√≥n</td>
      <td colSpan="4">UART</td>
    </tr>
    <tr>
      <td>M√©todo de Control</td>
      <td colSpan="4">PC</td>
    </tr>
  </tbody>
</table>

:::danger

Si compras la versi√≥n Arm Kit, ambas fuentes de alimentaci√≥n son de 5V. Si compras la versi√≥n Arm Kit Pro, por favor usa la fuente de alimentaci√≥n de 5V para la calibraci√≥n y cada paso del brazo rob√≥tico L√≠der, y la fuente de alimentaci√≥n de 12V para la calibraci√≥n y cada paso del brazo rob√≥tico Seguidor.

:::

## Lista de Materiales (BOM)

| Parte | Cantidad | Incluido|
|--|--|--|
|  Motores Servo | 12 | ‚úÖ |
| Placa de Control de Motor | 2 | ‚úÖ |
| Cable USB-C 2 piezas | 1 | ‚úÖ |
| Fuente de Alimentaci√≥n2 | 2 | ‚úÖ |
| Abrazadera de Mesa| 4 | ‚úÖ |
| Partes impresas en 3D del brazo | 1 | Opci√≥n |

## Entorno del Sistema Inicial

**Para Ubuntu x86:**

- Ubuntu 22.04  
- CUDA 12+  
- Python 3.10  
- Torch 2.6+  

**Para Jetson Orin:**

- Jetson JetPack 6.0 y 6.1, no soporta 6.1
- Python 3.10  
- Torch 2.3+

## Tabla de Contenidos

  [A. Gu√≠a de Impresi√≥n 3D](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#install-lerobot)

  [B. Instalar LeRobot](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#install-lerobot)

  [C. Configurar los motores](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#configure-the-motors)

  [D. Ensamblaje](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#assembly)

  [E. Calibrar](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#calibrate)

  [F. Teleoperar](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#teleoperate)

  [G. Agregar c√°maras](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#add-cameras)

  [H. Grabar el conjunto de datos](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#record-the-dataset)

  [I. Visualizar el conjunto de datos](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#visualize-the-dataset)

  [J. Reproducir un episodio](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#replay-an-episode)

  [K. Entrenar una pol√≠tica](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#train-a-policy)

  [L. Evaluar tu pol√≠tica](https://wiki.seeedstudio.com/es/lerobot_so100m_new/#evaluate-your-policy)

## Gu√≠a de Impresi√≥n 3D

:::caution
Siguiendo la actualizaci√≥n oficial de SO101, SO100 ya no lo soportar√° y los archivos fuente ser√°n eliminados seg√∫n lo oficial, pero los archivos fuente a√∫n se pueden encontrar en nuestro [Makerworld](https://makerworld.com/zh/models/908660). Sin embargo, para usuarios que han comprado previamente SO100, los tutoriales y m√©todos de instalaci√≥n siguen siendo compatibles. La impresi√≥n de SO101 es completamente compatible con la instalaci√≥n del kit de motor de SO100.
:::

### Paso 1: Elegir una impresora

Los archivos STL proporcionados est√°n listos para imprimir en muchas impresoras FDM. A continuaci√≥n se muestran las configuraciones probadas y sugeridas aunque otras pueden funcionar.

- Material: PLA+
- Di√°metro de Boquilla y Precisi√≥n: di√°metro de boquilla de 0.4mm a altura de capa de 0.2mm o boquilla de 0.6mm a altura de capa de 0.4mm.
- Densidad de Relleno: 15%  

### Paso 2: Configurar la impresora

- Aseg√∫rate de que la impresora est√© calibrada y el nivel de la cama est√© configurado correctamente usando las instrucciones espec√≠ficas de la impresora.
- Limpia la cama de impresi√≥n, asegur√°ndote de que est√© libre de polvo o grasa. Si limpias la cama usando agua u otro l√≠quido, seca la cama.
- Si tu impresora lo recomienda, usa una barra de pegamento est√°ndar y aplica una capa delgada y uniforme de pegamento en el √°rea de impresi√≥n de la cama. Evita la acumulaci√≥n o aplicaci√≥n desigual.
- Carga el filamento de la impresora usando las instrucciones espec√≠ficas de la impresora.
- Aseg√∫rate de que la configuraci√≥n de la impresora coincida con las sugeridas anteriormente (la mayor√≠a de las impresoras tienen m√∫ltiples configuraciones, as√≠ que elige las que m√°s se acerquen).
- Configura para soportes en todas partes pero ignora pendientes mayores a 45 grados respecto a la horizontal.
- No debe haber soportes en los agujeros de tornillos con ejes horizontales.

### Paso 3: Imprimir las piezas

Todas las piezas para el l√≠der o seguidor est√°n para impresi√≥n 3D f√°cil ya contenidas en un solo archivo, correctamente orientadas para z hacia arriba para minimizar soportes.

- Para tama√±os de cama de impresora de 220mmx220mm (como la Ender), imprime estos archivos:
  - [Seguidor](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Follower/Ender_Follower_SO101.stl)
  - [L√≠der](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Leader/Ender_Leader_SO101.stl)

- Para tama√±os de cama de impresora de 205mm x 250mm (como la Prusa/Up):
  - [Seguidor](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Follower/Prusa_Follower_SO101.stl)
  - [L√≠der](https://github.com/TheRobotStudio/SO-ARM100/blob/main/STL/SO101/Leader/Prusa_Leader_SO101.stl)

## Instalar LeRobot

Entornos como pytorch y torchvision necesitan ser instalados bas√°ndose en tu CUDA.

1. Instalar Miniconda:
Para Jetson:

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh
chmod +x Miniconda3-latest-Linux-aarch64.sh
./Miniconda3-latest-Linux-aarch64.sh
source ~/.bashrc
```

O, Para X86 Ubuntu 22.04:

```bash
mkdir -p ~/miniconda3
cd miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
source ~/miniconda3/bin/activate
conda init --all
```

2. Crear y activar un entorno conda fresco para lerobot

```bash
conda create -y -n lerobot python=3.10 && conda activate lerobot
```

3. Clonar Lerobot:

```bash
git clone https://github.com/Seeed-Projects/lerobot.git ~/lerobot
```

4. Cuando uses miniconda, instala ffmpeg en tu entorno:

```bash
conda install ffmpeg -c conda-forge
```

:::tip
Esto usualmente instala ffmpeg 7.X para tu plataforma compilado con el codificador libsvtav1. Si libsvtav1 no es compatible (verifica codificadores compatibles con ffmpeg -encoders), puedes:

- [En cualquier plataforma] Instalar expl√≠citamente ffmpeg 7.X usando:

```bash
conda install ffmpeg=7.1.1 -c conda-forge
```

- [Solo en Linux] Instalar dependencias de compilaci√≥n de ffmpeg y compilar ffmpeg desde el c√≥digo fuente con libsvtav1, y aseg√∫rate de usar el binario ffmpeg correspondiente a tu instalaci√≥n con which ffmpeg.

Si encuentras un error como este, tambi√©n puedes usar este comando.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/lekiwi/No valid stream.png" />
</div>

:::

5. Instalar LeRobot con dependencias para los motores feetech:

```bash
cd ~/lerobot && pip install -e ".[feetech]"
```

Para dispositivos Jetson Jetpack 6.0+ (por favor aseg√∫rate de instalar [Pytorch-gpu y Torchvision](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/tree/main/3-Basic-Tools-and-Getting-Started/3.5-Pytorch) desde el paso 5 antes de ejecutar este paso):

```bash
conda install -y -c conda-forge "opencv>=4.10.0.84"  # Install OpenCV and other dependencies through conda, this step is only for Jetson Jetpack 6.0+
conda remove opencv   # Uninstall OpenCV 
pip3 install opencv-python==4.10.0.84  # Then install opencv-python via pip3
conda install -y -c conda-forge ffmpeg
conda uninstall numpy
pip3 install numpy==1.26.0  # This should match torchvision
```

6. Verificar Pytorch y Torchvision

Dado que instalar el entorno lerobot v√≠a pip desinstalar√° el Pytorch y Torchvision originales e instalar√° las versiones CPU de Pytorch y Torchvision, necesitas realizar una verificaci√≥n en Python.

```python
import torch
print(torch.cuda.is_available())
```

Si el resultado impreso es False, necesitas reinstalar Pytorch y Torchvision seg√∫n el [tutorial del sitio web oficial](https://pytorch.org/index.html).

Si est√°s usando un dispositivo Jetson, instala Pytorch y Torchvision seg√∫n [este tutorial](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md#installing-pytorch-on-recomputer-nvidia-jetson).

## Configurar los motores

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>

<TabItem value="SO101" label="SO101">

El proceso de calibraci√≥n e inicializaci√≥n del servo para SO-ARM101 es el mismo que el de SO-ARM100 en t√©rminos tanto de m√©todo como de c√≥digo. Sin embargo, ten en cuenta que las relaciones de engranajes para las primeras tres articulaciones del Brazo L√≠der SO-ARM101 difieren de las de SO-ARM100, por lo que es importante distinguir y calibrarlas cuidadosamente.

Para configurar los motores designa un adaptador de servo de bus y 6 motores para tu brazo l√≠der, y de manera similar el otro adaptador de servo de bus y 6 motores para el brazo seguidor. Es conveniente etiquetarlos y escribir en cada motor si es para el seguidor F o para el l√≠der L y su ID del 1 al 6. Usamos **F1‚ÄìF6** para representar las articulaciones 1 a 6 del **Brazo Seguidor**, y **L1‚ÄìL6** para representar las articulaciones 1 a 6 del **Brazo L√≠der**. Los detalles correspondientes del modelo de servo, asignaciones de articulaciones y relaci√≥n de engranajes son los siguientes:

| Modelo de Servo                        | Relaci√≥n de Engranajes | Articulaciones Correspondientes |
|----------------------------------------|------------|------------------------------|
| ST-3215-C044(7.4V)                            | 1:191      | L1                           |
| ST-3215-C001(7.4V)                       | 1:345      | L2                           |
| ST-3215-C044(7.4V)                           | 1:191      | L3                           |
| ST-3215-C046(7.4V)                           | 1:147      | L4‚ÄìL6                        |
| ST-3215-C001(7.4V) / C018(12V) / C047(12V)             | 1:345      | F1‚ÄìF6                        |

:::danger
Ahora debes conectar la fuente de alimentaci√≥n de 5V o 12V al bus del motor. 5V para los motores STS3215 7.4V y 12V para los motores STS3215 12V. Ten en cuenta que el brazo l√≠der siempre usa los motores de 7.4V, as√≠ que ten cuidado de conectar la fuente de alimentaci√≥n correcta si tienes motores de 12V y 7.4V, ¬°de lo contrario podr√≠as quemar tus motores! Ahora, conecta el bus del motor a tu computadora v√≠a USB. Ten en cuenta que el USB no proporciona energ√≠a, y tanto la fuente de alimentaci√≥n como el USB deben estar conectados.
:::

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/all_motos.png" />
</div>

***Los siguientes son los pasos de calibraci√≥n de c√≥digo, por favor calibra con el servo de cableado de referencia en la imagen de arriba***

Encontrar puertos USB asociados a tus brazos
Para encontrar los puertos correctos para cada brazo, ejecuta el script de utilidad dos veces:

```bash
lerobot-find-port
```

Salida de ejemplo:

```bash
Finding all available ports for the MotorBus.
['/dev/ttyACM0', '/dev/ttyACM1']
Remove the usb cable from your MotorsBus and press Enter when done.

[...Disconnect corresponding leader or follower arm and press Enter...]

The port of this MotorsBus is /dev/ttyACM1
Reconnect the USB cable.
```

:::tip
Recuerda quitar el usb, de lo contrario la interfaz no ser√° detectada.
:::

Salida de ejemplo al identificar el puerto del brazo seguidor (ej., `/dev/tty.usbmodem575E0031751` en Mac, o posiblemente `/dev/ttyACM0` en Linux):

Salida de ejemplo al identificar el puerto del brazo l√≠der (ej., `/dev/tty.usbmodem575E0032081`, o posiblemente `/dev/ttyACM1` en Linux):

Podr√≠as necesitar dar acceso a los puertos USB ejecutando:

```bash
sudo chmod 666 /dev/ttyACM0
sudo chmod 666 /dev/ttyACM1
```

**Configurar tus motores**

:::danger
Por favor usa una fuente de alimentaci√≥n de 5V para calibrar los motores L√≠der (ST-3215-C046, C044, 001).
:::

| **Calibraci√≥n Articulaci√≥n 6 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 5 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 4 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 3 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 2 Brazo L√≠der** | **Calibraci√≥n Articulaci√≥n 1 Brazo L√≠der** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L5.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L4.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L3.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L2.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_L1.jpg) |

:::danger
Si compras la versi√≥n Arm Kit (ST-3215-C001), usa una fuente de alimentaci√≥n de 5V. Si compras la versi√≥n Arm Kit Pro, por favor usa una fuente de alimentaci√≥n de 12V para calibrar el servo (ST-3215-C047/ST-3215-C018).
:::

| **Calibraci√≥n Articulaci√≥n 6 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 5 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 4 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 3 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 2 Brazo Seguidor** | **Calibraci√≥n Articulaci√≥n 1 Brazo Seguidor** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F5.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F4.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F3.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F2.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/cal_F1.jpg) |

:::tip
Nuevamente, aseg√∫rate de que los IDs de las articulaciones del servo y las relaciones de engranajes correspondan estrictamente a las del SO-ARM101.
:::

Conecta el cable USB desde tu computadora y la fuente de alimentaci√≥n a la placa controladora del brazo seguidor. Luego, ejecuta el siguiente comando.

```bash
lerobot-setup-motors \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0  # <- paste here the port found at previous step
```

Deber√≠as ver la siguiente instrucci√≥n.

```bash
Connect the controller board to the 'gripper' motor only and press enter.
```

Como se indica, conecta el motor de la pinza. Aseg√∫rate de que sea el √∫nico motor conectado a la placa, y que el motor en s√≠ no est√© a√∫n conectado en cadena a ning√∫n otro motor. Al presionar [Enter], el script configurar√° autom√°ticamente el ID y la velocidad de baudios para ese motor.

Entonces deber√≠as ver el siguiente mensaje:

```bash
'gripper' motor id set to 6
```

Seguido de la siguiente instrucci√≥n:

```bash
Connect the controller board to the 'wrist_roll' motor only and press enter.
```

Puedes desconectar el cable de 3 pines de la placa controladora, pero puedes dejarlo conectado al motor de la pinza en el otro extremo, ya que ya estar√° en el lugar correcto. Ahora, conecta otro cable de 3 pines al motor de rotaci√≥n de la mu√±eca y con√©ctalo a la placa controladora. Como con el motor anterior, aseg√∫rate de que sea el √∫nico motor conectado a la placa y que el motor en s√≠ no est√© conectado a ning√∫n otro.

:::caution
Repite la operaci√≥n para cada motor seg√∫n se indica.
:::

:::tip
Verifica tu cableado en cada paso antes de presionar Enter. Por ejemplo, el cable de la fuente de alimentaci√≥n podr√≠a desconectarse mientras manipulas la placa.
:::

Cuando hayas terminado, el script simplemente finalizar√°, momento en el cual los motores estar√°n listos para ser utilizados. Ahora puedes conectar el cable de 3 pines de cada motor al siguiente, y el cable del primer motor (el 'giro del hombro' con id=1) a la placa controladora, que ahora puede ser fijada a la base del brazo.

Realiza los mismos pasos para el brazo l√≠der.

```bash
lerobot-setup-motors \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM0  # <- paste here the port found at previous step
```

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/hbW6eFYkHTg?si=jKdpTyI8wRC-iHxO" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

</TabItem>

</Tabs>

## Ensamblaje

:::tip

- El proceso de ensamblaje de brazo dual del SO-ARM101 es el mismo que el del SO-ARM100. Las √∫nicas diferencias son la adici√≥n de clips de cable en el SO-ARM101 y las diferentes relaciones de engranajes de los servos de las articulaciones en el Brazo L√≠der. Por lo tanto, tanto el SO100 como el SO101 pueden instalarse siguiendo el siguiente contenido
- Antes del ensamblaje, por favor verifica nuevamente tu modelo de motor y relaci√≥n de reducci√≥n. Si has comprado el SO100, puedes ignorar este paso. Si has comprado el SO101, por favor verifica la siguiente tabla para distinguir F1 a F6 y L1 a L6.

:::

  | Modelo de Servo                            | Relaci√≥n de Engranajes | Articulaciones Correspondientes         |
|----------------------------------------|------------|------------------------------|
| ST-3215-C044(7.4V)                            | 1:191      | L1                           |
| ST-3215-C001(7.4V)                       | 1:345      | L2                           |
| ST-3215-C044(7.4V)                           | 1:191      | L3                           |
| ST-3215-C046(7.4V)                           | 1:147      | L4‚ÄìL6                        |
| ST-3215-C001(7.4V) / C018(12V) / C047(12V)             | 1:345      | F1‚ÄìF6                        |

:::danger
Si compraste el **SO101 Arm Kit Standard Edition**, todas las fuentes de alimentaci√≥n son de 5V. Si compraste el **SO101 Arm Kit Pro Edition**, el Brazo L√≠der debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 5V, mientras que el Brazo Seguidor debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 12V.
:::

**Ensamblar Brazo L√≠der**

| **Paso 1** | **Paso 2** | **Paso 3** | **Paso 4** | **Paso 5** | **Paso 6** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L1.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L2.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L3.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L4.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L5.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L6.jpg) |
| **Paso 7** | **Paso 8** | **Paso 9** | **Paso 10** | **Paso 11** | **Paso 12** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L7.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L8.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L9.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L10.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L11.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L12.jpg) |
| **Paso 13** | **Paso 14** | **Paso 15** | **Paso 16** | **Paso 17** | **Paso 18** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L13.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L14.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L15.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L16.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L18.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L21.jpg) |
| **Paso 19** | **Paso 20** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L22.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_L23.jpg) |

**Ensamblar Brazo Seguidor**

:::tip

- Los pasos para ensamblar el Brazo Seguidor son generalmente los mismos que los del Brazo L√≠der. La √∫nica diferencia radica en el m√©todo de instalaci√≥n del efector final (pinza y mango) despu√©s del Paso 12.

:::

| **Paso 1** | **Paso 2** | **Paso 3** | **Paso 4** | **Paso 5** | **Paso 6** |
|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F1.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F2.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F3.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F3.5.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F4.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F5.jpg) |
| **Paso 7** | **Paso 8** | **Paso 9** | **Paso 10** | **Paso 11** | **Paso 12** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F6.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F7.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F8.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F9.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F11.jpg) |![fig6](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F12.jpg) |
| **Paso 13** | **Paso 14** | **Paso 15** | **Paso 16** | **Paso 17** |
| ![fig1](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F13.jpg) | ![fig2](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F14.jpg) | ![fig3](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F15.jpg) |![fig4](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F16.jpg) |![fig5](https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/install_F17.jpg) |

## Calibrar

:::tip
Los c√≥digos del SO100 y SO101 son compatibles. Los usuarios del SO100 pueden utilizar directamente los par√°metros y c√≥digo del SO101 para la operaci√≥n.
:::

:::danger
Si compraste el **SO101 Arm Kit Standard Edition**, todas las fuentes de alimentaci√≥n son de 5V. Si compraste el **SO101 Arm Kit Pro Edition**, el Brazo L√≠der debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 5V, mientras que el Brazo Seguidor debe calibrarse y operarse en cada paso usando una fuente de alimentaci√≥n de 12V.
:::

A continuaci√≥n, necesitas conectar la fuente de alimentaci√≥n y el cable de datos a tu robot SO-10x para la calibraci√≥n para asegurar que los brazos l√≠der y seguidor tengan los mismos valores de posici√≥n cuando est√©n en la misma posici√≥n f√≠sica. Esta calibraci√≥n es esencial porque permite que una red neuronal entrenada en un robot SO-10x funcione en otro. Si necesitas recalibrar el brazo rob√≥tico, elimina los archivos bajo `~/.cache/huggingface/lerobot/calibration/robots` o `~/.cache/huggingface/lerobot/calibration/teleoperators` y recalibra el brazo rob√≥tico. De lo contrario, aparecer√° un mensaje de error. La informaci√≥n de calibraci√≥n del brazo rob√≥tico se almacenar√° en los archivos JSON bajo este directorio.

**Calibraci√≥n manual del brazo seguidor**

Por favor conecta las interfaces de los 6 servos del robot mediante un cable de 3 pines y conecta el servo del chasis a la placa de control del servo, luego ejecuta el siguiente comando o ejemplo de API para calibrar el brazo rob√≥tico:

***Primero se otorgan permisos de interfaz***

```bash
sudo chmod 666 /dev/ttyACM*
```

***Luego calibra el brazo seguidor***

```python
lerobot-calibrate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \# <- The port of your robot
    --robot.id=my_awesome_follower_arm  # <- Give the robot a unique name
```

El video a continuaci√≥n muestra c√≥mo realizar la calibraci√≥n. Primero necesitas mover el robot a la posici√≥n donde todas las articulaciones est√©n en el medio de sus rangos. Luego, despu√©s de presionar enter, tienes que mover cada articulaci√≥n a trav√©s de su rango completo de movimiento.

**Calibraci√≥n manual del brazo l√≠der**

Realiza los mismos pasos para calibrar el brazo l√≠der, ejecuta el siguiente comando o ejemplo de API:

```python
lerobot-calibrate \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \# <- The port of your robot
    --teleop.id=my_awesome_leader_arm  # <- Give the robot a unique name
```

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/22n6f5xH9Dk?si=2QTzn1CDbsSv6Y_H" title="youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Teleoperar

**Teleoperaci√≥n simple**
¬°Entonces est√°s listo para teleoperar tu robot! Ejecuta este script simple (no se conectar√° ni mostrar√° las c√°maras):

Ten en cuenta que el id asociado con un robot se usa para almacenar el archivo de calibraci√≥n. Es importante usar el mismo id al teleoperar, grabar y evaluar cuando uses la misma configuraci√≥n.

```bash
sudo chmod 666 /dev/ttyACM*
```

```bash
lerobot-teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm
```

El comando teleoperate autom√°ticamente:

1. Identificar√° cualquier calibraci√≥n faltante e iniciar√° el procedimiento de calibraci√≥n.
2. Conectar√° el robot y el dispositivo de teleoperaci√≥n e iniciar√° la teleoperaci√≥n.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/hnRwfcyX1ZI?si=RuzYjP_FUTK16lfs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Agregar c√°maras

<details>
<summary> Si usas la C√°mara de Profundidad Orbbec Gemini2 </summary>

<div align="center">
    <img width={800}
    src="https://media-cdn.seeedstudio.com/media/catalog/product/cache/bb49d3ec4ee05b6f018e93f896b8a25d/0/-/0-101090144--orbbec-gemini-2-3d-camera.jpg" />
</div>
<div class="get_one_now_container" style={{textAlign: 'center'}}>
<a class="get_one_now_item" href="https://www.seeedstudio.com/Orbbec-Gemini-2-3D-Camera-p-6464.html" target="_blank" rel="noopener noreferrer" >
            <strong><span><font color={'FFFFFF'} size={"4"}> Obtener Uno Ahora üñ±Ô∏è</font></span></strong>
</a></div>

- üöÄ Paso 1: Instalar el Entorno Dependiente del SDK de Orbbec

1. Clonar el repositorio `pyorbbec`

   ```bash
   cd ~/
   git clone https://github.com/orbbec/pyorbbecsdk.git
   ```

2. Descargar e instalar el **archivo .whl** correspondiente para el SDK  
   Ve a [pyorbbecsdk Releases](https://github.com/orbbec/pyorbbecsdk/releases),  
   selecciona e instala bas√°ndote en tu versi√≥n de Python. Por ejemplo:

   ```bash
   pip install pyorbbecsdk-x.x.x-cp310-cp310-linux_x86_64.whl
   ```

3. Instalar dependencias en el directorio `pyorbbec`

   ```bash
   cd ~/pyorbbecsdk
   pip install -r requirements.txt
   ```

   Forzar la degradaci√≥n de la versi√≥n de `numpy` a `1.26.0`

    ```bash
    pip install numpy==1.26.0
    ```

  Los mensajes de error rojos pueden ser ignorados.

4. Clonar el SDK de Orbbec en el directorio `~/lerobot/src/cameras`

  ```bash
  cd ~/lerobot/src/cameras
  git clone https://github.com/ZhuYaoHui1998/orbbec.git
  ```

5. Modificar utils.py y **init**.py

- Encuentra `utils.py` en el directorio `~/lerobot/src/lerobot/cameras`, y agrega el siguiente c√≥digo en la l√≠nea 40:

```python
elif cfg.type == "orbbec":
            from .orbbec.camera_orbbec import OrbbecCamera

            cameras[key] = OrbbecCamera(cfg)
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/utils.png" />
</div>

- Encuentra `__init__.py` en el directorio `~/lerobot/src/lerobot/cameras`, y agrega el siguiente c√≥digo en la l√≠nea 18:

```python
from .orbbec.configuration_orbbec import OrbbecCameraConfig
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/init.png" />
</div>

- üöÄ Paso 2: Llamada de Funci√≥n y Ejemplos

En todos los siguientes ejemplos, reemplaza `so101_follower` con el modelo real del brazo rob√≥tico que est√©s usando (ej., `so100` / `so101`).

Hemos agregado el hiperpar√°metro `focus_area`. Dado que los datos de profundidad que est√°n demasiado lejos no tienen sentido para el brazo rob√≥tico (no puede alcanzar o agarrar objetos), los datos de profundidad menores o mayores que el `focus_area` se mostrar√°n en negro. El `focus_area` predeterminado es (20, 600).  
Actualmente, la √∫nica resoluci√≥n soportada es ancho: 640, alto: 880.

```bash
lerobot-teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ up: {type: orbbec, width: 640, height: 880, fps: 30, focus_area:[60,300]}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/orbbec_result.png" />
</div>

Para tareas posteriores como recolecci√≥n de datos, entrenamiento y evaluaci√≥n, el proceso es el mismo que para comandos RGB regulares. Solo necesitas reemplazar la parte relevante en el comando RGB regular con:

```bash
  --robot.cameras="{ up: {type: orbbec, width: 640, height: 880, fps: 30, focus_area:[60,300]}}" \
```

Tambi√©n puedes agregar una c√°mara RGB monocular adicional despu√©s.

</details>

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Para instanciar una c√°mara, necesitas un identificador de c√°mara. Este identificador podr√≠a cambiar si reinicias tu computadora o reconectas tu c√°mara, un comportamiento que depende principalmente de tu sistema operativo.

Para encontrar los √≠ndices de c√°mara de las c√°maras conectadas a tu sistema, ejecuta el siguiente script:

```python
lerobot-find-cameras opencv # or realsense for Intel Realsense cameras
```

La terminal imprimir√° la siguiente informaci√≥n.

```markdown
--- Detected Cameras ---
Camera #0:
  Name: OpenCV Camera @ 0
  Type: OpenCV
  Id: 0
  Backend api: AVFOUNDATION
  Default stream profile:
    Format: 16.0
    Width: 1920
    Height: 1080
    Fps: 15.0
--------------------
(more cameras ...)
```

Puedes encontrar las im√°genes tomadas por cada c√°mara en el directorio `outputs/captured_images`.

:::warning
Al usar c√°maras Intel RealSense en macOS, podr√≠as obtener este error: Error finding RealSense cameras: failed to set power state, esto se puede resolver ejecutando el mismo comando con permisos sudo. Ten en cuenta que usar c√°maras RealSense en macOS es inestable.
:::

Entonces podr√°s mostrar las c√°maras en tu computadora mientras teleoper√°s ejecutando el siguiente c√≥digo. Esto es √∫til para preparar tu configuraci√≥n antes de grabar tu primer conjunto de datos.

```bash
lerobot-teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

Si tienes m√°s c√°maras, puedes cambiar `--robot.cameras` para agregar c√°maras. Debes notar el formato del index_or_path, que est√° determinado por el √∫ltimo d√≠gito del ID de c√°mara mostrado por `python -m lerobot.find_cameras opencv`.

:::tip
Las im√°genes en formato `fourcc: "MJPG"` est√°n comprimidas. Puedes probar resoluciones m√°s altas, y tambi√©n puedes intentar el formato `YUYV`. Sin embargo, este √∫ltimo reducir√° la resoluci√≥n de imagen y FPS, causando retraso en la operaci√≥n del brazo rob√≥tico. Actualmente, bajo el formato `MJPG`, puede soportar 3 c√°maras a una resoluci√≥n de `1920*1080` manteniendo `30FPS`. Dicho esto, conectar 2 c√°maras a una computadora a trav√©s del mismo USB HUB a√∫n no se recomienda.
:::


Por ejemplo, quieres agregar una c√°mara lateral:

```bash
lerobot-teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true
```

:::tip
Las im√°genes en formato `fourcc: "MJPG"` est√°n comprimidas. Puedes probar resoluciones m√°s altas, y tambi√©n puedes intentar el formato `YUYV`. Sin embargo, este √∫ltimo reducir√° la resoluci√≥n de imagen y FPS, causando retraso en la operaci√≥n del brazo rob√≥tico. Actualmente, bajo el formato `MJPG`, puede soportar 3 c√°maras a una resoluci√≥n de `1920*1080` manteniendo `30FPS`. Dicho esto, conectar 2 c√°maras a una computadora a trav√©s del mismo USB HUB a√∫n no se recomienda.
:::


:::tip
Si encuentras un error como este.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/starai/rerun-version.png" />
</div>

Puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/EUcXlLlOjGE?si=6ncQ7o5ZFLR4PGTU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Grabar el conjunto de datos

- Si quieres guardar el conjunto de datos localmente, puedes ejecutarlo directamente:

```bash
lerobot-record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=seeedstudio123/test \
    --dataset.num_episodes=5 \
    --dataset.single_task="Grab the black cube" \
    --dataset.push_to_hub=false \
    --dataset.episode_time_s=30 \
    --dataset.reset_time_s=30 
```

Entre ellos, `repo_id` se puede modificar de forma personalizada, y `push_to_hub=false`. Finalmente, el conjunto de datos se guardar√° en el directorio `~/.cache/huggingface/lerobot` en la carpeta de inicio, donde se crear√° la carpeta `seeedstudio123/test` mencionada anteriormente.

- Si quieres usar las funciones del hub de Hugging Face para subir tu conjunto de datos y no lo has hecho anteriormente, aseg√∫rate de haber iniciado sesi√≥n usando un token de acceso de escritura, que se puede generar desde la [configuraci√≥n de Hugging Face](https://huggingface.co/settings/tokens):

```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Almacena el nombre de tu repositorio de Hugging Face en una variable para ejecutar estos comandos:

```bash
HF_USER=$(huggingface-cli whoami | head -n 1)
echo $HF_USER
```

Graba 5 episodios y sube tu conjunto de datos al hub:

```bash
lerobot-record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"}, side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=${HF_USER}/record-test \
    --dataset.num_episodes=5 \
    --dataset.single_task="Grab the black cube" \
    --dataset.push_to_hub=true \
    --dataset.episode_time_s=30 \
    --dataset.reset_time_s=30 
```

Ver√°s muchas l√≠neas apareciendo como esta:

```bash
INFO 2024-08-10 15:02:58 ol_robot.py:219 dt:33.34 (30.0hz) dtRlead: 5.06 (197.5hz) dtWfoll: 0.25 (3963.7hz) dtRfoll: 6.22 (160.7hz) dtRlaptop: 32.57 (30.7hz) dtRphone: 33.84 (29.5hz)
```

**Funci√≥n de grabaci√≥n**

La funci√≥n **record** proporciona un conjunto de herramientas para capturar y gestionar datos durante la operaci√≥n del robot.  

**1. Almacenamiento de Datos**

- Los datos se almacenan usando el formato `LeRobotDataset` y se guardan en disco durante la grabaci√≥n.
- Por defecto, el conjunto de datos se sube a tu p√°gina de Hugging Face despu√©s de la grabaci√≥n.  
- Para deshabilitar la subida, usa: `--dataset.push_to_hub=False`

**2. Puntos de Control y Reanudaci√≥n**

- Los puntos de control se crean autom√°ticamente durante la grabaci√≥n.  
- Para reanudar despu√©s de una interrupci√≥n, vuelve a ejecutar el mismo comando con: `--resume=true`

‚ö†Ô∏è Nota Cr√≠tica: Al reanudar, establece `--dataset.num_episodes` al n√∫mero de episodios adicionales a grabar (no el n√∫mero total objetivo de episodios en el conjunto de datos).  

- Para comenzar a grabar desde cero, **elimina manualmente** el directorio del conjunto de datos.

**3. Par√°metros de Grabaci√≥n**

Configura el flujo de grabaci√≥n de datos usando argumentos de l√≠nea de comandos:

| Par√°metro | Descripci√≥n | Por defecto |  
|-----------|-------------|---------|  
| --dataset.episode_time_s | Duraci√≥n por episodio de datos (segundos) | 60 |  
| --dataset.reset_time_s | Tiempo de reinicio del entorno despu√©s de cada episodio (segundos) | 60 |  
| --dataset.num_episodes | Total de episodios a grabar | 50 |  

**4. Controles de Teclado Durante la Grabaci√≥n**

Controla el flujo de grabaci√≥n de datos usando atajos de teclado:

| Tecla | Acci√≥n |  
|-----|--------|  
| ‚Üí (Flecha Derecha) | Detener temprano el episodio actual/reiniciar; pasar al siguiente. |  
| ‚Üê (Flecha Izquierda) | Cancelar episodio actual; volver a grabarlo. |  
| ESC | Detener sesi√≥n inmediatamente, codificar videos y subir conjunto de datos. |  

:::tip

Si el teclado no funciona, es posible que necesites instalar otra versi√≥n de pynput.

```bash
pip install pynput==1.6.8
```

:::

**Consejos para Recopilar Datos**

- Sugerencia de Tarea: Agarrar objetos en diferentes ubicaciones y colocarlos en un contenedor.  
- Escala: Grabar ‚â•50 episodios (10 episodios por ubicaci√≥n).  
- Consistencia:  
  - Mantener las c√°maras fijas.  
  - Mantener un comportamiento de agarre id√©ntico.  
  - Asegurar que los objetos manipulados sean visibles en las transmisiones de la c√°mara.  
- Progresi√≥n:  
  - Comenzar con un agarre confiable antes de agregar variaciones (nuevas ubicaciones, t√©cnicas, ajustes de c√°mara).  
  - Evitar aumentos r√°pidos de complejidad para prevenir fallos.  

üí° Regla General: Deber√≠as poder hacer la tarea t√∫ mismo solo mirando las im√°genes de la c√°mara.  

Si quieres profundizar en este tema importante, puedes consultar la [publicaci√≥n del blog](https://huggingface.co/blog/lerobot-datasets#what-makes-a-good-dataset) que escribimos sobre qu√© hace un buen conjunto de datos.

**Soluci√≥n de Problemas**

Problema espec√≠fico de Linux:  
Si las teclas Flecha Derecha/Flecha Izquierda/ESC no responden durante la grabaci√≥n:  

- Verifica que la variable de entorno `$DISPLAY` est√© configurada (ver [limitaciones de pynput](https://pynput.readthedocs.io/en/latest/limitations.html)).  

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=-eDB73KgUksyJXa-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## Visualizar el conjunto de datos

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Si subiste tu conjunto de datos al hub con `--control.push_to_hub=true`, puedes [visualizar tu conjunto de datos en l√≠nea](https://huggingface.co/spaces/lerobot/visualize_dataset) copiando y pegando tu repo id dado por:

```bash
echo ${HF_USER}/so101_test  
```

Si no subiste con `--dataset.push_to_hub=false`, tambi√©n puedes visualizarlo localmente con:

```bash
lerobot-dataset-viz \
  --repo-id ${HF_USER}/so101_test \
```

Si subes con `--dataset.push_to_hub=false`, tambi√©n puedes visualizarlo localmente con:

```bash
lerobot-dataset-viz \
  --repo-id seeed_123/so101_test \
```

**Aqu√≠, `seeed_123` es el nombre personalizado de `repo_id` definido al recopilar datos.**

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/visualize_datasets.png" />
</div>

## Reproducir un episodio

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Una funci√≥n √∫til es la funci√≥n `replay`, que te permite reproducir cualquier episodio que hayas grabado o episodios de cualquier conjunto de datos disponible. Esta funci√≥n te ayuda a probar la repetibilidad de las acciones de tu robot y evaluar la transferibilidad entre robots del mismo modelo.

Puedes reproducir el primer episodio en tu robot con el comando de abajo o con el ejemplo de API:

```bash
lerobot-replay \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --dataset.repo_id=${HF_USER}/record-test \
    --dataset.episode=0
```

Tu robot deber√≠a replicar movimientos similares a los que grabaste.

## Entrenar y Evaluar


<details>

<summary>[ACT](https://huggingface.co/docs/lerobot/act) </summary>

Consulta [ACT](https://huggingface.co/docs/lerobot/act)

Para entrenar una pol√≠tica para controlar tu robot, usa el script [lerobot-train](https://github.com/huggingface/lerobot/blob/main/src/lerobot/scripts/train.py). 

**Entrenar**


```bash
lerobot-train \
  --dataset.repo_id=${HF_USER}/so101_test \
  --policy.type=act \
  --output_dir=outputs/train/act_so101_test \
  --job_name=act_so101_test \
  --policy.device=cuda \
  --wandb.enable=false \
  --steps=300000 
```

**Si quieres entrenar en un conjunto de datos local, aseg√∫rate de que el `repo_id` coincida con el usado durante la recopilaci√≥n de datos y agrega `--policy.push_to_hub=False`.**

```bash
lerobot-train \
  --dataset.repo_id=seeedstudio123/test \
  --policy.type=act \
  --output_dir=outputs/train/act_so101_test \
  --job_name=act_so101_test \
  --policy.device=cuda \
  --wandb.enable=false \
  --policy.push_to_hub=false\
  --steps=300000 
```

Vamos a explicarlo:

- **Especificaci√≥n del conjunto de datos**: Proporcionamos el conjunto de datos a trav√©s del par√°metro `--dataset.repo_id=${HF_USER}/so101_test`.
- **Pasos de entrenamiento**: Modificamos el n√∫mero de pasos de entrenamiento usando `--steps=300000`. El algoritmo por defecto usa 800000 pasos, y puedes ajustarlo seg√∫n la dificultad de tu tarea y observando la p√©rdida durante el entrenamiento.
- **Tipo de pol√≠tica**: Proporcionamos la pol√≠tica con `policy.type=act`. De manera similar, puedes cambiar entre pol√≠ticas como [`act`, `diffusion`, `pi0`, `pi0fast`, `pi0fast`, `sac`, `smolvla`]., que cargar√° la configuraci√≥n desde `configuration_act.py`. Importante, esta pol√≠tica se adaptar√° autom√°ticamente a los estados del motor de tu robot (por ejemplo, `laptop` y `phone`), acciones del motor y el n√∫mero de c√°maras, ya que esta informaci√≥n ya est√° almacenada en tu conjunto de datos.
- **Selecci√≥n de dispositivo**: Proporcionamos `policy.device=cuda` porque estamos entrenando en una GPU Nvidia, pero puedes usar `policy.device=mps` para entrenar en Apple Silicon.
- **Herramienta de visualizaci√≥n**: Proporcionamos `wandb.enable=true` para visualizar gr√°ficos de entrenamiento usando [Weights and Biases](https://docs.wandb.ai/quickstart). Esto es opcional, pero si lo usas, aseg√∫rate de haber iniciado sesi√≥n ejecutando `wandb login`.


**Evaluar**

:::tip
Los c√≥digos SO100 y SO101 son compatibles. Los usuarios de SO100 pueden utilizar directamente los par√°metros y c√≥digo de SO101 para la operaci√≥n.
:::

Puedes usar la funci√≥n `record` de [`lerobot/record.py`](https://github.com/huggingface/lerobot/blob/main/lerobot/record.py) pero con un punto de control de pol√≠tica como entrada. Por ejemplo, ejecuta este comando para grabar 10 episodios de evaluaci√≥n:

```bash
lerobot-record \
  --robot.type=so100_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{ up: {type: opencv, index_or_path: /dev/video10, width: 640, height: 480, fps: 30, fourcc: "MJPG"}, side: {type: intelrealsense, serial_number_or_name: 233522074606, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=${HF_USER}/eval_so100 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=${HF_USER}/my_policy
```

como por ejemplo:

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"},   side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=seeed/eval_test123 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=outputs/train/act_so101_test/checkpoints/last/pretrained_model
```

1. El par√°metro `--policy.path` indica la ruta al archivo de pesos de los resultados de entrenamiento de tu pol√≠tica (por ejemplo, `outputs/train/act_so101_test/checkpoints/last/pretrained_model`). Si subes el archivo de pesos del resultado del entrenamiento del modelo a Hub, tambi√©n puedes usar el repositorio del modelo (por ejemplo, `${HF_USER}/act_so100_test`).

2. El nombre del conjunto de datos `dataset.repo_id` comienza con `eval_`. Esta operaci√≥n registrar√° por separado videos y datos durante la evaluaci√≥n, que se guardar√°n en la carpeta que comience con `eval_`, como `seeed/eval_test123`.

3. Si encuentras `File exists: 'home/xxxx/.cache/huggingface/lerobot/xxxxx/seeed/eval_xxxx'` durante la fase de evaluaci√≥n, por favor elimina primero la carpeta que comience con `eval_` y luego ejecuta el programa nuevamente.

4. Cuando encuentres `mean is infinity. You should either initialize with stats as an argument or use a pretrained model`, ten en cuenta que las palabras clave como front y side en el par√°metro `--robot.cameras` deben ser estrictamente consistentes con las utilizadas al recopilar el conjunto de datos.

<div class="video-container">
<iframe width="900" height="600" src="https://www.youtube.com/embed/wc-qh7UFkuQ?si=Y2SXU9T0DSmtz4ll" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>


</details>


<details>
<summary> SmolVLA </summary>

[SmolVLA](https://huggingface.co/docs/lerobot/smolvla) es el modelo fundacional ligero de Hugging Face para rob√≥tica. Dise√±ado para un ajuste fino f√°cil en conjuntos de datos de LeRobot, ¬°ayuda a acelerar tu desarrollo!

**Configura Tu Entorno**

Instala las dependencias de SmolVLA ejecutando:

```bash
pip install -e ".[smolvla]"
```

**Ajusta SmolVLA con tus datos**

Usa [smolvla_base](https://hf.co/lerobot/smolvla_base), nuestro modelo preentrenado de 450M, y aj√∫stalo con tus datos. Entrenar el modelo durante 20k pasos tomar√° aproximadamente ~4 horas en una sola GPU A100. Debes ajustar el n√∫mero de pasos bas√°ndote en el rendimiento y tu caso de uso.

Si no tienes un dispositivo GPU, puedes entrenar usando nuestro notebook en [Google Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/lerobot/training-smolvla.ipynb).

Pasa tu conjunto de datos al script de entrenamiento usando `--dataset.repo_id`. Si quieres probar tu instalaci√≥n, ejecuta el siguiente comando donde usamos uno de los conjuntos de datos que recopilamos para el [Art√≠culo de SmolVLA](https://huggingface.co/papers/2506.01844).

```bash
lerobot-train \
  --policy.path=lerobot/smolvla_base \
  --dataset.repo_id=${HF_USER}/mydataset \
  --batch_size=64 \
  --steps=20000 \
  --output_dir=outputs/train/my_smolvla \
  --job_name=my_smolvla_training \
  --policy.device=cuda \
  --wandb.enable=true
```

:::tip
Puedes comenzar con un tama√±o de lote peque√±o y aumentarlo incrementalmente, si la GPU lo permite, siempre que los tiempos de carga se mantengan cortos.
:::

El ajuste fino es un arte. Para una visi√≥n completa de las opciones para el ajuste fino, ejecuta

```bash
lerobot-train --help
```

**Eval√∫a el modelo ajustado y ejec√∫talo en tiempo real**

De manera similar a cuando grabas un episodio, se recomienda que hayas iniciado sesi√≥n en HuggingFace Hub. Puedes seguir los pasos correspondientes: [Grabar un conjunto de datos](https://huggingface.co/docs/lerobot/il_robots). Una vez que hayas iniciado sesi√≥n, puedes ejecutar la inferencia en tu configuraci√≥n haciendo:

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \ # <- Use your port
  --robot.id=my_blue_follower_arm \ # <- Use your robot id
  --robot.cameras="{ front: {type: opencv, index_or_path: 8, width: 640, height: 480, fps: 30, fourcc: "MJPG"}}" \ # <- Use your cameras
  --dataset.single_task="Grasp a lego block and put it in the bin." \ # <- Use the same task description you used in your dataset recording
  --dataset.repo_id=${HF_USER}/eval_DATASET_NAME_test \  # <- This will be the dataset name on HF Hub
  --dataset.episode_time_s=50 \
  --dataset.num_episodes=10 \
  # <- Teleop optional if you want to teleoperate in between episodes \
  # --teleop.type=so100_leader \
  # --teleop.port=/dev/ttyACM0 \
  # --teleop.id=my_red_leader_arm \
  --policy.path=HF_USER/FINETUNE_MODEL_NAME # <- Use your fine-tuned model
```

Dependiendo de tu configuraci√≥n de evaluaci√≥n, puedes configurar la duraci√≥n y el n√∫mero de episodios a grabar para tu suite de evaluaci√≥n.

</details>

<details>
<summary> LIBERO </summary>

[LIBERO](https://huggingface.co/docs/lerobot/libero) es un benchmark dise√±ado para estudiar el aprendizaje rob√≥tico de por vida. La idea es que los robots no solo ser√°n preentrenados una vez en una f√°brica, necesitar√°n seguir aprendiendo y adapt√°ndose con sus usuarios humanos a lo largo del tiempo. Esta adaptaci√≥n continua se llama aprendizaje de por vida en la toma de decisiones (LLDM), y es un paso clave hacia la construcci√≥n de robots que se conviertan en verdaderos asistentes personalizados.

- üìÑ [Art√≠culo de LIBERO](https://arxiv.org/abs/2306.03310)
- üíª [Repositorio original de LIBERO](https://github.com/Lifelong-Robot-Learning/LIBERO)

**Evaluando con LIBERO**

En **LeRobot**, portamos LIBERO a nuestro framework y lo usamos principalmente para **evaluar** [SmolVLA](https://huggingface.co/docs/lerobot/en/smolvla), nuestro modelo ligero de Visi√≥n-Lenguaje-Acci√≥n.

LIBERO ahora es parte de nuestra **simulaci√≥n multi-eval soportada**, lo que significa que puedes hacer benchmark de tus pol√≠ticas ya sea en una **suite √∫nica de tareas** o a trav√©s de **m√∫ltiples suites a la vez** con solo una bandera.

Para instalar LIBERO, despu√©s de seguir las instrucciones oficiales de LeRobot, simplemente haz: `pip install -e ".[libero]"`

***Evaluaci√≥n de suite √∫nica***

Eval√∫a una pol√≠tica en una suite de LIBERO:

```bash
lerobot-eval \
  --policy.path="your-policy-id" \
  --env.type=libero \
  --env.task=libero_object \
  --eval.batch_size=2 \
  --eval.n_episodes=3
```

- `--env.task` selecciona la suite (`libero_object`, `libero_spatial`, etc.).
- `--eval.batch_size` controla cu√°ntos entornos se ejecutan en paralelo.
- `--eval.n_episodes` establece cu√°ntos episodios ejecutar en total.

***Evaluaci√≥n multi-suite***

Haz benchmark de una pol√≠tica a trav√©s de m√∫ltiples suites a la vez:

```bash
lerobot-eval \
  --policy.path="your-policy-id" \
  --env.type=libero \
  --env.task=libero_object,libero_spatial \
  --eval.batch_size=1 \
  --eval.n_episodes=2
```

- Pasa una lista separada por comas a `--env.task` para evaluaci√≥n multi-suite.

**Comando de entrenamiento de ejemplo**

```bash
lerobot-train \
  --policy.type=smolvla \
  --policy.repo_id=${HF_USER}/libero-test \
  --dataset.repo_id=HuggingFaceVLA/libero \
  --env.type=libero \
  --env.task=libero_10 \
  --output_dir=./outputs/ \
  --steps=100000 \
  --batch_size=4 \
  --eval.batch_size=1 \
  --eval.n_episodes=1 \
  --eval_freq=1000 \
```

-----

**Nota sobre renderizado**

LeRobot usa MuJoCo para simulaci√≥n. Necesitas configurar el backend de renderizado antes del entrenamiento o evaluaci√≥n:

- `export MUJOCO_GL=egl` ‚Üí para servidores sin cabeza (por ejemplo, HPC, nube)

</details>


<details>
<summary>[Pi0](https://huggingface.co/docs/lerobot/pi0) </summary>

Consulta [Pi0](https://huggingface.co/docs/lerobot/pi0) 

```bash
pip install -e ".[pi]"
```

**Entrenar**
```bash
lerobot-train \
  --policy.type=pi0 \
  --dataset.repo_id=seeed/eval_test123 \
  --job_name=pi0_training \
  --output_dir=outputs/pi0_training \
  --policy.pretrained_path=lerobot/pi0_base \
  --policy.compile_model=true \
  --policy.gradient_checkpointing=true \
  --policy.dtype=bfloat16 \
  --steps=20000 \
  --policy.device=cuda \
  --batch_size=32 \
  --wandb.enable=false 
```

**Evaluar**

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"},   side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30,fourcc: "MJPG"}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=seeed/eval_test123 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=outputs/pi0_training/checkpoints/last/pretrained_model
```


</details>


<details>
<summary>[Pi0.5](https://huggingface.co/docs/lerobot/pi05) </summary>

Consulta [Pi0.5](https://huggingface.co/docs/lerobot/pi05) 

```bash
pip install -e ".[pi]"
```

**Entrenar**
```bash
lerobot-train \
    --dataset.repo_id=seeed/eval_test123 \
    --policy.type=pi05 \
    --output_dir=outputs/pi05_training \
    --job_name=pi05_training \
    --policy.pretrained_path=lerobot/pi05_base \
    --policy.compile_model=true \
    --policy.gradient_checkpointing=true \
    --wandb.enable=false \
    --policy.dtype=bfloat16 \
    --steps=3000 \
    --policy.device=cuda \
    --batch_size=32
```

**Evaluar**

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30, fourcc: "MJPG"},   side: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30,fourcc: "MJPG"}}" \
  --robot.id=my_awesome_follower_arm \
  --display_data=false \
  --dataset.repo_id=seeed/eval_test123 \
  --dataset.single_task="Put lego brick into the transparent box" \
  --policy.path=outputs/pi05_training/checkpoints/last/pretrained_model
```


</details>



<details>
<summary>[GR00T N1.5](https://huggingface.co/docs/lerobot/groot) </summary>

Consulta [GR00T N1.5](https://huggingface.co/docs/lerobot/groot) 


</details>



Si encuentras el siguiente error:

<div align="center">
    <img width={1000}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/so101/stack_bug.png" />
</div>

Intenta ejecutar el siguiente comando para resolverlo:

```bash
pip install datasets==2.19
```

El entrenamiento deber√≠a tomar varias horas. Encontrar√°s checkpoints en `outputs/train/act_so100_test/checkpoints`.

Para reanudar el entrenamiento desde un checkpoint, a continuaci√≥n se muestra un comando de ejemplo para reanudar desde el checkpoint `last` de la pol√≠tica `act_so101_test`:

```bash
lerobot-train \
  --config_path=outputs/train/act_so101_test/checkpoints/last/pretrained_model/train_config.json \
  --resume=true
```

**Subir checkpoints de pol√≠tica**

Una vez que el entrenamiento est√© completo, sube el √∫ltimo checkpoint con:

```bash
huggingface-cli upload ${HF_USER}/act_so101_test \
  outputs/train/act_so101_test/checkpoints/last/pretrained_model
```

Tambi√©n puedes subir checkpoints intermedios con:

```bash
CKPT=010000
huggingface-cli upload ${HF_USER}/act_so101_test${CKPT} \
  outputs/train/act_so101_test/checkpoints/${CKPT}/pretrained_model
```



## FAQ

- Si est√°s siguiendo esta documentaci√≥n/tutorial, por favor clona el repositorio de GitHub recomendado `https://github.com/Seeed-Projects/lerobot.git`. El repositorio recomendado en esta documentaci√≥n es una versi√≥n estable verificada; el repositorio oficial de Lerobot se actualiza continuamente a la √∫ltima versi√≥n, lo que puede causar problemas imprevistos como diferentes versiones de conjuntos de datos, diferentes comandos, etc.

- Si encuentras el siguiente error al calibrar los IDs de los servos:

  ```bash
  `Motor ‚Äògripper‚Äô was not found, Make sure it is connected`
  ```

  Por favor verifica cuidadosamente si el cable de comunicaci√≥n est√° conectado correctamente al servo y si la fuente de alimentaci√≥n est√° proporcionando el voltaje correcto.

- Si encuentras:

  ```bash
  Could not connect on port "/dev/ttyACM0"
  ```

  Y puedes ver que ACM0 existe al ejecutar `ls /dev/ttyACM*`, significa que olvidaste otorgar permisos al puerto serie. Ingresa `sudo chmod 666 /dev/ttyACM*` en la terminal para solucionarlo.

- Si encuentras:

  ```bash
  No valid stream found in input file. Is -1 of the desired media type?
  ```

  Por favor instala ffmpeg 7.1.1 usando `conda install ffmpeg=7.1.1 -c conda-forge`.

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/robotics/projects/lerobot/lekiwi/No valid stream.png" />
</div>

- Si encuentras:

  ```bash
  ConnectionError: Failed to sync read 'Present_Position' on ids=[1,2,3,4,5,6] after 1 tries. [TxRxResult] There is no status packet!
  ```

  Necesitas verificar si el brazo rob√≥tico en el puerto correspondiente est√° encendido, y si los cables de datos de los servos del bus est√°n sueltos o desconectados. Si la luz de un servo no est√° encendida, significa que el cable del servo anterior est√° suelto.

- Si encuentras el siguiente error al calibrar el brazo rob√≥tico:

  ```bash
  Magnitude 30841 exceeds 2047 (max for sign_bit_index=11)
  ```

  Apaga y reinicia el brazo rob√≥tico, luego intenta calibrar nuevamente. Este m√©todo tambi√©n se puede usar si el √°ngulo MAX alcanza un valor de decenas de miles durante la calibraci√≥n. Si esto no funciona, necesitas recalibrar los servos correspondientes, incluyendo la calibraci√≥n mediana y la escritura de ID.

- Si encuentras durante la fase de evaluaci√≥n:

  ```bash
  File exists: 'home/xxxx/.cache/huggingface/lerobot/xxxxx/seeed/eval_xxxx'
  ```

  Por favor elimina primero la carpeta que comience con `eval_` y luego ejecuta el programa nuevamente.

- Si encuentras durante la fase de evaluaci√≥n:

  ```bash
  `mean` is infinity. You should either initialize with `stats` as an argument or use a pretrained model
  ```

  Por favor ten en cuenta que las palabras clave como "front" y "side" en el par√°metro `--robot.cameras` deben ser estrictamente consistentes con las utilizadas al recopilar el conjunto de datos.

- Si has reparado o reemplazado partes del brazo rob√≥tico, por favor elimina completamente los archivos bajo `~/.cache/huggingface/lerobot/calibration/robots` o `~/.cache/huggingface/lerobot/calibration/teleoperators` y recalibra el brazo rob√≥tico. De lo contrario, pueden aparecer mensajes de error, ya que la informaci√≥n de calibraci√≥n se almacena en archivos JSON en estos directorios.

- Entrenar ACT en 50 conjuntos de datos toma aproximadamente 6 horas en una laptop con RTX 3060 (8GB), y alrededor de 2-3 horas en computadoras con GPUs RTX 4090 o A100.

- Durante la recopilaci√≥n de datos, aseg√∫rate de que la posici√≥n de la c√°mara, el √°ngulo y la iluminaci√≥n ambiental sean estables. Reduce la cantidad de fondo inestable y peatones capturados por la c√°mara, ya que cambios excesivos en el entorno de despliegue pueden causar que el brazo rob√≥tico falle al agarrar correctamente.

- Para el comando de recopilaci√≥n de datos, aseg√∫rate de que el par√°metro `num-episodes` est√© configurado para recopilar datos suficientes. No pauses manualmente a la mitad, ya que la media y la varianza de los datos se calculan solo despu√©s de que la recopilaci√≥n de datos est√© completa, las cuales son necesarias para el entrenamiento.

- Si el programa indica que no puede leer datos de imagen de la c√°mara USB, aseg√∫rate de que la c√°mara USB no est√© conectada a trav√©s de un hub. La c√°mara USB debe estar conectada directamente al dispositivo para garantizar una velocidad de transmisi√≥n de imagen r√°pida.

- Si encuentras un error como `AttributeError: module 'rerun' has no attribute 'scalar'. Did you mean: 'scalars'?`, puedes degradar la versi√≥n de rerun para resolver el problema.

```bash
pip3 install rerun-sdk==0.23
```

:::tip
Si encuentras problemas de software o problemas de dependencias del entorno que no se pueden resolver, adem√°s de verificar la secci√≥n FAQ al final de este tutorial, por favor reporta el problema oportunamente a la [plataforma LeRobot](https://github.com/huggingface/lerobot) o al [canal de Discord de LeRobot](https://discord.gg/8TnwDdjFGU).
:::

## Cita

[‰∏≠ÊñáÊñáÊ°£](https://wiki.seeedstudio.com/cn/lerobot_so100m_new/)

Proyecto TheRobotStudio: [SO-ARM10x](https://github.com/TheRobotStudio/SO-ARM100)

Proyecto Huggingface: [Lerobot](https://github.com/huggingface/lerobot/tree/main)

Dnsty: [Jetson Containers](https://github.com/dusty-nv/jetson-containers/tree/master/packages/robots/lerobot)

[Jetson AI Lab](https://www.jetson-ai-lab.com/lerobot.html)

[Diffusion Policy](https://diffusion-policy.cs.columbia.edu/)

[ACT or ALOHA](https://tonyzhaozh.github.io/aloha/)

[TDMPC](https://www.nicklashansen.com/td-mpc/)

[VQ-BeT](https://sjlee.cc/vq-bet/)

## Soporte T√©cnico y Discusi√≥n de Productos

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para brindarte diferentes tipos de soporte para asegurar que tu experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para satisfacer diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
