---
description: Un asistente de IA completamente local e interactivo por voz que combina Speech-to-Text (STT), Text-to-Speech (TTS) y Modelos de Lenguaje Grande (LLMs) locales usando Ollama y NVIDIA Riva. Funciona completamente en dispositivos edge como NVIDIA Jetson ‚Äî permitiendo conversaciones de voz privadas, en tiempo real y naturales sin depender de la nube.
title: Chatbot en Jetson
image: https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png
slug: /es/local_chatbot_recomputer
last_update:
  date: 01/29/2025
  author: kourosh
---

# Construyendo un Chatbot Interactivo por Voz con LLMs Locales, STT y TTS

Este proyecto hace realidad el sue√±o de un **asistente de IA completamente interactivo por voz** ‚Äî funcionando completamente **en hardware local**, sin dependencia de servicios en la nube.  
Al combinar **Speech-to-Text (STT)**, **Text-to-Speech (TTS)** y **Modelos de Lenguaje Grande (LLMs) Locales** usando **Ollama**, el sistema permite conversaciones naturales, privadas y en tiempo real entre humanos y m√°quinas.

Toda la configuraci√≥n funciona dentro de contenedores Docker y puede desplegarse en **dispositivos NVIDIA Jetson**, **computadoras edge** o cualquier sistema basado en Linux con aceleraci√≥n GPU.

---

## Descripci√≥n General del Proyecto

El objetivo de este proyecto es crear un **chatbot controlado por voz** capaz de:

- Escuchar tu voz en tiempo real.
- Entender tu habla usando **ASR (Reconocimiento Autom√°tico de Voz)** local.
- Generar respuestas inteligentes usando un **LLM local**.
- Hablar esas respuestas naturalmente usando **TTS (Text-to-Speech)**.

Todos los componentes son aut√≥nomos y funcionan localmente, d√°ndote control total sobre tus datos ‚Äî sin dependencias de la nube, sin latencia, sin preocupaciones de privacidad.

---

## Componentes del Sistema

### 1. M√≥dulo Speech-to-Text (STT)

Transforma tu entrada hablada en texto en tiempo real.  
Caracter√≠sticas clave:

- Transcripci√≥n r√°pida y precisa usando **NVIDIA Riva ASR**.  
- Soporte para m√∫ltiples idiomas.  
- Optimizado para dispositivos edge.

### 2. M√≥dulo Text-to-Speech (TTS)

Convierte las respuestas del chatbot en salida de voz de sonido natural.  
Caracter√≠sticas destacadas:

- S√≠ntesis de voz multiling√ºe, expresiva y realista.  
- Impulsado por **NVIDIA Riva TTS**.  
- Baja latencia ‚Äî perfecto para conversaciones interactivas.

### 3. LLM Local (Ollama)

En el coraz√≥n del chatbot est√° **Ollama**, un motor de inferencia local para ejecutar LLMs modernos de manera eficiente.  
Caracter√≠sticas:

- Operaci√≥n sin conexi√≥n (no se necesita internet).  
- Respuestas en tiempo real incluso en dispositivos Jetson.  
- Retenci√≥n de contexto para di√°logo fluido y coherente.  
- Soporta varios modelos incluyendo Llama, Phi, Gemma, Mistral y m√°s.

### 4. Capa de Interacci√≥n del Usuario

Una interfaz simple e intuitiva permite a los usuarios:

- Iniciar o detener la interacci√≥n por voz mediante botones o comandos.  
- Ver transcripciones en vivo y respuestas del chatbot.  
- Disfrutar de comunicaci√≥n fluida y de baja latencia de voz a voz.

---

## Configurando Ollama Localmente

Comenzaremos instalando [Jetson Containers](https://github.com/dusty-nv/jetson-containers) para gestionar y desplegar f√°cilmente nuestros servicios dentro de Docker.

```bash
# Install Jetson Container tools
git clone https://github.com/dusty-nv/jetson-containers
bash jetson-containers/install.sh
```

Una vez instalado, descarga y ejecuta el contenedor **Ollama**:

```bash
jetson-containers run --name ollama $(autotag ollama)
ollama run llama3.2:1b
```

üí° **Consejo:** Comienza con modelos m√°s peque√±os (como `llama3.2:1b`) para probar tu configuraci√≥n, luego escala hacia arriba.

Modelos disponibles en [ollama.com/library](https://ollama.com/library):

| Modelo | Par√°metros | Tama√±o | Comando |
|--------|------------|--------|---------|
| Llama 3.2 | 3B | 2.0 GB | `ollama run llama3.2` |
| Llama 3.2 | 1B | 1.3 GB | `ollama run llama3.2:1b` |
| Llama 3.2 Vision | 11B | 7.9 GB | `ollama run llama3.2-vision` |
| Phi 3 Mini | 3.8B | 2.3 GB | `ollama run phi3` |
| Gemma 2 | 9B | 5.5 GB | `ollama run gemma2` |
| Mistral | 7B | 4.1 GB | `ollama run mistral` |

Si est√°s usando un **NVIDIA Jetson AGX**, puedes ejecutar c√≥modamente modelos medianos a grandes. Para Jetsons m√°s peque√±os, mantente con modelos ligeros (1B‚Äì3B).

Ejecuta Ollama ya sea directamente en terminal o a trav√©s del script Python proporcionado `ollama_run.py`.

```bash
python3 ollama_run.py
```

**Ejemplos:**

Uso en terminal  
<img src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/local_voice_chatbot/terminal_ollama.gif" width="700"/>

Integraci√≥n con Python  
<img src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/local_voice_chatbot/ollama_python.gif" width="700"/>

---

## NVIDIA Riva: STT y TTS

Para habilitar la interacci√≥n de voz real, usamos **NVIDIA Riva**, un kit de herramientas acelerado por GPU que proporciona:

- **Reconocimiento Autom√°tico de Voz (ASR)**  
- **Text-to-Speech (TTS)**  
- **Traducci√≥n Autom√°tica Neural (NMT)** (opcional)

Puede desplegarse en cualquier lugar ‚Äî desde la nube hasta dispositivos embebidos como la **serie Jetson**.

### Paso 1: Obt√©n tu Clave API de NGC

1. Inicia sesi√≥n en [NVIDIA NGC](https://catalog.ngc.nvidia.com/).
2. Crea una **clave API** y gu√°rdala localmente ‚Äî la necesitar√°s para acceder a los recursos de Riva.

### Paso 2: Configura NGC en Jetson

```bash
cd ~ && mkdir ngc_setup && cd ngc_setup
wget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.36.0/files/ngccli_arm64.zip
unzip ngccli_arm64.zip 
chmod u+x ngc-cli/ngc
echo "export PATH=\"$PATH:$(pwd)/ngc-cli\"" >> ~/.bash_profile && source ~/.bash_profile
ngc config set
```

Usa tu clave API cuando se te solicite.

### Paso 3: Instala Riva en Jetson

Aseg√∫rate de estar ejecutando **JetPack 6.0** (o verifica la compatibilidad en la [Matriz de Soporte](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/support-matrix.html)).

```bash
cd ~ && mkdir riva_setup && cd riva_setup
ngc registry resource download-version nvidia/riva/riva_quickstart_arm64:2.16.0
cd riva_quickstart_v2.13.1
```

En `config.sh`, deshabilita los servicios no utilizados para ahorrar recursos:

```bash
service_enabled_nlp=false
service_enabled_nmt=false
```

Luego configura Docker para usar el runtime de NVIDIA editando `/etc/docker/daemon.json`:

```json
{
  "default-runtime": "nvidia",
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }
}
```

Reinicia Docker:

```bash
sudo systemctl restart docker
```

Finalmente, inicializa e inicia Riva:

```bash
sudo bash riva_init.sh
sudo bash riva_start.sh
```

---

## Ejecutando el Chatbot

Una vez que todo est√© listo, ejecuta la aplicaci√≥n principal:

```bash
git clone https://github.com/kouroshkarimi/local_chatbot_jetson.git
cd local_chatbot_jetson
python3 app.py --list-input-devices
python3 app.py --list-output-devices
python3 app.py --input-device <your_input_id> --output-device <your_output_id>
```

Ahora puedes **hablar con tu asistente**, y **escuchar√°, pensar√° y te responder√°** ‚Äî todo localmente, impulsado por tu Jetson.

---

## Ventajas Clave

- üîí 100% privado ‚Äì ning√∫n dato sale de tu dispositivo  
- ‚ö° Respuesta en tiempo real ‚Äì optimizado para baja latencia  
- üåê Multiling√ºe ‚Äì soporta m√∫ltiples idiomas y acentos  
- üß© Modular ‚Äì cada componente puede ser reemplazado o extendido  
- üñ•Ô∏è Amigable para edge ‚Äì desplegable en Jetson o sistemas Linux est√°ndar

---

## Mejoras Futuras

- Integraci√≥n con **m√≥dulos de visi√≥n** para interacci√≥n multimodal  
- Soporte para **clonaci√≥n de voz personalizada** en TTS  
- **Persistencia de memoria** entre sesiones para di√°logo m√°s natural  
- Interfaz web o m√≥vil

---

## üéâ ¬°Disfruta tus Conversaciones!

Felicitaciones ‚Äî acabas de construir tu propio **asistente de IA habilitado por voz y que prioriza la privacidad**.  
Ahora si√©ntate, habla con tu robot y divi√©rtete explorando el futuro de la interacci√≥n humano-IA. ü§ñüí¨

> "TEN UNA BUENA CONVERSACI√ìN CON ROBOTS :)"

---

## Referencias

1. [RAG Local basado en Jetson con LlamaIndex](https://wiki.seeedstudio.com/es/Local_RAG_based_on_Jetson_with_LlamaIndex/)
2. [Chatbot de Voz Local: Despliega Riva y Llama2 en reComputer](https://wiki.seeedstudio.com/es/Local_Voice_Chatbot/)
3. [ChatTTS](https://github.com/2noise/ChatTTS)
4. [Speech to Text (STT) y Text to Speech (TTS)](https://www.librechat.ai/docs/configuration/stt_tts)
5. [Ollama](https://github.com/ollama/ollama)

---

## ‚ú® Proyecto de Colaborador

- Este proyecto est√° respaldado por el [Proyecto de Colaborador](https://github.com/orgs/Seeed-Studio/projects/6/views/1?pane=issue&itemId=30957479) de Seeed Studio.
- Un agradecimiento especial a [kourosh karimi](https://github.com/orgs/Seeed-Studio/projects/6/views/1?filterQuery=Building+a+Voice-Interactive+Chatbot+with+STT%2C+TTS%2C+and+Local+LLMs%21&pane=issue&itemId=74620249&issue=Seeed-Studio%7Cwiki-documents%7C1553) por sus esfuerzos dedicados. Tu trabajo ser√° [exhibido](https://wiki.seeedstudio.com/es/contributors/).

## Soporte T√©cnico y Discusi√≥n de Productos

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para brindarte diferentes tipos de soporte para asegurar que tu experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para atender diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
