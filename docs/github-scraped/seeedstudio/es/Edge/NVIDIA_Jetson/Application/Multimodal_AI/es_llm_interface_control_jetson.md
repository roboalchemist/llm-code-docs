---
description: Jetson LLM Interface Controller es un asistente de IA completamente local, controlado por voz y texto, que funciona completamente en dispositivos NVIDIA Jetson. Combina Modelos de Lenguaje Grande locales (a trav√©s de Ollama) con Speech-to-Text y Text-to-Speech opcionales (NVIDIA Riva) para traducir comandos humanos naturales en acciones de hardware estructuradas y seguras. El sistema permite control privado y de baja latencia de interfaces integradas (GPIO, I2C, PWM, etc.) y sirve como una base modular para aplicaciones de IA en el borde como entornos inteligentes, rob√≥tica y agentes habilitados por visi√≥n‚Äîsin depender de la nube.
title: Agente LLM Local en Jetson para Control Seguro de Interfaces de Hardware
image: https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png
slug: /es/llm_interface_control_jetson
last_update:
  date: 01/29/2025
  author: kourosh
---


# Jetson LLM Interface Controller

![enter image description here](https://www.seeedstudio.com/blog/wp-content/uploads/2024/03/image-1030x616.png)

 Bienvenido, creador, so√±ador y constructor. Este no es solo otro proyecto de automatizaci√≥n del hogar‚Äîes el puente entre el pensamiento humano y la acci√≥n embebida. Al combinar el poder computacional bruto de un **NVIDIA Jetson Orin NX** con las capacidades de razonamiento de un Modelo de Lenguaje Grande local, est√°s creando un sistema nervioso inteligente para tu hogar, laboratorio o espacio creativo.

Imagina susurrar *"haz que la habitaci√≥n se sienta como un caf√© acogedor"* y ver las luces atenuarse, comenzar m√∫sica suave y el termostato ajustarse‚Äîtodo orquestado por una IA que verdaderamente *entiende* tu intenci√≥n. O imagina un agente consciente de la seguridad monitoreando la habitaci√≥n de un beb√© a trav√©s de una c√°mara, describiendo la escena y alert√°ndote al primer signo de peligro.

Este repositorio es tu plataforma de lanzamiento. Demuestra c√≥mo el lenguaje natural‚Äîya sea escrito o hablado‚Äîpuede transformarse en comandos de hardware precisos, ejecutados en tiempo real en el borde. El LLM act√∫a como un **"compilador neural"**‚Äîtraduciendo solicitudes humanas difusas en JSON estructurado y ejecutable sobre el cual tu Jetson puede actuar.

En esta wiki voy a escribir un punto de partida para crear tu propio agente asistente del hogar basado en recomputer Nvidia Jetson Orin nx. Este proyecto usa interfaces de Jetson para controlar el entorno y tendr√°s experiencia pr√°ctica con interfaces y mezclarlas con un agente LLM para convertir el prompt del usuario en comando debido a que Jetson sabe qu√© hacer. En otras palabras, el LLM es como un mapeo desde texto de usuario o voz (si quieres puedes agregar STT y TTS f√°cilmente al proyecto) a un comando que es comprensible para Jetson y tu controlador de hogar codificado. Incluso puedes expandir este proyecto y agregar algunas cosas m√°s interesantes como VLM. Por ejemplo, puedes agregar una c√°mara e intentar describir la habitaci√≥n del beb√© y si ocurre un peligro, el agente da una retroalimentaci√≥n o una llamada a tu m√≥vil.

Puedes ver el c√≥digo en [ESTE](https://github.com/kouroshkarimi/llm_interface_controll) enlace.

## ‚ú® Lo Que Este Proyecto Trae a la Vida

- **üß† An√°lisis Inteligente de Comandos**
  Un LLM local (como Llama, Mistral, u otro modelo ejecut√°ndose en tu Jetson) es cuidadosamente instruido para mapear texto de forma libre a comandos estructurados. La ingenier√≠a de prompts est√° capturada en [`models/jetson-controller.txt`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/models/jetson-controller.txt) un plano para ense√±ar al modelo tu dominio.

- **üåê API Minimalista y Robusta**
  Un endpoint limpio de FastAPI ([`app/main.py`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/main.py)) acepta solicitudes de usuario y orquesta todo el pipeline‚Äîan√°lisis, validaci√≥n y ejecuci√≥n‚Äîcon elegancia y velocidad.

- **‚ö° Capa de Abstracci√≥n de Hardware**
  Sum√©rgete en [`app/hardware_controller.py`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/hardware_controller.py) para encontrar rutinas para GPIO, PWM, I2C y m√°s. Aqu√≠ es donde los pulsos de software se convierten en acciones f√≠sicas: las luces se iluminan, los motores giran, los sensores leen.

- **üîó Integraci√≥n de Agente LLM**
  El m√≥dulo [`app/llm_agent.py`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/llm_agent.py) es un envoltorio delgado y adaptable que se comunica con tu servidor de modelo local. Intercambia modelos, ajusta par√°metros, o incluso cambia APIs sin romper el flujo.

- **üì¶ Analizador de Salida Estructurada**
  Extrae de manera confiable JSON de la respuesta del modelo con [`app/command_parser.py`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/command_parser.py). Asegura que incluso las salidas creativas del LLM se conviertan en comandos predecibles y ejecutables.

---

## üß≠ Navegaci√≥n y Enlaces R√°pidos

**Puntos de Entrada Principales**

- üö™ Gateway de API: [`app/main.py`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/main.py) ‚Äî El coraz√≥n FastAPI del sistema.
- üß© Analizador de Comandos: [`app.command_parser.parse_command`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/command_parser.py) ‚Äî De texto a estructura.
- üß† Comunicador LLM: [`app.llm_agent.ask_llm`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/llm_agent.py) ‚Äî Conversaciones con el modelo.
- ‚öôÔ∏è Ejecutor de Hardware: [`app.hardware_controller.execute`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/app/hardware_controller.py) ‚Äî Donde los comandos se convierten en acci√≥n.
- üìñ Prompt del Modelo: [`models/jetson-controller.txt`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/models/jetson-controller.txt) ‚Äî La "personalidad" de tu agente.
- üì¶ Dependencias: [`requirements.txt`](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/requirements.txt) ‚Äî Paquetes de Python para alimentar tu viaje.

## üåå Filosof√≠a y Visi√≥n

Este proyecto est√° construido sobre una idea simple y poderosa: **tus palabras deber√≠an controlar tu mundo.**
Al ejecutar un LLM localmente en el Jetson, aseguramos privacidad, baja latencia y personalizaci√≥n infinita. El sistema es deliberadamente modular‚Äîcada componente es una pieza de rompecabezas que puedes reemplazar, actualizar o reimaginar.

Pi√©nsalo como:

- Un **traductor** entre la intuici√≥n humana y la precisi√≥n de la m√°quina.
- Un **andamio** para construir entornos conscientes del contexto.
- Un **patio de juegos** para experimentar con IA en el borde.

---

## üß¨ El Lenguaje de Comandos: Esquema JSON

El LLM est√° entrenado para responder con una estructura JSON consistente‚Äîun contrato entre la comprensi√≥n de la IA y las capacidades del hardware.

```json
{
  "intent": "control_device | query_status | general_help | unknown",
  "device": "lights | fan | thermostat | garage | coffee_machine | speaker",
  "action": "on | off | set | query | play | pause",
  "location": "kitchen | bedroom | living_room | office",
  "parameters": {"brightness": 80, "temperature": 22},
  "confidence": 0.95
}
```

Cada campo cuenta una historia:

- **intent** ‚Äî El objetivo de alto nivel de la solicitud.
- **device & action** ‚Äî El hardware objetivo y la operaci√≥n a realizar.
- **location** ‚Äî Contexto espacial para configuraciones multi-habitaci√≥n o multi-zona.
- **parameters** ‚Äî Control de grano fino (niveles de atenuaci√≥n, temperaturas exactas, velocidades, etc.).
- **confidence** ‚Äî La certeza auto-evaluada del modelo, usada para controlar acciones riesgosas o ambiguas.

El prompt completo‚Äîincluyendo ejemplos de esquema y gu√≠a de tono‚Äîvive en:

```
models/jetson-controller.txt
```

---

## ‚öôÔ∏è Arquitectura: C√≥mo Fluye la Magia

### Viaje Paso a Paso

1. **La Invocaci√≥n**  
   Una solicitud `POST` llega a `/command`, llevando lenguaje natural.

2. **El Di√°logo**  
   El analizador consulta al LLM a trav√©s de `ask_llm()` para interpretar la solicitud.

3. **El Razonamiento**  
   Un modelo local (por ejemplo, una variante de 7B par√°metros) procesa el prompt y devuelve JSON estructurado.

4. **La Extracci√≥n**  
   El analizador valida, limpia y normaliza el JSON, asegurando que coincida con el esquema esperado.

5. **La Ejecuci√≥n**  
   `execute()` despacha el comando al manejador de hardware apropiado:

   - **Luces** ‚Üí pines GPIO, PWM para atenuaci√≥n
   - **Ventilador** ‚Üí GPIO o PWM para control de velocidad
   - **Termostato** ‚Üí comunicaci√≥n I2C con sensores de temperatura
   - **Altavoz** ‚Üí llamadas de subproceso `amixer` para volumen y reproducci√≥n

6. **El Bucle de Retroalimentaci√≥n**  
   El sistema devuelve un mensaje de √©xito o falla, cerrando la interacci√≥n.

---

## üîß Instalaci√≥n: Primeros Pasos

### Prerrequisitos

- Un **NVIDIA Jetson** (Orin NX recomendado) ejecutando JetPack
- **Python 3.8+**
- Un **servidor LLM local** (Ollama, llama.cpp, TensorRT-LLM, etc.) con un modelo compatible

### Preparando el Escenario

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Clone and enter the realm
git clone https://github.com/kouroshkarimi/jetson-llm-interface.git
cd jetson-llm-interface

# Install Python dependencies
pip install -r requirements.txt

# Create the llm prompt costumization for our project
ollama create jetson-controller -f models/jetson-controller.txt

```

### Configurando tu LLM

Edita `app/llm_agent.py` para apuntar a tu servidor de modelo. Aseg√∫rate de que la etiqueta del modelo coincida con la definida en tu archivo de prompt.

---

## `jetson-controller.txt`

### üß† Prop√≥sito y Rol

`jetson-controller.txt` es el **prompt del sistema central** que define el comportamiento del Modelo de Lenguaje Local (LLM) usado en el proyecto Jetson LLM Interface Controller.

Act√∫a como un **contrato** entre el lenguaje natural y la ejecuci√≥n de hardware.

Sus responsabilidades son:

- Interpretar comandos de lenguaje natural del usuario
- Restringir el LLM a **comportamiento predecible y seguro para la m√°quina**
- Emitir **JSON estrictamente estructurado** adecuado para ejecuci√≥n determin√≠stica
- Prevenir acciones inseguras, fuera de tema o alucinadas

En resumen:

> Este archivo es el cerebro que convierte la intenci√≥n humana en control confiable de dispositivos en el borde.

---

### üß± Declaraci√≥n del Modelo Base

```dockerfile
FROM llama3.2:1b
```

Esta l√≠nea especifica el **modelo fundacional** usado por el sistema. Puedes sustituirlo con otros modelos compatibles, como:

- Mistral
- LLaMA 3.x
- Qwen2
- Cualquier modelo compatible con Ollama / llama.cpp / TensorRT-LLM

El prompt est√° dise√±ado para ser **agn√≥stico al modelo**, enfoc√°ndose en el comportamiento m√°s que en la arquitectura.

---

### üé≠ Identidad del Sistema

```text
You are HomeAssistantAI...
```

Al modelo se le asigna expl√≠citamente un **rol e identidad**:

- Un int√©rprete de automatizaci√≥n del hogar
- No un chatbot
- No un asistente general
- No un escritor creativo

Esto reduce dr√°sticamente el comportamiento del modelo y reduce las alucinaciones.

---

### üéØ Objetivos del Prompt

La secci√≥n de objetivos define las **restricciones de misi√≥n** del modelo:

1. Entender lenguaje natural relacionado con hogar inteligente
2. Convertirlo en JSON estructurado
3. Rechazar solicitudes inseguras, irrelevantes o imposibles
4. Generar **solo JSON v√°lido**, nada m√°s

Esto asegura:

- An√°lisis determin√≠stico aguas abajo
- Sin trucos de post-procesamiento
- Sin ambig√ºedad entre "pensar" y "actuar"

---

### üì¶ Esquema de Salida JSON

El coraz√≥n del archivo es el **esquema de comandos**:

```json
{
  "intent": "...",
  "device": "...",
  "action": "...",
  "location": "...",
  "parameters": { ... },
  "confidence": 0.0
}
```

#### Por Qu√© Esto Importa

- Crea una **API estable** entre el LLM y el c√≥digo de hardware
- Permite la validaci√≥n de esquemas (Pydantic / JSON Schema)
- Permite el rechazo seguro basado en confianza

---

### üß© Desglose Campo por Campo

#### `intent`

Define **qu√© tipo de solicitud** hizo el usuario:

- `control_device` ‚Äî Ejecutar una acci√≥n f√≠sica
- `query_status` ‚Äî Leer el estado del sensor o dispositivo
- `general_help` ‚Äî Preguntas de uso o del sistema
- `unknown` ‚Äî Cualquier cosa insegura, fuera de tema o poco clara

Este campo es el **enrutador principal** en la l√≥gica del backend.

---

#### `device`

Representa la **abstracci√≥n de hardware objetivo**, no el controlador f√≠sico.

Ejemplos:

- `lights`
- `thermostat`
- `fan`
- `speaker`
- `garage`

Si no se aplica ning√∫n dispositivo, debe ser `null`.

Esto evita que el LLM invente hardware.

---

#### `action`

Describe **qu√© hacer** con el dispositivo:

- `turn_on`, `turn_off`
- `set`, `increase`, `decrease`
- `open`, `close`, `lock`, `unlock`

Si la acci√≥n no est√° clara o falta, se requiere `null`.

---

#### `location`

Proporciona **contexto espacial**, habilitando configuraciones de m√∫ltiples habitaciones:

- `living_room`
- `kitchen`
- `bedroom`
- `garage`

Si no se menciona expl√≠citamente, esto debe ser `null`.

---

#### `parameters`

Lleva **datos de control de grano fino**, tales como:

- Valores de temperatura
- Porcentajes de brillo
- Niveles de volumen
- Modos o preajustes

Puede ser:

- Un objeto (`{ "temperature": 22 }`)
- `{}`
- `null` cuando no se especifica

---

#### `confidence`

Un valor de punto flotante entre `0.0` y `1.0` que representa la **certeza autoevaluada** del modelo.

Esto permite:

- Control de confianza
- Umbrales de seguridad
- Validaci√≥n humana en el bucle

Ejemplo de uso:

```python
if command.confidence < 0.5:
    reject()
```

---

### üõ°Ô∏è Reglas de Comportamiento y Restricciones de Seguridad

La secci√≥n de reglas de comportamiento es **cr√≠tica para el despliegue seguro**.

Las protecciones clave incluyen:

- ‚ùå Sin lenguaje natural fuera de JSON
- ‚ùå Sin contenido creativo, pol√≠tico o no relacionado
- ‚ùå Sin dispositivos alucinados
- ‚ùå Sin ejecuci√≥n de comandos ambiguos con alta confianza

Las solicitudes fuera de tema se mapean forzosamente a:

```json
{
  "intent": "unknown",
  "confidence": 0.0
}
```

Esto asegura que el sistema **falle cerrado**, no abierto.

---

### üîÄ Manejo de Ambig√ºedad

Cuando una solicitud es *posiblemente* relacionada con el hogar pero poco clara:

- El modelo debe elegir la interpretaci√≥n razonable m√°s cercana
- La confianza debe ser **baja** (ej., 0.3‚Äì0.5)

Ejemplo:

> "Est√° muy oscuro aqu√≠"

‚Üí Posiblemente encender las luces, pero nunca con alta certeza.

---

### üßÆ Limitaci√≥n de M√∫ltiples Comandos

Si el usuario emite **m√∫ltiples comandos en una oraci√≥n**:

- Solo **un comando** est√° permitido en la salida
- La prioridad va al m√°s importante o al primero mencionado

Esto mantiene la ejecuci√≥n simple y evita fallas parciales.

---

### üß™ Secci√≥n de Ejemplos

Los ejemplos act√∫an como **entrenamiento de pocos disparos** para el modelo.

Demuestran:

- Uso correcto del esquema
- Niveles de confianza apropiados
- Manejo seguro de solicitudes inv√°lidas

Los ejemplos incluyen:

- Encender luces
- Establecer valores del termostato
- Consultar sensores
- Rechazar prompts creativos o no relacionados

Estos ejemplos son esenciales para **la alineaci√≥n y consistencia del modelo**.

---

### üß† Por Qu√© Este Archivo Es Tan Importante

`jetson-controller.txt` no es solo un prompt ‚Äî es:

- Una **pol√≠tica de seguridad**
- Una **especificaci√≥n de lenguaje de comandos**
- Una **capa de protecci√≥n de hardware**
- Una **interfaz determin√≠stica** entre la IA y el mundo f√≠sico

Cualquier cambio a este archivo afecta directamente:

- Seguridad del sistema
- Correcci√≥n de ejecuci√≥n
- Confianza del usuario

---

## üé¨ D√°ndole Vida: Ejemplos

```bash
# Run the uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Ejemplo 1: Estableciendo el Ambiente

```bash
curl -X POST http://localhost:8000/command \
  -H "Content-Type: application/json" \
  -d '{"text": "Dim the kitchen lights to 30% and play jazz"}'
```

**El Flujo Desplegado:**

- La API recibe la solicitud po√©tica.
- El LLM la analiza en dos comandos (luces + altavoz).
- El ejecutor ajusta PWM en el circuito de luz y activa una lista de reproducci√≥n.
- La habitaci√≥n se transforma.

---

### Ejemplo 2: Agente Inquisitivo

```bash
curl -X POST http://localhost:8000/command \
  -H "Content-Type: application/json" \
  -d '{"text": "What‚Äôs the temperature in the bedroom?"}'
```

**Detr√°s de Escena:**

- **Intenci√≥n:** `query_status`
- **Dispositivo:** termostato
- **Acci√≥n:** consulta
- I2C lee el sensor y devuelve una respuesta amigable (hablada, si se agrega TTS).

---
o puedes ir a este enlace y ejecutar tu comando en una interfaz web:

![enter image description here](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/assets/ex_1.png?raw=true)

![enter image description here](https://github.com/kouroshkarimi/llm_interface_controll/blob/master/assets/ex_3.png?raw=true)

## üß© Expandiendo el Universo: Personalizaci√≥n

### Agregar Nuevos Dispositivos

1. **Mapear el Hardware**  
   Extender `GPIO_PINS` en `app/hardware_controller.py`.

2. **Escribir un Manejador**  
   Seguir el patr√≥n:

   ```python
   def control_new_device(params):
       return bool, str
   ```

3. **Conectar los Puntos**  
   Agregar un caso en la l√≥gica de despacho `execute()`.

4. **Ense√±ar al LLM**  
   Actualizar el archivo de prompt con ejemplos para tu nuevo dispositivo.

---

### Mejorar el An√°lisis

- Integrar validaci√≥n de JSON Schema (ej., `jsonschema`) para an√°lisis a prueba de balas
- Agregar memoria de contexto conversacional para manejar seguimientos ("ap√°galas")
- Implementar umbrales de confianza para rechazar comandos ambiguos

---

### Intercambiar o Actualizar Modelos

- Editar el prompt en `models/jetson-controller.txt` para coincidir con las fortalezas de tu modelo
- Ajustar `ask_llm()` para soportar diferentes servidores de modelos (compatible con OpenAI, Hugging Face, etc.)

---

### Agente Habilitado con Visi√≥n

Conectar una c√°mara CSI e integrar un Modelo de Lenguaje de Visi√≥n (VLM) para habilitar:

- Descripci√≥n de escena
- Monitoreo de seguridad
- Control basado en gestos

---

## ‚ö†Ô∏è Seguridad y Creaci√≥n Responsable

### Seguridad de Hardware

- **Aislamiento Durante el Desarrollo** ‚Äî Simular GPIO e I2C cuando se codifica fuera del dispositivo
- **L√≠mites de Corriente y Voltaje** ‚Äî Usar controladores y rel√©s apropiados para cargas de alta potencia
- **Mecanismos de Seguridad** ‚Äî Por defecto a estados seguros (luces apagadas, motores detenidos)

### Seguridad de IA

- **Control de Confianza** ‚Äî Comandos con confianza < 0.5 son rechazados (configurable)
- **Filtrado de Intenci√≥n** ‚Äî Solicitudes fuera de tema o peligrosas devuelven `unknown`
- **Autenticaci√≥n** ‚Äî Agregar claves API u OAuth en entornos de producci√≥n

---

### Estrategia de Pruebas

- **Pruebas Unitarias** ‚Äî Simular `ask_llm()` y validar la l√≥gica de hardware
- **Pruebas de Integraci√≥n** ‚Äî Comenzar con perif√©ricos de baja potencia
- **Registro** ‚Äî Rastrear cada etapa del pipeline para transparencia

---

## üõ†Ô∏è Para el Desarrollador: Consejos Pro

- Emular hardware con un m√≥dulo `fake_gpio.py`
- Usar registro estructurado (`structlog`) para trazabilidad de extremo a extremo
- Agregar endpoints `/health` para verificaciones del sistema y modelo
- Validar comandos con modelos Pydantic antes de la ejecuci√≥n
- Perfilar el uso de CPU/GPU/MLP para evitar limitaci√≥n t√©rmica en Jetson
- Puedes agregar TTS y STT a este proyecto [enlace](https://github.com/kouroshkarimi/local_chatbot_jetson)

---

## Referencias

1. [RAG Local basado en Jetson con LlamaIndex](https://wiki.seeedstudio.com/es/Local_RAG_based_on_Jetson_with_LlamaIndex/)
2. [Chatbot de Voz Local: Desplegar Riva y Llama2 en reComputer](https://wiki.seeedstudio.com/es/Local_Voice_Chatbot/)
3. [ChatTTS](https://github.com/2noise/ChatTTS)
4. [Voz a Texto (STT) y Texto a Voz (TTS)](https://www.librechat.ai/docs/configuration/stt_tts)
5. [Ollama](https://github.com/ollama/ollama)

---

## ‚ú® Proyecto Colaborador

- Este proyecto est√° respaldado por el [Proyecto Colaborador](https://github.com/orgs/Seeed-Studio/projects/6/views/1?pane=issue&itemId=30957479) de Seeed Studio.
- Un agradecimiento especial a [kourosh karimi](https://github.com/orgs/Seeed-Studio/projects/6/views/1?filterQuery=Building+a+Voice-Interactive+Chatbot+with+STT%2C+TTS%2C+and+Local+LLMs%21&pane=issue&itemId=74620249&issue=Seeed-Studio%7Cwiki-documents%7C1553) por sus esfuerzos dedicados. Tu trabajo ser√° [exhibido](https://wiki.seeedstudio.com/es/contributors/).

## Soporte T√©cnico y Discusi√≥n de Productos

¬°Gracias por elegir nuestros productos! Estamos aqu√≠ para proporcionarte diferentes tipos de soporte para asegurar que tu experiencia con nuestros productos sea lo m√°s fluida posible. Ofrecemos varios canales de comunicaci√≥n para atender diferentes preferencias y necesidades.

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
