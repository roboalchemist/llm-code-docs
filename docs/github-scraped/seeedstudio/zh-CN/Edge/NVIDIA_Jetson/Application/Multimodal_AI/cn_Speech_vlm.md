---
description: æœ¬wikiæä¾›äº†å¦‚ä½•åœ¨reComputer AGX Orin 64Gä¸Šè¿è¡Œå¸¦è¯­éŸ³äº¤äº’çš„è§†è§‰è¯­è¨€æ¨¡å‹çš„æ•™ç¨‹ã€‚
title: è¿è¡Œå¸¦è¯­éŸ³äº¤äº’çš„VLM
keywords:
- Multimodal 
- NanoVLM
- TTS
- STT
image: https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png
slug: /cn/speech_vlm
last_update:
  date: 08/23/2024
  author: YaoHui Zhu
---

# å¦‚ä½•åœ¨reComputer Jetsonä¸Šè¿è¡Œå¸¦è¯­éŸ³äº¤äº’çš„VLM

## ä»‹ç»

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜äº†å¦‚ä½•åœ¨reComputer Nvidia Jetsonè®¾å¤‡ä¸Šè¿è¡Œå¸¦è¯­éŸ³äº¤äº’çš„å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å®˜æ–¹Nvidia Jetsonå¹³å°çš„å¼ºå¤§è®¡ç®—èƒ½åŠ›ï¼Œç»“åˆé˜¿é‡Œå·´å·´å¼€æºçš„è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹SenseVoiceå’Œcoqui-aiçš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œæ¥æ‰§è¡Œå¤æ‚çš„å¤šæ¨¡æ€ä»»åŠ¡ã€‚é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œæ‚¨å°†èƒ½å¤ŸæˆåŠŸå®‰è£…å’Œæ“ä½œæ­¤ç³»ç»Ÿï¼Œä½¿å…¶å…·å¤‡è§†è§‰è¯†åˆ«å’Œè¯­éŸ³äº¤äº’èƒ½åŠ›ï¼Œä»è€Œä¸ºæ‚¨çš„é¡¹ç›®æä¾›æ›´æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆã€‚

### [VLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ä»‹ç»](https://docs.nvidia.com/jetson/jps/inference-services/vlm.html)

è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ˜¯ä¸ºNvidia Jetsonå¹³å°ä¼˜åŒ–çš„å¤šæ¨¡æ€æ¨¡å‹ã€‚å®ƒç»“åˆäº†è§†è§‰å’Œè¯­è¨€å¤„ç†æ¥å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œå¦‚ç‰©ä½“è¯†åˆ«å’Œç”Ÿæˆæè¿°æ€§è¯­è¨€ã€‚VLMé€‚ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§å’Œæ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸï¼Œæä¾›æ™ºèƒ½ç›´è§‚çš„è§£å†³æ–¹æ¡ˆã€‚

<div align="center">
    <img width={800}
     src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/vlmgif.gif" />
</div>

### [SenseVoiceä»‹ç»](https://github.com/FunAudioLLM/SenseVoice/tree/main)

SenseVoiceæ˜¯ä¸€ä¸ªä¸“æ³¨äºé«˜ç²¾åº¦å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«å’ŒéŸ³é¢‘äº‹ä»¶æ£€æµ‹çš„å¼€æºæ¨¡å‹ã€‚å®ƒåœ¨è¶…è¿‡40ä¸‡å°æ—¶çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒ50å¤šç§è¯­è¨€ï¼Œæ€§èƒ½è¶…è¶ŠWhisperæ¨¡å‹ã€‚SenseVoice-Smallæ¨¡å‹æä¾›è¶…ä½å»¶è¿Ÿï¼Œä»…éœ€70æ¯«ç§’å³å¯å¤„ç†10ç§’éŸ³é¢‘ã€‚å®ƒè¿˜æä¾›ä¾¿æ·çš„å¾®è°ƒåŠŸèƒ½ï¼Œæ”¯æŒå¤šç§è¯­è¨€éƒ¨ç½²ï¼ŒåŒ…æ‹¬Pythonã€C++ã€HTMLã€Javaå’ŒC#ã€‚

<div align="center">
    <img width={800}
     src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/sensevoice2.png" />
</div>

### [TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰ä»‹ç»](https://github.com/coqui-ai/TTS)

TTSæ¨¡å‹æ˜¯ç”¨äºæ–‡æœ¬è½¬è¯­éŸ³ä»»åŠ¡çš„é«˜æ€§èƒ½æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚å®ƒåŒ…å«å„ç§æ¨¡å‹ï¼Œå¦‚Tacotron2å’Œå£°ç å™¨ï¼Œå¦‚MelGANå’ŒWaveRNNã€‚TTSæ¨¡å‹æ”¯æŒå¤šè¯´è¯äººTTSã€é«˜æ•ˆè®­ç»ƒï¼Œå¹¶æä¾›æ•°æ®é›†æ•´ç†å’Œæ¨¡å‹æµ‹è¯•å·¥å…·ã€‚å…¶æ¨¡å—åŒ–ä»£ç åº“å…è®¸è½»æ¾å®ç°æ–°åŠŸèƒ½ã€‚

<div align="center">
    <img width={800}
     src="https://raw.githubusercontent.com/coqui-ai/TTS/main/images/coqui-log-green-TTS.png" />
</div>

## å…ˆå†³æ¡ä»¶

- å…·æœ‰16GBä»¥ä¸Šå†…å­˜çš„reComputer Jetson AGX Orin 64Gæˆ–reComputer Jetson J4012 16Gè®¾å¤‡ã€‚
- USBå…é©±åŠ¨æ‰¬å£°å™¨éº¦å…‹é£
- èƒ½å¤Ÿè¾“å‡ºRTSPæµåœ°å€çš„IPæ‘„åƒå¤´ã€‚æˆ‘ä»¬è¿˜åŒ…å«äº†[å¦‚ä½•ä½¿ç”¨NVIDIA Nvstreamer](/cn/getting_started_with_nvstreamer)å·¥å…·å°†æœ¬åœ°è§†é¢‘è½¬æ¢ä¸ºRTSPæµçš„è¯´æ˜ã€‚

:::note
æˆ‘ä»¬å·²ç»åœ¨reComputer [Orin NX 16GB](https://www.seeedstudio.com/reComputer-J4012-p-5586.html)å’Œ[AGX Orin 64GB](https://www.seeedstudio.com/NVIDIArJetson-AGX-Orintm-64GB-Developer-Kit-p-5641.html)å¼€å‘å¥—ä»¶ä¸Šæµ‹è¯•äº†æœ¬wikiçš„å¯è¡Œæ€§ã€‚
:::

<div align="center">
    <img width={800}
     src="https://files.seeedstudio.com/wiki/reComputer-Jetson/Llama-Factory/agx_orin.png" />
</div>

<div class="get_one_now_container" style={{textAlign: 'center'}}>
    <a class="get_one_now_item" href="https://www.seeedstudio.com/AGX-Orin-32GB-H01-Kit-p-5569.html?queryID=a07376a957f072a4f755e1832fa0e544&objectID=5569&indexName=bazaar_retailer_products" target="_blank">
      <strong><span><font color={'FFFFFF'} size={"4"}> ç«‹å³è·å– ğŸ–±ï¸</font></span></strong>
    </a>
</div>

## å®‰è£…

### åˆå§‹åŒ–ç³»ç»Ÿç¯å¢ƒ

1. ä½¿ç”¨ JP6 å®‰è£…åˆå§‹ç³»ç»Ÿåï¼Œæ‚¨éœ€è¦æ£€æŸ¥ `CUDA` å’Œå…¶ä»–åº“çš„å®‰è£…æƒ…å†µã€‚æ‚¨å¯ä»¥é€šè¿‡è¿è¡Œ `sudo apt-get install nvidia-jetpack` æ¥éªŒè¯å’Œå®‰è£…å®ƒä»¬ã€‚

2. å®‰è£… `python3-pip`ã€`jtop` å’Œ `docker-ce`ã€‚
3. é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…å¿…è¦çš„ä¾èµ–é¡¹ï¼š

    ```bash
    sudo apt-get install libportaudio2 libportaudiocpp0 portaudio19-dev
    sudo pip3 install pyaudio playsound subprocess wave keyboard
    sudo pip3 --upgrade setuptools
    sudo pip3 install sudachipy==0.5.2
    ```

4. æ£€æŸ¥éŸ³é¢‘è¾“å…¥å’Œè¾“å‡ºä»¥åŠ USB æ‰¬å£°å™¨éº¦å…‹é£æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œå¹¶ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šã€‚

### å®‰è£… VLM

æœ¬é¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå…³äº[å¦‚ä½•åœ¨ reComputer Nvidia Jetson ä¸Šä½¿ç”¨ VLM](/cn/run_vlm_on_recomputer) çš„æŒ‡å—ã€‚è¯·å‚è€ƒæ­¤é“¾æ¥è·å–å®‰è£…å’Œä½¿ç”¨è¯´æ˜ã€‚åœ¨ç»§ç»­ä»¥ä¸‹æ­¥éª¤ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å®Œå…¨äº†è§£å¦‚ä½•åœ¨ VLM ä¸­ä½¿ç”¨æ–‡æœ¬æè¿°è¿›è¡Œæ¨ç†ã€‚

### å®‰è£… Pytorch Torchaudio

æˆ‘ä»¬ä¸ºåˆå­¦è€…æä¾›äº† Nvidia Jetson AI è¯¾ç¨‹ï¼Œå…¶ä¸­åŒ…æ‹¬[å¦‚ä½•å®‰è£… PyTorchã€Torchaudio å’Œ Torchvision](https://github.com/Seeed-Projects/reComputer-Jetson-for-Beginners/blob/main/3-Basic-Tools-and-Getting-Started/3.3-Pytorch-and-Tensorflow/README.md) çš„è¯´æ˜ã€‚è¯·æ ¹æ®æ‚¨çš„ç³»ç»Ÿç¯å¢ƒä¸‹è½½å¹¶å®‰è£…è¿™äº›åŒ…ã€‚

### å®‰è£… Speech_vlmï¼ˆåŸºäº SenseVoiceï¼‰

1. å…‹éš† Speech_vlm åŒ…ï¼š

    ```bash
    cd ~/
    git clone https://github.com/ZhuYaoHui1998/speech_vlm.git
    ```

2. å®‰è£… Speech_vlm ç¯å¢ƒï¼š

    ```bash
    cd ~/speech_vlm
    sudo pip3 install -r requement.txt
    ```

### å®‰è£… TTSï¼ˆåŸºäº Coqui-aiï¼‰

```bash
cd ~/speech_vlm/TTS
sudo pip3 install .[all]
```

## ä½¿ç”¨æ–¹æ³•

speech_vlm ä»“åº“çš„ç»“æ„å¦‚ä¸‹ï¼š

```bash
speech_vlm/
â”œâ”€â”€ /TTS   # Coqui-ai TTS program
â”œâ”€â”€ config # VLM config
â”œâ”€â”€ README.md    #Project Introduction
â”œâ”€â”€ requirements.txt   #SenseVoice required environment libraries
â”œâ”€â”€ compose.yaml   #VLM Docker Compose startup file
â”œâ”€â”€ delete_id.sh     #Delete camera ID script
â”œâ”€â”€ example_1.wav     #Audio feedback sound tone template (replaceable)
â”œâ”€â”€ model.py     #SenseVoice main program
â”œâ”€â”€ set_alerts.sh     #Set up camera alerts
â”œâ”€â”€ set_describe.sh     #Text input to have the VLM describe the current scene
â”œâ”€â”€ set_streamer_id.sh  #Add RTSP camera to VLM
â”œâ”€â”€ view_rtsp.py  # View RTSP stream by opencv
â””â”€â”€ vlm_voice.py  # multimodal main program
```

1. å¯åŠ¨ VLM

    ```bash
    cd ~/speech_vlm
    sudo docker compose up -d
    ```

    <div align="center">
        <img width={800}
        src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/dockerps.png" />
    </div>

2. å°† RTSP æµæ·»åŠ åˆ° VLM

æŸ¥çœ‹ `speech_vlm` ä»“åº“ä¸‹ `set_streamer_id.sh` çš„å†…å®¹ï¼š

```sh
#!/bin/bash
curl --location 'http://0.0.0.0:5010/api/v1/live-stream' \
--header 'Content-Type: application/json' \
--data '{"liveStreamUrl": "RTSP stream address"}'
```

å°† `0.0.0.0` æ›¿æ¢ä¸º Jetson è®¾å¤‡çš„ IP åœ°å€ï¼Œå°† `RTSP stream address` æ›¿æ¢ä¸ºæ‘„åƒå¤´çš„ RTSP æµåœ°å€ã€‚
ä¾‹å¦‚ï¼š

```sh
#!/bin/bash
curl --location 'http://192.168.49.227:5010/api/v1/live-stream' \
--header 'Content-Type: application/json' \
--data '{"liveStreamUrl": "rtsp://admin:IHFXnM8k@192.168.49.15:554//Streaming/Channels/1"}'
```

:::note
å¦‚æœæ‚¨æ²¡æœ‰ RTSP æ‘„åƒå¤´ï¼Œæˆ‘ä»¬æä¾›äº†å…³äº[å¦‚ä½•ä½¿ç”¨ NVStreamer å°†æœ¬åœ°è§†é¢‘æµå¼ä¼ è¾“ä¸º RTSP](/cn/getting_started_with_nvstreamer) ä»¥åŠ[å°†å®ƒä»¬æ·»åŠ åˆ° VLM](/cn/run_vlm_on_recomputer) çš„è¯´æ˜ã€‚
:::

è¿è¡Œ set_streamer_id.sh

```bash
cd ~/speech_vlm
sudo chmod +x ./set_streamer_id.sh
./set_streamer_id.sh
```

æˆ‘ä»¬å°†è·å¾—ä¸€ä¸ªæ‘„åƒå¤´IDï¼Œè¿™ä¸ªIDéå¸¸é‡è¦ï¼Œéœ€è¦è®°å½•ä¸‹æ¥ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/set_id.png" />
</div>

3. è¿è¡Œ vlm_voice.py

æ‚¨éœ€è¦åœ¨ä»¥ä¸‹ä¸¤è¡ŒPythonä»£ç ä¸­æ›¿æ¢ `0.0.0.0`ï¼š

```python
API_URL = 'http://0.0.0.0:5010/api/v1/chat/completions'  # API endpoint
REQUEST_ID = ""  # Request ID
```

ä½¿ç”¨ Jetson IP åœ°å€å¹¶å¡«å…¥ä»æ­¥éª¤ 2 è¿”å›çš„æ‘„åƒå¤´ ID æ¥æ›¿æ¢ `REQUEST_ID`ã€‚

<details>
<summary>vlm_voice.py</summary>

```python
import pyaudio
import wave
import keyboard
import subprocess
import json
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
import time
import torch
from TTS.api import TTS
import os
# Get device
device = "cuda" if torch.cuda.is_available() else "cpu"

# Init TTS
api = TTS("tts_models/en/ljspeech/glow-tts").to(device)

# Configuration parameters 
FORMAT = pyaudio.paInt16  # 16-bit resolution
CHANNELS = 1  # Mono channel
CHUNK = 1024  # Number of samples per chunk
OUTPUT_FILENAME = "output.wav"  # Output file name
API_URL = 'http://192.168.49.227:5010/api/v1/chat/completions'  # API endpoint
REQUEST_ID = "1388b691-3b9f-4bda-9d70-0ff0696f80f4"  # Request ID

# Initialize PyAudio
audio = pyaudio.PyAudio()
# Prepare the list to store recording data
frames = []

# Initialize Micphone Rate
print("Available audio input devices:")
for i in range(audio.get_device_count()):
    info = audio.get_device_info_by_index(i)
    print(f"Device {i}: {info['name']} - {info['maxInputChannels']} channels")

device_index = int(input("Please select the device index for your USB microphone: "))

device_info = audio.get_device_info_by_index(device_index)
supported_sample_rates = [8000, 16000, 32000, 44100, 48000]
supported_rate=0
for rate in supported_sample_rates:
    try:
        if audio.is_format_supported(rate,
                                     input_device=device_index,
                                     input_channels=1,
                                     input_format=pyaudio.paInt16):
            supported_rate=rate
            print(f"{rate} Hz is supported.")
    except ValueError:
        print(f"{rate} Hz is not supported.")


# Initialize the model
model = "./SenseVoiceSmall"
model = AutoModel(
    model=model,
    vad_model="./speech_fsmn_vad_zh-cn-16k-common-pytorch",
    vad_kwargs={"max_single_segment_time": 30000},
    trust_remote_code=True,
    disable_log=True
)


def extract_content(json_response):
    try:
        # è§£æJSONå­—ç¬¦ä¸²
        data = json.loads(json_response)
        
        # æå–contentéƒ¨åˆ†
        content = data["choices"][0]["message"]["content"]
        
        print(f"{content}")
        return content
    except KeyError as e:
        print(f"Key error: {e}")
    except json.JSONDecodeError as e:
        print(f"JSON decode error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

def start_recording():
    global frames
    frames = []
    
    try:
        stream = audio.open(format=FORMAT, channels=CHANNELS,
                            rate=supported_rate, input=True,
                            frames_per_buffer=CHUNK, input_device_index=device_index)
        print("Recording started... Press '2' to stop recording.")
    
        while True:
            if keyboard.is_pressed('2'):
                print("Recording stopped.")
                break
            data = stream.read(CHUNK)
            frames.append(data)
    
        stream.stop_stream()
        stream.close()
    
    except Exception as e:
        print(f"An error occurred during recording: {e}")

def save_recording():
    try:
        waveFile = wave.open(OUTPUT_FILENAME, 'wb')
        waveFile.setnchannels(CHANNELS)
        waveFile.setsampwidth(audio.get_sample_size(FORMAT))
        waveFile.setframerate(supported_rate)
        waveFile.writeframes(b''.join(frames))
        waveFile.close()
        print(f"Recording saved as {OUTPUT_FILENAME}")
    except Exception as e:
        print(f"An error occurred while saving the recording: {e}")

def send_alert(text):
    # Construct the JSON payload
    payload = {
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful AI assistant."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "stream",
                        "stream": {
                            "stream_id": REQUEST_ID
                        }
                    },
                    {
                        "type": "text",
                        "text": text
                    }
                ]
            }
        ],
        "min_tokens": 1,
        "max_tokens": 128
    }
    
    # Convert the payload to a JSON string
    json_payload = json.dumps(payload)
    
    # Execute the curl command using subprocess
    curl_command = [
        'curl', '--location', API_URL,
        '--header', 'Content-Type: application/json',
        '--data', json_payload
    ]
    
    try:
        result = subprocess.run(curl_command, check=True, capture_output=True, text=True)
        ##Get words
        content_result=extract_content(result.stdout)
        # TTS 
        api.tts_to_file(
            str(content_result),
            speaker_wav="./example_1.wav",
            file_path="speech.wav"
        )
        # Convert audio rate
        subprocess.run(['ffmpeg', '-i', 'speech.wav', '-ar',str(supported_rate), 'speech1.wav','-y'])
        # Play audio
        wf = wave.open('./speech1.wav', 'rb')
        stream = audio.open(format=pyaudio.paInt16,
                        channels=1,
                        rate=supported_rate,
                        output=True,
                        output_device_index=device_index)
        data = wf.readframes(1024)
        while data:
            stream.write(data)
            data = wf.readframes(1024)
        # Play audio
        os.remove('speech.wav')
        os.remove('speech1.wav')
        stream.stop_stream()
        stream.close()
        wf.close()  # Close the wave file as well

        #print(f"Alert sent successfully: {result.stdout}")
    except subprocess.CalledProcessError as e:
        print(f"An error occurred while sending the alert: {e.stderr}")
    finally:
        # Even if an error occurs, try to close the stream
        if stream.is_active():
            stream.stop_stream()
            os.remove('speech.wav')
            os.remove('speech1.wav')
            stream.close()
print("Welcome to the Recording and Speech-to-Text System!")
print("Press '1' to start recording, '2' to stop recording.")

while True:
    if keyboard.is_pressed('1'):
        print("Preparing to start recording...")
        start_recording()
        save_recording()
        
        print("Processing the recording file, please wait...")
        try:
            res = model.generate(
                input=f"./{OUTPUT_FILENAME}",
                cache={},
                language="auto",  # "zh", "en", "yue", "ja", "ko", "nospeech"
                use_itn=True,
                batch_size_s=60,
                merge_vad=True,
                merge_length_s=15,
            )
            text = rich_transcription_postprocess(res[0]["text"])
            print(f"Speech-to-Text Result:\n{text}")
            
            # Send the transcription result as an alert
            send_alert(text)
            
        except Exception as e:
            print(f"An error occurred while processing the recording: {e}")
        
    time.sleep(0.1)  # Reduce CPU usage
```

</details>

Run python:

```bash
cd ~/speech_vlm
sudo python3 vlm_voice.py
```

ç¨‹åºå¯åŠ¨åï¼Œå®ƒå°†æ‰«ææ‰€æœ‰éŸ³é¢‘è¾“å…¥å’Œè¾“å‡ºè®¾å¤‡ã€‚æ‚¨éœ€è¦æ‰‹åŠ¨é€‰æ‹©æ‰€éœ€éŸ³é¢‘è®¾å¤‡çš„ç´¢å¼•IDã€‚ç¨‹åºå³å°†å¼€å§‹å·¥ä½œï¼Œç„¶åæŒ‰ `1` å½•éŸ³ï¼ŒæŒ‰ `2` å‘é€ã€‚

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/select_mic.png" />
</div>

4. æŸ¥çœ‹ç»“æœ

æˆ‘ä»¬å‡†å¤‡äº†ä¸€ä¸ª `view_rtsp.py` è„šæœ¬æ¥æŸ¥çœ‹è¾“å‡ºç»“æœã€‚æ‚¨éœ€è¦å°† `rtsp_url = "rtsp://0.0.0.0:5011/out"` ä¸­çš„IPéƒ¨åˆ†æ›¿æ¢ä¸ºæ‚¨çš„Jetsonè®¾å¤‡çš„IPåœ°å€ã€‚

<details>
<summary>viwe_rtsp.py</summary>

```python
import cv2

rtsp_url = "rtsp://192.168.49.227:5011/out"

cap = cv2.VideoCapture(rtsp_url)

if not cap.isOpened():
    print("Cannot open RTSP stream")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        print("Failed to retrieve frame")
        break

    height, width = frame.shape[:2]

    frame_resized = cv2.resize(frame, (int(width // 1.1), int(height // 1.1)))

    cv2.imshow('RTSP Stream', frame_resized)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

</details>

```bash
sudo pip3 install opencv-python
cd ~/speech_vlm
sudo python3 view_rtsp.py
```

<div align="center">
    <img width={800}
    src="https://files.seeedstudio.com/wiki/reComputer/Application/Multimodal_ai/audio_vlm/view_result.png" />
</div>

### æ¼”ç¤º

<div class="video-container">
  <iframe width="800" height="450" src="https://www.youtube.com/embed/eYaA9WGXh4Y" title="Run VLM with Speech Interaction on Jetson" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

## æŠ€æœ¯æ”¯æŒä¸äº§å“è®¨è®º

æ„Ÿè°¢æ‚¨é€‰æ‹©æˆ‘ä»¬çš„äº§å“ï¼æˆ‘ä»¬åœ¨è¿™é‡Œä¸ºæ‚¨æä¾›ä¸åŒçš„æ”¯æŒï¼Œä»¥ç¡®ä¿æ‚¨ä½¿ç”¨æˆ‘ä»¬äº§å“çš„ä½“éªŒå°½å¯èƒ½é¡ºç•…ã€‚æˆ‘ä»¬æä¾›å¤šç§æ²Ÿé€šæ¸ é“ï¼Œä»¥æ»¡è¶³ä¸åŒçš„åå¥½å’Œéœ€æ±‚ã€‚

<div class="button_tech_support_container">
<a href="https://forum.seeedstudio.com/" class="button_forum"></a>
<a href="https://www.seeedstudio.com/contacts" class="button_email"></a>
</div>

<div class="button_tech_support_container">
<a href="https://discord.gg/eWkprNDMU7" class="button_discord"></a>
<a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" class="button_discussion"></a>
</div>
