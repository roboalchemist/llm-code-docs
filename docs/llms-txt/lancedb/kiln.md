# Source: https://docs.lancedb.com/integrations/ai/kiln.md

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.lancedb.com/llms.txt
> Use this file to discover all available pages before exploring further.

# Kiln AI

[**Kiln**](https://kiln.tech) is a free tool for building production-ready AI systems, combining an intuitive desktop application and an open-source Python library. It supports RAG pipelines, evaluations, agents, MCP tool-calling, synthetic data generation, and fine-tuning. Kiln provides deep integration with LanceDB for vector search, full-text search (BM25), and hybrid search.

## Quick Start: Build a RAG Pipeline in 5 Minutes with Kiln & LanceDB

Watch the [quick start overview on Vimeo](https://vimeo.com/1119945690).

Kiln's [app](https://kiln.tech/download) makes it easy to:

* Build a RAG pipeline with a simple drag-and-drop interface
* [Compare](#find-the-best-rag-pipeline-for-your-use-case) search index options (powered by LanceDB), document extractors, embedding models, and chunking strategies
* Create end-to-end [evaluations](https://docs.kiln.tech/docs/evaluations) to determine which search configuration works best for your use case
* Load your data from Kiln into LanceDB Cloud for production use
* Iterate with confidence by evaluating new content, prompts, models, and embeddings in minutes instead of weeks

## Find the Best RAG Pipeline for Your Use Case

There is no universal best RAG solutionâ€”only the best solution for your specific use case. Kiln makes it easy to compare state-of-the-art configurations and find which works best for you.

Start with pre-configured templates for state-of-the-art RAG at various performance/quality/cost levels, or experiment with any combination of options:

| Area                | Technologies                                                | Description                                                                                                                               |
| :------------------ | :---------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- |
| Search Index        | LanceDB                                                     | Compare LanceDB's vector search, full-text search (BM25), and hybrid search to find the best approach for your use case.                  |
| Content             | Kiln Document Library                                       | Collaborate on a document library with your team to find the best content for your RAG. Track every revision and tag document sets.       |
| Document Extraction | Gemini, OpenAI GPT, Qwen VL, and more                       | Find the most accurate document extraction models for converting PDFs, images, audio, video, and other formats into textual data for RAG. |
| Embeddings          | Embedding models from Gemini, OpenAI, Nomic, Qwen, and more | Find the embedding model best suited to your use case.                                                                                    |
| Chunking            | LlamaIndex                                                  | Find the ideal chunk size and method.                                                                                                     |

## Get Started

To get started, download the [Kiln App](https://kiln.tech/download), create a project, and navigate to "Docs & Search".

See the [Kiln documentation for creating a RAG system](https://docs.kiln.tech/docs/documents-and-search-rag) for details on each step of the process.

## More Information

* [Kiln Homepage](https://kiln.tech)
* [Download the Kiln App](https://kiln.tech/download)
* [Kiln GitHub Repository](https://github.com/Kiln-AI/Kiln)
* [Building RAG Systems - Kiln Documentation](https://docs.kiln.tech/docs/documents-and-search-rag)
* [Python Library](https://pypi.org/project/kiln-ai/) or `pip install kiln_ai`
