# Source: https://developers.cloudflare.com/agents/concepts/human-in-the-loop/index.md

---

title: Human in the Loop · Cloudflare Agents docs
description: Human-in-the-Loop (HITL) workflows integrate human judgment and
  oversight into automated processes. These workflows pause at critical points
  for human review, validation, or decision-making before proceeding.
lastUpdated: 2026-02-11T18:46:14.000Z
chatbotDeprioritize: false
source_url:
  html: https://developers.cloudflare.com/agents/concepts/human-in-the-loop/
  md: https://developers.cloudflare.com/agents/concepts/human-in-the-loop/index.md
---

Human-in-the-Loop (HITL) workflows integrate human judgment and oversight into automated processes. These workflows pause at critical points for human review, validation, or decision-making before proceeding.

## Why human-in-the-loop?

* **Compliance**: Regulatory requirements may mandate human approval for certain actions.
* **Safety**: High-stakes operations (payments, deletions, external communications) need oversight.
* **Quality**: Human review catches errors AI might miss.
* **Trust**: Users feel more confident when they can approve critical actions.

### Common use cases

| Use Case | Example |
| - | - |
| Financial approvals | Expense reports, payment processing |
| Content moderation | Publishing, email sending |
| Data operations | Bulk deletions, exports |
| AI tool execution | Confirming tool calls before running |
| Access control | Granting permissions, role changes |

## Patterns for human-in-the-loop

Cloudflare provides two main patterns for implementing human-in-the-loop:

### Workflow approval

For durable, multi-step processes with approval gates that can wait hours, days, or weeks. Use [Cloudflare Workflows](https://developers.cloudflare.com/workflows/) with the `waitForApproval()` method.

**Key APIs:**

* `waitForApproval(step, { timeout })` — Pause workflow until approved
* `approveWorkflow(instanceId, options)` — Approve a waiting workflow
* `rejectWorkflow(instanceId, options)` — Reject a waiting workflow

**Best for:** Expense approvals, content publishing pipelines, data export requests

### MCP elicitation

For MCP servers that need to request additional structured input from users during tool execution. The MCP client renders a form based on your JSON Schema.

**Key API:**

* `elicitInput(options, context)` — Request structured input from the user

**Best for:** Interactive tool confirmations, gathering additional parameters mid-execution

## How workflows handle approvals

![A human-in-the-loop diagram](https://developers.cloudflare.com/_astro/human-in-the-loop.C2xls7fV_1vt7N8.svg)

In a workflow-based approval:

1. The workflow reaches an approval step and calls `waitForApproval()`
2. The workflow pauses and reports progress to the agent
3. The agent updates its state with the pending approval
4. Connected clients see the pending approval and can approve or reject
5. When approved, the workflow resumes with the approval metadata
6. If rejected or timed out, the workflow handles the rejection appropriately

## Best practices

### Long-term state persistence

Human review processes do not operate on predictable timelines. A reviewer might need days or weeks to make a decision, especially for complex cases requiring additional investigation or multiple approvals. Your system needs to maintain perfect state consistency throughout this period, including:

* The original request and context
* All intermediate decisions and actions
* Any partial progress or temporary states
* Review history and feedback

Tip

[Durable Objects](https://developers.cloudflare.com/durable-objects/) provide an ideal solution for managing state in Human-in-the-Loop workflows, offering persistent compute instances that maintain state for hours, weeks, or months.

### Timeouts and escalation

Set timeouts to prevent workflows from waiting indefinitely. Use [scheduling](https://developers.cloudflare.com/agents/api-reference/schedule-tasks/) to:

* Send reminders after a period of inactivity
* Escalate to managers or alternative approvers
* Auto-reject or auto-approve based on business rules

### Audit trails

Maintain immutable audit logs of all approval decisions using the [SQL API](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/). Record:

* Who made the decision
* When the decision was made
* The reason or justification
* Any relevant metadata

### Continuous improvement

Human reviewers play a crucial role in evaluating and improving LLM performance. Implement a systematic evaluation process where human feedback is collected not just on the final output, but on the LLM's decision-making process:

* **Decision quality assessment**: Have reviewers evaluate the LLM's reasoning process and decision points.
* **Edge case identification**: Use human expertise to identify scenarios where performance could be improved.
* **Feedback collection**: Gather structured feedback that can be used to fine-tune the LLM. [AI Gateway](https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback/) can help set up an LLM feedback loop.

### Error handling and recovery

Robust error handling is essential for maintaining workflow integrity. Your system should gracefully handle:

* Reviewer unavailability
* System outages
* Conflicting reviews
* Timeout expiration

Implement clear escalation paths for exceptional cases and automatic checkpointing that allows workflows to resume from the last stable state after any interruption.

## Next steps

[Human-in-the-loop patterns](https://developers.cloudflare.com/agents/guides/human-in-the-loop/)Implementation examples for approval flows.

[Run Workflows](https://developers.cloudflare.com/agents/api-reference/run-workflows/)Complete API for workflow approvals.

[MCP elicitation](https://developers.cloudflare.com/agents/api-reference/mcp-agent-api/#elicitation-human-in-the-loop)Interactive input from MCP clients.
