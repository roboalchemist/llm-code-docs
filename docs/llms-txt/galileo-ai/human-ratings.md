# Source: https://docs.galileo.ai/galileo/gen-ai-studio-products/galileo-evaluate/concepts/human-ratings.md

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.galileo.ai/llms.txt
> Use this file to discover all available pages before exploring further.

# Human Ratings

> Learn how human ratings in Galileo Evaluate enable accurate model evaluations and improve performance through qualitative feedback.

What are Galileo human ratings?

Galileo allows users to create or rate [runs](/galileo/gen-ai-studio-products/galileo-evaluate/concepts/run) based on human ratings offering inside of [Galileo Evaluate](/galileo/gen-ai-studio-products/galileo-evaluate). Human ratings show in the Feedback section inside of Galileo Evaluate to offer the capability to see these ratings side-by-side with the runs and customize them based on the goals of the human rating. They allow users to add their own rating to a given run. The human rating types offered include:

* <Icon icon="thumbs-up" solid /> / <Icon icon="thumbs-down" solid />

* 1 - 5 <Icon icon="star" solid />

* Numerical ratings

* Categorical ratings (self-defined categories)

* Free-form text

Along with each rating, you can also allow users to provide a rationale. These ratings are aggregated against all of the runs in a [project](/galileo/gen-ai-studio-products/galileo-evaluate/concepts/project) or run.

<Frame caption="Caption Text">
  <img src="https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=1485bf9730338dad6f8e4389aa5d9511" data-og-width="291" width="291" data-og-height="350" height="350" data-path="images/ratings.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=280&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=a2f7bad47e65436463ef3ce81465b6b6 280w, https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=560&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=3df022e8446d00d6ecaaa5b4a5c75044 560w, https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=840&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=6c7f460bdb8416367157a3890dbc4b44 840w, https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=1100&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=f690d0500a0a9246a8a0d68cffbf67cb 1100w, https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=1650&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=b2e82712bf982bca675f25563394a5b7 1650w, https://mintcdn.com/galileo/PnVQRYgzV1f_rIIL/images/ratings.png?w=2500&fit=max&auto=format&n=PnVQRYgzV1f_rIIL&q=85&s=5148a8881ca7bfc4de88027aceb9ad9d 2500w" />
</Frame>

Human ratings are a great way to extend Galileo's generative AI evaluation platform to meet the needs of human evaluators, reviewers, business users, subject matter experts, data scientists, or developers. Because they are entirely customizable (through the Configure button) they can enable users to add their own feedback to a run. This is helpful in cases where [metrics](/galileo/gen-ai-studio-products/galileo-evaluate/concepts/metrics) don't capture everything being evaluated, review of metrics is being done, or additional information is gathered during evaluation. For more information, visit the [Evaluate with Human Feedback](/galileo/gen-ai-studio-products/galileo-evaluate/how-to/evaluate-with-human-feedback) page.
