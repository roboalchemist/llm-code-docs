# Source: https://developer.nvidia.com/metropolis.md

# NVIDIA Metropolis for Developers

Discover an advanced collection of developer blueprints, AI models, and tools that deliver exceptional scale, throughput, cost-effectiveness, and faster time to production. It provides everything you need to build, deploy, and scale vision AI agents and applications, from the edge to the cloud.

  
[Get Started](https://build.nvidia.com/explore/vision)

[![ A diagram showing NVIDIA Metropolis with a host of SDKs and developer tools](https://developer.download.nvidia.com/images/metropolis/metropolis-stack.png &quot; A diagram showing NVIDIA Metropolis with a host of SDKs and developer tools&quot;)](https://developer.download.nvidia.com/images/metropolis/metropolis-stack.png)

Click to enlarge

## Explore All the Benefits

### Faster Builds

Use and tune high-performance vision language models and vision foundation models to streamline AI training for your unique industry. NVIDIA Blueprints and cloud-native modular microservices are designed to help you accelerate development.

### Lower Cost

Powerful SDKs—including NVIDIA TensorRT™, DeepStream, and TAO—reduce overall solution cost. Generate synthetic data, boost accuracy with model customization, and maximize inference throughput on NVIDIA infrastructure.

### More Flexible Deployments

Deploy with flexibility using NVIDIA Inference Microservices (NIM™), cloud-native Metropolis microservices, and containerized applications offering options for on-premises, cloud, or hybrid deployments.

## Powerful Tools for   
AI-Enabled Video Analytics

The Metropolis suite of SDKs provides a variety of starting points for AI application development and deployment.

  
  

- [
#### View All
](#view-all)
- [
#### Models
](#models)
- [
#### Tools
](#tools)
- [
#### Data
](#data)

### State-of-the-Art Vision Language Models and Vision Foundation Models ​ 

[Vision language models](https://www.nvidia.com/en-us/glossary/vision-language-models/) (VLMs) are multimodal, generative AI models that can understand and process video, images, and text. Computer vision foundation models, including vision transformers (ViTs), analyze and interpret visual data to create embeddings or perform tasks like object detection, segmentation, and classification.   
 Cosmos Reason offers you an open and fully customizable world foundation model designed for video reasoning. It enables efficient training data curation for robotics and autonomous vehicles (AVs), and powers spatio-temporal understanding to accelerate automation across smart cities and industrial environments.

  

Explore

- [Explore NVIDIA NIM for Vision](https://build.nvidia.com/explore/vision)
- [Cosmos Reason](https://build.nvidia.com/nvidia/cosmos-reason1-7b)
- [Vision Foundation Models](https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/overview.html#foundation-models)

 ![A vision language model that generates text output for video insights](https://developer.download.nvidia.com/images/metropolis/metropolis-and-iva-ngc-visual-blog-1920x1080%20(2).jpg &quot;A vision language model that generates text output for video insights&quot;)

 ![The NVIDIA Train, Adapt, and Optimize (TAO) Toolkit](https://developer.download.nvidia.com/images/tao-tool-kit-key-visual-update-5.0-render-2686010.jpg &quot;The NVIDIA Train, Adapt, and Optimize (TAO) Toolkit&quot;)

### TAO 

The Train, Adapt, and Optimize (TAO) toolkit is a low-code AI model development solution for developers. It lets you use the power of transfer learning to fine-tune NVIDIA computer vision models and vision foundation models with your own data and optimize for inference—without AI expertise or a large training dataset.

  
[Learn More About TAO](/transfer-learning-toolkit)

### AI Agent Blueprints

The [NVIDIA AI Blueprint for video search and summarization (VSS)](https://build.nvidia.com/nvidia/video-search-and-summarization) makes it easy to build and customize video analytics AI agents using generative AI, VLMs, LLMs, and NVIDIA NIM. The [video analytics AI agents](https://www.nvidia.com/en-us/use-cases/video-analytics-ai-agents/) are given tasks through natural language and can analyze, interpret, and process vast amounts of video data to provide critical insights that help a range of industries optimize processes, improve safety, and cut costs.   
  
 VSS enables seamless integration of generative AI into existing computer vision pipelines—enhancing inspection, search, and analytics with multimodal understanding and zero-shot reasoning. Easily deploy from the edge to the cloud on platforms including NVIDIA RTX PRO™ 6000, DGX™ Spark, and Jetson Thor™.

  
[Explore NVIDIA AI Blueprint for Video Search and Summarization](https://build.nvidia.com/nvidia/video-search-and-summarization)

 ![Use NVIDIA AI Blueprint for video search and summarization](https://developer.download.nvidia.com/images/ai-agent-blueprints-1902x1080.jpg &quot;Use NVIDIA AI Blueprint for video search and summarization&quot;)

 ![NVIDIA NIM are easy to use, cloud-native microservices for inferencing](https://developer.download.nvidia.com/images/metropolis/practitioner-nim-1920x1080.png &quot;NVIDIA NIM are easy to use, cloud-native microservices for inferencing&quot;)

### NVIDIA NIM

NVIDIA NIM is a set of easy-to-use microservices designed for secure, reliable deployment of high-performance AI model inferencing across the cloud, data center, and workstations. Supporting a wide range of AI models—including foundation models, LLMs, VLMs, and more—NIM ensures seamless, scalable AI inferencing, on-premises or in the cloud, using industry-standard APIs.

  
[Explore NVIDIA NIM for Vision](https://build.nvidia.com/explore/vision)  

### Metropolis Microservices

Metropolis microservices provide powerful, customizable, cloud-native building blocks for developing vision AI agents, applications, and solutions. They’re built to run on NVIDIA cloud and data center GPUs, as well as the NVIDIA Jetson Orin™ edge AI platform.

  
[Learn More](/metropolis-microservices)

 ![Use Metropolis microservices to develop vision AI applications.](https://developer.download.nvidia.com/images/metropolis/metropolis-key-visual-microservices-ref-app.jpg &quot;Use Metropolis microservices to develop vision AI applications.&quot;)

 ![NVIDIA DeepStream SDK is a complete streaming analytics toolkit](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/deep-stream-sdk-630x354.jpg &quot;NVIDIA DeepStream SDK is a complete streaming analytics toolkit&quot;)

### DeepStream SDK

NVIDIA DeepStream SDK is a complete streaming analytics toolkit based on GStreamer for AI-based multi-sensor processing, video, audio, and image understanding. It’s ideal for vision AI developers, software partners, startups, and OEMs building IVA apps and services. DeepStream 8.0 will include multi-camera tracking and a low-code inference builder.

  
[Learn More About DeepStream SDK](/deepstream-sdk)

### NVIDIA Omniverse

NVIDIA Omniverse™ helps you integrate [OpenUSD](https://www.nvidia.com/en-us/omniverse/usd/), NVIDIA RTX™ rendering technologies, and generative [physical AI](https://www.nvidia.com/en-us/glossary/generative-physical-ai/) into existing software tools and simulation workflows to develop and test [digital twins](https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/). You can use it with your own software for building AI-powered robot brains that drive robots, Metropolis perception from cameras, equipment, and more for continuous development, testing, and optimization.  
  
 Omniverse Replicator makes it easier to generate physically accurate 3D synthetic data at scale, or build your own [synthetic data](https://nvidia.com/en-us/use-cases/synthetic-data/) tools and frameworks. Bootstrap perception AI model training and achieve accurate Sim2Real performance without having to manually curate and label real-world data.

  
[Learn More About Omniverse Replicator](/nvidia-omniverse-platform/replicator)

 ![An autonomous mobile robot in action in a warehouse](https://developer.download.nvidia.com/images/metropolis/replicator-isaac-sim-630x354.jpg &quot;An autonomous mobile robot in action in a warehouse&quot;)

 ![Use NVIDIA Cosmos generative world foundation models to build physical AI systems](https://developer.download.nvidia.com/images/metropolis/physical-ai-dataset-1902x1080.jpg &quot;Use NVIDIA Cosmos generative world foundation models to build physical AI systems&quot;)

### NVIDIA Cosmos

NVIDIA Cosmos™ is a platform of state-of-the-art generative [world foundation models](https://www.nvidia.com/en-us/glossary/world-models/?ncid=ref-dev-171762-vlm-jan-25) (WFMs), advanced tokenizers, guardrails, and an accelerated data processing and curation pipeline. It&#39;s purpose-built to accelerate the development of [physical AI](https://www.nvidia.com/en-us/glossary/physical-ai/?ncid=ref-dev-171762-vlm-jan-25) systems.

  
[Learn More About NVIDIA Cosmos](https://www.nvidia.com/en-us/ai/cosmos/)

### NVIDIA Physical AI Dataset

Unblock data bottlenecks with this open-source dataset for training vision AI applications to understand industrial facilities, smart cities, robots, and autonomous vehicle development. The unified collection is composed of validated data used to build NVIDIA physical AI solutions—now available for free to developers on Hugging Face.   
  
[Explore the NVIDIA Physical AI Dataset](https://huggingface.co/collections/nvidia/physicalai-67c643edbb024053dcbcd6d8)

 ![NVIDIA Physical AI dataset for smart spaces, robot, and autonomous vehicle development](https://developer.download.nvidia.com/images/metropolis/largest-synthetic-dataset-sfg.jpg &quot;NVIDIA Physical AI dataset for smart spaces, robot, and autonomous vehicle development&quot;)

 ![NVIDIA Isaac SIM mimics industrial facilities](https://developer.download.nvidia.com/images/metropolis/nvidia-isaac-sim.jpg &quot;NVIDIA Isaac SIM mimics industrial facilities&quot;)

### NVIDIA Isaac SIM

Developers need training data that mimics what cameras would capture in complex, dynamic 3D spaces such as industrial facilities and smart cities. Action and Event Data Generation is a reference application on NVIDIA Isaac Sim™. It lets developers generate synthetic image and video data in a physically accurate virtual environment to train custom vision AI models.   
  
 These include tools to simulate actors like humans and robots, create objects with domain randomization, and generate incident-based scenarios for various vision AI models. Use the VLM scene captioning tool to automatically generate image-caption pairs and accelerate the annotation process   
  
[Get started With Event and Actor Generation on Isaac SIM](https://docs.isaacsim.omniverse.nvidia.com/latest/action_and_event_data_generation/index.html)

## Use and Fine-Tune Optimized AI Models

### State-of-the-Art Vision Language Models and Vision Foundation Models ​ 

[Vision language models](https://www.nvidia.com/en-us/glossary/vision-language-models/) (VLMs) are multimodal, generative AI models that can understand and process video, images, and text. Computer vision foundation models, including vision transformers (ViTs), analyze and interpret visual data to create embeddings or perform tasks like object detection, segmentation, and classification.   
 Cosmos Reason offers you an open and fully customizable world foundation model designed for video reasoning. It enables efficient training data curation for robotics and autonomous vehicles (AVs), and powers spatio-temporal understanding to accelerate automation across smart cities and industrial environments.

  

Explore

- [Explore NVIDIA NIM for Vision](https://build.nvidia.com/explore/vision)
- [Cosmos Reason](https://build.nvidia.com/nvidia/cosmos-reason1-7b)
- [Vision Foundation Models](https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/overview.html#foundation-models)

 ![A vision language model that generates text output for video insights](https://developer.download.nvidia.com/images/metropolis/metropolis-and-iva-ngc-visual-blog-1920x1080%20(2).jpg &quot;A vision language model that generates text output for video insights&quot;)

 ![The NVIDIA Train, Adapt, and Optimize (TAO) Toolkit](https://developer.download.nvidia.com/images/tao-tool-kit-key-visual-update-5.0-render-2686010.jpg &quot;The NVIDIA Train, Adapt, and Optimize (TAO) Toolkit&quot;)

### TAO 

The Train, Adapt, and Optimize (TAO) toolkit is a low-code AI model development solution for developers. It lets you use the power of transfer learning to fine-tune NVIDIA computer vision models and vision foundation models with your own data and optimize for inference—without AI expertise or a large training dataset.

  
[Learn More About TAO](/transfer-learning-toolkit)

## Build Powerful AI Applications

### AI Agent Blueprints

The [NVIDIA AI Blueprint for video search and summarization (VSS)](https://build.nvidia.com/nvidia/video-search-and-summarization) makes it easy to build and customize video analytics AI agents using generative AI, VLMs, LLMs, and NVIDIA NIM. The [video analytics AI agents](https://www.nvidia.com/en-us/use-cases/video-analytics-ai-agents/) are given tasks through natural language and can analyze, interpret, and process vast amounts of video data to provide critical insights that help a range of industries optimize processes, improve safety, and cut costs.   
  
 VSS enables seamless integration of generative AI into existing computer vision pipelines—enhancing inspection, search, and analytics with multimodal understanding and zero-shot reasoning. Easily deploy from the edge to the cloud on platforms including NVIDIA RTX PRO™ 6000, DGX™ Spark, and Jetson Thor™.

  
[Explore NVIDIA AI Blueprint for Video Search and Summarization](https://build.nvidia.com/nvidia/video-search-and-summarization)

 ![Use NVIDIA AI Blueprint for video search and summarization](https://developer.download.nvidia.com/images/ai-agent-blueprints-1902x1080.jpg &quot;Use NVIDIA AI Blueprint for video search and summarization&quot;)

 ![NVIDIA NIM are easy to use, cloud-native microservices for inferencing](https://developer.download.nvidia.com/images/metropolis/practitioner-nim-1920x1080.png &quot;NVIDIA NIM are easy to use, cloud-native microservices for inferencing&quot;)

### NVIDIA NIM

NVIDIA NIM is a set of easy-to-use microservices designed for secure, reliable deployment of high-performance AI model inferencing across the cloud, data center, and workstations. Supporting a wide range of AI models—including foundation models, LLMs, VLMs, and more—NIM ensures seamless, scalable AI inferencing, on-premises or in the cloud, using industry-standard APIs.

  
[Explore NVIDIA NIM for Vision](https://build.nvidia.com/explore/vision)  

### Metropolis Microservices

Metropolis microservices provide powerful, customizable, cloud-native building blocks for developing vision AI agents, applications, and solutions. They’re built to run on NVIDIA cloud and data center GPUs, as well as the NVIDIA Jetson Orin™ edge AI platform.

  
[Learn More](/metropolis-microservices)

 ![Use Metropolis microservices to develop vision AI applications.](https://developer.download.nvidia.com/images/metropolis/metropolis-key-visual-microservices-ref-app.jpg &quot;Use Metropolis microservices to develop vision AI applications.&quot;)

 ![NVIDIA DeepStream SDK is a complete streaming analytics toolkit](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/deep-stream-sdk-630x354.jpg &quot;NVIDIA DeepStream SDK is a complete streaming analytics toolkit&quot;)

### DeepStream SDK

NVIDIA DeepStream SDK is a complete streaming analytics toolkit based on GStreamer for AI-based multi-sensor processing, video, audio, and image understanding. It’s ideal for vision AI developers, software partners, startups, and OEMs building IVA apps and services. DeepStream 8.0 will include multi-camera tracking and a low-code inference builder.

  
[Learn More About DeepStream SDK](/deepstream-sdk)

## Augment Training With Simulation and Synthetic Data

### NVIDIA Omniverse

NVIDIA Omniverse™ helps you integrate [OpenUSD](https://www.nvidia.com/en-us/omniverse/usd/), NVIDIA RTX™ rendering technologies, and generative [physical AI](https://www.nvidia.com/en-us/glossary/generative-physical-ai/) into existing software tools and simulation workflows to develop and test [digital twins](https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/). You can use it with your own software for building AI-powered robot brains that drive robots, Metropolis perception from cameras, equipment, and more for continuous development, testing, and optimization.  
  
 Omniverse Replicator makes it easier to generate physically accurate 3D synthetic data at scale, or build your own [synthetic data](https://nvidia.com/en-us/use-cases/synthetic-data/) tools and frameworks. Bootstrap perception AI model training and achieve accurate Sim2Real performance without having to manually curate and label real-world data.

  
[Learn More About Omniverse Replicator](/nvidia-omniverse-platform/replicator)

 ![An autonomous mobile robot in action in a warehouse](https://developer.download.nvidia.com/images/metropolis/replicator-isaac-sim-630x354.jpg &quot;An autonomous mobile robot in action in a warehouse&quot;)

 ![Use NVIDIA Cosmos generative world foundation models to build physical AI systems](https://developer.download.nvidia.com/images/metropolis/physical-ai-dataset-1902x1080.jpg &quot;Use NVIDIA Cosmos generative world foundation models to build physical AI systems&quot;)

### NVIDIA Cosmos

NVIDIA Cosmos™ is a platform of state-of-the-art generative [world foundation models](https://www.nvidia.com/en-us/glossary/world-models/?ncid=ref-dev-171762-vlm-jan-25) (WFMs), advanced tokenizers, guardrails, and an accelerated data processing and curation pipeline. It&#39;s purpose-built to accelerate the development of [physical AI](https://www.nvidia.com/en-us/glossary/physical-ai/?ncid=ref-dev-171762-vlm-jan-25) systems.

  
[Learn More About NVIDIA Cosmos](https://www.nvidia.com/en-us/ai/cosmos/)

### NVIDIA Physical AI Dataset

Unblock data bottlenecks with this open-source dataset for training vision AI applications to understand industrial facilities, smart cities, robots, and autonomous vehicle development. The unified collection is composed of validated data used to build NVIDIA physical AI solutions—now available for free to developers on Hugging Face.   
  
[Explore the NVIDIA Physical AI Dataset](https://huggingface.co/collections/nvidia/physicalai-67c643edbb024053dcbcd6d8)

 ![NVIDIA Physical AI dataset for smart spaces, robot, and autonomous vehicle development](https://developer.download.nvidia.com/images/metropolis/largest-synthetic-dataset-sfg.jpg &quot;NVIDIA Physical AI dataset for smart spaces, robot, and autonomous vehicle development&quot;)

 ![NVIDIA Isaac SIM mimics industrial facilities](https://developer.download.nvidia.com/images/metropolis/nvidia-isaac-sim.jpg &quot;NVIDIA Isaac SIM mimics industrial facilities&quot;)

### NVIDIA Isaac SIM

Developers need training data that mimics what cameras would capture in complex, dynamic 3D spaces such as industrial facilities and smart cities. Action and Event Data Generation is a reference application on NVIDIA Isaac Sim™. It lets developers generate synthetic image and video data in a physically accurate virtual environment to train custom vision AI models.   
  
 These include tools to simulate actors like humans and robots, create objects with domain randomization, and generate incident-based scenarios for various vision AI models. Use the VLM scene captioning tool to automatically generate image-caption pairs and accelerate the annotation process   
  
[Get started With Event and Actor Generation on Isaac SIM](https://docs.isaacsim.omniverse.nvidia.com/latest/action_and_event_data_generation/index.html)

  
  

* * *

## Developer Resources

 ![Learn how to build a video search and summarization agent](https://developer.download.nvidia.com/images/metropolis/build-video-search%201902x1080.jpg &quot;Learn how to build a video search and summarization agent&quot;)

### Build a Video Search and Summarization Agent

Learn how to seamlessly build a video analytics AI agent using NVIDIA AI Blueprint for video search and summarization (VSS).

Read the Blog:

[Part 1](https://developer.nvidia.com/blog/build-a-video-search-and-summarization-agent-with-nvidia-ai-blueprint/) | [Part 2](https://developer.nvidia.com/blog/advance-video-analytics-ai-agents-using-the-nvidia-ai-blueprint-for-video-search-and-summarization/)

 ![A vision language model workflow](https://developer.download.nvidia.com/images/metropolis/vlm-reference-workflows-1902x1080.jpg &quot;A vision language model workflow&quot;)

### VLM Reference Workflows

Check out advanced workflows for building multimodal visual AI agents.

[Read the Blog](/blog/build-multimodal-visual-ai-agents-powered-by-nvidia-nim/)

 ![Security alert on detecting a person without wearing a helmet](https://developer.download.nvidia.com/images/metropolis/vlm-prompt-guide-1902x1080.jpg &quot;Security alert on detecting a person without wearing a helmet&quot;)

### VLM Prompt Guide

Learn how to effectively prompt a VLM for single-image, multi-image, and video-understanding use cases.

[Read the Blog](/blog/vision-language-model-prompt-engineering-guide-for-image-and-video-understanding/)

 ![Learn how to fine-tune NVIDIA Cosmos Reason](https://developer.download.nvidia.com/images/metropolis/nvidia-cosmos.jpg &quot; Learn how to fine-tune NVIDIA Cosmos Reason &quot;)

### Post-train NVIDIA Cosmos Reason

Learn how to fine-tune NVIDIA Cosmos Reason VLM for physical AI and robotics.

[Read the Blog](/blog/maximize-robotics-performance-by-post-training-nvidia-cosmos-reason)

  
[View all Metropolis technical blogs](/blog/tag/metropolis/)

## Explore NVIDIA GTC Talks On-Demand

Develop, deploy, and scale AI-enabled video analytics applications with NVIDIA Metropolis.

  
[Get Started](https://build.nvidia.com/explore/vision)

