# Trigger Documentation

Source: https://trigger.dev/docs/llms-full.txt

---

# API keys
Source: https://trigger.dev/docs/apikeys

How to authenticate with Trigger.dev so you can trigger tasks.

### Authentication and your secret keys

When you [trigger a task](/triggering) from your backend code, you need to set the `TRIGGER_SECRET_KEY` environment variable.

Each environment has its own secret key. You can find the value on the API keys page in the Trigger.dev dashboard:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=89dd26bf57f345bad4508ee5eec70c8c" alt="How to find your secret key" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/api-keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988f98dd098b108ca51d8c0aeb829344 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=14431ee3376a9a6b845744b0b3acce60 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9059b9369eb793b9df4cceee1f985286 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccd1e2a8512f491128a53cd4ebe8823f 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ab656ff2f4b95e32558aacaa485c86ea 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3bb0b87a8e1a3033a8ff1ba3590f5786 2500w" />

<Note>
  For preview branches, you need to also set the `TRIGGER_PREVIEW_BRANCH` environment variable as
  well. You can find the value on the API keys page when you're on the preview branch.
</Note>

### Automatically Configuring the SDK

To automatically configure the SDK with your secret key, you can set the `TRIGGER_SECRET_KEY` environment variable. The SDK will automatically use this value when calling API methods (like `trigger`).

```bash .env theme={null}
TRIGGER_SECRET_KEY="tr_dev_â€¦"
TRIGGER_PREVIEW_BRANCH="my-branch" # Only needed for preview branches
```

You can do the same if you are self-hosting and need to change the default URL by using `TRIGGER_API_URL`.

```bash .env theme={null}
TRIGGER_API_URL="https://trigger.example.com"
TRIGGER_PREVIEW_BRANCH="my-branch" # Only needed for preview branches
```

The default URL is `https://api.trigger.dev`.

### Manually Configuring the SDK

If you prefer to manually configure the SDK, you can call the `configure` method:

```ts  theme={null}
import { configure } from "@trigger.dev/sdk";
import { myTask } from "./trigger/myTasks";

configure({
  secretKey: "tr_dev_1234", // WARNING: Never actually hardcode your secret key like this
  previewBranch: "my-branch", // Only needed for preview branches
  baseURL: "https://mytrigger.example.com", // Optional
});

async function triggerTask() {
  await myTask.trigger({ userId: "1234" }); // This will use the secret key and base URL you configured
}
```


# Bulk actions
Source: https://trigger.dev/docs/bulk-actions

Perform actions like replay and cancel on multiple runs at once.

Bulk actions allow you to perform replaying and canceling on multiple runs at once. This is especially useful when you need to retry a batch of failed runs with a new version of your code, or when you need to cancel multiple in-progress runs.

<video src="https://content.trigger.dev/bulk-actions.mp4" preload="auto" controls={true} loop muted autoPlay={true} width="100%" height="100%" />

## How to create a new bulk action

<Icon icon="circle-1" iconType="solid" color="#FF2D6B" size="20" /> Open the bulk action panel from the top right of the runs page

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e514c6b6e2c85aa8dc9bbb2cc6604f21" alt="Access bulk actions" data-og-width="964" width="964" data-og-height="603" height="603" data-path="images/bulk-action-open-panel.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2db95026487a80b1d57ee2e9d323de2e 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=deac85b94c6525e9ca7136e4d7901430 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=390ddf4d7547afda4ef773ebd77df3a3 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=287b549119575900dcc9a35e2a7ab102 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=64b3370c36d84378503b75a0ad69625e 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-open-panel.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a27ba4f0c162eedea68d4aa30fea586d 2500w" />

<Icon icon="circle-2" iconType="solid" color="#FF2D6B" size="20" /> Filter the runs table to show the runs you want to bulk action

<Icon icon="circle-3" iconType="solid" color="#FF2D6B" size="20" /> Alternatively, you can select individual runs

<Icon icon="circle-4" iconType="solid" color="#FF2D6B" size="20" /> Choose the runs you want to bulk action

<Icon icon="circle-5" iconType="solid" color="#FF2D6B" size="20" /> Name your bulk action (optional)

<Icon icon="circle-6" iconType="solid" color="#FF2D6B" size="20" /> Choose the action you want to perform, replay or cancel

<Icon icon="circle-7" iconType="solid" color="#FF2D6B" size="20" /> Click the "Replay" or "Cancel" button and confirm in the dialog

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=defba18d2817528b5cbbfbdac1b01552" alt="Access bulk actions" data-og-width="2259" width="2259" data-og-height="1367" height="1367" data-path="images/bulk-action-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=19fd9f671352330844e7f110ad14a0f8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=87fd7db03b2a74b800ef8e0a604bd6f0 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ea3a3098343e2d2e60da28dc7b9fef31 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8161348b29508970accc2f5446e50efe 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=924aaf1bb8da051d13bd69ea4519d7cd 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-create.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6803e8104f4d87f836cf33c62b62a8d1 2500w" />

<Icon icon="circle-8" iconType="solid" color="#FF2D6B" size="20" /> You'll now view the bulk action processing from the bulk action page

<Icon icon="circle-9" iconType="solid" color="#FF2D6B" size="20" /> You can replay or view the runs from this page

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a796b724494a8c0cce3883d2befc5b46" alt="Access bulk actions" data-og-width="2257" width="2257" data-og-height="1361" height="1361" data-path="images/bulk-action-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7a3efe830f40fa011a4989395b15e379 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f92ad95480036aa4aa2a8afc068ac13d 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2608c90d86865c4e11f61ab04bae1500 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f76d6f0f705e3ee06b4093a6ab2f1d0e 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1e717867248f17650f73fdfa29483255 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/bulk-action-page.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0efccaacafe8c9b650ff5beee3f8b82e 2500w" />

<Note>
  You can only cancel runs that are in states that allow cancellation (like QUEUED or EXECUTING).
  Runs that are already completed, failed, or in other final states by the time the bulk action process gets to them, cannot be canceled.
</Note>


# Changelog
Source: https://trigger.dev/docs/changelog



Our [changelog](https://trigger.dev/changelog) is the best way to stay up to date with the latest changes to Trigger.


# CLI deploy command
Source: https://trigger.dev/docs/cli-deploy-commands

Use the deploy command to deploy your tasks to Trigger.dev.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

<Warning>
  This will fail in CI if any version mismatches are detected. Ensure everything runs locally first
  using the [dev](/cli-dev-commands) command and don't bypass the version checks!
</Warning>

It performs a few steps to deploy:

1. Optionally updates packages when running locally.
2. Compiles and bundles the code.
3. Deploys the code to the Trigger.dev instance.
4. Registers the tasks as a new version in the environment (prod by default).

## Deploying from CI

When deploying from CI/CD environments such as GitHub Actions, GitLab CI, or Jenkins, you need to authenticate non-interactively by setting the `TRIGGER_ACCESS_TOKEN` environment variable. Please see the [CI / GitHub Actions guide](/github-actions) for more information.

## Arguments

```
npx trigger.dev@latest deploy [path]
```

<ParamField body="Project path" type="[path]">
  The path to the project. Defaults to the current directory.
</ParamField>

## Options

<ParamField body="Config file" type="--config | -c">
  The name of the config file found at the project path. Defaults to `trigger.config.ts`
</ParamField>

<ParamField body="Project ref" type="--project-ref | -p">
  The project ref. Required if there is no config file.
</ParamField>

<ParamField body="Env file" type="--env-file">
  Load environment variables from a file. This will only hydrate the `process.env` of the CLI
  process, not the tasks.
</ParamField>

<ParamField body="Skip update check" type="--skip-update-check">
  Skip checking for `@trigger.dev` package updates.
</ParamField>

<ParamField body="Environment" type="--env | -e">
  Defaults to `prod` but you can specify `staging` or `preview`. If you specify `preview` we will
  try and automatically detect the branch name from git.
</ParamField>

<ParamField body="Preview branch" type="--branch | -b">
  When using `--env preview` the branch is automatically detected from git. But you can manually
  specify it by using this option, e.g. `--branch my-branch` or `-b my-branch`.
</ParamField>

<ParamField body="Dry run" type="--dry-run">
  Create a deployable build but don't deploy it. Prints out the build path so you can inspect it.
</ParamField>

<ParamField body="Skip promotion" type="--skip-promotion">
  Skips automatically promoting the newly deployed version to the "current" deploy.
</ParamField>

<ParamField body="Skip syncing env vars" type="--skip-sync-env-vars">
  Turn off syncing environment variables with the Trigger.dev instance.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>

### Self-hosting

These options are typically used when [self-hosting](/open-source-self-hosting) or for local development.

<ParamField body="Self-hosted (builds locally)" type="--self-hosted">
  Builds and loads the image using your local docker. Use the `--registry` option to specify the
  registry to push the image to when using `--self-hosted`, or just use `--push` to push to the
  default registry.
</ParamField>

<ParamField body="Skip deploying the image" type="--skip-deploy | -D">
  Load the built image into your local docker.
</ParamField>

<ParamField body="Load image" type="--load-image">
  Loads the image into your local docker after building it.
</ParamField>

<ParamField body="Registry" type="--registry">
  Specify the registry to push the image to when using `--self-hosted`. Will automatically enable
  `--push`.
</ParamField>

<ParamField body="Push image" type="--push">
  When using the `--self-hosted` flag, push the image to the registry.
</ParamField>

<ParamField body="Namespace" type="--namespace">
  The namespace to use when pushing the image to the registry. For example, if pushing to Docker
  Hub, the namespace is your Docker Hub username.
</ParamField>

<ParamField body="Network" type="--network">
  The networking mode for RUN instructions when using `--self-hosted`.
</ParamField>

## Examples

### Push to Docker Hub (self-hosted)

An example of deploying to Docker Hub when using a self-hosted setup:

```bash  theme={null}
npx trigger.dev@latest deploy \
  --self-hosted \
  --load-image \
  --registry docker.io \
  --namespace mydockerhubusername
```


# CLI dev command
Source: https://trigger.dev/docs/cli-dev

The `trigger.dev dev` command is used to run your tasks locally.

This runs a server on your machine that can execute Trigger.dev tasks:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest dev
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest dev
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest dev
  ```
</CodeGroup>

It will first perform an update check to prevent version mismatches, failed deploys, and other errors. You will always be prompted first.

You will see in the terminal that the server is running and listening for tasks. When you run a task, you will see it in the terminal along with a link to view it in the dashboard.

It is worth noting that each task runs in a separate Node process. This means that if you have a long-running task, it will not block other tasks from running.

## Options

<ParamField body="Config file" type="--config | -c">
  The name of the config file found at the project path. Defaults to `trigger.config.ts`
</ParamField>

<ParamField body="Project ref" type="--project-ref | -p">
  The project ref. Required if there is no config file.
</ParamField>

<ParamField body="Env file" type="--env-file">
  Load environment variables from a file. This will only hydrate the `process.env` of the CLI
  process, not the tasks.
</ParamField>

<ParamField body="Skip update check" type="--skip-update-check">
  Skip checking for `@trigger.dev` package updates.
</ParamField>

<ParamField body="Analyze build output" type="--analyze">
  Analyzes the build output and displays detailed import timings. This is useful for debugging the
  start times for your runs which can be caused by importing lots of code or heavy packages.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>

## Concurrently running the terminal

Install the concurrently package as a dev dependency:

```ts  theme={null}
concurrently --raw --kill-others npm:dev:remix npm:dev:trigger
```

Then add something like this in your package.json scripts:

```json  theme={null}
"scripts": {
  "dev": "concurrently --raw --kill-others npm:dev:*",
  "dev:trigger": "npx trigger.dev@latest dev",
  // Add your framework-specific dev script here, for example:
  // "dev:next": "next dev",
  // "dev:remix": "remix dev",
  //...
}
```


# CLI dev command
Source: https://trigger.dev/docs/cli-dev-commands

The `trigger.dev dev` command is used to run your tasks locally.

This runs a server on your machine that can execute Trigger.dev tasks:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest dev
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest dev
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest dev
  ```
</CodeGroup>

It will first perform an update check to prevent version mismatches, failed deploys, and other errors. You will always be prompted first.

You will see in the terminal that the server is running and listening for tasks. When you run a task, you will see it in the terminal along with a link to view it in the dashboard.

It is worth noting that each task runs in a separate Node process. This means that if you have a long-running task, it will not block other tasks from running.

## Options

<ParamField body="Config file" type="--config | -c">
  The name of the config file found at the project path. Defaults to `trigger.config.ts`
</ParamField>

<ParamField body="Project ref" type="--project-ref | -p">
  The project ref. Required if there is no config file.
</ParamField>

<ParamField body="Env file" type="--env-file">
  Load environment variables from a file. This will only hydrate the `process.env` of the CLI
  process, not the tasks.
</ParamField>

<ParamField body="Skip update check" type="--skip-update-check">
  Skip checking for `@trigger.dev` package updates.
</ParamField>

<ParamField body="Analyze build output" type="--analyze">
  Analyzes the build output and displays detailed import timings. This is useful for debugging the
  start times for your runs which can be caused by importing lots of code or heavy packages.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>

## Concurrently running the terminal

Install the concurrently package as a dev dependency:

```ts  theme={null}
concurrently --raw --kill-others npm:dev:remix npm:dev:trigger
```

Then add something like this in your package.json scripts:

```json  theme={null}
"scripts": {
  "dev": "concurrently --raw --kill-others npm:dev:*",
  "dev:trigger": "npx trigger.dev@latest dev",
  // Add your framework-specific dev script here, for example:
  // "dev:next": "next dev",
  // "dev:remix": "remix dev",
  //...
}
```


# CLI init command
Source: https://trigger.dev/docs/cli-init-commands

Use these options when running the CLI `init` command.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest init
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest init
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest init
  ```
</CodeGroup>

## Options

<ParamField body="Javascript" type="--javascript">
  By default, the init command assumes you are using TypeScript. Use this flag to initialize a
  project that uses JavaScript.
</ParamField>

<ParamField body="Project ref" type="--project-ref | -p">
  The project ref to use when initializing the project.
</ParamField>

<ParamField body="Package tag" type="--tag | -t">
  The version of the `@trigger.dev/sdk` package to install. Defaults to `latest`.
</ParamField>

<ParamField body="Skip package install" type="--skip-package-install">
  Skip installing the `@trigger.dev/sdk` package.
</ParamField>

<ParamField body="Override config" type="--override-config">
  Override the existing config file if it exists.
</ParamField>

<ParamField body="Package arguments" type="--pkg-args">
  Additional arguments to pass to the package manager. Accepts CSV for multiple args.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# Introduction
Source: https://trigger.dev/docs/cli-introduction

The Trigger.dev CLI has a number of options and commands to help you develop locally, self host, and deploy your tasks.

## Options

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>

## Commands

| Command                                      | Description                                                        |
| :------------------------------------------- | :----------------------------------------------------------------- |
| [login](/cli-login-commands)                 | Login with Trigger.dev so you can perform authenticated actions.   |
| [init](/cli-init-commands)                   | Initialize your existing project for development with Trigger.dev. |
| [dev](/cli-dev-commands)                     | Run your Trigger.dev tasks locally.                                |
| [deploy](/cli-deploy-commands)               | Deploy your Trigger.dev v3 project to the cloud.                   |
| [whoami](/cli-whoami-commands)               | Display the current logged in user and project details.            |
| [logout](/cli-logout-commands)               | Logout of Trigger.dev.                                             |
| [list-profiles](/cli-list-profiles-commands) | List all of your CLI profiles.                                     |
| [update](/cli-update-commands)               | Updates all `@trigger.dev/*` packages to match the CLI version.    |


# CLI list-profiles command
Source: https://trigger.dev/docs/cli-list-profiles-commands

Use these options when using the `list-profiles` CLI command.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest list-profiles
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest list-profiles
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest list-profiles
  ```
</CodeGroup>

## Options

### Common options

These options are available on most commands.

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI login command
Source: https://trigger.dev/docs/cli-login-commands

Use these options when logging in to Trigger.dev using the CLI.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest login
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest login
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest login
  ```
</CodeGroup>

## Options

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI logout command
Source: https://trigger.dev/docs/cli-logout-commands

Use these options when using the `logout` CLI command.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest logout
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest logout
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest logout
  ```
</CodeGroup>

## Options

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI preview archive command
Source: https://trigger.dev/docs/cli-preview-archive

The `trigger.dev preview archive` command can be used to archive a preview branch.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest preview archive
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest preview archive
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest preview archive
  ```
</CodeGroup>

It will archive the preview branch, automatically detecting the branch name from git. You can manually specify the branch using the `--branch` option.

## Arguments

```
npx trigger.dev@latest preview archive [path]
```

<ParamField body="Project path" type="[path]">
  The path to the project. Defaults to the current directory.
</ParamField>

## Options

<ParamField body="Preview branch" type="--branch | -b">
  When using `--env preview` the branch is automatically detected from git. But you can manually
  specify it by using this option, e.g. `--branch my-branch` or `-b my-branch`.
</ParamField>

<ParamField body="Config file" type="--config | -c">
  The name of the config file found at the project path. Defaults to `trigger.config.ts`
</ParamField>

<ParamField body="Project ref" type="--project-ref | -p">
  The project ref. Required if there is no config file.
</ParamField>

<ParamField body="Env file" type="--env-file">
  Load environment variables from a file. This will only hydrate the `process.env` of the CLI
  process, not the tasks.
</ParamField>

<ParamField body="Skip update check" type="--skip-update-check">
  Skip checking for `@trigger.dev` package updates.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI promote command
Source: https://trigger.dev/docs/cli-promote-commands

Use the promote command to promote a previously deployed version to the current version.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest promote [version]
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest promote [version]
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest promote [version]
  ```
</CodeGroup>

## Arguments

```
npx trigger.dev@latest promote [version]
```

<ParamField body="Deployment version" type="[version]">
  The version to promote. This is the version that was previously deployed.
</ParamField>

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI switch command
Source: https://trigger.dev/docs/cli-switch

The `trigger.dev switch` command can be used to switch between profiles.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest switch [profile]
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest switch [profile]
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest switch [profile]
  ```
</CodeGroup>

It will switch to the specified profile. If no profile is specified, it will list all available profiles and run interactively.

## Arguments

```
npx trigger.dev@latest switch [profile]
```

<ParamField body="Profile" type="[profile]">
  The profile to switch to. If not specified, it will list all available profiles and run interactively.
</ParamField>


# CLI update command
Source: https://trigger.dev/docs/cli-update-commands

Use these options when using the `update` CLI command.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest update
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest update
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest update
  ```
</CodeGroup>

## Options

### Common options

These options are available on most commands.

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# CLI whoami command
Source: https://trigger.dev/docs/cli-whoami-commands

Use these options to display the current logged in user and project details.

Run the command like this:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest whoami
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest whoami
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest whoami
  ```
</CodeGroup>

## Options

### Common options

These options are available on most commands.

<ParamField body="Login profile" type="--profile">
  The login profile to use. Defaults to "default".
</ParamField>

<ParamField body="API URL" type="--api-url | -a">
  Override the default API URL. If not specified, it uses `https://api.trigger.dev`. This can also be set via the `TRIGGER_API_URL` environment variable.
</ParamField>

<ParamField body="Log level" type="--log-level | -l">
  The CLI log level to use. Options are `debug`, `info`, `log`, `warn`, `error`, and `none`. This does not affect the log level of your trigger.dev tasks. Defaults to `log`.
</ParamField>

<ParamField body="Skip telemetry" type="--skip-telemetry">
  Opt-out of sending telemetry data. This can also be done via the `TRIGGER_TELEMETRY_DISABLED` environment variable. Just set it to anything other than an empty string.
</ParamField>

<ParamField body="Help" type="--help | -h">
  Shows the help information for the command.
</ParamField>

<ParamField body="Version" type="--version | -v">
  Displays the version number of the CLI.
</ParamField>


# Discord Community
Source: https://trigger.dev/docs/community



Please [join our community on Discord](https://trigger.dev/discord) to ask questions, share your projects, and get help from other developers.


# The trigger.config.ts file
Source: https://trigger.dev/docs/config/config-file

This file is used to configure your project and how it's built.

The `trigger.config.ts` file is used to configure your Trigger.dev project. It is a TypeScript file at the root of your project that exports a default configuration object. Here's an example:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  // Your project ref (you can see it on the Project settings page in the dashboard)
  project: "<project ref>",
  //The paths for your trigger folders
  dirs: ["./trigger"],
  retries: {
    //If you want to retry a task in dev mode (when using the CLI)
    enabledInDev: false,
    //the default retry settings. Used if you don't specify on a task.
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
});
```

The config file handles a lot of things, like:

* Specifying where your trigger tasks are located using the `dirs` option.
* Setting the default retry settings.
* Configuring OpenTelemetry instrumentations.
* Customizing the build process.
* Adding global task lifecycle functions.

<Note>
  The config file is bundled with your project, so code imported in the config file is also bundled,
  which can have an effect on build times and cold start duration. One important qualification is
  anything defined in the `build` config is automatically stripped out of the config file, and
  imports used inside build config with be tree-shaken out.
</Note>

## Dirs

You can specify the directories where your tasks are located using the `dirs` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  dirs: ["./trigger"],
});
```

If you omit the `dirs` option, we will automatically detect directories that are named `trigger` in your project, but we recommend specifying the directories explicitly. The `dirs` option is an array of strings, so you can specify multiple directories if you have tasks in multiple locations.

We will search for TypeScript and JavaScript files in the specified directories and include them in the build process. We automatically exclude files that have `.test` or `.spec` in the name, but you can customize this by specifying glob patterns in the `ignorePatterns` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  dirs: ["./trigger"],
  ignorePatterns: ["**/*.my-test.ts"],
});
```

## Custom tsconfig path

You can specify a custom path to your tsconfig file. This is useful if you have a custom tsconfig file that you want to use.

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  dirs: ["./trigger"],
  tsconfig: "./custom-tsconfig.json", // Custom tsconfig path
});
```

## Lifecycle functions

You can add lifecycle functions to get notified when any task starts, succeeds, or fails using `onStart`, `onSuccess` and `onFailure`:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  onSuccess: async ({ payload, output, ctx }) => {
    console.log("Task succeeded", ctx.task.id);
  },
  onFailure: async ({ payload, error, ctx }) => {
    console.log("Task failed", ctx.task.id);
  },
  onStart: async ({ payload, ctx }) => {
    console.log("Task started", ctx.task.id);
  },
  init: async ({ payload, ctx }) => {
    console.log("I run before any task is run");
  },
});
```

Read more about task lifecycle functions in the [tasks overview](/tasks/overview).

## Instrumentations

We use OpenTelemetry (OTEL) for our run logs. This means you get a lot of information about your tasks with no effort. But you probably want to add more information to your logs. For example, here's all the Prisma calls automatically logged:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c23b7b3b9b853d52af2850b732e576d7" alt="The run log" data-og-width="1442" width="1442" data-og-height="521" height="521" data-path="images/auto-instrumentation.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d087748854dbe051414c3f842f183af8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c86e6cc078f69e7585836db0561eae15 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c03cb732f67e320ac58efc3fd6001a66 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f91182e7070b80515e916f1401c40212 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6182199af22c75f77a02bdfb9a8d42d5 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b161da0f8c3c970e234e7574c0042951 2500w" />

Here we add Prisma and OpenAI instrumentations to your `trigger.config.ts` file.

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { PrismaInstrumentation } from "@prisma/instrumentation";
import { OpenAIInstrumentation } from "@traceloop/instrumentation-openai";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  telemetry: {
    instrumentations: [new PrismaInstrumentation(), new OpenAIInstrumentation()],
  },
});
```

There is a [huge library of instrumentations](https://opentelemetry.io/ecosystem/registry/?language=js) you can easily add to your project like this.

Some ones we recommend:

| Package                               | Description                                                                                                              |
| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| `@opentelemetry/instrumentation-http` | Logs all HTTP calls                                                                                                      |
| `@prisma/instrumentation`             | Logs all Prisma calls, you need to [enable tracing](https://github.com/prisma/prisma/tree/main/packages/instrumentation) |
| `@traceloop/instrumentation-openai`   | Logs all OpenAI calls                                                                                                    |

<Note>
  `@opentelemetry/instrumentation-fs` which logs all file system calls is currently not supported.
</Note>

### Telemetry Exporters

You can also configure custom telemetry exporters to send your traces and logs to other external services. For example, you can send your logs to [Axiom](https://axiom.co/docs/guides/opentelemetry-nodejs#exporter-instrumentation-ts). First, add the opentelemetry exporter packages to your package.json file:

```json package.json theme={null}
"dependencies": {
  "@opentelemetry/exporter-logs-otlp-http": "0.52.1",
  "@opentelemetry/exporter-trace-otlp-http": "0.52.1"
}
```

Then, configure the exporters in your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { OTLPTraceExporter } from "@opentelemetry/exporter-trace-otlp-http";
import { OTLPLogExporter } from "@opentelemetry/exporter-logs-otlp-http";

// Initialize OTLP trace exporter with the endpoint URL and headers;
export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  telemetry: {
    instrumentations: [
      // Your instrumentations here
    ],
    logExporters: [
      new OTLPLogExporter({
        url: "https://api.axiom.co/v1/logs",
        headers: {
          Authorization: `Bearer ${process.env.AXIOM_API_TOKEN}`,
          "X-Axiom-Dataset": process.env.AXIOM_DATASET,
        },
      }),
    ],
    exporters: [
      new OTLPTraceExporter({
        url: "https://api.axiom.co/v1/traces",
        headers: {
          Authorization: `Bearer ${process.env.AXIOM_API_TOKEN}`,
          "X-Axiom-Dataset": process.env.AXIOM_DATASET,
        },
      }),
    ],
  },
});
```

Make sure to set the `AXIOM_API_TOKEN` and `AXIOM_DATASET` environment variables in your project.

It's important to note that you cannot configure exporters using `OTEL_*` environment variables, as they would conflict with our internal telemetry. Instead you should configure the exporters via passing in arguments to the `OTLPTraceExporter` and `OTLPLogExporter` constructors. For example, here is how you can configure exporting to Honeycomb:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { OTLPTraceExporter } from "@opentelemetry/exporter-trace-otlp-http";
import { OTLPLogExporter } from "@opentelemetry/exporter-logs-otlp-http";

// Initialize OTLP trace exporter with the endpoint URL and headers;
export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  telemetry: {
    instrumentations: [
      // Your instrumentations here
    ],
    logExporters: [
      new OTLPLogExporter({
        url: "https://api.honeycomb.io/v1/logs",
        headers: {
          "x-honeycomb-team": process.env.HONEYCOMB_API_KEY,
          "x-honeycomb-dataset": process.env.HONEYCOMB_DATASET,
        },
      }),
    ],
    exporters: [
      new OTLPTraceExporter({
        url: "https://api.honeycomb.io/v1/traces",
        headers: {
          "x-honeycomb-team": process.env.HONEYCOMB_API_KEY,
          "x-honeycomb-dataset": process.env.HONEYCOMB_DATASET,
        },
      }),
    ],
  },
});
```

## Runtime

We currently only officially support the `node` runtime, but you can try our experimental `bun` runtime by setting the `runtime` option in your config file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  runtime: "bun",
});
```

See our [Bun guide](/guides/frameworks/bun) for more information.

### Node.js versions

Trigger.dev runs your tasks on specific Node.js versions:

### v3

* Node.js `21.7.3`

### v4

* Node.js `21.7.3` (default)
* Node.js `22.16.0` (`node-22`)
* Bun `1.2.20` (`bun`)

You can change the runtime by setting the `runtime` field in your `trigger.config.ts` file.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  // "node", "node-22" or "bun"
  runtime: "node-22",
  project: "<your-project-ref>",
});
```

## Default machine

You can specify the default machine for all tasks in your project:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  defaultMachine: "large-1x",
});
```

See our [machines documentation](/machines) for more information.

## Log level

You can set the log level for your project:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  logLevel: "debug",
});
```

The `logLevel` only determines which logs are sent to the Trigger.dev instance when using the `logger` API. All `console` based logs are always sent.

## Console logging

You can control console logging behavior in development:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  enableConsoleLogging: true, // Enable console logging while running dev CLI
  disableConsoleInterceptor: false, // Disable console interceptor (prevents logs from being sent to the trigger.dev dashboard)
});
```

## Max duration

You can set the default `maxDuration` for all tasks in your project:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  maxDuration: 60, // 60 seconds
});
```

See our [maxDuration guide](/runs/max-duration) for more information.

## Process keep alive

Keep the process alive after the task has finished running so the next task doesn't have to wait for the process to start up again.

Note that the process could be killed at any time, and we don't make any guarantees about the process being alive for a certain amount of time

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  processKeepAlive: true,
});
```

You can pass an object to the `processKeepAlive` option to configure the behavior:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  processKeepAlive: {
    enabled: true,
    // The maximum number of executions per process. If the process has run more than this number of times, it will be killed.
    maxExecutionsPerProcess: 50, // Default: 50
    // The maximum number of concurrent processes to keep alive in dev.
    devMaxPoolSize: 25, // Default: 25
  },
});
```

## Development behavior

You can control the working directory behavior in development:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  legacyDevProcessCwdBehaviour: false, // Default: true
});
```

When set to `false`, the current working directory will be set to the build directory, which more closely matches production behavior.

## CA certificates

CA Cert file to be added to NODE\_EXTRA\_CA\_CERT environment variable, useful in use with self signed cert in the trigger.dev environment.

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  // Must start with "./" and be relative to project root
  extraCACerts: "./certs/ca.crt",
});
```

## Build configuration

You can customize the build process using the `build` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // Don't bundle these packages
    external: ["header-generator"],
    // Automatically detect external dependencies (default: true)
    autoDetectExternal: true,
    // Keep function/class names in bundle (default: true)
    keepNames: true,
    // Minify generated code (default: false, experimental)
    minify: false,
  },
});
```

<Note>
  The `trigger.config.ts` file is included in the bundle, but with the `build` configuration
  stripped out. These means any imports only used inside the `build` configuration are also removed
  from the final bundle.
</Note>

### External

All code is bundled by default, but you can exclude some packages from the bundle using the `external` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    external: ["header-generator"],
  },
});
```

When a package is excluded from the bundle, it will be added to a dynamically generated package.json file in the build directory. The version of the package will be the same as the version found in your `node_modules` directory.

Each entry in the external should be a package name, not necessarily the import path. For example, if you want to exclude the `ai` package, but you are importing `ai/rsc`, you should just include `ai` in the `external` array:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    external: ["ai"],
  },
});
```

<Note>
  Any packages that install or build a native binary should be added to external, as native binaries
  cannot be bundled. For example, `re2`, `sharp`, and `sqlite3` should be added to external.
</Note>

### JSX

You can customize the `jsx` options that are passed to `esbuild` using the `jsx` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    jsx: {
      // Use the Fragment component instead of React.Fragment
      fragment: "Fragment",
      // Use the h function instead of React.createElement
      factory: "h",
      // Turn off automatic runtime
      automatic: false,
    },
  },
});
```

By default we enabled [esbuild's automatic JSX runtime](https://esbuild.github.io/content-types/#auto-import-for-jsx) which means you don't need to import `React` in your JSX files. You can disable this by setting `automatic` to `false`.

See the [esbuild JSX documentation](https://esbuild.github.io/content-types/#jsx) for more information.

### Conditions

You can add custom [import conditions](https://esbuild.github.io/api/#conditions) to your build using the `conditions` option:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    conditions: ["react-server"],
  },
});
```

These conditions effect how imports are resolved during the build process. For example, the `react-server` condition will resolve `ai/rsc` to the server version of the `ai/rsc` export.

Custom conditions will also be passed to the `node` runtime when running your tasks.

### Extensions

Build extension allow you to hook into the build system and customize the build process or the resulting bundle and container image (in the case of deploying). You can use pre-built extensions by installing the `@trigger.dev/build` package into your `devDependencies`, or you can create your own.

#### additionalFiles

See the [additionalFiles documentation](/config/extensions/additionalFiles) for more information.

#### `additionalPackages`

See the [additionalPackages documentation](/config/extensions/additionalPackages) for more information.

#### `emitDecoratorMetadata`

See the [emitDecoratorMetadata documentation](/config/extensions/emitDecoratorMetadata) for more information.

#### Prisma

See the [prismaExtension documentation](/config/extensions/prismaExtension) for more information.

#### syncEnvVars

See the [syncEnvVars documentation](/config/extensions/syncEnvVars) for more information.

#### puppeteer

See the [puppeteer documentation](/config/extensions/puppeteer) for more information.

#### ffmpeg

See the [ffmpeg documentation](/config/extensions/ffmpeg) for more information.

#### esbuild plugins

See the [esbuild plugins documentation](/config/extensions/esbuildPlugin) for more information.

#### aptGet

See the [aptGet documentation](/config/extensions/aptGet) for more information.


# Additional Files
Source: https://trigger.dev/docs/config/extensions/additionalFiles

Use the additionalFiles build extension to copy additional files to the build directory

Import the `additionalFiles` build extension and use it in your `trigger.config.ts` file:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { additionalFiles } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  // We strongly recommend setting this to false
  // When set to `false`, the current working directory will be set to the build directory, which more closely matches production behavior.
  legacyDevProcessCwdBehaviour: false, // Default: true
  build: {
    extensions: [additionalFiles({ files: ["./assets/**", "wrangler/wrangler.toml"] })],
  },
});
```

This will copy the files specified in the `files` array to the build directory. The `files` array can contain globs. The output paths will match the path of the file, relative to the root of the project.

This extension effects both the `dev` and the `deploy` commands, and the resulting paths will be the same for both.

If you use `legacyDevProcessCwdBehaviour: false`, you can then do this:

```ts  theme={null}
import path from "node:path";

// You can use `process.cwd()` if you use `legacyDevProcessCwdBehaviour: false`
const interRegularFont = path.join(process.cwd(), "assets/Inter-Regular.ttf");
```

<Note>The root of the project is the directory that contains the trigger.config.ts file</Note>


# Additional Packages
Source: https://trigger.dev/docs/config/extensions/additionalPackages

Use the additionalPackages build extension to include additional packages in the build

Import the `additionalPackages` build extension and use it in your `trigger.config.ts` file:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { additionalPackages } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [additionalPackages({ packages: ["wrangler"] })],
  },
});
```

This allows you to include additional packages in the build that are not automatically included via imports. This is useful if you want to install a package that includes a CLI tool that you want to invoke in your tasks via `exec`. We will try to automatically resolve the version of the package but you can specify the version by using the `@` symbol:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [additionalPackages({ packages: ["wrangler@1.19.0"] })],
  },
});
```

This extension does not do anything in `dev` mode, but it will install the packages in the build directory when you run `deploy`. The packages will be installed in the `node_modules` directory in the build directory.


# apt-get
Source: https://trigger.dev/docs/config/extensions/aptGet

Use the aptGet build extension to install system packages into the deployed image

You can install system packages into the deployed image using the `aptGet` extension:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { aptGet } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [aptGet({ packages: ["ffmpeg"] })],
  },
});
```

If you want to install a specific version of a package, you can specify the version like this:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [aptGet({ packages: ["ffmpeg=6.0-4"] })],
  },
});
```


# Audio Waveform
Source: https://trigger.dev/docs/config/extensions/audioWaveform

Use the audioWaveform build extension to add support for Audio Waveform in your project

Previously, we installed [Audio Waveform](https://github.com/bbc/audiowaveform) in the build image. That's been moved to a build extension:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { audioWaveform } from "@trigger.dev/build/extensions/audioWaveform";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [audioWaveform()], // uses verson 1.1.0 of audiowaveform by default
  },
});
```


# Custom build extensions
Source: https://trigger.dev/docs/config/extensions/custom

Customize how your project is built and deployed to Trigger.dev with your own custom build extensions

Build extensions allow you to hook into the build system and customize the build process or the resulting bundle and container image (in the case of deploying). See our [build extension overview](/config/extensions/overview) for more information on how to install and use our built-in extensions. Build extensions can do the following:

* Add additional files to the build
* Add dependencies to the list of externals
* Add esbuild plugins
* Add additional npm dependencies
* Add additional system packages to the image build container
* Add commands to run in the image build container
* Add environment variables to the image build container
* Sync environment variables to your Trigger.dev project

## Creating a build extension

Build extensions are added to your `trigger.config.ts` file, with a required `name` and optional build hook functions. Here's a simple example of a build extension that just logs a message when the build starts:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildStart: async (context) => {
          console.log("Build starting!");
        },
      },
    ],
  },
});
```

You can also extract that out into a function instead of defining it inline, in which case you will need to import the `BuildExtension` type from the `@trigger.dev/build` package:

<Note>
  You'll need to add the `@trigger.dev/build` package to your `devDependencies` before the below
  code will work. Make sure it's version matches that of the installed `@trigger.dev/sdk` package.
</Note>

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { BuildExtension } from "@trigger.dev/build";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [myExtension()],
  },
});

function myExtension(): BuildExtension {
  return {
    name: "my-extension",
    onBuildStart: async (context) => {
      console.log("Build starting!");
    },
  };
}
```

## Build hooks

### externalsForTarget

This allows the extension to add additional dependencies to the list of externals for the build. This is useful for dependencies that are not included in the bundle, but are expected to be available at runtime.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        externalsForTarget: async (target) => {
          return ["my-dependency"];
        },
      },
    ],
  },
});
```

### onBuildStart

This hook runs before the build starts. It receives the `BuildContext` object as an argument.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildStart: async (context) => {
          console.log("Build starting!");
        },
      },
    ],
  },
});
```

If you want to add an esbuild plugin, you must do so in the `onBuildStart` hook. Here's an example of adding a custom esbuild plugin:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildStart: async (context) => {
          context.registerPlugin({
            name: "my-plugin",
            setup(build) {
              build.onLoad({ filter: /.*/, namespace: "file" }, async (args) => {
                return {
                  contents: "console.log('Hello, world!')",
                  loader: "js",
                };
              });
            },
          });
        },
      },
    ],
  },
});
```

You can use the `BuildContext.target` property to determine if the build is for `dev` or `deploy`:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildStart: async (context) => {
          if (context.target === "dev") {
            console.log("Building for dev");
          } else {
            console.log("Building for deploy");
          }
        },
      },
    ],
  },
});
```

### onBuildComplete

This hook runs after the build completes. It receives the `BuildContext` object and a `BuildManifest` object as arguments. This is where you can add in one or more `BuildLayer`'s to the context.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildComplete: async (context, manifest) => {
          context.addLayer({
            id: "more-dependencies",
            dependencies,
          });
        },
      },
    ],
  },
});
```

See the [addLayer](#addlayer) documentation for more information on how to use `addLayer`.

## BuildTarget

Can either be `dev` or `deploy`, matching the CLI command name that is being run.

```sh  theme={null}
npx trigger.dev@latest dev # BuildTarget is "dev"
npx trigger.dev@latest deploy # BuildTarget is "deploy"
```

## BuildContext

### addLayer()

<ParamField path="layer" type="BuildLayer">
  The layer to add to the build context. See the [BuildLayer](#buildlayer) documentation for more
  information.
</ParamField>

### registerPlugin()

<ParamField path="plugin" type="esbuild.Plugin" required>
  The esbuild plugin to register.
</ParamField>

<ParamField path="options" type="object">
  <Expandable title="properties">
    <ResponseField name="target" type="BuildTarget">
      An optional target to register the plugin for. If not provided, the plugin will be registered
      for all targets.
    </ResponseField>

    <ResponseField name="placement" type="first | last">
      An optional placement for the plugin. If not provided, the plugin will be registered in place.
      This allows you to control the order of plugins.
    </ResponseField>
  </Expandable>
</ParamField>

### resolvePath()

Resolves a path relative to the project's working directory.

<ParamField path="path" type="string">
  The path to resolve.
</ParamField>

```ts  theme={null}
const resolvedPath = context.resolvePath("my-other-dependency");
```

### properties

<ParamField path="target" type="BuildTarget">
  The target of the build, either `dev` or `deploy`.
</ParamField>

<ParamField path="config" type="ResolvedConfig">
  <Expandable title="properties">
    <ResponseField name="runtime" type="string">
      The runtime of the project (either node or bun)
    </ResponseField>

    <ResponseField name="project" type="string">
      The project ref
    </ResponseField>

    <ResponseField name="dirs" type="string[]">
      The trigger directories to search for tasks
    </ResponseField>

    <ResponseField name="build" type="object">
      The build configuration object
    </ResponseField>

    <ResponseField name="workingDir" type="string">
      The working directory of the project
    </ResponseField>

    <ResponseField name="workspaceDir" type="string">
      The root workspace directory of the project
    </ResponseField>

    <ResponseField name="packageJsonPath" type="string">
      The path to the package.json file
    </ResponseField>

    <ResponseField name="lockfilePath" type="string">
      The path to the lockfile (package-lock.json, yarn.lock, or pnpm-lock.yaml)
    </ResponseField>

    <ResponseField name="configFile" type="string">
      The path to the trigger.config.ts file
    </ResponseField>

    <ResponseField name="tsconfigPath" type="string">
      The path to the tsconfig.json file
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField path="logger" type="BuildLogger">
  A logger object that can be used to log messages to the console.
</ParamField>

## BuildLayer

<ParamField path="id" type="string">
  A unique identifier for the layer.
</ParamField>

<ParamField path="commands" type="string[]">
  An array of commands to run in the image build container.

  ```ts  theme={null}
  commands: ["echo 'Hello, world!'"];
  ```

  These commands are run after packages have been installed and the code copied into the container in the "build" stage of the Dockerfile. This means you cannot install system packages in these commands because they won't be available in the final stage. To do that, please use the `pkgs` property of the `image` object.
</ParamField>

<ParamField path="image" type="object">
  <Expandable title="properties">
    <ResponseField name="pkgs" type="string[]">
      An array of system packages to install in the image build container.
    </ResponseField>

    <ResponseField name="instructions" type="string[]">
      An array of instructions to add to the Dockerfile.
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField path="build" type="object">
  <Expandable title="properties">
    <ResponseField name="env" type="Record<string, string>">
      Environment variables to add to the image build container, but only during the "build" stage
      of the Dockerfile. This is where you'd put environment variables that are needed when running
      any of the commands in the `commands` array.
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField path="deploy" type="object">
  <Expandable title="properties">
    <ResponseField name="env" type="Record<string, string>">
      Environment variables that should sync to the Trigger.dev project, which will then be avalable
      in your tasks at runtime. Importantly, these are NOT added to the image build container, but
      are instead added to the Trigger.dev project and stored securely.
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField path="dependencies" type="Record<string, string>">
  An object of dependencies to add to the build. The key is the package name and the value is the
  version.

  ```ts  theme={null}
  dependencies: {
    "my-dependency": "^1.0.0",
  };
  ```
</ParamField>

### examples

Add a command that will echo the value of an environment variable:

```ts  theme={null}
context.addLayer({
  id: "my-layer",
  commands: [`echo $MY_ENV_VAR`],
  build: {
    env: {
      MY_ENV_VAR: "Hello, world!",
    },
  },
});
```

## Troubleshooting

When creating a build extension, you may run into issues with the build process. One thing that can help is turning on `debug` logging when running either `dev` or `deploy`:

```sh  theme={null}
npx trigger.dev@latest dev --log-level debug
npx trigger.dev@latest deploy --log-level debug
```

Another helpful tool is the `--dry-run` flag on the `deploy` command, which will bundle your project and generate the Containerfile (e.g. the Dockerfile) without actually deploying it. This can help you see what the final image will look like and debug any issues with the build process.

```sh  theme={null}
npx trigger.dev@latest deploy --dry-run
```

You should also take a look at our built in extensions for inspiration on how to create your own. You can find them in in [the source code here](https://github.com/triggerdotdev/trigger.dev/tree/main/packages/build/src/extensions).


# Emit Decorator Metadata
Source: https://trigger.dev/docs/config/extensions/emitDecoratorMetadata

Use the emitDecoratorMetadata build extension to enable support for the emitDecoratorMetadata TypeScript compiler option

If you need support for the `emitDecoratorMetadata` typescript compiler option, import the `emitDecoratorMetadata` build extension and use it in your `trigger.config.ts` file:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { emitDecoratorMetadata } from "@trigger.dev/build/extensions/typescript";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [emitDecoratorMetadata()],
  },
});
```

This is usually required if you are using certain ORMs, like TypeORM, that require this option to be enabled. It's not enabled by default because there is a performance cost to enabling it.

<Note>
  emitDecoratorMetadata works by hooking into the esbuild bundle process and using the TypeScript
  compiler API to compile files where we detect the use of decorators. This means you must have
  `emitDecoratorMetadata` enabled in your `tsconfig.json` file, as well as `typescript` installed in
  your `devDependencies`.
</Note>


# esbuild Plugin
Source: https://trigger.dev/docs/config/extensions/esbuildPlugin

Use the esbuildPlugin build extension to add existing or custom esbuild plugins to your build process

You can easily add existing or custom esbuild plugins to your build process using the `esbuildPlugin` extension:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { esbuildPlugin } from "@trigger.dev/build/extensions";
import { sentryEsbuildPlugin } from "@sentry/esbuild-plugin";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      esbuildPlugin(
        sentryEsbuildPlugin({
          org: process.env.SENTRY_ORG,
          project: process.env.SENTRY_PROJECT,
          authToken: process.env.SENTRY_AUTH_TOKEN,
        }),
        // optional - only runs during the deploy command, and adds the plugin to the end of the list of plugins
        { placement: "last", target: "deploy" }
      ),
    ],
  },
});
```


# FFmpeg
Source: https://trigger.dev/docs/config/extensions/ffmpeg

Use the ffmpeg build extension to include FFmpeg in your project

You can add the `ffmpeg` build extension to your build process:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { ffmpeg } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [ffmpeg()],
  },
});
```

By default, this will install the version of `ffmpeg` that is available in the Debian package manager (via `apt`).

## FFmpeg 7.x (static build)

If you need FFmpeg 7.x, you can pass `{ version: "7" }` to the extension. This will install a static build of FFmpeg 7.x instead of using the Debian package:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { ffmpeg } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [ffmpeg({ version: "7" })],
  },
});
```

This extension will also add the `FFMPEG_PATH` and `FFPROBE_PATH` to your environment variables, making it easy to use popular ffmpeg libraries like `fluent-ffmpeg`.

Note that `fluent-ffmpeg` needs to be added to [`external`](/config/config-file#external) in your `trigger.config.ts` file.

Follow [this example](/guides/examples/ffmpeg-video-processing) to get setup with Trigger.dev and FFmpeg in your project.


# Lightpanda
Source: https://trigger.dev/docs/config/extensions/lightpanda

Use the lightpanda build extension to add Lightpanda browser to your project

To use the Lightpanda browser in your project, add the extension to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { lightpanda } from "@trigger.dev/build/extensions/lightpanda";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [lightpanda()],
  },
});
```

## Options

* `version`: The version of the browser to install. Default: `"latest"`.
* `disableTelemetry`: Whether to disable telemetry. Default: `false`.

For example:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { lightpanda } from "@trigger.dev/build/extensions/lightpanda";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      lightpanda({
        version: "nightly",
        disableTelemetry: true,
      }),
    ],
  },
});
```

## Development

When running in dev, you will first have to download the Lightpanda browser binary and make sure it's in your `PATH`. See [Lightpanda's installation guide](https://lightpanda.io/docs/getting-started/installation).

## Next steps

<CardGroup>
  <Card title="Lightpanda" color="#6ac6e2" icon="bolt" href="/guides/examples/lightpanda">
    Learn how to use Lightpanda in your project.
  </Card>
</CardGroup>


# Build extensions
Source: https://trigger.dev/docs/config/extensions/overview

Customize how your project is built and deployed to Trigger.dev with build extensions

Build extensions allow you to hook into the build system and customize the build process or the resulting bundle and container image (in the case of deploying).

You can use pre-built extensions by installing the `@trigger.dev/build` package into your `devDependencies`, or you can create your own.

Build extensions are added to your `trigger.config.ts` file under the `build.extensions` property:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [
      {
        name: "my-extension",
        onBuildStart: async (context) => {
          console.log("Build starting!");
        },
      },
    ],
  },
});
```

If you are using a pre-built extension, you can import it from the `@trigger.dev/build` package:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { ffmpeg } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "my-project",
  build: {
    extensions: [ffmpeg()],
  },
});
```

## Built-in extensions

Trigger.dev provides a set of built-in extensions that you can use to customize how your project is built and deployed. These extensions are available out of the box and can be configured in your `trigger.config.ts` file.

| Extension                                                             | Description                                                                    |
| :-------------------------------------------------------------------- | :----------------------------------------------------------------------------- |
| [prismaExtension](/config/extensions/prismaExtension)                 | Using prisma in your Trigger.dev tasks                                         |
| [pythonExtension](/config/extensions/pythonExtension)                 | Execute Python scripts in your project                                         |
| [puppeteer](/config/extensions/puppeteer)                             | Use Puppeteer in your Trigger.dev tasks                                        |
| [ffmpeg](/config/extensions/ffmpeg)                                   | Use FFmpeg in your Trigger.dev tasks                                           |
| [aptGet](/config/extensions/aptGet)                                   | Install system packages in your build image                                    |
| [additionalFiles](/config/extensions/additionalFiles)                 | Copy additional files to your build image                                      |
| [additionalPackages](/config/extensions/additionalPackages)           | Install additional npm packages in your build image                            |
| [syncEnvVars](/config/extensions/syncEnvVars)                         | Automatically sync environment variables from external services to Trigger.dev |
| [syncVercelEnvVars](/config/extensions/syncEnvVars#syncVercelEnvVars) | Automatically sync environment variables from Vercel to Trigger.dev            |
| [esbuildPlugin](/config/extensions/esbuildPlugin)                     | Add existing or custom esbuild extensions to customize your build process      |
| [emitDecoratorMetadata](/config/extensions/emitDecoratorMetadata)     | Enable `emitDecoratorMetadata` in your TypeScript build                        |
| [audioWaveform](/config/extensions/audioWaveform)                     | Add Audio Waveform to your build image                                         |

## Custom extensions

If one of the built-in extensions doesn't meet your needs, you can create your own custom extension. See our [guide on creating custom build extensions](/config/extensions/custom) for more information.


# Playwright
Source: https://trigger.dev/docs/config/extensions/playwright

Use the playwright build extension to use Playwright with Trigger.dev

If you are using [Playwright](https://playwright.dev/), you should use the Playwright build extension.

* Automatically installs Playwright and required browser dependencies
* Allows you to specify which browsers to install (chromium, firefox, webkit)
* Supports headless or non-headless mode
* Lets you specify the Playwright version, or auto-detects it
* Installs only the dependencies needed for the selected browsers to optimize build time and image size

<Note>
  This extension only affects the build and deploy process, not the `dev` command.
</Note>

You can use it for a simple Playwright setup like this:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { playwright } from "@trigger.dev/build/extensions/playwright";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      playwright(),
    ],
  },
});
```

### Options

* `browsers`: Array of browsers to install. Valid values: `"chromium"`, `"firefox"`, `"webkit"`. Default: `["chromium"]`.
* `headless`: Run browsers in headless mode. Default: `true`. If set to `false`, a virtual display (Xvfb) will be set up automatically.
* `version`: Playwright version to install. If not provided, the version will be auto-detected from your dependencies (recommended).

  <Warning>
    Using a different version in your app than specified here will break things. We recommend not setting this option to automatically detect the version.
  </Warning>

### Custom browsers and version

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { playwright } from "@trigger.dev/build/extensions/playwright";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      playwright({
        browsers: ["chromium", "webkit"], // optional, will use ["chromium"] if not provided
        version: "1.43.1",  // optional, will automatically detect the version if not provided
      }),
    ],
  },
});
```

### Headless mode

By default, browsers are run in headless mode. If you need to run browsers with a UI (for example, for debugging), set `headless: false`. This will automatically set up a virtual display using Xvfb.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { playwright } from "@trigger.dev/build/extensions/playwright";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      playwright({
        headless: false,
      }),
    ],
  },
});
```

### Environment variables

The extension sets the following environment variables during the build:

* `PLAYWRIGHT_BROWSERS_PATH`: Set to `/ms-playwright` so Playwright finds the installed browsers
* `PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD`: Set to `1` to skip browser download at runtime
* `PLAYWRIGHT_SKIP_BROWSER_VALIDATION`: Set to `1` to skip browser validation at runtime
* `DISPLAY`: Set to `:99` if `headless: false` (for Xvfb)

## Managing browser instances

To prevent issues with waits and resumes, you can use middleware and locals to manage the browser instance. This will ensure the browser is available for the whole run, and is properly cleaned up on waits, resumes, and after the run completes.

Here's an example using `chromium`, but you can adapt it for other browsers:

```ts  theme={null}
import { logger, tasks, locals } from "@trigger.dev/sdk";
import { chromium, type Browser } from "playwright";

// Create a locals key for the browser instance
const PlaywrightBrowserLocal = locals.create<{ browser: Browser }>("playwright-browser");

export function getBrowser() {
  return locals.getOrThrow(PlaywrightBrowserLocal).browser;
}

export function setBrowser(browser: Browser) {
  locals.set(PlaywrightBrowserLocal, { browser });
}

tasks.middleware("playwright-browser", async ({ next }) => {
  // Launch the browser before the task runs
  const browser = await chromium.launch();
  setBrowser(browser);
  logger.log("[chromium]: Browser launched (middleware)");

  try {
    await next();
  } finally {
    // Always close the browser after the task completes
    await browser.close();
    logger.log("[chromium]: Browser closed (middleware)");
  }
});

tasks.onWait("playwright-browser", async () => {
  // Close the browser when the run is waiting
  const browser = getBrowser();
  await browser.close();
  logger.log("[chromium]: Browser closed (onWait)");
});

tasks.onResume("playwright-browser", async () => {
  // Relaunch the browser when the run resumes
  // Note: You will have to have to manually get a new browser instance in the run function
  const browser = await chromium.launch();
  setBrowser(browser);
  logger.log("[chromium]: Browser launched (onResume)");
});
```

You can then use `getBrowser()` in your task's `run` function to access the browser instance:

```ts  theme={null}
export const playwrightTestTask = task({
  id: "playwright-test",
  run: async () => {
    const browser = getBrowser();
    const page = await browser.newPage();
    await page.goto("https://google.com");
    await page.screenshot({ path: "screenshot.png" });
    await page.close();

    // Waits will gracefully close the browser
    await wait.for({ seconds: 10 });

    // On resume, we will re-launch the browser but you will have to manually get the new instance
    const newBrowser = getBrowser();
    const newPage = await newBrowser.newPage();
    await newPage.goto("https://playwright.dev");
    await newPage.screenshot({ path: "screenshot2.png" });
    await newPage.close();
  },
});
```


# Prisma
Source: https://trigger.dev/docs/config/extensions/prismaExtension

Use the prismaExtension build extension to use Prisma with Trigger.dev

If you are using Prisma, you should use the prisma build extension.

* Automatically handles copying Prisma files to the build directory
* Generates the Prisma client during the deploy process
* Optionally will migrate the database during the deploy process
* Support for TypedSQL and multiple schema files
* You can use `prismaSchemaFolder` to specify just the directory containing your schema file, instead of the full path
* You can add the extension twice if you have multiple separate schemas in the same project (example below)

You can use it for a simple Prisma setup like this:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { prismaExtension } from "@trigger.dev/build/extensions/prisma";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      prismaExtension({
        version: "5.19.0", // optional, we'll automatically detect the version if not provided
        schema: "prisma/schema.prisma",
      }),
    ],
  },
});
```

<Note>
  This does not have any effect when running the `dev` command, only when running the `deploy`
  command.
</Note>

### Migrations

If you want to also run migrations during the build process, you can pass in the `migrate` option:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { prismaExtension } from "@trigger.dev/build/extensions/prisma";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      prismaExtension({
        schema: "prisma/schema.prisma",
        migrate: true,
        directUrlEnvVarName: "DATABASE_URL_UNPOOLED", // optional - the name of the environment variable that contains the direct database URL if you are using a direct database URL
      }),
    ],
  },
});
```

### clientGenerator

If you have multiple `generator` statements defined in your schema file, you can pass in the `clientGenerator` option to specify the `prisma-client-js` generator, which will prevent other generators from being generated. Some examples where you may need to do this include when using the `prisma-kysely` or `prisma-json-types-generator` generators.

<CodeGroup>
  ```prisma schema.prisma theme={null}
  datasource db {
    provider  = "postgresql"
    url       = env("DATABASE_URL")
    directUrl = env("DATABASE_URL_UNPOOLED")
  }

  // We only want to generate the prisma-client-js generator
  generator client {
    provider        = "prisma-client-js"
  }

  generator kysely {
    provider     = "prisma-kysely"
    output       = "../../src/kysely"
    enumFileName = "enums.ts"
    fileName     = "types.ts"
  }

  generator json {
    provider = "prisma-json-types-generator"
  }
  ```

  ```ts trigger.config.ts theme={null}
  import { defineConfig } from "@trigger.dev/sdk";
  import { prismaExtension } from "@trigger.dev/build/extensions/prisma";

  export default defineConfig({
    project: "<project ref>",
    // Your other config settings...
    build: {
      extensions: [
        prismaExtension({
          schema: "prisma/schema.prisma",
          clientGenerator: "client",
        }),
      ],
    },
  });
  ```
</CodeGroup>

### TypedSQL

If you are using [TypedSQL](https://www.prisma.io/typedsql), you'll need to enable it via the `typedSql` option:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      prismaExtension({
        schema: "prisma/schema.prisma",
        typedSql: true,
      }),
    ],
  },
});
```

<Note>
  The `prismaExtension` will inject the `DATABASE_URL` environment variable into the build process. Learn more about setting environment variables for deploying in our [Environment Variables](/deploy-environment-variables) guide.

  These environment variables are only used during the build process and are not embedded in the final container image.

  If you're experiencing database connection issues during deployment, you may need to add `?connection_limit=1` to your `DATABASE_URL` to limit the number of concurrent connections during the build process.
</Note>

### Using with Supabase Supavisor

When using Prisma with Supabase's Supavisor pooler, use a pooled URL for Prisma Client and a session/direct URL for schema operations to avoid prepared statement conflicts. As of Feb 28, 2025, port 6543 runs Transaction Mode only; use port 5432 for Session Mode.

```ts  theme={null}
prismaExtension({
  schema: "prisma/schema.prisma",
  directUrlEnvVarName: "DATABASE_URL_UNPOOLED",
}),
```

```bash  theme={null}
# Environment variables
# Pooled (Transaction Mode, port 6543)
DATABASE_URL="postgresql://postgres.[PROJECT_REF]:<PASSWORD>@aws-0-[REGION].pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1"
# Session/Direct (used by Prisma schema engine, port 5432)
DATABASE_URL_UNPOOLED="postgresql://postgres.[PROJECT_REF]:<PASSWORD>@aws-0-[REGION].pooler.supabase.com:5432/postgres"
```

<Note>
  Use the pooled connection (port 6543, Transaction Mode) for regular Prisma Client queries. Use the
  session/direct connection (port 5432, Session Mode) for migrations and other schema operations.
</Note>

### Multiple schemas

If you have multiple separate schemas in the same project you can add the extension multiple times:

```ts  theme={null}
prismaExtension({
  schema: 'prisma/schema/main.prisma',
  version: '6.2.0',
  migrate: false,
}),
prismaExtension({
  schema: 'prisma/schema/secondary.prisma',
  version: '6.2.0',
  migrate: false,
}),
```


# Puppeteer
Source: https://trigger.dev/docs/config/extensions/puppeteer

Use the puppeteer build extension to enable support for Puppeteer in your project

<ScrapingWarning />

To use Puppeteer in your project, add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { puppeteer } from "@trigger.dev/build/extensions/puppeteer";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [puppeteer()],
  },
});
```

And add the following environment variable in your Trigger.dev dashboard on the Environment Variables page:

```bash  theme={null}
PUPPETEER_EXECUTABLE_PATH: "/usr/bin/google-chrome-stable",
```

Follow [this example](/guides/examples/puppeteer) to get setup with Trigger.dev and Puppeteer in your project.


# Python
Source: https://trigger.dev/docs/config/extensions/pythonExtension

Use the python build extension to add support for executing Python scripts in your project

If you need to execute Python scripts in your Trigger.dev project, you can use the `pythonExtension` build extension via the `@trigger.dev/python` package.

First, you'll need to install the `@trigger.dev/python` package:

```bash  theme={null}
npm add @trigger.dev/python
```

Then, you can use the `pythonExtension` build extension in your `trigger.config.ts` file:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { pythonExtension } from "@trigger.dev/python/extension";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [pythonExtension()],
  },
});
```

This will take care of adding python to the build image and setting up the necessary environment variables to execute Python scripts. You can then use our `python` utilities in the `@trigger.dev/python` package to execute Python scripts in your tasks. For example, running a Python script inline in a task:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";

export const myScript = task({
  id: "my-python-script",
  run: async () => {
    const result = await python.runInline(`print("Hello, world!")`);
    return result.stdout;
  },
});
```

## Adding python scripts

You can automatically add python scripts to your project using the `scripts` option in the `pythonExtension` function. This will copy the specified scripts to the build directory during the deploy process. For example:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { pythonExtension } from "@trigger.dev/python/extension";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      pythonExtension({
        scripts: ["./python/**/*.py"],
      }),
    ],
  },
});
```

This will copy all Python files in the `python` directory to the build directory during the deploy process. You can then execute these scripts using the `python.runScript` function:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";

export const myScript = task({
  id: "my-python-script",
  run: async () => {
    const result = await python.runScript("./python/my_script.py", ["hello", "world"]);
    return result.stdout;
  },
});
```

<Note>
  The pythonExtension will also take care of moving the scripts to the correct location during `dev`
  mode, so you can use the same exact path in development as you do in production.
</Note>

## Using requirements files

If you have a `requirements.txt` file in your project, you can use the `requirementsFile` option in the `pythonExtension` function to install the required packages during the build process. For example:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { pythonExtension } from "@trigger.dev/python/extension";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      pythonExtension({
        requirementsFile: "./requirements.txt",
      }),
    ],
  },
});
```

This will install the packages specified in the `requirements.txt` file during the build process. You can then use these packages in your Python scripts.

<Note>
  The `requirementsFile` option is only available in production mode. In development mode, you can
  install the required packages manually using the `pip` command.
</Note>

## Virtual environments

If you are using a virtual environment in your project, you can use the `devPythonBinaryPath` option in the `pythonExtension` function to specify the path to the Python binary in the virtual environment. For example:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { pythonExtension } from "@trigger.dev/python/extension";

export default defineConfig({
  project: "<project ref>",
  build: {
    extensions: [
      pythonExtension({
        devPythonBinaryPath: ".venv/bin/python",
      }),
    ],
  },
});
```

This has no effect in production mode, but in development mode, it will use the specified Python binary to execute Python scripts.

## Streaming output

All of the `python` functions have a streaming version that allows you to stream the output of the Python script as it runs. For example:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";

export const myStreamingScript = task({
  id: "my-streaming-python-script",
  run: async () => {
    // You don't need to await the result
    const result = python.stream.runScript("./python/my_script.py", ["hello", "world"]);

    // result is an async iterable/readable stream
    for await (const chunk of streamingResult) {
      console.log(chunk);
    }
  },
});
```

## Environment variables

We automatically inject the environment variables in the `process.env` object when running Python scripts. You can access these environment variables in your Python scripts using the `os.environ` dictionary. For example:

```python  theme={null}
import os

print(os.environ["MY_ENV_VAR"])
```

You can also pass additional environment variables to the Python script using the `env` option in the `python.runScript` function. For example:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";

export const myScript = task({
  id: "my-python-script",
  run: async () => {
    const result = await python.runScript("./python/my_script.py", ["hello", "world"], {
      env: {
        MY_ENV_VAR: "my value",
      },
    });
    return result.stdout;
  },
});
```


# Sync env vars
Source: https://trigger.dev/docs/config/extensions/syncEnvVars

Use the syncEnvVars build extension to automatically sync environment variables to Trigger.dev

The `syncEnvVars` build extension will sync env vars from another service into Trigger.dev before the deployment starts. This is useful if you are using a secret store service like Infisical or AWS Secrets Manager to store your secrets.

`syncEnvVars` takes an async callback function, and any env vars returned from the callback will be synced to Trigger.dev.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  build: {
    extensions: [
      syncEnvVars(async (ctx) => {
        return [
          { name: "SECRET_KEY", value: "secret-value" },
          { name: "ANOTHER_SECRET", value: "another-secret-value" },
        ];
      }),
    ],
  },
});
```

The callback is passed a context object with the following properties:

* `environment`: The environment name that the task is being deployed to (e.g. `production`, `staging`, etc.)
* `projectRef`: The project ref of the Trigger.dev project
* `env`: The environment variables that are currently set in the Trigger.dev project

### Example: Sync env vars from Infisical

In this example we're using env vars from [Infisical](https://infisical.com).

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncEnvVars } from "@trigger.dev/build/extensions/core";
import { InfisicalSDK } from "@infisical/sdk";

export default defineConfig({
  build: {
    extensions: [
      syncEnvVars(async (ctx) => {
        const client = new InfisicalSDK();

        await client.auth().universalAuth.login({
          clientId: process.env.INFISICAL_CLIENT_ID!,
          clientSecret: process.env.INFISICAL_CLIENT_SECRET!,
        });

        const { secrets } = await client.secrets().listSecrets({
          environment: ctx.environment,
          projectId: process.env.INFISICAL_PROJECT_ID!,
        });

        return secrets.map((secret) => ({
          name: secret.secretKey,
          value: secret.secretValue,
        }));
      }),
    ],
  },
});
```

### syncVercelEnvVars

The `syncVercelEnvVars` build extension syncs environment variables from your Vercel project to Trigger.dev.

<Note>
  You need to set the `VERCEL_ACCESS_TOKEN` and `VERCEL_PROJECT_ID` environment variables, or pass
  in the token and project ID as arguments to the `syncVercelEnvVars` build extension. If you're
  working with a team project, you'll also need to set `VERCEL_TEAM_ID`, which can be found in your
  team settings. You can find / generate the `VERCEL_ACCESS_TOKEN` in your Vercel
  [dashboard](https://vercel.com/account/settings/tokens). Make sure the scope of the token covers
  the project with the environment variables you want to sync.
</Note>

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncVercelEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // This will automatically use the VERCEL_ACCESS_TOKEN and VERCEL_PROJECT_ID environment variables
    extensions: [syncVercelEnvVars()],
  },
});
```

Or you can pass in the token and project ID as arguments:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncVercelEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      syncVercelEnvVars({
        projectId: "your-vercel-project-id",
        vercelAccessToken: "your-vercel-access-token",
        vercelTeamId: "your-vercel-team-id", // optional
      }),
    ],
  },
});
```


# Context
Source: https://trigger.dev/docs/context

Get the context of a task run.

Context (`ctx`) is a way to get information about a run.

<Note>
  The context object does not change whilst your code is executing. This means values like
  `ctx.run.durationMs` will be fixed at the moment the `run()` function is called.
</Note>

<RequestExample>
  ```typescript Context example theme={null}
  import { task } from "@trigger.dev/sdk";

  export const parentTask = task({
    id: "parent-task",
    run: async (payload: { message: string }, { ctx }) => {
      if (ctx.environment.type === "DEVELOPMENT") {
        return;
      }
    },
  });
  ```
</RequestExample>

## Context properties

<ResponseField name="task" type="object">
  <Expandable title="properties" defaultOpen={true}>
    <ResponseField name="exportName" type="string">
      The exported function name of the task e.g. `myTask` if you defined it like this: `export
            const myTask = task(...)`.
    </ResponseField>

    <ResponseField name="id" type="string">
      The ID of the task.
    </ResponseField>

    <ResponseField name="filePath" type="string">
      The file path of the task.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="attempt" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the execution attempt.
    </ResponseField>

    <ResponseField name="number" type="number">
      The attempt number.
    </ResponseField>

    <ResponseField name="startedAt" type="date">
      The start time of the attempt.
    </ResponseField>

    <ResponseField name="backgroundWorkerId" type="string">
      The ID of the background worker.
    </ResponseField>

    <ResponseField name="backgroundWorkerTaskId" type="string">
      The ID of the background worker task.
    </ResponseField>

    <ResponseField name="status" type="string">
      The current status of the attempt.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="run" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the task run.
    </ResponseField>

    <ResponseField name="context" type="any" optional>
      The context of the task run.
    </ResponseField>

    <ResponseField name="tags" type="array">
      An array of [tags](/tags) associated with the task run.
    </ResponseField>

    <ResponseField name="isTest" type="boolean">
      Whether this is a [test run](/run-tests).
    </ResponseField>

    <ResponseField name="createdAt" type="date">
      The creation time of the task run.
    </ResponseField>

    <ResponseField name="startedAt" type="date">
      The start time of the task run.
    </ResponseField>

    <ResponseField name="idempotencyKey" type="string" optional>
      An optional [idempotency key](/idempotency) for the task run.
    </ResponseField>

    <ResponseField name="maxAttempts" type="number" optional>
      The [maximum number of attempts](/triggering#maxattempts) allowed for this task run.
    </ResponseField>

    <ResponseField name="durationMs" type="number">
      The duration of the task run in milliseconds when the `run()` function is called. For live
      values use the [usage SDK functions](/run-usage).
    </ResponseField>

    <ResponseField name="costInCents" type="number">
      The cost of the task run in cents when the `run()` function is called. For live values use the
      [usage SDK functions](/run-usage).
    </ResponseField>

    <ResponseField name="baseCostInCents" type="number">
      The base cost of the task run in cents when the `run()` function is called. For live values
      use the [usage SDK functions](/run-usage).
    </ResponseField>

    <ResponseField name="version" type="string" optional>
      The [version](/versioning) of the task run.
    </ResponseField>

    <ResponseField name="maxDuration" type="number" optional>
      The [maximum allowed duration](/runs/max-duration) for the task run.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="queue" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the queue.
    </ResponseField>

    <ResponseField name="name" type="string">
      The name of the queue.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="environment" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the environment.
    </ResponseField>

    <ResponseField name="slug" type="string">
      The slug of the environment.
    </ResponseField>

    <ResponseField name="type" type="string">
      The type of the environment (PRODUCTION, STAGING, DEVELOPMENT, or PREVIEW).
    </ResponseField>

    <ResponseField name="branchName" type="string" optional>
      If the environment is `PREVIEW` then this will be the branch name.
    </ResponseField>

    <ResponseField name="git" type="object">
      <Expandable title="properties">
        <ResponseField name="commitAuthorName" type="string" optional>
          The name of the commit author.
        </ResponseField>

        <ResponseField name="commitMessage" type="string" optional>
          The message of the commit.
        </ResponseField>

        <ResponseField name="commitRef" type="string" optional>
          The ref of the commit.
        </ResponseField>

        <ResponseField name="commitSha" type="string" optional>
          The SHA of the commit.
        </ResponseField>

        <ResponseField name="dirty" type="boolean" optional>
          Whether the commit is dirty, i.e. there are uncommitted changes.
        </ResponseField>

        <ResponseField name="remoteUrl" type="string" optional>
          The remote URL of the repository.
        </ResponseField>

        <ResponseField name="pullRequestNumber" type="number" optional>
          The number of the pull request.
        </ResponseField>

        <ResponseField name="pullRequestTitle" type="string" optional>
          The title of the pull request.
        </ResponseField>

        <ResponseField name="pullRequestState" type="string" optional>
          The state of the pull request (open, closed, or merged).
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="organization" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the organization.
    </ResponseField>

    <ResponseField name="slug" type="string">
      The slug of the organization.
    </ResponseField>

    <ResponseField name="name" type="string">
      The name of the organization.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="project" type="object">
  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the project.
    </ResponseField>

    <ResponseField name="ref" type="string">
      The reference of the project.
    </ResponseField>

    <ResponseField name="slug" type="string">
      The slug of the project.
    </ResponseField>

    <ResponseField name="name" type="string">
      The name of the project.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="batch" type="object" optional>
  Optional information about the batch, if applicable.

  <Expandable title="properties">
    <ResponseField name="id" type="string">
      The ID of the batch.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="machine" type="object" optional>
  Optional information about the machine preset used for execution.

  <Expandable title="properties">
    <ResponseField name="name" type="string">
      The name of the machine preset.
    </ResponseField>

    <ResponseField name="cpu" type="number">
      The CPU allocation for the machine.
    </ResponseField>

    <ResponseField name="memory" type="number">
      The memory allocation for the machine.
    </ResponseField>

    <ResponseField name="centsPerMs" type="number">
      The cost in cents per millisecond for this machine preset.
    </ResponseField>
  </Expandable>
</ResponseField>


# Environment Variables
Source: https://trigger.dev/docs/deploy-environment-variables

Any environment variables used in your tasks need to be added so the deployed code will run successfully.

An environment variable in Node.js is accessed in your code using `process.env.MY_ENV_VAR`.

We deploy your tasks and scale them up and down when they are triggered. So any environment variables you use in your tasks need to accessible to us so your code will run successfully.

## In the dashboard

### Setting environment variables

<Steps>
  <Step title="Go to the Environment Variables page">
    In the sidebar select the "Environment Variables" page, then press the "New environment variable"
    button. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=af652254781808a35c2bcefd4b61b59f" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-page.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fd6487833d9c659f8a514c7cc86cf84d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1758721fd84f5040b88997db401f7391 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4416f51b1528ae14285a03b560f22389 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12b90b89f7662aadaea07df17d9d3898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28e6921620cda10d335a095dbfa85806 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4f6c67a030b20699bde25c22d68e57af 2500w" />
  </Step>

  <Step title="Add your environment variables">
    You can add values for your local dev environment, staging and prod. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79b5fd91e809cb0c6c9298410922df96" alt="Environment variables
    page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-panel.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4c3f6181dea5542157cdbdebafb44989 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0c302ef3d814a0c781b684e64d090f9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a110ee9bb119eaaf7404097904a1f442 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e774fb137908fbaaf28318d1bfa419d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aa5d4bef7b66551887043c4420807bc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed23a501677d11631bb832eb6f95ceae 2500w" />
  </Step>
</Steps>

<Note>
  Specifying Dev values is optional. They will be overriden by values in your .env file when running
  locally.
</Note>

### Editing environment variables

You can edit an environment variable's values. You cannot edit the key name, you must delete and create a new one.

<Steps>
  <Step title="Press the action button on a variable">
        <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05dd8ce39784065107f6eba1625866d0" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-actions.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fbed005dc7dcd0058a422838de4c0b9b 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7e7f70a3116af7bba9837b4f87a85637 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=00ef502fa21ec6d5b0ad1268844fca1f 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ead290a05e430dc69fa2cfdb2fa4217d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d769af16568cd23cbe1a7d6d5ed7c46e 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ce9fba7375a89774d6eb6fd3800ba2b9 2500w" />
  </Step>

  <Step title="Press edit">
        <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e865f9406555034430788bbf98fbc785" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-edit-popover.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f163d64590aa81c0cb6d74c3c7f94a2a 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0a7d79db13a818c545764a658c81aba8 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=dbe05ce74ce05ae3100b8520f24a48e1 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c0660d9ee4369bd8bdf4e7c5b9849258 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b030c985d2733fc8b6ae7bdcb6577688 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-edit-popover.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a56b25cb17ed5da98f82f0ede3e1b14f 2500w" />
  </Step>
</Steps>

### Deleting environment variables

<Warn>
  Environment variables are fetched and injected before a runs begins. So if you delete one you can
  cause runs to fail that are expecting variables to be set.
</Warn>

<Steps>
  <Step title="Press the action button on a variable">
        <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05dd8ce39784065107f6eba1625866d0" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-actions.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fbed005dc7dcd0058a422838de4c0b9b 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7e7f70a3116af7bba9837b4f87a85637 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=00ef502fa21ec6d5b0ad1268844fca1f 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ead290a05e430dc69fa2cfdb2fa4217d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d769af16568cd23cbe1a7d6d5ed7c46e 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-actions.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ce9fba7375a89774d6eb6fd3800ba2b9 2500w" />
  </Step>

  <Step title="Press delete">
    This will immediately delete the variable. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=642350946bd75c3c508065a198aaa005" alt="Environment variables
    page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-delete-popover.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9f4d42ee9719adbb6c6850c63839e6a2 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8ec32e6dffaa55bc7baabeec69610136 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=42771e6c5b67013d13dbb23a84f37754 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=59a6c0bf701def1f80311e61916d481d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2b0182cb34138fc9beda364b95de7f68 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-delete-popover.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5564d5157938fad70bbb0bed5cbd7ad7 2500w" />
  </Step>
</Steps>

## In your code

You can use our SDK to get and manipulate environment variables. You can also easily sync environment variables from another service into Trigger.dev.

### Directly manipulating environment variables

We have a complete set of SDK functions (and REST API) you can use to directly manipulate environment variables.

| Function                                           | Description                                                 |
| -------------------------------------------------- | ----------------------------------------------------------- |
| [envvars.list()](/management/envvars/list)         | List all environment variables                              |
| [envvars.upload()](/management/envvars/import)     | Upload multiple env vars. You can override existing values. |
| [envvars.create()](/management/envvars/create)     | Create a new environment variable                           |
| [envvars.retrieve()](/management/envvars/retrieve) | Retrieve an environment variable                            |
| [envvars.update()](/management/envvars/update)     | Update a single environment variable                        |
| [envvars.del()](/management/envvars/delete)        | Delete a single environment variable                        |

### Sync env vars from another service

You could use the SDK functions above but it's much easier to use our `syncEnvVars` build extension in your `trigger.config` file.

<Note>
  To use the `syncEnvVars` build extension, you should first install the `@trigger.dev/build`
  package into your devDependencies.
</Note>

In this example we're using env vars from [Infisical](https://infisical.com).

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncEnvVars } from "@trigger.dev/build/extensions/core";
import { InfisicalSDK } from "@infisical/sdk";

export default defineConfig({
  build: {
    extensions: [
      syncEnvVars(async (ctx) => {
        const client = new InfisicalSDK();

        await client.auth().universalAuth.login({
          clientId: process.env.INFISICAL_CLIENT_ID!,
          clientSecret: process.env.INFISICAL_CLIENT_SECRET!,
        });

        const { secrets } = await client.secrets().listSecrets({
          environment: ctx.environment,
          projectId: process.env.INFISICAL_PROJECT_ID!,
        });

        return secrets.map((secret) => ({
          name: secret.secretKey,
          value: secret.secretValue,
        }));
      }),
    ],
  },
});
```

#### Syncing environment variables from Vercel

To sync environment variables from your Vercel projects to Trigger.dev, you can use our build extension. Check out our [syncing environment variables from Vercel guide](/guides/examples/vercel-sync-env-vars).

#### Deploy

When you run the [CLI deploy command](/cli-deploy) directly or using [GitHub Actions](/github-actions) it will sync the environment variables from [Infisical](https://infisical.com) to Trigger.dev. This means they'll appear on the Environment Variables page so you can confirm that it's worked.

This means that you need to redeploy your Trigger.dev tasks if you change the environment variables in [Infisical](https://infisical.com).

<Note>
  The `process.env.INFISICAL_CLIENT_ID`, `process.env.INFISICAL_CLIENT_SECRET` and
  `process.env.INFISICAL_PROJECT_ID` will need to be supplied to the `deploy` CLI command. You can
  do this via the `--env-file .env` flag or by setting them as environment variables in your
  terminal.
</Note>

#### Dev

`syncEnvVars` does not have any effect when running the `dev` command locally. If you want to inject environment variables from another service into your local environment you can do so via a `.env` file or just supplying them as environment variables in your terminal. Most services will have a CLI tool that allows you to run a command with environment variables set:

```sh  theme={null}
infisical run -- npx trigger.dev@latest dev
```

Any environment variables set in the CLI command will be available to your local Trigger.dev tasks.

### The syncEnvVars callback return type

You can return env vars as an object with string keys and values, or an array of names + values.

```ts  theme={null}
return {
  MY_ENV_VAR: "my value",
  MY_OTHER_ENV_VAR: "my other value",
};
```

or

```ts  theme={null}
return [
  {
    name: "MY_ENV_VAR",
    value: "my value",
  },
  {
    name: "MY_OTHER_ENV_VAR",
    value: "my other value",
  },
];
```

This should mean that for most secret services you won't need to convert the data into a different format.

### Using Google credential JSON files

Securely pass a Google credential JSON file to your Trigger.dev task using environment variables.

<Steps>
  <Step title="Convert the Google credential file to base64">
    In your terminal, run the following command and copy the resulting base64 string:

    ```
    base64 -i path/to/your/service-account-file.json
    ```
  </Step>

  <Step title="Set up the environment variable in Trigger.dev">
    Follow [these steps](/deploy-environment-variables) to set a new environment variable using the base64 string as the value.

    ```
    GOOGLE_CREDENTIALS_BASE64="<your base64 string>"
    ```
  </Step>

  <Step title="Use the environment variable in your code">
    Add the following code to your Trigger.dev task:

    ```ts  theme={null}
    import { google } from "googleapis";

    const credentials = JSON.parse(
      Buffer.from(process.env.GOOGLE_CREDENTIALS_BASE64, "base64").toString("utf8")
    );

    const auth = new google.auth.GoogleAuth({
      credentials,
      scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    });

    const client = await auth.getClient();
    ```
  </Step>

  <Step title="Use the client in your code">
    You can now use the `client` object to make authenticated requests to Google APIs
  </Step>
</Steps>

## Using `.env.production` or dotenvx with Trigger.dev

Trigger.dev does not automatically load `.env.production` files or dotenvx files during deploys.\
To use these files in your Trigger.dev environment:

### Option 1 â€” Manually add your environment variables

1. Open your `.env.production` (or `.env`) file
2. Copy the full contents
3. Go to your Trigger.dev project â†’ **Environment Variables**
4. Click **Add variables**
5. Paste the contents directly into the editor

Trigger.dev will automatically parse and create each key/value pair.

This is the simplest way to bring dotenvx or `.env.production` variables into your Trigger.dev environment.

### Option 2 â€” Sync variables automatically using `syncEnvVars`

If you'd prefer an automated flow, you can use the `syncEnvVars` build extension to programmatically load and return your variables:

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncEnvVars } from "@trigger.dev/build/extensions/core";
import dotenvx from "@dotenvx/dotenvx";
import { readFileSync } from "fs";

export default defineConfig({
  project: "<project id>",
  build: {
    extensions: [
      syncEnvVars(async () => {
        const envContent = readFileSync(".env.production", "utf-8");
        const parsed = dotenvx.parse(envContent);
        return parsed ?? {};
      }),
    ],
  },
});
```

This will read your .env.production file using dotenvx and sync the variables to Trigger.dev during every deploy.

**Summary**

* Trigger.dev does not automatically detect .env.production or dotenvx files
* You can paste them manually into the dashboard
* Or sync them automatically using a build extension


# Atomic deploys
Source: https://trigger.dev/docs/deployment/atomic-deployment

Use atomic deploys to coordinate changes to your tasks and your application.

Atomic deploys in Trigger.dev allow you to synchronize the deployment of your application with a specific version of your tasks. This ensures that your application always uses the correct version of its associated tasks, preventing inconsistencies or errors due to version mismatches.

## How it works

Atomic deploys achieve synchronization by deploying your tasks to Trigger.dev without promoting them to the default version. Instead, you explicitly specify the deployed task version in your applicationâ€™s environment. Hereâ€™s the process at a glance:

1. **Deploy Tasks to Trigger.dev**: Use the Trigger.dev CLI to deploy your tasks with the `--skip-promotion` flag. This creates a new task version without making it the default.
2. **Capture the Deployment Version**: The CLI outputs the version of the deployed tasks, which youâ€™ll use in the next step.
3. **Deploy Your Application**: Deploy your application (e.g., to Vercel), setting an environment variable like `TRIGGER_VERSION` to the captured task version.

## Vercel CLI & GitHub Actions

If you deploy to Vercel via their CLI, you can use this sample workflow that demonstrates performing atomic deploys with GitHub Actions, Trigger.dev, and Vercel:

```yml  theme={null}
name: Deploy to Trigger.dev (prod)
on:
  push:
    branches:
      - main
concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Use Node.js 20.x
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"

      - name: Install dependencies
        run: npm install

      - name: Deploy Trigger.dev
        id: deploy-trigger
        env:
          TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
        run: |
          npx trigger.dev@latest deploy --skip-promotion

      - name: Deploy to Vercel
        run: npx vercel --yes --prod -e TRIGGER_VERSION=$TRIGGER_VERSION --token $VERCEL_TOKEN
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          TRIGGER_VERSION: ${{ steps.deploy-trigger.outputs.deploymentVersion }}

      - name: Promote Trigger.dev Version
        run: npx trigger.dev@latest promote $TRIGGER_VERSION
        env:
          TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
          TRIGGER_VERSION: ${{ steps.deploy-trigger.outputs.deploymentVersion }}
```

* Deploy to Trigger.dev

  * The `npx trigger.dev deploy` command uses `--skip-promotion` to deploy the tasks without setting the version as the default.
  * The stepâ€™s id: `deploy-trigger` allows us to capture the deployment version in the output (deploymentVersion).

* Deploy to Vercel:
  * The `npx vercel` command deploys the application, setting the `TRIGGER_VERSION` environment variable to the task version from the previous step.
  * The --prod flag ensures a production deployment, and -e passes the environment variable.
  * The `@trigger.dev/sdk` automatically uses the `TRIGGER_VERSION` environment variable to trigger the correct version of the tasks.

For this workflow to work, you need to set up the following secrets in your GitHub repository:

* `TRIGGER_ACCESS_TOKEN`: Your Trigger.dev personal access token. View the instructions [here](/github-actions) to learn more.
* `VERCEL_TOKEN`: Your Vercel personal access token. You can find this in your Vercel account settings.

## Vercel GitHub integration

If you're are using Vercel, chances are you are using their GitHub integration and deploying your application directly from pushes to GitHub. This section covers how to achieve atomic deploys with Trigger.dev in this setup.

### Turn off automatic promotion

By default, Vercel automatically promotes new deployments to production. To prevent this, you need to disable the auto-promotion feature in your Vercel project settings:

1. Go to your Production environment settings in Vercel at `https://vercel.com/<team-slug>/<project-slug>/settings/environments/production`
2. Disable the "Auto-assign Custom Production Domains" setting:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1a82653803937c6ede1654685ae3ab1a" alt="Vercel project settings showing the auto-promotion setting" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/auto-assign-production-domains.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=51949f92176304c5138b0d872a96a00b 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8d9909069f5df4f737cff40aa3f7442b 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a03b0fde711bd11841eabba8f67b0782 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=35ec9c3a631ddb638f819ba1f73a2c73 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=53606d194dccfb069794a90693bcd78f 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/auto-assign-production-domains.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4aefd7660260c92d5e0256186edf0b58 2500w" />

3. Hit the "Save" button to apply the changes.

Now whenever you push to your main branch, Vercel will deploy your application to the production environment without promoting it, and you can control the promotion manually.

### Deploy with Trigger.dev

Now we want to deploy that same commit to Trigger.dev, and then promote the Vercel deployment when that completes. Here's a sample GitHub Actions workflow that does this:

```yml  theme={null}
name: Deploy to Trigger.dev (prod)

on:
  push:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Use Node.js 20.x
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"

      - name: Install dependencies
        run: npm install

      - name: Wait for vercel deployment (push)
        id: wait-for-vercel
        uses: ludalex/vercel-wait@v1
        with:
          project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          team-id: ${{ secrets.VERCEL_SCOPE_NAME }}
          token: ${{ secrets.VERCEL_TOKEN }}
          sha: ${{ github.sha }}

      - name: ðŸš€ Deploy Trigger.dev
        id: deploy-trigger
        env:
          TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
        run: |
          npx trigger.dev@latest deploy

      - name: Promote Vercel deploy
        run: npx vercel promote $VERCEL_DEPLOYMENT_ID --yes --token $VERCEL_TOKEN --scope $VERCEL_SCOPE_NAME
        env:
          VERCEL_DEPLOYMENT_ID: ${{ steps.wait-for-vercel.outputs.deployment-id }}
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_SCOPE_NAME: ${{ secrets.VERCEL_SCOPE_NAME }}
```

This workflow does the following:

1. Waits for the Vercel deployment to complete using the `ludalex/vercel-wait` action.
2. Deploys the tasks to Trigger.dev using the `npx trigger.dev deploy` command. There's no need to use the `--skip-promotion` flag because we want to promote the deployment.
3. Promotes the Vercel deployment using the `npx vercel promote` command.

For this workflow to work, you need to set up the following secrets in your GitHub repository:

* `TRIGGER_ACCESS_TOKEN`: Your Trigger.dev personal access token. View the instructions [here](/github-actions) to learn more.
* `VERCEL_TOKEN`: Your Vercel personal access token. You can find this in your Vercel account settings.
* `VERCEL_PROJECT_ID`: Your Vercel project ID. You can find this in your Vercel project settings.
* `VERCEL_SCOPE_NAME`: Your Vercel team slug.

Checkout our [example repo](https://github.com/ericallam/vercel-atomic-deploys) to see this workflow in action.

<Note>
  We are using the `ludalex/vercel-wait` action above as a fork of the [official
  tj-actions/vercel-wait](https://github.com/tj-actions/vercel-wait) action because there is a bug
  in the official action that exits early if the deployment isn't found in the first check and due
  to the fact that it supports treating skipped (cancelled) Vercel deployments as valid (on by default).
  I've opened a PR for this issue [here](https://github.com/tj-actions/vercel-wait/pull/106).
</Note>


# Deployment
Source: https://trigger.dev/docs/deployment/overview

Learn how to deploy your tasks to Trigger.dev.

Before you can run production workloads on Trigger.dev, you need to deploy your tasks. The only way to do this at the moment is through the [deploy CLI command](/cli-deploy):

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

## Deploying 101

Let's assume you have an existing trigger.dev project with a few tasks that you have been running locally but now want to deploy to the Trigger.dev cloud (or your self-hosted instance).

First, let's make sure you are logged in to the CLI (if you haven't already):

```bash  theme={null}
npx trigger.dev login
```

This will open a browser window where you can log in with your Trigger.dev account and link your CLI.

Now you can deploy your tasks:

```bash  theme={null}
npx trigger.dev deploy
```

This should print out a success message and let you know a new version has been deployed:

```bash  theme={null}
Trigger.dev (3.3.16)
------------------------------------------------------
â”Œ  Deploying project
â”‚
â—‡  Retrieved your account details for eric@trigger.dev
â”‚
â—‡  Successfully built code
â”‚
â—‡  Successfully deployed version 20250228.1
â”‚
â””  Version 20250228.1 deployed with 4 detected tasks
```

Now if you visit your Trigger.dev dashboard you should see the new version deployed:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8344be75888505d3036e114a4a15eeeb" alt="Trigger.dev dashboard showing the latest version deployed" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/my-first-deployment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=cac39957aa83193bff6e3a3b87fafd74 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8561cd6fed50a4694cbb1daf925c3580 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8645655fd002204b6dcfb65dc5f9eeec 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a515ee7f96995c3da3038e44aa00a60b 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=90f7d69e2f1e12ed7a55cf9d98ceb2ae 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/my-first-deployment.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e3d467bc4d5de26e0ab935f657c73634 2500w" />

<Note>
  Deploying consists of building your tasks and uploading them to the Trigger.dev cloud. This
  process can take a few seconds to a few minutes depending on the size of your project.
</Note>

## Triggering deployed tasks

Once you have deployed your tasks, you can trigger tasks exactly the same way you did locally, but with the "PROD" API key:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aeb9a89c08e9cd4a60c5a18a738126f7" alt="Trigger.dev dashboard showing the API key" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/api-key.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05bcc6ce43becedbb845431960f77d40 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5b44df0271962534989ed980e6e0d8a6 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=640a299e25e4816fceb80c4213b8e454 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f8da89fb8751a1946e563958bbfb88a8 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=310401c9ae6cb588764c4ec40845b404 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/api-key.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=96b825a5094caa74ac1b504802aa1a41 2500w" />

Copy the API key from the dashboard and set the `TRIGGER_SECRET_KEY` environment variable, and then any tasks you trigger will run against the deployed version:

```txt .env theme={null}
TRIGGER_SECRET_KEY="tr_prod_abc123"
```

Now you can trigger your tasks:

```ts  theme={null}
import { myTask } from "./trigger/tasks";

await myTask.trigger({ foo: "bar" });
```

See our [triggering tasks](/triggering) guide for more information.

## Versions

When you deploy your tasks, Trigger.dev creates a new version of all tasks in your project. A version is a snapshot of your tasks at a certain point in time. This ensures that tasks are not affected by changes to the code.

### Current version

When you deploy, the version number is automatically incremented, and the new version is set as the current version for that environment.

<Note>
  A single environment (prod, staging, etc.) can only have a single "current" version at a time.
</Note>

The current version defines which version of the code new task runs will execute against. When a task run starts, it is locked to the current version. This ensures that the task run is not affected by changes to the code. Retries of the task run will also be locked to the original version.

<Note>
  When you Replay a run in the dashboard we will create a new run, locked to the current version and
  not necessarily the version of the original run.
</Note>

### Version locking

You can optionally specify the version when triggering a task using the `version` parameter. This is useful when you want to run a task against a specific version of the code:

```ts  theme={null}
await myTask.trigger({ foo: "bar" }, { version: "20250228.1" });
```

If you want to set a global version to run all tasks against, you can use the `TRIGGER_VERSION` environment variable:

```bash  theme={null}
TRIGGER_VERSION=20250228.1
```

### Child tasks and auto-version locking

Trigger and wait functions version lock child task runs to the parent task run version. This ensures the results from child runs match what the parent task is expecting. If you don't wait then version locking doesn't apply.

| Trigger function        | Parent task version | Child task version | isLocked |
| ----------------------- | ------------------- | ------------------ | -------- |
| `trigger()`             | `20240313.2`        | Current            | No       |
| `batchTrigger()`        | `20240313.2`        | Current            | No       |
| `triggerAndWait()`      | `20240313.2`        | `20240313.2`       | Yes      |
| `batchTriggerAndWait()` | `20240313.2`        | `20240313.2`       | Yes      |

### Skipping promotion

When you deploy, the new version is automatically promoted be the current version. If you want to skip this promotion, you can use the `--skip-promotion` flag:

```bash  theme={null}
npx trigger.dev deploy --skip-promotion
```

This will create a new deployment version but not promote it to the current version:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bc95f9c6a0ccffb47d3d5026587c3cf4" alt="Trigger.dev dashboard showing the latest version deployed but not promoted" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/skip-promotion.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5d92f5c6be5252b269c977ddab4d6c8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=311e323fef63322878f6ced3985ebdfb 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2525cede6e9f48e4fea404a6a9264009 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60c76e6e1fa70fc1594b891802d0b9ca 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=296f61ab0d0ceae21bd661100fa88dec 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/skip-promotion.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0cee76dfc877b3f9458fab9c2ac8d960 2500w" />

This allows you to deploy and test a new version without affecting new task runs. When you want to promote the version, you can do so from the CLI:

```bash  theme={null}
npx trigger.dev promote 20250228.1
```

Or from the dashboard:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=48aaab3ef5f3ef4bc63d2f15566746e2" alt="Trigger.dev dashboard showing the promote button" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/promote-button.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6f9c8cea47d6cee468271830244bcd03 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccd06eca746c1428f1fba3348c63bb51 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=03fecc67bfd2e4b8d2a23e50bccdeaaa 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3fdb56c5c9cc5131e5f26f9efe41ff07 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=54529693d8d673d25f721aa66cda2d94 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/promote-button.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=cec8c4a1ee1b52e0b367f5b3d09871a5 2500w" />

To learn more about skipping promotion and how this enables atomic deployments, see our [Atomic deployment](/deployment/atomic-deployment) guide.

## Staging deploys

By default, the `deploy` command will deploy to the `prod` environment. If you want to deploy to a different environment, you can use the `--env` flag:

```bash  theme={null}
npx trigger.dev deploy --env staging
```

<Note>
  If you are using the Trigger.dev Cloud, staging deploys are only available on the Hobby and Pro
  plans.
</Note>

This will create an entirely new version of your tasks for the `staging` environment, with a new version number and an independent current version:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1a35a918611faf39246296633c28ba7f" alt="Trigger.dev dashboard showing the staging environment" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="deployment/staging-deploy.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e0548dca7ddaec29119449bfdac1569c 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9ae816833dd01066d6f54777e00ad9c2 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=54ab132986f150ba263ef461b901872d 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3fed2a9daf41ddb7d76acdee2a76ff29 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1ce57df105b4ce7a4f316047be934a92 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/staging-deploy.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9070a4a84cc1b356419d2331ae984b13 2500w" />

Now you can trigger tasks against the staging environment by setting the `TRIGGER_SECRET_KEY` environment variable to the staging API key:

```txt .env theme={null}
TRIGGER_SECRET_KEY="tr_stg_abcd123"
```

Currently, we only support two environments: `prod` and `staging`. Multiple environments are on our roadmap which you can track [here](https://feedback.trigger.dev/p/more-environments).

## Local builds

By default we use a remote build provider to speed up builds. However, you can also force the build to happen locally on your machine using the `--force-local-build` flag:

```bash  theme={null}
npx trigger.dev deploy --force-local-build
```

<Tip>
  Deploying with local builds can be a useful fallback in cases where our remote build provider is experiencing availability issues.
</Tip>

### System requirements

To use local builds, you need the following tools installed on your machine:

* Docker ([installation guide](https://docs.docker.com/get-started/get-docker))
* Docker Buildx ([installation guide](https://github.com/docker/buildx#installing))

## Environment variables

To add custom environment variables to your deployed tasks, you need to add them to your project in the Trigger.dev dashboard, or automatically sync them using our [syncEnvVars](/config/config-file#syncenvvars) or [syncVercelEnvVars](/config/config-file#syncvercelenvvars) build extensions.

For more information on environment variables, see our [environment variables](/deploy-environment-variables) guide.

## Troubleshooting

When things go wrong with your deployment, there are a few things you can do to diagnose the issue:

### Dry runs

You can do a "dry run" of the deployment to see what is built and uploaded without actually deploying:

```bash  theme={null}
npx trigger.dev deploy --dry-run

#  Dry run complete. View the built project at /<project path>/.trigger/tmp/<build dir>
```

The dry run will output the build directory where you can inspect the built tasks and dependencies. You can also compress this directory and send it to us if you need help debugging.

### Debug logs

You can run the deploy command with `--log-level debug` at the end. This will print out a lot of information about the deploy. If you can't figure out the problem from the information below please join [our Discord](https://trigger.dev/discord) and create a help forum post. Do NOT share the extended debug logs publicly as they might reveal private information about your project.

### Common issues

#### `Failed to build project image: Error building image`

There should be a link below the error message to the full build logs on your machine. Take a look at these to see what went wrong. Join [our Discord](https://trigger.dev/discord) and you share it privately with us if you can't figure out what's going wrong. Do NOT share these publicly as the verbose logs might reveal private information about your project.

Sometimes these errors are caused by upstream availability issues with our remote build provider. In this case, you can try deploying with a local build using the `--force-local-build` flag. Refer to the [Local builds](#local-builds) section for more information.

#### `Deployment encountered an error`

Usually there will be some useful guidance below this message. If you can't figure out what's going wrong then join [our Discord](https://trigger.dev/discord) and create a Help forum post with a link to your deployment.

#### `No loader is configured for ".node" files`

This happens because `.node` files are native code and can't be bundled like other packages. To fix this, add your package to [`build.external`](/config/config-file#external) in the `trigger.config.ts` file like this:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    external: ["your-node-package"],
  },
});
```

### `Cannot find matching keyid`

This error occurs when using Node.js v22 with corepack, as it's not yet compatible with the latest package manager signatures. To fix this, either:

1. Downgrade to Node.js v20 (LTS), or
2. Install corepack globally: `npm i -g corepack@latest`

The corepack bug and workaround are detailed in [this issue](https://github.com/npm/cli/issues/8075).


# Preview branches
Source: https://trigger.dev/docs/deployment/preview-branches

Create isolated environments for each branch of your code, allowing you to test changes before merging to production. You can create preview branches manually or automatically from your git branches.

## How to use preview branches

The preview environment is special â€“ you create branches from it. The branches you create live under the preview environment and have all the features you're used to from other environments (like staging or production). That means you can trigger runs, have schedules, test them, use Realtime, etc.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1ea48ad7377b6824a293e69044448b53" alt="Preview environment and branches" data-og-width="620" width="620" data-og-height="420" height="420" data-path="deployment/preview-environment-branches.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=69369bcd1ab2140a176cc511b15c2a97 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=89cfa57faadd32d488631ba089082c2e 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=11366f107502a534f4301c76b7e6493d 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f51b933f65ef7dcb24e693185e8142dc 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1c035becc9fb7ae0e75b8171a176d03c 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-branches.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5f3be2cf5cd9cc99e18cc5a0f9a0998 2500w" />

We recommend you automatically create a preview branch for each git branch when a Pull Request is opened and then archive it automatically when the PR is merged/closed.

The process to use preview branches looks like this:

1. Create a preview branch
2. Deploy to the preview branch (1+ times)
3. Trigger runs using your Preview API key (`TRIGGER_SECRET_KEY`) and the branch name (`TRIGGER_PREVIEW_BRANCH`).
4. Archive the preview branch when the branch is done.

There are two main ways to do this:

1. Automatically: using GitHub Actions (recommended).
2. Manually: in the dashboard and/or using the CLI.

### Limits on active preview branches

We restrict the number of active preview branches (per project). You can archive a preview branch at any time (automatically or manually) to unlock another slot â€“ or you can upgrade your plan.

Once archived you can still view the dashboard for the branch but you can't trigger or execute runs (or other write operations).

This limit exists because each branch has an independent concurrency limit. For the Cloud product these are the limits:

| Plan  | Active preview branches |
| ----- | ----------------------- |
| Free  | 0                       |
| Hobby | 5                       |
| Pro   | 20 (then paid for more) |

For full details see our [pricing page](https://trigger.dev/pricing).

## Triggering runs and using the SDK

Before we talk about how to deploy to preview branches, one important thing to understand is that you must set the `TRIGGER_PREVIEW_BRANCH` environment variable as well as the `TRIGGER_SECRET_KEY` environment variable.

When deploying to somewhere that supports `process.env` (like Node.js runtimes) you can just set the environment variables:

```bash  theme={null}
TRIGGER_SECRET_KEY="tr_preview_1234567890"
TRIGGER_PREVIEW_BRANCH="your-branch-name"
```

If you're deploying somewhere that doesn't support `process.env` (like some edge runtimes) you can manually configure the SDK:

```ts  theme={null}
import { configure } from "@trigger.dev/sdk";
import { myTask } from "./trigger/myTasks";

configure({
  secretKey: "tr_preview_1234567890", // WARNING: Never actually hardcode your secret key like this
  previewBranch: "your-branch-name",
});

async function triggerTask() {
  await myTask.trigger({ userId: "1234" }); // Trigger a run in your-branch-name
}
```

## Preview branches with GitHub Actions (recommended)

This GitHub Action will:

1. Automatically create a preview branch for your Pull Request (if the branch doesn't already exist).
2. Deploy the preview branch.
3. Archive the preview branch when the Pull Request is merged/closed.

```yml .github/workflows/trigger-preview-branches.yml theme={null}
name: Deploy to Trigger.dev (preview branches)

on:
  pull_request:
    types: [opened, synchronize, reopened, closed]

jobs:
  deploy-preview:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Use Node.js 20.x
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"

      - name: Install dependencies
        run: npm install

      - name: Deploy preview branch
        run: npx trigger.dev@latest deploy --env preview
        env:
          TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
```

For this workflow to work, you need to set the following secrets in your GitHub repository:

* `TRIGGER_ACCESS_TOKEN`: A Trigger.dev personal access token (they start with `tr_pat_`). [Learn how to create one and set it in GitHub](/github-actions#creating-a-personal-access-token).

Notice that the deploy command has `--env preview` at the end. We automatically detect the preview branch from the GitHub actions env var.

You can manually specify the branch using `--branch <branch-name>` in the deploy command, but this isn't required.

## Preview branches with the CLI (manual)

### Deploying a preview branch

Creating and deploying a preview branch manually is easy:

```bash  theme={null}
npx trigger.dev@latest deploy --env preview
```

This will create and deploy a preview branch, automatically detecting the git branch. If for some reason the auto-detection doesn't work it will let you know and tell you do this:

```bash  theme={null}
npx trigger.dev@latest deploy --env preview --branch your-branch-name
```

### Archiving a preview branch

You can manually archive a preview branch with the CLI:

```bash  theme={null}
npx trigger.dev@latest preview archive
```

Again we will try auto-detect the current branch. But you can specify the branch name with `--branch <branch-name>`.

## Creating and archiving preview branches from the dashboard

From the "Preview branches" page you can create a branch:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2f169fe8a12fd5e71c68e72dff38d0ba" alt="Preview branches page" data-og-width="2832" width="2832" data-og-height="2060" height="2060" data-path="deployment/preview-branches.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d77850e6aabba369b59bb11e49415629 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c18074538e204e2a8049d3969049d6c9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=84140227247ee335b6daec14586fc2f8 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=59cdc0dedce739dfbd926cf171029898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d0335bb6a3865d7f3e51b5bbc26b7642 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=643a7ea8cea29bec0cf4c3dd5e9b7b9f 2500w" />
<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=daac2d1f55ba7ddc7bba83bceb9f65f8" alt="Create preview branch" data-og-width="1196" width="1196" data-og-height="603" height="603" data-path="deployment/preview-branches-new.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=72cd18942952158e9ebfcf4a788e653e 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3d166afef618f1e992dfa921dd2a73e5 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f3e9a8814ae6039751aa648dec8b2066 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=051c4f7ed376b7e7901debb23142125a 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d241dccbfbbad0d59a165feba6f2ae5d 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-new.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c07177baf4a0581142ac55f2213181e5 2500w" />

You can also archive a branch:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1908c37fe8b46c3f942b0caf386094fd" alt="Archive preview branch" data-og-width="2832" width="2832" data-og-height="2060" height="2060" data-path="deployment/preview-branches-archive.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e1035c51deb29876494525b4317f4fb4 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a237012a0892cdb9fab4e40a293d1041 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a809dadcaa8d7903ad34610951721884 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=834c2099f1f7771a793c9ec84717b5fa 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9cbcbaf8c212805aea80207a731a24d5 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-branches-archive.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0c65583a0291f776674ff89c21c409ca 2500w" />

## Environment variables

You can set environment variables for "Preview" and they will get applied to all branches (existing and new). You can also set environment variables for a specific branch. If they are set for both then the branch-specific variables will take precedence.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=dcf6d3db8d2892e68351ddcdd367ac6e" alt="Environment variables" data-og-width="1012" width="1012" data-og-height="586" height="586" data-path="deployment/preview-environment-variables.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=379f827c4015c9d2fd362267843a84cf 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fa4d754f9946cf09cfeacd065f5eeddb 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ba1f6b354220f2bf3b06ac13be1343f0 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9b3b68749706d0c00978ea6fb4dc7b29 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=cb25b22522a78e81bac0b2d06475058d 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/deployment/preview-environment-variables.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3d088494a88aa0bc8a52775e17448ed6 2500w" />

These can be set manually in the dashboard, or automatically at deploy time using the [syncEnvVars()](/config/extensions/syncEnvVars) or [syncVercelEnvVars()](/config/extensions/syncEnvVars#syncvercelenvvars) build extensions.

### Sync environment variables

Full instructions are in the [syncEnvVars()](/config/extensions/syncEnvVars) documentation.

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
// You will need to install the @trigger.dev/build package
import { syncEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  //... other config
  build: {
    // This will automatically detect and sync environment variables
    extensions: [
      syncEnvVars(async (ctx) => {
        // You can fetch env variables from a 3rd party service like Infisical, Hashicorp Vault, etc.
        // The ctx.branch will be set if it's a preview deployment.
        return await fetchEnvVars(ctx.environment, ctx.branch);
      }),
    ],
  },
});
```

### Sync Vercel environment variables

You need to set the `VERCEL_ACCESS_TOKEN`, `VERCEL_PROJECT_ID` and `VERCEL_TEAM_ID` environment variables. You can find these in the Vercel dashboard. Full instructions are in the [syncVercelEnvVars()](/config/extensions/syncEnvVars#syncvercelenvvars) documentation.

The extension will automatically detect a preview branch deploy from Vercel and sync the appropriate environment variables.

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
// You will need to install the @trigger.dev/build package
import { syncVercelEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  //... other config
  build: {
    // This will automatically detect and sync environment variables
    extensions: [syncVercelEnvVars()],
  },
});
```


# Errors & Retrying
Source: https://trigger.dev/docs/errors-retrying

How to deal with errors and write reliable tasks.

When an uncaught error is thrown inside your task, that task attempt will fail.

You can configure retrying in two ways:

1. In your [trigger.config file](/config/config-file) you can set the default retrying behavior for all tasks.
2. On each task you can set the retrying behavior.

<Note>
  By default when you create your project using the CLI init command we disabled retrying in the DEV
  environment. You can enable it in your [trigger.config file](/config/config-file).
</Note>

## A simple example with OpenAI

This task will retry 10 times with exponential backoff.

* `openai.chat.completions.create()` can throw an error.
* The result can be empty and we want to try again. So we manually throw an error.

```ts /trigger/openai.ts theme={null}
import { task } from "@trigger.dev/sdk";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export const openaiTask = task({
  id: "openai-task",
  //specifying retry options overrides the defaults defined in your trigger.config file
  retry: {
    maxAttempts: 10,
    factor: 1.8,
    minTimeoutInMs: 500,
    maxTimeoutInMs: 30_000,
    randomize: false,
  },
  run: async (payload: { prompt: string }) => {
    //if this fails, it will throw an error and retry
    const chatCompletion = await openai.chat.completions.create({
      messages: [{ role: "user", content: payload.prompt }],
      model: "gpt-3.5-turbo",
    });

    if (chatCompletion.choices[0]?.message.content === undefined) {
      //sometimes OpenAI returns an empty response, let's retry by throwing an error
      throw new Error("OpenAI call failed");
    }

    return chatCompletion.choices[0].message.content;
  },
});
```

## Combining tasks

One way to gain reliability is to break your work into smaller tasks and [trigger](/triggering) them from each other. Each task can have its own retrying behavior:

```ts /trigger/multiple-tasks.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 10,
  },
  run: async (payload: string) => {
    const result = await otherTask.triggerAndWait("some data");
    //...do other stuff
  },
});

export const otherTask = task({
  id: "other-task",
  retry: {
    maxAttempts: 5,
  },
  run: async (payload: string) => {
    return {
      foo: "bar",
    };
  },
});
```

Another benefit of this approach is that you can view the logs and retry each task independently from the dashboard.

## Retrying smaller parts of a task

Another complimentary strategy is to perform retrying inside of your task.

We provide some useful functions that you can use to retry smaller parts of a task. Of course, you can also write your own logic or use other packages.

### retry.onThrow()

You can retry a block of code that can throw an error, with the same retry settings as a task.

```ts /trigger/retry-on-throw.ts theme={null}
import { task, logger, retry } from "@trigger.dev/sdk";

export const retryOnThrow = task({
  id: "retry-on-throw",
  run: async (payload: any) => {
    //Will retry up to 3 times. If it fails 3 times it will throw.
    const result = await retry.onThrow(
      async ({ attempt }) => {
        //throw on purpose the first 2 times, obviously this is a contrived example
        if (attempt < 3) throw new Error("failed");
        //...
        return {
          foo: "bar",
        };
      },
      { maxAttempts: 3, randomize: false }
    );

    //this will log out after 3 attempts of retry.onThrow
    logger.info("Result", { result });
  },
});
```

<Note>
  If all of the attempts with `retry.onThrow` fail, an error will be thrown. You can catch this or
  let it cause a retry of the entire task.
</Note>

### retry.fetch()

You can use `fetch`, `axios`, or any other library in your code.

But we do provide a convenient function to perform HTTP requests with conditional retrying based on the response:

```ts /trigger/retry-fetch.ts theme={null}
import { task, logger, retry } from "@trigger.dev/sdk";

export const taskWithFetchRetries = task({
  id: "task-with-fetch-retries",
  run: async ({ payload, ctx }) => {
    //if the Response is a 429 (too many requests), it will retry using the data from the response. A lot of good APIs send these headers.
    const headersResponse = await retry.fetch("http://my.host/test-headers", {
      retry: {
        byStatus: {
          "429": {
            strategy: "headers",
            limitHeader: "x-ratelimit-limit",
            remainingHeader: "x-ratelimit-remaining",
            resetHeader: "x-ratelimit-reset",
            resetFormat: "unix_timestamp_in_ms",
          },
        },
      },
    });
    const json = await headersResponse.json();
    logger.info("Fetched headers response", { json });

    //if the Response is a 500-599 (issue with the server you're calling), it will retry up to 10 times with exponential backoff
    const backoffResponse = await retry.fetch("http://my.host/test-backoff", {
      retry: {
        byStatus: {
          "500-599": {
            strategy: "backoff",
            maxAttempts: 10,
            factor: 2,
            minTimeoutInMs: 1_000,
            maxTimeoutInMs: 30_000,
            randomize: false,
          },
        },
      },
    });
    const json2 = await backoffResponse.json();
    logger.info("Fetched backoff response", { json2 });

    //You can additionally specify a timeout. In this case if the response takes longer than 1 second, it will retry up to 5 times with exponential backoff
    const timeoutResponse = await retry.fetch("https://httpbin.org/delay/2", {
      timeoutInMs: 1000,
      retry: {
        timeout: {
          maxAttempts: 5,
          factor: 1.8,
          minTimeoutInMs: 500,
          maxTimeoutInMs: 30_000,
          randomize: false,
        },
      },
    });
    const json3 = await timeoutResponse.json();
    logger.info("Fetched timeout response", { json3 });

    return {
      result: "success",
      payload,
      json,
      json2,
      json3,
    };
  },
});
```

<Note>
  If all of the attempts with `retry.fetch` fail, an error will be thrown. You can catch this or let
  it cause a retry of the entire task.
</Note>

## Advanced error handling and retrying

We provide a `catchError` callback on the task and in your `trigger.config` file. This gets called when an uncaught error is thrown in your task.

You can

* Inspect the error, log it, and return a different error if you'd like.
* Modify the retrying behavior based on the error, payload, context, etc.

If you don't return anything from the function it will use the settings on the task (or inherited from the config). So you only need to use this to override things.

### OpenAI error handling example

OpenAI calls can fail for a lot of reasons and the ideal retry behavior is different for each.

In this complicated example:

* We skip retrying if there's no Response status.
* We skip retrying if you've run out of credits.
* If there are no Response headers we let the normal retrying logic handle it (return undefined).
* If we've run out of requests or tokens we retry at the time specified in the headers.

<CodeGroup>
  ```ts tasks.ts theme={null}
  import { task } from "@trigger.dev/sdk";
  import { calculateISO8601DurationOpenAIVariantResetAt, openai } from "./openai.js";

  export const openaiTask = task({
    id: "openai-task",
    retry: {
      maxAttempts: 1,
    },
    run: async (payload: { prompt: string }) => {
      const chatCompletion = await openai.chat.completions.create({
        messages: [{ role: "user", content: payload.prompt }],
        model: "gpt-3.5-turbo",
      });

      return chatCompletion.choices[0].message.content;
    },
    catchError: async ({ payload, error, ctx, retryAt }) => {
      if (error instanceof OpenAI.APIError) {
        if (!error.status) {
          return {
            skipRetrying: true,
          };
        }

        if (error.status === 429 && error.type === "insufficient_quota") {
          return {
            skipRetrying: true,
          };
        }

        if (!error.headers) {
          //returning undefined means the normal retrying logic will be used
          return;
        }

        const remainingRequests = error.headers["x-ratelimit-remaining-requests"];
        const requestResets = error.headers["x-ratelimit-reset-requests"];

        if (typeof remainingRequests === "string" && Number(remainingRequests) === 0) {
          return {
            retryAt: calculateISO8601DurationOpenAIVariantResetAt(requestResets),
          };
        }

        const remainingTokens = error.headers["x-ratelimit-remaining-tokens"];
        const tokensResets = error.headers["x-ratelimit-reset-tokens"];

        if (typeof remainingTokens === "string" && Number(remainingTokens) === 0) {
          return {
            retryAt: calculateISO8601DurationOpenAIVariantResetAt(tokensResets),
          };
        }
      }
    },
  });
  ```

  ```ts openai.ts theme={null}
  import { OpenAI } from "openai";

  export const openai = new OpenAI({ apiKey: env.OPENAI_API_KEY });

  export function calculateISO8601DurationOpenAIVariantResetAt(
    resets: string,
    now: Date = new Date()
  ): Date | undefined {
    // Check if the input is null or undefined
    if (!resets) return undefined;

    // Regular expression to match the duration string pattern
    const pattern = /^(?:(\d+)d)?(?:(\d+)h)?(?:(\d+)m)?(?:(\d+(?:\.\d+)?)s)?(?:(\d+)ms)?$/;
    const match = resets.match(pattern);

    // If the string doesn't match the expected format, return undefined
    if (!match) return undefined;

    // Extract days, hours, minutes, seconds, and milliseconds from the string
    const days = parseInt(match[1] ?? "0", 10) || 0;
    const hours = parseInt(match[2] ?? "0", 10) || 0;
    const minutes = parseInt(match[3] ?? "0", 10) || 0;
    const seconds = parseFloat(match[4] ?? "0") || 0;
    const milliseconds = parseInt(match[5] ?? "0", 10) || 0;

    // Calculate the future date based on the current date plus the extracted time
    const resetAt = new Date(now);
    resetAt.setDate(resetAt.getDate() + days);
    resetAt.setHours(resetAt.getHours() + hours);
    resetAt.setMinutes(resetAt.getMinutes() + minutes);
    resetAt.setSeconds(resetAt.getSeconds() + Math.floor(seconds));
    resetAt.setMilliseconds(
      resetAt.getMilliseconds() + (seconds - Math.floor(seconds)) * 1000 + milliseconds
    );

    return resetAt;
  }
  ```
</CodeGroup>

## Preventing retries

### Using `AbortTaskRunError`

You can prevent retries by throwing an `AbortTaskRunError`. This will fail the task attempt and disable retrying.

```ts /trigger/myTasks.ts theme={null}
import { task, AbortTaskRunError } from "@trigger.dev/sdk";

export const openaiTask = task({
  id: "openai-task",
  run: async (payload: { prompt: string }) => {
    //if this fails, it will throw an error and stop retrying
    const chatCompletion = await openai.chat.completions.create({
      messages: [{ role: "user", content: payload.prompt }],
      model: "gpt-3.5-turbo",
    });

    if (chatCompletion.choices[0]?.message.content === undefined) {
      // If OpenAI returns an empty response, abort retrying
      throw new AbortTaskRunError("OpenAI call failed");
    }

    return chatCompletion.choices[0].message.content;
  },
});
```

### Using try/catch

Sometimes you want to catch an error and don't want to retry the task. You can use try/catch as you normally would. In this example we fallback to using Replicate if OpenAI fails.

```ts /trigger/myTasks.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const openaiTask = task({
  id: "openai-task",
  run: async (payload: { prompt: string }) => {
    try {
      //if this fails, it will throw an error and retry
      const chatCompletion = await openai.chat.completions.create({
        messages: [{ role: "user", content: payload.prompt }],
        model: "gpt-3.5-turbo",
      });

      if (chatCompletion.choices[0]?.message.content === undefined) {
        //sometimes OpenAI returns an empty response, let's retry by throwing an error
        throw new Error("OpenAI call failed");
      }

      return chatCompletion.choices[0].message.content;
    } catch (error) {
      //use Replicate if OpenAI fails
      const prediction = await replicate.run(
        "meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",
        {
          input: {
            prompt: payload.prompt,
            max_new_tokens: 250,
          },
        }
      );

      if (prediction.output === undefined) {
        //retry if Replicate fails
        throw new Error("Replicate call failed");
      }

      return prediction.output;
    }
  },
});
```


# CI / GitHub Actions
Source: https://trigger.dev/docs/github-actions

You can easily deploy your tasks with GitHub actions and other CI environments.

The instructions below are specific to GitHub Actions, but the same concepts can be used with other CI systems.

<Tip>
  Check out our new [GitHub integration](/github-integration) for automatic deployments, without adding any GitHub Actions workflows.
</Tip>

## GitHub Actions example

This simple GitHub action workflow will deploy your Trigger.dev tasks when new code is pushed to the `main` branch and the `trigger` directory has changes in it.

<Warning>
  The deploy step will fail if any version mismatches are detected. Please see the [version
  pinning](/github-actions#version-pinning) section for more details.
</Warning>

<CodeGroup>
  ```yaml .github/workflows/release-trigger-prod.yml theme={null}
  name: Deploy to Trigger.dev (prod)

  on:
    push:
      branches:
        - main

  jobs:
    deploy:
      runs-on: ubuntu-latest

      steps:
        - uses: actions/checkout@v4

        - name: Use Node.js 20.x
          uses: actions/setup-node@v4
          with:
            node-version: "20.x"

        - name: Install dependencies
          run: npm install

        - name: ðŸš€ Deploy Trigger.dev
          env:
            TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
          run: |
            npx trigger.dev@latest deploy
  ```

  ```yaml .github/workflows/release-trigger-staging.yml theme={null}
  name: Deploy to Trigger.dev (staging)

  # Requires manually calling the workflow from a branch / commit to deploy to staging
  on:
    workflow_dispatch:

  jobs:
    deploy:
      runs-on: ubuntu-latest

      steps:
        - uses: actions/checkout@v4

        - name: Use Node.js 20.x
          uses: actions/setup-node@v4
          with:
            node-version: "20.x"

        - name: Install dependencies
          run: npm install

        - name: ðŸš€ Deploy Trigger.dev
          env:
            TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
          run: |
            npx trigger.dev@latest deploy --env staging
  ```
</CodeGroup>

If you already have a GitHub action file, you can just add the final step "ðŸš€ Deploy Trigger.dev" to your existing file.

## Creating a Personal Access Token

<Steps>
  <Step title="Create a new access token">
    Go to your profile page and click on the ["Personal Access
    Tokens"](https://cloud.trigger.dev/account/tokens) tab.
  </Step>

  <Step title="Go to your repository on GitHub.">
    Click on 'Settings' -> 'Secrets and variables' -> 'Actions' -> 'New repository secret'
  </Step>

  <Step title="Add the TRIGGER_ACCESS_TOKEN">
    Add the name `TRIGGER_ACCESS_TOKEN` and the value of your access token. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6c516d32254c19937c0e7104753316a7" alt="Add TRIGGER_ACCESS_TOKEN
    in GitHub" data-og-width="1373" width="1373" data-og-height="919" height="919" data-path="images/github-access-token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=067664630f87c18f4f22ad7b1b4483e0 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=153409ea82e92f09591159880a32594a 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3088626084cb0a4a13f6155f7a6b56c2 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3845374b71af491ff1a43e8deca2f445 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ebe6406d9a669c5e045378d24fbcb9c3 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/github-access-token.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f8a87db188028dc7b104f6cf9ddbde0a 2500w" />
  </Step>
</Steps>

## CLI Version pinning

The CLI and `@trigger.dev/*` package versions need to be in sync with the `trigger.dev` CLI, otherwise there will be errors and unpredictable behavior. Hence, the `deploy` command will automatically fail during CI on any version mismatches.
Tip: add the `trigger.dev` CLI to your `devDependencies` and the deploy command to your `package.json` file to keep versions managed in the same place. For example:

```json  theme={null}
{
  "scripts": {
    "deploy:trigger-prod": "trigger deploy",
    "deploy:trigger": "trigger deploy --env staging"
  },
  "devDependencies": {
    "trigger.dev": "4.0.2"
  }
}
```

Your workflow file will follow the version specified in the `package.json` script, like so:

```yaml .github/workflows/release-trigger.yml theme={null}
- name: ðŸš€ Deploy Trigger.dev
  env:
    TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
  run: |
    npm run deploy:trigger
```

You should use the version you run locally during dev and manual deploy. The current version is displayed in the banner, but you can also check it by appending `--version` to any command.

## Self-hosting

When self-hosting, you will have to take a few additional steps:

* Specify the `TRIGGER_API_URL` environment variable. You can add it to the GitHub secrets the same way as the access token. This should point at your webapp domain, for example: `https://trigger.example.com`
* Setup docker as you will need to build and push the image to your registry. On [Trigger.dev Cloud](https://cloud.trigger.dev) this is all done remotely.
* Add your registry credentials to the GitHub secrets.
* Use the `--self-hosted` and `--push` flags when deploying.

<Tip>If you're self-hosting v4, the `--self-hosted` and `--push` flags are **NOT** needed.</Tip>

Other than that, your GitHub action file will look very similar to the one above:

<CodeGroup>
  ```yaml .github/workflows/release-trigger-self-hosted.yml theme={null}
  name: Deploy to Trigger.dev (self-hosted)

  on:
    push:
      branches:
        - main

  jobs:
    deploy:
      runs-on: ubuntu-latest

      steps:
        - uses: actions/checkout@v4

        - name: Use Node.js 20.x
          uses: actions/setup-node@v4
          with:
            node-version: "20.x"

        - name: Install dependencies
          run: npm install

        # docker setup - part 1
        - name: Set up Docker Buildx
          uses: docker/setup-buildx-action@v3
          with:
            version: latest

        # docker setup - part 2
        - name: Login to DockerHub
          uses: docker/login-action@v3
          with:
            username: ${{ secrets.DOCKERHUB_USERNAME }}
            password: ${{ secrets.DOCKERHUB_TOKEN }}

        - name: ðŸš€ Deploy Trigger.dev
          env:
            TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
            # required when self-hosting
            TRIGGER_API_URL: ${{ secrets.TRIGGER_API_URL }}
          # deploy with additional flags
          run: |
            npx trigger.dev@latest deploy --self-hosted --push
  ```
</CodeGroup>


# GitHub integration
Source: https://trigger.dev/docs/github-integration

Automatically deploy your tasks on every push to your GitHub repository.

## How it works

Once you connect a GitHub repository to your project, you can configure tracking branches for the production and staging environments.
Every push to a tracked branch creates a deployment in the corresponding environment. Preview branch deployments are also supported for pull requests.

This eliminates the need to manually run the `trigger.dev deploy` command or set up custom CI/CD workflows.

## Setup

<Steps>
  <Step title="Install our GitHub app">
    Go to your project's settings page and click `Install GitHub app`.
    This will take you to GitHub to authorize the Trigger.dev app for your organization or personal account.
  </Step>

  <Step title="Connect your repository">
    Select a repository to connect to your project.
  </Step>

  <Step title="Configure branch tracking">
    Choose which branches should trigger automatic deployments:

    * **Production**: The branch that deploys to your production environment, e.g., `main`.
    * **Staging**: The branch that deploys to your staging environment.
    * **Preview**: Toggle to enable preview deployments for pull requests
  </Step>

  <Step title="Customize build settings (optional)">
    Configure how your project is built:

    * **Trigger config file**: Path to your `trigger.config.ts` file. By default, we look for it in the root of your repository. The path should be relative to the root of your repository and contain the config file name, e.g., `apps/tasks/trigger.config.ts`.
    * **Install command**: Auto-detected by default, but you can override it if necessary. The command will be run from the root of your repository.
    * **Pre-build command**: Run any commands before building and deploying your project, e.g., `pnpm run prisma:generate`. The command will be run from the root of your repository.
  </Step>
</Steps>

## Branch tracking

Our GitHub integration uses branch tracking to determine when and where to deploy your code.

<img src="https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=22539316605344f0d461e9132b365161" alt="Trigger.dev project git settings" data-og-width="2128" width="2128" data-og-height="1312" height="1312" data-path="deployment/git-settings.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=280&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=d6e36be08415a61faffca2d42a4f581f 280w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=560&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=56da45f1ba051ae3849c01f1752b3bc8 560w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=840&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=f72bcc7fa00d560bcafec619b1fc987a 840w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=1100&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=984cc0145d10478fa1e4e9383a28be9d 1100w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=1650&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=271094babe4404695f896005a11e9ba9 1650w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/git-settings.png?w=2500&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=46c3892badd5efd5dd1ff6da7bae4e0b 2500w" />

### Production and staging branches

When you connect a repository, the default branch of your repository will be used as the production tracking branch, by default.

When you configure a production or staging branch, every push to that branch will trigger a deployment.
Our build server will install the project dependencies, build your project, and deploy it to the corresponding environment.

If there are multiple consecutive pushes to a tracked branch, the later deployments will be queued until the previous deployment completes.

<Note>
  When you connect a repository, the default branch of your repository will be used as the production tracking branch by default.
  You can change this in the git settings of your project.
</Note>

### Pull requests

By default, pull requests will be deployed to preview branch environments, enabling you to test changes before merging.
When the pull request is merged or closed, the preview branch is automatically archived.

The name of the preview branch matches the branch name of the pull request.

<Note>
  Preview branch deployments require the preview environment to be enabled on your project. Learn more about [preview branches](/deployment/preview-branches).
</Note>

## Disconnecting a repository

You can disconnect a repository at any time from your project git settings. This will stop automatic deployments triggered from GitHub.

## Managing repository access

To add or remove repository access for the Trigger.dev GitHub app, follow the link in the `Connect GitHub repository` modal:

<img src="https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=60a5382c08d707000e907b292242f388" alt="Trigger.dev prompt to connect a GitHub repository" data-og-width="2128" width="2128" data-og-height="1312" height="1312" data-path="deployment/connect-repo.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=280&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=8f66d138ecf9cc56a8ff97d9e484d40f 280w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=560&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=ac67e6a07bd9e132609c66480b843b2e 560w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=840&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=5a538fa4904a6fd41fbbaf36e101521f 840w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=1100&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=06dde82cb6f249a009cc0714dc9eaf73 1100w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=1650&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=1d4bfea5cfe868c25fa73ce902123470 1650w, https://mintcdn.com/trigger/rYmvd2BT_CpeAo5i/deployment/connect-repo.png?w=2500&fit=max&auto=format&n=rYmvd2BT_CpeAo5i&q=85&s=ffea2ffa393258159c1c60e2686af341 2500w" />

Alternatively, you can follow these steps on GitHub:

1. Go to your GitHub account settings
2. Navigate to **Settings** â†’ **Applications** â†’ **Installed GitHub Apps**
3. Click **Configure** next to `Trigger.dev App`
4. Update repository access under `Repository access`

Changes to repository access will be reflected immediately in your Trigger.dev project settings.

## Environment variables at build time

You can expose environment variables during the build and deployment process by prefixing them with `TRIGGER_BUILD_`.
In the build server, the `TRIGGER_BUILD_` prefix is stripped from the variable name, i.e., `TRIGGER_BUILD_MY_TOKEN` is exposed as `MY_TOKEN`.

Build extensions will also have access to these variables.

<Note>
  Build environment variables only apply to deployments in the environment you set them in.
</Note>

Learn more about managing [environment variables](/deploy-environment-variables).

## Using a private npm registry

If your project uses packages from a private npm registry, you can provide authentication by setting a `TRIGGER_BUILD_NPM_RC` environment variable.

The value should be the contents of your `.npmrc` file including any token credentials, encoded to base64.

### Example

Example `.npmrc` file containing credentials for a private npm registry and a GitHub package registry:

```
//registry.npmjs.org/:_authToken=<YOUR_NPM_TOKEN>
@<YOUR_NAMESPACE>:registry=https://npm.pkg.github.com
//npm.pkg.github.com/:always-auth=true
//npm.pkg.github.com/:_authToken=<YOUR_GITHUB_TOKEN>
```

Encode it to base64:

```bash  theme={null}
# Encode your .npmrc file
cat .npmrc | base64
```

Then, set the `TRIGGER_BUILD_NPM_RC` environment variable in your project settings with the encoded value.

<Note>
  The build server will automatically create a `.npmrc` file in the installation directory based on the content of the `TRIGGER_BUILD_NPM_RC` environment variable.
  This enables the build server to authenticate to your private npm registry.
</Note>


# GitHub repo
Source: https://trigger.dev/docs/github-repo



Trigger.dev is [Open Source on GitHub](https://github.com/triggerdotdev/trigger.dev). You can contribute to the project by submitting issues, pull requests, or simply by using it and providing feedback.

You can also [self-host](/open-source-self-hosting) the project if you want to run it on your own infrastructure.


# Generate and translate copy
Source: https://trigger.dev/docs/guides/ai-agents/generate-translate-copy

Create an AI agent workflow that generates and translates copy

## Overview

**Prompt chaining** is an AI workflow pattern that decomposes a complex task into a sequence of steps, where each LLM call processes the output of the previous one. This approach trades off latency for higher accuracy by making each LLM call an easier, more focused task, with the ability to add programmatic checks between steps to ensure the process remains on track.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8bc4a5c5ff644c6b7c675672d5cab313" alt="Generating and translating copy" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/prompt-chaining.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b3122be12a3e08d344331200b5beff33 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b505be00532b2e8c583a7a83d7d1ad67 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5e63269a727185873ea0d35392d8a568 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=16ad5688eac01d05220a8b20fc75af1a 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=40c58aedf4cccde7e3654e25aedc274a 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fcf4372192360767b8e1de9a50ff6340 2500w" />

## Example task

In this example, we'll create a workflow that generates and translates copy. This approach is particularly effective when tasks require different models or approaches for different inputs.

**This task:**

* Uses `generateText` from [Vercel's AI SDK](https://sdk.vercel.ai/docs/introduction) to interact with OpenAI models
* Uses `experimental_telemetry` to provide LLM logs
* Generates marketing copy based on subject and target word count
* Validates the generated copy meets word count requirements (Â±10 words)
* Translates the validated copy to the target language while preserving tone

```typescript  theme={null}
import { openai } from "@ai-sdk/openai";
import { task } from "@trigger.dev/sdk";
import { generateText } from "ai";

export interface TranslatePayload {
  marketingSubject: string;
  targetLanguage: string;
  targetWordCount: number;
}

export const generateAndTranslateTask = task({
  id: "generate-and-translate-copy",
  maxDuration: 300, // Stop executing after 5 mins of compute
  run: async (payload: TranslatePayload) => {
    // Step 1: Generate marketing copy
    const generatedCopy = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content: "You are an expert copywriter.",
        },
        {
          role: "user",
          content: `Generate as close as possible to ${payload.targetWordCount} words of compelling marketing copy for ${payload.marketingSubject}`,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "generate-and-translate-copy",
      },
    });

    // Gate: Validate the generated copy meets the word count target
    const wordCount = generatedCopy.text.split(/\s+/).length;

    if (
      wordCount < payload.targetWordCount - 10 ||
      wordCount > payload.targetWordCount + 10
    ) {
      throw new Error(
        `Generated copy length (${wordCount} words) is outside acceptable range of ${
          payload.targetWordCount - 10
        }-${payload.targetWordCount + 10} words`
      );
    }

    // Step 2: Translate to target language
    const translatedCopy = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content: `You are an expert translator specializing in marketing content translation into ${payload.targetLanguage}.`,
        },
        {
          role: "user",
          content: `Translate the following marketing copy to ${payload.targetLanguage}, maintaining the same tone and marketing impact:\n\n${generatedCopy.text}`,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "generate-and-translate-copy",
      },
    });

    return {
      englishCopy: generatedCopy,
      translatedCopy,
    };
  },
});
```

## Run a test

On the Test page in the dashboard, select the `generate-and-translate-copy` task and include a payload like the following:

```json  theme={null}
{
  marketingSubject: "The controversial new Jaguar electric concept car",
  targetLanguage: "Spanish",
  targetWordCount: 100,
}
```

This example payload generates copy and then translates it using sequential LLM calls. The translation only begins after the generated copy has been validated against the word count requirements.

<video src="https://content.trigger.dev/agent-prompt-chaining-3.mp4" controls muted autoPlay loop />


# AI agents overview
Source: https://trigger.dev/docs/guides/ai-agents/overview

Real world AI agent example tasks using Trigger.dev

## Overview

These guides will show you how to set up different types of AI agent workflows with Trigger.dev. The examples take inspiration from Anthropic's blog post on [building effective agents](https://www.anthropic.com/research/building-effective-agents).

<CardGroup cols={2}>
  <Card title="Prompt chaining" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8bc4a5c5ff644c6b7c675672d5cab313" href="/guides/ai-agents/generate-translate-copy" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/prompt-chaining.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b3122be12a3e08d344331200b5beff33 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b505be00532b2e8c583a7a83d7d1ad67 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5e63269a727185873ea0d35392d8a568 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=16ad5688eac01d05220a8b20fc75af1a 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=40c58aedf4cccde7e3654e25aedc274a 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/prompt-chaining.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fcf4372192360767b8e1de9a50ff6340 2500w">
    Chain prompts together to generate and translate marketing copy automatically
  </Card>

  <Card title="Routing" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2f586095b267c7d969afdc0a1e167071" href="/guides/ai-agents/route-question" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/routing.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=40f3589d2b62e618a7b1d792be296330 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d0cd9a0c53b7ee3fb0d7ef0e84e97936 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0e6a9e0aef55f30078825981a3f5445 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=97fc784cc9a90f4c542f7ce4423d4ea5 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2ccca06d7bf06a3fd3d07bde7fc982ef 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=371e95357260a464adb4fe5408fe6a30 2500w">
    Send questions to different AI models based on complexity analysis
  </Card>

  <Card title="Parallelization" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=385b3c71db00c3995cb3de787ef462b4" href="/guides/ai-agents/respond-and-check-content" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/parallelization.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=560093586ba22fa29ef9b31f99e9b773 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2fe3d6a2b9d9dc31804cf5ba89910849 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=84ccb0dd6586fdd84ffbed4705f8e05a 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8c036426d21172e60147fa5cb5907f6d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=03cf5a5f250bac272f7a068e7283abc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7d50bd85587ffbe8a020ad63b797e414 2500w">
    Simultaneously check for inappropriate content while responding to customer inquiries
  </Card>

  <Card title="Orchestrator" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05a71d4ef13664e4e73ed32bfd2a942c" href="/guides/ai-agents/verify-news-article" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/orchestrator-workers.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=035f5aa0c78609052e8b456d07b2b52d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4a011fa4f129882e3bb025f3ce05ef50 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccc65d7967ba73b1acfe056f8ca2935b 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=42cd3b5918af9d2254decbe1b27cd999 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b1e9b61d149c08a99e0cdea56ab25d3a 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3237a8fbb14118204277d67294f8a7e4 2500w">
    Coordinate multiple AI workers to verify news article accuracy
  </Card>

  <Card title="Evaluator-optimizer" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60942bcc65c91600a84882c90eabc016" href="/guides/ai-agents/translate-and-refine" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/evaluator-optimizer.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d38309cc661150f5d5f53d72bc52716e 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9d53fef641d7c81ab0815111c675dab1 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05ecd7d9039c13fe5c0877e584455660 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a0348eeb47d70e01de841ef2753c4c39 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5ff8bb708f22b482e1eeadc7f13697d8 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=06ab54339a2fc6ef4553e65b47d66219 2500w">
    Translate text and automatically improve quality through feedback loops
  </Card>
</CardGroup>

## Example projects using AI agents

<CardGroup cols={2}>
  <Card icon="hand" title="Human-in-the-loop workflow" href="/guides/example-projects/human-in-the-loop-workflow">
    Create audio summaries of newspaper articles using a human-in-the-loop workflow built with
    ReactFlow and Trigger.dev waitpoint tokens.
  </Card>

  <Card title="Mastra agents with memory" icon="database" href="/guides/example-projects/mastra-agents-with-memory">
    Use Mastra to create a weather agent that can collect live weather data and generate clothing
    recommendations.
  </Card>

  <Card title="OpenAI Agent Python SDK guardrails" icon="snake" href="/guides/example-projects/openai-agent-sdk-guardrails">
    Use the OpenAI Agent SDK to create a guardrails system for your AI agents.
  </Card>

  <Card title="OpenAI Agent TypeScript SDK playground" icon="rocket" href="/guides/example-projects/openai-agents-sdk-typescript-playground">
    A playground containing 7 AI agents using the OpenAI Agent SDK for TypeScript with Trigger.dev.
  </Card>

  <Card title="Vercel AI SDK deep research agent" icon="triangle" href="/guides/example-projects/vercel-ai-sdk-deep-research">
    Use the Vercel AI SDK to generate comprehensive PDF reports using a deep research agent.
  </Card>
</CardGroup>


# Respond to customer inquiry and check for inappropriate content
Source: https://trigger.dev/docs/guides/ai-agents/respond-and-check-content

Create an AI agent workflow that responds to customer inquiries while checking if their text is inappropriate

## Overview

**Parallelization** is a workflow pattern where multiple tasks or processes run simultaneously instead of sequentially, allowing for more efficient use of resources and faster overall execution. It's particularly valuable when different parts of a task can be handled independently, such as running content analysis and response generation at the same time.
<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=385b3c71db00c3995cb3de787ef462b4" alt="Parallelization" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/parallelization.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=560093586ba22fa29ef9b31f99e9b773 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2fe3d6a2b9d9dc31804cf5ba89910849 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=84ccb0dd6586fdd84ffbed4705f8e05a 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8c036426d21172e60147fa5cb5907f6d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=03cf5a5f250bac272f7a068e7283abc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/parallelization.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7d50bd85587ffbe8a020ad63b797e414 2500w" />

## Example task

In this example, we'll create a workflow that simultaneously checks content for issues while responding to customer inquiries. This approach is particularly effective when tasks require multiple perspectives or parallel processing streams, with the orchestrator synthesizing the results into a cohesive output.

**This task:**

* Uses `generateText` from [Vercel's AI SDK](https://sdk.vercel.ai/docs/introduction) to interact with OpenAI models
* Uses `experimental_telemetry` to provide LLM logs
* Uses [`batch.triggerByTaskAndWait`](/triggering#batch-triggerbytaskandwait) to run customer response and content moderation tasks in parallel
* Generates customer service responses using an AI model
* Simultaneously checks for inappropriate content while generating responses

```typescript  theme={null}
import { openai } from "@ai-sdk/openai";
import { batch, task } from "@trigger.dev/sdk";
import { generateText } from "ai";

// Task to generate customer response
export const generateCustomerResponse = task({
  id: "generate-customer-response",
  run: async (payload: { question: string }) => {
    const response = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content: "You are a helpful customer service representative.",
        },
        { role: "user", content: payload.question },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "generate-customer-response",
      },
    });

    return response.text;
  },
});

// Task to check for inappropriate content
export const checkInappropriateContent = task({
  id: "check-inappropriate-content",
  run: async (payload: { text: string }) => {
    const response = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content:
            "You are a content moderator. Respond with 'true' if the content is inappropriate or contains harmful, threatening, offensive, or explicit content, 'false' otherwise.",
        },
        { role: "user", content: payload.text },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "check-inappropriate-content",
      },
    });

    return response.text.toLowerCase().includes("true");
  },
});

// Main task that coordinates the parallel execution
export const handleCustomerQuestion = task({
  id: "handle-customer-question",
  run: async (payload: { question: string }) => {
    const {
      runs: [responseRun, moderationRun],
    } = await batch.triggerByTaskAndWait([
      {
        task: generateCustomerResponse,
        payload: { question: payload.question },
      },
      {
        task: checkInappropriateContent,
        payload: { text: payload.question },
      },
    ]);

    // Check moderation result first
    if (moderationRun.ok && moderationRun.output === true) {
      return {
        response:
          "I apologize, but I cannot process this request as it contains inappropriate content.",
        wasInappropriate: true,
      };
    }

    // Return the generated response if everything is ok
    if (responseRun.ok) {
      return {
        response: responseRun.output,
        wasInappropriate: false,
      };
    }

    // Handle any errors
    throw new Error("Failed to process customer question");
  },
});
```

## Run a test

On the Test page in the dashboard, select the `handle-customer-question` task and include a payload like the following:

```json  theme={null}
{
  "question": "Can you explain 2FA?"
}
```

When triggered with a question, the task simultaneously generates a response while checking for inappropriate content using two parallel LLM calls. The main task waits for both operations to complete before delivering the final response.

<video src="https://content.trigger.dev/agent-parallelization.mp4" controls muted autoPlay loop />


# Route a question to a different AI model
Source: https://trigger.dev/docs/guides/ai-agents/route-question

Create an AI agent workflow that routes a question to a different AI model depending on its complexity

## Overview

**Routing** is a workflow pattern that classifies an input and directs it to a specialized followup task. This pattern allows for separation of concerns and building more specialized prompts, which is particularly effective when there are distinct categories that are better handled separately. Without routing, optimizing for one kind of input can hurt performance on other inputs.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2f586095b267c7d969afdc0a1e167071" alt="Routing" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/routing.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=40f3589d2b62e618a7b1d792be296330 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d0cd9a0c53b7ee3fb0d7ef0e84e97936 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0e6a9e0aef55f30078825981a3f5445 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=97fc784cc9a90f4c542f7ce4423d4ea5 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2ccca06d7bf06a3fd3d07bde7fc982ef 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/routing.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=371e95357260a464adb4fe5408fe6a30 2500w" />

## Example task

In this example, we'll create a workflow that routes a question to a different AI model depending on its complexity. This approach is particularly effective when tasks require different models or approaches for different inputs.

**This task:**

* Uses `generateText` from [Vercel's AI SDK](https://sdk.vercel.ai/docs/introduction) to interact with OpenAI models
* Uses `experimental_telemetry` in the source verification and historical analysis tasks to provide LLM logs
* Routes questions using a lightweight model (`o1-mini`) to classify complexity
* Directs simple questions to `gpt-4o` and complex ones to `gpt-o3-mini`
* Returns both the answer and metadata about the routing decision

````typescript  theme={null}
import { openai } from "@ai-sdk/openai";
import { task } from "@trigger.dev/sdk";
import { generateText } from "ai";
import { z } from "zod";

// Schema for router response
const routingSchema = z.object({
  model: z.enum(["gpt-4o", "gpt-o3-mini"]),
  reason: z.string(),
});

// Router prompt template
const ROUTER_PROMPT = `You are a routing assistant that determines the complexity of questions.
Analyze the following question and route it to the appropriate model:

- Use "gpt-4o" for simple, common, or straightforward questions
- Use "gpt-o3-mini" for complex, unusual, or questions requiring deep reasoning

Respond with a JSON object in this exact format:
{"model": "gpt-4o" or "gpt-o3-mini", "reason": "your reasoning here"}

Question: `;

export const routeAndAnswerQuestion = task({
  id: "route-and-answer-question",
  run: async (payload: { question: string }) => {
    // Step 1: Route the question
    const routingResponse = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content:
            "You must respond with a valid JSON object containing only 'model' and 'reason' fields. No markdown, no backticks, no explanation.",
        },
        {
          role: "user",
          content: ROUTER_PROMPT + payload.question,
        },
      ],
      temperature: 0.1,
      experimental_telemetry: {
        isEnabled: true,
        functionId: "route-and-answer-question",
      },
    });

    // Add error handling and cleanup
    let jsonText = routingResponse.text.trim();
    if (jsonText.startsWith("```")) {
      jsonText = jsonText.replace(/```json\n|\n```/g, "");
    }

    const routingResult = routingSchema.parse(JSON.parse(jsonText));

    // Step 2: Get the answer using the selected model
    const answerResult = await generateText({
      model: openai(routingResult.model),
      messages: [{ role: "user", content: payload.question }],
    });

    return {
      answer: answerResult.text,
      selectedModel: routingResult.model,
      routingReason: routingResult.reason,
    };
  },
});
````

## Run a test

Triggering our task with a simple question shows it routing to the gpt-4o model and returning the answer with reasoning:

```json  theme={null}
{
  "question": "How many planets are there in the solar system?"
}
```

<video src="https://content.trigger.dev/agent-routing.mp4" controls muted autoPlay loop />


# Translate text and refine it based on feedback
Source: https://trigger.dev/docs/guides/ai-agents/translate-and-refine

This guide will show you how to create a task that translates text and refines it based on feedback.

## Overview

This example is based on the **evaluator-optimizer** pattern, where one LLM generates a response while another provides evaluation and feedback in a loop. This is particularly effective for tasks with clear evaluation criteria where iterative refinement provides better results.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60942bcc65c91600a84882c90eabc016" alt="Evaluator-optimizer" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/evaluator-optimizer.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d38309cc661150f5d5f53d72bc52716e 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9d53fef641d7c81ab0815111c675dab1 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05ecd7d9039c13fe5c0877e584455660 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a0348eeb47d70e01de841ef2753c4c39 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5ff8bb708f22b482e1eeadc7f13697d8 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/evaluator-optimizer.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=06ab54339a2fc6ef4553e65b47d66219 2500w" />

## Example task

This example task translates text into a target language and refines the translation over a number of iterations based on feedback provided by the LLM.

**This task:**

* Uses `generateText` from [Vercel's AI SDK](https://sdk.vercel.ai/docs/introduction) to generate the translation
* Uses `experimental_telemetry` to provide LLM logs on the Run page in the dashboard
* Runs for a maximum of 10 iterations
* Uses `generateText` again to evaluate the translation
* Recursively calls itself to refine the translation based on the feedback

```typescript  theme={null}
import { task } from "@trigger.dev/sdk";
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

interface TranslationPayload {
  text: string;
  targetLanguage: string;
  previousTranslation?: string;
  feedback?: string;
  rejectionCount?: number;
}

export const translateAndRefine = task({
  id: "translate-and-refine",
  run: async (payload: TranslationPayload) => {
    const rejectionCount = payload.rejectionCount || 0;

    // Bail out if we've hit the maximum attempts
    if (rejectionCount >= 10) {
      return {
        finalTranslation: payload.previousTranslation,
        iterations: rejectionCount,
        status: "MAX_ITERATIONS_REACHED",
      };
    }

    // Generate translation (or refinement if we have previous feedback)
    const translationPrompt = payload.feedback
      ? `Previous translation: "${payload.previousTranslation}"\n\nFeedback received: "${payload.feedback}"\n\nPlease provide an improved translation addressing this feedback.`
      : `Translate this text into ${payload.targetLanguage}, preserving style and meaning: "${payload.text}"`;

    const translation = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content: `You are an expert literary translator into ${payload.targetLanguage}.
                   Focus on accuracy first, then style and natural flow.`,
        },
        {
          role: "user",
          content: translationPrompt,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "translate-and-refine",
      },
    });

    // Evaluate the translation
    const evaluation = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content: `You are an expert literary critic and translator focused on practical, high-quality translations.
                 Your goal is to ensure translations are accurate and natural, but not necessarily perfect.
                 This is iteration ${
                   rejectionCount + 1
                 } of a maximum 5 iterations.
                 
                 RESPONSE FORMAT:
                 - If the translation meets 90%+ quality: Respond with exactly "APPROVED" (nothing else)
                 - If improvements are needed: Provide only the specific issues that must be fixed
                 
                 Evaluation criteria:
                 - Accuracy of meaning (primary importance)
                 - Natural flow in the target language
                 - Preservation of key style elements
                 
                 DO NOT provide detailed analysis, suggestions, or compliments.
                 DO NOT include the translation in your response.
                 
                 IMPORTANT RULES:
                 - First iteration MUST receive feedback for improvement
                 - Be very strict on accuracy in early iterations
                 - After 3 iterations, lower quality threshold to 85%`,
        },
        {
          role: "user",
          content: `Original: "${payload.text}"
                 Translation: "${translation.text}"
                 Target Language: ${payload.targetLanguage}
                 Iteration: ${rejectionCount + 1}
                 Previous Feedback: ${
                   payload.feedback ? `"${payload.feedback}"` : "None"
                 }
                 
                 ${
                   rejectionCount === 0
                     ? "This is the first attempt. Find aspects to improve."
                     : 'Either respond with exactly "APPROVED" or provide only critical issues that must be fixed.'
                 }`,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "translate-and-refine",
      },
    });

    // If approved, return the final result
    if (evaluation.text.trim() === "APPROVED") {
      return {
        finalTranslation: translation.text,
        iterations: rejectionCount,
        status: "APPROVED",
      };
    }

    // If not approved, recursively call the task with feedback
    await translateAndRefine
      .triggerAndWait({
        text: payload.text,
        targetLanguage: payload.targetLanguage,
        previousTranslation: translation.text,
        feedback: evaluation.text,
        rejectionCount: rejectionCount + 1,
      })
      .unwrap();
  },
});
```

## Run a test

On the Test page in the dashboard, select the `translate-and-refine` task and include a payload like the following:

```json  theme={null}
{
  "text": "In the twilight of his years, the old clockmaker's hands, once steady as the timepieces he crafted, now trembled like autumn leaves in the wind.",
  "targetLanguage": "French"
}
```

This example payload translates the text into French and should be suitably difficult to require a few iterations, depending on the model used and the prompt criteria you set.

<video src="https://content.trigger.dev/agent-evaluator-optimizer.mp4" controls muted autoPlay loop />


# Verify a news article
Source: https://trigger.dev/docs/guides/ai-agents/verify-news-article

Create an AI agent workflow that verifies the facts in a news article

## Overview

This example demonstrates the **orchestrator-workers** pattern, where a central AI agent dynamically breaks down complex tasks and delegates them to specialized worker agents. This pattern is particularly effective when tasks require multiple perspectives or parallel processing streams, with the orchestrator synthesizing the results into a cohesive output.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=05a71d4ef13664e4e73ed32bfd2a942c" alt="Orchestrator" data-og-width="1293" width="1293" data-og-height="428" height="428" data-path="guides/ai-agents/orchestrator-workers.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=035f5aa0c78609052e8b456d07b2b52d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4a011fa4f129882e3bb025f3ce05ef50 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccc65d7967ba73b1acfe056f8ca2935b 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=42cd3b5918af9d2254decbe1b27cd999 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b1e9b61d149c08a99e0cdea56ab25d3a 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/guides/ai-agents/orchestrator-workers.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3237a8fbb14118204277d67294f8a7e4 2500w" />

## Example task

Our example task uses multiple LLM calls to extract claims from a news article and analyze them in parallel, combining source verification and historical context to assess their credibility.

**This task:**

* Uses `generateText` from [Vercel's AI SDK](https://sdk.vercel.ai/docs/introduction) to interact with OpenAI models
* Uses `experimental_telemetry` to provide LLM logs
* Uses [`batch.triggerByTaskAndWait`](/triggering#batch-triggerbytaskandwait) to orchestrate parallel processing of claims
* Extracts factual claims from news articles using the `o1-mini` model
* Evaluates claims against recent sources and analyzes historical context in parallel
* Combines results into a structured analysis report

```typescript  theme={null}
import { openai } from "@ai-sdk/openai";
import { batch, logger, task } from "@trigger.dev/sdk";
import { CoreMessage, generateText } from "ai";

// Define types for our workers' outputs
interface Claim {
  id: number;
  text: string;
}

interface SourceVerification {
  claimId: number;
  isVerified: boolean;
  confidence: number;
  explanation: string;
}

interface HistoricalAnalysis {
  claimId: number;
  feasibility: number;
  historicalContext: string;
}

// Worker 1: Claim Extractor
export const extractClaims = task({
  id: "extract-claims",
  run: async ({ article }: { article: string }) => {
    try {
      const messages: CoreMessage[] = [
        {
          role: "system",
          content:
            "Extract distinct factual claims from the news article. Format as numbered claims.",
        },
        {
          role: "user",
          content: article,
        },
      ];

      const response = await generateText({
        model: openai("o1-mini"),
        messages,
      });

      const claims = response.text
        .split("\n")
        .filter((line: string) => line.trim())
        .map((claim: string, index: number) => ({
          id: index + 1,
          text: claim.replace(/^\d+\.\s*/, ""),
        }));

      logger.info("Extracted claims", { claimCount: claims.length });
      return claims;
    } catch (error) {
      logger.error("Error in claim extraction", {
        error: error instanceof Error ? error.message : "Unknown error",
      });
      throw error;
    }
  },
});

// Worker 2: Source Verifier
export const verifySource = task({
  id: "verify-source",
  run: async (claim: Claim) => {
    const response = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content:
            "Verify this claim by considering recent news sources and official statements. Assess reliability.",
        },
        {
          role: "user",
          content: claim.text,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "verify-source",
      },
    });

    return {
      claimId: claim.id,
      isVerified: false,
      confidence: 0.7,
      explanation: response.text,
    };
  },
});

// Worker 3: Historical Context Analyzer
export const analyzeHistory = task({
  id: "analyze-history",
  run: async (claim: Claim) => {
    const response = await generateText({
      model: openai("o1-mini"),
      messages: [
        {
          role: "system",
          content:
            "Analyze this claim in historical context, considering past announcements and technological feasibility.",
        },
        {
          role: "user",
          content: claim.text,
        },
      ],
      experimental_telemetry: {
        isEnabled: true,
        functionId: "analyze-history",
      },
    });

    return {
      claimId: claim.id,
      feasibility: 0.8,
      historicalContext: response.text,
    };
  },
});

// Orchestrator
export const newsFactChecker = task({
  id: "news-fact-checker",
  run: async ({ article }: { article: string }) => {
    // Step 1: Extract claims
    const claimsResult = await batch.triggerByTaskAndWait([
      { task: extractClaims, payload: { article } },
    ]);

    if (!claimsResult.runs[0].ok) {
      logger.error("Failed to extract claims", {
        error: claimsResult.runs[0].error,
        runId: claimsResult.runs[0].id,
      });
      throw new Error(
        `Failed to extract claims: ${claimsResult.runs[0].error}`
      );
    }

    const claims = claimsResult.runs[0].output;

    // Step 2: Process claims in parallel
    const parallelResults = await batch.triggerByTaskAndWait([
      ...claims.map((claim) => ({ task: verifySource, payload: claim })),
      ...claims.map((claim) => ({ task: analyzeHistory, payload: claim })),
    ]);

    // Split and process results
    const verifications = parallelResults.runs
      .filter(
        (run): run is typeof run & { ok: true } =>
          run.ok && run.taskIdentifier === "verify-source"
      )
      .map((run) => run.output as SourceVerification);

    const historicalAnalyses = parallelResults.runs
      .filter(
        (run): run is typeof run & { ok: true } =>
          run.ok && run.taskIdentifier === "analyze-history"
      )
      .map((run) => run.output as HistoricalAnalysis);

    return { claims, verifications, historicalAnalyses };
  },
});
```

## Run a test

On the Test page in the dashboard, select the `news-fact-checker` task and include a payload like the following:

```json  theme={null}
{
  "article": "Tesla announced a new breakthrough in battery technology today. The company claims their new batteries will have 50% more capacity and cost 30% less to produce. Elon Musk stated this development will enable electric vehicles to achieve price parity with gasoline cars by 2024. The new batteries are scheduled to enter production next quarter at the Texas Gigafactory."
}
```

This example payload verifies the claims in the news article and provides a report on the results.

<video src="https://content.trigger.dev/agent-orchestrator-workers.mp4" controls muted autoPlay loop />


# dotenvx
Source: https://trigger.dev/docs/guides/community/dotenvx

A dotenvx package for Trigger.dev.

This is a community developed package from [dotenvx](https://dotenvx.com/) that enables you to use dotenvx with Trigger.dev.

[View the docs](https://dotenvx.com/docs/background-jobs/triggerdotdev)


# Fatima
Source: https://trigger.dev/docs/guides/community/fatima

A Fatima package for Trigger.dev.

This is a community developed package from [@Fgc17](https://github.com/Fgc17) that enables you to use Fatima with Trigger.dev.

[View the Fatima docs](https://fatimajs.vercel.app/docs/adapters/trigger)

[View the repo](https://github.com/Fgc17/fatima)


# Rate limiter
Source: https://trigger.dev/docs/guides/community/rate-limiter

A rate limiter for Trigger.dev.

This is a community developed package from [@ian](https://github.com/ian) that uses Redis to rate limit Trigger.dev tasks.

[View the repo](https://github.com/ian/trigger-rate-limiting)


# SvelteKit setup guide
Source: https://trigger.dev/docs/guides/community/sveltekit

A plugin for SvelteKit to integrate with Trigger.dev.

export const framework_0 = "SvelteKit"

This is a community developed Vite plugin from [@cptCrunch\_](https://x.com/cptCrunch_) that enables seamless integration between SvelteKit and Trigger.dev by allowing you to use your SvelteKit functions directly in your Trigger.dev projects.

## Features

* Use SvelteKit functions directly in Trigger.dev tasks
* Automatic function discovery and export
* TypeScript support with type preservation
* Works with Trigger.dev V3
* Configurable directory scanning

## Prerequisites

* Setup a project in {framework_0}
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## Setup

[View setup guide on npm](https://www.npmjs.com/package/triggerkit)

```bash  theme={null}
npm i triggerkit
```

<UsefulNextSteps />


# Automated website monitoring with Anchor Browser
Source: https://trigger.dev/docs/guides/example-projects/anchor-browser-web-scraper

Automated web monitoring using Trigger.dev's task scheduling and Anchor Browser's AI-powered browser automation.

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

## Overview

This example demonstrates automated web monitoring using Trigger.dev's task scheduling and Anchor Browser's AI-powered browser automation tools.

The task runs daily at 5pm ET to find the cheapest Broadway tickets available for same-day shows.

**How it works:**

* Trigger.dev schedules and executes the monitoring task
* Anchor Browser spins up a remote browser session with an AI agent
* The AI agent uses computer vision and natural language processing to analyze the TDF website
* AI agent returns the lowest-priced show with specific details: name, price, and showtime

## Tech stack

* **[Node.js](https://nodejs.org)** runtime environment (version 18.2 or higher)
* **[Trigger.dev](https://trigger.dev)** for task scheduling and task orchestration
* **[Anchor Browser](https://anchorbrowser.io/)** for AI-powered browser automation
* **[Playwright](https://playwright.dev/)** for browser automation libraries (handled via external dependencies)

## GitHub repo

<Card title="View the Anchor Browser web scraper repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/anchor-browser-web-scraper">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Relevant code

### Broadway ticket monitor task

This task runs daily at 5pm ET, in [src/trigger/broadway-monitor.ts](https://github.com/triggerdotdev/examples/tree/main/anchor-browser-web-scraper/src/trigger/broadway-monitor.ts):

```ts  theme={null}
import { schedules } from "@trigger.dev/sdk";
import Anchorbrowser from "anchorbrowser";

export const broadwayMonitor = schedules.task({
  id: "broadway-ticket-monitor",
  cron: "0 21 * * *",
  run: async (payload, { ctx }) => {
    const client = new Anchorbrowser({
      apiKey: process.env.ANCHOR_BROWSER_API_KEY!,
    });

    let session;
    try {
      // Create explicit session to get live view URL
      session = await client.sessions.create();
      console.log(`Session ID: ${session.data.id}`);
      console.log(`Live View URL: https://live.anchorbrowser.io?sessionId=${session.data.id}`);

      const response = await client.tools.performWebTask({
        sessionId: session.data.id,
        url: "https://www.tdf.org/discount-ticket-programs/tkts-by-tdf/tkts-live/",
        prompt: `Look for the "Broadway Shows" section on this page. Find the show with the absolute lowest starting price available right now and return the show name, current lowest price, and show time. Be very specific about the current price you see. Format as: Show: [name], Price: [exact current price], Time: [time]`,
      });

      console.log("Raw response:", response);

      const result = response.data.result?.result || response.data.result || response.data;

      if (result && typeof result === "string" && result.includes("Show:")) {
        console.log(`ðŸŽ­ Best Broadway Deal Found!`);
        console.log(result);

        return {
          success: true,
          bestDeal: result,
          liveViewUrl: `https://live.anchorbrowser.io?sessionId=${session.data.id}`,
        };
      } else {
        console.log("No Broadway deals found today");
        return { success: true, message: "No deals found" };
      }
    } finally {
      if (session?.data?.id) {
        try {
          await client.sessions.delete(session.data.id);
        } catch (cleanupError) {
          console.warn("Failed to cleanup session:", cleanupError);
        }
      }
    }
  },
});
```

### Build configuration

Since Anchor Browser uses browser automation libraries (Playwright) under the hood, we need to configure Trigger.dev to handle these dependencies properly by excluding them from the build bundle in [trigger.config.ts](https://github.com/triggerdotdev/examples/tree/main/anchor-browser-web-scraper/trigger.config.ts):

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "proj_your_project_id_here", // Get from Trigger.dev dashboard
  maxDuration: 3600, // 1 hour - plenty of time for web automation
  dirs: ["./src/trigger"],
  build: {
    external: ["playwright-core", "playwright", "chromium-bidi"],
  },
});
```

## Learn more

* View the [Anchor Browser docs](https://anchorbrowser.io/docs) to learn more about Anchor Browser's AI-powered browser automation tools.
* Check out the source code for the [Anchor Browser web scraper repo](https://github.com/triggerdotdev/examples/tree/main/anchor-browser-web-scraper) on GitHub.
* Browser our [example projects](/guides/introduction) to see how you can use Trigger.dev with other services.


# Next.js Batch LLM Evaluator
Source: https://trigger.dev/docs/guides/example-projects/batch-llm-evaluator

This example Next.js project evaluates multiple LLM models using the Vercel AI SDK and streams updates to the frontend using Trigger.dev Realtime.

## Overview

This demo is a full stack example that uses the following:

* A [Next.js](https://nextjs.org/) app with [Prisma](https://www.prisma.io/) for the database.
* Trigger.dev [Realtime](https://trigger.dev/launchweek/0/realtime) to stream updates to the frontend.
* Work with multiple LLM models using the Vercel [AI SDK](https://sdk.vercel.ai/docs/introduction). (OpenAI, Anthropic, XAI)
* Distribute tasks across multiple tasks using the new [`batch.triggerByTaskAndWait`](https://trigger.dev/docs/triggering#batch-triggerbytaskandwait) method.

## GitHub repo

<Card title="View the Batch LLM Evaluator repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/batch-llm-evaluator">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://content.trigger.dev/batch-llm-evaluator.mp4" />

## Relevant code

* View the Trigger.dev task code in the [src/trigger/batch.ts](https://github.com/triggerdotdev/examples/blob/main/batch-llm-evaluator/src/trigger/batch.ts) file.
* The `evaluateModels` task uses the `batch.triggerByTaskAndWait` method to distribute the task to the different LLM models.
* It then passes the results through to a `summarizeEvals` task that calculates some dummy "tags" for each LLM response.
* We use a [useRealtimeRunsWithTag](/realtime/react-hooks/subscribe#userealtimerunswithtag) hook to subscribe to the different evaluation tasks runs in the [src/components/llm-evaluator.tsx](https://github.com/triggerdotdev/examples/blob/main/batch-llm-evaluator/src/components/llm-evaluator.tsx) file.
* We then pass the relevant run down into three different components for the different models:
  * The `AnthropicEval` component: [src/components/evals/Anthropic.tsx](https://github.com/triggerdotdev/examples/blob/main/batch-llm-evaluator/src/components/evals/Anthropic.tsx)
  * The `XAIEval` component: [src/components/evals/XAI.tsx](https://github.com/triggerdotdev/examples/blob/main/batch-llm-evaluator/src/components/evals/XAI.tsx)
  * The `OpenAIEval` component: [src/components/evals/OpenAI.tsx](https://github.com/triggerdotdev/examples/blob/main/batch-llm-evaluator/src/components/evals/OpenAI.tsx)
* Each of these components then uses [useRealtimeRunWithStreams](/realtime/react-hooks/streams#userealtimerunwithstreams) to subscribe to the different LLM responses.

<Note>
  This example uses the older `useRealtimeRunWithStreams` hook. For new projects, consider using the new [`useRealtimeStream`](/realtime/react-hooks/streams#userealtimestream-recommended) hook (SDK 4.1.0+) for a simpler API and better type safety with defined streams.
</Note>

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Claude 3.7 thinking chatbot
Source: https://trigger.dev/docs/guides/example-projects/claude-thinking-chatbot

This example Next.js project uses Vercel's AI SDK and Anthropic's Claude 3.7 model to create a thinking chatbot.

## Overview

This demo is a full stack example that uses the following:

* A [Next.js](https://nextjs.org/) app for the chat interface
* [Trigger.dev Realtime](/realtime/overview) to stream AI responses and thinking/reasoning process to the frontend
* [Claude 3.7 Sonnet](https://www.anthropic.com/claude) for generating AI responses
* [AI SDK](https://sdk.vercel.ai/docs/introduction) for working with the Claude model

## GitHub repo

<Card title="View the Claude thinking chatbot repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/claude-thinking-chatbot">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/053739a5-9736-4cb5-ab1c-81c35b69f4c4" />

## Relevant code

* **Claude Stream Task**: View the Trigger.dev task code in the [src/trigger/claude-stream.ts](https://github.com/triggerdotdev/examples/tree/main/claude-thinking-chatbot/src/trigger/claude-stream.ts) file, which sets up the streaming connection with Claude.
* **Chat Component**: The main chat interface is in [app/components/claude-chat.tsx](https://github.com/triggerdotdev/examples/tree/main/claude-thinking-chatbot/app/components/claude-chat.tsx), which handles:
  * Message state management
  * User input handling
  * Rendering of message bubbles
  * Integration with Trigger.dev for streaming
* **Stream Response**: The `StreamResponse` component within the chat component handles:
  * Displaying streaming text from Claude
  * Showing/hiding the thinking process with an animated toggle
  * Auto-scrolling as new content arrives

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Human-in-the-loop workflow with ReactFlow and Trigger.dev waitpoint tokens
Source: https://trigger.dev/docs/guides/example-projects/human-in-the-loop-workflow

This example project creates audio summaries of newspaper articles using a human-in-the-loop workflow built with ReactFlow and Trigger.dev waitpoint tokens.

## Overview

This demo is a full stack example that uses the following:

* [Next.js](https://nextjs.org/) for the web application
* [ReactFlow](https://reactflow.dev/) for the workflow UI
* [Trigger.dev Realtime](/realtime/overview) to subscribe to task runs and show the real-time status of the workflow steps
* [Trigger.dev waitpoint tokens](/wait-for-token) to create a human-in-the-loop flow with a review step
* [OpenAI API](https://openai.com/api/) to generate article summaries
* [ElevenLabs](https://elevenlabs.io/text-to-speech) to convert text to speech

## GitHub repo

<Card title="View the human-in-the-loop workflow repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/article-summary-workflow">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://content.trigger.dev/reactflow-waitpoints-example.mov" />

## Relevant code

Each node in the workflow corresponds to a Trigger.dev task. The idea is to enable building flows by composition of different tasks. The output of one task serves as input for another.

* **Trigger.dev task splitting**:
  * The [summarizeArticle](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/trigger/summarizeArticle.ts) task uses the OpenAI API to generate a summary an article.
  * The [convertTextToSpeech](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/trigger/convertTextToSpeech.ts) task uses the ElevenLabs API to convert the summary into an audio stream and upload it to an S3 bucket.
  * The [reviewSummary](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/trigger/reviewSummary.ts) task is a human-in-the-loop step that shows the result and waits for approval of the summary before continuing.
  * [articleWorkflow](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/trigger/articleWorkflow.ts) is the entrypoint that ties the workflow together and orchestrates the tasks. You might choose to approach the orchestration differently, depending on your use case.
* **ReactFlow Nodes**: there are three types of nodes in this example. All of them are custom ReactFlow nodes.
  * The [InputNode](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/components/InputNode.tsx) is the starting node of the workflow. It triggers the workflow by submitting an article URL.
  * The [ActionNode](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/components/ActionNode.tsx) is a node that shows the status of a task run in Trigger.dev, in real-time using the React hooks for Trigger.dev.
  * The [ReviewNode](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/components/ReviewNode.tsx) is a node that shows the summary result and prompts the user for approval before continuing. It uses the Realtime API to fetch details about the review status. Also, it interacts with the Trigger.dev waitpoint API for completing the waitpoint token using Next.js server actions.
* **Workflow orchestration**:
  * The workflow is orchestrated by the [Flow](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/components/Flow.tsx) component. It lays out the nodes, the connections between them, as well as the mapping to the Trigger.dev tasks.
    It also uses the `useRealtimeRunsWithTag` hook to subscribe to task runs associated with the workflow and passes down the run details to the nodes.

The waitpoint token is created in [a Next.js server action](https://github.com/triggerdotdev/examples/blob/main/article-summary-workflow/src/app/actions.ts#L26):

```ts  theme={null}
const reviewWaitpointToken = await wait.createToken({
  tags: [workflowTag],
  timeout: "1h",
  idempotencyKey: `review-summary-${workflowTag}`,
});
```

and later completed in another server action in the same file:

```ts  theme={null}
await wait.completeToken<ReviewPayload>(
  { id: tokenId },
  {
    approved: true,
    approvedAt: new Date(),
    approvedBy: user,
  }
);
```

While the workflow in this example is static and does not allow changing the connections between nodes in the UI, it serves as a good baseline for understanding how to build completely custom workflow builders using Trigger.dev and ReactFlow.

## Learn more about Trigger.dev Realtime and waitpoint tokens

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API
* [Waitpoint tokens](/wait-for-token) - learn about waitpoint tokens in Trigger.dev and human-in-the-loop flows


# Mastra agents with memory sharing + Trigger.dev task orchestration
Source: https://trigger.dev/docs/guides/example-projects/mastra-agents-with-memory

Multi-agent workflow with persistent memory sharing using Mastra and Trigger.dev for clothing recommendations based on weather data.

## Overview

Enter a city and an activity, and get a clothing recommendation generated for you based on today's weather.

![Generated clothing recommendations](https://github.com/user-attachments/assets/edfca304-6b22-4fa8-9362-71ecb3fe4903)

By combining Mastra's persistent memory system and agent orchestration with Trigger.dev's durable task execution, retries and observability, you get production-ready AI workflows that survive failures, scale automatically, and maintain context across long-running operations.

## Tech stack

* **[Node.js](https://nodejs.org)** runtime environment
* **[Mastra](https://mastra.ai)** for AI agent orchestration and memory management (Mastra is a Typescript framework for building AI agents, and uses Vercel's AI Agent SDK under the hood.)
* **[PostgreSQL](https://postgresql.org)** for persistent storage and memory sharing
* **[Trigger.dev](https://trigger.dev)** for task orchestration, batching, and observability
* **[OpenAI GPT-4](https://openai.com)** for natural language processing
* **[Open-Meteo API](https://open-meteo.com)** for weather data (no API key required)
* **[Zod](https://zod.dev)** for schema validation and type safety

## GitHub repo

<Card title="View the Mastra agents with memory repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/mastra-agents">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Featured patterns

* **[Agent Memory Sharing](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/trigger/weather-task.ts)**: Efficient data sharing between agents using Mastra's working memory system
* **[Task Orchestration](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/trigger/weather-task.ts)**: Multi-step workflows with `triggerAndWait` for sequential agent execution
* **[Centralized Storage](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/index.ts)**: Single PostgreSQL storage instance shared across all agents to prevent connection duplication
* **[Custom Tools](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/tools/weather-tool.ts)**: External API integration with structured output validation
* **[Agent Specialization](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/agents/)**: Purpose-built agents with specific roles and instructions
* **[Schema Optimization](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/schemas/weather-data.ts)**: Lightweight data structures for performance

## Project Structure

```
src/
â”œâ”€â”€ mastra/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ weather-analyst.ts    # Weather data collection
â”‚   â”‚   â”œâ”€â”€ clothing-advisor.ts   # Clothing recommendations
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ weather-tool.ts       # Enhanced weather API tool
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ weather-data.ts       # Weather schema
â”‚   â””â”€â”€ index.ts                  # Mastra configuration
â”œâ”€â”€ trigger/
â”‚   â””â”€â”€ weather-task.ts           # Trigger.dev tasks
```

## Relevant code

* **[Multi-step task orchestration](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/trigger/weather-task.ts)**: Multi-step task orchestration with `triggerAndWait` for sequential agent execution and shared memory context
* **[Weather analyst agent](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/agents/weather-analyst.ts)**: Specialized agent for weather data collection with external API integration and memory storage
* **[Clothing advisor agent](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/agents/clothing-advisor.ts)**: Purpose-built agent that reads from working memory and generates natural language responses
* **[Weather tool](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/tools/weather-tool.ts)**: Custom Mastra tool with Zod validation for external API calls and error handling
* **[Weather data schema](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/schemas/weather-data.ts)**: Optimized Zod schema for efficient memory storage and type safety
* **[Mastra configuration](https://github.com/triggerdotdev/examples/blob/main/mastra-agents/src/mastra/index.ts)**: Mastra configuration with PostgreSQL storage and agent registration

## Storage Architecture

This project uses a **centralized PostgreSQL storage** approach where a single database connection is shared across all Mastra agents. This prevents duplicate database connections and ensures efficient memory sharing between the weather analyst and clothing advisor agents.

### Storage Configuration

The storage is configured once in the main Mastra instance (`src/mastra/index.ts`) and automatically inherited by all agent Memory instances. This eliminates the "duplicate database object" warning that can occur with multiple PostgreSQL connections.

The PostgreSQL storage works seamlessly in both local development and serverless environments with any PostgreSQL provider, such as:

* [Local PostgreSQL instance](https://postgresql.org)
* [Supabase](https://supabase.com) - Serverless PostgreSQL
* [Neon](https://neon.tech) - Serverless PostgreSQL
* [Railway](https://railway.app) - Simple PostgreSQL hosting
* [AWS RDS](https://aws.amazon.com/rds/postgresql/) - Managed PostgreSQL

## Learn More

To learn more about the technologies used in this project, check out the following resources:

* [Mastra docs](https://mastra.ai/en/docs) - learn about AI agent orchestration and memory management
* [Mastra working memory](https://mastra.ai/en/docs/memory/overview) - learn about efficient data sharing between agents


# Meme generator with human-in-the-loop approval
Source: https://trigger.dev/docs/guides/example-projects/meme-generator-human-in-the-loop

This example project creates memes using OpenAI's DALL-E 3 with a human-in-the-loop approval workflow built using Trigger.dev waitpoint tokens.

## Overview

This demo is a full stack example that uses the following:

* A [Next.js](https://nextjs.org/) app, with an [endpoint](https://github.com/triggerdotdev/examples/blob/main/meme-generator-human-in-the-loop/src/app/endpoints/\[slug]/page.tsx) for approving the generated memes
* [Trigger.dev](https://trigger.dev) tasks to generate the images and orchestrate the waitpoint workflow
* [OpenAI DALL-E 3](https://platform.openai.com/docs/guides/images) for generating the images
* A [Slack app](https://api.slack.com/quickstart) for the human-in-the-loop step, with the approval buttons linked to the endpoint

## GitHub repo

<Card title="View the meme generator human-in-the-loop example repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/meme-generator-human-in-the-loop">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Post to Slack

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b1f4a27701fd8f2899e4454f7bb72e91" alt="Meme Generator with Human-in-the-Loop Approval" data-og-width="1073" width="1073" data-og-height="900" height="900" data-path="images/slack-meme-approval.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cdc950328aa47c2b6bc01350bca4ee98 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a4a89e890e1380f99abad6142284dd44 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=661bae7ff1423a52296186cac080e225 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=df8f583f34558590e910bfdce86d3f28 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3628c0b4def34c6423ac6f09464bd3ed 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/slack-meme-approval.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4f9d0357cc10f5c9f5e57203987102c5 2500w" />

## Relevant code

* **Meme generator task**:

  * The [memegenerator.ts](https://github.com/triggerdotdev/examples/blob/main/meme-generator-human-in-the-loop/src/trigger/memegenerator.ts) task:
    * Generates two meme variants using DALL-E 3
    * Uses [batchTriggerAndWait](/triggering#yourtask-batchtriggerandwait) to generate multiple meme variants simultaneously (this is because you can only generate 1 image at a time with DALL-E 3)
    * Creates a [waitpoint token](/wait-for-token)
    * Sends the generated images with approval buttons to Slack for review
    * Handles the approval workflow

* **Approval Endpoint**:
  * The waitpoint approval handling is in [page.tsx](https://github.com/triggerdotdev/examples/blob/main/meme-generator-human-in-the-loop/src/app/endpoints/\[slug]/page.tsx), which processes:
    * User selections from Slack buttons
    * Waitpoint completion with the chosen meme variant
    * Success/failure feedback to the approver

## Learn more

To learn more, take a look at the following resources:

* [Waitpoint tokens](/wait-for-token) - learn about waitpoint tokens in Trigger.dev and human-in-the-loop flows
* [OpenAI DALL-E API](https://platform.openai.com/docs/guides/images) - learn about the DALL-E image generation API
* [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API
* [Slack Incoming Webhooks](https://api.slack.com/messaging/webhooks) - learn about integrating with Slack


# OpenAI Agents SDK for Python guardrails
Source: https://trigger.dev/docs/guides/example-projects/openai-agent-sdk-guardrails

This example project demonstrates how to implement different types of guardrails using the OpenAI Agent SDK for Python with Trigger.dev.

## Overview

This demo is a practical guide that demonstrates:

* **Three types of AI guardrails**: Input validation, output checking, and real-time streaming monitoring
* Integration of the [OpenAI Agent SDK for Python](https://openai.github.io/openai-agents-python/) with [Trigger.dev](https://trigger.dev) for production AI workflows
* Triggering Python scripts from tasks using our [Python build extension](/config/extensions/pythonExtension)
* **Educational examples** of implementing guardrails for AI safety and control mechanisms
* Real-world scenarios like math tutoring agents with content validation and complexity monitoring

Guardrails are safety mechanisms that run alongside AI agents to validate input, check output, monitor streaming content in real-time, and prevent unwanted or harmful behavior.

## GitHub repo

<Card title="View the OpenAI Agent SDK Guardrails repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/openai-agent-sdk-guardrails-examples">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/9b1e55c7-467d-4aca-8b4a-a018014c0827" />

## Relevant code

### Trigger.dev Tasks

* **[inputGuardrails.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/trigger/inputGuardrails.ts)** - Passes user prompts to Python script and handles `InputGuardrailTripwireTriggered` exceptions
* **[outputGuardrails.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/trigger/outputGuardrails.ts)** - Runs agent generation and catches `OutputGuardrailTripwireTriggered` exceptions with detailed error info
* **[streamingGuardrails.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/trigger/streamingGuardrails.ts)** - Executes streaming Python script and parses JSON output containing guardrail metrics

### Python Implementations

* **[input-guardrails.py](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/python/input-guardrails.py)** - Agent with `@input_guardrail` decorator that validates user input before processing (example: math tutor that only responds to math questions)
* **[output-guardrails.py](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/python/output-guardrails.py)** - Agent with `@output_guardrail` decorator that validates generated responses using a separate guardrail agent
* **[streaming-guardrails.py](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/src/python/streaming-guardrails.py)** - Processes `ResponseTextDeltaEvent` streams with async guardrail checks at configurable intervals (example: stops streaming if language is too complex for a 10-year-old)

### Configuration

* **[trigger.config.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agent-sdk-guardrails-examples/trigger.config.ts)** - Uses the Trigger.dev Python extension

### Learn more

* [OpenAI Agent SDK documentation](https://openai.github.io/openai-agents-python/)
* [OpenAI Agent SDK guardrails](https://openai.github.io/openai-agents-python/guardrails/)
* Our [Python build extension](/config/extensions/pythonExtension#python)


# OpenAI Agents SDK for Typescript + Trigger.dev playground
Source: https://trigger.dev/docs/guides/example-projects/openai-agents-sdk-typescript-playground

Build production-ready AI agents with OpenAI Agents SDK for Typescript and Trigger.dev. Explore 7 examples covering streaming, multi-agent systems, and tool integration.

## Overview

7 production-ready patterns built with the OpenAI Agents SDK and Trigger.dev. Clone this repo to experiment with everything from basic calls to workflows with tools, streaming, guardrails, handoffs, and more.

By combining the OpenAI Agents SDK with Trigger.dev, you can create durable agents that can be deployed to production and scaled to any size, with retries, queues, and full observability built-in.

## Video

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/d3a1c709-412f-48e8-a4aa-f0ef50dce5c8" />

## Tech stack

* [Node.js](https://nodejs.org) runtime environment
* [OpenAI Agents SDK for Typescript](https://openai.github.io/openai-agents-js/) for creating and managing AI agents
* [Trigger.dev](https://trigger.dev) for task orchestration, batching, scheduling, and workflow management
* [Zod](https://zod.dev) for payload validation

## GitHub repo

<Card title="View the OpenAI Agents SDK TypeScript playground repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/openai-agents-sdk-with-trigger-playground">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Agent tasks

* **Basic Agent Chat**: Personality-based conversations with strategic model selection
* **Agent with Tools**: A simple agent that can call tools to get weather data
* **Streaming Agent**: Real-time content generation with progress tracking
* **Agent Handoffs**: True multi-agent collaboration using the [handoff pattern](https://openai.github.io/openai-agents-js/guides/handoffs/) where agents can dynamically transfer control to specialists
* **Parallel Agents**: Concurrent agent processing for complex analysis tasks
* **Scheduled Agent**: Time-based agent workflows for continuous monitoring
* **Agent with Guardrails**: Input guardrails for safe AI interactions

## Relevant code

* **[basicAgentChat.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/basicAgentChat.ts)** - Strategic model selection (GPT-4, o1-preview, o1-mini, gpt-4o-mini) mapped to personality types with Trigger.dev task orchestration
* **[agentWithTools.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/agentWithTools.ts)** - OpenAI tool calling with Zod validation integrated into Trigger.dev's retry and error handling mechanisms
* **[streamingAgent.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/streamingAgent.ts)** - Native OpenAI streaming responses with real-time progress tracking via Trigger.dev metadata
* **[scheduledAgent.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/scheduledAgent.ts)** - Cron-scheduled OpenAI agents running every 6 hours with automatic trend analysis
* **[parallelAgents.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/parallelAgents.ts)** - Concurrent OpenAI agent execution using Trigger.dev batch operations (`batch.triggerByTaskAndWait`) for scalable text analysis
* **[agentWithGuardrails.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/agentWithGuardrails.ts)** - OpenAI classification agents as input guardrails with structured validation and exception handling
* **[agentHandoff.ts](https://github.com/triggerdotdev/examples/blob/main/openai-agents-sdk-with-trigger-playground/src/trigger/agentHandoff.ts)** - OpenAI Agents SDK handoff pattern with specialist delegation orchestrated through Trigger.dev workflows

## Learn more

* [OpenAI Agents SDK docs](https://openai.github.io/openai-agents-js/) - learn about creating and managing AI agents
* [OpenAI Agents SDK handoffs](https://openai.github.io/openai-agents-js/guides/handoffs/) - learn about agent-to-agent delegation patterns
* [Batch triggering](/triggering#batch-trigger) - learn about parallel task execution
* [Scheduled tasks (cron)](/tasks/scheduled#scheduled-tasks-cron) - learn about cron-based task scheduling


# Product image generator using Replicate and Trigger.dev
Source: https://trigger.dev/docs/guides/example-projects/product-image-generator

AI-powered product image generator that transforms basic product photos into professional marketing shots using Replicate's image generation models

## Overview

This project demonstrates how to build an AI-powered product image generator that transforms basic product photos into professional marketing shots. Users upload a product image and receive three professionally styled variations: clean product shots, lifestyle scenes, and hero shots with dramatic lighting.

## Video

<video controls className="w-full aspect-video" src="https://content.trigger.dev/product-image-generator-example.mp4" />

## GitHub repo

Clone this repo and follow the instructions in the `README.md` file to get started.

<Card title="View the product image generator repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/product-image-generator">
  Click here to view the full code in our examples repository on GitHub. You can fork it and use it
  as a starting point for your project.
</Card>

## Tech stack

* [**Next.js**](https://nextjs.org/) â€“ frontend React framework
* [**Replicate**](https://replicate.com/docs) â€“ AI image generation using the `google/nano-banana` image-to-image model
* [**UploadThing**](https://uploadthing.com/) â€“ file upload management and server callbacks
* [**Cloudflare R2**](https://developers.cloudflare.com/r2/) â€“ scalable image storage with public URLs

## How it works

The application orchestrates image generation through two main tasks: [`generateImages`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/trigger/generate-images.ts) coordinates batch processing, while [`generateImage`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/trigger/generate-images.ts) handles individual style generation.

Each generation task enhances prompts with style-specific instructions, calls Replicate's `google/nano-banana` image-to-image model, creates waitpoint tokens for async webhook handling, and uploads results to Cloudflare R2. The frontend displays real-time progress updates via React hooks as tasks complete.

Style presets include clean product shots (white background), lifestyle scenes (person holding product), and hero shots (dramatic lighting).

## Relevant code

* **Image generation tasks** â€“ batch processing with waitpoints for Replicate webhook callbacks ([`app/trigger/generate-images.ts`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/trigger/generate-images.ts))
* **Upload handler** â€“ UploadThing integration that triggers batch generation ([`app/api/uploadthing/core.ts`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/api/uploadthing/core.ts))
* **Real-time progress UI** â€“ live task updates using React hooks ([`app/components/GeneratedCard.tsx`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/components/GeneratedCard.tsx))
* **Custom prompt interface** â€“ user-defined style generation ([`app/components/CustomPromptCard.tsx`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/components/CustomPromptCard.tsx))
* **Main app component** â€“ layout and state management ([`app/ProductImageGenerator.tsx`](https://github.com/triggerdotdev/examples/blob/main/product-image-generator/app/ProductImageGenerator.tsx))

## Learn more

* [**Waitpoints**](/wait-for-token) â€“ pause tasks for async webhook callbacks
* [**React hooks**](/realtime/react-hooks/overview) â€“ real-time task updates and frontend integration
* [**Batch operations**](/triggering#tasks-batchtrigger) â€“ parallel task execution patterns
* [**Replicate API**](https://replicate.com/docs/get-started/nextjs) â€“ AI model integration
* [**UploadThing**](https://docs.uploadthing.com/) â€“ file upload handling and server callbacks


# Next.js Realtime CSV Importer
Source: https://trigger.dev/docs/guides/example-projects/realtime-csv-importer

This example Next.js project demonstrates how to use Trigger.dev Realtime to build a CSV Uploader with progress updates streamed to the frontend.

## Overview

The frontend is a Next.js app that allows users to upload a CSV file, which is then processed in the background using Trigger.dev tasks. The progress of the task is streamed back to the frontend in real-time using Trigger.dev Realtime.

* A [Next.js](https://nextjs.org/) app with [Trigger.dev](https://trigger.dev/) for the background tasks.
* [UploadThing](https://uploadthing.com/) to handle CSV file uploads
* Trigger.dev [Realtime](https://trigger.dev/launchweek/0/realtime) to stream updates to the frontend.

## GitHub repo

<Card title="View the Realtime CSV Importer repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/blob/main/realtime-csv-importer/README.md">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/25160343-6663-452c-8a27-819c3fd7b8df" />

## Relevant code

* View the Trigger.dev task code in the [src/trigger/csv.ts](https://github.com/triggerdotdev/examples/blob/main/realtime-csv-importer/src/trigger/csv.ts) file.
* The parent task `csvValidator` downloads the CSV file, parses it, and then splits the rows into multiple batches. It then does a `batch.triggerAndWait` to distribute the work the `handleCSVRow` task.
* The `handleCSVRow` task "simulates" checking the row for a valid email address and then updates the progress of the parent task using `metadata.parent`. See the [Trigger.dev docs](/runs/metadata#parent-and-root-updates) for more information on how to use the `metadata.parent` object.
* The `useRealtimeCSVValidator` hook in the [src/hooks/useRealtimeCSVValidator.ts](https://github.com/triggerdotdev/examples/blob/main/realtime-csv-importer/src/hooks/useRealtimeCSVValidator.ts) file handles the call to `useRealtimeRun` to get the progress of the parent task.
* The `CSVProcessor` component in the [src/components/CSVProcessor.tsx](https://github.com/triggerdotdev/examples/blob/main/realtime-csv-importer/src/components/CSVProcessor.tsx) file handles the file upload and displays the progress bar, and uses the `useRealtimeCSVValidator` hook to get the progress updates.

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Image generation with Fal.ai and Trigger.dev Realtime
Source: https://trigger.dev/docs/guides/example-projects/realtime-fal-ai

This example Next.js project generates an image from a prompt using Fal.ai and shows the progress of the task on the frontend using Trigger.dev Realtime.

## Overview

This full stack Next.js project showcases the following:

* A Trigger.dev task which [generates an image from a prompt using Fal.ai](https://github.com/triggerdotdev/examples/blob/main/realtime-fal-ai-image-generation/src/trigger/realtime-generate-image.ts)
* When a [form is submitted](https://github.com/triggerdotdev/examples/blob/main/realtime-fal-ai-image-generation/src/app/page.tsx) in the UI, triggering the task using a [server action](https://github.com/triggerdotdev/examples/blob/main/realtime-fal-ai-image-generation/src/app/actions/process-image.ts)
* Showing the [progress of the task](https://github.com/triggerdotdev/examples/blob/main/realtime-fal-ai-image-generation/src/app/processing/%5Bid%5D/ProcessingContent.tsx) on the frontend using Trigger.dev Realtime. This also includes error handling and a fallback UI
* Once the task is completed, showing the generated image on the frontend next to the original image

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/realtime-fal-ai-image-generation">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Walkthrough video

This video walks through the process of creating this task in a Next.js project.

<iframe width="100%" height="315" src="https://www.youtube.com/embed/BWZqYfUaigg?si=XpqVUEIf1j4bsYZ4" title="Trigger.dev walkthrough" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen />

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Turborepo monorepo with Prisma
Source: https://trigger.dev/docs/guides/example-projects/turborepo-monorepo-prisma

Two example projects demonstrating how to use Prisma and Trigger.dev in a Turborepo monorepo setup.

## Overview

These examples demonstrate two different ways of using Prisma and Trigger.dev in a Turborepo monorepo. In both examples, a task is triggered from a Next.js app using a server action, which uses Prisma to add a user to a database table. The examples differ in how Trigger.dev is installed and configured.

* Example 1: Turborepo monorepo demo with Trigger.dev and Prisma packages
* Example 2: Turborepo monorepo demo with a Prisma package and Trigger.dev installed in a Next.js app

<Note>
  You can either fork the repos below, or simply check out the project structures and code to get an idea of how to set up Trigger.dev in your own monorepos.
</Note>

## Example 1: Turborepo monorepo demo with Trigger.dev and Prisma packages

This simple example demonstrates how to use Trigger.dev and Prisma as packages inside a monorepo created with Turborepo. The Trigger.dev task is triggered by a button click in a Next.js app which triggers the task via a server action.

### GitHub repo

Fork the GitHub repo below to get started with this example project.

<Card title="Check out the Turborepo monorepo demo with Trigger.dev and Prisma packages" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

### Features

* This monorepo has been created using the [Turborepo CLI](https://turbo.build/repo), following the official [Prisma and Turborepo docs](https://www.prisma.io/docs/guides/turborepo), and then adapted for use with Trigger.dev.
* [pnpm](https://pnpm.io/) has been used as the package manager.
* A tasks package (`@repo/tasks`) using [Trigger.dev](https://trigger.dev) is used to create and execute tasks from an app inside the monorepo.
* A database package (`@repo/db`) using [Prisma ORM](https://www.prisma.io/docs/orm/) is used to interact with the database. You can use any popular Postgres database supported by Prisma, e.g. [Supabase](https://supabase.com/), [Neon](https://neon.tech/), etc.
* A [Next.js](https://nextjs.org/) example app (`apps/web`) to show how to trigger the task via a server action.

### Project structure

Simplified project structure for this example:

```
|
| â€” apps/
|   | â€” web/                    # Next.js frontend application
|   |   | â€” app/                # Next.js app router
|   |   |   | â€” api/
|   |   |   |   | â€” actions.ts  # Server actions for triggering tasks
|   |   |   | â€” page.tsx        # Main page with "Add new user" button
|   |   |   | â€” layout.tsx      # App layout
|   |   | â€” package.json        # Dependencies including @repo/db and @repo/tasks
|   |
|   | â€” docs/                   # Documentation app (not fully implemented)
|
| â€” packages/
|   | â€” database/               # Prisma database package (@repo/db)
|   |   | â€” prisma/
|   |   |   | â€” schema.prisma   # Database schema definition
|   |   | â€” generated/          # Generated Prisma client (gitignored)
|   |   | â€” src/
|   |   |   | â€” index.ts        # Exports from the database package
|   |   | â€” package.json        # Database package dependencies
|   |
|   | â€” tasks/                  # Trigger.dev tasks package (@repo/tasks)
|   |   | â€” src/
|   |   |   | â€” index.ts        # Exports from the tasks package
|   |   |   | â€” trigger/
|   |   |       | â€” index.ts    # Exports the tasks
|   |   |       | â€” addNewUser.ts # Task implementation for adding users
|   |   | â€” trigger.config.ts   # Trigger.dev configuration
|   |   | â€” package.json        # Tasks package dependencies
|   |
|   | â€” ui/                     # UI components package (referenced but not detailed)
|
| â€” turbo.json                  # Turborepo configuration
| â€” package.json                # Root package.json with workspace config
```

### Relevant files and code

#### Database package

* Prisma is added as a package in [`/packages/database`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/database/) and exported as `@repo/db` in the [`package.json`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/database/package.json) file.
* The schema is defined in the [`prisma/schema.prisma`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/database/prisma/schema.prisma) file.

#### Tasks package

<Note>
  to run `pnpm dlx trigger.dev@latest init` in a blank packages folder, you have to add a `package.json` file first, otherwise it will attempt to add Trigger.dev files in the root of your monorepo.
</Note>

* Trigger.dev is added as a package in [`/packages/tasks`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks) and exported as `@repo/tasks` in the [`package.json`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/package.json) file.
* The [`addNewUser.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/src/trigger/addNewUser.ts) task adds a new user to the database.
* The [`packages/tasks/src/index.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/src/index.ts) file exports values and types from the Trigger.dev SDK, and is exported from the package via the [`package.json`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/package.json) file.
* The [`packages/tasks/src/trigger/index.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/src/trigger/index.ts) file exports the task from the package. Every task must be exported from the package like this.
* The [`trigger.config.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/packages/tasks/trigger.config.ts) file configures the Trigger.dev project settings. This is where the Trigger.dev [Prisma build extension](https://trigger.dev/docs/config/extensions/prismaExtension) is added, which is required to use Prisma in the Trigger.dev task.

<Info>
  You must include the version of Prisma you are using in the `trigger.config.ts` file, otherwise the Prisma build extension will not work. Learn more about our [Prisma build extension](/config/extensions/prismaExtension).
</Info>

#### The Next.js app `apps/web`

* The app is a simple Next.js app using the App Router, that uses the `@repo/db` package to interact with the database and the `@repo/tasks` package to trigger the task. These are both added as dependencies in the [`package.json`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/apps/web/package.json) file.
* The task is triggered from a button click in the app in [`page.tsx`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/apps/web/app/page.tsx), which uses a server action in [`/app/api/actions.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/apps/web/app/api/actions.ts) to trigger the task with an example payload.

### Running the example

To run this example, check out the full instructions [in the GitHub repo README file](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package/README.md).

## Example 2: Turborepo monorepo demo with a Prisma package and Trigger.dev installed in a Next.js app

This example demonstrates how to use Trigger.dev and Prisma in a monorepo created with Turborepo. Prisma has been added as a package, and Trigger.dev has been installed in a Next.js app. The task is triggered by a button click in the app via a server action.

### GitHub repo

Fork the GitHub repo below to get started with this example project.

<Card title="Check out the Turborepo monorepo demo with a Prisma package and Trigger.dev installed in a Next.js app" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

### Features

* This monorepo has been created using the [Turborepo CLI](https://turbo.build/repo), following the official [Prisma and Turborepo docs](https://www.prisma.io/docs/guides/turborepo), and then adapted for use with Trigger.dev.
* [pnpm](https://pnpm.io/) has been used as the package manager.
* A database package (`@repo/db`) using [Prisma ORM](https://www.prisma.io/docs/orm/) is used to interact with the database. You can use any popular Postgres database supported by Prisma, e.g. [Supabase](https://supabase.com/), [Neon](https://neon.tech/), etc.
* A [Next.js](https://nextjs.org/) example app (`apps/web`) to show how to trigger the task via a server action.
* Trigger.dev initialized and an `addNewUser` task created in the `web` app.

### Project structure

Simplified project structure for this example:

```
|
| â€” apps/
|   | â€” web/                       # Next.js frontend application
|   |   | â€” app/                   # Next.js app router
|   |   |   | â€” api/
|   |   |   |   | â€” actions.ts     # Server actions for triggering tasks
|   |   |   | â€” page.tsx           # Main page with "Add new user" button
|   |   | â€” src/
|   |   |   | â€” trigger/
|   |   |       | â€” addNewUser.ts  # Task implementation for adding users
|   |   | â€” trigger.config.ts      # Trigger.dev configuration
|   |   | â€” package.json           # Dependencies including @repo/db
|   |
|   | â€” docs/                      # Documentation app
|       | â€” app/
|           | â€” page.tsx           # Docs landing page
|
| â€” packages/
|   | â€” database/                  # Prisma database package (@repo/db)
|   |   | â€” prisma/
|   |   |   | â€” schema.prisma      # Database schema definition
|   |
|   | â€” ui/                        # UI components package
|
| â€” turbo.json                     # Turborepo configuration
| â€” package.json                   # Root package.json with workspace config
```

## Relevant files and code

### Database package (`@repo/db`)

* Located in [`/packages/database/`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/packages/database/) and exported as `@repo/db`
* Schema defined in [`schema.prisma`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/packages/database/prisma/schema.prisma)
* Provides database access to other packages and apps

### Next.js app (`apps/web`)

* Contains Trigger.dev configuration in [`trigger.config.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/apps/web/trigger.config.ts)
* Trigger.dev tasks are defined in [`src/trigger/`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/apps/web/src/trigger/) (e.g., [`addNewUser.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/apps/web/src/trigger/addNewUser.ts))
* Demonstrates triggering tasks via server actions in [`app/api/actions.ts`](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/apps/web/app/api/actions.ts)

### Running the example

To run this example, check out the full instructions [in the GitHub repo README file](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-trigger/README.md).


# Deep research agent using Vercel's AI SDK
Source: https://trigger.dev/docs/guides/example-projects/vercel-ai-sdk-deep-research

Deep research agent which generates comprehensive PDF reports using Vercel's AI SDK.

<Info title="Acknowledgements">
  Acknowledgements: This example project is derived from the brilliant [deep research
  guide](https://aie-feb-25.vercel.app/docs/deep-research) by [Nico
  Albanese](https://x.com/nicoalbanese10).
</Info>

## Overview

This full-stack project is an intelligent deep research agent that autonomously conducts multi-layered web research, generating comprehensive reports which are then converted to PDF and uploaded to storage.

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/aa86d2b2-7aa7-4948-82ff-5e1e80cf8e37" />

**Tech stack:**

* **[Next.js](https://nextjs.org/)** for the web app
* **[Vercel's AI SDK](https://sdk.vercel.ai/)** for AI model integration and structured generation
* **[Trigger.dev](https://trigger.dev)** for task orchestration, execution and real-time progress updates
* **[OpenAI's GPT-4o model](https://openai.com/gpt-4)** for intelligent query generation, content analysis, and report creation
* **[Exa API](https://exa.ai/)** for semantic web search with live crawling
* **[LibreOffice](https://www.libreoffice.org/)** for PDF generation
* **[Cloudflare R2](https://developers.cloudflare.com/r2/)** to store the generated reports

**Features:**

* **Recursive research**: AI generates search queries, evaluates their relevance, asks follow-up questions and searches deeper based on initial findings.
* **Real-time progress**: Live updates are shown on the frontend using Trigger.dev Realtime as research progresses.
* **Intelligent source evaluation**: AI evaluates search result relevance before processing.
* **Research report generation**: The completed research is converted to a structured HTML report using a detailed system prompt.
* **PDF creation and uploading to Cloud storage**: The completed reports are then converted to PDF using LibreOffice and uploaded to Cloudflare R2.

## GitHub repo

<Card title="View the Vercel AI SDK deep research agent repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-deep-research-agent">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## How the deep research agent works

### Trigger.dev orchestration

The research process is orchestrated through three connected Trigger.dev tasks:

1. `deepResearchOrchestrator` - Main task that coordinates the entire research workflow.
2. `generateReport` - Processes research data into a structured HTML report using OpenAI's GPT-4o model
3. `generatePdfAndUpload` - Converts HTML to PDF using LibreOffice and uploads to R2 cloud storage

Each task uses `triggerAndWait()` to create a dependency chain, ensuring proper sequencing while maintaining isolation and error handling.

### The deep research recursive function

The core research logic uses a recursive depth-first search approach. A query is recursively expanded and the results are collected.

**Key parameters:**

* `depth`: Controls recursion levels (default: 2)
* `breadth`: Number of queries per level (default: 2, halved each recursion)

```
Level 0 (Initial Query): "AI safety in autonomous vehicles"
â”‚
â”œâ”€â”€ Level 1 (depth = 1, breadth = 2):
â”‚   â”œâ”€â”€ Sub-query 1: "Machine learning safety protocols in self-driving cars"
â”‚   â”‚   â”œâ”€â”€ â†’ Search Web â†’ Evaluate Relevance â†’ Extract Learnings
â”‚   â”‚   â””â”€â”€ â†’ Follow-up: "How do neural networks handle edge cases?"
â”‚   â”‚
â”‚   â””â”€â”€ Sub-query 2: "Regulatory frameworks for autonomous vehicle testing"
â”‚       â”œâ”€â”€ â†’ Search Web â†’ Evaluate Relevance â†’ Extract Learnings
â”‚       â””â”€â”€ â†’ Follow-up: "What are current safety certification requirements?"
â”‚
â””â”€â”€ Level 2 (depth = 2, breadth = 1):
    â”œâ”€â”€ From Sub-query 1 follow-up:
    â”‚   â””â”€â”€ "Neural network edge case handling in autonomous systems"
    â”‚       â””â”€â”€ â†’ Search Web â†’ Evaluate â†’ Extract â†’ DEPTH LIMIT REACHED
    â”‚
    â””â”€â”€ From Sub-query 2 follow-up:
        â””â”€â”€ "Safety certification requirements for self-driving vehicles"
            â””â”€â”€ â†’ Search Web â†’ Evaluate â†’ Extract â†’ DEPTH LIMIT REACHED
```

**Process flow:**

1. **Query generation**: OpenAI's GPT-4o generates multiple search queries from the input
2. **Web search**: Each query searches the web via the Exa API with live crawling
3. **Relevance evaluation**: OpenAI's GPT-4o evaluates if results help answer the query
4. **Learning extraction**: Relevant results are analyzed for key insights and follow-up questions
5. **Recursive deepening**: Follow-up questions become new queries for the next depth level
6. **Accumulation**: All learnings, sources, and queries are accumulated across recursion levels

### Using Trigger.dev Realtime to trigger and subscribe to the deep research task

We use the [`useRealtimeTaskTrigger`](/realtime/react-hooks/triggering#userealtimetasktrigger) React hook to trigger the `deep-research` task and subscribe to it's updates.

**Frontend (React Hook)**:

```typescript  theme={null}
const triggerInstance = useRealtimeTaskTrigger<typeof deepResearchOrchestrator>("deep-research", {
  accessToken: triggerToken,
});
const { progress, label } = parseStatus(triggerInstance.run?.metadata);
```

As the research progresses, the metadata is set within the tasks and the frontend is kept updated with every new status:

**Task Metadata**:

```typescript  theme={null}
metadata.set("status", {
  progress: 25,
  label: `Searching the web for: "${query}"`,
});
```

## Relevant code

* **Deep research task**: Core logic in [src/trigger/deepResearch.ts](https://github.com/triggerdotdev/examples/blob/main/vercel-ai-sdk-deep-research-agent/src/trigger/deepResearch.ts) - orchestrates the recursive research process. Here you can change the model, the depth and the breadth of the research.
* **Report generation**: [src/trigger/generateReport.ts](https://github.com/triggerdotdev/examples/blob/main/vercel-ai-sdk-deep-research-agent/src/trigger/generateReport.ts) - creates structured HTML reports from research data. The system prompt is defined in the code - this can be updated to be more or less detailed.
* **PDF generation**: [src/trigger/generatePdfAndUpload.ts](https://github.com/triggerdotdev/examples/blob/main/vercel-ai-sdk-deep-research-agent/src/trigger/generatePdfAndUpload.ts) - converts reports to PDF and uploads to R2. This is a simple example of how to use LibreOffice to convert HTML to PDF.
* **Research agent UI**: [src/components/DeepResearchAgent.tsx](https://github.com/triggerdotdev/examples/blob/main/vercel-ai-sdk-deep-research-agent/src/components/DeepResearchAgent.tsx) - handles form submission and real-time progress display using the `useRealtimeTaskTrigger` hook.
* **Progress component**: [src/components/progress-section.tsx](https://github.com/triggerdotdev/examples/blob/main/deep-research-agent/src/components/progress-section.tsx) - displays live research progress.

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Vercel AI SDK image generator
Source: https://trigger.dev/docs/guides/example-projects/vercel-ai-sdk-image-generator

This example Next.js project uses the Vercel AI SDK to generate images from a prompt.

## Overview

This demo is a full stack example that uses the following:

* A [Next.js](https://nextjs.org/) app using [shadcn](https://ui.shadcn.com/) for the UI
* Our 'useRealtimeRun' [React hook](/realtime/react-hooks/subscribe#userealtimerun) to subscribe to the run and show updates on the frontend
* The [Vercel AI SDK](https://sdk.vercel.ai/docs/introduction) to [generate images](https://sdk.vercel.ai/docs/ai-sdk-core/image-generation) using OpenAI's DALL-E models

## GitHub repo

<Card title="View the Vercel AI SDK image generator repo" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-image-generator">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Video

<video controls className="w-full aspect-video" src="https://github.com/user-attachments/assets/960edcb6-e225-4983-a48c-6fa697295dec" />

## Relevant code

* View the Trigger.dev task code which generates the image using the Vercel AI SDK in [src/trigger/realtime-generate-image.ts](https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-image-generator/src/trigger/realtime-generate-image.ts).
* We use a [useRealtimeRun](/realtime/react-hooks/subscribe#userealtimerun) hook to subscribe to the run in [src/app/processing/\[id\]/ProcessingContent.tsx](https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-image-generator/src/app/processing/\[id]/ProcessingContent.tsx).

## Learn more about Trigger.dev Realtime

To learn more, take a look at the following resources:

* [Trigger.dev Realtime](/realtime) - learn more about how to subscribe to runs and get real-time updates
* [Realtime streaming](/realtime/react-hooks/streams) - learn more about streaming data from your tasks
* [Batch Triggering](/triggering#tasks-batchtrigger) - learn more about how to trigger tasks in batches
* [React hooks](/realtime/react-hooks) - learn more about using React hooks to interact with the Trigger.dev API


# Generate an image using DALLÂ·E 3
Source: https://trigger.dev/docs/guides/examples/dall-e3-generate-image

This example will show you how to generate an image using DALLÂ·E 3 and text using GPT-4o with Trigger.dev.

## Overview

This example demonstrates how to use Trigger.dev to make reliable calls to AI APIs, specifically OpenAI's GPT-4o and DALL-E 3. It showcases automatic retrying with a maximum of 3 attempts, built-in error handling to avoid timeouts, and the ability to trace and monitor API calls.

## Task code

```ts trigger/generateContent.ts theme={null}
import { task } from "@trigger.dev/sdk";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

type Payload = {
  theme: string;
  description: string;
};

export const generateContent = task({
  id: "generate-content",
  retry: {
    maxAttempts: 3, // Retry up to 3 times
  },
  run: async ({ theme, description }: Payload) => {
    // Generate text
    const textResult = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: generateTextPrompt(theme, description),
    });

    if (!textResult.choices[0]) {
      throw new Error("No content, retryingâ€¦");
    }

    // Generate image
    const imageResult = await openai.images.generate({
      model: "dall-e-3",
      prompt: generateImagePrompt(theme, description),
    });

    if (!imageResult.data[0]) {
      throw new Error("No image, retryingâ€¦");
    }

    return {
      text: textResult.choices[0],
      image: imageResult.data[0].url,
    };
  },
});

function generateTextPrompt(theme: string, description: string): any {
  return `Theme: ${theme}\n\nDescription: ${description}`;
}

function generateImagePrompt(theme: string, description: string): any {
  return `Theme: ${theme}\n\nDescription: ${description}`;
}
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "theme": "A beautiful sunset",
  "description": "A sunset over the ocean with a tiny yacht in the distance."
}
```


# Transcribe audio using Deepgram
Source: https://trigger.dev/docs/guides/examples/deepgram-transcribe-audio

This example will show you how to transcribe audio using Deepgram's speech recognition API with Trigger.dev.

## Overview

Transcribe audio using [Deepgram's](https://developers.deepgram.com/docs/introduction) speech recognition API.

## Key Features

* Transcribe audio from a URL
* Use the Nova 2 model for transcription

## Task code

```ts trigger/deepgramTranscription.ts theme={null}
import { createClient } from "@deepgram/sdk";
import { logger, task } from "@trigger.dev/sdk";

// Initialize the Deepgram client, using your Deepgram API key (you can find this in your Deepgram account settings).
const deepgram = createClient(process.env.DEEPGRAM_SECRET_KEY);

export const deepgramTranscription = task({
  id: "deepgram-transcribe-audio",
  run: async (payload: { audioUrl: string }) => {
    const { audioUrl } = payload;

    logger.log("Transcribing audio from URL", { audioUrl });

    // Transcribe the audio using Deepgram
    const { result, error } = await deepgram.listen.prerecorded.transcribeUrl(
      {
        url: audioUrl,
      },
      {
        model: "nova-2", // Use the Nova 2 model for the transcription
        smart_format: true, // Automatically format transcriptions to improve readability
        diarize: true, // Recognize speaker changes and assign a speaker to each word in the transcript
      }
    );

    if (error) {
      logger.error("Failed to transcribe audio", { error });
      throw error;
    }

    console.dir(result, { depth: null });

    // Extract the transcription from the result
    const transcription = result.results.channels[0].alternatives[0].paragraphs?.transcript;

    logger.log(`Generated transcription: ${transcription}`);

    return {
      result,
    };
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "audioUrl": "https://dpgr.am/spacewalk.wav"
}
```


# Convert an image to a cartoon using Fal.ai
Source: https://trigger.dev/docs/guides/examples/fal-ai-image-to-cartoon

This example task generates an image from a URL using Fal.ai and uploads it to Cloudflare R2.

## Walkthrough

This video walks through the process of creating this task in a Next.js project.

<iframe width="100%" height="315" src="https://www.youtube.com/embed/AyRT4X8dHK0?si=ugA172V_3TMjik9h" title="Trigger.dev walkthrough" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen />

## Prerequisites

* An existing project
* A [Trigger.dev account](https://cloud.trigger.dev) with Trigger.dev [initialized in your project](/quick-start)
* A [Fal.ai](https://fal.ai/) account
* A [Cloudflare](https://developers.cloudflare.com/r2/) account with an R2 bucket setup

## Task code

This task converts an image to a cartoon using Fal.ai, and uploads the result to Cloudflare R2.

```ts trigger/fal-ai-image-to-cartoon.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import * as fal from "@fal-ai/serverless-client";
import fetch from "node-fetch";
import { z } from "zod";

// Initialize fal.ai client
fal.config({
  credentials: process.env.FAL_KEY, // Get this from your fal.ai dashboard
});

// Initialize S3-compatible client for Cloudflare R2
const s3Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const FalResult = z.object({
  images: z.tuple([z.object({ url: z.string() })]),
});

export const falAiImageToCartoon = task({
  id: "fal-ai-image-to-cartoon",
  run: async (payload: { imageUrl: string; fileName: string }) => {
    logger.log("Converting image to cartoon", payload);

    // Convert image to cartoon using fal.ai
    const result = await fal.subscribe("fal-ai/flux/dev/image-to-image", {
      input: {
        prompt: "Turn the image into a cartoon in the style of a Pixar character",
        image_url: payload.imageUrl,
      },
      onQueueUpdate: (update) => {
        logger.info("Fal.ai processing update", { update });
      },
    });

    const $result = FalResult.parse(result);
    const [{ url: cartoonImageUrl }] = $result.images;

    // Download the cartoon image
    const imageResponse = await fetch(cartoonImageUrl);
    const imageBuffer = await imageResponse.arrayBuffer().then(Buffer.from);

    // Upload to Cloudflare R2
    const r2Key = `cartoons/${payload.fileName}`;
    const uploadParams = {
      Bucket: process.env.R2_BUCKET, // Create a bucket in your Cloudflare dashboard
      Key: r2Key,
      Body: imageBuffer,
      ContentType: "image/png",
    };

    logger.log("Uploading cartoon to R2", { key: r2Key });
    await s3Client.send(new PutObjectCommand(uploadParams));

    logger.log("Cartoon uploaded to R2", { key: r2Key });

    return {
      originalUrl: payload.imageUrl,
      cartoonUrl: `File uploaded to storage at: ${r2Key}`,
    };
  },
});
```

### Testing your task

You can test your task by triggering it from the Trigger.dev dashboard.

```json  theme={null}
"imageUrl": "<image-url>", // Replace with the URL of the image you want to convert to a cartoon
"fileName": "<file-name>" // Replace with the name you want to save the file as in Cloudflare R2
```


# Generate an image from a prompt using Fal.ai and Trigger.dev Realtime
Source: https://trigger.dev/docs/guides/examples/fal-ai-realtime

This example task generates an image from a prompt using Fal.ai and shows the progress of the task on the frontend using Trigger.dev Realtime.

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/realtime-fal-ai-image-generation">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Walkthrough

This video walks through the process of creating this task in a Next.js project.

<iframe width="100%" height="315" src="https://www.youtube.com/embed/BWZqYfUaigg?si=XpqVUEIf1j4bsYZ4" title="Trigger.dev walkthrough" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen />

## Prerequisites

* An existing project
* A [Trigger.dev account](https://cloud.trigger.dev) with Trigger.dev [initialized in your project](/quick-start)
* A [Fal.ai](https://fal.ai/) account

## Task code

This task generates an image from a prompt using Fal.ai.

```ts trigger/fal-ai-image-from-prompt-realtime.ts theme={null}
import * as fal from "@fal-ai/serverless-client";
import { logger, schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";

export const FalResult = z.object({
  images: z.tuple([z.object({ url: z.string() })]),
});

export const payloadSchema = z.object({
  imageUrl: z.string().url(),
  prompt: z.string(),
});

export const realtimeImageGeneration = schemaTask({
  id: "realtime-image-generation",
  schema: payloadSchema,
  run: async (payload) => {
    const result = await fal.subscribe("fal-ai/flux/dev/image-to-image", {
      input: {
        image_url: payload.imageUrl,
        prompt: payload.prompt,
      },
      onQueueUpdate: (update) => {
        logger.info("Fal.ai processing update", { update });
      },
    });

    const $result = FalResult.parse(result);
    const [{ url: cartoonUrl }] = $result.images;

    return {
      imageUrl: cartoonUrl,
    };
  },
});
```

### Testing your task

You can test your task by triggering it from the Trigger.dev dashboard. Here's an example payload:

```json  theme={null}
{
  "imageUrl": "https://static.vecteezy.com/system/resources/previews/005/857/332/non_2x/funny-portrait-of-cute-corgi-dog-outdoors-free-photo.jpg",
  "prompt": "Dress this dog for Christmas"
}
```


# Video processing with FFmpeg
Source: https://trigger.dev/docs/guides/examples/ffmpeg-video-processing

These examples show you how to process videos in various ways using FFmpeg with Trigger.dev.

export const packages_0 = "ffmpeg"

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [FFmpeg](https://www.ffmpeg.org/download.html) installed on your machine

### Adding the FFmpeg build extension

To use these example tasks, you'll first need to add our FFmpeg extension to your project configuration like this:

```ts trigger.config.ts theme={null}
import { ffmpeg } from "@trigger.dev/build/extensions/core";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [ffmpeg()],
  },
});
```

<Note>
  [Build extensions](/config/extensions/overview) allow you to hook into the build system and
  customize the build process or the resulting bundle and container image (in the case of
  deploying). You can use pre-built extensions or create your own.
</Note>

You'll also need to add `@trigger.dev/build` to your `package.json` file under `devDependencies` if you don't already have it there.

If you are modifying this example and using popular FFmpeg libraries like `fluent-ffmpeg` you'll also need to add them to [`external`](/config/config-file#external) in your `trigger.config.ts` file.

## Compress a video using FFmpeg

This task demonstrates how to use FFmpeg to compress a video, reducing its file size while maintaining reasonable quality, and upload the compressed video to R2 storage.

### Key Features

* Fetches a video from a given URL
* Compresses the video using FFmpeg with various compression settings
* Uploads the compressed video to R2 storage

### Task code

```ts trigger/ffmpeg-compress-video.ts theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { logger, task } from "@trigger.dev/sdk";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs/promises";
import fetch from "node-fetch";
import { Readable } from "node:stream";
import os from "os";
import path from "path";

// Initialize S3 client
const s3Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const ffmpegCompressVideo = task({
  id: "ffmpeg-compress-video",
  run: async (payload: { videoUrl: string }) => {
    const { videoUrl } = payload;

    // Generate temporary file names
    const tempDirectory = os.tmpdir();
    const outputPath = path.join(tempDirectory, `output_${Date.now()}.mp4`);

    // Fetch the video
    const response = await fetch(videoUrl);

    // Compress the video
    await new Promise((resolve, reject) => {
      if (!response.body) {
        return reject(new Error("Failed to fetch video"));
      }

      ffmpeg(Readable.from(response.body))
        .outputOptions([
          "-c:v libx264", // Use H.264 codec
          "-crf 28", // Higher CRF for more compression (28 is near the upper limit for acceptable quality)
          "-preset veryslow", // Slowest preset for best compression
          "-vf scale=iw/2:ih/2", // Reduce resolution to 320p width (height auto-calculated)
          "-c:a aac", // Use AAC for audio
          "-b:a 64k", // Reduce audio bitrate to 64k
          "-ac 1", // Convert to mono audio
        ])
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    // Read the compressed video
    const compressedVideo = await fs.readFile(outputPath);
    const compressedSize = compressedVideo.length;

    // Log compression results
    logger.log(`Compressed video size: ${compressedSize} bytes`);
    logger.log(`Temporary compressed video file created`, { outputPath });

    // Create the r2Key for the extracted audio, using the base name of the output path
    const r2Key = `processed-videos/${path.basename(outputPath)}`;

    const uploadParams = {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
      Body: compressedVideo,
    };

    // Upload the video to R2 and get the URL
    await s3Client.send(new PutObjectCommand(uploadParams));
    logger.log(`Compressed video saved to your r2 bucket`, { r2Key });

    // Delete the temporary compressed video file
    await fs.unlink(outputPath);
    logger.log(`Temporary compressed video file deleted`, { outputPath });

    // Return the compressed video buffer and r2 key
    return {
      Bucket: process.env.R2_BUCKET,
      r2Key,
    };
  },
});
```

### Testing your task

To test this task, use this payload structure:

```json  theme={null}
{
  "videoUrl": "<video-url>" // Replace <a-video-url> with the URL of the video you want to upload
}
```

## Extract audio from a video using FFmpeg

This task demonstrates how to use FFmpeg to extract audio from a video, convert it to WAV format, and upload it to R2 storage.

### Key Features

* Fetches a video from a given URL
* Extracts the audio from the video using FFmpeg
* Converts the extracted audio to WAV format
* Uploads the extracted audio to R2 storage

### Task code

```ts trigger/ffmpeg-extract-audio.ts theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { logger, task } from "@trigger.dev/sdk";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs/promises";
import fetch from "node-fetch";
import { Readable } from "node:stream";
import os from "os";
import path from "path";

// Initialize S3 client
const s3Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const ffmpegExtractAudio = task({
  id: "ffmpeg-extract-audio",
  run: async (payload: { videoUrl: string }) => {
    const { videoUrl } = payload;

    // Generate temporary file names
    const tempDirectory = os.tmpdir();
    const outputPath = path.join(tempDirectory, `audio_${Date.now()}.wav`);

    // Fetch the video
    const response = await fetch(videoUrl);

    // Extract the audio
    await new Promise((resolve, reject) => {
      if (!response.body) {
        return reject(new Error("Failed to fetch video"));
      }

      ffmpeg(Readable.from(response.body))
        .outputOptions([
          "-vn", // Disable video output
          "-acodec pcm_s16le", // Use PCM 16-bit little-endian encoding
          "-ar 44100", // Set audio sample rate to 44.1 kHz
          "-ac 2", // Set audio channels to stereo
        ])
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    // Read the extracted audio
    const audioBuffer = await fs.readFile(outputPath);
    const audioSize = audioBuffer.length;

    // Log audio extraction results
    logger.log(`Extracted audio size: ${audioSize} bytes`);
    logger.log(`Temporary audio file created`, { outputPath });

    // Create the r2Key for the extracted audio, using the base name of the output path
    const r2Key = `extracted-audio/${path.basename(outputPath)}`;

    const uploadParams = {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
      Body: audioBuffer,
    };

    // Upload the audio to R2 and get the URL
    await s3Client.send(new PutObjectCommand(uploadParams));
    logger.log(`Extracted audio saved to your R2 bucket`, { r2Key });

    // Delete the temporary audio file
    await fs.unlink(outputPath);
    logger.log(`Temporary audio file deleted`, { outputPath });

    // Return the audio file path, size, and R2 URL
    return {
      Bucket: process.env.R2_BUCKET,
      r2Key,
    };
  },
});
```

### Testing your task

To test this task, use this payload structure:

<Warning>
  Make sure to provide a video URL that contains audio. If the video does not have audio, the task
  will fail.
</Warning>

```json  theme={null}
{
  "videoUrl": "<video-url>" // Replace <a-video-url> with the URL of the video you want to upload
}
```

## Generate a thumbnail from a video using FFmpeg

This task demonstrates how to use FFmpeg to generate a thumbnail from a video at a specific time and upload the generated thumbnail to R2 storage.

### Key Features

* Fetches a video from a given URL
* Generates a thumbnail from the video at the 5-second mark
* Uploads the generated thumbnail to R2 storage

### Task code

```ts trigger/ffmpeg-generate-thumbnail.ts theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { logger, task } from "@trigger.dev/sdk";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs/promises";
import fetch from "node-fetch";
import { Readable } from "node:stream";
import os from "os";
import path from "path";

// Initialize S3 client
const s3Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const ffmpegGenerateThumbnail = task({
  id: "ffmpeg-generate-thumbnail",
  run: async (payload: { videoUrl: string }) => {
    const { videoUrl } = payload;

    // Generate output file name
    const tempDirectory = os.tmpdir();
    const outputPath = path.join(tempDirectory, `thumbnail_${Date.now()}.jpg`);

    // Fetch the video
    const response = await fetch(videoUrl);

    // Generate the thumbnail
    await new Promise((resolve, reject) => {
      if (!response.body) {
        return reject(new Error("Failed to fetch video"));
      }
      ffmpeg(Readable.from(response.body))
        .screenshots({
          count: 1,
          folder: "/tmp",
          filename: path.basename(outputPath),
          size: "320x240",
          timemarks: ["5"], // 5 seconds
        })
        .on("end", resolve)
        .on("error", reject);
    });

    // Read the generated thumbnail
    const thumbnail = await fs.readFile(outputPath);

    // Create the r2Key for the extracted audio, using the base name of the output path
    const r2Key = `thumbnails/${path.basename(outputPath)}`;

    const uploadParams = {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
      Body: thumbnail,
    };

    // Upload the thumbnail to R2 and get the URL
    await s3Client.send(new PutObjectCommand(uploadParams));
    const r2Url = `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com/${process.env.R2_BUCKET}/${r2Key}`;
    logger.log("Thumbnail uploaded to R2", { url: r2Url });

    // Delete the temporary file
    await fs.unlink(outputPath);

    // Log thumbnail generation results
    logger.log(`Thumbnail uploaded to S3: ${r2Url}`);

    // Return the thumbnail buffer, path, and R2 URL
    return {
      thumbnailBuffer: thumbnail,
      thumbnailPath: outputPath,
      r2Url,
    };
  },
});
```

### Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "videoUrl": "<video-url>" // Replace <a-video-url> with the URL of the video you want to upload
}
```

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.


# Crawl a URL using Firecrawl
Source: https://trigger.dev/docs/guides/examples/firecrawl-url-crawl

This example demonstrates how to crawl a URL using Firecrawl with Trigger.dev.

## Overview

Firecrawl is a tool for crawling websites and extracting clean markdown that's structured in an LLM-ready format.

Here are two examples of how to use Firecrawl with Trigger.dev:

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* A [Firecrawl](https://firecrawl.dev/) account

## Example 1: crawl an entire website with Firecrawl

This task crawls a website and returns the `crawlResult` object. You can set the `limit` parameter to control the number of URLs that are crawled.

```ts trigger/firecrawl-url-crawl.ts theme={null}
import FirecrawlApp from "@mendable/firecrawl-js";
import { task } from "@trigger.dev/sdk";

// Initialize the Firecrawl client with your API key
const firecrawlClient = new FirecrawlApp({
  apiKey: process.env.FIRECRAWL_API_KEY, // Get this from your Firecrawl dashboard
});

export const firecrawlCrawl = task({
  id: "firecrawl-crawl",
  run: async (payload: { url: string }) => {
    const { url } = payload;

    // Crawl: scrapes all the URLs of a web page and return content in LLM-ready format
    const crawlResult = await firecrawlClient.crawlUrl(url, {
      limit: 100, // Limit the number of URLs to crawl
      scrapeOptions: {
        formats: ["markdown", "html"],
      },
    });

    if (!crawlResult.success) {
      throw new Error(`Failed to crawl: ${crawlResult.error}`);
    }

    return {
      data: crawlResult,
    };
  },
});
```

### Testing your task

You can test your task by triggering it from the Trigger.dev dashboard.

```json  theme={null}
"url": "<url-to-crawl>" // Replace with the URL you want to crawl
```

## Example 2: scrape a single URL with Firecrawl

This task scrapes a single URL and returns the `scrapeResult` object.

```ts trigger/firecrawl-url-scrape.ts theme={null}
import FirecrawlApp, { ScrapeResponse } from "@mendable/firecrawl-js";
import { task } from "@trigger.dev/sdk";

// Initialize the Firecrawl client with your API key
const firecrawlClient = new FirecrawlApp({
  apiKey: process.env.FIRECRAWL_API_KEY, // Get this from your Firecrawl dashboard
});

export const firecrawlScrape = task({
  id: "firecrawl-scrape",
  run: async (payload: { url: string }) => {
    const { url } = payload;

    // Scrape: scrapes a URL and get its content in LLM-ready format (markdown, structured data via LLM Extract, screenshot, html)
    const scrapeResult = (await firecrawlClient.scrapeUrl(url, {
      formats: ["markdown", "html"],
    })) as ScrapeResponse;

    if (!scrapeResult.success) {
      throw new Error(`Failed to scrape: ${scrapeResult.error}`);
    }

    return {
      data: scrapeResult,
    };
  },
});
```

### Testing your task

You can test your task by triggering it from the Trigger.dev dashboard.

```json  theme={null}
"url": "<url-to-scrape>" // Replace with the URL you want to scrape
```


# Convert documents to PDF using LibreOffice
Source: https://trigger.dev/docs/guides/examples/libreoffice-pdf-conversion

This example demonstrates how to convert documents to PDF using LibreOffice with Trigger.dev.

export const packages_0 = "libreoffice"

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [LibreOffice](https://www.libreoffice.org/download/libreoffice-fresh/) installed on your machine
* A [Cloudflare R2](https://developers.cloudflare.com) account and bucket

### Using our `aptGet` build extension to add the LibreOffice package

To deploy this task, you'll need to add LibreOffice to your project configuration, like this:

```ts trigger.config.ts theme={null}
import { aptGet } from "@trigger.dev/build/extensions/core";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      aptGet({
        packages: ["libreoffice"],
      }),
    ],
  },
});
```

<Note>
  [Build extensions](/config/extensions/overview) allow you to hook into the build system and
  customize the build process or the resulting bundle and container image (in the case of
  deploying). You can use pre-built extensions or create your own.
</Note>

You'll also need to add `@trigger.dev/build` to your `package.json` file under `devDependencies` if you don't already have it there.

## Convert a document to PDF using LibreOffice and upload to R2

This task demonstrates how to use LibreOffice to convert a document (.doc or .docx) to PDF and upload the PDF to an R2 storage bucket.

### Key Features

* Fetches a document from a given URL
* Converts the document to PDF
* Uploads the PDF to R2 storage

### Task code

```ts trigger/libreoffice-pdf-convert.ts theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { task } from "@trigger.dev/sdk";
import libreoffice from "libreoffice-convert";
import { promisify } from "node:util";
import path from "path";
import fs from "fs";

const convert = promisify(libreoffice.convert);

// Initialize S3 client
const s3Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const libreOfficePdfConvert = task({
  id: "libreoffice-pdf-convert",
  run: async (payload: { documentUrl: string }, { ctx }) => {
    // Set LibreOffice path for production environment
    if (ctx.environment.type !== "DEVELOPMENT") {
      process.env.LIBREOFFICE_PATH = "/usr/bin/libreoffice";
    }

    try {
      // Create temporary file paths
      const inputPath = path.join(process.cwd(), `input_${Date.now()}.docx`);
      const outputPath = path.join(process.cwd(), `output_${Date.now()}.pdf`);

      // Download file from URL
      const response = await fetch(payload.documentUrl);
      const buffer = Buffer.from(await response.arrayBuffer());
      fs.writeFileSync(inputPath, buffer);

      const inputFile = fs.readFileSync(inputPath);
      // Convert to PDF using LibreOffice
      const pdfBuffer = await convert(inputFile, ".pdf", undefined);
      fs.writeFileSync(outputPath, pdfBuffer);

      // Upload to R2
      const key = `converted-pdfs/output_${Date.now()}.pdf`;
      await s3Client.send(
        new PutObjectCommand({
          Bucket: process.env.R2_BUCKET,
          Key: key,
          Body: fs.readFileSync(outputPath),
        })
      );

      // Cleanup temporary files
      fs.unlinkSync(inputPath);
      fs.unlinkSync(outputPath);

      return { pdfLocation: key };
    } catch (error) {
      console.error("Error converting PDF:", error);
      throw error;
    }
  },
});
```

### Testing your task

To test this task, use this payload structure:

```json  theme={null}
{
  "documentUrl": "<a-document-url>" // Replace <a-document-url> with the URL of the document you want to convert
}
```

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.


# Lightpanda
Source: https://trigger.dev/docs/guides/examples/lightpanda

These examples demonstrate how to use Lightpanda with Trigger.dev.

## Overview

Lightpanda is a purpose-built browser for AI and automation workflows. It is 10x faster, uses 10x less RAM than Chrome headless.

Here are a few examples of how to use Lightpanda with Trigger.dev.

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

## Limitations

* Lightpanda does not support the `puppeteer` screenshot feature.

## Using Lightpanda Cloud

### Prerequisites

* A [Lightpanda](https://lightpanda.io/) cloud token

### Get links from a website

In this task we use Lightpanda browser to get links from a provided URL. You will have to pass the URL as a payload when triggering the task.

Make sure to add `LIGHTPANDA_TOKEN` to your Trigger.dev dashboard on the Environment Variables page:

```bash  theme={null}
LIGHTPANDA_TOKEN="<your-token>"
```

```ts trigger/lightpanda-cloud-puppeteer.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import puppeteer from "puppeteer-core";

export const lightpandaCloudPuppeteer = task({
  id: "lightpanda-cloud-puppeteer",
  machine: {
    preset: "micro",
  },
  run: async (payload: { url: string }, { ctx }) => {
    logger.log("Lets get a page's links with Lightpanda!", { payload, ctx });

    if (!payload.url) {
      logger.warn("Please define the payload url");
      throw new Error("payload.url is undefined");
    }

    const token = process.env.LIGHTPANDA_TOKEN;
    if (!token) {
      logger.warn("Please define the env variable LIGHTPANDA_TOKEN");
      throw new Error("LIGHTPANDA_TOKEN is undefined");
    }

    // Connect to Lightpanda's cloud
    const browser = await puppeteer.connect({
      browserWSEndpoint: `wss://cloud.lightpanda.io/ws?browser=lightpanda&token=${token}`,
    });
    const context = await browser.createBrowserContext();
    const page = await context.newPage();

    // Dump all the links from the page.
    await page.goto(payload.url);

    const links = await page.evaluate(() => {
      return Array.from(document.querySelectorAll("a")).map((row) => {
        return row.getAttribute("href");
      });
    });

    logger.info("Processing done, shutting downâ€¦");

    await page.close();
    await context.close();
    await browser.disconnect();

    logger.info("âœ… Completed");

    return {
      links,
    };
  },
});
```

### Proxies

Proxies can be used with your browser via the proxy query string parameter. By default, the proxy used is "datacenter" which is a pool of shared datacenter IPs.
`datacenter` accepts an optional `country` query string parameter which is an [ISO 3166-1 alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) country code.

```bash  theme={null}
# This example will use a German IP
wss://cloud.lightpanda.io/ws?proxy=datacenter&country=de&token=${token}
```

### Session

A session is alive until you close it or the connection is closed. The max duration of a session is 15 minutes.

## Using Lightpanda browser directly

### Prerequisites

* Setup the [Lightpanda build extension](/config/extensions/lightpanda)

### Get the HTML of a webpage

This task will dump the HTML of a provided URL using the Lightpanda browser binary. You will have to pass the URL as a payload when triggering the task.

```ts trigger/lightpanda-fetch.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { execSync } from "node:child_process";

export const lightpandaFetch = task({
  id: "lightpanda-fetch",
  machine: {
    preset: "micro",
  },
  run: async (payload: { url: string }, { ctx }) => {
    logger.log("Lets get a page's content with Lightpanda!", { payload, ctx });

    if (!payload.url) {
      logger.warn("Please define the payload url");
      throw new Error("payload.url is undefined");
    }

    const buffer = execSync(`lightpanda fetch --dump ${payload.url}`);

    logger.info("âœ… Completed");

    return {
      message: buffer.toString(),
    };
  },
});
```

### Lightpanda CDP with Puppeteer

This task initializes a Lightpanda CDP server and uses it with `puppeteer-core` to scrape a provided URL.

```ts trigger/lightpanda-cdp.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { spawn, type ChildProcessWithoutNullStreams } from "node:child_process";
import puppeteer from "puppeteer-core";

const spawnLightpanda = async (host: string, port: string) =>
  new Promise<ChildProcessWithoutNullStreams>((resolve, reject) => {
    const child = spawn("lightpanda", [
      "serve",
      "--host",
      host,
      "--port",
      port,
      "--log_level",
      "info",
    ]);

    child.on("spawn", async () => {
      logger.info("Running Lightpanda's CDP serverâ€¦", {
        pid: child.pid,
      });

      await new Promise((resolve) => setTimeout(resolve, 250));
      resolve(child);
    });
    child.on("error", (e) => reject(e));
  });

export const lightpandaCDP = task({
  id: "lightpanda-cdp",
  machine: {
    preset: "micro",
  },
  run: async (payload: { url: string }, { ctx }) => {
    logger.log("Lets get a page's links with Lightpanda!", { payload, ctx });

    if (!payload.url) {
      logger.warn("Please define the payload url");
      throw new Error("payload.url is undefined");
    }

    const host = process.env.LIGHTPANDA_CDP_HOST ?? "127.0.0.1";
    const port = process.env.LIGHTPANDA_CDP_PORT ?? "9222";

    // Launch Lightpanda's CDP server
    const lpProcess = await spawnLightpanda(host, port);

    const browser = await puppeteer.connect({
      browserWSEndpoint: `ws://${host}:${port}`,
    });
    const context = await browser.createBrowserContext();
    const page = await context.newPage();

    // Dump all the links from the page.
    await page.goto(payload.url);

    const links = await page.evaluate(() => {
      return Array.from(document.querySelectorAll("a")).map((row) => {
        return row.getAttribute("href");
      });
    });

    logger.info("Processing done");
    logger.info("Shutting downâ€¦");

    // Close Puppeteer instance
    await browser.close();

    // Stop Lightpanda's CDP Server
    lpProcess.kill();

    logger.info("âœ… Completed");

    return {
      links,
    };
  },
});
```


# Call OpenAI with retrying
Source: https://trigger.dev/docs/guides/examples/open-ai-with-retrying

This example will show you how to call OpenAI with retrying using Trigger.dev.

## Overview

Sometimes OpenAI calls can take a long time to complete, or they can fail. This task will retry if the API call fails completely or if the response is empty.

## Task code

```ts trigger/openai.ts theme={null}
import { task } from "@trigger.dev/sdk";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export const openaiTask = task({
  id: "openai-task",
  //specifying retry options overrides the defaults defined in your trigger.config file
  retry: {
    maxAttempts: 10,
    factor: 1.8,
    minTimeoutInMs: 500,
    maxTimeoutInMs: 30_000,
    randomize: false,
  },
  run: async (payload: { prompt: string }) => {
    //if this fails, it will throw an error and retry
    const chatCompletion = await openai.chat.completions.create({
      messages: [{ role: "user", content: payload.prompt }],
      model: "gpt-3.5-turbo",
    });

    if (chatCompletion.choices[0]?.message.content === undefined) {
      //sometimes OpenAI returns an empty response, let's retry by throwing an error
      throw new Error("OpenAI call failed");
    }

    return chatCompletion.choices[0].message.content;
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "prompt": "What is the meaning of life?"
}
```


# Turn a PDF into an image using MuPDF
Source: https://trigger.dev/docs/guides/examples/pdf-to-image

This example will show you how to turn a PDF into an image using MuPDF and Trigger.dev.

export const packages_0 = "mupdf-tools from MuPDF"

## Overview

This example demonstrates how to use Trigger.dev to turn a PDF into a series of images using MuPDF and upload them to Cloudflare R2.

## Update your build configuration

To use this example, add these build settings below to your `trigger.config.ts` file. They ensure that the `mutool` and `curl` packages are installed when you deploy your task. You can learn more about this and see more build settings [here](/config/extensions/aptGet).

```ts trigger.config.ts theme={null}
export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [aptGet({ packages: ["mupdf-tools", "curl"] })],
  },
});
```

## Task code

```ts trigger/pdfToImage.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { execSync } from "child_process";
import fs from "fs";
import path from "path";

// Initialize S3 client
const s3Client = new S3Client({
  region: "auto",
  endpoint: process.env.S3_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const pdfToImage = task({
  id: "pdf-to-image",
  run: async (payload: { pdfUrl: string; documentId: string }) => {
    logger.log("Converting PDF to images", payload);

    const pdfPath = `/tmp/${payload.documentId}.pdf`;
    const outputDir = `/tmp/${payload.documentId}`;

    // Download PDF and convert to images using MuPDF
    execSync(`curl -s -o ${pdfPath} ${payload.pdfUrl}`);
    fs.mkdirSync(outputDir, { recursive: true });
    execSync(`mutool convert -o ${outputDir}/page-%d.png ${pdfPath}`);

    // Upload images to R2
    const uploadedUrls = [];
    for (const file of fs.readdirSync(outputDir)) {
      const s3Key = `images/${payload.documentId}/${file}`;
      const uploadParams = {
        Bucket: process.env.S3_BUCKET,
        Key: s3Key,
        Body: fs.readFileSync(path.join(outputDir, file)),
        ContentType: "image/png",
      };

      logger.log("Uploading to R2", uploadParams);

      await s3Client.send(new PutObjectCommand(uploadParams));
      const s3Url = `https://${process.env.S3_BUCKET}.r2.cloudflarestorage.com/${s3Key}`;
      uploadedUrls.push(s3Url);
      logger.log("Image uploaded to R2", { url: s3Url });
    }

    // Clean up
    fs.rmSync(outputDir, { recursive: true, force: true });
    fs.unlinkSync(pdfPath);

    logger.log("All images uploaded to R2", { urls: uploadedUrls });

    return {
      imageUrls: uploadedUrls,
    };
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "pdfUrl": "https://pdfobject.com/pdf/sample.pdf",
  "documentId": "unique-document-id"
}
```

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.


# Puppeteer
Source: https://trigger.dev/docs/guides/examples/puppeteer

These examples demonstrate how to use Puppeteer with Trigger.dev.

export const packages_0 = "the Puppeteer library."

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Puppeteer](https://pptr.dev/guides/installation) installed on your machine

## Overview

There are 3 example tasks to follow on this page:

1. [Basic example](/guides/examples/puppeteer#basic-example)
2. [Generate a PDF from a web page](/guides/examples/puppeteer#generate-a-pdf-from-a-web-page)
3. [Scrape content from a web page](/guides/examples/puppeteer#scrape-content-from-a-web-page)

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

## Build configuration

To use all examples on this page, you'll first need to add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { puppeteer } from "@trigger.dev/build/extensions/puppeteer";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // This is required to use the Puppeteer library
    extensions: [puppeteer()],
  },
});
```

Learn more about the [trigger.config.ts](/config/config-file) file including setting default retry settings, customizing the build environment, and more.

## Set an environment variable

Set the following environment variable in your [Trigger.dev dashboard](/deploy-environment-variables) or [using the SDK](/deploy-environment-variables#in-your-code):

```bash  theme={null}
PUPPETEER_EXECUTABLE_PATH: "/usr/bin/google-chrome-stable",
```

## Basic example

### Overview

In this example we use [Puppeteer](https://pptr.dev/) to log out the title of a web page, in this case from the [Trigger.dev](https://trigger.dev) landing page.

### Task code

```ts trigger/puppeteer-basic-example.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import puppeteer from "puppeteer";

export const puppeteerTask = task({
  id: "puppeteer-log-title",
  run: async () => {
    const browser = await puppeteer.launch();
    const page = await browser.newPage();

    await page.goto("https://trigger.dev");

    const content = await page.title();
    logger.info("Content", { content });

    await browser.close();
  },
});
```

### Testing your task

There's no payload required for this task so you can just click "Run test" from the Test page in the dashboard. Learn more about testing tasks [here](/run-tests).

## Generate a PDF from a web page

### Overview

In this example we use [Puppeteer](https://pptr.dev/) to generate a PDF from the [Trigger.dev](https://trigger.dev) landing page and upload it to [Cloudflare R2](https://developers.cloudflare.com/r2/).

### Task code

```ts trigger/puppeteer-generate-pdf.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import puppeteer from "puppeteer";
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";

// Initialize S3 client
const s3Client = new S3Client({
  region: "auto",
  endpoint: process.env.S3_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const puppeteerWebpageToPDF = task({
  id: "puppeteer-webpage-to-pdf",
  run: async () => {
    const browser = await puppeteer.launch();
    const page = await browser.newPage();
    const response = await page.goto("https://trigger.dev");
    const url = response?.url() ?? "No URL found";

    // Generate PDF from the web page
    const generatePdf = await page.pdf();

    logger.info("PDF generated from URL", { url });

    await browser.close();

    // Upload to R2
    const s3Key = `pdfs/test.pdf`;
    const uploadParams = {
      Bucket: process.env.S3_BUCKET,
      Key: s3Key,
      Body: generatePdf,
      ContentType: "application/pdf",
    };

    logger.log("Uploading to R2 with params", uploadParams);

    // Upload the PDF to R2 and return the URL.
    await s3Client.send(new PutObjectCommand(uploadParams));
    const s3Url = `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${s3Key}`;
    logger.log("PDF uploaded to R2", { url: s3Url });
    return { pdfUrl: s3Url };
  },
});
```

### Testing your task

There's no payload required for this task so you can just click "Run test" from the Test page in the dashboard. Learn more about testing tasks [here](/run-tests).

## Scrape content from a web page

### Overview

In this example we use [Puppeteer](https://pptr.dev/) with a [BrowserBase](https://www.browserbase.com/) proxy to scrape the GitHub stars count from the [Trigger.dev](https://trigger.dev) landing page and log it out. See [this list](/guides/examples/puppeteer#proxying) for more proxying services we recommend.

<Warning>
  When web scraping, you MUST use the technique below which uses a proxy with Puppeteer. Direct
  scraping without using `browserWSEndpoint` is prohibited and will result in account suspension.
</Warning>

### Task code

```ts trigger/scrape-website.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import puppeteer from "puppeteer-core";

export const puppeteerScrapeWithProxy = task({
  id: "puppeteer-scrape-with-proxy",
  run: async () => {
    const browser = await puppeteer.connect({
      browserWSEndpoint: `wss://connect.browserbase.com?apiKey=${process.env.BROWSERBASE_API_KEY}`,
    });

    const page = await browser.newPage();

    try {
      // Navigate to the target website
      await page.goto("https://trigger.dev", { waitUntil: "networkidle0" });

      // Scrape the GitHub stars count
      const starCount = await page.evaluate(() => {
        const starElement = document.querySelector(".github-star-count");
        const text = starElement?.textContent ?? "0";
        const numberText = text.replace(/[^0-9]/g, "");
        return parseInt(numberText);
      });

      logger.info("GitHub star count", { starCount });

      return { starCount };
    } catch (error) {
      logger.error("Error during scraping", {
        error: error instanceof Error ? error.message : String(error),
      });
      throw error;
    } finally {
      await browser.close();
    }
  },
});
```

### Testing your task

There's no payload required for this task so you can just click "Run test" from the Test page in the dashboard. Learn more about testing tasks [here](/run-tests).

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.

## Proxying

If you're using Trigger.dev Cloud and Puppeteer or any other tool to scrape content from websites you don't own, you'll need to proxy your requests. **If you don't you'll risk getting our IP address blocked and we will ban you from our service. You must always have permission from the website owner to scrape their content.**

Here are a list of proxy services we recommend:

* [Browserbase](https://www.browserbase.com/)
* [Brightdata](https://brightdata.com/)
* [Browserless](https://browserless.io/)
* [Oxylabs](https://oxylabs.io/)
* [ScrapingBee](https://scrapingbee.com/)
* [Smartproxy](https://smartproxy.com/)


# Send emails using React Email
Source: https://trigger.dev/docs/guides/examples/react-email

Learn how to send beautiful emails using React Email and Trigger.dev.

## Overview

This example demonstrates how to use Trigger.dev to send emails using [React Email](https://react.email/).

<Note>
  This example uses [Resend](https://resend.com) as the email provider. You can use other email
  providers like [Loops](https://loops.so) or [SendGrid](https://sendgrid.com) etc. Full list of
  their integrations can be found [here](https://react.email/docs/introduction#integrations).
</Note>

## Task code

<Warning>
  This email is built using React components. To use React components in your task, it must be a
  .tsx file.
</Warning>

```tsx trigger/sendReactEmail.tsx theme={null}
import { Body, Button, Container, Head, Heading, Html, Preview } from "@react-email/components";
import { logger, task } from "@trigger.dev/sdk";
import { Resend } from "resend";

// Initialize Resend client
const resend = new Resend(process.env.RESEND_API_KEY);

// React Email template component
const EmailTemplate = ({ name, message }: { name: string; message: string }) => (
  <Html lang="en">
    <Head />
    <Preview>New message from {name}</Preview>
    <Body style={{ fontFamily: "Arial, sans-serif", margin: "0", padding: "0" }}>
      <Container style={{ padding: "20px", maxWidth: "600px" }}>
        <Heading>Hello from Acme Inc.</Heading>
        <p>Hi {name},</p>
        <p>{message}</p>
        <Button
          href="https://trigger.dev"
          style={{
            backgroundColor: "#0070f3",
            color: "white",
            padding: "12px 20px",
            borderRadius: "8px",
          }}
        >
          Go to Acme Inc.
        </Button>
      </Container>
    </Body>
  </Html>
);

export const sendEmail = task({
  id: "send-react-email",
  run: async (payload: {
    to: string;
    name: string;
    message: string;
    subject: string;
    from?: string;
  }) => {
    try {
      logger.info("Sending email using React.email and Resend", {
        to: payload.to,
      });

      // Send the email using Resend
      const { data, error } = await resend.emails.send({
        // The from address needs to be a verified email address you own
        from: payload.from || "email@acmeinc.com", // Default from address
        to: payload.to,
        subject: payload.subject,
        react: <EmailTemplate name={payload.name} message={payload.message} />,
      });

      if (error) {
        logger.error("Failed to send email", { error });
        throw new Error(`Failed to send email: ${error.message}`);
      }

      logger.info("Email sent successfully", { emailId: data?.id });

      // Return the response from Resend
      return {
        id: data?.id,
        status: "sent",
      };
    } catch (error) {
      logger.error("Unexpected error sending email", { error });
      throw error;
    }
  },
});
```

## The email

This example email should look like this:
<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=89d3a9eb719a46bfdbe445157260dbc7" alt="React Email" data-og-width="1202" width="1202" data-og-height="526" height="526" data-path="images/react-email.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=725f712a1680d1c755b237ba970c5125 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=adad5c98b98b563889846e2a49f221ca 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6f9bf6a14de88f2d3ff96f7d1a571e7b 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=322a321698bfedacdb974f22b47fb43a 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=dc7e4bc132c05f616b0ae34852d792ae 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1281ba4f08fe017c3cab10d66c208592 2500w" />

This is just a simple implementation, you can customize the email to be as complex as you want. Check out the [React email templates](https://react.email/templates) for more inspiration.

## Testing your task

To test this task in the [dashboard](https://cloud.trigger.dev), you can use the following payload:

```json  theme={null}
{
  "to": "recipient@example.com",
  "name": "Jane Doe",
  "message": "Thank you for signing up for our service!",
  "subject": "Welcome to Acme Inc."
}
```

## Deploying your task

Deploy the task to production using the Trigger.dev CLI `deploy` command.

## Using Cursor / AI to build your emails

In this video you can see how we use Cursor to build a welcome email.

We recommend using our [Cursor rules](https://trigger.dev/changelog/cursor-rules-writing-tasks/) to help you build your tasks and emails.

#### Video: creating a new email template using Cursor

<video src="https://content.trigger.dev/trigger-welcome-email-cursor.mp4" controls muted autoPlay loop />

#### The generated email template

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a6f143fe952bc0a93a2a50c96970b863" alt="Cursor" data-og-width="1559" width="1559" data-og-height="1141" height="1141" data-path="images/react-email-welcome.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2487ce4d2be4b80794cb4820a2953ec9 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1059539f4cd6983974e5ae79023fda9e 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=70bd8821dfbdd05bec826784070a2919 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f55b8f390636416420d513d7ed428e21 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7a1a3281a62666deac2d98f40f05e0e5 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-email-welcome.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e145996626c42ce55077aafb7cebfa47 2500w" />

#### The generated code

```tsx emails/trigger-welcome-email.tsx theme={null}
import {
  Body,
  Button,
  Container,
  Head,
  Heading,
  Hr,
  Html,
  Img,
  Link,
  Preview,
  Section,
  Text,
} from "@react-email/components";

const baseUrl = process.env.VERCEL_URL ? `https://${process.env.VERCEL_URL}` : "";

export interface TriggerWelcomeEmailProps {
  name: string;
}

export const TriggerWelcomeEmail = ({ name }: TriggerWelcomeEmailProps) => (
  <Html>
    <Head />
    <Preview>Welcome to Trigger.dev - Your background jobs platform!</Preview>
    <Body style={main}>
      <Container style={container}>
        <Section style={box}>
          <Img
            src="https://trigger.dev/assets/triggerdev-lockup--light.svg"
            width="150"
            height="40"
            alt="Trigger.dev"
          />
          <Hr style={hr} />
          <Heading>Welcome, {name}!</Heading>
          <Text style={paragraph}>
            Thanks for signing up for Trigger.dev! You're now ready to start creating powerful
            background jobs and workflows.
          </Text>
          <Text style={paragraph}>
            You can monitor your jobs, view runs, and manage your projects right from your
            dashboard.
          </Text>
          <Button style={button} href="https://cloud.trigger.dev/dashboard">
            View your Trigger.dev Dashboard
          </Button>
          <Hr style={hr} />
          <Text style={paragraph}>
            To help you get started, check out our{" "}
            <Link style={anchor} href="https://trigger.dev/docs">
              documentation
            </Link>{" "}
            and{" "}
            <Link style={anchor} href="https://trigger.dev/docs/quickstart">
              quickstart guide
            </Link>
            .
          </Text>
          <Text style={paragraph}>
            You can create your first job using our SDK, set up integrations, and configure triggers
            to automate your workflows. Take a look at our{" "}
            <Link style={anchor} href="https://trigger.dev/docs/examples">
              examples
            </Link>{" "}
            for inspiration.
          </Text>
          <Text style={paragraph}>
            Join our{" "}
            <Link style={anchor} href="https://discord.gg/kA47vcd8Qr">
              Discord community
            </Link>{" "}
            to connect with other developers and get help when you need it.
          </Text>
          <Text style={paragraph}>
            We're here to help you build amazing things. If you have any questions, check out our{" "}
            <Link style={anchor} href="https://trigger.dev/docs">
              documentation
            </Link>{" "}
            or reach out to us on Discord.
          </Text>
          <Text style={paragraph}>â€” The Trigger.dev team</Text>
          <Hr style={hr} />
          <Text style={footer}>Trigger.dev Inc.</Text>
        </Section>
      </Container>
    </Body>
  </Html>
);

export default TriggerWelcomeEmail;

const main = {
  backgroundColor: "#0E0C15",
  fontFamily:
    '-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Ubuntu,sans-serif',
};

const container = {
  backgroundColor: "#1D1B27",
  margin: "0 auto",
  padding: "20px 0 48px",
  marginBottom: "64px",
};

const box = {
  padding: "0 48px",
};

const hr = {
  borderColor: "#2D2B3B",
  margin: "20px 0",
};

const paragraph = {
  color: "#E1E1E3",
  fontSize: "16px",
  lineHeight: "24px",
  textAlign: "left" as const,
};

const anchor = {
  color: "#A78BFA",
};

const button = {
  backgroundColor: "#7C3AED",
  borderRadius: "6px",
  color: "#fff",
  fontSize: "16px",
  fontWeight: "bold",
  textDecoration: "none",
  textAlign: "center" as const,
  display: "block",
  width: "100%",
  padding: "12px",
};

const footer = {
  color: "#9CA3AF",
  fontSize: "12px",
  lineHeight: "16px",
};
```

And then to trigger the email, you can use the following task:

```tsx trigger/triggerWelcomeEmail.tsx theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { Resend } from "resend";
import TriggerWelcomeEmail from "emails/trigger-welcome-email";

// Initialize Resend client
const resend = new Resend(process.env.RESEND_API_KEY);

export const sendEmail = task({
  id: "trigger-welcome-email",
  run: async (payload: { to: string; name: string; subject: string; from?: string }) => {
    try {
        to: payload.to,
      });

      const { data, error } = await resend.emails.send({
        // The from address needs to be a verified email address
        from: payload.from || "email@acmeinc.com", // Default from address
        to: payload.to,
        subject: payload.subject,
        react: <TriggerWelcomeEmail name={payload.name} />,
      });

      if (error) {
        logger.error("Failed to send email", { error });
        throw new Error(`Failed to send email: ${error.message}`);
      }

      logger.info("Email sent successfully", { emailId: data?.id });

      return {
        id: data?.id,
        status: "sent",
      };
    } catch (error) {
      logger.error("Unexpected error sending email", { error });
      throw error;
    }
  },
});
```

## Troubleshooting

If you see this error when using `react-email` packages:

```
reactDOMServer.renderToPipeableStream is not a function
```

See our [common problems guide](/troubleshooting#reactdomserver-rendertopipeablestream-is-not-a-function-when-using-react-email) for more information.

## Learn more

### React Email docs

Check out the [React Email docs](https://react.email/docs) and learn how to set up and use React Email, including how to preview your emails locally.

<CardGroup cols={2}>
  <Card title="Components" icon="puzzle-piece" href="https://react.email/components">
    Pre-built components you can copy and paste into your emails.
  </Card>

  <Card title="Templates" icon="rectangle-list" href="https://react.email/templates">
    Extensive pre-built templates ready to use.
  </Card>
</CardGroup>


# Generate a PDF using react-pdf and save it to R2
Source: https://trigger.dev/docs/guides/examples/react-pdf

This example will show you how to generate a PDF using Trigger.dev.

## Overview

This example demonstrates how to use Trigger.dev to generate a PDF using [react-pdf](https://react-pdf.org/) and save it to Cloudflare R2.

## Task code

<Info> This example must be a .tsx file to use React components.</Info>

```ts trigger/generateResumePDF.tsx theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { renderToBuffer, Document, Page, Text, View } from "@react-pdf/renderer";
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";

// Initialize R2 client
const r2Client = new S3Client({
  // How to authenticate to R2: https://developers.cloudflare.com/r2/api/s3/tokens/
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const generateResumePDF = task({
  id: "generate-resume-pdf",
  run: async (payload: { text: string }) => {
    // Log the payload
    logger.log("Generating PDF resume", payload);

    // Render the ResumeDocument component to a PDF buffer
    const pdfBuffer = await renderToBuffer(
      <Document>
        <Page size="A4">
          <View>
            <Text>{payload.text}</Text>
          </View>
        </Page>
      </Document>
    );

    // Generate a unique filename based on the text and current timestamp
    const filename = `${payload.text.replace(/\s+/g, "-").toLowerCase()}-${Date.now()}.pdf`;

    // Set the R2 key for the PDF file
    const r2Key = `resumes/${filename}`;

    // Set the upload parameters for R2
    const uploadParams = {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
      Body: pdfBuffer,
      ContentType: "application/pdf",
    };

    // Log the upload parameters
    logger.log("Uploading to R2 with params", uploadParams);

    // Upload the PDF to R2
    await r2Client.send(new PutObjectCommand(uploadParams));

    // Return the Bucket and R2 key for the uploaded PDF
    return {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
    };
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "text": "Hello, world!"
}
```


# Image-to-image generation using Replicate and nano-banana
Source: https://trigger.dev/docs/guides/examples/replicate-image-generation

Learn how to generate images from source image URLs using Replicate and Trigger.dev.

## Overview

This example demonstrates how to use Trigger.dev to generate images from source image URLs using [Replicate](https://replicate.com/), the [nano-banana-image-to-image](https://replicate.com/meta/nano-banana-image-to-image) model.

## Task code

```tsx trigger/generateImage.tsx theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { task, wait } from "@trigger.dev/sdk";
import Replicate, { Prediction } from "replicate";

// Initialize clients
const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

const s3Client = new S3Client({
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

const model = "google/nano-banana";

export const generateImageAndUploadToR2 = task({
  id: "generate-image-and-upload-to-r2",
  run: async (payload: { prompt: string; imageUrl: string }) => {
    const { prompt, imageUrl } = payload;

    const token = await wait.createToken({
      timeout: "10m",
    });

    // Use Flux with structured prompt
    const output = await replicate.predictions.create({
      model: model,
      input: { prompt, image_input: [imageUrl] },
      // pass the provided URL to Replicate's webhook, so they can "callback"
      webhook: token.url,
      webhook_events_filter: ["completed"],
    });

    const result = await wait.forToken<Prediction>(token).unwrap();
    // unwrap() throws a timeout error or returns the result ðŸ‘†

    if (!result.ok) {
      throw new Error("Failed to create prediction");
    }

    const generatedImageUrl = result.output.output;

    const image = await fetch(generatedImageUrl);
    const imageBuffer = Buffer.from(await image.arrayBuffer());

    const base64Image = Buffer.from(imageBuffer).toString("base64");

    const timestamp = Date.now();
    const filename = `generated-${timestamp}.png`;

    // Generate unique key for R2
    const sanitizedFileName = filename.replace(/[^a-zA-Z0-9.-]/g, "_");
    const r2Key = `uploaded-images/${timestamp}-${sanitizedFileName}`;

    const uploadParams = {
      Bucket: process.env.R2_BUCKET,
      Key: r2Key,
      Body: imageBuffer,
      ContentType: "image/png",
      // Add cache control for better performance
      CacheControl: "public, max-age=31536000", // 1 year
    };

    const uploadResult = await s3Client.send(new PutObjectCommand(uploadParams));

    // Construct the public URL using the R2_PUBLIC_URL env var
    const publicUrl = `${process.env.R2_PUBLIC_URL}/${r2Key}`;

    return {
      success: true,
      publicUrl,
      originalPrompt: prompt,
      sourceImageUrl: imageUrl,
    };
  },
});
```

## Environment variables

You will need to set the following environment variables:

```
TRIGGER_SECRET_KEY=<your-trigger-secret-key>
REPLICATE_API_TOKEN=<your-replicate-api-token>
R2_ENDPOINT=<your-r2-endpoint>
R2_ACCESS_KEY_ID=<your-r2-access-key-id>
R2_SECRET_ACCESS_KEY=<your-r2-secret-access-key>
R2_BUCKET=<your-r2-bucket>
R2_PUBLIC_URL=<your-r2-public-url>
```


# Send a sequence of emails using Resend
Source: https://trigger.dev/docs/guides/examples/resend-email-sequence

This example will show you how to send a sequence of emails over several days using Resend with Trigger.dev.

## Overview

Each email is wrapped in retry.onThrow. This will retry the block of code if an error is thrown. This is useful when you donâ€™t want to retry the whole task, but just a part of it. The entire task will use the default retrying, so can also retry.

Additionally this task uses wait.for to wait for a certain amount of time before sending the next email. During the waiting time, the task will be paused and will not consume any resources.

## Task code

```ts trigger/email-sequence.ts theme={null}
import { Resend } from "resend";

const resend = new Resend(process.env.RESEND_ASP_KEY);

export const emailSequence = task({
  id: "email-sequence",
  run: async (payload: { userId: string; email: string; name: string }) => {
    console.log(`Start email sequence for user ${payload.userId}`, payload);

    // Send the first email immediately
    const firstEmailResult = await retry.onThrow(
      async ({ attempt }) => {
        const { data, error } = await resend.emails.send({
          from: "hello@trigger.dev",
          to: payload.email,
          subject: "Welcome to Trigger.dev",
          html: `<p>Hello ${payload.name},</p><p>Welcome to Trigger.dev</p>`,
        });

        if (error) {
          // Throwing an error will trigger a retry of this block
          throw error;
        }

        return data;
      },
      { maxAttempts: 3 }
    );

    // Then wait 3 days
    await wait.for({ days: 3 });

    // Send the second email
    const secondEmailResult = await retry.onThrow(
      async ({ attempt }) => {
        const { data, error } = await resend.emails.send({
          from: "hello@trigger.dev",
          to: payload.email,
          subject: "Some tips for you",
          html: `<p>Hello ${payload.name},</p><p>Here are some tips for youâ€¦</p>`,
        });

        if (error) {
          // Throwing an error will trigger a retry of this block
          throw error;
        }

        return data;
      },
      { maxAttempts: 3 }
    );

    //etc...
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "userId": "123",
  "email": "<your-test-email>", // Replace with your test email
  "name": "Alice Testington"
}
```


# Generate OG Images using Satori
Source: https://trigger.dev/docs/guides/examples/satori

Learn how to generate dynamic Open Graph images using Satori and Trigger.dev.

## Overview

This example demonstrates how to use Trigger.dev to generate dynamic Open Graph (OG) images using Vercel's [Satori](https://github.com/vercel/satori). The task takes a title and image URL as input and generates a beautiful OG image with text overlay.

This can be customized and extended however you like, full list of options can be found [here](https://github.com/vercel/satori).

## Task code

```tsx trigger/generateOgImage.ts theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";
import satori from "satori";
import sharp from "sharp";
import { join } from "path";
import fs from "fs/promises";

export const generateOgImage = schemaTask({
  id: "generate-og-image",
  schema: z.object({
    width: z.number().optional(),
    height: z.number().optional(),
    title: z.string(),
    imageUrl: z.string().url(),
  }),
  run: async (payload) => {
    // Load font
    const fontResponse = await fetch(
      "https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf"
    ).then((res) => res.arrayBuffer());

    // Fetch and convert image to base64
    const imageResponse = await fetch(payload.imageUrl);
    const imageBuffer = await imageResponse.arrayBuffer();
    const imageBase64 = `data:${
      imageResponse.headers.get("content-type") || "image/jpeg"
    };base64,${Buffer.from(imageBuffer).toString("base64")}`;

    const markup = (
      <div
        style={{
          width: payload.width ?? 1200,
          height: payload.height ?? 630,
          display: "flex",
          backgroundColor: "#121317",
          position: "relative",
          fontFamily: "Roboto",
        }}
      >
        <img
          src={imageBase64}
          width={payload.width ?? 1200}
          height={payload.height ?? 630}
          style={{
            objectFit: "cover",
          }}
        />
        <h1
          style={{
            fontSize: "60px",
            fontWeight: "bold",
            color: "#fff",
            margin: 0,
            position: "absolute",
            top: "50%",
            transform: "translateY(-50%)",
            left: "48px",
            maxWidth: "60%",
            textShadow: "0 2px 4px rgba(0,0,0,0.5)",
          }}
        >
          {payload.title}
        </h1>
      </div>
    );

    const svg = await satori(markup, {
      width: payload.width ?? 1200,
      height: payload.height ?? 630,
      fonts: [
        {
          name: "Roboto",
          data: fontResponse,
          weight: 400,
          style: "normal",
        },
      ],
    });

    const fileName = `og-${Date.now()}.jpg`;
    const tempDir = join(process.cwd(), "tmp");
    await fs.mkdir(tempDir, { recursive: true });
    const outputPath = join(tempDir, fileName);

    await sharp(Buffer.from(svg))
      .jpeg({
        quality: 90,
        mozjpeg: true,
      })
      .toFile(outputPath);

    return {
      filePath: outputPath,
      width: payload.width,
      height: payload.height,
    };
  },
});
```

## Image example

This image was generated using the above task.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=10c7715e00714ea7ef7c27bb7ace5c0c" alt="OG Image" data-og-width="1200" width="1200" data-og-height="630" height="630" data-path="images/react-satori-og.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8cd98cbeef77cb233b870851ce7cb74f 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6fe23d397f6b7c27ea5c4dd471315ae9 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3b5900f0b2fba062fa9b5255410404c0 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3c140d3148b7f9820fbb83576aa50635 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4ab2adcc93d6e0fde7541cf4fd62df15 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/react-satori-og.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f588de73d95f7c3cebb82a4278de3ec5 2500w" />

## Testing your task

To test this task in the [dashboard](https://cloud.trigger.dev), you can use the following payload:

```json  theme={null}
{
  "title": "My Awesome OG image",
  "imageUrl": "<your-image-url>",
  "width": 1200, // optional, defaults to 1200
  "height": 630 // optional, defaults to 630
}
```


# Scrape the top 3 articles from Hacker News and email yourself a summary every weekday
Source: https://trigger.dev/docs/guides/examples/scrape-hacker-news

This example demonstrates how to scrape the top 3 articles from Hacker News using BrowserBase and Puppeteer, summarize them with ChatGPT and send a nicely formatted email summary to yourself every weekday using Resend.

export const packages_0 = "the Puppeteer library"

<iframe width="100%" height="315" src="https://www.youtube.com/embed/6azvzrZITKY?si=muKtsBiS9TJGGKWg" title="YouTube video player" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen />

## Overview

In this example we'll be using a number of different tools and features to:

1. Scrape the content of the top 3 articles from Hacker News
2. Summarize each article
3. Email the summaries to yourself

And we'll be using the following tools and features:

* [Schedules](/tasks/scheduled) to run the task every weekday at 9 AM
* [Batch Triggering](/triggering#yourtask-batchtriggerandwait) to run separate child tasks for each article while the parent task waits for them all to complete
* [idempotencyKey](/triggering#idempotencykey) to prevent tasks being triggered multiple times
* [BrowserBase](https://browserbase.com/) to proxy the scraping of the Hacker News articles
* [Puppeteer](https://pptr.dev/) to scrape the articles linked from Hacker News
* [OpenAI](https://platform.openai.com/docs/overview) to summarize the articles
* [Resend](https://resend.com/) to send a nicely formatted email summary

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Puppeteer](https://pptr.dev/guides/installation) installed on your machine
* A [BrowserBase](https://browserbase.com/) account
* An [OpenAI](https://platform.openai.com/docs/overview) account
* A [Resend](https://resend.com/) account

## Build configuration

First up, add these build settings to your `trigger.config.ts` file:

```tsx trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { puppeteer } from "@trigger.dev/build/extensions/puppeteer";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // This is required to use the Puppeteer library
    extensions: [puppeteer()],
  },
});
```

Learn more about the [trigger.config.ts](/config/config-file) file including setting default retry settings, customizing the build environment, and more.

### Environment variables

Set the following environment variable in your local `.env` file to run this task locally. And before deploying your task, set them in the [Trigger.dev dashboard](/deploy-environment-variables) or [using the SDK](/deploy-environment-variables#in-your-code):

```bash  theme={null}
BROWSERBASE_API_KEY: "<your BrowserBase API key>"
OPENAI_API_KEY: "<your OpenAI API key>"
RESEND_API_KEY: "<your Resend API key>"
```

### Task code

```ts trigger/scrape-hacker-news.ts theme={null}
import { render } from "@react-email/render";
import { logger, schedules, task, wait } from "@trigger.dev/sdk";
import { OpenAI } from "openai";
import puppeteer from "puppeteer-core";
import { Resend } from "resend";
import { HNSummaryEmail } from "./summarize-hn-email";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const resend = new Resend(process.env.RESEND_API_KEY);

// Parent task (scheduled to run 9AM every weekday)
export const summarizeHackerNews = schedules.task({
  id: "summarize-hacker-news",
  cron: {
    pattern: "0 9 * * 1-5",
    timezone: "Europe/London",
  }, // Run at 9 AM, Monday to Friday
  run: async () => {
    // Connect to BrowserBase to proxy the scraping of the Hacker News articles
    const browser = await puppeteer.connect({
      browserWSEndpoint: `wss://connect.browserbase.com?apiKey=${process.env.BROWSERBASE_API_KEY}`,
    });
    logger.info("Connected to Browserbase");

    const page = await browser.newPage();

    // Navigate to Hacker News and scrape top 3 articles
    await page.goto("https://news.ycombinator.com/news", {
      waitUntil: "networkidle0",
    });
    logger.info("Navigated to Hacker News");

    const articles = await page.evaluate(() => {
      const items = document.querySelectorAll(".athing");
      return Array.from(items)
        .slice(0, 3)
        .map((item) => {
          const titleElement = item.querySelector(".titleline > a");
          const link = titleElement?.getAttribute("href");
          const title = titleElement?.textContent;
          return { title, link };
        });
    });
    logger.info("Scraped top 3 articles", { articles });

    await browser.close();
    await wait.for({ seconds: 5 });

    // Use batchTriggerAndWait to process articles
    const summaries = await scrapeAndSummarizeArticle
      .batchTriggerAndWait(
        articles.map((article) => ({
          payload: { title: article.title!, link: article.link! },
        }))
      )
      .then((batch) => batch.runs.filter((run) => run.ok).map((run) => run.output));

    // Send email using Resend
    await resend.emails.send({
      from: "Hacker News Summary <hi@demo.tgr.dev>",
      to: ["james@trigger.dev"],
      subject: "Your morning HN summary",
      html: render(<HNSummaryEmail articles={summaries} />),
    });

    logger.info("Email sent successfully");
  },
});

// Child task for scraping and summarizing individual articles
export const scrapeAndSummarizeArticle = task({
  id: "scrape-and-summarize-articles",
  retry: {
    maxAttempts: 3,
    minTimeoutInMs: 5000,
    maxTimeoutInMs: 10000,
    factor: 2,
    randomize: true,
  },
  run: async ({ title, link }: { title: string; link: string }) => {
    logger.info(`Summarizing ${title}`);

    const browser = await puppeteer.connect({
      browserWSEndpoint: `wss://connect.browserbase.com?apiKey=${process.env.BROWSERBASE_API_KEY}`,
    });
    const page = await browser.newPage();

    // Prevent all assets from loading, images, stylesheets etc
    await page.setRequestInterception(true);
    page.on("request", (request) => {
      if (["script", "stylesheet", "image", "media", "font"].includes(request.resourceType())) {
        request.abort();
      } else {
        request.continue();
      }
    });

    await page.goto(link, { waitUntil: "networkidle0" });
    logger.info(`Navigated to article: ${title}`);

    // Extract the main content of the article
    const content = await page.evaluate(() => {
      const articleElement = document.querySelector("article") || document.body;
      return articleElement.innerText.trim().slice(0, 1500); // Limit to 1500 characters
    });

    await browser.close();

    logger.info(`Extracted content for article: ${title}`, { content });

    // Summarize the content using ChatGPT
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "user",
          content: `Summarize this article in 2-3 concise sentences:\n\n${content}`,
        },
      ],
    });

    logger.info(`Generated summary for article: ${title}`);

    return {
      title,
      link,
      summary: response.choices[0].message.content,
    };
  },
});
```

## Create your email template using React Email

To prevent the main example from becoming too cluttered, we'll create a separate file for our email template. It's formatted using [React Email](https://react.email/docs/introduction) components so you'll need to install the package to use it.

Notice how this file is imported into the main task code and passed to Resend to send the email.

```tsx summarize-hn-email.tsx theme={null}
import { Html, Head, Body, Container, Section, Heading, Text, Link } from "@react-email/components";

interface Article {
  title: string;
  link: string;
  summary: string | null;
}

export const HNSummaryEmail: React.FC<{ articles: Article[] }> = ({ articles }) => (
  <Html>
    <Head />
    <Body style={{ fontFamily: "Arial, sans-serif", padding: "20px" }}>
      <Container>
        <Heading as="h1">Your Morning HN Summary</Heading>
        {articles.map((article, index) => (
          <Section key={index} style={{ marginBottom: "20px" }}>
            <Heading as="h3">
              <Link href={article.link}>{article.title}</Link>
            </Heading>
            <Text>{article.summary || "No summary available"}</Text>
          </Section>
        ))}
      </Container>
    </Body>
  </Html>
);
```

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.

## Testing your task

To test this task in the dashboard, use the Test page and set the schedule date to "Now" to ensure the task triggers immediately. Then click "Run test" and wait for the task to complete.


# Track errors with Sentry
Source: https://trigger.dev/docs/guides/examples/sentry-error-tracking

This example demonstrates how to track errors with Sentry using Trigger.dev.

## Overview

Automatically send errors and source maps to your Sentry project from your Trigger.dev tasks. Sending source maps to Sentry allows for more detailed stack traces when errors occur, as Sentry can map the minified code back to the original source code.

## Prerequisites

* A [Sentry](https://sentry.io) account and project
* A [Trigger.dev](https://trigger.dev) account and project

## Build configuration

To send errors to Sentry when there are errors in your tasks, you'll need to add this build configuration to your `trigger.config.ts` file. This will then run every time you deploy your project.

<Note>
  You will need to set the `SENTRY_AUTH_TOKEN` and `SENTRY_DSN` environment variables. You can find
  the `SENTRY_AUTH_TOKEN` in your Sentry dashboard, in settings -> developer settings -> auth tokens
  and the `SENTRY_DSN` in your Sentry dashboard, in settings -> projects -> your project -> client
  keys (DSN). Add these to your `.env` file, and in your [Trigger.dev
  dashboard](https://cloud.trigger.dev), under environment variables in your project's sidebar.
</Note>

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { esbuildPlugin } from "@trigger.dev/build/extensions";
import { sentryEsbuildPlugin } from "@sentry/esbuild-plugin";
import * as Sentry from "@sentry/node";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      esbuildPlugin(
        sentryEsbuildPlugin({
          org: "<your-sentry-org>",
          project: "<your-sentry-project>",
          // Find this auth token in settings -> developer settings -> auth tokens
          authToken: process.env.SENTRY_AUTH_TOKEN,
        }),
        { placement: "last", target: "deploy" }
      ),
    ],
  },
  init: async () => {
    Sentry.init({
      defaultIntegrations: false,
      // The Data Source Name (DSN) is a unique identifier for your Sentry project.
      dsn: process.env.SENTRY_DSN,
      // Update this to match the environment you want to track errors for
      environment: process.env.NODE_ENV === "production" ? "production" : "development",
    });
  },
  onFailure: async ({ payload, error, ctx }) => {
    Sentry.captureException(error, {
      extra: {
        payload,
        ctx,
      },
    });
  },
});
```

<Note>
  [Build extensions](/config/extensions/overview) allow you to hook into the build system and
  customize the build process or the resulting bundle and container image (in the case of
  deploying). You can use pre-built extensions or create your own.
</Note>

## Testing that errors are being sent to Sentry

To test that errors are being sent to Sentry, you need to create a task that will fail.

This task takes no payload, and will throw an error.

```ts trigger/sentry-error-test.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const sentryErrorTest = task({
  id: "sentry-error-test",
  retry: {
    // Only retry once
    maxAttempts: 1,
  },
  run: async () => {
    const error = new Error("This is a custom error that Sentry will capture");
    error.cause = { additionalContext: "This is additional context" };
    throw error;
  },
});
```

After creating the task, deploy your project.

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

Once deployed, navigate to the `test` page in the sidebar of your [Trigger.dev dashboard](https://cloud.trigger.dev), click on your `prod` environment, and select the `sentryErrorTest` task.

Run a test task with an empty payload by clicking the `Run test` button.

Your run should then fail, and if everything is set up correctly, you will see an error in the Sentry project dashboard shortly after.


# Process images using Sharp
Source: https://trigger.dev/docs/guides/examples/sharp-image-processing

This example demonstrates how to process images using the Sharp library with Trigger.dev.

export const packages_0 = "the Sharp image processing library"

## Overview

This task processes and watermarks an image using the Sharp library, and then uploads it to R2 storage.

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* The [Sharp](https://sharp.pixelplumbing.com/install) library installed on your machine
* An R2-compatible object storage service, such as [Cloudflare R2](https://developers.cloudflare.com/r2)

## Adding the build configuration

To use this example, you'll first need to add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // This is required to use the Sharp library
    external: ["sharp"],
  },
});
```

<Note>
  Any packages that install or build a native binary should be added to external, as native binaries
  cannot be bundled.
</Note>

## Key features

* Resizes a JPEG image to 800x800 pixels
* Adds a watermark to the image, positioned in the bottom-right corner, using a PNG image
* Uploads the processed image to R2 storage

## Task code

```ts trigger/sharp-image-processing.ts theme={null}
import { S3Client } from "@aws-sdk/client-s3";
import { Upload } from "@aws-sdk/lib-storage";
import { logger, task } from "@trigger.dev/sdk";
import fs from "fs/promises";
import os from "os";
import path from "path";
import sharp from "sharp";

// Initialize R2 client using your R2 account details
const r2Client = new S3Client({
  region: "auto",
  endpoint: process.env.R2_ENDPOINT,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY ?? "",
  },
});

export const sharpProcessImage = task({
  id: "sharp-process-image",
  retry: { maxAttempts: 1 },
  run: async (payload: { imageUrl: string; watermarkUrl: string }) => {
    const { imageUrl, watermarkUrl } = payload;
    const outputPath = path.join(os.tmpdir(), `output_${Date.now()}.jpg`);

    const [imageResponse, watermarkResponse] = await Promise.all([
      fetch(imageUrl),
      fetch(watermarkUrl),
    ]);
    const imageBuffer = await imageResponse.arrayBuffer();
    const watermarkBuffer = await watermarkResponse.arrayBuffer();

    await sharp(Buffer.from(imageBuffer))
      .resize(800, 800) // Resize the image to 800x800px
      .composite([
        {
          input: Buffer.from(watermarkBuffer),
          gravity: "southeast", // Position the watermark in the bottom-right corner
        },
      ])
      .jpeg() // Convert to jpeg
      .toBuffer() // Convert to buffer
      .then(async (outputBuffer) => {
        await fs.writeFile(outputPath, outputBuffer); // Write the buffer to file

        const r2Key = `processed-images/${path.basename(outputPath)}`;
        const uploadParams = {
          Bucket: process.env.R2_BUCKET,
          Key: r2Key,
          Body: await fs.readFile(outputPath),
        };

        const upload = new Upload({
          client: r2Client,
          params: uploadParams,
        });

        await upload.done();
        logger.log("Image uploaded to R2 storage.", {
          path: `/${process.env.R2_BUCKET}/${r2Key}`,
        });

        await fs.unlink(outputPath); // Clean up the temporary file
        return { r2Key };
      });
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "imageUrl": "<an-image-url.jpg>", // Replace with a URL to a JPEG image
  "watermarkUrl": "<an-image-url.png>" // Replace with a URL to a PNG watermark image
}
```

## Local development

To test this example task locally, be sure to install any packages from the build extensions you added to your `trigger.config.ts` file to your local machine. In this case, you need to install {packages_0}.


# Trigger a task from Stripe webhook events
Source: https://trigger.dev/docs/guides/examples/stripe-webhook

This example demonstrates how to handle Stripe webhook events using Trigger.dev.

## Overview

This example shows how to set up a webhook handler in your existing app for incoming Stripe events. The handler triggers a task when a `checkout.session.completed` event is received. This is easily customisable to handle other Stripe events.

## Key features

* Shows how to create a Stripe webhook handler in your app
* Triggers a task from your backend when a `checkout.session.completed` event is received

## Environment variables

You'll need to configure the following environment variables for this example to work:

* `STRIPE_WEBHOOK_SECRET` The secret key used to verify the Stripe webhook signature.
* `TRIGGER_API_URL` Your Trigger.dev API url: `https://api.trigger.dev`
* `TRIGGER_SECRET_KEY` Your Trigger.dev secret key

## Setting up the Stripe webhook handler

First you'll need to create a [Stripe webhook](https://stripe.com/docs/webhooks) handler route that listens for POST requests and verifies the Stripe signature.

Here are examples of how you can set up a handler using different frameworks:

<CodeGroup>
  ```ts Next.js theme={null}
  // app/api/stripe-webhook/route.ts
  import { NextResponse } from "next/server";
  import { tasks } from "@trigger.dev/sdk";
  import Stripe from "stripe";
  import type { stripeCheckoutCompleted } from "@/trigger/stripe-checkout-completed";
  //     ðŸ‘† **type-only** import

  export async function POST(request: Request) {
    const signature = request.headers.get("stripe-signature");
    const payload = await request.text();

    if (!signature || !payload) {
      return NextResponse.json(
        { error: "Invalid Stripe payload/signature" },
        {
          status: 400,
        }
      );
    }

    const event = Stripe.webhooks.constructEvent(
      payload,
      signature,
      process.env.STRIPE_WEBHOOK_SECRET as string
    );

    // Perform the check based on the event type
    switch (event.type) {
      case "checkout.session.completed": {
        // Trigger the task only if the event type is "checkout.session.completed"
        const { id } = await tasks.trigger<typeof stripeCheckoutCompleted>(
          "stripe-checkout-completed",
          event.data.object
        );
        return NextResponse.json({ runId: id });
      }
      default: {
        // Return a response indicating that the event is not handled
        return NextResponse.json(
          { message: "Event not handled" },
          {
            status: 200,
          }
        );
      }
    }
  }
  ```

  ```ts Remix theme={null}
  // app/webhooks.stripe.ts
  import { type ActionFunctionArgs, json } from "@remix-run/node";
  import type { stripeCheckoutCompleted } from "src/trigger/stripe-webhook";
  //     ðŸ‘† **type-only** import
  import { tasks } from "@trigger.dev/sdk";
  import Stripe from "stripe";

  export async function action({ request }: ActionFunctionArgs) {
    // Validate the Stripe webhook payload
    const signature = request.headers.get("stripe-signature");
    const payload = await request.text();

    if (!signature || !payload) {
      return json({ error: "Invalid Stripe payload/signature" }, { status: 400 });
    }

    const event = Stripe.webhooks.constructEvent(
      payload,
      signature,
      process.env.STRIPE_WEBHOOK_SECRET as string
    );

    // Perform the check based on the event type
    switch (event.type) {
      case "checkout.session.completed": {
        // Trigger the task only if the event type is "checkout.session.completed"
        const { id } = await tasks.trigger<typeof stripeCheckoutCompleted>(
          "stripe-checkout-completed",
          event.data.object
        );
        return json({ runId: id });
      }
      default: {
        // Return a response indicating that the event is not handled
        return json({ message: "Event not handled" }, { status: 200 });
      }
    }
  }
  ```
</CodeGroup>

## Task code

This task is triggered when a `checkout.session.completed` event is received from Stripe.

```ts trigger/stripe-checkout-completed.ts theme={null}
import { task } from "@trigger.dev/sdk";
import type stripe from "stripe";

export const stripeCheckoutCompleted = task({
  id: "stripe-checkout-completed",
  run: async (payload: stripe.Checkout.Session) => {
    // Add your custom logic for handling the checkout.session.completed event here
  },
});
```

## Testing your task locally

To test everything is working you can use the Stripe CLI to send test events to your endpoint:

1. Install the [Stripe CLI](https://stripe.com/docs/stripe-cli#install), and login
2. Follow the instructions to [test your handler](https://docs.stripe.com/webhooks#test-webhook). This will include a temporary `STRIPE_WEBHOOK_SECRET` that you can use for testing.
3. When triggering the event, use the `checkout.session.completed` event type. With the Stripe CLI: `stripe trigger checkout.session.completed`
4. If your endpoint is set up correctly, you should see the Stripe events logged in your console with a status of `200`.
5. Then, check the [Trigger.dev](https://cloud.trigger.dev) dashboard and you should see the successful run of the `stripe-webhook` task.

For more information on setting up and testing Stripe webhooks, refer to the [Stripe Webhook Documentation](https://stripe.com/docs/webhooks).


# Supabase database operations using Trigger.dev
Source: https://trigger.dev/docs/guides/examples/supabase-database-operations

These examples demonstrate how to run basic CRUD operations on a table in a Supabase database using Trigger.dev.

## Add a new user to a table in a Supabase database

This is a basic task which inserts a new row into a table from a Trigger.dev task.

### Key features

* Shows how to set up a Supabase client using the `@supabase/supabase-js` library
* Shows how to add a new row to a table using `insert`

### Prerequisites

* A [Supabase account](https://supabase.com/dashboard/) and a project set up
* In your Supabase project, create a table called `user_subscriptions`.
* In your `user_subscriptions` table, create a new column:
  * `user_id`, with the data type: `text`

### Task code

```ts trigger/supabase-database-insert.ts theme={null}
import { createClient } from "@supabase/supabase-js";
import { task } from "@trigger.dev/sdk";
import jwt from "jsonwebtoken";
// Generate the Typescript types using the Supabase CLI: https://supabase.com/docs/guides/api/rest/generating-types
import { Database } from "database.types";

export const supabaseDatabaseInsert = task({
  id: "add-new-user",
  run: async (payload: { userId: string }) => {
    const { userId } = payload;

    // Get JWT secret from env vars
    const jwtSecret = process.env.SUPABASE_JWT_SECRET;
    if (!jwtSecret) {
      throw new Error("SUPABASE_JWT_SECRET is not defined in environment variables");
    }

    // Create JWT token for the user
    const token = jwt.sign({ sub: userId }, jwtSecret, { expiresIn: "1h" });

    // Initialize Supabase client with JWT
    const supabase = createClient<Database>(
      process.env.SUPABASE_URL as string,
      process.env.SUPABASE_ANON_KEY as string,
      {
        global: {
          headers: {
            Authorization: `Bearer ${token}`,
          },
        },
      }
    );

    // Insert a new row into the user_subscriptions table with the provided userId
    const { error } = await supabase.from("user_subscriptions").insert({
      user_id: userId,
    });

    // If there was an error inserting the new user, throw an error
    if (error) {
      throw new Error(`Failed to insert new user: ${error.message}`);
    }

    return {
      message: `New user added successfully: ${userId}`,
    };
  },
});
```

<Note>
  To learn more about how to properly configure Supabase auth for Trigger.dev tasks, please refer to
  our [Supabase Authentication guide](/guides/frameworks/supabase-authentication). It demonstrates
  how to use JWT authentication for user-specific operations or your service role key for
  admin-level access.
</Note>

### Testing your task

To test this task in the [Trigger.dev dashboard](https://cloud.trigger.dev), you can use the following payload:

```json  theme={null}
{
  "userId": "user_12345"
}
```

If the task completes successfully, you will see a new row in your `user_subscriptions` table with the `user_id` set to `user_12345`.

## Update a user's subscription on a table in a Supabase database

This task shows how to update a user's subscription on a table. It checks if the user already has a subscription and either inserts a new row or updates an existing row with the new plan.

This type of task is useful for managing user subscriptions, updating user details, or performing other operations you might need to do on a database table.

### Key features

* Shows how to set up a Supabase client using the `@supabase/supabase-js` library
* Adds a new row to the table if the user doesn't exist using `insert`
* Checks if the user already has a plan, and if they do updates the existing row using `update`
* Demonstrates how to use [AbortTaskRunError](https://trigger.dev/docs/errors-retrying#using-aborttaskrunerror) to stop the task run without retrying if an invalid plan type is provided

### Prerequisites

* A [Supabase account](https://supabase.com/dashboard/) and a project set up
* In your Supabase project, create a table called `user_subscriptions` (if you haven't already)
* In your `user_subscriptions` table, create these columns (if they don't already exist):

  * `user_id`, with the data type: `text`
  * `plan`, with the data type: `text`
  * `updated_at`, with the data type: `timestamptz`

### Task code

```ts trigger/supabase-update-user-subscription.ts theme={null}
import { createClient } from "@supabase/supabase-js";
import { AbortTaskRunError, task } from "@trigger.dev/sdk";
// Generate the Typescript types using the Supabase CLI: https://supabase.com/docs/guides/api/rest/generating-types
import { Database } from "database.types";

// Define the allowed plan types
type PlanType = "hobby" | "pro" | "enterprise";

// Create a single Supabase client for interacting with your database
// 'Database' supplies the type definitions to supabase-js
const supabase = createClient<Database>(
  // These details can be found in your Supabase project settings under `API`
  process.env.SUPABASE_PROJECT_URL as string, // e.g. https://abc123.supabase.co - replace 'abc123' with your project ID
  process.env.SUPABASE_SERVICE_ROLE_KEY as string // Your service role secret key
);

export const supabaseUpdateUserSubscription = task({
  id: "update-user-subscription",
  run: async (payload: { userId: string; newPlan: PlanType }) => {
    const { userId, newPlan } = payload;

    // Abort the task run without retrying if the new plan type is invalid
    if (!["hobby", "pro", "enterprise"].includes(newPlan)) {
      throw new AbortTaskRunError(
        `Invalid plan type: ${newPlan}. Allowed types are 'hobby', 'pro', or 'enterprise'.`
      );
    }

    // Query the user_subscriptions table to check if the user already has a subscription
    const { data: existingSubscriptions } = await supabase
      .from("user_subscriptions")
      .select("user_id")
      .eq("user_id", userId);

    if (!existingSubscriptions || existingSubscriptions.length === 0) {
      // If there are no existing users with the provided userId and plan, insert a new row
      const { error: insertError } = await supabase.from("user_subscriptions").insert({
        user_id: userId,
        plan: newPlan,
        updated_at: new Date().toISOString(),
      });

      // If there was an error inserting the new subscription, throw an error
      if (insertError) {
        throw new Error(`Failed to insert user subscription: ${insertError.message}`);
      }
    } else {
      // If the user already has a subscription, update their existing row
      const { error: updateError } = await supabase
        .from("user_subscriptions")
        // Set the plan to the new plan and update the timestamp
        .update({ plan: newPlan, updated_at: new Date().toISOString() })
        .eq("user_id", userId);

      // If there was an error updating the subscription, throw an error
      if (updateError) {
        throw new Error(`Failed to update user subscription: ${updateError.message}`);
      }
    }

    // Return an object with the userId and newPlan
    return {
      userId,
      newPlan,
    };
  },
});
```

<Note>
  This task uses your service role secret key to bypass Row Level Security. There are different ways
  of configuring your [RLS
  policies](https://supabase.com/docs/guides/database/postgres/row-level-security), so always make
  sure you have the correct permissions set up for your project.
</Note>

### Testing your task

To test this task in the [Trigger.dev dashboard](https://cloud.trigger.dev), you can use the following payload:

```json  theme={null}
{
  "userId": "user_12345",
  "newPlan": "pro"
}
```

If the task completes successfully, you will see a new row in your `user_subscriptions` table with the `user_id` set to `user_12345`, the `plan` set to `pro`, and the `updated_at` timestamp updated to the current time.

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Uploading files to Supabase Storage
Source: https://trigger.dev/docs/guides/examples/supabase-storage-upload

This example demonstrates how to upload files to Supabase Storage using Trigger.dev.

## Overview

This example shows how to upload a video file to Supabase Storage using two different methods.

* [Upload to Supabase Storage using the Supabase client](/guides/examples/supabase-storage-upload#example-1-upload-to-supabase-storage-using-the-supabase-storage-client)
* [Upload to Supabase Storage using the AWS S3 client](/guides/examples/supabase-storage-upload#example-2-upload-to-supabase-storage-using-the-aws-s3-client)

## Upload to Supabase Storage using the Supabase client

This task downloads a video from a provided URL and uploads it to Supabase Storage using the Supabase client.

### Task code

```ts trigger/supabase-storage-upload.ts theme={null}
import { createClient } from "@supabase/supabase-js";
import { logger, task } from "@trigger.dev/sdk";
import fetch from "node-fetch";

// Initialize Supabase client
const supabase = createClient(
  process.env.SUPABASE_PROJECT_URL ?? "",
  process.env.SUPABASE_SERVICE_ROLE_KEY ?? ""
);

export const supabaseStorageUpload = task({
  id: "supabase-storage-upload",
  run: async (payload: { videoUrl: string }) => {
    const { videoUrl } = payload;

    const bucket = "my_bucket"; // Replace "my_bucket" with your bucket name
    const objectKey = `video_${Date.now()}.mp4`;

    // Download video data as a buffer
    const response = await fetch(videoUrl);

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const videoBuffer = await response.buffer();

    // Upload the video directly to Supabase Storage
    const { error } = await supabase.storage.from(bucket).upload(objectKey, videoBuffer, {
      contentType: "video/mp4",
      upsert: true,
    });

    if (error) {
      throw new Error(`Error uploading video: ${error.message}`);
    }

    logger.log(`Video uploaded to Supabase Storage bucket`, { objectKey });

    // Return the video object key and bucket
    return {
      objectKey,
      bucket: bucket,
    };
  },
});
```

### Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "videoUrl": "<a-video-url>" // Replace <a-video-url> with the URL of the video you want to upload
}
```

## Upload to Supabase Storage using the AWS S3 client

This task downloads a video from a provided URL, saves it to a temporary file, and then uploads the video file to Supabase Storage using the AWS S3 client.

### Key features

* Fetches a video from a provided URL
* Uploads the video file to Supabase Storage using S3

### Task code

```ts trigger/supabase-storage-upload-s3.ts theme={null}
import { PutObjectCommand, S3Client } from "@aws-sdk/client-s3";
import { logger, task } from "@trigger.dev/sdk";
import fetch from "node-fetch";

// Initialize S3 client for Supabase Storage
const s3Client = new S3Client({
  region: process.env.SUPABASE_REGION, // Your Supabase project's region e.g. "us-east-1"
  endpoint: `https://${process.env.SUPABASE_PROJECT_ID}.supabase.co/storage/v1/s3`,
  credentials: {
    // These credentials can be found in your supabase storage settings, under 'S3 access keys'
    accessKeyId: process.env.SUPABASE_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.SUPABASE_SECRET_ACCESS_KEY ?? "",
  },
});

export const supabaseStorageUploadS3 = task({
  id: "supabase-storage-upload-s3",
  run: async (payload: { videoUrl: string }) => {
    const { videoUrl } = payload;

    // Fetch the video as an ArrayBuffer
    const response = await fetch(videoUrl);
    const videoArrayBuffer = await response.arrayBuffer();
    const videoBuffer = Buffer.from(videoArrayBuffer);

    const bucket = "my_bucket"; // Replace "my_bucket" with your bucket name
    const objectKey = `video_${Date.now()}.mp4`;

    // Upload the video directly to Supabase Storage
    await s3Client.send(
      new PutObjectCommand({
        Bucket: bucket,
        Key: objectKey,
        Body: videoBuffer,
      })
    );
    logger.log(`Video uploaded to Supabase Storage bucket`, { objectKey });

    // Return the video object key
    return {
      objectKey,
      bucket: bucket,
    };
  },
});
```

<Note>
  To learn more about how to properly configure Supabase auth for Trigger.dev tasks, please refer to
  our [Supabase Authentication guide](/guides/frameworks/supabase-authentication). It demonstrates
  how to use JWT authentication for user-specific operations or your service role key for
  admin-level access.
</Note>

### Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "videoUrl": "<a-video-url>" // Replace <a-video-url> with the URL of the video you want to upload
}
```

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Using the Vercel AI SDK
Source: https://trigger.dev/docs/guides/examples/vercel-ai-sdk

This example demonstrates how to use the Vercel AI SDK with Trigger.dev.

## Overview

The [Vercel AI SDK](https://www.npmjs.com/package/ai) is a simple way to use AI models from many different providers, including OpenAI, Microsoft Azure, Google Generative AI, Anthropic, Amazon Bedrock, Groq, Perplexity and [more](https://sdk.vercel.ai/providers/ai-sdk-providers).

It provides a consistent interface to interact with the different AI models, so you can easily switch between them without needing to change your code.

## Generate text using OpenAI

This task shows how to use the Vercel AI SDK to generate text from a prompt with OpenAI.

### Task code

```ts trigger/vercel-ai-sdk-openai.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { generateText } from "ai";
// Install the package of the AI model you want to use, in this case OpenAI
import { openai } from "@ai-sdk/openai"; // Ensure OPENAI_API_KEY environment variable is set

export const openaiTask = task({
  id: "openai-text-generate",

  run: async (payload: { prompt: string }) => {
    const chatCompletion = await generateText({
      model: openai("gpt-4-turbo"),
      // Add a system message which will be included with the prompt
      system: "You are a friendly assistant!",
      // The prompt passed in from the payload
      prompt: payload.prompt,
    });

    // Log the generated text
    logger.log("chatCompletion text:" + chatCompletion.text);

    return chatCompletion;
  },
});
```

## Testing your task

To test this task in the dashboard, you can use the following payload:

```json  theme={null}
{
  "prompt": "What is the meaning of life?"
}
```

## Learn more about Next.js and Trigger.dev

### Walk-through guides from development to deployment

<CardGroup cols={2}>
  <Card title="Next.js - setup guide" icon="N" href="/guides/frameworks/nextjs">
    Learn how to setup Trigger.dev with Next.js, using either the pages or app router.
  </Card>

  <Card title="Next.js - triggering tasks using webhooks" icon="N" href="/guides/frameworks/nextjs-webhooks">
    Learn how to create a webhook handler for incoming webhooks in a Next.js app, and trigger a task from it.
  </Card>
</CardGroup>

### Task examples

<CardGroup cols={2}>
  <Card title="Fal.ai with Realtime in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9ac31bb57678b222a82b04055184eea0" href="/guides/examples/fal-ai-realtime" data-og-width="1442" width="1442" data-og-height="812" height="812" data-path="images/fal-realtime-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=086231461af2b9520f9200889fc04724 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5ab58baba8000266aac79117dc8944d 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988fe253a646e5af2188f81297d01897 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=db65bbdf0995fc1ac72bda2512c31800 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e7890d597065f8bc9edd0ac90257185 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60bc05bc63c0c1d1ad59eaafb0808aa6 2500w">
    Generate an image from a prompt using Fal.ai and Trigger.dev Realtime.
  </Card>

  <Card title="Generate a cartoon using Fal.ai in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=003d7870f36310d14ca9a71a952667d3" href="/guides/examples/fal-ai-image-to-cartoon" data-og-width="1442" width="1442" data-og-height="816" height="816" data-path="images/fal-generate-cartoon-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ec0e05813f874082257e2d32bad407a8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f3f70889ad11953d44f72224712722aa 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b8df38a222a7431d55a1af1af61dffd1 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=268ac6b0faf34bb46a8a8d676658b0b8 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4be96f4df2d49b7a71d0e960df9cc93b 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bc15e1a3df4484cfdcd200d49fd1ac4b 2500w">
    Convert an image to a cartoon using Fal.ai.
  </Card>

  <Card title="Vercel sync environment variables" icon="code" href="/guides/examples/vercel-sync-env-vars">
    Learn how to automatically sync environment variables from your Vercel projects to Trigger.dev.
  </Card>

  <Card title="Vercel AI SDK" icon="code" href="/guides/examples/vercel-ai-sdk">
    Learn how to use the Vercel AI SDK, which is a simple way to use AI models from different
    providers, including OpenAI, Anthropic, Amazon Bedrock, Groq, Perplexity etc.
  </Card>
</CardGroup>


# Syncing environment variables from your Vercel projects
Source: https://trigger.dev/docs/guides/examples/vercel-sync-env-vars

This example demonstrates how to sync environment variables from your Vercel project to Trigger.dev.

## Build configuration

To sync environment variables, you just need to add our build extension to your `trigger.config.ts` file. This extension will then automatically run every time you deploy your Trigger.dev project.

<Note>
  You need to set the `VERCEL_ACCESS_TOKEN` and `VERCEL_PROJECT_ID` environment variables, or pass
  in the token and project ID as arguments to the `syncVercelEnvVars` build extension. If you're
  working with a team project, you'll also need to set `VERCEL_TEAM_ID`, which can be found in your
  team settings. You can find / generate the `VERCEL_ACCESS_TOKEN` in your Vercel
  [dashboard](https://vercel.com/account/settings/tokens). Make sure the scope of the token covers
  the project with the environment variables you want to sync.
</Note>

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncVercelEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    // Add the syncVercelEnvVars build extension
    extensions: [
      syncVercelEnvVars({
        // A personal access token created in your Vercel account settings
        // Used to authenticate API requests to Vercel
        // Generate at: https://vercel.com/account/tokens
        vercelAccessToken: process.env.VERCEL_ACCESS_TOKEN,
        // The unique identifier of your Vercel project
        // Found in Project Settings > General > Project ID
        projectId: process.env.VERCEL_PROJECT_ID,
        // Optional: The ID of your Vercel team
        // Only required for team projects
        // Found in Team Settings > General > Team ID
        vercelTeamId: process.env.VERCEL_TEAM_ID,
      }),
    ],
  },
});
```

<Note>
  [Build extensions](/config/extensions/overview) allow you to hook into the build system and
  customize the build process or the resulting bundle and container image (in the case of
  deploying). You can use pre-built extensions or create your own.
</Note>

## Running the sync operation

To sync the environment variables, all you need to do is run our `deploy` command. You should see some output in the console indicating that the environment variables have been synced, and they should now be available in your Trigger.dev dashboard.

```bash  theme={null}
npx trigger.dev@latest deploy
```

## Learn more about Next.js and Trigger.dev

### Walk-through guides from development to deployment

<CardGroup cols={2}>
  <Card title="Next.js - setup guide" icon="N" href="/guides/frameworks/nextjs">
    Learn how to setup Trigger.dev with Next.js, using either the pages or app router.
  </Card>

  <Card title="Next.js - triggering tasks using webhooks" icon="N" href="/guides/frameworks/nextjs-webhooks">
    Learn how to create a webhook handler for incoming webhooks in a Next.js app, and trigger a task from it.
  </Card>
</CardGroup>

### Task examples

<CardGroup cols={2}>
  <Card title="Fal.ai with Realtime in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9ac31bb57678b222a82b04055184eea0" href="/guides/examples/fal-ai-realtime" data-og-width="1442" width="1442" data-og-height="812" height="812" data-path="images/fal-realtime-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=086231461af2b9520f9200889fc04724 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5ab58baba8000266aac79117dc8944d 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988fe253a646e5af2188f81297d01897 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=db65bbdf0995fc1ac72bda2512c31800 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e7890d597065f8bc9edd0ac90257185 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60bc05bc63c0c1d1ad59eaafb0808aa6 2500w">
    Generate an image from a prompt using Fal.ai and Trigger.dev Realtime.
  </Card>

  <Card title="Generate a cartoon using Fal.ai in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=003d7870f36310d14ca9a71a952667d3" href="/guides/examples/fal-ai-image-to-cartoon" data-og-width="1442" width="1442" data-og-height="816" height="816" data-path="images/fal-generate-cartoon-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ec0e05813f874082257e2d32bad407a8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f3f70889ad11953d44f72224712722aa 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b8df38a222a7431d55a1af1af61dffd1 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=268ac6b0faf34bb46a8a8d676658b0b8 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4be96f4df2d49b7a71d0e960df9cc93b 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bc15e1a3df4484cfdcd200d49fd1ac4b 2500w">
    Convert an image to a cartoon using Fal.ai.
  </Card>

  <Card title="Vercel sync environment variables" icon="code" href="/guides/examples/vercel-sync-env-vars">
    Learn how to automatically sync environment variables from your Vercel projects to Trigger.dev.
  </Card>

  <Card title="Vercel AI SDK" icon="code" href="/guides/examples/vercel-ai-sdk">
    Learn how to use the Vercel AI SDK, which is a simple way to use AI models from different
    providers, including OpenAI, Anthropic, Amazon Bedrock, Groq, Perplexity etc.
  </Card>
</CardGroup>


# Bun guide
Source: https://trigger.dev/docs/guides/frameworks/bun

This guide will show you how to setup Trigger.dev in your existing Bun project, test an example task, and view the run.

export const framework_0 = "Bun"

<Warning>
  The trigger.dev CLI does not yet support Bun. So you will need to run the CLI using Node.js.
  Bun will still be used to execute your tasks, even in the `dev` environment.
</Warning>

## Prerequisites

* Setup a project in {framework_0}
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## Known issues

* Certain OpenTelemetry instrumentation will not work with Bun, because Bun does not support Node's `register` hook. This means that some libraries that rely on this hook will not work with Bun.

## Initial setup

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init --runtime bun
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init --runtime bun
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init --runtime bun
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/src/trigger` directory with an example task, `/src/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Update example.ts to use Bun">
    Open the `/src/trigger/example.ts` file and replace the contents with the following:

    ```ts example.ts theme={null}
    import { Database } from "bun:sqlite";
    import { task } from "@trigger.dev/sdk";

    export const bunTask = task({
      id: "bun-task",
      run: async (payload: { query: string }) => {
        const db = new Database(":memory:");
        const query = db.query("select 'Hello world' as message;");
        console.log(query.get()); // => { message: "Hello world" }

        return {
          message: "Query executed",
        };
      },
    });

    ```
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>


# Drizzle setup guide
Source: https://trigger.dev/docs/guides/frameworks/drizzle

This guide will show you how to set up Drizzle ORM with Trigger.dev

## Overview

This guide will show you how to set up [Drizzle ORM](https://orm.drizzle.team/) with Trigger.dev, test and view an example task run.

## Prerequisites

* An existing Node.js project with a `package.json` file
* Ensure TypeScript is installed
* A [PostgreSQL](https://www.postgresql.org/) database server running locally, or accessible via a connection string
* Drizzle ORM [installed and initialized](https://orm.drizzle.team/docs/get-started) in your project
* A `DATABASE_URL` environment variable set in your `.env` file, pointing to your PostgreSQL database (e.g. `postgresql://user:password@localhost:5432/dbname`)

## Initial setup (optional)

Follow these steps if you don't already have Trigger.dev set up in your project.

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Creating a task using Drizzle and deploying it to production

<Steps>
  <Step title="The task using Drizzle">
    First, create a new task file in your `trigger` folder.

    This is a simple task that will add a new user to your database, we will call it `drizzle-add-new-user`.

    <Note>
      For this task to work correctly, you will need to have a `users` table schema defined with Drizzle
      that includes `name`, `age` and `email` fields.
    </Note>

    ```ts /trigger/drizzle-add-new-user.ts theme={null}
    import { eq } from "drizzle-orm";
    import { task } from "@trigger.dev/sdk";
    import { users } from "src/db/schema";
    import { drizzle } from "drizzle-orm/node-postgres";

    // Initialize Drizzle client
    const db = drizzle(process.env.DATABASE_URL!);

    export const addNewUser = task({
      id: "drizzle-add-new-user",
      run: async (payload: typeof users.$inferInsert) => {
        // Create new user
        const [user] = await db.insert(users).values(payload).returning();

        return {
          createdUser: user,
          message: "User created and updated successfully",
        };
      },
    });
    ```
  </Step>

  <Step title="Configuring the build">
    Next, in your `trigger.config.js` file, add `pg` to the `externals` array. `pg` is a non-blocking PostgreSQL client for Node.js.

    It is marked as an external to ensure that it is not bundled into the task's bundle, and instead will be installed and loaded from `node_modules` at runtime.

    ```js /trigger.config.js theme={null}
    import { defineConfig } from "@trigger.dev/sdk";

    export default defineConfig({
      project: "<project ref>", // Your project reference
      // Your other config settings...
      build: {
        externals: ["pg"],
      },
    });
    ```
  </Step>

  <Step title="Deploying your task">
    Once the build configuration is added, you can now deploy your task using the Trigger.dev CLI.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest deploy
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest deploy
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest deploy
      ```
    </CodeGroup>
  </Step>

  <Step title="Adding your DATABASE_URL environment variable to Trigger.dev">
    In your Trigger.dev dashboard sidebar click "Environment Variables" <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />, and then the "New environment variable" button <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />.

        <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=af652254781808a35c2bcefd4b61b59f" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-page.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fd6487833d9c659f8a514c7cc86cf84d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1758721fd84f5040b88997db401f7391 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4416f51b1528ae14285a03b560f22389 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12b90b89f7662aadaea07df17d9d3898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28e6921620cda10d335a095dbfa85806 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4f6c67a030b20699bde25c22d68e57af 2500w" />

    You can add values for your local dev environment, staging and prod. in this case we will add the `DATABASE_URL` for the production environment.

        <img
          src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79b5fd91e809cb0c6c9298410922df96"
          alt="Environment variables
    page"
          data-og-width="1600"
          width="1600"
          data-og-height="900"
          height="900"
          data-path="images/environment-variables-panel.jpg"
          data-optimize="true"
          data-opv="3"
          srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4c3f6181dea5542157cdbdebafb44989 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0c302ef3d814a0c781b684e64d090f9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a110ee9bb119eaaf7404097904a1f442 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e774fb137908fbaaf28318d1bfa419d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aa5d4bef7b66551887043c4420807bc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed23a501677d11631bb832eb6f95ceae 2500w"
        />
  </Step>

  <Step title="Running your task">
    To test this task, go to the 'test' page in the Trigger.dev dashboard and run the task with the following payload:

    ```json  theme={null}
    {
      "name": "<a-name>", // e.g. "John Doe"
      "age": "<an-age>", // e.g. 25
      "email": "<an-email>" // e.g. "john@doe.test"
    }
    ```

    Congratulations! You should now see a new completed run, and a new user with the credentials you provided should be added to your database.
  </Step>
</Steps>

## Useful next steps

<CardGroup cols={2}>
  <Card title="Tasks overview" icon="diagram-subtask" href="/tasks/overview">
    Learn what tasks are and their options
  </Card>

  <Card title="Writing tasks" icon="pen-nib" href="/writing-tasks-introduction">
    Learn how to write your own tasks
  </Card>

  <Card title="Deploy using the CLI" icon="terminal" href="/cli-deploy">
    Learn how to deploy your task manually using the CLI
  </Card>

  <Card title="Deploy using GitHub actions" icon="github" href="/github-actions">
    Learn how to deploy your task using GitHub actions
  </Card>
</CardGroup>


# Next.js setup guide
Source: https://trigger.dev/docs/guides/frameworks/nextjs

This guide will show you how to setup Trigger.dev in your existing Next.js project, test an example task, and view the run.

export const framework_0 = "Next.js"

<Note>This guide can be followed for both App and Pages router as well as Server Actions.</Note>

## Prerequisites

* Setup a project in {framework_0}
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## Initial setup

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

<Tip>
  Instead of running your Next.js app and Trigger.dev dev server in separate terminals, you can run them concurrently. First, add these scripts to your `package.json`:

  ```json  theme={null}
  {
    "scripts": {
      "trigger:dev": "npx trigger.dev@latest dev",
      "dev": "npx concurrently --kill-others --names \"next,trigger\" --prefix-colors \"yellow,blue\" \"next dev\" \"npm run trigger:dev\""
    }
  }
  ```

  Then, in your terminal, you can start both servers with a single command:

  ```bash  theme={null}
  npm run dev
  ```

  This will run both your Next.js app and Trigger.dev dev server in the same terminal window, with color-coded output to distinguish between them.
</Tip>

## Set your secret key locally

Set your `TRIGGER_SECRET_KEY` environment variable in your `.env.local` file if using the Next.js App router or `.env` file if using Pages router. This key is used to authenticate with Trigger.dev, so you can trigger runs from your Next.js app. Visit the API Keys page in the dashboard and select the DEV secret key.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=89dd26bf57f345bad4508ee5eec70c8c" alt="How to find your secret key" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/api-keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988f98dd098b108ca51d8c0aeb829344 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=14431ee3376a9a6b845744b0b3acce60 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9059b9369eb793b9df4cceee1f985286 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccd1e2a8512f491128a53cd4ebe8823f 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ab656ff2f4b95e32558aacaa485c86ea 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3bb0b87a8e1a3033a8ff1ba3590f5786 2500w" />

For more information on authenticating with Trigger.dev, see the [API keys page](/apikeys).

## Triggering your task in Next.js

Here are the steps to trigger your task in the Next.js App and Pages router and Server Actions. Alternatively, check out this repo for a [full working example](https://github.com/triggerdotdev/example-projects/tree/main/nextjs/server-actions/my-app) of a Next.js app with a Trigger.dev task triggered using a Server Action.

<Tabs>
  <Tab title="App Router">
    <Steps>
      <Step title="Create a Route Handler">
        Add a Route Handler by creating a `route.ts` file (or `route.js` file) in the `app/api` directory like this: `app/api/hello-world/route.ts`.
      </Step>

      <Step title="Add your task">
        Add this code to your `route.ts` file which imports your task along with `NextResponse` to handle the API route response:

        ```ts app/api/hello-world/route.ts theme={null}
        // Next.js API route support: https://nextjs.org/docs/api-routes/introduction
        import type { helloWorldTask } from "@/trigger/example";
        import { tasks } from "@trigger.dev/sdk";
        import { NextResponse } from "next/server";

        //tasks.trigger also works with the edge runtime
        //export const runtime = "edge";

        export async function GET() {
          const handle = await tasks.trigger<typeof helloWorldTask>(
            "hello-world",
            "James"
          );

          return NextResponse.json(handle);
        }
        ```
      </Step>

      <Step title="Trigger your task">
        Run your Next.js app:

        <CodeGroup>
          ```bash npm theme={null}
          npm run dev
          ```

          ```bash pnpm theme={null}
          pnpm run dev
          ```

          ```bash yarn theme={null}
          yarn dev
          ```
        </CodeGroup>

        Run the dev server from Step 2. of the [Initial Setup](/guides/frameworks/nextjs#initial-setup) section above if it's not already running:

        <CodeGroup>
          ```bash npm theme={null}
          npx trigger.dev@latest dev
          ```

          ```bash pnpm theme={null}
          pnpm dlx trigger.dev@latest dev
          ```

          ```bash yarn theme={null}
          yarn dlx trigger.dev@latest dev
          ```
        </CodeGroup>

        Now visit the URL in your browser to trigger the task. Ensure the port number is the same as the one you're running your Next.js app on. For example, if you're running your Next.js app on port 3000, visit:

        ```bash  theme={null}
        http://localhost:3000/api/hello-world
        ```

        You should see the CLI log the task run with a link to view the logs in the dashboard.

                <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=75168b271620e7206a50b041224a98b0" alt="Trigger.dev CLI showing a successful run" data-og-width="839" width="839" data-og-height="174" height="174" data-path="images/trigger-cli-run-success.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5593976094a4db89b9bcefe743b670f5 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3ece99db078f44f61721287482ac6288 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=49c3058ed0f3baa282eba729cc765924 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=863029ceaad9808f725ce07a119a861a 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=98f234c6774c19d0966c77c157a696c3 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fb955cb91d22967fc4251ab00d09547d 2500w" />

        Visit the [Trigger.dev dashboard](https://cloud.trigger.dev) to see your run.
      </Step>
    </Steps>
  </Tab>

  <Tab title="App Router (Server Actions)">
    <Steps>
      <Step title="Create an `actions.ts` file">
        Create an `actions.ts` file in the `app/api` directory and add this code which imports your `helloWorldTask()` task. Make sure to include `"use server";` at the top of the file.

        ```ts app/api/actions.ts theme={null}
          "use server";

          import type { helloWorldTask } from "@/trigger/example";
          import { tasks } from "@trigger.dev/sdk";

          export async function myTask() {
            try {
              const handle = await tasks.trigger<typeof helloWorldTask>(
                "hello-world",
                "James"
              );

              return { handle };
            } catch (error) {
              console.error(error);
              return {
                error: "something went wrong",
              };
            }
          }
        ```
      </Step>

      <Step title="Create a button to trigger your task">
        For the purposes of this guide, we'll create a button with an `onClick` event that triggers your task. We'll add this to the `page.tsx` file so we can trigger the task by clicking the button. Make sure to import your task and include `"use client";` at the top of your file.

        ```ts app/page.tsx theme={null}
        "use client";

        import { myTask } from "./actions";

        export default function Home() {
          return (
            <main className="flex min-h-screen flex-col items-center justify-center p-24">
              <button
                onClick={async () => {
                  await myTask();
                }}
              >
                Trigger my task
              </button>
            </main>
          );
        }
        ```
      </Step>

      <Step title="Trigger your task">
        Run your Next.js app:

        <CodeGroup>
          ```bash npm theme={null}
          npm run dev
          ```

          ```bash pnpm theme={null}
          pnpm run dev
          ```

          ```bash yarn theme={null}
          yarn dev
          ```
        </CodeGroup>

        Open your app in a browser, making sure the port number is the same as the one you're running your Next.js app on. For example, if you're running your Next.js app on port 3000, visit:

        ```bash  theme={null}
        http://localhost:3000
        ```

        Run the dev server from Step 2. of the [Initial Setup](/guides/frameworks/nextjs#initial-setup) section above if it's not already running:

        <CodeGroup>
          ```bash npm theme={null}
          npx trigger.dev@latest dev
          ```

          ```bash pnpm theme={null}
          pnpm dlx trigger.dev@latest dev
          ```

          ```bash yarn theme={null}
          yarn dlx trigger.dev@latest dev
          ```
        </CodeGroup>

        Then click the button we created in your app to trigger the task. You should see the CLI log the task run with a link to view the logs.

                <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=75168b271620e7206a50b041224a98b0" alt="Trigger.dev CLI showing a successful run" data-og-width="839" width="839" data-og-height="174" height="174" data-path="images/trigger-cli-run-success.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5593976094a4db89b9bcefe743b670f5 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3ece99db078f44f61721287482ac6288 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=49c3058ed0f3baa282eba729cc765924 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=863029ceaad9808f725ce07a119a861a 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=98f234c6774c19d0966c77c157a696c3 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fb955cb91d22967fc4251ab00d09547d 2500w" />

        Visit the [Trigger.dev dashboard](https://cloud.trigger.dev) to see your run.
      </Step>
    </Steps>
  </Tab>

  <Tab title="Pages Router">
    <Steps>
      <Step title="Create an API route">
        Create an API route in the `pages/api` directory. Then create a `hello-world .ts` (or `hello-world.js`) file for your task and copy this code example:

        ```ts pages/api/hello-world.ts theme={null}
        // Next.js API route support: https://nextjs.org/docs/api-routes/introduction
        import { helloWorldTask } from "@/trigger/example";
        import { tasks } from "@trigger.dev/sdk";
        import type { NextApiRequest, NextApiResponse } from "next";

        export default async function handler(
          req: NextApiRequest,
          res: NextApiResponse<{ id: string }>
        ) {
          const handle = await tasks.trigger<typeof helloWorldTask>(
          "hello-world",
          "James"
          );

          res.status(200).json(handle);
        }
        ```
      </Step>

      <Step title="Trigger your task">
        Run your Next.js app:

        <CodeGroup>
          ```bash npm theme={null}
          npm run dev
          ```

          ```bash pnpm theme={null}
          pnpm run dev
          ```

          ```bash yarn theme={null}
          yarn dev
          ```
        </CodeGroup>

        Run the dev server from Step 2. of the [Initial Setup](/guides/frameworks/nextjs#initial-setup) section above if it's not already running:

        <CodeGroup>
          ```bash npm theme={null}
          npx trigger.dev@latest dev
          ```

          ```bash pnpm theme={null}
          pnpm dlx trigger.dev@latest dev
          ```

          ```bash yarn theme={null}
          yarn dlx trigger.dev@latest dev
          ```
        </CodeGroup>

        Now visit the URL in your browser to trigger the task. Ensure the port number is the same as the one you're running your Next.js app on. For example, if you're running your Next.js app on port 3000, visit:

        ```bash  theme={null}
        http://localhost:3000/api/hello-world
        ```

        You should see the CLI log the task run with a link to view the logs in the dashboard.

                <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=75168b271620e7206a50b041224a98b0" alt="Trigger.dev CLI showing a successful run" data-og-width="839" width="839" data-og-height="174" height="174" data-path="images/trigger-cli-run-success.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5593976094a4db89b9bcefe743b670f5 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3ece99db078f44f61721287482ac6288 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=49c3058ed0f3baa282eba729cc765924 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=863029ceaad9808f725ce07a119a861a 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=98f234c6774c19d0966c77c157a696c3 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fb955cb91d22967fc4251ab00d09547d 2500w" />

        Visit the [Trigger.dev dashboard](https://cloud.trigger.dev) to see your run.
      </Step>
    </Steps>
  </Tab>
</Tabs>

## Automatically sync environment variables from your Vercel project (optional)

If you want to automatically sync environment variables from your Vercel project to Trigger.dev, you can add our `syncVercelEnvVars` build extension to your `trigger.config.ts` file.

<Note>
  You need to set the `VERCEL_ACCESS_TOKEN` and `VERCEL_PROJECT_ID` environment variables, or pass
  in the token and project ID as arguments to the `syncVercelEnvVars` build extension. If you're
  working with a team project, you'll also need to set `VERCEL_TEAM_ID`, which can be found in your
  team settings. You can find / generate the `VERCEL_ACCESS_TOKEN` in your Vercel
  [dashboard](https://vercel.com/account/settings/tokens). Make sure the scope of the token covers
  the project with the environment variables you want to sync.
</Note>

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { syncVercelEnvVars } from "@trigger.dev/build/extensions/core";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [syncVercelEnvVars()],
  },
});
```

<Note>
  For more information, see our [Vercel sync environment
  variables](/guides/examples/vercel-sync-env-vars) guide.
</Note>

## Manually add your environment variables (optional)

If you have any environment variables in your tasks, be sure to add them in the dashboard so deployed code runs successfully. In Node.js, these environment variables are accessed in your code using `process.env.MY_ENV_VAR`.

In the sidebar select the "Environment Variables" page, then press the "New environment variable"
button. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=af652254781808a35c2bcefd4b61b59f" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-page.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fd6487833d9c659f8a514c7cc86cf84d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1758721fd84f5040b88997db401f7391 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4416f51b1528ae14285a03b560f22389 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12b90b89f7662aadaea07df17d9d3898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28e6921620cda10d335a095dbfa85806 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4f6c67a030b20699bde25c22d68e57af 2500w" />

You can add values for your local dev environment, staging and prod. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79b5fd91e809cb0c6c9298410922df96" alt="Environment variables
page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-panel.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4c3f6181dea5542157cdbdebafb44989 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0c302ef3d814a0c781b684e64d090f9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a110ee9bb119eaaf7404097904a1f442 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e774fb137908fbaaf28318d1bfa419d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aa5d4bef7b66551887043c4420807bc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed23a501677d11631bb832eb6f95ceae 2500w" />

You can also add environment variables in code by following the steps on the [Environment Variables page](/deploy-environment-variables#in-your-code).

## Deploying your task to Trigger.dev

For this guide, we'll manually deploy your task by running the [CLI deploy command](/cli-deploy) below. Other ways to deploy are listed in the next section.

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

### Other ways to deploy

<Tabs>
  <Tab title="GitHub Actions">
    Use GitHub Actions to automatically deploy your tasks whenever new code is pushed and when the `trigger` directory has changes in it. Follow [this guide](/github-actions) to set up GitHub Actions.
  </Tab>

  <Tab title="Vercel Integration">
    We're working on adding an official [Vercel integration](/vercel-integration) which you can follow the progress of [here](https://feedback.trigger.dev/p/vercel-integration-3).
  </Tab>
</Tabs>

## Troubleshooting & extra resources

### Revalidation from your Trigger.dev tasks

[Revalidation](https://vercel.com/docs/incremental-static-regeneration/quickstart#on-demand-revalidation) allows you to purge the cache for an ISR route. To revalidate an ISR route from a Trigger.dev task, you have to set up a handler for the `revalidate` event. This is an API route that you can add to your Next.js app.

This handler will run the `revalidatePath` function from Next.js, which purges the cache for the given path.

The handlers are slightly different for the App and Pages router:

#### Revalidation handler: App Router

If you are using the App router, create a new revalidation route at `app/api/revalidate/path/route.ts`:

```ts app/api/revalidate/path/route.ts theme={null}
import { NextRequest, NextResponse } from "next/server";
import { revalidatePath } from "next/cache";

export async function POST(request: NextRequest) {
  try {
    const { path, type, secret } = await request.json();
    // Create a REVALIDATION_SECRET and set it in your environment variables
    if (secret !== process.env.REVALIDATION_SECRET) {
      return NextResponse.json({ message: "Invalid secret" }, { status: 401 });
    }

    if (!path) {
      return NextResponse.json({ message: "Path is required" }, { status: 400 });
    }

    revalidatePath(path, type);

    return NextResponse.json({ revalidated: true });
  } catch (err) {
    console.error("Error revalidating path:", err);
    return NextResponse.json({ message: "Error revalidating path" }, { status: 500 });
  }
}
```

#### Revalidation handler: Pages Router

If you are using the Pages router, create a new revalidation route at `pages/api/revalidate/path.ts`:

```ts pages/api/revalidate/path.ts theme={null}
import type { NextApiRequest, NextApiResponse } from "next";

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  try {
    if (req.method !== "POST") {
      return res.status(405).json({ message: "Method not allowed" });
    }

    const { path, secret } = req.body;

    if (secret !== process.env.REVALIDATION_SECRET) {
      return res.status(401).json({ message: "Invalid secret" });
    }

    if (!path) {
      return res.status(400).json({ message: "Path is required" });
    }

    await res.revalidate(path);

    return res.json({ revalidated: true });
  } catch (err) {
    console.error("Error revalidating path:", err);
    return res.status(500).json({ message: "Error revalidating path" });
  }
}
```

#### Revalidation task

This task takes a `path` as a payload and will revalidate the path you specify, using the handler you set up previously.

<Note>
  To run this task locally you will need to set the `REVALIDATION_SECRET` environment variable in your `.env.local` file (or `.env` file if using Pages router).

  To run this task in production, you will need to set the `REVALIDATION_SECRET` environment variable in Vercel, in your project settings, and also in your environment variables in the Trigger.dev dashboard.
</Note>

```ts trigger/revalidate-path.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";

const NEXTJS_APP_URL = process.env.NEXTJS_APP_URL; // e.g. "http://localhost:3000" or "https://my-nextjs-app.vercel.app"
const REVALIDATION_SECRET = process.env.REVALIDATION_SECRET; // Create a REVALIDATION_SECRET and set it in your environment variables

export const revalidatePath = task({
  id: "revalidate-path",
  run: async (payload: { path: string }) => {
    const { path } = payload;

    try {
      const response = await fetch(`${NEXTJS_APP_URL}/api/revalidate/path`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          path: `${NEXTJS_APP_URL}/${path}`,
          secret: REVALIDATION_SECRET,
        }),
      });

      if (response.ok) {
        logger.log("Path revalidation successful", { path });
        return { success: true };
      } else {
        logger.error("Path revalidation failed", {
          path,
          statusCode: response.status,
          statusText: response.statusText,
        });
        return {
          success: false,
          error: `Revalidation failed with status ${response.status}: ${response.statusText}`,
        };
      }
    } catch (error) {
      logger.error("Path revalidation encountered an error", {
        path,
        error: error instanceof Error ? error.message : String(error),
      });
      return {
        success: false,
        error: `Failed to revalidate path due to an unexpected error`,
      };
    }
  },
});
```

#### Testing the revalidation task

You can test your revalidation task in the Trigger.dev dashboard on the testing page, using the following payload.

```json  theme={null}
{
  "path": "<path-to-revalidate>" // e.g. "blog"
}
```

### Next.js build failing due to missing API key in GitHub CI

This issue occurs during the Next.js app build process on GitHub CI where the Trigger.dev SDK is expecting the TRIGGER\_SECRET\_KEY environment variable to be set at build time. Next.js attempts to compile routes and creates static pages, which can cause issues with SDKs that require runtime environment variables. The solution is to mark the relevant pages as dynamic to prevent Next.js from trying to make them static. You can do this by adding the following line to the route file:

```ts  theme={null}
export const dynamic = "force-dynamic";
```

### Correctly passing event handlers to React components

An issue can sometimes arise when you try to pass a function directly to the `onClick` prop. This is because the function may require specific arguments or context that are not available when the event occurs. By wrapping the function call in an arrow function, you ensure that the handler is called with the correct context and any necessary arguments. For example:

This works:

```tsx  theme={null}
<Button onClick={() => myTask()}>Trigger my task</Button>
```

Whereas this does not work:

```tsx  theme={null}
<Button onClick={myTask}>Trigger my task</Button>
```

## Learn more about Next.js and Trigger.dev

### Walk-through guides from development to deployment

<CardGroup cols={2}>
  <Card title="Next.js - setup guide" icon="N" href="/guides/frameworks/nextjs">
    Learn how to setup Trigger.dev with Next.js, using either the pages or app router.
  </Card>

  <Card title="Next.js - triggering tasks using webhooks" icon="N" href="/guides/frameworks/nextjs-webhooks">
    Learn how to create a webhook handler for incoming webhooks in a Next.js app, and trigger a task from it.
  </Card>
</CardGroup>

### Task examples

<CardGroup cols={2}>
  <Card title="Fal.ai with Realtime in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9ac31bb57678b222a82b04055184eea0" href="/guides/examples/fal-ai-realtime" data-og-width="1442" width="1442" data-og-height="812" height="812" data-path="images/fal-realtime-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=086231461af2b9520f9200889fc04724 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5ab58baba8000266aac79117dc8944d 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988fe253a646e5af2188f81297d01897 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=db65bbdf0995fc1ac72bda2512c31800 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e7890d597065f8bc9edd0ac90257185 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60bc05bc63c0c1d1ad59eaafb0808aa6 2500w">
    Generate an image from a prompt using Fal.ai and Trigger.dev Realtime.
  </Card>

  <Card title="Generate a cartoon using Fal.ai in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=003d7870f36310d14ca9a71a952667d3" href="/guides/examples/fal-ai-image-to-cartoon" data-og-width="1442" width="1442" data-og-height="816" height="816" data-path="images/fal-generate-cartoon-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ec0e05813f874082257e2d32bad407a8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f3f70889ad11953d44f72224712722aa 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b8df38a222a7431d55a1af1af61dffd1 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=268ac6b0faf34bb46a8a8d676658b0b8 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4be96f4df2d49b7a71d0e960df9cc93b 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bc15e1a3df4484cfdcd200d49fd1ac4b 2500w">
    Convert an image to a cartoon using Fal.ai.
  </Card>

  <Card title="Vercel sync environment variables" icon="code" href="/guides/examples/vercel-sync-env-vars">
    Learn how to automatically sync environment variables from your Vercel projects to Trigger.dev.
  </Card>

  <Card title="Vercel AI SDK" icon="code" href="/guides/examples/vercel-ai-sdk">
    Learn how to use the Vercel AI SDK, which is a simple way to use AI models from different
    providers, including OpenAI, Anthropic, Amazon Bedrock, Groq, Perplexity etc.
  </Card>
</CardGroup>

## Useful next steps

<CardGroup cols={2}>
  <Card title="Tasks overview" icon="diagram-subtask" href="/tasks/overview">
    Learn what tasks are and their options
  </Card>

  <Card title="Writing tasks" icon="pen-nib" href="/writing-tasks-introduction">
    Learn how to write your own tasks
  </Card>

  <Card title="Deploy using the CLI" icon="terminal" href="/cli-deploy">
    Learn how to deploy your task manually using the CLI
  </Card>

  <Card title="Deploy using GitHub actions" icon="github" href="/github-actions">
    Learn how to deploy your task using GitHub actions
  </Card>
</CardGroup>


# Triggering tasks with webhooks in Next.js
Source: https://trigger.dev/docs/guides/frameworks/nextjs-webhooks

Learn how to trigger a task from a webhook in a Next.js app.

## Prerequisites

* [A Next.js project, set up with Trigger.dev](/guides/frameworks/nextjs)
* [cURL](https://curl.se/) installed on your local machine. This will be used to send a POST request to your webhook handler.

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/nextjs-webhooks/my-app">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Adding the webhook handler

The webhook handler in this guide will be an API route.

This will be different depending on whether you are using the Next.js pages router or the app router.

### Pages router: creating the webhook handler

Create a new file `pages/api/webhook-handler.ts` or `pages/api/webhook-hander.js`.

In your new file, add the following code:

```ts /pages/api/webhook-handler.ts theme={null}
import { helloWorldTask } from "@/trigger/example";
import { tasks } from "@trigger.dev/sdk";
import type { NextApiRequest, NextApiResponse } from "next";

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  // Parse the webhook payload
  const payload = req.body;

  // Trigger the helloWorldTask with the webhook data as the payload
  await tasks.trigger<typeof helloWorldTask>("hello-world", payload);

  res.status(200).json({ message: "OK" });
}
```

This code will handle the webhook payload and trigger the 'Hello World' task.

### App router: creating the webhook handler

Create a new file in the `app/api/webhook-handler/route.ts` or `app/api/webhook-handler/route.js`.

In your new file, add the following code:

```ts /app/api/webhook-handler/route.ts theme={null}
import type { helloWorldTask } from "@/trigger/example";
import { tasks } from "@trigger.dev/sdk";
import { NextResponse } from "next/server";

export async function POST(req: Request) {
  // Parse the webhook payload
  const payload = await req.json();

  // Trigger the helloWorldTask with the webhook data as the payload
  await tasks.trigger<typeof helloWorldTask>("hello-world", payload);

  return NextResponse.json("OK", { status: 200 });
}
```

This code will handle the webhook payload and trigger the 'Hello World' task.

## Triggering the task locally

Now that you have your webhook handler set up, you can trigger the 'Hello World' task from it. We will do this locally using cURL.

<Steps>
  <Step title="Run your Next.js app and the Trigger.dev dev server">
    First, run your Next.js app.

    <CodeGroup>
      ```bash npm theme={null}
      npm run dev
      ```

      ```bash pnpm theme={null}
      pnpm run dev
      ```

      ```bash yarn theme={null}
      yarn dev
      ```
    </CodeGroup>

    Then, open up a second terminal window and start the Trigger.dev dev server:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Trigger the webhook with some dummy data">
    To send a POST request to your webhook handler, open up a terminal window on your local machine and run the following command:

    <Tip>
      If `http://localhost:3000` isn't the URL of your locally running Next.js app, replace the URL in
      the below command with that URL instead.
    </Tip>

    ```bash  theme={null}
    curl -X POST -H "Content-Type: application/json" -d '{"Name": "John Doe", "Age": "87"}' http://localhost:3000/api/webhook-handler
    ```

    This will send a POST request to your webhook handler, with a JSON payload.
  </Step>

  <Step title="Check the task ran successfully">
    After running the command, you should see a successful dev run and a 200 response in your terminals.

    If you now go to your [Trigger.dev dashboard](https://cloud.trigger.dev), you should also see a successful run for the 'Hello World' task, with the payload you sent, in this case; `{"name": "John Doe", "age": "87"}`.
  </Step>
</Steps>

## Learn more about Next.js and Trigger.dev

### Walk-through guides from development to deployment

<CardGroup cols={2}>
  <Card title="Next.js - setup guide" icon="N" href="/guides/frameworks/nextjs">
    Learn how to setup Trigger.dev with Next.js, using either the pages or app router.
  </Card>

  <Card title="Next.js - triggering tasks using webhooks" icon="N" href="/guides/frameworks/nextjs-webhooks">
    Learn how to create a webhook handler for incoming webhooks in a Next.js app, and trigger a task from it.
  </Card>
</CardGroup>

### Task examples

<CardGroup cols={2}>
  <Card title="Fal.ai with Realtime in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9ac31bb57678b222a82b04055184eea0" href="/guides/examples/fal-ai-realtime" data-og-width="1442" width="1442" data-og-height="812" height="812" data-path="images/fal-realtime-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=086231461af2b9520f9200889fc04724 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c5ab58baba8000266aac79117dc8944d 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988fe253a646e5af2188f81297d01897 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=db65bbdf0995fc1ac72bda2512c31800 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e7890d597065f8bc9edd0ac90257185 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-realtime-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=60bc05bc63c0c1d1ad59eaafb0808aa6 2500w">
    Generate an image from a prompt using Fal.ai and Trigger.dev Realtime.
  </Card>

  <Card title="Generate a cartoon using Fal.ai in Next.js" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=003d7870f36310d14ca9a71a952667d3" href="/guides/examples/fal-ai-image-to-cartoon" data-og-width="1442" width="1442" data-og-height="816" height="816" data-path="images/fal-generate-cartoon-thumbnail.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ec0e05813f874082257e2d32bad407a8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f3f70889ad11953d44f72224712722aa 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b8df38a222a7431d55a1af1af61dffd1 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=268ac6b0faf34bb46a8a8d676658b0b8 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4be96f4df2d49b7a71d0e960df9cc93b 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/fal-generate-cartoon-thumbnail.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bc15e1a3df4484cfdcd200d49fd1ac4b 2500w">
    Convert an image to a cartoon using Fal.ai.
  </Card>

  <Card title="Vercel sync environment variables" icon="code" href="/guides/examples/vercel-sync-env-vars">
    Learn how to automatically sync environment variables from your Vercel projects to Trigger.dev.
  </Card>

  <Card title="Vercel AI SDK" icon="code" href="/guides/examples/vercel-ai-sdk">
    Learn how to use the Vercel AI SDK, which is a simple way to use AI models from different
    providers, including OpenAI, Anthropic, Amazon Bedrock, Groq, Perplexity etc.
  </Card>
</CardGroup>


# Node.js setup guide
Source: https://trigger.dev/docs/guides/frameworks/nodejs

This guide will show you how to setup Trigger.dev in your existing Node.js project, test an example task, and view the run.

export const framework_0 = "Node.js"

## Prerequisites

* Setup a project in {framework_0}
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## Initial setup

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Useful next steps

<CardGroup cols={2}>
  <Card title="Tasks overview" icon="diagram-subtask" href="/tasks/overview">
    Learn what tasks are and their options
  </Card>

  <Card title="Writing tasks" icon="pen-nib" href="/writing-tasks-introduction">
    Learn how to write your own tasks
  </Card>

  <Card title="Deploy using the CLI" icon="terminal" href="/cli-deploy">
    Learn how to deploy your task manually using the CLI
  </Card>

  <Card title="Deploy using GitHub actions" icon="github" href="/github-actions">
    Learn how to deploy your task using GitHub actions
  </Card>
</CardGroup>


# Prisma setup guide
Source: https://trigger.dev/docs/guides/frameworks/prisma

This guide will show you how to set up Prisma with Trigger.dev

## Overview

This guide will show you how to set up [Prisma](https://www.prisma.io/) with Trigger.dev, test and view an example task run.

## Prerequisites

* An existing Node.js project with a `package.json` file
* Ensure TypeScript is installed
* A [PostgreSQL](https://www.postgresql.org/) database server running locally, or accessible via a connection string
* Prisma ORM [installed and initialized](https://www.prisma.io/docs/getting-started/quickstart) in your project
* A `DATABASE_URL` environment variable set in your `.env` file, pointing to your PostgreSQL database (e.g. `postgresql://user:password@localhost:5432/dbname`)

## Initial setup (optional)

Follow these steps if you don't already have Trigger.dev set up in your project.

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Creating a task using Prisma and deploying it to production

<Steps>
  <Step title="Writing the Prisma task">
    First, create a new task file in your `trigger` folder.

    This is a simple task that will add a new user to the database.

    <Note>
      For this task to work correctly, you will need to have a `user` model in your Prisma schema with
      an `id` field, a `name` field, and an `email` field.
    </Note>

    ```ts /trigger/prisma-add-new-user.ts theme={null}
    import { PrismaClient } from "@prisma/client";
    import { task } from "@trigger.dev/sdk";

    // Initialize Prisma client
    const prisma = new PrismaClient();

    export const addNewUser = task({
      id: "prisma-add-new-user",
      run: async (payload: { name: string; email: string; id: number }) => {
        const { name, email, id } = payload;

        // This will create a new user in the database
        const user = await prisma.user.create({
          data: {
            name: name,
            email: email,
            id: id,
          },
        });

        return {
          message: `New user added successfully: ${user.id}`,
        };
      },
    });
    ```
  </Step>

  <Step title="Configuring the build extension">
    Next, configure the Prisma [build extension](https://trigger.dev/docs/config/extensions/overview) in the `trigger.config.js` file to include the Prisma client in the build.

    This will ensure that the Prisma client is available when the task runs.

    For a full list of options available in the Prisma build extension, see the [Prisma build extension documentation](https://trigger.dev/docs/config/extensions/prismaExtension).

    ```js /trigger.config.js theme={null}
    export default defineConfig({
      project: "<project ref>", // Your project reference
      // Your other config settings...
      build: {
        extensions: [
          prismaExtension({
            version: "5.20.0", // optional, we'll automatically detect the version if not provided
            // update this to the path of your Prisma schema file
            schema: "prisma/schema.prisma",
          }),
        ],
      },
    });
    ```

    <Note>
      [Build extensions](/config/extensions/overview) allow you to hook into the build system and
      customize the build process or the resulting bundle and container image (in the case of
      deploying). You can use pre-built extensions or create your own.
    </Note>
  </Step>

  <Step title="Optional: adding Prisma instrumentation">
    We use OpenTelemetry to [instrument](https://trigger.dev/docs/config/config-file#instrumentations) our tasks and collect telemetry data.

    If you want to automatically log all Prisma queries and mutations, you can use the Prisma instrumentation extension.

    ```js /trigger.config.js theme={null}
    import { defineConfig } from "@trigger.dev/sdk";
    import { PrismaInstrumentation } from "@prisma/instrumentation";
    import { OpenAIInstrumentation } from "@traceloop/instrumentation-openai";

    export default defineConfig({
      //..other stuff
      instrumentations: [new PrismaInstrumentation(), new OpenAIInstrumentation()],
    });
    ```

    This provides much more detailed information about your tasks with minimal effort.
  </Step>

  <Step title="Deploying your task">
    With the build extension and task configured, you can now deploy your task using the Trigger.dev CLI.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest deploy
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest deploy
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest deploy
      ```
    </CodeGroup>
  </Step>

  <Step title="Adding your DATABASE_URL environment variable to Trigger.dev">
    In your Trigger.dev dashboard sidebar click "Environment Variables" <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />, and then the "New environment variable" button <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />.

    You can add values for your local dev environment, staging and prod. in this case we will add the `DATABASE_URL` for the production environment.

        <img
          src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79b5fd91e809cb0c6c9298410922df96"
          alt="Environment variables
    page"
          data-og-width="1600"
          width="1600"
          data-og-height="900"
          height="900"
          data-path="images/environment-variables-panel.jpg"
          data-optimize="true"
          data-opv="3"
          srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4c3f6181dea5542157cdbdebafb44989 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0c302ef3d814a0c781b684e64d090f9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a110ee9bb119eaaf7404097904a1f442 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e774fb137908fbaaf28318d1bfa419d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aa5d4bef7b66551887043c4420807bc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed23a501677d11631bb832eb6f95ceae 2500w"
        />
  </Step>

  <Step title="Running your task">
    To test this task, go to the 'test' page in the Trigger.dev dashboard and run the task with the following payload:

    ```json  theme={null}
    {
      "name": "<a-name>", // e.g. "John Doe"
      "email": "<a-email>", // e.g. "john@doe.test"
      "id": <a-number> // e.g. 12345
    }
    ```

    Congratulations! You should now see a new completed run, and a new user with the credentials you provided should be added to your database.
  </Step>
</Steps>

## Useful next steps

<CardGroup cols={2}>
  <Card title="Tasks overview" icon="diagram-subtask" href="/tasks/overview">
    Learn what tasks are and their options
  </Card>

  <Card title="Writing tasks" icon="pen-nib" href="/writing-tasks-introduction">
    Learn how to write your own tasks
  </Card>

  <Card title="Deploy using the CLI" icon="terminal" href="/cli-deploy">
    Learn how to deploy your task manually using the CLI
  </Card>

  <Card title="Deploy using GitHub actions" icon="github" href="/github-actions">
    Learn how to deploy your task using GitHub actions
  </Card>
</CardGroup>


# Remix setup guide
Source: https://trigger.dev/docs/guides/frameworks/remix

This guide will show you how to setup Trigger.dev in your existing Remix project, test an example task, and view the run.

export const framework_0 = "Remix"

## Prerequisites

* Setup a project in {framework_0}
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## Initial setup

<Steps>
  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Set your secret key locally

Set your `TRIGGER_SECRET_KEY` environment variable in your `.env` file. This key is used to authenticate with Trigger.dev, so you can trigger runs from your Remix app. Visit the API Keys page in the dashboard and select the DEV secret key.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=89dd26bf57f345bad4508ee5eec70c8c" alt="How to find your secret key" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/api-keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988f98dd098b108ca51d8c0aeb829344 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=14431ee3376a9a6b845744b0b3acce60 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9059b9369eb793b9df4cceee1f985286 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccd1e2a8512f491128a53cd4ebe8823f 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ab656ff2f4b95e32558aacaa485c86ea 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3bb0b87a8e1a3033a8ff1ba3590f5786 2500w" />

For more information on authenticating with Trigger.dev, see the [API keys page](/apikeys).

## Triggering your task in Remix

<Steps>
  <Step title="Create an API route">
    Create a new file called `api.hello-world.ts` (or `api.hello-world.js`) in the `app/routes` directory like this: `app/routes/api.hello-world.ts`.
  </Step>

  <Step title="Add your task">
    Add this code to your `api.hello-world.ts` file which imports your task:

    ```ts app/routes/api.hello-world.ts theme={null}
    import type { helloWorldTask } from "../../src/trigger/example";
    import { tasks } from "@trigger.dev/sdk";

    export async function loader() {
      const handle = await tasks.trigger<typeof helloWorldTask>("hello-world", "James");

      return new Response(JSON.stringify(handle), {
        headers: { "Content-Type": "application/json" },
      });
    }
    ```
  </Step>

  <Step title="Trigger your task">
    Run your Remix app:

    <CodeGroup>
      ```bash npm theme={null}
      npm run dev
      ```

      ```bash pnpm theme={null}
      pnpm run dev
      ```

      ```bash yarn theme={null}
      yarn dev
      ```
    </CodeGroup>

    Run the dev server from Step 2. of the [Initial Setup](/guides/frameworks/remix#initial-setup) section above if it's not already running:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>

    Now visit the URL in your browser to trigger the task. Ensure the port number is the same as the one you're running your Remix app on. For example, if you're running your Remix app on port 3000, visit:

    ```bash  theme={null}
    http://localhost:3000/api/trigger
    ```

    You should see the CLI log the task run with a link to view the logs in the dashboard.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=75168b271620e7206a50b041224a98b0" alt="Trigger.dev CLI showing a successful run" data-og-width="839" width="839" data-og-height="174" height="174" data-path="images/trigger-cli-run-success.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5593976094a4db89b9bcefe743b670f5 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3ece99db078f44f61721287482ac6288 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=49c3058ed0f3baa282eba729cc765924 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=863029ceaad9808f725ce07a119a861a 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=98f234c6774c19d0966c77c157a696c3 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/trigger-cli-run-success.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fb955cb91d22967fc4251ab00d09547d 2500w" />

    Visit the [Trigger.dev dashboard](https://cloud.trigger.dev) to see your run.
  </Step>
</Steps>

## Manually add your environment variables (optional)

If you have any environment variables in your tasks, be sure to add them in the dashboard so deployed code runs successfully. In Node.js, these environment variables are accessed in your code using `process.env.MY_ENV_VAR`.

In the sidebar select the "Environment Variables" page, then press the "New environment variable"
button. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=af652254781808a35c2bcefd4b61b59f" alt="Environment variables page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-page.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fd6487833d9c659f8a514c7cc86cf84d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1758721fd84f5040b88997db401f7391 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4416f51b1528ae14285a03b560f22389 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12b90b89f7662aadaea07df17d9d3898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28e6921620cda10d335a095dbfa85806 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4f6c67a030b20699bde25c22d68e57af 2500w" />

You can add values for your local dev environment, staging and prod. <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79b5fd91e809cb0c6c9298410922df96" alt="Environment variables
page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-panel.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4c3f6181dea5542157cdbdebafb44989 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b0c302ef3d814a0c781b684e64d090f9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a110ee9bb119eaaf7404097904a1f442 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e774fb137908fbaaf28318d1bfa419d 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aa5d4bef7b66551887043c4420807bc4 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-panel.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed23a501677d11631bb832eb6f95ceae 2500w" />

You can also add environment variables in code by following the steps on the [Environment Variables page](/deploy-environment-variables#in-your-code).

## Deploying your task to Trigger.dev

For this guide, we'll manually deploy your task by running the [CLI deploy command](/cli-deploy) below. Other ways to deploy are listed in the next section.

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

### Other ways to deploy

<Tabs>
  <Tab title="GitHub Actions">
    Use GitHub Actions to automatically deploy your tasks whenever new code is pushed and when the `trigger` directory has changes in it. Follow [this guide](/github-actions) to set up GitHub Actions.
  </Tab>

  <Tab title="Vercel Integration">
    We're working on adding an official [Vercel integration](/vercel-integration) which you can follow the progress of [here](https://feedback.trigger.dev/p/vercel-integration-3).
  </Tab>
</Tabs>

## Deploying to Vercel Edge Functions

Before we start, it's important to note that:

* We'll be using a type-only import for the task to ensure compatibility with the edge runtime.
* The `@trigger.dev/sdk` package supports the edge runtime out of the box.

There are a few extra steps to follow to deploy your `/api/hello-world` API endpoint to Vercel Edge Functions.

<Steps>
  <Step title="Update your API route">
    Update your API route to use the `runtime: "edge"` option and change it to an `action()` so we can trigger the task from a curl request later on.

    ```ts app/routes/api.hello-world.ts theme={null}
    import { tasks } from "@trigger.dev/sdk";
    import type { helloWorldTask } from "../../src/trigger/example";
    //      ðŸ‘† **type-only** import

    // include this at the top of your API route file
    export const config = {
      runtime: "edge",
    };
    export async function action({ request }: { request: Request }) {
      // This is where you'd authenticate the request
      const payload = await request.json();
      const handle = await tasks.trigger<typeof helloWorldTask>("hello-world", payload);
      return new Response(JSON.stringify(handle), {
        headers: { "Content-Type": "application/json" },
      });
    }
    ```
  </Step>

  <Step title="Update the Vercel configuration">
    Create or update the `vercel.json` file with the following:

    ```json vercel.json theme={null}
    {
      "buildCommand": "npm run vercel-build",
      "devCommand": "npm run dev",
      "framework": "remix",
      "installCommand": "npm install",
      "outputDirectory": "build/client"
    }
    ```
  </Step>

  <Step title="Update package.json scripts">
    Update your `package.json` to include the following scripts:

    ```json package.json theme={null}
    "scripts": {
        "build": "remix vite:build",
        "dev": "remix vite:dev",
        "lint": "eslint --ignore-path .gitignore --cache --cache-location ./node_modules/.cache/eslint .",
        "start": "remix-serve ./build/server/index.js",
        "typecheck": "tsc",
        "vercel-build": "remix vite:build && cp -r ./public ./build/client"
    },
    ```
  </Step>

  <Step title="Deploy to Vercel">
    Push your code to a Git repository and create a new project in the Vercel dashboard. Select your repository and follow the prompts to complete the deployment.
  </Step>

  <Step title="Add your Vercel environment variables">
    In the Vercel project settings, add your Trigger.dev secret key:

    ```bash  theme={null}
    TRIGGER_SECRET_KEY=your-secret-key
    ```

    You can find this key in the Trigger.dev dashboard under API Keys and select the environment key you want to use.

        <img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=89dd26bf57f345bad4508ee5eec70c8c" alt="How to find your secret key" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/api-keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=988f98dd098b108ca51d8c0aeb829344 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=14431ee3376a9a6b845744b0b3acce60 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9059b9369eb793b9df4cceee1f985286 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ccd1e2a8512f491128a53cd4ebe8823f 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ab656ff2f4b95e32558aacaa485c86ea 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-keys.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3bb0b87a8e1a3033a8ff1ba3590f5786 2500w" />
  </Step>

  <Step title="Deploy your project">
    Once you've added the environment variable, deploy your project to Vercel.

    <Note>
      Ensure you have also deployed your Trigger.dev task. See [deploy your task
      step](/guides/frameworks/remix#deploying-your-task-to-trigger-dev).
    </Note>
  </Step>

  <Step title="Test your task in production">
    After deployment, you can test your task in production by running this curl command:

    ```bash  theme={null}
    curl -X POST https://your-app.vercel.app/api/hello-world \
    -H "Content-Type: application/json" \
    -d '{"name": "James"}'
    ```

    This sends a POST request to your API endpoint with a JSON payload.
  </Step>
</Steps>

### Additional notes

The `vercel-build` script in `package.json` is specific to Remix projects on Vercel, ensuring that static assets are correctly copied to the build output.

The `runtime: "edge"` configuration in the API route allows for better performance on Vercel's Edge Network.

## Additional resources for Remix

<Card title="Remix - triggering tasks using webhooks" icon="R" href="/guides/frameworks/remix-webhooks">
  How to create a webhook handler in a Remix app, and trigger a task from it.
</Card>

## Useful next steps

<CardGroup cols={2}>
  <Card title="Tasks overview" icon="diagram-subtask" href="/tasks/overview">
    Learn what tasks are and their options
  </Card>

  <Card title="Writing tasks" icon="pen-nib" href="/writing-tasks-introduction">
    Learn how to write your own tasks
  </Card>

  <Card title="Deploy using the CLI" icon="terminal" href="/cli-deploy">
    Learn how to deploy your task manually using the CLI
  </Card>

  <Card title="Deploy using GitHub actions" icon="github" href="/github-actions">
    Learn how to deploy your task using GitHub actions
  </Card>
</CardGroup>


# Triggering tasks with webhooks in Remix
Source: https://trigger.dev/docs/guides/frameworks/remix-webhooks

Learn how to trigger a task from a webhook in a Remix app.

## Prerequisites

* [A Remix project, set up with Trigger.dev](/guides/frameworks/remix)
* [cURL](https://curl.se/) installed on your local machine. This will be used to send a POST request to your webhook handler.

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/remix-webhooks">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Adding the webhook handler

The webhook handler in this guide will be an API route. Create a new file `app/routes/api.webhook-handler.ts` or `app/routes/api.webhook-handler.js`.

In your new file, add the following code:

```ts /api/webhook-handler.ts theme={null}
import type { ActionFunctionArgs } from "@remix-run/node";
import { tasks } from "@trigger.dev/sdk";
import { helloWorldTask } from "src/trigger/example";

export async function action({ request }: ActionFunctionArgs) {
  const payload = await request.json();

  // Trigger the helloWorldTask with the webhook data as the payload
  await tasks.trigger<typeof helloWorldTask>("hello-world", payload);

  return new Response("OK", { status: 200 });
}
```

This code will handle the webhook payload and trigger the 'Hello World' task.

## Triggering the task locally

Now that you have a webhook handler set up, you can trigger the 'Hello World' task from it. We will do this locally using cURL.

<Steps>
  <Step title="Run your Remix app and the Trigger.dev dev server">
    First, run your Remix app.

    <CodeGroup>
      ```bash npm theme={null}
      npm run dev
      ```

      ```bash pnpm theme={null}
      pnpm run dev
      ```

      ```bash yarn theme={null}
      yarn dev
      ```
    </CodeGroup>

    Then, open up a second terminal window and start the Trigger.dev dev server:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Trigger the webhook with some dummy data">
    To send a POST request to your webhook handler, open up a terminal window on your local machine and run the following command:

    <Tip>
      If `http://localhost:5173` isn't the URL of your locally running Remix app, replace the URL in the
      below command with that URL instead.
    </Tip>

    ```bash  theme={null}
    curl -X POST -H "Content-Type: application/json" -d '{"Name": "John Doe", "Age": "87"}' http://localhost:5173/api/webhook-handler
    ```

    This will send a POST request to your webhook handler, with a JSON payload.
  </Step>

  <Step title="Check the task ran successfully">
    After running the command, you should see a successful dev run and a 200 response in your terminals.

    If you now go to your [Trigger.dev dashboard](https://cloud.trigger.dev), you should also see a successful run for the 'Hello World' task, with the payload you sent, in this case; `{"name": "John Doe", "age": "87"}`.
  </Step>
</Steps>


# Sequin database triggers
Source: https://trigger.dev/docs/guides/frameworks/sequin

This guide will show you how to trigger tasks from database changes using Sequin

[Sequin](https://sequinstream.com) allows you to trigger tasks from database changes. Sequin captures every insert, update, and delete on a table and then ensures a task is triggered for each change.

Often, task runs coincide with database changes. For instance, you might want to use a Trigger.dev task to generate an embedding for each post in your database:

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2b47f798eae889e5ae4273368ee9cdc1" alt="Sequin and Trigger.dev Overview" data-og-width="1773" width="1773" data-og-height="492" height="492" data-path="images/sequin-intro.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9c9196f7d3a2a2a9fdf874702460c059 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ce2fe0003447192821d6ddafe872ffe8 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f1bfbbc8c685ff84061f57d0a0312aca 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=51d4acaeaa75050b0327cd77220ca814 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8320b585fc6fb4446a46f3c2913fc831 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-intro.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e533eec55e2c3ae56d5a99bcb6bbd7db 2500w" />

In this guide, you'll learn how to use Sequin to trigger Trigger.dev tasks from database changes.

## Prerequisites

You are about to create a [regular Trigger.dev task](/tasks-regular) that you will execute when ever a post is inserted or updated in your database. Sequin will detect all the changes on the `posts` table and then send the payload of the post to an API endpoint that will call `tasks.trigger()` to create the embedding and update the database.

As long as you create an HTTP endpoint that Sequin can deliver webhooks to, you can use any web framework or edge function (e.g. Supabase Edge Functions, Vercel Functions, Cloudflare Workers, etc.) to invoke your Trigger.dev task. In this guide, we'll show you how to setup Trigger.dev tasks using Next.js API Routes.

You'll need the following to follow this guide:

* A Next.js project with [Trigger.dev](https://trigger.dev) installed
  <Info>
    If you don't have one already, follow [Trigger.dev's Next.js setup
    guide](/guides/frameworks/nextjs) to setup your project. You can return to this guide when
    you're ready to write your first Trigger.dev task.
  </Info>
* A [Sequin](https://console.sequinstream.com/register) account
* A Postgres database (Sequin works with any Postgres database version 12 and up) with a `posts` table.

## Create a Trigger.dev task

Start by creating a new Trigger.dev task that takes in a Sequin change event as a payload, creates an embedding, and then inserts the embedding into the database:

<Steps titleSize="h3">
  <Step title="Create a `create-embedding-for-post` task">
    In your `src/trigger/tasks` directory, create a new file called `create-embedding-for-post.ts` and add the following code:

    <CodeGroup>
      ```ts trigger/create-embedding-for-post.ts theme={null}
      import { task } from "@trigger.dev/sdk";
      import { OpenAI } from "openai";
      import { upsertEmbedding } from "../util";

      const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      });

      export const createEmbeddingForPost = task({
      id: "create-embedding-for-post",
      run: async (payload: {
      record: {
      id: number;
      title: string;
      body: string;
      author: string;
      createdAt: string;
      embedding: string | null;
      },
      metadata: {
      table_schema: string,
      table_name: string,
      consumer: {
      id: string;
      name: string;
      };
      };
      }) => {
      // Create an embedding using the title and body of payload.record
      const content = `${payload.record.title}\n\n${payload.record.body}`;
      const embedding = (await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: content,
      })).data[0].embedding;

          // Upsert the embedding in the database. See utils.ts for the implementation -> ->
          await upsertEmbedding(embedding, payload.record.id);

          // Return the updated record
          return {
            ...payload.record,
            embedding: JSON.stringify(embedding),
          };
        }

      });

      ```

      ```ts utils.ts theme={null}
      import pg from "pg";

      export async function upsertEmbedding(embedding: number[], id: number) {
        const client = new pg.Client({
          connectionString: process.env.DATABASE_URL,
        });
        await client.connect();

        try {
          const query = `
            INSERT INTO post_embeddings (id, embedding)
            VALUES ($2, $1)
            ON CONFLICT (id)
            DO UPDATE SET embedding = $1
          `;
          const values = [JSON.stringify(embedding), id];

          const result = await client.query(query, values);
          console.log(`Updated record in database. Rows affected: ${result.rowCount}`);

          return result.rowCount;
        } catch (error) {
          console.error("Error updating record in database:", error);
          throw error;
        } finally {
          await client.end();
        }
      }
      ```
    </CodeGroup>

    This task takes in a Sequin record event, creates an embedding, and then upserts the embedding into a `post_embeddings` table.
  </Step>

  <Step title="Add the task to your Trigger.dev project">
    Register the `create-embedding-for-post` task to your Trigger.dev cloud project by running the following command:

    ```bash  theme={null}
    npx trigger.dev@latest dev
    ```

    In the Trigger.dev dashboard, you should now see the `create-embedding-for-post` task:

    <Frame>
      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=747c6f96abca5112fb406fe215e0b587" alt="Task added" data-og-width="2834" width="2834" data-og-height="482" height="482" data-path="images/sequin-register-task.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a641edafb2f279adabeb241452f97a2a 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fea53dc47cd6fe8aa9ced24df43afa91 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8569ed20a7843f45bd41a49062dccaaa 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f2377811f9fa930b91335a61dfe6a107 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=726d52318e2994eee969ef6f6f17dc5c 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-register-task.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c3fd7773430f2d99da46e8de7a94dd1 2500w" />
    </Frame>
  </Step>
</Steps>

<Check>
  You've successfully created a Trigger.dev task that will create an embedding for each post in your
  database. In the next step, you'll create an API endpoint that Sequin can deliver records to.
</Check>

## Setup API route

You'll now create an API endpoint that will receive posts from Sequin and then trigger the `create-embedding-for-post` task.

<Info>
  This guide covers how to setup an API endpoint using the Next.js App Router. You can find examples
  for Next.js Server Actions and Pages Router in the [Trigger.dev
  documentation](https://trigger.dev/docs/guides/frameworks/nextjs).
</Info>

<Steps titleSize="h3">
  <Step title="Create a route handler">
    Add a route handler by creating a new `route.ts` file in a `/app/api/create-embedding-for-post` directory:

    ```ts app/api/create-embedding-for-post/route.ts theme={null}
    import type { createEmbeddingForPost } from "@/trigger/create-embedding-for-post";
    import { tasks } from "@trigger.dev/sdk";
    import { NextResponse } from "next/server";

    export async function POST(req: Request) {
      const authHeader = req.headers.get("authorization");
      if (!authHeader || authHeader !== `Bearer ${process.env.SEQUIN_WEBHOOK_SECRET}`) {
        return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
      }
      const payload = await req.json();
      const handle = await tasks.trigger<typeof createEmbeddingForPost>(
        "create-embedding-for-post",
        payload
      );

      return NextResponse.json(handle);
    }
    ```

    This route handler will receive records from Sequin, parse them, and then trigger the `create-embedding-for-post` task.
  </Step>

  <Step title="Set secret keys">
    You'll need to set four secret keys in a `.env.local` file:

    ```bash  theme={null}
    SEQUIN_WEBHOOK_SECRET=your-secret-key
    TRIGGER_SECRET_KEY=secret-from-trigger-dev
    OPENAI_API_KEY=sk-proj-asdfasdfasdf
    DATABASE_URL=postgresql://
    ```

    The `SEQUIN_WEBHOOK_SECRET` ensures that only Sequin can access your API endpoint.

    The `TRIGGER_SECRET_KEY` is used to authenticate requests to Trigger.dev and can be found in the **API keys** tab of the Trigger.dev dashboard.

    The `OPENAI_API_KEY` and `DATABASE_URL` are used to create an embedding using OpenAI and connect to your database. Be sure to add these as [environment variables](https://trigger.dev/docs/deploy-environment-variables) in Trigger.dev as well.
  </Step>
</Steps>

<Check>
  You've successfully created an API endpoint that can receive record payloads from Sequin and
  trigger a Trigger.dev task. In the next step, you'll setup Sequin to trigger the endpoint.
</Check>

## Create Sequin consumer

You'll now configure Sequin to send every row in your `posts` table to your Trigger.dev task.

<Steps titleSize="h3">
  <Step title="Connect Sequin to your database">
    1. Login to your Sequin account and click the **Add New Database** button.
    2. Enter the connection details for your Postgres database.

    <Info>
      If you need to connect to a local dev database, flip the **use localhost** switch and follow the instructions to create a tunnel using the [Sequin CLI](https://sequinstream.com/docs/cli).
    </Info>

    3. Follow the instructions to create a publication and a replication slot by running two SQL commands in your database:

    ```sql  theme={null}
    create publication sequin_pub for all tables;
    select pg_create_logical_replication_slot('sequin_slot', 'pgoutput');
    ```

    4. Name your database and click the **Connect Database** button.

    Sequin will connect to your database and ensure that it's configured properly.

    <Note>
      If you need step-by-step connection instructions to connect Sequin to your database, check out our [quickstart guide](https://sequinstream.com/docs/quickstart).
    </Note>
  </Step>

  <Step title="Tunnel to your local endpoint">
    Now, create a tunnel to your local endpoint so Sequin can deliver change payloads to your local API:

    1. In the Sequin console, open the **HTTP Endpoint** tab and click the **Create HTTP Endpoint** button.
    2. Enter a name for your endpoint (i.e. `local_endpoint`) and flip the **Use localhost** switch. Follow the instructions in the Sequin console to [install the Sequin CLI](https://sequinstream.com/docs/cli), then run:

    ```bash  theme={null}
    sequin tunnel --ports=3001:local_endpoint
    ```

    3. Now, click **Add encryption header** and set the key to `Authorization` and the value to `Bearer SEQUIN_WEBHOOK_SECRET`.
    4. Click **Create HTTP Endpoint**.
  </Step>

  <Step title="Create a Push Consumer">
    Create a push consumer that will capture posts from your database and deliver them to your local endpoint:

    1. Navigate to the **Consumers** tab and click the **Create Consumer** button.
    2. Select your `posts` table (i.e `public.posts`).
    3. You want to ensure that every post receives an embedding - and that embeddings are updated as posts are updated. To do this, select to process **Rows** and click **Continue**.

    <Note>
      You can also use **changes** for this particular use case, but **rows** comes with some nice replay and backfill features.
    </Note>

    4. You'll now set the sort and filter for the consumer. For this guide, we'll sort by `updated_at` and start at the beginning of the table. We won't apply any filters:

    <Frame>
      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ff47bd808e04dc361aa45fdf353604a0" alt="Consumer Sort and Filter" data-og-width="1880" width="1880" data-og-height="980" height="980" data-path="images/sequin-sort-and-filter.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e0dc893629a4fe4e84d1a8df13dd4929 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=af076e0deed39c456fb63471a43db6de 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c273e1d361b2c1f85e6a70cdb0425a43 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=71a729303042a8388f550530d9f16cf1 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a4a7f5bbf7bea59e0fac5b8d822c3631 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-sort-and-filter.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c7b8f9fbc1fdca8bc70dc593c4dad4f4 2500w" />
    </Frame>

    5. On the next screen, select **Push** to have Sequin send the events to your webhook URL. Click **Continue**.
    6. Now, give your consumer a name (i.e. `posts_push_consumer`) and in the **HTTP Endpoint** section select the `local_endpoint` you created above. Add the exact API route you created in the previous step (i.e. `/api/create-embedding-for-post`):

    <Frame>
      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=67defd6931a599625ba1688d920bb7e6" alt="Consumer Endpoint" data-og-width="1990" width="1990" data-og-height="1312" height="1312" data-path="images/sequin-consumer-config.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=57804d5d01973860174459a2c2618987 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=5cf6e70ac1cfad808bbb9a0746b61720 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b6fcaad93ead958208e23a5ea71d8afa 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1fe0b25fc33ed12670bb11125a68b68b 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1db08ad9fc8923069c5e7a627f5b615f 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-consumer-config.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=20ecfe5931f428662687f3e4ab77e202 2500w" />
    </Frame>

    7. Click the **Create Consumer** button.
  </Step>
</Steps>

<Check>Your Sequin consumer is now created and ready to send events to your API endpoint.</Check>

## Test end-to-end

<Steps titleSize="h3">
  <Step title="Spin up you dev environment">
    1. The Next.js app is running: `npm run dev`
    2. The Trigger.dev dev server is running `npx trigger.dev@latest dev`
    3. The Sequin tunnel is running: `sequin tunnel --ports=3001:local_endpoint`
  </Step>

  <Step title="Create a new post in your database">
    ```sql  theme={null}
    insert into
    posts (title, body, author)
    values
      (
        'The Future of AI',
        'An insightful look into how artificial intelligence is shaping the future of technology and society.',
        'Alice H Johnson'
      );
    ```
  </Step>

  <Step title="Trace the change in the Sequin dashboard">
    In the Sequin console, navigate to the [**Trace**](https://console.sequinstream.com/trace) tab and confirm that Sequin delivered the event to your local endpoint:

    <Frame>
      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=dd86f0e4f083bff4921c54d15822a465" alt="Trace Event" data-og-width="2818" width="2818" data-og-height="1622" height="1622" data-path="images/sequin-trace.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e0f4b9353418a510c04ff85fe9680eb6 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d2589ab5edb952c9a13b949e5f648bd2 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e0363b09ab88bc159c5865888d8cf642 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ac67708d978c528b9a6aecf8e5c9f854 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3c90e4277c0a5aff51c11eabe5f25965 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-trace.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f0460a55146329bd7906a1dff4032482 2500w" />
    </Frame>
  </Step>

  <Step title="Confirm the event was received by your endpoint">
    In your local terminal, you should see a `200` response in your Next.js app:

    ```bash  theme={null}
    POST /api/create-embedding-for-post 200 in 262ms
    ```
  </Step>

  <Step title="Observe the task run in the Trigger.dev dashboard">
    Finally, in the [**Trigger.dev dashboard**](https://cloud.trigger.dev/), navigate to the Runs page and confirm that the task run completed successfully:

    <Frame>
      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2268cf3d51e4821aba5e13467a1f96ec" alt="Task run" data-og-width="3198" width="3198" data-og-height="2038" height="2038" data-path="images/sequin-final-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0f4001b06cba64dd3f890ee6024c0537 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=33721ede31a7e68c5d9c5a0f64f50cd6 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cb21081fa0989a2a225bbd940eb40041 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0a33666f493cde10babf7414892cbc2b 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=bf4b50f0734948802244a669ac203773 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/sequin-final-run.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a0958fb3d3160984ca3ec726c7d79168 2500w" />
    </Frame>
  </Step>
</Steps>

<Check>
  Every time a post is created or updated, Sequin will deliver the row payload to your API endpoint
  and Trigger.dev will run the `create-embedding-for-post` task.
</Check>

## Next steps

With Sequin and Trigger.dev, every post in your database will now have an embedding. This is a simple example of how you can trigger long-running tasks on database changes.

From here, add error handling and deploy to production:

* Add [retries](/errors-retrying) to your Trigger.dev task to ensure that any errors are captured and logged.
* Deploy to [production](/guides/frameworks/nextjs#deploying-your-task-to-trigger-dev) and update your Sequin consumer to point to your production database and endpoint.


# Authenticating Supabase tasks: JWTs and service roles
Source: https://trigger.dev/docs/guides/frameworks/supabase-authentication

Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role keys for admin access.

There are two ways to authenticate your Supabase client in Trigger.dev tasks:

### 1. Using JWT Authentication (Recommended for User-Specific Operations)

A JWT (JSON Web Token) is a string-formatted data container that typically stores user identity and permissions data. Row Level Security policies are based on the information present in JWTs. Supabase JWT docs can be found [here](https://supabase.com/docs/guides/auth/jwts).

To use JWTs with Supabase, you'll need to add the `SUPABASE_JWT_SECRET` environment variable in your project. This secret is used to sign the JWTs. This can be found in your Supabase project settings under `Data API`.

This example code shows how to create a JWT token for a user and initialize a Supabase client with that token for authentication, allowing the task to perform database operations as that specific user. You can adapt this code to fit your own use case.

```ts  theme={null}

// The rest of your task code
async run(payload: { user_id: string }) {
    const { user_id } = payload;

    // Optional error handling
    const jwtSecret = process.env.SUPABASE_JWT_SECRET;
    if (!jwtSecret) {
      throw new Error(
        "SUPABASE_JWT_SECRET is not defined in environment variables"
      );
    }

    // Create a JWT token for the user that expires in 1 hour
    const token = jwt.sign({ sub: user_id }, jwtSecret, { expiresIn: "1h" });

    // Initialize the Supabase client with the JWT token
    const supabase = createClient(
      // These details can be found in your Supabase project settings under `Data API`
      process.env.SUPABASE_URL as string,
      process.env.SUPABASE_ANON_KEY as string,
      {
        global: {
          headers: {
            Authorization: `Bearer ${token}`,
          },
        },
      }
    );
// The rest of your task code
```

Using JWTs to authenticate Supabase operations is more secure than using service role keys because it respects Row Level Security policies, maintains user-specific audit trails, and follows the principle of least privileged access.

### 2. Using Service Role Key (For Admin-Level Access)

<Warning>
  The service role key has unlimited access and bypasses all security checks. Only use it when you
  need admin-level privileges, and never expose it client-side.
</Warning>

This example code creates a Supabase client with admin-level privileges using a service role key, bypassing all Row Level Security policies to allow unrestricted database access.

```ts  theme={null}
// Create a single Supabase client for interacting with your database
// 'Database' supplies the type definitions to supabase-js
const supabase = createClient<Database>(
  // These details can be found in your Supabase project settings under `API`
  process.env.SUPABASE_PROJECT_URL as string, // e.g. https://abc123.supabase.co - replace 'abc123' with your project ID
  process.env.SUPABASE_SERVICE_ROLE_KEY as string // Your service role secret key
);

// Your task
```

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Triggering tasks from Supabase edge functions
Source: https://trigger.dev/docs/guides/frameworks/supabase-edge-functions-basic

This guide will show you how to trigger a task from a Supabase edge function, and then view the run in our dashboard.

## Overview

Supabase edge functions allow you to trigger tasks either when an event is sent from a third party (e.g. when a new Stripe payment is processed, when a new user signs up to a service, etc), or when there are any changes or updates to your Supabase database.

This guide shows you how to set up and deploy a simple Supabase edge function example that triggers a task when an edge function URL is accessed.

## Prerequisites

* Ensure you have the [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started) installed
* Since Supabase CLI version 1.123.4, you must have [Docker Desktop installed](https://supabase.com/docs/guides/functions/deploy#deploy-your-edge-functions) to deploy Edge Functions
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/supabase-edge-functions">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Initial setup

<Steps>
  <Step title="Optional step 1: create a new Supabase project">
    <Info> If you already have a Supabase project on your local machine you can skip this step.</Info>

    You can create a new project by running the following command in your terminal using the Supabase CLI:

    ```bash  theme={null}
    supabase init
    ```

    <Note>
      If you are using VS Code, ensure to answer 'y' when asked to generate VS Code settings for Deno,
      and install any recommended extensions.
    </Note>
  </Step>

  <Step title="Optional step 2: create a package.json file">
    If your project does not already have `package.json` file (e.g. if you are using Deno), create it manually in your project's root folder.

    <Info> If your project has a `package.json` file you can skip this step.</Info>

    This is required for the Trigger.dev SDK to work correctly.

    ```ts package.json theme={null}
    {
      "devDependencies": {
        "typescript": "^5.6.2"
      }
    }
    ```

    <Note> Update your Typescript version to the latest version available. </Note>
  </Step>

  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Create a new Supabase edge function and deploy it

<Steps>
  <Step title="Create a new Supabase edge function">
    We'll call this example `edge-function-trigger`.

    In your project, run the following command in the terminal using the Supabase CLI:

    ```bash  theme={null}
    supabase functions new edge-function-trigger
    ```
  </Step>

  <Step title="Update the edge function code">
    Replace the placeholder code in your `edge-function-trigger/index.ts` file with the following:

    ```ts functions/edge-function-trigger/index.ts theme={null}
    // Setup type definitions for built-in Supabase Runtime APIs
    import "jsr:@supabase/functions-js/edge-runtime.d.ts";
    // Import the Trigger.dev SDK - replace "<your-sdk-version>" with the version of the SDK you are using, e.g. "3.0.0". You can find this in your package.json file.
    import { tasks } from "npm:@trigger.dev/sdk@3.0.0";
    // Import your task type from your /trigger folder
    import type { helloWorldTask } from "../../../src/trigger/example.ts";
    //     ðŸ‘† **type-only** import

    Deno.serve(async () => {
      await tasks.trigger<typeof helloWorldTask>(
        // Your task id
        "hello-world",
        // Your task payload
        "Hello from a Supabase Edge Function!"
      );
      return new Response("OK");
    });
    ```

    <Note>You can only import the `type` from the task.</Note>

    <Note>
      Tasks in the `trigger` folder use Node, so they must stay in there or they will not run,
      especially if you are using a different runtime like Deno. Also do not add "`npm:`" to imports
      inside your task files, for the same reason.
    </Note>
  </Step>

  <Step title="Deploy your edge function using the Supabase CLI">
    You can now deploy your edge function with the following command in your terminal:

    ```bash  theme={null}
    supabase functions deploy edge-function-trigger --no-verify-jwt
    ```

    <Warning>
      `--no-verify-jwt` removes the JSON Web Tokens requirement from the authorization header. By
      default this should be on, but it is not strictly required for this hello world example.
    </Warning>

    <Note>
      To learn more about how to properly configure Supabase auth for Trigger.dev tasks, please refer to
      our [Supabase Authentication guide](/guides/frameworks/supabase-authentication). It demonstrates
      how to use JWT authentication for user-specific operations or your service role key for
      admin-level access.
    </Note>

    Follow the CLI instructions and once complete you should now see your new edge function deployment in your Supabase edge functions dashboard.

    There will be a link to the dashboard in your terminal output, or you can find it at this URL:

    `https://supabase.com/dashboard/project/<your-project-id>/functions`

    <Note>Replace `your-project-id` with your actual project ID.</Note>
  </Step>
</Steps>

## Set your Trigger.dev prod secret key in the Supabase dashboard

To trigger a task from your edge function, you need to set your Trigger.dev secret key in the Supabase dashboard.

To do this, first go to your Trigger.dev [project dashboard](https://cloud.trigger.dev) and copy the `prod` secret key from the API keys page.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0733b8d37ded28dfc8eb55cfbbf8d1de" alt="How to find your prod secret key" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/api-key-prod.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b6322b1c7486febaa68d044cdcee166a 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5a9c86949e65af4e51e105f3e3a6bcc9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0b8cd9edac7b0f133e8790c302a64269 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5f86de1e7348b781d66bd13737b0dd37 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5f2fc6b58d2ed8d6d6a1653bb840bd67 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aed3fb7368091c0ee12cac472e02fc07 2500w" />

Then, in [Supabase](https://supabase.com/dashboard/projects), select your project, navigate to 'Project settings' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />, click 'Edge functions' <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" /> in the configurations menu, and then click the 'Add new secret' <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" /> button.

Add `TRIGGER_SECRET_KEY` <Icon icon="circle-4" iconType="solid" size={20} color="A8FF53" /> with the pasted value of your Trigger.dev `prod` secret key.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=70842bf838bc1ea9e1f195c9926bb746" alt="Add secret key in Supabase" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-keys-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=1b893de3a516863384e77179c709a631 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ba9cab56f377dc72898cd388a3280901 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=37d7d313be698f7015fe490fc01cad30 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=73a7d40712c7a889bbe6af3803b86df7 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0c62e86405a9e23947ed073be6c5fca4 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=30c4316db62c7820dd5c513c922b2976 2500w" />

## Deploy your task and trigger it from your edge function

<Steps>
  <Step title="Deploy your 'Hello World' task">
    Next, deploy your `hello-world` task to [Trigger.dev cloud](https://cloud.trigger.dev).

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest deploy
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest deploy
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest deploy
      ```
    </CodeGroup>
  </Step>

  <Step title="Trigger a prod run from your deployed edge function">
    To do this all you need to do is simply open the `edge-function-trigger` URL.

    `https://supabase.com/dashboard/project/<your-project-id>/functions`

    <Note>Replace `your-project-id` with your actual project ID.</Note>

    In your Supabase project, go to your Edge function dashboard, find `edge-function-trigger`, copy the URL, and paste it into a new window in your browser.

    Once loaded you should see â€˜OKâ€™ on the new screen.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=39bf78f3b0d9fab4d92cc1cda60fbcec" alt="Edge function URL" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-function-url.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ec78f91a1c5569170094e79228eb7e13 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=bb2c38ef3741c7f9efbf9aeeed2d9212 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=91eeaf194a648ab24e3d372722f0ba3d 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2ad7b3e2ffb9a70bb87dff0b0c41c94c 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d25ca24ca979a211d53163b0a8daf9aa 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-function-url.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f29534a7737c8c81db3da9c382dc9e97 2500w" />

    The task will be triggered when your edge function URL is accessed.

    Check your [cloud.trigger.dev](http://cloud.trigger.dev) dashboard and you should see a succesful `hello-world` task.

    **Congratulations, you have run a simple Hello World task from a Supabase edge function!**
  </Step>
</Steps>

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Triggering tasks from Supabase Database Webhooks
Source: https://trigger.dev/docs/guides/frameworks/supabase-edge-functions-database-webhooks

This guide shows you how to trigger a transcribing task when a row is added to a table in a Supabase database, using a Database Webhook and Edge Function.

## Overview

Supabase and Trigger.dev can be used together to create powerful workflows triggered by real-time changes in your database tables:

* A Supabase Database Webhook triggers an Edge Function when a row including a video URL is inserted into a table
* The Edge Function triggers a Trigger.dev task, passing the `video_url` column data from the new table row as the payload
* The Trigger.dev task then:

  * Uses [FFmpeg](https://www.ffmpeg.org/) to extract the audio track from a video URL
  * Uses [Deepgram](https://deepgram.com) to transcribe the extracted audio
  * Updates the original table row using the `record.id` in Supabase with the new transcription using `update`

## Prerequisites

* Ensure you have the [Supabase CLI](https://supabase.com/docs/guides/cli/getting-started) installed
* Since Supabase CLI version 1.123.4, you must have [Docker Desktop installed](https://supabase.com/docs/guides/functions/deploy#deploy-your-edge-functions) to deploy Edge Functions
* Ensure TypeScript is installed
* [Create a Trigger.dev account](https://cloud.trigger.dev)
* Create a new Trigger.dev project
* [Create a new Deepgram account](https://deepgram.com/) and get your API key from the dashboard

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/supabase-edge-functions">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## Initial setup

<Steps>
  <Step title="Optional step 1: create a new Supabase project">
    <Info> If you already have a Supabase project on your local machine you can skip this step.</Info>

    You can create a new project by running the following command in your terminal using the Supabase CLI:

    ```bash  theme={null}
    supabase init
    ```

    <Note>
      If you are using VS Code, ensure to answer 'y' when asked to generate VS Code settings for Deno,
      and install any recommended extensions.
    </Note>
  </Step>

  <Step title="Optional step 2: create a package.json file">
    If your project does not already have `package.json` file (e.g. if you are using Deno), create it manually in your project's root folder.

    <Info> If your project has a `package.json` file you can skip this step.</Info>

    This is required for the Trigger.dev SDK to work correctly.

    ```ts package.json theme={null}
    {
      "devDependencies": {
        "typescript": "^5.6.2"
      }
    }
    ```

    <Note> Update your Typescript version to the latest version available. </Note>
  </Step>

  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Choose "None" when prompted to install an example task. We will create a new task for this guide.
  </Step>
</Steps>

## Create a new table in your Supabase database

First, in the Supabase project dashboard, you'll need to create a new table to store the video URL and transcription.

To do this, click on 'Table Editor' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" /> in the left-hand menu and create a new table. <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4b7630a86b91ac5f942ac31538ad401d" alt="How to create a new Supabase table" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-new-table-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=cb8f066d063d37ba77150315e852ce86 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e6826c90fe6a0b9ade20f16e343bffc8 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f502bf263b08fb57a28095131987eef5 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=bda96d83c7276830f239d7a1773cf379 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0db75386570571a94a218936a250c737 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-1.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0a2bbf11537f694d5e8888c590d8a22b 2500w" />

Call your table `video_transcriptions`. <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />

Add two new columns, one called `video_url` with the type `text` <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />, and another called `transcription`, also with the type `text` <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" />.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a1c1f36b91edf8538ae33cc465f9ec47" alt="How to create a new Supabase table 2" data-og-width="3224" width="3224" data-og-height="1824" height="1824" data-path="images/supabase-new-table-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a1a99d222b35bd675f86b37cd83e14b4 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=6189562ca9bebf649c074db28126c3ed 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=73262a6abaa2851fbabed87f3200b930 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=53054702bf0efbd27e3920cb8957d1aa 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4efb3c0cbaa50ed4611f62fc537ca04b 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-2.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=78d48f7f37128ea37b494a76a824f511 2500w" />

## Create and deploy the Trigger.dev task

### Generate the Database type definitions

To allow you to use TypeScript to interact with your table, you need to [generate the type definitions](https://supabase.com/docs/guides/api/rest/generating-types) for your Supabase table using the Supabase CLI.

```bash  theme={null}
supabase gen types --lang=typescript --project-id <project-ref> --schema public > database.types.ts
```

<Note> Replace `<project-ref>` with your Supabase project reference ID. This can be found in your Supabase project settings under 'General'. </Note>

### Create the transcription task

Create a new task file in your `/trigger` folder. Call it `videoProcessAndUpdate.ts`.

This task takes a video from a public video url, extracts the audio using FFmpeg and transcribes the audio using Deepgram. The transcription summary will then be updated back to the original row in the `video_transcriptions` table in Supabase.

You will need to install some additional dependencies for this task:

<CodeGroup>
  ```bash npm theme={null}
  npm install @deepgram/sdk @supabase/supabase-js fluent-ffmpeg
  ```

  ```bash pnpm theme={null}
  pnpm install @deepgram/sdk @supabase/supabase-js fluent-ffmpeg
  ```

  ```bash yarn theme={null}
  yarn install @deepgram/sdk @supabase/supabase-js fluent-ffmpeg
  ```
</CodeGroup>

These dependencies will allow you to interact with the Deepgram and Supabase APIs and extract audio from a video using FFmpeg.

<Warning>
  When updating your tables from a Trigger.dev task which has been triggered by a database change,
  be extremely careful to not cause an infinite loop. Ensure you have the correct conditions in
  place to prevent this.
</Warning>

```ts /trigger/videoProcessAndUpdate.ts theme={null}
// Install any missing dependencies below
import { createClient as createDeepgramClient } from "@deepgram/sdk";
import { createClient as createSupabaseClient } from "@supabase/supabase-js";
import { logger, task } from "@trigger.dev/sdk";
import ffmpeg from "fluent-ffmpeg";
import fs from "fs";
import { Readable } from "node:stream";
import os from "os";
import path from "path";
import { Database } from "../../database.types";

// Create a single Supabase client for interacting with your database
// 'Database' supplies the type definitions to supabase-js
const supabase = createSupabaseClient<Database>(
  // These details can be found in your Supabase project settings under `API`
  process.env.SUPABASE_PROJECT_URL as string, // e.g. https://abc123.supabase.co - replace 'abc123' with your project ID
  process.env.SUPABASE_SERVICE_ROLE_KEY as string // Your service role secret key
);

// Your DEEPGRAM_SECRET_KEY can be found in your Deepgram dashboard
const deepgram = createDeepgramClient(process.env.DEEPGRAM_SECRET_KEY);

export const videoProcessAndUpdate = task({
  id: "video-process-and-update",
  run: async (payload: { videoUrl: string; id: number }) => {
    const { videoUrl, id } = payload;

    logger.log(`Processing video at URL: ${videoUrl}`);

    // Generate temporary file names
    const tempDirectory = os.tmpdir();
    const outputPath = path.join(tempDirectory, `audio_${Date.now()}.wav`);

    const response = await fetch(videoUrl);

    // Extract the audio using FFmpeg
    await new Promise((resolve, reject) => {
      if (!response.body) {
        return reject(new Error("Failed to fetch video"));
      }

      ffmpeg(Readable.from(response.body))
        .outputOptions([
          "-vn", // Disable video output
          "-acodec pcm_s16le", // Use PCM 16-bit little-endian encoding
          "-ar 44100", // Set audio sample rate to 44.1 kHz
          "-ac 2", // Set audio channels to stereo
        ])
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    logger.log(`Audio extracted from video`, { outputPath });

    // Transcribe the audio using Deepgram
    const { result, error } = await deepgram.listen.prerecorded.transcribeFile(
      fs.readFileSync(outputPath),
      {
        model: "nova-2", // Use the Nova 2 model
        smart_format: true, // Automatically format the transcription
        diarize: true, // Enable speaker diarization
      }
    );

    if (error) {
      throw error;
    }

    const transcription = result.results.channels[0].alternatives[0].paragraphs?.transcript;

    logger.log(`Transcription: ${transcription}`);

    // Delete the temporary audio file
    fs.unlinkSync(outputPath);
    logger.log(`Temporary audio file deleted`, { outputPath });

    const { error: updateError } = await supabase
      .from("video_transcriptions")
      // Update the transcription column
      .update({ transcription: transcription })
      // Find the row by its ID
      .eq("id", id);

    if (updateError) {
      throw new Error(`Failed to update transcription: ${updateError.message}`);
    }

    return {
      message: `Summary of the audio: ${transcription}`,
      result,
    };
  },
});
```

<Warning>
  This task uses your service role secret key to bypass Row Level Security. This is not recommended
  for production use as it has unlimited access and bypasses all security checks.
</Warning>

<Note>
  To learn more about how to properly configure Supabase auth for Trigger.dev tasks, please refer to
  our [Supabase Authentication guide](/guides/frameworks/supabase-authentication). It demonstrates
  how to use JWT authentication for user-specific operations or your service role key for
  admin-level access.
</Note>

### Adding the FFmpeg build extension

Before you can deploy the task, you'll need to add the FFmpeg build extension to your `trigger.config.ts` file.

```ts trigger.config.ts theme={null}
// Add this import
import { ffmpeg } from "@trigger.dev/build/extensions/core";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>", // Replace with your project ref
  // Your other config settings...
  build: {
    // Add the FFmpeg build extension
    extensions: [ffmpeg()],
  },
});
```

<Note>
  [Build extensions](/config/extensions/overview) allow you to hook into the build system and
  customize the build process or the resulting bundle and container image (in the case of
  deploying). You can use pre-built extensions or create your own.
</Note>

<Note>
  You'll also need to add `@trigger.dev/build` to your `package.json` file under `devDependencies`
  if you don't already have it there.
</Note>

If you are modifying this example and using popular FFmpeg libraries like `fluent-ffmpeg` you'll also need to add them to [`external`](/config/config-file#external) in your `trigger.config.ts` file.

### Add your Deepgram and Supabase environment variables to your Trigger.dev project

You will need to add your `DEEPGRAM_SECRET_KEY`, `SUPABASE_PROJECT_URL` and `SUPABASE_SERVICE_ROLE_KEY` as environment variables in your Trigger.dev project. This can be done in the 'Environment Variables' page in your project dashboard.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=af652254781808a35c2bcefd4b61b59f" alt="Adding environment variables" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/environment-variables-page.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fd6487833d9c659f8a514c7cc86cf84d 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1758721fd84f5040b88997db401f7391 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4416f51b1528ae14285a03b560f22389 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12b90b89f7662aadaea07df17d9d3898 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28e6921620cda10d335a095dbfa85806 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/environment-variables-page.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4f6c67a030b20699bde25c22d68e57af 2500w" />

### Deploying your task

Now you can now deploy your task using the following command:

<CodeGroup>
  ```bash npm theme={null}
  npx trigger.dev@latest deploy
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest deploy
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest deploy
  ```
</CodeGroup>

## Create and deploy the Supabase Edge Function

### Add your Trigger.dev prod secret key to the Supabase dashboard

Go to your Trigger.dev [project dashboard](https://cloud.trigger.dev) and copy the `prod` secret key from the API keys page.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0733b8d37ded28dfc8eb55cfbbf8d1de" alt="How to find your prod secret key" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/api-key-prod.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b6322b1c7486febaa68d044cdcee166a 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5a9c86949e65af4e51e105f3e3a6bcc9 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0b8cd9edac7b0f133e8790c302a64269 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5f86de1e7348b781d66bd13737b0dd37 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5f2fc6b58d2ed8d6d6a1653bb840bd67 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/api-key-prod.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=aed3fb7368091c0ee12cac472e02fc07 2500w" />

Then, in [Supabase](https://supabase.com/dashboard/projects), select the project you want to use, navigate to 'Project settings' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />, click 'Edge Functions' <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" /> in the configurations menu, and then click the 'Add new secret' <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" /> button.

Add `TRIGGER_SECRET_KEY` <Icon icon="circle-4" iconType="solid" size={20} color="A8FF53" /> with the pasted value of your Trigger.dev `prod` secret key.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=70842bf838bc1ea9e1f195c9926bb746" alt="Add secret key in Supabase" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-keys-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=1b893de3a516863384e77179c709a631 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ba9cab56f377dc72898cd388a3280901 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=37d7d313be698f7015fe490fc01cad30 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=73a7d40712c7a889bbe6af3803b86df7 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0c62e86405a9e23947ed073be6c5fca4 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-keys-1.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=30c4316db62c7820dd5c513c922b2976 2500w" />

### Create a new Edge Function using the Supabase CLI

Now create an Edge Function using the Supabase CLI. Call it `video-processing-handler`. This function will be triggered by the Database Webhook.

```bash  theme={null}
supabase functions new video-processing-handler
```

```ts functions/video-processing-handler/index.ts theme={null}
// Setup type definitions for built-in Supabase Runtime APIs
import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { tasks } from "npm:@trigger.dev/sdk@latest";
// Import the videoProcessAndUpdate task from the trigger folder
import type { videoProcessAndUpdate } from "../../../src/trigger/videoProcessAndUpdate.ts";
//     ðŸ‘† type only import

// Sets up a Deno server that listens for incoming JSON requests
Deno.serve(async (req) => {
  const payload = await req.json();

  // This payload will contain the video url and id from the new row in the table
  const videoUrl = payload.record.video_url;
  const id = payload.record.id;

  // Trigger the videoProcessAndUpdate task with the videoUrl payload
  await tasks.trigger<typeof videoProcessAndUpdate>("video-process-and-update", { videoUrl, id });
  console.log(payload ?? "No name provided");

  return new Response("ok");
});
```

<Note>
  Tasks in the `trigger` folder use Node, so they must stay in there or they will not run,
  especially if you are using a different runtime like Deno. Also do not add "`npm:`" to imports
  inside your task files, for the same reason.
</Note>

### Deploy the Edge Function

Now deploy your new Edge Function with the following command:

```bash  theme={null}
supabase functions deploy video-processing-handler
```

Follow the CLI instructions, selecting the same project you added your `prod` secret key to, and once complete you should see your new Edge Function deployment in your Supabase Edge Functions dashboard.

There will be a link to the dashboard in your terminal output.

## Create the Database Webhook

In your Supabase project dashboard, click 'Project settings' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />, then the 'API' tab <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />, and copy the `anon` `public` API key from the table <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" />.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d842b953497f2819e64abd2497e0f25" alt="How to find your Supabase API keys" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-api-key.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1b09ec34e37b4569f6ffae7b41100bad 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a205e60a3d33fae2ff4f719287df05c4 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c9ba5c95634b152931fab0d43f75778c 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=736ebe39bec4eec64ac11e0ca03e6d09 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6483cb22bbbed8fbaf29d05f5ed50580 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-api-key.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=569ff35cadfacd0d89408e4be2f336b6 2500w" />

Then, go to 'Database' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" /> click on 'Webhooks' <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" />, and then click 'Create a new hook' <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" />.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b14ffc5195561195ba824430fd5b3566" alt="How to create a new webhook" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-create-webhook-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f388b147fed1a3e4e68015d4b56e54e5 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=94e5f71acebb513862c8855c1500e57b 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=962d9b080e507d5af564fabd6db53f1a 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=693a3b514e1e1dac9787e78c1bbe7aea 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=46f027cf03b1b286f375848ee81d7a94 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-1.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d9af95ddd3d3f6be3ecd08d20ad4604c 2500w" />

<Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" /> Call the hook `edge-function-hook`.

<Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" /> Select the new table you have created:
`public` `video_transcriptions`.

<Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" /> Choose the `insert` event.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9e7e86e98234a3bb4a852e7c1f429381" alt="How to create a new webhook 2" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-create-webhook-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ca6621f024688dd564ad99e0fdb0ffb7 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0a13a85ad5879e439acbe6dc8b5310c8 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2cd3eec702d6b89fbc3f7864244ff903 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=062d31b161b8ae0c7e5ecda295da4369 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3664d62d87ac15550a882d1c223fa9fb 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/supabase-create-webhook-2.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4a6e4965d3dce81b2f305cc1e265d172 2500w" />

<Icon icon="circle-4" iconType="solid" size={20} color="A8FF53" /> Under 'Webhook configuration', select
'Supabase Edge Functions'{" "}

<Icon icon="circle-5" iconType="solid" size={20} color="A8FF53" /> Under 'Edge Function', choose `POST`
and select the Edge Function you have created: `video-processing-handler`.{" "}

<Icon icon="circle-6" iconType="solid" size={20} color="A8FF53" /> Under 'HTTP Headers', add a new header with the key `Authorization` and the value `Bearer <your-api-key>` (replace `<your-api-key>` with the `anon` `public` API key you copied earlier).

<Info>
  Supabase Edge Functions require a JSON Web Token [JWT](https://supabase.com/docs/guides/auth/jwts)
  in the authorization header. This is to ensure that only authorized users can access your edge
  functions.
</Info>

<Icon icon="circle-7" iconType="solid" size={20} color="A8FF53" /> Click 'Create webhook'.{" "}

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ef4b8d91417d1e923063a9f599537f1f" alt="How to create a new webhook 3" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-create-webhook-3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d1f574a056c46ecca8e8facc2c7f11d3 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e141e894768eadb53174d283e8bb7864 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=c38276204880ba27b452b0a9eccf8696 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=aa04b198f2fb191a288a4f8b37f02e31 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d4dccfa32030a493caecab6383c8a6af 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-create-webhook-3.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=9afd89ffa262e871ee3b1864bbb8b95e 2500w" />

Your Database Webhook is now ready to use.

## Triggering the entire workflow

Your `video-processing-handler` Edge Function is now set up to trigger the `videoProcessAndUpdate` task every time a new row is inserted into your `video_transcriptions` table.

To do this, go back to your Supabase project dashboard, click on 'Table Editor' <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" /> in the left-hand menu, click on the `video_transcriptions` table <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" /> , and then click 'Insert', 'Insert Row' <Icon icon="circle-3" iconType="solid" size={20} color="A8FF53" />.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=018a4b143a7e610ef85fe630cb5f3942" alt="How to insert a new row 1" data-og-width="1624" width="1624" data-og-height="924" height="924" data-path="images/supabase-new-table-3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fc1cee2d21ace6b3ba5a879a6be235c3 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=190c3f6352ca9ea4f47dc7122ecf0fc9 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=20e488fddd2a02db28ef49b3205a3a02 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=cdab5cdbb858decd062c5e0d8ba4f13c 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=6dd9a76d09f9a9edd2238ee72b92d98c 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-3.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=cb14e79904fdd5dc076fc3ea24816621 2500w" />

Add a new item under `video_url`, with a public video url. <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" />.

You can use the following public video URL for testing: `https://content.trigger.dev/Supabase%20Edge%20Functions%20Quickstart.mp4`.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4f12c856f8e921c287e2d3d45c4db397" alt="How to insert a new row 2" data-og-width="3224" width="3224" data-og-height="1824" height="1824" data-path="images/supabase-new-table-4.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=c5737feb6cf79dd20606c52f9a3733b0 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=15aa16b5e45cae5189960db92ca6bec4 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f115634df16843b498ac988f966494f8 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=7733ad6bd8f283a808616182a5a0aee3 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=13987e360ef986d88a454526b834f227 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-new-table-4.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d17d016e9c0d2c213839932e56b5d600 2500w" />

Once the new table row has been inserted, check your [cloud.trigger.dev](http://cloud.trigger.dev) project 'Runs' list <Icon icon="circle-1" iconType="solid" size={20} color="A8FF53" /> and you should see a processing `videoProcessAndUpdate` task <Icon icon="circle-2" iconType="solid" size={20} color="A8FF53" /> which has been triggered when you added a new row with the video url to your `video_transcriptions` table.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=845a8ec72040ad8cdab18b905cf52096" alt="Supabase successful run" data-og-width="3224" width="3224" data-og-height="1824" height="1824" data-path="images/supabase-run-result.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4905e76d9f60762b4b91cd41d6964e44 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e98ab82fe22ea3c04f4907ff673bfbe3 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=559ef31d145b622f9881499b74c628c4 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=003369ca97e1241b1ee739b45def2bf5 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=78039d0ebf7cf5338e0c18846057c191 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-run-result.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8373b7a03955d029487eee841aa6fdcd 2500w" />

Once the run has completed successfully, go back to your Supabase `video_transcriptions` table, and you should see that in the row containing the original video URL, the transcription has now been added to the `transcription` column.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=9d53cd6ba016677b7a8ad6eea4f9c58e" alt="Supabase successful table update" data-og-width="3224" width="3224" data-og-height="1824" height="1824" data-path="images/supabase-table-result.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=1719d1347851ea2f54d620c897e9b057 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=15a9901f3cccbdf20700dec20638744d 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e900a2cfbfe4544448d048ec34bc107e 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=730b4c94f32134794e13863de70c4e42 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=6b5616e3a599e1a3e4a983d24beaf37a 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/supabase-table-result.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=146d83c0d05046987d297578ff5f5124 2500w" />

**Congratulations! You have completed the full workflow from Supabase to Trigger.dev and back again.**

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Supabase overview
Source: https://trigger.dev/docs/guides/frameworks/supabase-guides-overview

Guides and examples for using Supabase with Trigger.dev.

## Learn more about Supabase and Trigger.dev

### Full walkthrough guides from development to deployment

<CardGroup cols={1}>
  <Card title="Edge function hello world guide" icon="book" href="/guides/frameworks/supabase-edge-functions-basic">
    Learn how to trigger a task from a Supabase edge function when a URL is visited.
  </Card>

  <Card title="Database webhooks guide" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>

  <Card title="Supabase authentication guide" icon="book" href="/guides/frameworks/supabase-authentication">
    Learn how to authenticate Supabase tasks using JWTs for Row Level Security (RLS) or service role
    keys for admin access.
  </Card>
</CardGroup>

### Task examples with code you can copy and paste

<CardGroup cols={2}>
  <Card title="Supabase database operations" icon="bolt" href="/guides/examples/supabase-database-operations">
    Run basic CRUD operations on a table in a Supabase database using Trigger.dev.
  </Card>

  <Card title="Supabase Storage upload" icon="bolt" href="/guides/examples/supabase-storage-upload">
    Download a video from a URL and upload it to Supabase Storage using S3.
  </Card>
</CardGroup>


# Using webhooks with Trigger.dev
Source: https://trigger.dev/docs/guides/frameworks/webhooks-guides-overview

Guides for using webhooks with Trigger.dev.

## Overview

Webhooks are a way to send and receive events from external services. Triggering tasks using webhooks allow you to add real-time, event driven functionality to your app.

A webhook handler is code that executes in response to an event. They can be endpoints in your framework's routing which can be triggered by an external service.

## Webhook guides

<CardGroup cols={2}>
  <Card title="Next.js - triggering tasks using webhooks" icon="N" href="/guides/frameworks/nextjs-webhooks">
    How to create a webhook handler in a Next.js app, and trigger a task from it.
  </Card>

  <Card title="Remix - triggering tasks using webhooks" icon="R" href="/guides/frameworks/remix-webhooks">
    How to create a webhook handler in a Remix app, and trigger a task from it.
  </Card>

  <Card title="Stripe webhooks" icon="webhook" href="/guides/examples/stripe-webhook">
    How to create a Stripe webhook handler and trigger a task when a 'checkout session completed'
    event is received.
  </Card>

  <Card title="Supabase database webhooks guide" icon="webhook" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Learn how to trigger a task from a Supabase edge function when an event occurs in your database.
  </Card>
</CardGroup>


# Frameworks, guides and examples
Source: https://trigger.dev/docs/guides/introduction

A growing list of guides and examples to get the most out of Trigger.dev.

## Frameworks

<CardGroup cols={3}>
  <Card title="Bun" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=66ba8e5d8b75666ef2f6bc402cde6200" href="/guides/frameworks/bun" data-og-width="483" width="483" data-og-height="282" height="282" data-path="images/logo-bun.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=82015d4b1f1ef4a232755368c33a7f73 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b15d2152f74e189b44aa1b96fde5d281 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a2fb7961ab6d94b1b0196c2a38a713e0 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1f1c78ec4a10b7ff0c905b45e2d82915 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ef1cde36b5be1fbd5987555eee5b1636 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-bun.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ae5ea69d721d3bcfe2ceb79f510457b4 2500w" />

  <Card title="Next.js" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a9f98e3c3948aeb3acb74648ad29cc8f" href="/guides/frameworks/nextjs" data-og-width="483" width="483" data-og-height="282" height="282" data-path="images/logo-nextjs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a194514a9fc67ba3450568f5e7275231 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e4cf4d8664bea382d6e2ad19d1a3e4a2 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8e011dac5b19895363c483904a6e4ed0 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1989b26e995e0703437f00a839946eb5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=59ad44ef970a051aab37a18358bc8a3c 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nextjs.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e3786a7da1a73b0b58f59c38a49e05f4 2500w" />

  <Card title="Node.js" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=45e461847bf3377f5a4bb12daabc04c1" href="/guides/frameworks/nodejs" data-og-width="483" width="483" data-og-height="282" height="282" data-path="images/logo-nodejs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ed5332d326f804b5ae1277177250d78c 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2796537dadb0348e65baad6218f958f3 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9799dd3aadbc114599963698c0151f6a 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9288db090fa58a5137be6b66654bead5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=42d29f55b525c55d6bd6ea7f32e39b28 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-nodejs.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b6094d1b1a064915e68de98dde37dee9 2500w" />

  <Card title="Remix" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b87aae0d212fdbe8d766de947055f6e" href="/guides/frameworks/remix" data-og-width="483" width="483" data-og-height="282" height="282" data-path="images/logo-remix.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=414c844373d339d6401419d5637389a0 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c732bdea6232e6290ae5d61fe8856d13 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=407ed0fc36edf9365e0045c02e2622fb 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ebecbd154b93506f650831d2f9b4b494 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4660677717fd473460a01232376471d7 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-remix.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=eb158ce25e5b218a5d02b20ba060b137 2500w" />

  <Card title="SvelteKit" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a0648a3f93ec288a35cf17c9cf8cfdea" href="/guides/community/sveltekit" data-og-width="480" width="480" data-og-height="282" height="282" data-path="images/logo-svelte.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c337195e80ce92dc8e8a9c8029ef2d91 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=38c9b366a9eda7f5e801a3ded8be8a43 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=bd078aa2ffbfbc7f9dd90d5528e56ed8 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=db91534920c01eb7c3f541d7511e87c3 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=06c4f47f541a95c1005ec0b9564021b3 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/logo-svelte.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=19ab12550b98c9400e2558ef06a75432 2500w" />
</CardGroup>

## Guides

Get set up fast using our detailed walk-through guides.

| Guide                                                                                      | Description                                                          |
| :----------------------------------------------------------------------------------------- | :------------------------------------------------------------------- |
| [AI Agent: Content moderation](/guides/ai-agents/respond-and-check-content)                | Parallel check content while responding to customers                 |
| [AI Agent: Generate and translate copy](/guides/ai-agents/generate-translate-copy)         | Chain prompts to generate and translate content                      |
| [AI Agent: News verification](/guides/ai-agents/verify-news-article)                       | Orchestrate fact checking of news articles                           |
| [AI Agent: Route questions](/guides/ai-agents/route-question)                              | Route questions to different models based on complexity              |
| [AI Agent: Translation refinement](/guides/ai-agents/translate-and-refine)                 | Evaluate and refine translations with feedback                       |
| [Cursor rules](/guides/cursor-rules)                                                       | Use Cursor rules to help write Trigger.dev tasks                     |
| [Prisma](/guides/frameworks/prisma)                                                        | How to setup Prisma with Trigger.dev                                 |
| [Python image processing](/guides/python/python-image-processing)                          | Use Python and Pillow to process images                              |
| [Python document to markdown](/guides/python/python-doc-to-markdown)                       | Use Python and MarkItDown to convert documents to markdown           |
| [Python PDF form extractor](/guides/python/python-pdf-form-extractor)                      | Use Python, PyMuPDF and Trigger.dev to extract data from a PDF form  |
| [Python web crawler](/guides/python/python-crawl4ai)                                       | Use Python, Crawl4AI and Playwright to create a headless web crawler |
| [Sequin database triggers](/guides/frameworks/sequin)                                      | Trigger tasks from database changes using Sequin                     |
| [Stripe webhooks](/guides/examples/stripe-webhook)                                         | Trigger tasks from incoming Stripe webhook events                    |
| [Supabase database webhooks](/guides/frameworks/supabase-edge-functions-database-webhooks) | Trigger tasks using Supabase database webhooks                       |
| [Supabase edge function hello world](/guides/frameworks/supabase-edge-functions-basic)     | Trigger tasks from Supabase edge function                            |
| [Using webhooks in Next.js](/guides/frameworks/nextjs-webhooks)                            | Trigger tasks from a webhook in Next.js                              |
| [Using webhooks in Remix](/guides/frameworks/remix-webhooks)                               | Trigger tasks from a webhook in Remix                                |

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>

## Example projects

Example projects are full projects with example repos you can fork and use. These are a great way of learning how to use Trigger.dev in your projects.

| Example project                                                                                                 | Description                                                                                                                            | Framework | GitHub                                                                                                         |
| :-------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------- | :-------- | :------------------------------------------------------------------------------------------------------------- |
| [Anchor Browser web scraper](/guides/example-projects/anchor-browser-web-scraper)                               | Monitor a website and find the cheapest tickets for a show.                                                                            | â€”         | [View the repo](https://github.com/triggerdotdev/examples/tree/main/anchor-browser-web-scraper)                |
| [Batch LLM Evaluator](/guides/example-projects/batch-llm-evaluator)                                             | Evaluate multiple LLM models and stream the results to the frontend.                                                                   | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/batch-llm-evaluator)                       |
| [Claude thinking chatbot](/guides/example-projects/claude-thinking-chatbot)                                     | Use Vercel's AI SDK and Anthropic's Claude 3.7 model to create a thinking chatbot.                                                     | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/claude-thinking-chatbot)                   |
| [Human-in-the-loop workflow](/guides/example-projects/human-in-the-loop-workflow)                               | Create audio summaries of newspaper articles using a human-in-the-loop workflow built with ReactFlow and Trigger.dev waitpoint tokens. | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/article-summary-workflow)                  |
| [Mastra agents with memory](/guides/example-projects/mastra-agents-with-memory)                                 | Use Mastra to create a weather agent that can collect live weather data and generate clothing recommendations.                         | â€”         | [View the repo](https://github.com/triggerdotdev/examples/tree/main/mastra-agents)                             |
| [OpenAI Agents SDK for Python guardrails](/guides/example-projects/openai-agent-sdk-guardrails)                 | Use the OpenAI Agents SDK for Python to create a guardrails system for your AI agents.                                                 | â€”         | [View the repo](https://github.com/triggerdotdev/examples/tree/main/openai-agent-sdk-guardrails-examples)      |
| [OpenAI Agents SDK for TypeScript playground](/guides/example-projects/openai-agents-sdk-typescript-playground) | A playground containing 7 AI agents using the OpenAI Agents SDK for TypeScript with Trigger.dev.                                       | â€”         | [View the repo](https://github.com/triggerdotdev/examples/tree/main/openai-agents-sdk-with-trigger-playground) |
| [Product image generator](/guides/example-projects/product-image-generator)                                     | Transform basic product photos into professional marketing shots using Replicate's image generation models.                            | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/product-image-generator)                   |
| [Python web crawler](/guides/python/python-crawl4ai)                                                            | Use Python, Crawl4AI and Playwright to create a headless web crawler with Trigger.dev.                                                 | â€”         | [View the repo](https://github.com/triggerdotdev/examples/tree/main/python-crawl4ai)                           |
| [Realtime CSV Importer](/guides/example-projects/realtime-csv-importer)                                         | Upload a CSV file and see the progress of the task streamed to the frontend.                                                           | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/realtime-csv-importer)                     |
| [Realtime Fal.ai image generation](/guides/example-projects/realtime-fal-ai)                                    | Generate an image from a prompt using Fal.ai and show the progress of the task on the frontend using Realtime.                         | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/realtime-fal-ai-image-generation)          |
| [Turborepo monorepo with Prisma](/guides/example-projects/turborepo-monorepo-prisma)                            | Use Prisma in a Turborepo monorepo with Trigger.dev.                                                                                   | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package)  |
| [Vercel AI SDK image generator](/guides/example-projects/vercel-ai-sdk-image-generator)                         | Use the Vercel AI SDK to generate images from a prompt.                                                                                | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-image-generator)             |
| [Vercel AI SDK deep research agent](/guides/example-projects/vercel-ai-sdk-deep-research)                       | Use the Vercel AI SDK to generate comprehensive PDF reports using a deep research agent.                                               | Next.js   | [View the repo](https://github.com/triggerdotdev/examples/tree/main/vercel-ai-sdk-deep-research-agent)         |

## Example tasks

Task code you can copy and paste to use in your project. They can all be extended and customized to fit your needs.

| Example task                                                                  | Description                                                                                                                                          |
| :---------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- |
| [DALLÂ·E 3 image generation](/guides/examples/dall-e3-generate-image)          | Use OpenAI's GPT-4o and DALLÂ·E 3 to generate an image and text.                                                                                      |
| [Deepgram audio transcription](/guides/examples/deepgram-transcribe-audio)    | Transcribe audio using Deepgram's speech recognition API.                                                                                            |
| [Fal.ai image to cartoon](/guides/examples/fal-ai-image-to-cartoon)           | Convert an image to a cartoon using Fal.ai, and upload the result to Cloudflare R2.                                                                  |
| [Fal.ai with Realtime](/guides/examples/fal-ai-realtime)                      | Generate an image from a prompt using Fal.ai and show the progress of the task on the frontend using Realtime.                                       |
| [FFmpeg video processing](/guides/examples/ffmpeg-video-processing)           | Use FFmpeg to process a video in various ways and save it to Cloudflare R2.                                                                          |
| [Firecrawl URL crawl](/guides/examples/firecrawl-url-crawl)                   | Learn how to use Firecrawl to crawl a URL and return LLM-ready markdown.                                                                             |
| [LibreOffice PDF conversion](/guides/examples/libreoffice-pdf-conversion)     | Convert a document to PDF using LibreOffice.                                                                                                         |
| [Lightpanda](/guides/examples/lightpanda)                                     | Use Lightpanda browser (or cloud version) to get a webpage's content.                                                                                |
| [OpenAI with retrying](/guides/examples/open-ai-with-retrying)                | Create a reusable OpenAI task with custom retry options.                                                                                             |
| [PDF to image](/guides/examples/pdf-to-image)                                 | Use `MuPDF` to turn a PDF into images and save them to Cloudflare R2.                                                                                |
| [Puppeteer](/guides/examples/puppeteer)                                       | Use Puppeteer to generate a PDF or scrape a webpage.                                                                                                 |
| [React email](/guides/examples/react-email)                                   | Send an email using React Email.                                                                                                                     |
| [React to PDF](/guides/examples/react-pdf)                                    | Use `react-pdf` to generate a PDF and save it to Cloudflare R2.                                                                                      |
| [Resend email sequence](/guides/examples/resend-email-sequence)               | Send a sequence of emails over several days using Resend with Trigger.dev.                                                                           |
| [Replicate image generation](/guides/examples/replicate-image-generation)     | Learn how to generate images from source image URLs using Replicate and Trigger.dev.                                                                 |
| [Satori](/guides/examples/satori)                                             | Generate OG images using React Satori.                                                                                                               |
| [Scrape Hacker News](/guides/examples/scrape-hacker-news)                     | Scrape Hacker News using BrowserBase and Puppeteer, summarize the articles with ChatGPT and send an email of the summary every weekday using Resend. |
| [Sentry error tracking](/guides/examples/sentry-error-tracking)               | Automatically send errors to Sentry from your tasks.                                                                                                 |
| [Sharp image processing](/guides/examples/sharp-image-processing)             | Use Sharp to process an image and save it to Cloudflare R2.                                                                                          |
| [Supabase database operations](/guides/examples/supabase-database-operations) | Run basic CRUD operations on a table in a Supabase database using Trigger.dev.                                                                       |
| [Supabase Storage upload](/guides/examples/supabase-storage-upload)           | Download a video from a URL and upload it to Supabase Storage using S3.                                                                              |
| [Vercel AI SDK](/guides/examples/vercel-ai-sdk)                               | Use Vercel AI SDK to generate text using OpenAI.                                                                                                     |
| [Vercel sync environment variables](/guides/examples/vercel-sync-env-vars)    | Automatically sync environment variables from your Vercel projects to Trigger.dev.                                                                   |

<Note>
  If you would like to see a guide for your framework, or an example task for your use case, please
  request it in our [Discord server](https://trigger.dev/discord) and we'll add it to the list.
</Note>


# Python headless browser web crawler example
Source: https://trigger.dev/docs/guides/python/python-crawl4ai

Learn how to use Python, Crawl4AI and Playwright to create a headless browser web crawler with Trigger.dev.

## Overview

This demo showcases how to use Trigger.dev with Python to build a web crawler that uses a headless browser to navigate websites and extract content.

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Python](https://www.python.org/) installed on your local machine

## Features

* [Trigger.dev](https://trigger.dev) for background task orchestration
* Our [Python build extension](/config/extensions/pythonExtension) to install the dependencies and run the Python script
* [Crawl4AI](https://github.com/unclecode/crawl4ai), an open source LLM friendly web crawler
* A custom [Playwright extension](https://playwright.dev/) to create a headless chromium browser
* Proxy support

## Using Proxies

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

Some popular proxy services are:

* [Smartproxy](https://smartproxy.com/)
* [Bright Data](https://brightdata.com/)
* [Browserbase](https://browserbase.com/)
* [Oxylabs](https://oxylabs.io/)
* [ScrapingBee](https://scrapingbee.com/)

Once you have a proxy service, set the following environment variables in your Trigger.dev .env file, and add them in the Trigger.dev dashboard:

* `PROXY_URL`: The URL of your proxy server (e.g., `http://proxy.example.com:8080`)
* `PROXY_USERNAME`: Username for authenticated proxies (optional)
* `PROXY_PASSWORD`: Password for authenticated proxies (optional)

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/python-crawl4ai">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## The code

### Build configuration

After you've initialized your project with Trigger.dev, add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { pythonExtension } from "@trigger.dev/python/extension";
import type { BuildContext, BuildExtension } from "@trigger.dev/core/build";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    extensions: [
      // This is required to use the Python extension
      pythonExtension(),
      // This is required to create a headless chromium browser with Playwright
      installPlaywrightChromium(),
    ],
  },
});

// This is a custom build extension to install Playwright and Chromium
export function installPlaywrightChromium(): BuildExtension {
  return {
    name: "InstallPlaywrightChromium",
    onBuildComplete(context: BuildContext) {
      const instructions = [
        // Base and Chromium dependencies
        `RUN apt-get update && apt-get install -y --no-install-recommends \
          curl unzip npm libnspr4 libatk1.0-0 libatk-bridge2.0-0 libatspi2.0-0 \
          libasound2 libnss3 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 \
          libgbm1 libxkbcommon0 \
          && apt-get clean && rm -rf /var/lib/apt/lists/*`,

        // Install Playwright and Chromium
        `RUN npm install -g playwright`,
        `RUN mkdir -p /ms-playwright`,
        `RUN PLAYWRIGHT_BROWSERS_PATH=/ms-playwright python -m playwright install --with-deps chromium`,
      ];

      context.addLayer({
        id: "playwright",
        image: { instructions },
        deploy: {
          env: {
            PLAYWRIGHT_BROWSERS_PATH: "/ms-playwright",
            PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1",
            PLAYWRIGHT_SKIP_BROWSER_VALIDATION: "1",
          },
          override: true,
        },
      });
    },
  };
}
```

<Info>
  Learn more about executing scripts in your Trigger.dev project using our Python build extension
  [here](/config/extensions/pythonExtension).
</Info>

### Task code

This task uses the `python.runScript` method to run the `crawl-url.py` script with the given URL as an argument. You can see the original task in our examples repository [here](https://github.com/triggerdotdev/examples/blob/main/python-crawl4ai/src/trigger/pythonTasks.ts).

```ts src/trigger/pythonTasks.ts theme={null}
import { logger, schemaTask, task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";
import { z } from "zod";

export const convertUrlToMarkdown = schemaTask({
  id: "convert-url-to-markdown",
  schema: z.object({
    url: z.string().url(),
  }),
  run: async (payload) => {
    // Pass through any proxy environment variables
    const env = {
      PROXY_URL: process.env.PROXY_URL,
      PROXY_USERNAME: process.env.PROXY_USERNAME,
      PROXY_PASSWORD: process.env.PROXY_PASSWORD,
    };

    const result = await python.runScript("./src/python/crawl-url.py", [payload.url], { env });

    logger.debug("convert-url-to-markdown", {
      url: payload.url,
      result,
    });

    return result.stdout;
  },
});
```

### Add a requirements.txt file

Add the following to your `requirements.txt` file. This is required in Python projects to install the dependencies.

```txt requirements.txt theme={null}
crawl4ai
playwright
urllib3<2.0.0
```

### The Python script

The Python script is a simple script using Crawl4AI that takes a URL and returns the markdown content of the page. You can see the original script in our examples repository [here](https://github.com/triggerdotdev/examples/blob/main/python-crawl4ai/src/python/crawl-url.py).

```python src/python/crawl-url.py theme={null}
import asyncio
import sys
import os
from crawl4ai import *
from crawl4ai.async_configs import BrowserConfig

async def main(url: str):
    # Get proxy configuration from environment variables
    proxy_url = os.environ.get("PROXY_URL")
    proxy_username = os.environ.get("PROXY_USERNAME")
    proxy_password = os.environ.get("PROXY_PASSWORD")

    # Configure the proxy
    browser_config = None
    if proxy_url:
        if proxy_username and proxy_password:
            # Use authenticated proxy
            proxy_config = {
                "server": proxy_url,
                "username": proxy_username,
                "password": proxy_password
            }
            browser_config = BrowserConfig(proxy_config=proxy_config)
        else:
            # Use simple proxy
            browser_config = BrowserConfig(proxy=proxy_url)
    else:
        browser_config = BrowserConfig()

    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url=url,
        )
        print(result.markdown)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python crawl-url.py <url>")
        sys.exit(1)
    url = sys.argv[1]
    asyncio.run(main(url))
```

## Testing your task

1. Create a virtual environment `python -m venv venv`
2. Activate the virtual environment, depending on your OS: On Mac/Linux: `source venv/bin/activate`, on Windows: `venv\Scripts\activate`
3. Install the Python dependencies `pip install -r requirements.txt`
4. If you haven't already, copy your project ref from your [Trigger.dev dashboard](https://cloud.trigger.dev) and add it to the `trigger.config.ts` file.
5. Run the Trigger.dev CLI `dev` command (it may ask you to authorize the CLI if you haven't already).
6. Test the task in the dashboard, using a URL of your choice.

<Warning>
  **WEB SCRAPING:** When web scraping, you MUST use a proxy to comply with our terms of service. Direct scraping of third-party websites without the site owner's permission using Trigger.dev Cloud is prohibited and will result in account suspension. See [this example](/guides/examples/puppeteer#scrape-content-from-a-web-page) which uses a proxy.
</Warning>

## Deploying your task

Deploy the task to production using the Trigger.dev CLI `deploy` command.

## Learn more about using Python with Trigger.dev

<Card title="Python build extension" icon="code" href="/config/extensions/pythonExtension">
  Learn how to use our built-in Python build extension to install dependencies and run your Python
  code.
</Card>


# Convert documents to markdown using Python and MarkItDown
Source: https://trigger.dev/docs/guides/python/python-doc-to-markdown

Learn how to use Trigger.dev with Python to convert documents to markdown using MarkItDown.

## Overview

Convert documents to markdown using Microsoft's [MarkItDown](https://github.com/microsoft/markitdown) library. This can be especially useful for preparing documents in a structured format for AI applications.

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Python](https://www.python.org/) installed on your local machine. *This example requires Python 3.10 or higher.*

## Features

* A Trigger.dev task which downloads a document from a URL and runs the Python script which converts it to markdown
* A Python script to convert documents to markdown using Microsoft's [MarkItDown](https://github.com/microsoft/markitdown) library
* Uses our [Python build extension](/config/extensions/pythonExtension) to install dependencies and run Python scripts

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/python-doc-to-markdown-converter">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## The code

### Build configuration

After you've initialized your project with Trigger.dev, add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { pythonExtension } from "@trigger.dev/python/extension";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  runtime: "node",
  project: "<your-project-ref>",
  // Your other config settings...
  build: {
    extensions: [
      pythonExtension({
        // The path to your requirements.txt file
        requirementsFile: "./requirements.txt",
        // The path to your Python binary
        devPythonBinaryPath: `venv/bin/python`,
        // The paths to your Python scripts to run
        scripts: ["src/python/**/*.py"],
      }),
    ],
  },
});
```

<Info>
  Learn more about executing scripts in your Trigger.dev project using our Python build extension
  [here](/config/extensions/pythonExtension).
</Info>

### Task code

This task uses the `python.runScript` method to run the `markdown-converter.py` script with the given document URL as an argument.

```ts src/trigger/convertToMarkdown.ts theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";
import * as fs from "fs";
import * as path from "path";
import * as os from "os";

export const convertToMarkdown = task({
  id: "convert-to-markdown",
  run: async (payload: { url: string }) => {
    const { url } = payload;

    // STEP 1: Create temporary file with unique name
    const tempDir = os.tmpdir();
    const fileName = `doc-${Date.now()}-${Math.random().toString(36).substring(2, 7)}`;
    const urlPath = new URL(url).pathname;
    const extension = path.extname(urlPath) || ".docx";
    const tempFilePath = path.join(tempDir, `${fileName}${extension}`);

    // STEP 2: Download file from URL
    const response = await fetch(url);
    const buffer = await response.arrayBuffer();
    await fs.promises.writeFile(tempFilePath, Buffer.from(buffer));

    // STEP 3: Run Python script to convert document to markdown
    const pythonResult = await python.runScript("./src/python/markdown-converter.py", [
      JSON.stringify({ file_path: tempFilePath }),
    ]);

    // STEP 4: Clean up temporary file
    fs.unlink(tempFilePath, () => {});

    // STEP 5: Process result
    if (pythonResult.stdout) {
      const result = JSON.parse(pythonResult.stdout);
      return {
        url,
        markdown: result.status === "success" ? result.markdown : null,
        error: result.status === "error" ? result.error : null,
        success: result.status === "success",
      };
    }

    return {
      url,
      markdown: null,
      error: "No output from Python script",
      success: false,
    };
  },
});
```

### Add a requirements.txt file

Add the following to your `requirements.txt` file. This is required in Python projects to install the dependencies.

```txt requirements.txt theme={null}
markitdown[all]
```

### The Python script

The Python script uses MarkItDown to convert documents to Markdown format.

```python src/python/markdown-converter.py theme={null}
import json
import sys
import os
from markitdown import MarkItDown

def convert_to_markdown(file_path):
    """Convert a file to markdown format using MarkItDown"""
    # Check if file exists
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    # Initialize MarkItDown
    md = MarkItDown()

    # Convert the file
    try:
        result = md.convert(file_path)
        return result.text_content
    except Exception as e:
        raise Exception(f"Error converting file: {str(e)}")

def process_trigger_task(file_path):
    """Process a file and convert to markdown"""
    try:
        markdown_result = convert_to_markdown(file_path)
        return {
            "status": "success",
            "markdown": markdown_result
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

if __name__ == "__main__":
    # Get the file path from command line arguments
    if len(sys.argv) < 2:
        print(json.dumps({"status": "error", "error": "No file path provided"}))
        sys.exit(1)

    try:
        config = json.loads(sys.argv[1])
        file_path = config.get("file_path")

        if not file_path:
            print(json.dumps({"status": "error", "error": "No file path specified in config"}))
            sys.exit(1)

        result = process_trigger_task(file_path)
        print(json.dumps(result))
    except Exception as e:
        print(json.dumps({"status": "error", "error": str(e)}))
        sys.exit(1)
```

## Testing your task

1. Create a virtual environment `python -m venv venv`
2. Activate the virtual environment, depending on your OS: On Mac/Linux: `source venv/bin/activate`, on Windows: `venv\Scripts\activate`
3. Install the Python dependencies `pip install -r requirements.txt`. *Make sure you have Python 3.10 or higher installed.*
4. Copy the project ref from your [Trigger.dev dashboard](https://cloud.trigger.dev) and add it to the `trigger.config.ts` file.
5. Run the Trigger.dev CLI `dev` command (it may ask you to authorize the CLI if you haven't already).
6. Test the task in the dashboard by providing a valid document URL.
7. Deploy the task to production using the Trigger.dev CLI `deploy` command.

## MarkItDown Conversion Capabilities

* Convert various file formats to Markdown:
  * Office formats (Word, PowerPoint, Excel)
  * PDFs
  * Images (with optional LLM-generated descriptions)
  * HTML, CSV, JSON, XML
  * Audio files (with optional transcription)
  * ZIP archives
  * And more
* Preserve document structure (headings, lists, tables, etc.)
* Handle multiple input methods (file paths, URLs, base64 data)
* Optional Azure Document Intelligence integration for better PDF and image conversion

## Learn more about using Python with Trigger.dev

<Card title="Python build extension" icon="code" href="/config/extensions/pythonExtension">
  Learn how to use our built-in Python build extension to install dependencies and run your Python
  code.
</Card>


# Python image processing example
Source: https://trigger.dev/docs/guides/python/python-image-processing

Learn how to use Trigger.dev with Python to process images from URLs and upload them to S3.

## Overview

This demo showcases how to use Trigger.dev with Python to process an image using Pillow (PIL) from a URL and upload it to S3-compatible storage bucket.

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Python](https://www.python.org/) installed on your local machine

## Features

* A [Trigger.dev](https://trigger.dev) task to trigger the image processing Python script, and then upload the processed image to S3-compatible storage
* The [Trigger.dev Python build extension](https://trigger.dev/docs/config/extensions/pythonExtension) to install dependencies and run Python scripts
* [Pillow (PIL)](https://pillow.readthedocs.io/) for powerful image processing capabilities
* [AWS SDK v3](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/client/s3/) for S3 uploads
* S3-compatible storage support (AWS S3, Cloudflare R2, etc.)

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/tree/main/python-image-processing">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## The code

### Build configuration

After you've initialized your project with Trigger.dev, add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { pythonExtension } from "@trigger.dev/python/extension";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  runtime: "node",
  project: "<your-project-ref>",
  // Your other config settings...
  build: {
    extensions: [
      pythonExtension({
        // The path to your requirements.txt file
        requirementsFile: "./requirements.txt",
        // The path to your Python binary
        devPythonBinaryPath: `venv/bin/python`,
        // The paths to your Python scripts to run
        scripts: ["src/python/**/*.py"],
      }),
    ],
  },
});
```

<Info>
  Learn more about executing scripts in your Trigger.dev project using our Python build extension
  [here](/config/extensions/pythonExtension).
</Info>

### Task code

This task uses the `python.runScript` method to run the `image-processing.py` script with the given image URL as an argument. You can adjust the image processing parameters in the payload, with options such as height, width, quality, output format, etc.

```ts src/trigger/processImage.ts theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";
import { python } from "@trigger.dev/python";
import { promises as fs } from "fs";
import { S3Client } from "@aws-sdk/client-s3";
import { Upload } from "@aws-sdk/lib-storage";

// Initialize S3 client
const s3Client = new S3Client({
  region: "auto",
  endpoint: process.env.S3_ENDPOINT,
  credentials: {
    accessKeyId: process.env.S3_ACCESS_KEY_ID ?? "",
    secretAccessKey: process.env.S3_SECRET_ACCESS_KEY ?? "",
  },
});

// Define the input schema with Zod
const imageProcessingSchema = z.object({
  imageUrl: z.string().url(),
  height: z.number().positive().optional().default(800),
  width: z.number().positive().optional().default(600),
  quality: z.number().min(1).max(100).optional().default(85),
  maintainAspectRatio: z.boolean().optional().default(true),
  outputFormat: z.enum(["jpeg", "png", "webp", "gif", "avif"]).optional().default("jpeg"),
  brightness: z.number().optional(),
  contrast: z.number().optional(),
  sharpness: z.number().optional(),
  grayscale: z.boolean().optional().default(false),
});

// Define the output schema
const outputSchema = z.object({
  url: z.string().url(),
  key: z.string(),
  format: z.string(),
  originalSize: z.object({
    width: z.number(),
    height: z.number(),
  }),
  newSize: z.object({
    width: z.number(),
    height: z.number(),
  }),
  fileSizeBytes: z.number(),
  exitCode: z.number(),
});

export const processImage = schemaTask({
  id: "process-image",
  schema: imageProcessingSchema,
  run: async (payload, io) => {
    const {
      imageUrl,
      height,
      width,
      quality,
      maintainAspectRatio,
      outputFormat,
      brightness,
      contrast,
      sharpness,
      grayscale,
    } = payload;

    try {
      // Run the Python script
      const result = await python.runScript("./src/python/image-processing.py", [
        imageUrl,
        height.toString(),
        width.toString(),
        quality.toString(),
        maintainAspectRatio.toString(),
        outputFormat,
        brightness?.toString() || "null",
        contrast?.toString() || "null",
        sharpness?.toString() || "null",
        grayscale.toString(),
      ]);

      const { outputPath, format, originalSize, newSize, fileSizeBytes } = JSON.parse(
        result.stdout
      );

      // Read file once
      const fileContent = await fs.readFile(outputPath);

      try {
        // Upload to S3
        const key = `processed-images/${Date.now()}-${outputPath.split("/").pop()}`;
        await new Upload({
          client: s3Client,
          params: {
            Bucket: process.env.S3_BUCKET!,
            Key: key,
            Body: fileContent,
            ContentType: `image/${format}`,
          },
        }).done();

        return {
          url: `${process.env.S3_PUBLIC_URL}/${key}`,
          key,
          format,
          originalSize,
          newSize,
          fileSizeBytes,
          exitCode: result.exitCode,
        };
      } finally {
        // Always clean up the temp file
        await fs.unlink(outputPath).catch(console.error);
      }
    } catch (error) {
      throw new Error(
        `Processing failed: ${error instanceof Error ? error.message : "Unknown error"}`
      );
    }
  },
});
```

### Add a requirements.txt file

Add the following to your `requirements.txt` file. This is required in Python projects to install the dependencies.

```txt requirements.txt theme={null}
# Core dependencies
Pillow==10.2.0            # Image processing library
python-dotenv==1.0.0      # Environment variable management
requests==2.31.0          # HTTP requests
numpy==1.26.3             # Numerical operations (for advanced processing)

# Optional enhancements
opencv-python==4.8.1.78   # For more advanced image processing
```

### The Python script

The Python script uses Pillow (PIL) to process an image. You can see the original script in our examples repository [here](https://github.com/triggerdotdev/examples/blob/main/python-image-processing/src/python/image-processing.py).

```python src/python/image-processing.py theme={null}
from PIL import Image, ImageOps, ImageEnhance
import io
from io import BytesIO
import os
from typing import Tuple, List, Dict, Optional, Union
import logging
import sys
import json
import requests

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ImageProcessor:
    """Image processing utility for resizing, optimizing, and converting images."""

    # Supported formats for conversion
    SUPPORTED_FORMATS = ['JPEG', 'PNG', 'WEBP', 'GIF', 'AVIF']

    @staticmethod
    def open_image(image_data: Union[bytes, str]) -> Image.Image:
        """Open an image from bytes or file path."""
        try:
            if isinstance(image_data, bytes):
                return Image.open(io.BytesIO(image_data))
            else:
                return Image.open(image_data)
        except Exception as e:
            logger.error(f"Failed to open image: {e}")
            raise ValueError(f"Could not open image: {e}")

    @staticmethod
    def resize_image(
        img: Image.Image,
        width: Optional[int] = None,
        height: Optional[int] = None,
        maintain_aspect_ratio: bool = True
    ) -> Image.Image:
        """
        Resize an image to specified dimensions.

        Args:
            img: PIL Image object
            width: Target width (None to auto-calculate from height)
            height: Target height (None to auto-calculate from width)
            maintain_aspect_ratio: Whether to maintain the original aspect ratio

        Returns:
            Resized PIL Image
        """
        if width is None and height is None:
            return img  # No resize needed

        original_width, original_height = img.size

        if maintain_aspect_ratio:
            if width and height:
                # Calculate the best fit while maintaining aspect ratio
                ratio = min(width / original_width, height / original_height)
                new_width = int(original_width * ratio)
                new_height = int(original_height * ratio)
            elif width:
                # Calculate height based on width
                ratio = width / original_width
                new_width = width
                new_height = int(original_height * ratio)
            else:
                # Calculate width based on height
                ratio = height / original_height
                new_width = int(original_width * ratio)
                new_height = height
        else:
            # Force exact dimensions
            new_width = width if width else original_width
            new_height = height if height else original_height

        return img.resize((new_width, new_height), Image.LANCZOS)

    @staticmethod
    def optimize_image(
        img: Image.Image,
        quality: int = 85,
        format: Optional[str] = None
    ) -> Tuple[bytes, str]:
        """
        Optimize an image for web delivery.

        Args:
            img: PIL Image object
            quality: JPEG/WebP quality (0-100)
            format: Output format (JPEG, PNG, WEBP, etc.)

        Returns:
            Tuple of (image_bytes, format)
        """
        if format is None:
            format = img.format or 'JPEG'

        format = format.upper()
        if format not in ImageProcessor.SUPPORTED_FORMATS:
            format = 'JPEG'  # Default to JPEG if unsupported format

        # Convert mode if needed
        if format == 'JPEG' and img.mode in ('RGBA', 'P'):
            img = img.convert('RGB')

        # Save to bytes
        buffer = io.BytesIO()

        if format == 'JPEG':
            img.save(buffer, format=format, quality=quality, optimize=True)
        elif format == 'PNG':
            img.save(buffer, format=format, optimize=True)
        elif format == 'WEBP':
            img.save(buffer, format=format, quality=quality)
        elif format == 'AVIF':
            img.save(buffer, format=format, quality=quality)
        else:
            img.save(buffer, format=format)

        buffer.seek(0)
        return buffer.getvalue(), format.lower()

    @staticmethod
    def apply_filters(
        img: Image.Image,
        brightness: Optional[float] = None,
        contrast: Optional[float] = None,
        sharpness: Optional[float] = None,
        grayscale: bool = False
    ) -> Image.Image:
        """
        Apply various filters and enhancements to an image.

        Args:
            img: PIL Image object
            brightness: Brightness factor (0.0-2.0, 1.0 is original)
            contrast: Contrast factor (0.0-2.0, 1.0 is original)
            sharpness: Sharpness factor (0.0-2.0, 1.0 is original)
            grayscale: Convert to grayscale if True

        Returns:
            Processed PIL Image
        """
        # Apply grayscale first if requested
        if grayscale:
            img = ImageOps.grayscale(img)
            # Convert back to RGB if other filters will be applied
            if any(x is not None for x in [brightness, contrast, sharpness]):
                img = img.convert('RGB')

        # Apply enhancements
        if brightness is not None:
            img = ImageEnhance.Brightness(img).enhance(brightness)

        if contrast is not None:
            img = ImageEnhance.Contrast(img).enhance(contrast)

        if sharpness is not None:
            img = ImageEnhance.Sharpness(img).enhance(sharpness)

        return img

    @staticmethod
    def process_image(
        image_data: Union[bytes, str],
        width: Optional[int] = None,
        height: Optional[int] = None,
        maintain_aspect_ratio: bool = True,
        quality: int = 85,
        output_format: Optional[str] = None,
        brightness: Optional[float] = None,
        contrast: Optional[float] = None,
        sharpness: Optional[float] = None,
        grayscale: bool = False
    ) -> Dict:
        """
        Process an image with all available options.

        Args:
            image_data: Image bytes or file path
            width: Target width
            height: Target height
            maintain_aspect_ratio: Whether to maintain aspect ratio
            quality: Output quality
            output_format: Output format
            brightness: Brightness adjustment
            contrast: Contrast adjustment
            sharpness: Sharpness adjustment
            grayscale: Convert to grayscale

        Returns:
            Dict with processed image data and metadata
        """
        # Open the image
        img = ImageProcessor.open_image(image_data)
        original_format = img.format
        original_size = img.size

        # Apply filters
        img = ImageProcessor.apply_filters(
            img,
            brightness=brightness,
            contrast=contrast,
            sharpness=sharpness,
            grayscale=grayscale
        )

        # Resize if needed
        if width or height:
            img = ImageProcessor.resize_image(
                img,
                width=width,
                height=height,
                maintain_aspect_ratio=maintain_aspect_ratio
            )

        # Optimize and get bytes
        processed_bytes, actual_format = ImageProcessor.optimize_image(
            img,
            quality=quality,
            format=output_format
        )

        # Return result with metadata
        return {
            "processed_image": processed_bytes,
            "format": actual_format,
            "original_format": original_format,
            "original_size": original_size,
            "new_size": img.size,
            "file_size_bytes": len(processed_bytes)
        }

def process_image(url, height, width, quality):
    # Download image from URL
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))

    # Resize
    img = img.resize((int(width), int(height)), Image.Resampling.LANCZOS)

    # Save with quality setting
    output_path = f"/tmp/processed_{width}x{height}.jpg"
    img.save(output_path, "JPEG", quality=int(quality))

    return output_path

if __name__ == "__main__":
    url = sys.argv[1]
    height = int(sys.argv[2])
    width = int(sys.argv[3])
    quality = int(sys.argv[4])
    maintain_aspect_ratio = sys.argv[5].lower() == 'true'
    output_format = sys.argv[6]
    brightness = float(sys.argv[7]) if sys.argv[7] != 'null' else None
    contrast = float(sys.argv[8]) if sys.argv[8] != 'null' else None
    sharpness = float(sys.argv[9]) if sys.argv[9] != 'null' else None
    grayscale = sys.argv[10].lower() == 'true'

    processor = ImageProcessor()
    result = processor.process_image(
        requests.get(url).content,
        width=width,
        height=height,
        maintain_aspect_ratio=maintain_aspect_ratio,
        quality=quality,
        output_format=output_format,
        brightness=brightness,
        contrast=contrast,
        sharpness=sharpness,
        grayscale=grayscale
    )

    output_path = f"/tmp/processed_{width}x{height}.{result['format']}"
    with open(output_path, 'wb') as f:
        f.write(result['processed_image'])

    print(json.dumps({
        "outputPath": output_path,
        "format": result['format'],
        "originalSize": result['original_size'],
        "newSize": result['new_size'],
        "fileSizeBytes": result['file_size_bytes']
    }))
```

## Testing your task

1. Create a virtual environment `python -m venv venv`
2. Activate the virtual environment, depending on your OS: On Mac/Linux: `source venv/bin/activate`, on Windows: `venv\Scripts\activate`
3. Install the Python dependencies `pip install -r requirements.txt`
4. Set up your S3-compatible storage credentials in your environment variables, in .env for local development, or in the Trigger.dev dashboard for production:
   ```
   S3_ENDPOINT=https://your-endpoint.com
   S3_ACCESS_KEY_ID=your-access-key
   S3_SECRET_ACCESS_KEY=your-secret-key
   S3_BUCKET=your-bucket-name
   S3_PUBLIC_URL=https://your-public-url.com
   ```
5. Copy the project ref from your [Trigger.dev dashboard](https://cloud.trigger.dev) and add it to the `trigger.config.ts` file.
6. Run the Trigger.dev CLI `dev` command (it may ask you to authorize the CLI if you haven't already).
7. Test the task in the dashboard by providing a valid image URL and processing options.
8. Deploy the task to production using the Trigger.dev CLI `deploy` command.

## Example Payload

These are all optional parameters that can be passed to the `image-processing.py` Python script from the `processImage.ts` task.

```json  theme={null}
{
  "imageUrl": "<your-image-url>",
  "height": 1200,
  "width": 900,
  "quality": 90,
  "maintainAspectRatio": true,
  "outputFormat": "webp",
  "brightness": 1.2,
  "contrast": 1.1,
  "sharpness": 1.3,
  "grayscale": false
}
```

## Deploying your task

Deploy the task to production using the CLI command `npx trigger.dev@latest deploy`

## Learn more about using Python with Trigger.dev

<Card title="Python build extension" icon="code" href="/config/extensions/pythonExtension">
  Learn how to use our built-in Python build extension to install dependencies and run your Python
  code.
</Card>


# Python PDF form extractor example
Source: https://trigger.dev/docs/guides/python/python-pdf-form-extractor

Learn how to use Trigger.dev with Python to extract form data from PDF files.

## Overview

This demo showcases how to use Trigger.dev with Python to extract structured form data from a PDF file available at a URL.

## Prerequisites

* A project with [Trigger.dev initialized](/quick-start)
* [Python](https://www.python.org/) installed on your local machine

## Features

* A [Trigger.dev](https://trigger.dev) task to trigger the Python script
* [Trigger.dev Python build extension](https://trigger.dev/docs/config/extensions/pythonExtension) to install the dependencies and run the Python script
* [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/) to extract form data from PDF files
* [Requests](https://docs.python-requests.org/en/master/) to download PDF files from URLs

## GitHub repo

<Card title="View the project on GitHub" icon="GitHub" href="https://github.com/triggerdotdev/examples/edit/main/python-pdf-form-extractor/">
  Click here to view the full code for this project in our examples repository on GitHub. You can
  fork it and use it as a starting point for your own project.
</Card>

## The code

### Build configuration

After you've initialized your project with Trigger.dev, add these build settings to your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { pythonExtension } from "@trigger.dev/python/extension";
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  runtime: "node",
  project: "<your-project-ref>",
  // Your other config settings...
  build: {
    extensions: [
      pythonExtension({
        // The path to your requirements.txt file
        requirementsFile: "./requirements.txt",
        // The path to your Python binary
        devPythonBinaryPath: `venv/bin/python`,
        // The paths to your Python scripts to run
        scripts: ["src/python/**/*.py"],
      }),
    ],
  },
});
```

<Info>
  Learn more about executing scripts in your Trigger.dev project using our Python build extension
  [here](/config/extensions/pythonExtension).
</Info>

### Task code

This task uses the `python.runScript` method to run the `image-processing.py` script with the given image URL as an argument. You can adjust the image processing parameters in the payload, with options such as height, width, quality, output format, etc.

```ts src/trigger/pythonPdfTask.ts theme={null}
import { task } from "@trigger.dev/sdk";
import { python } from "@trigger.dev/python";

export const processPdfForm = task({
  id: "process-pdf-form",
  run: async (payload: { pdfUrl: string }, io: any) => {
    const { pdfUrl } = payload;
    const args = [pdfUrl];

    const result = await python.runScript("./src/python/extract-pdf-form.py", args);

    // Parse the JSON output from the script
    let formData;
    try {
      formData = JSON.parse(result.stdout);
    } catch (error) {
      throw new Error(`Failed to parse JSON output: ${result.stdout}`);
    }

    return {
      formData,
      stderr: result.stderr,
      exitCode: result.exitCode,
    };
  },
});
```

### Add a requirements.txt file

Add the following to your `requirements.txt` file. This is required in Python projects to install the dependencies.

```txt requirements.txt theme={null}
PyMuPDF==1.23.8
requests==2.31.0
```

### The Python script

The Python script uses PyMuPDF to extract form data from a PDF file. You can see the original script in our examples repository [here](https://github.com/triggerdotdev/examples/blob/main/python-pdf-form-extractor/src/python/extract-pdf-form.py).

```python src/python/extract-pdf-form.py theme={null}
import fitz  # PyMuPDF
import requests
import os
import json
import sys
from urllib.parse import urlparse

def download_pdf(url):
    """Download PDF from URL to a temporary file"""
    response = requests.get(url)
    response.raise_for_status()

    # Get filename from URL or use default
    filename = os.path.basename(urlparse(url).path) or "downloaded.pdf"
    filepath = os.path.join("/tmp", filename)

    with open(filepath, 'wb') as f:
        f.write(response.content)
    return filepath

def extract_form_data(pdf_path):
    """Extract form data from a PDF file."""
    doc = fitz.open(pdf_path)
    form_data = {}

    for page_num, page in enumerate(doc):
        fields = page.widgets()
        for field in fields:
            field_name = field.field_name or f"unnamed_field_{page_num}_{len(form_data)}"
            field_type = field.field_type_string
            field_value = field.field_value

            # For checkboxes, convert to boolean
            if field_type == "CheckBox":
                field_value = field_value == "Yes"

            form_data[field_name] = {
                "type": field_type,
                "value": field_value,
                "page": page_num + 1
            }

    return form_data

def main():
    if len(sys.argv) < 2:
        print(json.dumps({"error": "PDF URL is required as an argument"}), file=sys.stderr)
        return 1

    url = sys.argv[1]

    try:
        pdf_path = download_pdf(url)
        form_data = extract_form_data(pdf_path)

        # Convert to JSON for structured output
        structured_output = json.dumps(form_data, indent=2)
        print(structured_output)
        return 0
    except Exception as e:
        print(json.dumps({"error": str(e)}), file=sys.stderr)
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

## Testing your task

1. Create a virtual environment `python -m venv venv`
2. Activate the virtual environment, depending on your OS: On Mac/Linux: `source venv/bin/activate`, on Windows: `venv\Scripts\activate`
3. Install the Python dependencies `pip install -r requirements.txt`
4. Copy the project ref from your [Trigger.dev dashboard](https://cloud.trigger.dev) and add it to the `trigger.config.ts` file.
5. Run the Trigger.dev CLI `dev` command (it may ask you to authorize the CLI if you haven't already).
6. Test the task in the dashboard by providing a valid PDF URL.
7. Deploy the task to production using the Trigger.dev CLI `deploy` command.

## Learn more about using Python with Trigger.dev

<Card title="Python build extension" icon="code" href="/config/extensions/pythonExtension">
  Learn how to use our built-in Python build extension to install dependencies and run your Python
  code.
</Card>


# Data processing & ETL workflows
Source: https://trigger.dev/docs/guides/use-cases/data-processing-etl

Learn how to use Trigger.dev for data processing and ETL (Extract, Transform, Load), including web scraping, database synchronization, batch enrichment and more.

## Overview

Build complex data pipelines that process large datasets without timeouts. Handle streaming analytics, batch enrichment, web scraping, database sync, and file processing with automatic retries and progress tracking.

## Featured examples

<CardGroup cols={3}>
  <Card title="Realtime CSV importer" icon="book" href="/guides/example-projects/realtime-csv-importer">
    Import CSV files with progress streamed live to frontend.
  </Card>

  <Card title="Web scraper with BrowserBase" icon="book" href="/guides/examples/scrape-hacker-news">
    Scrape websites using BrowserBase and Puppeteer.
  </Card>

  <Card title="Supabase database webhooks" icon="book" href="/guides/frameworks/supabase-edge-functions-database-webhooks">
    Trigger tasks from Supabase database webhooks.
  </Card>
</CardGroup>

## Benefits of using Trigger.dev for data processing & ETL workflows

**Process datasets for hours without timeouts:** Handle multi-hour transformations, large file processing, or complete database exports. No execution time limits.

**Parallel processing with built-in rate limiting:** Process thousands of records simultaneously while respecting API rate limits. Scale efficiently without overwhelming downstream services.

**Stream progress to your users in real-time:** Show row-by-row processing status updating live in your dashboard. Users see exactly where processing is and how long remains.

## Production use cases

<CardGroup cols={1}>
  <Card title="MagicSchool AI customer story" href="https://trigger.dev/customers/magicschool-ai-customer-story">
    Read how MagicSchool AI uses Trigger.dev to generate insights from millions of student interactions.
  </Card>

  <Card title="Comp AI customer story" href="https://trigger.dev/customers/comp-ai-customer-story">
    Read how Comp AI uses Trigger.dev to automate evidence collection at scale, powering their open source, AI-driven compliance platform.
  </Card>

  <Card title="Midday customer story" href="https://trigger.dev/customers/midday-customer-story">
    Read how Midday use Trigger.dev to sync large volumes of bank transactions in their financial management platform.
  </Card>
</CardGroup>

## Example workflow patterns

<Tabs>
  <Tab title="CSV file import">
    Simple CSV import pipeline. Receives file upload, parses CSV rows, validates data, imports to database with progress tracking.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[importCSV] --> B[parseCSVFile]
          B --> C[validateRows]
          C --> D[bulkInsertToDB]
          D --> E[notifyCompletion]
      ```
    </div>
  </Tab>

  <Tab title="Multi-source ETL pipeline">
    **Coordinator pattern with parallel extraction**. Batch triggers parallel extraction from multiple sources (APIs, databases, S3), transforms and validates data, loads to data warehouse with monitoring.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[runETLPipeline] --> B[coordinateExtraction]
          B --> C[batchTriggerAndWait]

          C --> D[extractFromAPI]
          C --> E[extractFromDatabase]
          C --> F[extractFromS3]

          D --> G[transformData]
          E --> G
          F --> G

          G --> H[validateData]
          H --> I[loadToWarehouse]
      ```
    </div>
  </Tab>

  <Tab title="Parallel web scraping">
    **Coordinator pattern with browser automation**. Launches headless browsers in parallel to scrape multiple pages, extracts structured data, cleans and normalizes content, stores in database.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[scrapeSite] --> B[coordinateScraping]
          B --> C[batchTriggerAndWait]

          C --> D[scrapePage1]
          C --> E[scrapePage2]
          C --> F[scrapePageN]

          D --> G[cleanData]
          E --> G
          F --> G

          G --> H[normalizeData]
          H --> I[storeInDatabase]
      ```
    </div>
  </Tab>

  <Tab title="Batch data enrichment">
    **Coordinator pattern with rate limiting**. Fetches records needing enrichment, batch triggers parallel API calls with configurable concurrency to respect rate limits, validates enriched data, updates database.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[enrichRecords] --> B[fetchRecordsToEnrich]
          B --> C[coordinateEnrichment]
          C --> D[batchTriggerAndWait]

          D --> E[enrichRecord1]
          D --> F[enrichRecord2]
          D --> G[enrichRecordN]

          E --> H[validateEnrichedData]
          F --> H
          G --> H

          H --> I[updateDatabase]
      ```
    </div>
  </Tab>
</Tabs>

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>


# Marketing workflows
Source: https://trigger.dev/docs/guides/use-cases/marketing

Learn how to use Trigger.dev for marketing workflows, including drip campaigns, behavioral triggers, personalization engines, and AI-powered content workflows

## Overview

Build marketing workflows from email drip sequences to orchestrating full multi-channel campaigns. Handle multi-day sequences, behavioral triggers, dynamic content generation, and build live analytics dashboards.

## Featured examples

<CardGroup cols={3}>
  <Card title="Email sequences with Resend" icon="book" href="/guides/examples/resend-email-sequence">
    Send multi-day email sequences with wait delays between messages.
  </Card>

  <Card title="Product image generator" icon="book" href="/guides/example-projects/product-image-generator">
    Transform product photos into professional marketing images using Replicate.
  </Card>

  <Card title="Human-in-the-loop workflow" icon="book" href="/guides/example-projects/human-in-the-loop-workflow">
    Approve marketing content using a human-in-the-loop workflow.
  </Card>
</CardGroup>

## Benefits of using Trigger.dev for marketing workflows

**Delays without idle costs:** Wait hours or weeks between steps. Waits over 5 seconds are automatically checkpointed and don't count towards compute usage. Perfect for drip campaigns and scheduled follow-ups.

**Guaranteed delivery:** Messages send exactly once, even after retries. Personalized content isn't regenerated on failure.

**Scale without limits:** Process thousands in parallel while respecting rate limits. Send to entire segments without overwhelming APIs.

## Production use cases

<Card title="Icon customer story" href="https://trigger.dev/customers/icon-customer-story">
  Read how Icon uses Trigger.dev to process and generate thousands of videos per month for their AI-driven video creation platform.
</Card>

## Example workflow patterns

<Tabs>
  <Tab title="Drip email campaign">
    Simple drip campaign. User signs up, waits specified delay, sends personalized email, tracks engagement.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[userCreateAccount] --> B[sendWelcomeEmail]
          B --> C[wait.for 24h]
          C --> D[sendProductTipsEmail]
          D --> E[wait.for 7d]
          E --> F[sendFeedbackEmail]

      ```
    </div>
  </Tab>

  <Tab title="Multi-channel campaigns">
    **Router pattern with delay orchestration**. User action triggers campaign, router selects channel based on preferences (email/SMS/push), coordinates multi-day sequence with delays between messages, tracks engagement across channels.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[startCampaign] --> B[fetchUserProfile]
          B --> C[selectChannel]
          C --> D{Preferred<br/>Channel?}

          D -->|Email| E[sendEmail1]
          D -->|SMS| F[sendSMS1]
          D -->|Push| G[sendPush1]

          E --> H[wait.for 2d]
          F --> H
          G --> H

          H --> I[sendFollowUp]
          I --> J[trackConversion]
      ```
    </div>
  </Tab>

  <Tab title="AI content with approval">
    **Supervisor pattern with approval gate**. Generates AI marketing content (images, copy, assets), pauses with wait.forToken for human review, applies revisions if needed, publishes to channels after approval.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[createCampaignAssets] --> B[generateAIContent]
          B --> C[wait.forToken approval]
          C --> D{Approved?}

          D -->|Yes| E[publishToChannels]
          D -->|Needs revision| F[applyFeedback]
          F --> B
      ```
    </div>
  </Tab>

  <Tab title="Survey response enrichment">
    **Coordinator pattern with enrichment**. User completes survey, batch triggers parallel enrichment from CRM/analytics, analyzes and scores responses, updates customer profiles, triggers personalized follow-up campaigns.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processSurveyResponse] --> B[coordinateEnrichment]
          B --> C[batchTriggerAndWait]

          C --> D[fetchCRMData]
          C --> E[fetchAnalytics]
          C --> F[fetchBehaviorData]

          D --> G[analyzeAndScore]
          E --> G
          F --> G

          G --> H[updateCRMProfile]
          H --> I[triggerFollowUp]
      ```
    </div>
  </Tab>
</Tabs>

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>


# AI media generation workflows
Source: https://trigger.dev/docs/guides/use-cases/media-generation

Learn how to use Trigger.dev for AI media generation including image creation, video synthesis, audio generation, and multi-modal content workflows

## Overview

Build AI media generation pipelines that handle unpredictable API latencies and long-running operations. Generate images, videos, audio, and multi-modal content with automatic retries, progress tracking, and no timeout limits.

## Featured examples

<CardGroup cols={3}>
  <Card title="Product image generator" icon="book" href="/guides/example-projects/product-image-generator">
    Transform product photos into professional marketing images using Replicate.
  </Card>

  <Card title="Meme generator (human-in-the-loop)" icon="book" href="/guides/example-projects/meme-generator-human-in-the-loop">
    Generate memes with DALLÂ·E 3 and add human approval steps.
  </Card>

  <Card title="Vercel AI SDK image generation" icon="book" href="/guides/example-projects/vercel-ai-sdk-image-generator">
    Generate images from text prompts using the Vercel AI SDK.
  </Card>
</CardGroup>

## Benefits of using Trigger.dev for AI media generation workflows

**Pay only for active compute, not AI inference time:** Checkpoint-resume pauses during AI API calls. Generate content that takes minutes or hours without paying for idle inference time.

**No timeout limits for long generations:** Handle generations that take minutes or hours without execution limits. Perfect for high-quality video synthesis and complex multi-modal workflows.

**Human approval gates for brand safety:** Add review steps before publishing AI-generated content. Pause workflows for human approval using waitpoint tokens.

## Production use cases

<CardGroup cols={1}>
  <Card title="Icon customer story" href="https://trigger.dev/customers/icon-customer-story">
    Read how Icon uses Trigger.dev to process and generate thousands of videos per month for their AI-driven video creation platform.
  </Card>

  <Card title="Papermark customer story" href="https://trigger.dev/customers/papermark-customer-story">
    Read how Papermark process thousands of documents per month using Trigger.dev.
  </Card>
</CardGroup>

## Example workflow patterns

<Tabs>
  <Tab title="AI content with approval">
    **Supervisor pattern with approval gate**. Generates AI content, pauses execution with wait.forToken to allow human review, applies feedback if needed, publishes approved content.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[generateContent] --> B[createWithAI]
          B --> C[wait.forToken approval]
          C --> D{Approved?}

          D -->|Yes| E[publishContent]
          D -->|Needs revision| F[applyFeedback]
          F --> B
      ```
    </div>
  </Tab>

  <Tab title="AI image generation">
    Simple AI image generation. Receives prompt and parameters, calls OpenAI DALLÂ·E 3, post-processes result, uploads to storage.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[generateImage] --> B[optimizeImage]
          B --> C[uploadToStorage]
          C --> D[updateDatabase]
      ```
    </div>
  </Tab>

  <Tab title="Batch image generation">
    **Coordinator pattern with rate limiting**. Receives batch of generation requests, coordinates parallel processing with configurable concurrency to respect API rate limits, validates outputs, stores results.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processBatch] --> B[coordinateGeneration]
          B --> C[batchTriggerAndWait]

          C --> D[generateImage1]
          C --> E[generateImage2]
          C --> F[generateImageN]

          D --> G[validateResults]
          E --> G
          F --> G

          G --> H[storeResults]
          H --> I[notifyCompletion]
      ```
    </div>
  </Tab>

  <Tab title="Multi-step image enhancement">
    **Coordinator pattern with sequential processing**. Generates initial content with AI, applies style transfer or enhancement, upscales resolution, optimizes and compresses for delivery.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processCreative] --> B[generateWithAI]
          B --> C[applyStyleTransfer]
          C --> D[upscaleResolution]
          D --> E[optimizeAndCompress]
          E --> F[uploadToStorage]
      ```
    </div>
  </Tab>
</Tabs>

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>


# Media processing workflows
Source: https://trigger.dev/docs/guides/use-cases/media-processing

Learn how to use Trigger.dev for media processing including video transcoding, image optimization, audio transformation, and document conversion.

## Overview

Build media processing pipelines that handle large files and long-running operations. Process videos, images, audio, and documents with automatic retries, progress tracking, and no timeout limits.

## Featured examples

<CardGroup cols={3}>
  <Card title="FFmpeg video processing" icon="book" href="/guides/examples/ffmpeg-video-processing">
    Process videos and upload results to R2 storage using FFmpeg.
  </Card>

  <Card title="Product image generator" icon="book" href="/guides/example-projects/product-image-generator">
    Transform product photos into professional marketing images using Replicate.
  </Card>

  <Card title="LibreOffice PDF conversion" icon="book" href="/guides/examples/libreoffice-pdf-conversion">
    Convert documents to PDF using LibreOffice.
  </Card>
</CardGroup>

## Benefits of using Trigger.dev for media processing workflows

**Process multi-hour videos without timeouts:** Transcode videos, extract frames, or run CPU-intensive operations for hours. No execution time limits.

**Stream progress to users in real-time:** Show processing status updating live in your UI. Users see exactly where encoding is and how long remains.

**Parallel processing with resource control:** Process hundreds of files simultaneously with configurable concurrency limits. Control resource usage without overwhelming infrastructure.

## Example workflow patterns

<Tabs>
  <Tab title="Video transcode">
    Simple video transcoding pipeline. Downloads video from storage, batch triggers parallel transcoding to multiple formats and thumbnail extraction, uploads all results.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processVideo] --> B[downloadFromStorage]
          B --> C[batchTriggerAndWait]

          C --> D[transcodeToHD]
          C --> E[transcodeToSD]
          C --> F[extractThumbnail]

          D --> G[uploadToStorage]
          E --> G
          F --> G
      ```
    </div>
  </Tab>

  <Tab title="Adaptive video processing">
    **Router + Coordinator pattern**. Analyzes video metadata to determine source resolution, routes to appropriate transcoding preset, batch triggers parallel post-processing for thumbnails, preview clips, and chapter detection.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processVideoUpload] --> B[analyzeMetadata]
          B --> C{Source<br/>Resolution?}

          C -->|4K Source| D[transcode4K]
          C -->|HD Source| E[transcodeHD]
          C -->|SD Source| F[transcodeSD]

          D --> G[coordinatePostProcessing]
          E --> G
          F --> G

          G --> H[batchTriggerAndWait]
          H --> I[extractThumbnails]
          H --> J[generatePreview]
          H --> K[detectChapters]

          I --> L[uploadToStorage]
          J --> L
          K --> L

          L --> M[notifyComplete]
      ```
    </div>
  </Tab>

  <Tab title="Smart image optimization">
    **Router + Coordinator pattern**. Analyzes image content to detect type, routes to specialized processing (background removal for products, face detection for portraits, scene analysis for landscapes), upscales with AI, batch triggers parallel variant generation.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processImageUpload] --> B[analyzeContent]
          B --> C{Content<br/>Type?}

          C -->|Product| D[removeBackground]
          C -->|Portrait| E[detectFaces]
          C -->|Landscape| F[analyzeScene]

          D --> G[upscaleWithAI]
          E --> G
          F --> G

          G --> H[batchTriggerAndWait]
          H --> I[generateWebP]
          H --> J[generateThumbnails]
          H --> K[generateSocialCrops]

          I --> L[uploadToStorage]
          J --> L
          K --> L
      ```
    </div>
  </Tab>

  <Tab title="Podcast production">
    **Coordinator pattern**. Pre-processes raw audio with noise reduction and speaker diarization, batch triggers parallel tasks for transcription (Deepgram), audio enhancement, and chapter detection, aggregates results to generate show notes and publish.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processAudioUpload] --> B[cleanAudio]
          B --> C[coordinateProcessing]

          C --> D[batchTriggerAndWait]
          D --> E[transcribeWithDeepgram]
          D --> F[enhanceAudio]
          D --> G[detectChapters]

          E --> H[generateShowNotes]
          F --> H
          G --> H

          H --> I[publishToPlatforms]
      ```
    </div>
  </Tab>

  <Tab title="Document extraction with approval">
    **Router pattern with human-in-the-loop**. Detects file type and routes to appropriate processor, classifies document with AI to determine type (invoice/contract/receipt), extracts structured data fields, optionally pauses with wait.forToken for human approval.

    <div align="center">
      ```mermaid  theme={null}
      graph TB
          A[processDocumentUpload] --> B[detectFileType]

          B -->|PDF| C[extractText]
          B -->|Word/Excel| D[convertToPDF]
          B -->|Image| E[runOCR]

          C --> F[classifyDocument]
          D --> F
          E --> F

          F -->|Invoice| G[extractLineItems]
          F -->|Contract| H[extractClauses]
          F -->|Receipt| I[extractExpenses]

          G --> J{Needs<br/>Review?}
          H --> J
          I --> J

          J -->|Yes| K[wait.forToken approval]
          J -->|No| L[processAndIntegrate]
          K --> L
      ```
    </div>
  </Tab>
</Tabs>

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>


# Use cases
Source: https://trigger.dev/docs/guides/use-cases/overview

Explore common use cases for Trigger.dev including data processing, media workflows, marketing automation, and AI generation

Trigger.dev handles workflows that traditional platforms struggle with: long-running operations, unpredictable API latencies, multi-hour processing, and complex orchestration patterns. Our platform provides no timeout limits, automatic retries, and real-time progress tracking built in.

## Featured use cases

<CardGroup cols={2}>
  <Card title="Data processing & ETL workflows" icon="database" href="/guides/use-cases/data-processing-etl">
    Build complex data pipelines that process large datasets without timeouts.
  </Card>

  <Card title="Media processing workflows" icon="film" href="/guides/use-cases/media-processing">
    Batch process videos, images, audio, and documents with no execution time limits.
  </Card>

  <Card title="AI media generation workflows" icon="wand-magic-sparkles" href="/guides/use-cases/media-generation">
    Generate images, videos, audio, documents and other media using AI models.
  </Card>

  <Card title="Marketing workflows" icon="bullhorn" href="/guides/use-cases/marketing">
    Build drip campaigns, create marketing content, and orchestrate multi-channel campaigns.
  </Card>
</CardGroup>


# Email us
Source: https://trigger.dev/docs/help-email



You can [email us](https://trigger.dev/contact) by filling out this form.


# Slack support
Source: https://trigger.dev/docs/help-slack



If you have a paid Trigger.dev account, you can request a private Slack Connect channel.

To do this:

1. Login to the [Trigger.dev web app](https://cloud.trigger.dev).
2. Subscribe to a paid plan if you haven't already.
3. In the bottom-left corner click "Join our Slack".


# Hidden tasks
Source: https://trigger.dev/docs/hidden-tasks

Create tasks that are not exported from your trigger files but can still be executed.

Hidden tasks are tasks that are not exported from your trigger files but can still be executed. These tasks are only accessible to other tasks within the same file or module where they're defined.

```ts trigger/my-task.ts theme={null}
import { task } from "@trigger.dev/sdk";

// This is a hidden task - not exported
const internalTask = task({
  id: "internal-processing",
  run: async (payload: any, { ctx }) => {
    // Internal processing logic
  },
});
```

Hidden tasks are useful for creating internal workflows that should only be triggered by other tasks in the same file:

```ts trigger/my-workflow.ts theme={null}
import { task } from "@trigger.dev/sdk";

// Hidden task for internal use
const processData = task({
  id: "process-data",
  run: async (payload: { data: string }, { ctx }) => {
    // Process the data
    return { processed: payload.data.toUpperCase() };
  },
});

// Public task that uses the hidden task
export const mainWorkflow = task({
  id: "main-workflow",
  run: async (payload: any, { ctx }) => {
    const result = await processData.trigger({ data: payload.input });
    return result;
  },
});
```

You can also create packages of reusable tasks that can be imported and used without needing to re-export them:

```ts trigger/my-task.ts theme={null}
import { task } from "@trigger.dev/sdk";
import { sendToSlack } from "@repo/tasks"; // Hidden task from another package

export const notificationTask = task({
  id: "send-notification",
  run: async (payload: any, { ctx }) => {
    await sendToSlack.trigger(payload);
  },
});
```


# How it works
Source: https://trigger.dev/docs/how-it-works

Understand how Trigger.dev works and how it can help you.

## Introduction

Trigger.dev v3 allows you to integrate long-running async tasks into your application and run them in the background. This allows you to offload tasks that take a long time to complete, such as sending multi-day email campaigns, processing videos, or running long chains of AI tasks.

For example, the below task processes a video with `ffmpeg` and sends the results to an s3 bucket, then updates a database with the results and sends an email to the user.

```ts /trigger/video.ts theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { updateVideoUrl } from "../db.js";
import ffmpeg from "fluent-ffmpeg";
import { Readable } from "node:stream";
import type { ReadableStream } from "node:stream/web";
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
import { sendEmail } from "../email.js";
import { getVideo } from "../db.js";

// Initialize S3 client
const s3Client = new S3Client({
  region: process.env.AWS_REGION,
});

export const convertVideo = task({
  id: "convert-video",
  retry: {
    maxAttempts: 5,
    minTimeoutInMs: 1000,
    maxTimeoutInMs: 10000,
    factor: 2,
  },
  run: async ({ videoId }: { videoId: string }) => {
    const { url, userId } = await getVideo(videoId);

    const outputPath = path.join("/tmp", `output_${videoId}.mp4`);

    const response = await fetch(url);

    await new Promise((resolve, reject) => {
      ffmpeg(Readable.fromWeb(response.body as ReadableStream))
        .videoFilters("scale=iw/2:ih/2")
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    const processedContent = await fs.readFile(outputPath);

    // Upload to S3
    const s3Key = `processed-videos/output_${videoId}.mp4`;

    const uploadParams = {
      Bucket: process.env.S3_BUCKET,
      Key: s3Key,
      Body: processedContent,
    };

    await s3Client.send(new PutObjectCommand(uploadParams));
    const s3Url = `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${s3Key}`;

    logger.info("Video converted", { videoId, s3Url });

    // Update database
    await updateVideoUrl(videoId, s3Url);

    await sendEmail(
      userId,
      "Video Processing Complete",
      `Your video has been processed and is available at: ${s3Url}`
    );

    return { success: true, s3Url };
  },
});
```

Now in your application, you can trigger this task by calling:

```ts  theme={null}
import { NextResponse } from "next/server";
import { tasks } from "@trigger.dev/sdk";
import type { convertVideo } from "./trigger/video";
//     ðŸ‘† **type-only** import

export async function POST(request: Request) {
  const body = await request.json();

  // Trigger the task, this will return before the task is completed
  const handle = await tasks.trigger<typeof convertVideo>("convert-video", body);

  return NextResponse.json(handle);
}
```

This will schedule the task to run in the background and return a handle that you can use to check the status of the task. This allows your backend application to respond quickly to the user and offload the long-running task to Trigger.dev.

## The CLI

Trigger.dev comes with a CLI that allows you to initialize Trigger.dev into your project, deploy your tasks, and run your tasks locally. You can run it via `npx` like so:

```sh  theme={null}
npx trigger.dev@latest login # Log in to your Trigger.dev account
npx trigger.dev@latest init # Initialize Trigger.dev in your project
npx trigger.dev@latest dev # Run your tasks locally
npx trigger.dev@latest deploy # Deploy your tasks to the Trigger.dev instance
```

All these commands work with the Trigger.dev cloud and/or your self-hosted instance. It supports multiple profiles so you can easily switch between different accounts or instances.

```sh  theme={null}
npx trigger.dev@latest login --profile <profile> -a https://trigger.example.com # Log in to a specific profile into a self-hosted instance
npx trigger.dev@latest dev --profile <profile> # Initialize Trigger.dev in your project
npx trigger.dev@latest deploy --profile <profile> # Deploy your tasks to the Trigger.dev instance
```

## Trigger.dev architecture

Trigger.dev implements a serverless architecture (without timeouts!) that allows you to run your tasks in a scalable and reliable way. When you run `npx trigger.dev@latest deploy`, we build and deploy your task code to your Trigger.dev instance. Then, when you trigger a task from your application, it's run in a secure, isolated environment with the resources you need to complete the task. A simplified diagram for a task execution looks like this:

```mermaid  theme={null}
sequenceDiagram
  participant App
  participant Trigger.dev
  participant Task Worker

  App->>Trigger.dev: Trigger task
  Trigger.dev-->>App: Task handle
  Trigger.dev->>Task Worker: Run task
  Task Worker-->>Trigger.dev: Task completed
```

In reality there are many more components involved, such as the task queue, the task scheduler, and the task worker pool, logging (etc.), but this diagram gives you a high-level overview of how Trigger.dev works.

## The Checkpoint-Resume System

Trigger.dev implements a powerful Checkpoint-Resume System that enables efficient execution of long-running background tasks in a serverless-like environment. This system allows tasks to pause, checkpoint their state, and resume seamlessly, optimizing resource usage and enabling complex workflows.

Here's how the Checkpoint-Resume System works:

1. **Task Execution**: When a task is triggered, it runs in an isolated environment with all necessary resources.

2. **Subtask Handling**: If a task needs to trigger a subtask, it can do so and wait for its completion using `triggerAndWait`

3. **State Checkpointing**: While waiting for a subtask or during a programmed pause (e.g., `wait.for({ seconds: 30 })`), the system uses CRIU (Checkpoint/Restore In Userspace) to create a checkpoint of the task's entire state, including memory, CPU registers, and open file descriptors.

4. **Resource Release**: After checkpointing, the parent task's resources are released, freeing up the execution environment.

5. **Efficient Storage**: The checkpoint is efficiently compressed and stored on disk, ready to be restored when needed.

6. **Event-Driven Resumption**: When a subtask completes or a wait period ends, Trigger.dev's event system triggers the restoration process.

7. **State Restoration**: The checkpoint is loaded back into a new execution environment, restoring the task to its exact state before suspension.

8. **Seamless Continuation**: The task resumes execution from where it left off, with any subtask results or updated state seamlessly integrated.

This approach allows Trigger.dev to manage resources efficiently, handle complex task dependencies, and provide a virtually limitless execution time for your tasks, all while maintaining the simplicity and scalability of a serverless architecture.

Example of a parent and child task using the Checkpoint-Resume System:

```ts  theme={null}
import { task, wait } from "@trigger.dev/sdk";

export const parentTask = task({
  id: "parent-task",
  run: async () => {
    console.log("Starting parent task");

    // This will cause the parent task to be checkpointed and suspended
    const result = await childTask.triggerAndWait({ data: "some data" });

    console.log("Child task result:", result);

    // This will also cause the task to be checkpointed and suspended
    await wait.for({ seconds: 30 });

    console.log("Resumed after 30 seconds");

    return "Parent task completed";
  },
});

export const childTask = task({
  id: "child-task",
  run: async (payload: { data: string }) => {
    console.log("Starting child task with data:", payload.data);

    // Simulate some work
    await sleep(5);

    return "Child task result";
  },
});
```

The diagram below illustrates the flow of the parent and child tasks using the Checkpoint-Resume System:

```mermaid  theme={null}
sequenceDiagram
    participant App
    participant Trigger.dev
    participant Parent Task
    participant Child Task
    participant CR System
    participant Storage

    App->>Trigger.dev: Trigger parent task
    Trigger.dev->>Parent Task: Start execution
    Parent Task->>Child Task: Trigger child task
    Parent Task->>CR System: Request snapshot
    CR System->>Storage: Store snapshot
    CR System-->>Parent Task: Confirm snapshot stored
    Parent Task->>Trigger.dev: Release resources

    Child Task->>Trigger.dev: Complete execution
    Trigger.dev->>CR System: Request parent task restoration
    CR System->>Storage: Retrieve snapshot
    CR System->>Parent Task: Restore state
    Parent Task->>Trigger.dev: Resume execution
    Parent Task->>Trigger.dev: Complete execution
```

<Note>
  This is why, in the Trigger.dev Cloud, we don't charge for the time waiting for subtasks or the
  time spent in a paused state.
</Note>

## Durable execution

Trigger.dev's Checkpoint-Resume System, combined with idempotency keys, enables durable execution of complex workflows. This approach allows for efficient retries and caching of results, ensuring that work is not unnecessarily repeated in case of failures.

### How it works

1. **Task breakdown**: Complex workflows are broken down into smaller, independent subtasks.
2. **Idempotency keys**: Each subtask is assigned a unique idempotency key.
3. **Result caching**: The output of each subtask is cached based on its idempotency key.
4. **Intelligent retries**: If a failure occurs, only the failed subtask and subsequent tasks are retried.

### Example: Video processing workflow

Let's rewrite the `convert-video` task above to be more durable:

<CodeGroup>
  ```ts /trigger/video.ts theme={null}
  import { idempotencyKeys, logger, task } from "@trigger.dev/sdk";
  import { processVideo, sendUserEmail, uploadToS3 } from "./tasks.js";
  import { updateVideoUrl } from "../db.js";

  export const convertVideo = task({
    id: "convert-video",
    retry: {
      maxAttempts: 5,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
    },
    run: async ({ videoId }: { videoId: string }) => {
      // Automatically scope the idempotency key to this run, across retries
      const idempotencyKey = await idempotencyKeys.create(videoId);

      // Process video
      const { processedContent } = await processVideo
        .triggerAndWait({ videoId }, { idempotencyKey })
        .unwrap(); // Calling unwrap will return the output of the subtask, or throw an error if the subtask failed

      // Upload to S3
      const { s3Url } = await uploadToS3
        .triggerAndWait({ processedContent, videoId }, { idempotencyKey })
        .unwrap();

      // Update database
      await updateVideoUrl(videoId, s3Url);

      // Send email, we don't need to wait for this to finish
      await sendUserEmail.trigger({ videoId, s3Url }, { idempotencyKey });

      return { success: true, s3Url };
    },
  });
  ```

  ```ts /trigger/tasks.ts theme={null}
  import { task, logger } from "@trigger.dev/sdk";
  import ffmpeg from "fluent-ffmpeg";
  import { Readable } from "node:stream";
  import type { ReadableStream } from "node:stream/web";
  import * as fs from "node:fs/promises";
  import * as path from "node:path";
  import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
  import { sendEmail } from "../email.js";
  import { getVideo } from "../db.js";

  // Initialize S3 client
  const s3Client = new S3Client({
    region: process.env.AWS_REGION,
  });

  export const processVideo = task({
    id: "process-video",
    run: async ({ videoId }: { videoId: string }) => {
      const { url } = await getVideo(videoId);

      const outputPath = path.join("/tmp", `output_${videoId}.mp4`);
      const response = await fetch(url);

      await logger.trace("ffmpeg", async (span) => {
        await new Promise((resolve, reject) => {
          ffmpeg(Readable.fromWeb(response.body as ReadableStream))
            .videoFilters("scale=iw/2:ih/2")
            .output(outputPath)
            .on("end", resolve)
            .on("error", reject)
            .run();
        });
      });

      const processedContent = await fs.readFile(outputPath);

      await fs.unlink(outputPath);

      return { processedContent: processedContent.toString("base64") };
    },
  });

  export const uploadToS3 = task({
    id: "upload-to-s3",
    run: async (payload: { processedContent: string; videoId: string }) => {
      const { processedContent, videoId } = payload;

      const s3Key = `processed-videos/output_${videoId}.mp4`;

      const uploadParams = {
        Bucket: process.env.S3_BUCKET,
        Key: s3Key,
        Body: Buffer.from(processedContent, "base64"),
      };

      await s3Client.send(new PutObjectCommand(uploadParams));
      const s3Url = `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${s3Key}`;

      return { s3Url };
    },
  });

  export const sendUserEmail = task({
    id: "send-user-email",
    run: async ({ videoId, s3Url }: { videoId: string; s3Url: string }) => {
      const { userId } = await getVideo(videoId);

      return await sendEmail(
        userId,
        "Video Processing Complete",
        `Your video has been processed and is available at: ${s3Url}`
      );
    },
  });
  ```
</CodeGroup>

### How retries work

Let's say the email sending fails in our video processing workflow. Here's how the retry process works:

1. The main task throws an error and is scheduled for retry.
2. When retried, it starts from the beginning, but leverages cached results for completed subtasks.

Here's a sequence diagram illustrating this process:

```mermaid  theme={null}
sequenceDiagram
  participant Main as Main Task
  participant Process as Process Video
  participant Upload as Upload to S3
  participant DB as Update Database
  participant Email as Send Email

  Main->>Process: triggerAndWait (1st attempt)
  Process-->>Main: Return result
  Main->>Upload: triggerAndWait (1st attempt)
  Upload-->>Main: Return result
  Main->>DB: Update
  Main->>Email: triggerAndWait (1st attempt)
  Email--xMain: Fail
  Main-->>Main: Schedule retry

  Main->>Process: triggerAndWait (2nd attempt)
  Process-->>Main: Return cached result
  Main->>Upload: triggerAndWait (2nd attempt)
  Upload-->>Main: Return cached result
  Main->>DB: Update (idempotent)
  Main->>Email: triggerAndWait (2nd attempt)
  Email-->>Main: Success
```

## The build system

When you run `npx trigger.dev@latest deploy` or `npx trigger.dev@latest dev`, we build your task code using our build system, which is powered by [esbuild](https://esbuild.github.io/). When deploying, the code is packaged up into a Docker image and deployed to your Trigger.dev instance. When running in dev mode, the code is built and run locally on your machine. Some features of our build system include:

* **Bundled by default**: Code + dependencies are bundled and tree-shaked by default.
* **Build extensions**: Use and write custom build extensions to transform your code or the resulting docker image.
* **ESM ouput**: We output to ESM, which allows tree-shaking and better performance.

You can review the build output by running deploy with the `--dry-run` flag, which will output the Containerfile and the build output.

Learn more about working with our build system in the [configuration docs](/config/config-file).

## Dev mode

When you run `npx trigger.dev@latest dev`, we run your task code locally on your machine. All scheduling is still done in the Trigger.dev server instance, but the task code is run locally. This allows you to develop and test your tasks locally before deploying them to the cloud, and is especially useful for debugging and testing.

* The same build system is used in dev mode, so you can be sure that your code will run the same locally as it does in the cloud.
* Changes are automatically detected and a new version is spun up when you save your code.
* Add debuggers and breakpoints to your code and debug it locally.
* Each task is run in a separate process, so you can run multiple tasks in parallel.
* Auto-cancels tasks when you stop the dev server.

<Note>
  Trigger.dev currently does not support "offline" dev mode, where you can run tasks without an
  internet connection. [Please let us know](https://feedback.trigger.dev/) if this is a feature you
  want/need.
</Note>

## Staging and production environments

Trigger.dev supports deploying to multiple "deployed" environments, such as staging and production. This allows you to test your tasks in a staging environment before deploying them to production. You can deploy to a new environment by running `npx trigger.dev@latest deploy --env <env>`, where `<env>` is the name of the environment you want to deploy to. Each environment has its own API Key, which you can use to trigger tasks in that environment.

## OpenTelemetry

The Trigger.dev logging and task dashboard is powered by OpenTelemetry traces and logs, which allows you to trace your tasks and auto-instrument your code. We also auto-correlate logs from subtasks and parent tasks, making it easy view the entire trace of a task execution. A single run of the video processing task above looks like this in the dashboard:

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ebea352695140cd16747daf0c02fc49d" alt="OpenTelemetry trace" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="images/opentelemetry-trace.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c8ff0aabe7e1daa0b4f1766d2a965ae3 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=000644a0bd32f77210f1042cc14404aa 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7b554aaaf552b319acc56550f900b3d1 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0c5c3083a6228e307d970b6d407f4584 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c1548c787cec380d3e5234e0e3ea4879 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/opentelemetry-trace.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d22d7242dbe210b3a6a78c19d6554b36 2500w" />

Because we use standard OpenTelemetry, you can instrument your code and OpenTelemetry compatible libraries to get detailed traces and logs of your tasks. The above trace instruments both Prisma and the AWS SDK:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { PrismaInstrumentation } from "@prisma/instrumentation";
import { AwsInstrumentation } from "@opentelemetry/instrumentation-aws-sdk";

export default defineConfig({
  project: "<your-project-ref>",
  instrumentations: [new PrismaInstrumentation(), new AwsInstrumentation()],
});
```


# How to reduce your spend
Source: https://trigger.dev/docs/how-to-reduce-your-spend

Tips and best practices to reduce your costs on Trigger.dev

## Check out your usage page regularly

Monitor your usage dashboard to understand your spending patterns. You can see:

* Your most expensive tasks
* Your total duration by task
* Number of runs by task
* Spikes in your daily usage

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0117c432cfbb809afbcc5698314dc97d" alt="Usage dashboard" data-og-width="1586" width="1586" data-og-height="1068" height="1068" data-path="images/usage-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8bfe7c067705696a1d1c4185cb42e0b4 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=b9059cd16ffc6ecce13077378646f956 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=aa9acbd91ba5192e66f7718c16b3dbdd 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0922aa95ad5d3a175c560700a869f4e2 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4d6c19d83cbf2a21928c9c1393b01749 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/usage-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e98f6e2d5bfd4e6350b622b3ade51afe 2500w" />

You can view your usage page by clicking the "Organization" menu in the top left of the dashboard and then clicking "Usage".

## Create billing alerts

Configure billing alerts in your dashboard to get notified when you approach spending thresholds. This helps you:

* Catch unexpected cost increases early
* Identify runaway tasks before they become expensive

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=cc2a66d8aab0d8941f81dd70bc7fb61f" alt="Billing alerts" data-og-width="925" width="925" data-og-height="757" height="757" data-path="images/billing-alerts-ui.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1239c92296178c20b1fa90beb3a516f2 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bbadf36f5ec87cac2007f8f6075974ca 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c741c8297876d7cfadedba38ed28853f 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=594b1eec851cd8d5199d47a6b35a6b40 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=692aebc1193500cc97c275f0bd5ddb0c 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/billing-alerts-ui.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=813b55e61d9c1bffd376f06acd7f7d3f 2500w" />

You can view your billing alerts page by clicking the "Organization" menu in the top left of the dashboard and then clicking "Settings".

## Reduce your machine sizes

The larger the machine, the more it costs per second. [View the machine pricing](https://trigger.dev/pricing#computePricing).

Start with the smallest machine that works, then scale up only if needed:

```ts  theme={null}
// Default: small-1x (0.5 vCPU, 0.5 GB RAM)
export const lightTask = task({
  id: "light-task",
  // No machine config needed - uses small-1x by default
  run: async (payload) => {
    // Simple operations
  },
});

// Only use larger machines when necessary
export const heavyTask = task({
  id: "heavy-task",
  machine: "medium-1x", // 1 vCPU, 2 GB RAM
  run: async (payload) => {
    // CPU/memory intensive operations
  },
});
```

You can also override machine size when triggering if you know certain payloads need more resources. [Read more about machine sizes](/machines).

## Avoid duplicate work using idempotencyKey

Idempotency keys prevent expensive duplicate work by ensuring the same operation isn't performed multiple times. This is especially valuable during task retries or when the same trigger might fire multiple times.

When you use an idempotency key, Trigger.dev remembers the result and skips re-execution, saving you compute costs:

```ts  theme={null}
export const expensiveApiCall = task({
  id: "expensive-api-call",
  run: async (payload: { userId: string }) => {
    // This expensive operation will only run once per user
    await wait.for(
      { seconds: 30 },
      {
        idempotencyKey: `user-processing-${payload.userId}`,
        idempotencyKeyTTL: "1h",
      }
    );

    const result = await processUserData(payload.userId);
    return result;
  },
});
```

You can use idempotency keys with various wait functions:

```ts  theme={null}
// Skip waits during retries
const token = await wait.createToken({
  idempotencyKey: `daily-report-${new Date().toDateString()}`,
  idempotencyKeyTTL: "24h",
});

// Prevent duplicate child task execution
await childTask.triggerAndWait(
  { data: payload },
  {
    idempotencyKey: `process-${payload.id}`,
    idempotencyKeyTTL: "1h",
  }
);
```

The `idempotencyKeyTTL` controls how long the result is cached. Use shorter TTLs (like "1h") for time-sensitive operations, or longer ones (up to 30 days default) for expensive operations that rarely need re-execution. This prevents both unnecessary duplicate work and stale data issues.

## Do more work in parallel in a single task

Sometimes it's more efficient to do more work in a single task than split across many. This is particularly true when you're doing lots of async work such as API calls â€“ most of the time is spent waiting, so it's an ideal candidate for doing calls in parallel inside the same task.

```ts  theme={null}
export const processItems = task({
  id: "process-items",
  run: async (payload: { items: string[] }) => {
    // Process all items in parallel
    const promises = payload.items.map((item) => processItem(item));
    // This works very well for API calls
    await Promise.all(promises);
  },
});
```

## Don't needlessly retry

When an error is thrown in a task, your run will be automatically reattempted based on your [retry settings](/tasks/overview#retry-options).

Try setting lower `maxAttempts` for less critical tasks:

```ts  theme={null}
export const apiTask = task({
  id: "api-task",
  retry: {
    maxAttempts: 2, // Don't retry forever
  },
  run: async (payload) => {
    // API calls that might fail
  },
});
```

This is very useful for intermittent errors, but if there's a permanent error you don't want to retry because you will just keep failing and waste compute. Use [AbortTaskRunError](/errors-retrying#using-aborttaskrunerror) to prevent a retry:

```ts  theme={null}
import { task, AbortTaskRunError } from "@trigger.dev/sdk";

export const someTask = task({
  id: "some-task",
  run: async (payload) => {
    const result = await doSomething(payload);

    if (!result.success) {
      // This is a known permanent error, so don't retry
      throw new AbortTaskRunError(result.error);
    }

    return result;
  },
});
```

## Use appropriate maxDuration settings

Set realistic maxDurations to prevent runs from executing for too long:

```ts  theme={null}
export const boundedTask = task({
  id: "bounded-task",
  maxDuration: 300, // 5 minutes max
  run: async (payload) => {
    // Task will be terminated after 5 minutes
  },
});
```


# Idempotency
Source: https://trigger.dev/docs/idempotency

An API call or operation is â€œidempotentâ€ if it has the same result when called more than once.

We currently support idempotency at the task level, meaning that if you trigger a task with the same `idempotencyKey` twice, the second request will not create a new task run.

## `idempotencyKey` option

You can provide an `idempotencyKey` to ensure that a task is only triggered once with the same key. This is useful if you are triggering a task within another task that might be retried:

```ts  theme={null}
import { idempotencyKeys, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 4,
  },
  run: async (payload: any) => {
    // This idempotency key will be unique to this task run, meaning the childTask will only be triggered once across all retries
    const idempotencyKey = await idempotencyKeys.create("my-task-key");

    // childTask will only be triggered once with the same idempotency key
    await childTask.trigger({ foo: "bar" }, { idempotencyKey });

    // Do something else, that may throw an error and cause the task to be retried
    throw new Error("Something went wrong");
  },
});
```

You can use the `idempotencyKeys.create` SDK function to create an idempotency key before passing it to the `options` object.

We automatically inject the run ID when generating the idempotency key when running inside a task by default. You can turn it off by passing the `scope` option to `idempotencyKeys.create`:

```ts  theme={null}
import { idempotencyKeys, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 4,
  },
  run: async (payload: any) => {
    // This idempotency key will be globally unique, meaning only a single task run will be triggered with this key
    const idempotencyKey = await idempotencyKeys.create("my-task-key", { scope: "global" });

    // childTask will only be triggered once with the same idempotency key
    await childTask.trigger({ foo: "bar" }, { idempotencyKey });
  },
});
```

If you are triggering a task from your backend code, you can use the `idempotencyKeys.create` SDK function to create an idempotency key.

```ts  theme={null}
import { idempotencyKeys, tasks } from "@trigger.dev/sdk";

// You can also pass an array of strings to create a idempotency key
const idempotencyKey = await idempotencyKeys.create([myUser.id, "my-task"]);
await tasks.trigger("my-task", { some: "data" }, { idempotencyKey });
```

You can also pass a string to the `idempotencyKey` option, without first creating it with `idempotencyKeys.create`.

```ts  theme={null}
import { myTask } from "./trigger/myTasks";

// You can also pass an array of strings to create a idempotency key
await myTask.trigger({ some: "data" }, { idempotencyKey: myUser.id });
```

<Note>Make sure you provide sufficiently unique keys to avoid collisions.</Note>

You can pass the `idempotencyKey` when calling `batchTrigger` as well:

```ts  theme={null}
import { tasks } from "@trigger.dev/sdk";

await tasks.batchTrigger("my-task", [
  {
    payload: { some: "data" },
    options: { idempotencyKey: await idempotencyKeys.create(myUser.id) },
  },
]);
```

## `idempotencyKeyTTL` option

The `idempotencyKeyTTL` option defines a time window during which a task with the same idempotency key will only run once. Here's how it works:

1. When you trigger a task with an idempotency key and set `idempotencyKeyTTL: "5m"`, it creates a 5-minute window.
2. During this window, any subsequent triggers with the same idempotency key will return the original task run instead of creating a new one.
3. Once the TTL window expires, the next trigger with that idempotency key will create a new task run and start a new time window.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ed13a5a2782dceb10e62483dd0ad6417" alt="idempotency-key-ttl" data-og-width="939" width="939" data-og-height="924" height="924" data-path="images/idempotency-key-ttl.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5e9e71c9b27dbd12ce2d427b6a381976 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=27c5b4751d25d9dd76a109487b926d10 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=28adb87d5c934a925e3a9494c23c983a 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=234d6cc345f7e86c88627eca77503d1a 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fb417bbcbc46cd9ad684783313b9a91f 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/idempotency-key-ttl.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d701231ed25ac6e732be10529e46e017 2500w" />

By default idempotency keys are stored for 30 days. You can change this by passing the `idempotencyKeyTTL` option when triggering a task:

```ts  theme={null}
import { idempotencyKeys, task, wait } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 4,
  },
  run: async (payload: any) => {
    const idempotencyKey = await idempotencyKeys.create("my-task-key");

    // The idempotency key will expire after 60 seconds
    await childTask.trigger({ foo: "bar" }, { idempotencyKey, idempotencyKeyTTL: "60s" });

    await wait.for({ seconds: 61 });

    // The idempotency key will have expired, so the childTask will be triggered again
    await childTask.trigger({ foo: "bar" }, { idempotencyKey });

    // Do something else, that may throw an error and cause the task to be retried
    throw new Error("Something went wrong");
  },
});
```

You can use the following units for the `idempotencyKeyTTL` option:

* `s` for seconds (e.g. `60s`)
* `m` for minutes (e.g. `5m`)
* `h` for hours (e.g. `2h`)
* `d` for days (e.g. `3d`)

## Payload-based idempotency

We don't currently support payload-based idempotency, but you can implement it yourself by hashing the payload and using the hash as the idempotency key.

```ts  theme={null}
import { idempotencyKeys, task } from "@trigger.dev/sdk";
import { createHash } from "node:crypto";

// Somewhere in your code
const idempotencyKey = await idempotencyKeys.create(hash(childPayload));
// childTask will only be triggered once with the same idempotency key
await tasks.trigger("child-task", { some: "payload" }, { idempotencyKey });

// Create a hash of the payload using Node.js crypto
// Ideally, you'd do a stable serialization of the payload before hashing, to ensure the same payload always results in the same hash
function hash(payload: any): string {
  const hash = createHash("sha256");
  hash.update(JSON.stringify(payload));
  return hash.digest("hex");
}
```

## Important notes

Idempotency keys, even the ones scoped globally, are actually scoped to the task and the environment. This means that you cannot collide with keys from other environments (e.g. dev will never collide with prod), or to other projects and orgs.

If you use the same idempotency key for triggering different tasks, the tasks will not be idempotent, and both tasks will be triggered. There's currently no way to make multiple tasks idempotent with the same key.


# Welcome to the Trigger.dev docs
Source: https://trigger.dev/docs/introduction

Find all the resources and guides you need to get started

<CardGroup cols={2}>
  <Card title="Quick start" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3daa6c1f067453c49af4221cb7dae812" href="/quick-start" data-og-width="480" width="480" data-og-height="280" height="280" data-path="images/intro-quickstart.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f007fba3d74040ab1bf5792a0b25fb94 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=efab6d38781d8435bb4b37baac2e8b99 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=756260cad7e8a96f2ef4438197f9cea6 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=efbb722cebc3f79afd7e80375042e45a 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9bd7639a9277dd5ac7c9b7bf37f59b15 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-quickstart.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c04bc953621d99ddf8d647a4c8ac2518 2500w">
    Get started with Trigger.dev and run your first task in 3 minutes
  </Card>

  <Card title="Guides, frameworks & examples" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a0d04795e0949c204f31dba612d3f351" href="/guides/introduction#example-tasks" data-og-width="480" width="480" data-og-height="280" height="280" data-path="images/intro-examples.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=98d8ee9833e36a5d7d99831c5582fee0 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bd202420893e3f9c4a5c649a3362497a 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=43d5c5eb74c6c1d9950c3149fd65875f 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ad7aa47a74372c1abe8187c57827bcb9 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=792d568625d46c6736a144d81b0772b5 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-examples.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=5db47fb7f73728553b5bac2eadee572b 2500w">
    Browse our wide range of guides, frameworks and example projects
  </Card>

  <Card title="MCP Server" img="https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=0b1535467cdc23f489dc300c71e784bb" href="/mcp-introduction" data-og-width="480" width="480" data-og-height="280" height="280" data-path="images/intro-mcp.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=280&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=e828f87118521030e1d4f006c53d3b53 280w, https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=560&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=60156c7a7e97c0178cb5a631a8515302 560w, https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=840&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=c01a8c054c96dc5940a48547a0727941 840w, https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=1100&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=0157e86ef0c2218cd19206affd15cc5c 1100w, https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=1650&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=4311def68cd35fd8cfe617cfbcf60de3 1650w, https://mintcdn.com/trigger/O9QeT-PFPY5Njogw/images/intro-mcp.jpg?w=2500&fit=max&auto=format&n=O9QeT-PFPY5Njogw&q=85&s=ff386b0658d0002f7ac83049d6aeebb0 2500w">
    Learn how to install and configure the Trigger.dev MCP Server
  </Card>

  <Card title="Video walkthrough" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3a34fcac5370ad06e3c5d317719a8acc" href="/video-walkthrough" data-og-width="480" width="480" data-og-height="280" height="280" data-path="images/intro-video.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=09d5ec6d1cd85243d920ab1ed5b4b6a5 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=28179e87cee604339ec921de45ea0008 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c38cdd9228eb8bbad04e8a5ea28f02a5 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f37e8622b472fced9035a30d7e036e9f 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=09c16d181df9ad822424c4ce9d2c75d4 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-video.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=012be02b3d348512fa5613d1b58bcb28 2500w">
    Watch an end-to-end demo of Trigger.dev in 10 minutes
  </Card>
</CardGroup>

## What is Trigger.dev?

Trigger.dev is an open source background jobs framework that lets you write reliable workflows in plain async code. Run long-running AI tasks, handle complex background jobs, and build AI agents with built-in queuing, automatic retries, and real-time monitoring. No timeouts, elastic scaling, and zero infrastructure management required.

We provide everything you need to build and manage background tasks: a CLI and SDK for writing tasks in your existing codebase, support for both [regular](/tasks/overview) and [scheduled](/tasks/scheduled) tasks, full observability through our dashboard, and a [Realtime API](/realtime) with [React hooks](/realtime/react-hooks#realtime-hooks) for showing task status in your frontend. You can use [Trigger.dev Cloud](https://cloud.trigger.dev) or [self-host](/self-hosting/overview) on your own infrastructure.

## Learn the concepts

<CardGroup cols={2}>
  <Card title="Writing tasks" icon="wand-magic-sparkles" href="/tasks/overview" color="#3B82F6">
    Tasks are the core of Trigger.dev. Learn what they are and how to write them.
  </Card>

  <Card title="Triggering tasks" icon="bullseye-pointer" href="/triggering" color="#fbbf24">
    Learn how to trigger tasks from your codebase.
  </Card>

  <Card title="Runs" icon="person-running" href="/runs" color="#EA189E">
    Runs are the instances of tasks that are executed. Learn how they work.
  </Card>

  <Card title="API keys" icon="key" href="/apikeys" color="#EAEA08">
    API keys are used to authenticate requests to the Trigger.dev API. Learn how to create and use
    them.
  </Card>
</CardGroup>

## Explore by feature

<CardGroup>
  <Card title="Scheduled tasks (cron)" icon="clock" href="/tasks/scheduled" color="#EAEA08">
    Scheduled tasks are a type of task that is scheduled to run at a specific time.
  </Card>

  <Card title="Realtime API" icon="loader" href="/realtime" color="#22C55E">
    The Realtime API allows you to trigger tasks and get the status of runs.
  </Card>

  <Card title="React hooks" icon="react" href="/realtime/react-hooks" color="#3B82F6">
    React hooks are a way to show task status in your frontend.
  </Card>

  <Card title="Waits" icon="calendar-clock" href="/wait" color="#F59E0B">
    Waits are a way to wait for a task to finish before continuing.
  </Card>

  <Card title="Errors and retries" icon="message-exclamation" href="/errors-retrying" color="#F43F5E">
    Learn how to handle errors and retries.
  </Card>

  <Card title="Concurrency & Queues" icon="line-height" href="/queue-concurrency" color="#D946EF">
    Configure what you want to happen when there is more than one run at a time.
  </Card>

  <Card title="Wait for token (human-in-the-loop)" icon="hand" href="/wait-for-token" color="#EAEA08">
    Pause runs until a token is completed via an approval workflow.
  </Card>

  <Card title="Build extensions" icon="gear" href="/config/extensions/overview" color="#22C55E">
    Customize the build process or the resulting bundle and container image.
  </Card>
</CardGroup>

## Explore by build extension

| Extension             | What it does                                                 | Docs                                                   |
| :-------------------- | :----------------------------------------------------------- | :----------------------------------------------------- |
| prismaExtension       | Use Prisma with Trigger.dev                                  | [Learn more](/config/extensions/prismaExtension)       |
| pythonExtension       | Execute Python scripts in Trigger.dev                        | [Learn more](/config/extensions/pythonExtension)       |
| playwright            | Use Playwright with Trigger.dev                              | [Learn more](/config/extensions/playwright)            |
| puppeteer             | Use Puppeteer with Trigger.dev                               | [Learn more](/config/extensions/puppeteer)             |
| lightpanda            | Use Lightpanda with Trigger.dev                              | [Learn more](/config/extensions/lightpanda)            |
| ffmpeg                | Use FFmpeg with Trigger.dev                                  | [Learn more](/config/extensions/ffmpeg)                |
| aptGet                | Install system packages with aptGet                          | [Learn more](/config/extensions/aptGet)                |
| additionalFiles       | Copy additional files to the build directory                 | [Learn more](/config/extensions/additionalFiles)       |
| additionalPackages    | Include additional packages in the build                     | [Learn more](/config/extensions/additionalPackages)    |
| syncEnvVars           | Automatically sync environment variables to Trigger.dev      | [Learn more](/config/extensions/syncEnvVars)           |
| esbuildPlugin         | Add existing or custom esbuild plugins to your build process | [Learn more](/config/extensions/esbuildPlugin)         |
| emitDecoratorMetadata | Support for the emitDecoratorMetadata TypeScript compiler    | [Learn more](/config/extensions/emitDecoratorMetadata) |
| audioWaveform         | Support for Audio Waveform in your project                   | [Learn more](/config/extensions/audioWaveform)         |

## Explore by example

<CardGroup cols={3}>
  <Card title="FFmpeg" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=308ca975004d564b951b5247fa42e1ba" href="/guides/examples/ffmpeg-video-processing" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-ffmpeg.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=50b20cc1ce3b013390374b650c160a8a 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4efedf86cefcb2b4071c08dcd1fd9634 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1a1009efa595d46490efaf848e13c2cd 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e2f6b59884b95dd976f2a3570ddc8714 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=284de6e4c3eedbd6663b0fd7a66a3a6b 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-ffmpeg.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ee2e35399d23ea25110516b541d699eb 2500w" />

  <Card title="Fal.ai" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=553e3f821fb8ee2776783e992e69063e" href="/guides/examples/fal-ai-image-to-cartoon" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-fal.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=30bea8d94d5486b3bce3c17c21f03bea 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6c0b6596344ad2f1001cef7eecd5d564 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=66fe4f5d5564792add7c14d03c614409 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=306e732afbc891ae91b132835bf89632 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=74e49a6ecab024a0843169b85478d91a 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-fal.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fc1da0a07093e461f1ae95e867e6b562 2500w" />

  <Card title="Puppeteer" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d87baa6ed5eb42a9f44c3f192675353f" href="/guides/examples/puppeteer" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-puppeteer.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b3ac0a433d872bf5b57335d162dcce4c 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=35df7b5bfc747dc97f45b8c3f9f45478 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4ff92ad8a2dcac1db0d6614a3513e97e 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=3c067ac24018cacddfc38076d7cb704b 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a36ffdf53cb05d1a48d6a5cacea6f9dd 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-puppeteer.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6e5c6e5774c0e7bcff7a20b4f4b8cdb4 2500w" />

  <Card title="LibreOffice" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ef98f3b2a4289ded93b40f454a570ff8" href="/guides/examples/libreoffice-pdf-conversion" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-libreoffice.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=187fe896ab79b2d257b79fdbae1084f9 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9e22f338d2789e3d0d15f9a10008dd49 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4377131d4951b67eef44d23cce0adc74 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f15e4c04279cdf4cbba42335083c758b 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=306c50f36bf9df92613a60bbda204c65 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-libreoffice.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=19cf8150a75754a50dd530cc479b8734 2500w" />

  <Card title="OpenAI" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bb55c727721a1d192f05bfbd4b2aedd0" href="/guides/examples/open-ai-with-retrying" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-openai.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=804ed1edf44a880f92166720ac152b41 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=400560d4d5dbd0997ec59676de140336 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=702d5edd4e4b2c64f5c236135fe23f09 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ac46d3e8215b7883e50fb0dd570be4a4 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=de2b9c512de8ad08a58bc56bd01f2cd3 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=41f2edcb4f467f64616ea98076850367 2500w" />

  <Card title="Browserbase" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=352fb95a185e61f6eb76b829465f5760" href="/guides/examples/scrape-hacker-news" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-browserbase.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6b8953fe0f084bd45609935db71775b3 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b50a1920addcdc16183af1fac0d4ffb6 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9755604b742f51965ac16fe6c0620c36 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6d8a2b3eac6e6ea30573597042db02f3 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=32fec71af786bf4f485f547c72b94392 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-browserbase.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=e81273b45fa13a05bdf4db434be06c7e 2500w" />

  <Card title="Sentry" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=984402dfeeff094b78af3f511ae110d6" href="/guides/examples/sentry-error-tracking" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-sentry.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ca4c36a0bd998047218376e1a6ad9cdd 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3038004a3cebc85adccbf6a5df69410e 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9359664068ff677d69c6a689b653d66f 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cbf973d9fce1245f5f44bb3104e6fc22 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=279ea6752575b58c363f4f8e0e5e6f1b 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sentry.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e2e14007ef4ede97b3e172a3a51e295e 2500w" />

  <Card title="Resend" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=1132b85155953b871bcc310e2d0791ca" href="/guides/examples/resend-email-sequence" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-resend.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fcdb1621b2af47568d9f2e8757c60524 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4a973d71db540048191aaadfd7ada258 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=02f8ed472d2f1a4232d36faaffa90496 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=95a6ebda32b42caa135ce0e520c4cc33 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=7ce7a62b7dcd3fbbc88191fe9d4bcb12 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-resend.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=47ad461fe5624b5aadb9de23b4089ef4 2500w" />

  <Card title="Vercel AI SDK" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9509bd7265563f221aa2c883a6636604" href="/guides/examples/vercel-ai-sdk" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-vercel.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=dcf1c80803fe78806c742dd5a8a40a05 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3fbfab53ebdd9e827b9714fa0db976fe 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=25985533ac75665a57f5766dfd536c0d 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ed0558226346e611c1e1b57b5cc9f9fb 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cf90b10c302ff4e67a2179dbc0fb9908 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-vercel.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c0676c8fbf7aadccac1c7369c5614e7 2500w" />

  <Card title="Sharp" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=dc7f8fee7e41659bc26c3f82465bcad9" href="/guides/examples/sharp-image-processing" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-sharp.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=bc1cecbe48567ff501d58bbbe5f9b546 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=711a7d34171b069a15f4a138b958230a 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0d6a85390203f5b559c9c748df389bf7 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fa01bba7583a9d0f1d11631862dec0b3 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ce0059c974fe529af51c6f0ea5c9ee65 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-sharp.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=03322f9ac91591a47f67479355e97625 2500w" />

  <Card title="Deepgram" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=feb9e540b0c7f9164afe5f490d1e7f15" href="/guides/examples/deepgram-transcribe-audio" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-deepgram.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=dd0b19a52aa86daf35aedb41e03237eb 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2278887e1305326123cf2b940b480b76 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9d130f5e0ddd091ef7fcfbf4834a5974 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=106d584ce33ea29d305be0e65d8ad4b1 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a4ed91bcf5b47fce740d9598d6a7b1c2 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-deepgram.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ff29802a9e84279c2ab0d3263eb38ae1 2500w" />

  <Card title="Supabase" img="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e12aee521d12d2b5002e9ffe63fd1c43" href="/guides/examples/supabase-database-operations" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-supabase.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=378114042ed64925968eda7afb41a4dd 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=92c281c515d77722fe11a440dc0e4d8c 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0f47163542864a0cb09afbab5183690e 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c8f8a045c1895ad6ab849a9984ce81f8 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=17b8aa806fe6590159bff079152a6910 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/intro-supabase.jpg?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=85c9b5c2531480e66aa75723953afbab 2500w" />

  <Card title="DALLâ€¢E" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=bb55c727721a1d192f05bfbd4b2aedd0" href="/guides/examples/dall-e3-generate-image" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-openai.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=804ed1edf44a880f92166720ac152b41 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=400560d4d5dbd0997ec59676de140336 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=702d5edd4e4b2c64f5c236135fe23f09 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=ac46d3e8215b7883e50fb0dd570be4a4 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=de2b9c512de8ad08a58bc56bd01f2cd3 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-openai.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=41f2edcb4f467f64616ea98076850367 2500w" />

  <Card title="Firecrawl" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c992f70dfa2e7324a5a6c23fdfb5f1ce" href="/guides/examples/firecrawl-url-crawl" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-firecrawl.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=a70817b40350fc2f0e4f3d80b70b8cd9 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=dc8f447d095336ad25d0ffde813a5bd0 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c3839edafb3fe9afa9a691857d7c920d 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2267747bd997ec4dc84c018f2468eb51 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=be5edf52ca41b6685da8495c05661f15 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-firecrawl.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=213f79f8cc8eac5d672750c9f1669c1e 2500w" />

  <Card title="Lightpanda" img="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f0d242338bf995c2872da2aac5cefd7b" href="/guides/examples/lightpanda" data-og-width="300" width="300" data-og-height="160" height="160" data-path="images/intro-lightpanda.jpg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8f1038a9f7aa12ca4b0691d889ff5af3 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=55778ec1b01b144e3a910491d316c5f0 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d13f6e47f07a9e789d489b583f10347a 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=4622ebbf10b29fdc28a5fd6ec08f7fe7 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=df90e0d88e401591cc007b09fe9e15fe 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/intro-lightpanda.jpg?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9a61b99beb043406e40fcf27d9027860 2500w" />
</CardGroup>

## Getting help

We'd love to hear from you or give you a hand getting started. Here are some ways to get in touch with us.

<CardGroup>
  <Card title="Join our Discord server" icon="discord" href="https://discord.gg/kA47vcd8P6" color="#5865F2">
    Our Discord is the best place to get help with any questions about Trigger.dev.
  </Card>

  <Card
    title="Follow us on X (Twitter)"
    icon={
    <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 0 512 512">
      <path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z" />
    </svg>
  }
    href="https://twitter.com/triggerdotdev"
    color="#1DA1F2"
  >
    Follow us to get the latest updates and news.
  </Card>

  <Card title="Schedule a call" icon="phone" iconType="solid" color="#22C55E" href="https://cal.com/team/triggerdotdev/founders-call">
    Arrange a call with one of the founders to get help with any questions.
  </Card>

  <Card title="Give us a star on GitHub" icon="star" iconType="solid" href="https://github.com/triggerdotdev/trigger.dev" color="#fbbf24">
    Check us out our GitHub repo and give us a star if you like what we're doing.
  </Card>
</CardGroup>


# Limits
Source: https://trigger.dev/docs/limits

There are some hard and soft limits that you might hit.

## Concurrency limits

| Pricing tier | Limit                |
| :----------- | :------------------- |
| Free         | 10 concurrent runs   |
| Hobby        | 25 concurrent runs   |
| Pro          | 100+ concurrent runs |

Additional bundles above the Pro tier are available for \$50/month per 50 concurrent runs. Contact us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord) to request more.

## Rate limits

Generally speaking each SDK call is an API call.

| Limit | Details                   |
| :---- | :------------------------ |
| API   | 1,500 requests per minute |

You can request a higher rate limit from us if you're on a paid plan.

The most common cause of hitting the API rate limit is if youâ€™re calling `trigger()` on a task in a loop, instead of doing this use `batchTrigger()` which will trigger multiple tasks in a single API call. You can have up to 500 tasks in a single batch trigger call.

## Queued tasks

The number of queued tasks by environment.

| Limit   | Details            |
| :------ | :----------------- |
| Dev     | At most 500        |
| Staging | At most 10 million |
| Prod    | At most 10 million |

## Schedules

| Pricing tier | Limit              |
| :----------- | :----------------- |
| Free         | 10 per project     |
| Hobby        | 100 per project    |
| Pro          | 1,000+ per project |

Additional bundles above the Pro tier are available for \$10/month per 1,000 schedules. Contact us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord) to request more.

When attaching schedules to tasks we strongly recommend you add them [in our dashboard](/tasks/scheduled#attaching-schedules-in-the-dashboard) if they're "static". That way you can control them easily per environment.

If you add them [dynamically using code](/management/schedules/create) make sure you add a `deduplicationKey` so you don't add the same schedule to a task multiple times. If you don't your task will get triggered multiple times, it will cost you more, and you will hit the limit.

If you're creating schedules for your user you will definitely need to request more schedules from us.

## Preview branches

| Pricing tier | Limit                |
| :----------- | :------------------- |
| Free         | Not available        |
| Hobby        | 5 preview branches   |
| Pro          | 20+ preview branches |

Additional bundles above the Pro tier are available for \$10/month per preview branch. Contact us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord) to request more.

## Realtime connections

| Pricing tier | Limit                       |
| :----------- | :-------------------------- |
| Free         | 10 concurrent connections   |
| Hobby        | 50 concurrent connections   |
| Pro          | 500+ concurrent connections |

Additional bundles are available for \$10/month per 100 concurrent connections. Contact us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord) to request more.

## Task payloads and outputs

| Limit                  | Details                                       |
| :--------------------- | :-------------------------------------------- |
| Single trigger payload | Must not exceed 3MB                           |
| Batch trigger payload  | The total of all payloads must not exceed 5MB |
| Task outputs           | Must not exceed 10MB                          |

Payloads and outputs that exceed 512KB will be offloaded to object storage and a presigned URL will be provided to download the data when calling `runs.retrieve`. You don't need to do anything to handle this in your tasks however, as we will transparently upload/download these during operation.

## Batch size

A single batch can have a maximum of 500 items.

<SoftLimit />

## Log retention

| Pricing tier | Limit   |
| :----------- | :------ |
| Free         | 1 day   |
| Hobby        | 7 days  |
| Pro          | 30 days |

## Log size

We limit the size of logs to prevent oversized data potentially causing issues.

<Expandable title="log limits">
  #### Attribute Limits

  * Span Attribute Count Limit: 256
  * Log Attribute Count Limit: 256
  * Span Attribute Value Length Limit: 131072 characters
  * Log Attribute Value Length Limit: 131072 characters

  #### Event and Link Limits

  * Span Event Count Limit: 10
  * Link Count Limit: 2
  * Attributes per Link Limit: 10
  * Attributes per Event Limit: 10

  #### I/O Packet Length Limit

  128 KB (131,072 bytes)

  #### Attribute Clipping Behavior

  * Attributes exceeding the value length limit (1028 characters) are discarded.
  * If the total number of attributes exceeds 256, additional attributes are not included.

  #### Attribute Value Size Calculation

  * Strings: Actual length of the string
  * Numbers: 8 bytes
  * Booleans: 4 bytes
  * Arrays: Sum of the sizes of all elements
  * Undefined or null: 0 bytes
</Expandable>

## Alerts

An alert destination is a single email address, Slack channel, or webhook URL that you want to send alerts to.

| Pricing tier | Limit                   |
| :----------- | :---------------------- |
| Free         | 1 alert destination     |
| Hobby        | 3 alert destinations    |
| Pro          | 100+ alert destinations |

If you're on the Pro plan and need more than the plan limit, you can request more by contacting us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord).

## Machines

The default machine is `small-1x` which has 0.5 vCPU and 0.5 GB of RAM. You can optionally configure a higher spec machine which will increase the cost of running the task but can also improve the performance of the task if it is CPU or memory bound.

See the [machine configurations](/machines#machine-configurations) for more details.

## Team members

| Pricing tier | Limit            |
| :----------- | :--------------- |
| Free         | 5 team members   |
| Hobby        | 5 team members   |
| Pro          | 25+ team members |

Additional seats are available for \$20/month per seat. Contact us via [email](https://trigger.dev/contact) or [Discord](https://trigger.dev/discord) to request more.


# Logging and tracing
Source: https://trigger.dev/docs/logging

How to use the built-in logging and tracing system.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=595580c7a9e3e5dcc0e3297f0f6fec68" alt="The run log" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/run-log.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8e387330e0f9ff8717932fae4d604ecf 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fd0e82f755dd03d33b64384d10bd5969 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6dfa64d17a661cf7715799d82ed898ca 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7ddf07bfae2ad13b921b2051002f4ad5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=541fa551d5361702d92e41b0dad28b50 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-log.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cd7e639daec0374eb8c2cb6c5017f89b 2500w" />

The run log shows you exactly what happened in every run of your tasks. It is comprised of logs, traces and spans.

## Logs

You can use `console.log()`, `console.error()`, etc as normal and they will be shown in your run log. This is the standard function so you can use it as you would in any other JavaScript or TypeScript code. Logs from any functions/packages will also be shown.

### logger

We recommend that you use our `logger` object which creates structured logs. Structured logs will make it easier for you to search the logs to quickly find runs.

```ts /trigger/logging.ts theme={null}
import { task, logger } from "@trigger.dev/sdk";

export const loggingExample = task({
  id: "logging-example",
  run: async (payload: { data: Record<string, string> }) => {
    //the first parameter is the message, the second parameter must be a key-value object (Record<string, unknown>)
    logger.debug("Debug message", payload.data);
    logger.log("Log message", payload.data);
    logger.info("Info message", payload.data);
    logger.warn("You've been warned", payload.data);
    logger.error("Error message", payload.data);
  },
});
```

## Tracing and spans

Tracing is a way to follow the flow of your code. It's very useful for debugging and understanding how your code is working, especially with long-running or complex tasks.

Trigger.dev uses OpenTelemetry tracing under the hood. With automatic tracing for many things like task triggering, task attempts, HTTP requests, and more.

| Name          | Description                      |
| :------------ | :------------------------------- |
| Task triggers | Task triggers                    |
| Task attempts | Task attempts                    |
| HTTP requests | HTTP requests made by your code. |

### Adding instrumentations

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c23b7b3b9b853d52af2850b732e576d7" alt="The run log" data-og-width="1442" width="1442" data-og-height="521" height="521" data-path="images/auto-instrumentation.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d087748854dbe051414c3f842f183af8 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c86e6cc078f69e7585836db0561eae15 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=c03cb732f67e320ac58efc3fd6001a66 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=f91182e7070b80515e916f1401c40212 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6182199af22c75f77a02bdfb9a8d42d5 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/auto-instrumentation.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b161da0f8c3c970e234e7574c0042951 2500w" />

You can [add instrumentations](/config/config-file#instrumentations). The Prisma one above will automatically trace all Prisma queries.

### Add custom traces

If you want to add custom traces to your code, you can use the `logger.trace` function. It will create a new OTEL trace and you can set attributes on it.

```ts  theme={null}
import { logger, task } from "@trigger.dev/sdk";

export const customTrace = task({
  id: "custom-trace",
  run: async (payload) => {
    //you can wrap code in a trace, and set attributes
    const user = await logger.trace("fetch-user", async (span) => {
      span.setAttribute("user.id", "1");

      //...do stuff

      //you can return a value
      return {
        id: "1",
        name: "John Doe",
        fetchedAt: new Date(),
      };
    });

    const usersName = user.name;
  },
});
```


# Machines
Source: https://trigger.dev/docs/machines

Configure the number of vCPUs and GBs of RAM you want the task to use.

The `machine` configuration is optional. Using higher spec machines will increase the cost of running the task but can also improve the performance of the task if it is CPU or memory bound.

```ts /trigger/heavy-task.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const heavyTask = task({
  id: "heavy-task",
  machine: "large-1x",
  run: async ({ payload, ctx }) => {
    //...
  },
});
```

The default machine is `small-1x` which has 0.5 vCPU and 0.5 GB of RAM. You can change the default machine in your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import type { TriggerConfig } from "@trigger.dev/sdk";

export const config: TriggerConfig = {
  machine: "small-2x",
  // ... other config
};
```

## Machine configurations

| Preset             | vCPU | Memory | Disk space |
| :----------------- | :--- | :----- | :--------- |
| micro              | 0.25 | 0.25   | 10GB       |
| small-1x (default) | 0.5  | 0.5    | 10GB       |
| small-2x           | 1    | 1      | 10GB       |
| medium-1x          | 1    | 2      | 10GB       |
| medium-2x          | 2    | 4      | 10GB       |
| large-1x           | 4    | 8      | 10GB       |
| large-2x           | 8    | 16     | 10GB       |

You can view the Trigger.dev cloud pricing for these machines [here](https://trigger.dev/pricing#computePricing).

## Overriding the machine when triggering

You can also override the task machine when you [trigger](/triggering) it:

```ts  theme={null}
await tasks.trigger<typeof heavyTask>(
  "heavy-task",
  { message: "hello world" },
  { machine: "large-2x" }
);
```

This is useful when you know that a certain payload will require more memory than the default machine. For example, you know it's a larger file or a customer that has a lot of data.

## Out Of Memory (OOM) errors

Sometimes you might see one of your runs fail with an "Out Of Memory" error.

> TASK\_PROCESS\_OOM\_KILLED. Your run was terminated due to exceeding the machine's memory limit. Try increasing the machine preset in your task options or replay using a larger machine.

We automatically detect common Out Of Memory errors:

* When using Node.js, if the V8 heap limit is exceeded (this can happen when creating large long-lived objects)
* When the entire process exceeds the memory limit of the machine the run is executing on.
* When a child process, such as ffmpeg, causes the memory limit of the machine to be exceeded, and exits with a non-zero code.

### Memory/Resource monitoring

To better understand why an OOM error occurred, we've published a helper class that will log memory debug information at regular intervals.

First, add this `ResourceMonitor` class to your project:

<Accordion title="View ResourceMonitor class">
  ```ts /src/resourceMonitor.ts theme={null}
  import { promisify } from "node:util";
  import { exec } from "node:child_process";
  import os from "node:os";
  import { promises as fs } from "node:fs";
  import { type Context, logger } from "@trigger.dev/sdk";
  import { getHeapStatistics } from "node:v8";
  import { PerformanceObserver, constants } from "node:perf_hooks";

  const execAsync = promisify(exec);

  export type DiskMetrics = {
    total: number;
    used: number;
    free: number;
    percentUsed: number;
    warning?: string;
  };

  export type MemoryMetrics = {
    total: number;
    free: number;
    used: number;
    percentUsed: number;
  };

  export type NodeProcessMetrics = {
    memoryUsage: number;
    memoryUsagePercent: number;
    heapUsed: number;
    heapSizeLimit: number;
    heapUsagePercent: number;
    availableHeap: number;
    isNearHeapLimit: boolean;
  };

  export type TargetProcessMetrics = {
    method: string;
    processName: string;
    count: number;
    processes: ProcessInfo[];
    averages: {
      cpu: number;
      memory: number;
      rss: number;
      vsz: number;
    } | null;
    totals: {
      cpu: number;
      memory: number;
      rss: number;
      vsz: number;
    } | null;
  };

  export type ProcessMetrics = {
    node: NodeProcessMetrics;
    targetProcess: TargetProcessMetrics | null;
  };

  type GCSummary = {
    count: number;
    totalDuration: number; // ms
    avgDuration: number; // ms
    maxDuration: number; // ms
    kinds: Record<
      string,
      {
        // breakdown by kind
        count: number;
        totalDuration: number;
        avgDuration: number;
        maxDuration: number;
      }
    >;
  };

  type ProcessInfo = {
    user: string;
    pid: number;
    cpu: number;
    mem: number;
    vsz: number;
    rss: number;
    command: string;
  };

  export type SystemMetrics = {
    disk: DiskMetrics;
    memory: MemoryMetrics;
  };

  export type ResourceMonitorConfig = {
    dirName?: string;
    processName?: string;
    ctx: Context;
    compactLogging?: boolean;
  };

  // Constants
  const DISK_LIMIT_GB = 10;
  const DISK_LIMIT_BYTES = DISK_LIMIT_GB * 1024 * 1024 * 1024; // 10Gi in bytes

  export class ResourceMonitor {
    private logInterval: NodeJS.Timeout | null = null;
    private logger: typeof logger;
    private dirName: string;
    private processName: string | undefined;
    private ctx: Context;
    private verbose: boolean;
    private compactLogging: boolean;
    private gcObserver: PerformanceObserver | null = null;
    private bufferedGcEntries: PerformanceEntry[] = [];

    constructor(config: ResourceMonitorConfig) {
      this.logger = logger;
      this.dirName = config.dirName ?? "/tmp";
      this.processName = config.processName;
      this.ctx = config.ctx;
      this.verbose = true;
      this.compactLogging = config.compactLogging ?? false;
    }

    /**
     * Start periodic resource monitoring
     * @param intervalMs Monitoring interval in milliseconds
     */
    startMonitoring(intervalMs = 10000): void {
      if (intervalMs < 1000) {
        intervalMs = 1000;
        this.logger.warn("ResourceMonitor: intervalMs is less than 1000, setting to 1000");
      }

      if (this.logInterval) {
        clearInterval(this.logInterval);
      }

      this.logInterval = setInterval(this.logResources.bind(this), intervalMs);

      this.gcObserver = new PerformanceObserver((list) => {
        this.bufferedGcEntries.push(...list.getEntries());
      });

      this.gcObserver.observe({ entryTypes: ["gc"], buffered: true });
    }

    /**
     * Stop resource monitoring
     */
    stopMonitoring(): void {
      if (this.logInterval) {
        clearInterval(this.logInterval);
        this.logInterval = null;
      }

      if (this.gcObserver) {
        this.gcObserver.disconnect();
        this.gcObserver = null;
      }
    }

    private async logResources() {
      try {
        await this.logResourceSnapshot("ResourceMonitor");
      } catch (error) {
        this.logger.error(
          `Resource monitoring error: ${error instanceof Error ? error.message : String(error)}`
        );
      }
    }

    /**
     * Get combined system metrics (disk and memory)
     */
    private async getSystemMetrics(): Promise<SystemMetrics> {
      const [disk, memory] = await Promise.all([this.getDiskMetrics(), this.getMemoryMetrics()]);
      return { disk, memory };
    }

    /**
     * Get disk space information
     */
    private async getDiskMetrics(): Promise<DiskMetrics> {
      try {
        // Even with permission errors, du will output a total
        const { stdout, stderr } = await execAsync(`du -sb ${this.dirName} || true`);

        // Get the last line of stdout which contains the total
        const lastLine = stdout.split("\n").filter(Boolean).pop() || "";
        const usedBytes = parseInt(lastLine.split("\t")[0], 10);

        const effectiveTotal = DISK_LIMIT_BYTES;
        const effectiveUsed = Math.min(usedBytes, DISK_LIMIT_BYTES);
        const effectiveFree = effectiveTotal - effectiveUsed;
        const percentUsed = (effectiveUsed / effectiveTotal) * 100;

        const metrics: DiskMetrics = {
          total: effectiveTotal,
          used: effectiveUsed,
          free: effectiveFree,
          percentUsed,
        };

        // If we had permission errors, add a warning
        if (stderr.includes("Permission denied") || stderr.includes("cannot access")) {
          metrics.warning = "Some directories were not accessible";
        } else if (stderr.includes("No such file or directory")) {
          metrics.warning = "The directory does not exist";
        }

        return metrics;
      } catch (error) {
        this.logger.error(
          `Error getting disk metrics: ${error instanceof Error ? error.message : String(error)}`
        );
        return {
          free: DISK_LIMIT_BYTES,
          total: DISK_LIMIT_BYTES,
          used: 0,
          percentUsed: 0,
          warning: "Failed to measure disk usage",
        };
      }
    }

    /**
     * Get memory metrics
     */
    private getMemoryMetrics(): MemoryMetrics {
      const total = os.totalmem();
      const free = os.freemem();
      const used = total - free;
      const percentUsed = (used / total) * 100;

      return { total, free, used, percentUsed };
    }

    /**
     * Get process-specific metrics using /proc filesystem
     */
    private async getProcMetrics(pids: number[]): Promise<ProcessInfo[]> {
      return Promise.all(
        pids.map(async (pid) => {
          try {
            // Read process status
            const status = await fs.readFile(`/proc/${pid}/status`, "utf8");
            const cmdline = await fs.readFile(`/proc/${pid}/cmdline`, "utf8");
            const stat = await fs.readFile(`/proc/${pid}/stat`, "utf8");

            // Parse VmRSS (resident set size) from status
            const rss = parseInt(status.match(/VmRSS:\s+(\d+)/)?.[1] ?? "0", 10);
            // Parse VmSize (virtual memory size) from status
            const vsz = parseInt(status.match(/VmSize:\s+(\d+)/)?.[1] ?? "0", 10);
            // Get process owner
            const user = (await fs.stat(`/proc/${pid}`)).uid.toString();

            // Parse CPU stats from /proc/[pid]/stat
            const stats = stat.split(" ");
            const utime = parseInt(stats[13], 10);
            const stime = parseInt(stats[14], 10);
            const starttime = parseInt(stats[21], 10);

            // Calculate CPU percentage
            const totalTime = utime + stime;
            const uptime = os.uptime();
            const hertz = 100; // Usually 100 on Linux
            const elapsedTime = uptime - starttime / hertz;
            const cpuUsage = 100 * (totalTime / hertz / elapsedTime);

            // Calculate memory percentage against total system memory
            const totalMem = os.totalmem();
            const memoryPercent = (rss * 1024 * 100) / totalMem;

            return {
              user,
              pid,
              cpu: cpuUsage,
              mem: memoryPercent,
              vsz,
              rss,
              command: cmdline.replace(/\0/g, " ").trim(),
            };
          } catch (error) {
            return null;
          }
        })
      ).then((results) => results.filter((r): r is ProcessInfo => r !== null));
    }

    /**
     * Find PIDs for a process name using /proc filesystem
     */
    private async findPidsByName(processName?: string): Promise<number[]> {
      if (!processName) {
        return [];
      }

      try {
        const pids: number[] = [];
        const procDirs = await fs.readdir("/proc");

        for (const dir of procDirs) {
          if (!/^\d+$/.test(dir)) continue;

          const processPid = parseInt(dir, 10);

          // Ignore processes that have a lower PID than our own PID
          if (processPid <= process.pid) {
            continue;
          }

          try {
            const cmdline = await fs.readFile(`/proc/${dir}/cmdline`, "utf8");
            if (cmdline.includes(processName)) {
              pids.push(parseInt(dir, 10));
            }
          } catch {
            // Ignore errors reading individual process info
            continue;
          }
        }

        return pids;
      } catch {
        return [];
      }
    }

    /**
     * Get process-specific metrics
     */
    private async getProcessMetrics(): Promise<ProcessMetrics> {
      // Get Node.js process metrics
      const totalMemory = os.totalmem();
      // Convert GB to bytes (machine.memory is in GB)
      const machineMemoryBytes = this.ctx.machine
        ? this.ctx.machine.memory * 1024 * 1024 * 1024
        : totalMemory;
      const nodeMemoryUsage = process.memoryUsage();

      // Node process percentage is based on machine memory if available, otherwise system memory
      const nodeMemoryPercent = (nodeMemoryUsage.rss / machineMemoryBytes) * 100;
      const heapStats = getHeapStatistics();

      const nodeMetrics: NodeProcessMetrics = {
        memoryUsage: nodeMemoryUsage.rss,
        memoryUsagePercent: nodeMemoryPercent,
        heapUsed: nodeMemoryUsage.heapUsed,
        heapSizeLimit: heapStats.heap_size_limit,
        heapUsagePercent: (heapStats.used_heap_size / heapStats.heap_size_limit) * 100,
        availableHeap: heapStats.total_available_size,
        isNearHeapLimit: heapStats.used_heap_size / heapStats.heap_size_limit > 0.8,
      };

      let method = "ps";

      try {
        let processes: ProcessInfo[] = [];

        // Try ps first, fall back to /proc if it fails
        try {
          const { stdout: psOutput } = await execAsync(
            `ps aux | grep ${this.processName} | grep -v grep`
          );

          if (psOutput.trim()) {
            processes = psOutput
              .trim()
              .split("\n")
              .filter((line) => {
                const parts = line.trim().split(/\s+/);
                const pid = parseInt(parts[1], 10);

                // Ignore processes that have a lower PID than our own PID
                return pid > process.pid;
              })
              .map((line) => {
                const parts = line.trim().split(/\s+/);
                return {
                  user: parts[0],
                  pid: parseInt(parts[1], 10),
                  cpu: parseFloat(parts[2]),
                  mem: parseFloat(parts[3]),
                  vsz: parseInt(parts[4], 10),
                  rss: parseInt(parts[5], 10),
                  command: parts.slice(10).join(" "),
                };
              });
          }
        } catch {
          // ps failed, try /proc instead
          method = "proc";
          const pids = await this.findPidsByName(this.processName);
          processes = await this.getProcMetrics(pids);
        }

        if (processes.length === 0) {
          return {
            node: nodeMetrics,
            targetProcess: this.processName
              ? {
                  method,
                  processName: this.processName,
                  count: 0,
                  processes: [],
                  averages: null,
                  totals: null,
                }
              : null,
          };
        }

        // For CPU:
        // - ps shows CPU percentage per core (e.g., 100% = 1 core)
        // - machine.cpu is in cores (e.g., 0.5 = half a core)
        // - we want to show percentage of allocated CPU (e.g., 100% = using all allocated CPU)
        const availableCpu = this.ctx.machine?.cpu ?? os.cpus().length;
        const cpuNormalizer = availableCpu * 100; // Convert to basis points for better precision with fractional CPUs

        // For Memory:
        // - ps 'mem' is already a percentage of system memory
        // - we need to convert it to a percentage of machine memory
        // - if machine memory is 0.5GB and system has 16GB, we multiply the percentage by 32
        const memoryScaleFactor = this.ctx.machine ? totalMemory / machineMemoryBytes : 1;

        const totals = processes.reduce(
          (acc, proc) => ({
            cpu: acc.cpu + proc.cpu,
            // Scale memory percentage to machine memory
            // TODO: test this
            memory: acc.memory + proc.mem * memoryScaleFactor,
            rss: acc.rss + proc.rss,
            vsz: acc.vsz + proc.vsz,
          }),
          { cpu: 0, memory: 0, rss: 0, vsz: 0 }
        );

        const count = processes.length;

        const averages = {
          cpu: totals.cpu / (count * cpuNormalizer),
          memory: totals.memory / count,
          rss: totals.rss / count,
          vsz: totals.vsz / count,
        };

        return {
          node: nodeMetrics,
          targetProcess: this.processName
            ? {
                method,
                processName: this.processName,
                count,
                processes,
                averages,
                totals: {
                  cpu: totals.cpu / cpuNormalizer,
                  memory: totals.memory,
                  rss: totals.rss,
                  vsz: totals.vsz,
                },
              }
            : null,
        };
      } catch (error) {
        return {
          node: nodeMetrics,
          targetProcess: this.processName
            ? {
                method,
                processName: this.processName,
                count: 0,
                processes: [],
                averages: null,
                totals: null,
              }
            : null,
        };
      }
    }

    /**
     * Log a snapshot of current resource usage
     */
    async logResourceSnapshot(label = "Resource Snapshot"): Promise<void> {
      try {
        const payload = await this.getResourceSnapshotPayload();
        const enhancedLabel = this.compactLogging
          ? this.createCompactLabel(payload, label)
          : this.createEnhancedLabel(payload, label);

        if (payload.process.node.isNearHeapLimit) {
          this.logger.warn(`${enhancedLabel}: Node is near heap limit`, payload);
        } else {
          this.logger.info(enhancedLabel, payload);
        }
      } catch (error) {
        this.logger.error(
          `Error logging resource snapshot: ${error instanceof Error ? error.message : String(error)}`
        );
      }
    }

    /**
     * Create an enhanced log label with key metrics for quick scanning
     */
    private createEnhancedLabel(payload: any, baseLabel: string): string {
      const parts: string[] = [baseLabel];

      // System resources with text indicators
      const diskPercent = parseFloat(payload.system.disk.percentUsed);
      const memoryPercent = parseFloat(payload.system.memory.percentUsed);
      const diskIndicator = this.getTextIndicator(diskPercent, 80, 90);
      const memIndicator = this.getTextIndicator(memoryPercent, 80, 90);
      parts.push(`Disk:${diskPercent.toFixed(1).padStart(5)}%${diskIndicator}`);
      parts.push(`Mem:${memoryPercent.toFixed(1).padStart(5)}%${memIndicator}`);

      // Node process metrics with text indicators
      const nodeMemPercent = parseFloat(payload.process.node.memoryUsagePercent);
      const heapPercent = parseFloat(payload.process.node.heapUsagePercent);
      const nodeIndicator = this.getTextIndicator(nodeMemPercent, 70, 85);
      const heapIndicator = this.getTextIndicator(heapPercent, 70, 85);
      parts.push(`Node:${nodeMemPercent.toFixed(1).padStart(4)}%${nodeIndicator}`);
      parts.push(`Heap:${heapPercent.toFixed(1).padStart(4)}%${heapIndicator}`);

      // Target process metrics (if available)
      if (payload.process.targetProcess && payload.process.targetProcess.count > 0) {
        const targetCpu = payload.process.targetProcess.totals?.cpuPercent || "0";
        const targetMem = payload.process.targetProcess.totals?.memoryPercent || "0";
        const targetCpuNum = parseFloat(targetCpu);
        const targetMemNum = parseFloat(targetMem);
        const cpuIndicator = this.getTextIndicator(targetCpuNum, 80, 90);
        const memIndicator = this.getTextIndicator(targetMemNum, 80, 90);
        parts.push(
          `${payload.process.targetProcess.processName}:${targetCpu.padStart(
            4
          )}%${cpuIndicator}/${targetMem.padStart(4)}%${memIndicator}`
        );
      }

      // GC activity with performance indicators
      if (payload.gc && payload.gc.count > 0) {
        const avgDuration = payload.gc.avgDuration;
        const gcIndicator = this.getTextIndicator(avgDuration, 5, 10, true);
        parts.push(
          `GC:${payload.gc.count.toString().padStart(2)}(${avgDuration
            .toFixed(1)
            .padStart(4)}ms)${gcIndicator}`
        );
      }

      // Machine constraints
      if (payload.constraints) {
        parts.push(`[${payload.constraints.cpu}CPU/${payload.constraints.memoryGB}GB]`);
      }

      // Warning indicators (only show critical ones in the main label)
      const criticalWarnings: string[] = [];
      if (payload.process.node.isNearHeapLimit) criticalWarnings.push("HEAP_LIMIT");
      if (diskPercent > 90) criticalWarnings.push("DISK_CRITICAL");
      if (memoryPercent > 95) criticalWarnings.push("MEM_CRITICAL");
      if (payload.system.disk.warning) criticalWarnings.push("DISK_WARN");

      if (criticalWarnings.length > 0) {
        parts.push(`[${criticalWarnings.join(",")}]`);
      }

      return parts.join(" | ");
    }

    /**
     * Get text-based indicator for percentage values
     */
    private getTextIndicator(
      value: number,
      warningThreshold: number,
      criticalThreshold: number,
      isDuration = false
    ): string {
      if (isDuration) {
        // For duration values, higher is worse
        if (value >= criticalThreshold) return " [CRIT]";
        if (value >= warningThreshold) return " [WARN]";
        return " [OK]";
      } else {
        // For percentage values, higher is worse
        if (value >= criticalThreshold) return " [CRIT]";
        if (value >= warningThreshold) return " [WARN]";
        return " [OK]";
      }
    }

    /**
     * Create a compact version of the enhanced label for high-frequency logging
     */
    private createCompactLabel(payload: any, baseLabel: string): string {
      const parts: string[] = [baseLabel];

      // Only show critical metrics in compact mode
      const diskPercent = parseFloat(payload.system.disk.percentUsed);
      const memoryPercent = parseFloat(payload.system.memory.percentUsed);
      const heapPercent = parseFloat(payload.process.node.heapUsagePercent);

      // Use single character indicators for compactness
      const diskIndicator = diskPercent > 90 ? "!" : diskPercent > 80 ? "?" : ".";
      const memIndicator = memoryPercent > 95 ? "!" : memoryPercent > 80 ? "?" : ".";
      const heapIndicator = heapPercent > 85 ? "!" : heapPercent > 70 ? "?" : ".";

      parts.push(`D:${diskPercent.toFixed(0).padStart(2)}%${diskIndicator}`);
      parts.push(`M:${memoryPercent.toFixed(0).padStart(2)}%${memIndicator}`);
      parts.push(`H:${heapPercent.toFixed(0).padStart(2)}%${heapIndicator}`);

      // GC activity (only if significant)
      if (payload.gc && payload.gc.count > 0 && payload.gc.avgDuration > 2) {
        const gcIndicator =
          payload.gc.avgDuration > 10 ? "!" : payload.gc.avgDuration > 5 ? "?" : ".";
        parts.push(`GC:${payload.gc.count}${gcIndicator}`);
      }

      return parts.join(" ");
    }

    async getResourceSnapshotPayload() {
      const [systemMetrics, processMetrics] = await Promise.all([
        this.getSystemMetrics(),
        this.getProcessMetrics(),
      ]);

      const gcSummary = summarizeGCEntries(this.bufferedGcEntries);
      this.bufferedGcEntries = [];

      const formatBytes = (bytes: number) => (bytes / (1024 * 1024)).toFixed(2);
      const formatPercent = (value: number) => value.toFixed(1);

      return {
        system: {
          disk: {
            limitGiB: DISK_LIMIT_GB,
            dirName: this.dirName,
            usedGiB: (systemMetrics.disk.used / (1024 * 1024 * 1024)).toFixed(2),
            freeGiB: (systemMetrics.disk.free / (1024 * 1024 * 1024)).toFixed(2),
            percentUsed: formatPercent(systemMetrics.disk.percentUsed),
            warning: systemMetrics.disk.warning,
          },
          memory: {
            freeGB: (systemMetrics.memory.free / (1024 * 1024 * 1024)).toFixed(2),
            percentUsed: formatPercent(systemMetrics.memory.percentUsed),
          },
        },
        gc: gcSummary,
        constraints: this.ctx.machine
          ? {
              cpu: this.ctx.machine.cpu,
              memoryGB: this.ctx.machine.memory,
              diskGB: DISK_LIMIT_BYTES / (1024 * 1024 * 1024),
            }
          : {
              cpu: os.cpus().length,
              memoryGB: Math.floor(os.totalmem() / (1024 * 1024 * 1024)),
              note: "Using system resources (no machine constraints specified)",
            },
        process: {
          node: {
            memoryUsageMB: formatBytes(processMetrics.node.memoryUsage),
            memoryUsagePercent: formatPercent(processMetrics.node.memoryUsagePercent),
            heapUsedMB: formatBytes(processMetrics.node.heapUsed),
            heapSizeLimitMB: formatBytes(processMetrics.node.heapSizeLimit),
            heapUsagePercent: formatPercent(processMetrics.node.heapUsagePercent),
            availableHeapMB: formatBytes(processMetrics.node.availableHeap),
            isNearHeapLimit: processMetrics.node.isNearHeapLimit,
            ...(this.verbose
              ? {
                  heapStats: getHeapStatistics(),
                }
              : {}),
          },
          targetProcess: processMetrics.targetProcess
            ? {
                method: processMetrics.targetProcess.method,
                processName: processMetrics.targetProcess.processName,
                count: processMetrics.targetProcess.count,
                averages: processMetrics.targetProcess.averages
                  ? {
                      cpuPercent: formatPercent(processMetrics.targetProcess.averages.cpu * 100),
                      memoryPercent: formatPercent(processMetrics.targetProcess.averages.memory),
                      rssMB: formatBytes(processMetrics.targetProcess.averages.rss * 1024),
                      vszMB: formatBytes(processMetrics.targetProcess.averages.vsz * 1024),
                    }
                  : null,
                totals: processMetrics.targetProcess.totals
                  ? {
                      cpuPercent: formatPercent(processMetrics.targetProcess.totals.cpu * 100),
                      memoryPercent: formatPercent(processMetrics.targetProcess.totals.memory),
                      rssMB: formatBytes(processMetrics.targetProcess.totals.rss * 1024),
                      vszMB: formatBytes(processMetrics.targetProcess.totals.vsz * 1024),
                    }
                  : null,
              }
            : null,
        },
        timestamp: new Date().toISOString(),
      };
    }
  }

  function summarizeGCEntries(entries: PerformanceEntry[]): GCSummary {
    if (entries.length === 0) {
      return {
        count: 0,
        totalDuration: 0,
        avgDuration: 0,
        maxDuration: 0,
        kinds: {},
      };
    }

    let totalDuration = 0;
    let maxDuration = 0;
    const kinds: Record<string, { count: number; totalDuration: number; maxDuration: number }> = {};

    for (const e of entries) {
      const duration = e.duration;
      totalDuration += duration;
      if (duration > maxDuration) maxDuration = duration;

      const kind = kindName((e as any)?.detail?.kind ?? "unknown");
      if (!kinds[kind]) {
        kinds[kind] = { count: 0, totalDuration: 0, maxDuration: 0 };
      }
      kinds[kind].count += 1;
      kinds[kind].totalDuration += duration;
      if (duration > kinds[kind].maxDuration) kinds[kind].maxDuration = duration;
    }

    // finalize averages
    const avgDuration = totalDuration / entries.length;
    const kindsWithAvg: GCSummary["kinds"] = {};
    for (const [kind, stats] of Object.entries(kinds)) {
      kindsWithAvg[kind] = {
        count: stats.count,
        totalDuration: stats.totalDuration,
        avgDuration: stats.totalDuration / stats.count,
        maxDuration: stats.maxDuration,
      };
    }

    return {
      count: entries.length,
      totalDuration,
      avgDuration,
      maxDuration,
      kinds: kindsWithAvg,
    };
  }

  const kindName = (k: number | string) => {
    if (typeof k === "number") {
      return (
        {
          [constants.NODE_PERFORMANCE_GC_MAJOR]: "major",
          [constants.NODE_PERFORMANCE_GC_MINOR]: "minor",
          [constants.NODE_PERFORMANCE_GC_INCREMENTAL]: "incremental",
          [constants.NODE_PERFORMANCE_GC_WEAKCB]: "weak-cb",
        }[k] ?? `kind:${k}`
      );
    }
    return k;
  };
  ```
</Accordion>

Then, in your task, you can create an instance of the `ResourceMonitor` class and start monitoring memory, disk, and CPU usage:

```ts /src/trigger/example.ts theme={null}
import { task, logger, wait } from "@trigger.dev/sdk";
import { ResourceMonitor } from "../resourceMonitor.js";

// Middleware to enable the resource monitor
tasks.middleware("resource-monitor", async ({ ctx, next }) => {
  const resourceMonitor = new ResourceMonitor({
    ctx,
  });

  // Only enable the resource monitor if the environment variable is set
  if (process.env.RESOURCE_MONITOR_ENABLED === "1") {
    resourceMonitor.startMonitoring(1_000);
  }

  await next();

  resourceMonitor.stopMonitoring();
});

export const resourceMonitorTest = task({
  id: "resource-monitor-test",
  run: async (payload: any, { ctx }) => {
    const interval = createMemoryPressure();

    await setTimeout(180_000);

    clearInterval(interval);

    return {
      message: "Hello, resources!",
    };
  },
});
```

This will produce logs that look like this:

<img src="https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=3a64b733bd0da3afa0586b4927021655" alt="Resource monitor logs" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="images/machines-resource-monitor-logs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=280&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=0a96fa6cbe4be566eb6fcc1372d22ba0 280w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=560&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=93d9d1599c03b63a0b9c9409c73aedf6 560w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=840&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=452c9301db3e604f01c9c95e92f02897 840w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=1100&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=d0e3899942fa65289681ae353b2d0c2b 1100w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=1650&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=8cf2b9e6b5ecf3b71530696e004d23f0 1650w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-logs.png?w=2500&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=b565ef6b5295ce0d44fa6feba31ff143 2500w" />

If you are spawning a child process and you want to monitor its memory usage, you can pass the `processName` option to the `ResourceMonitor` class:

```ts /src/trigger/example.ts theme={null}
const resourceMonitor = new ResourceMonitor({
  ctx,
  processName: "ffmpeg",
});
```

This will produce logs that includes the memory and CPU usage of the `ffmpeg` process:

<img src="https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=c89a4f855cd01efc4a6576a6e9b0924b" alt="Resource monitor logs" data-og-width="3680" width="3680" data-og-height="2382" height="2382" data-path="images/machines-resource-monitor-ffmpeg.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=280&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=240ae6d3a7bb4590777ee9f7e7385571 280w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=560&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=5446bdac18860b6f49b4fef3c42c4e93 560w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=840&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=55e1f132b35dfe02908e827e27c1043e 840w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=1100&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=9ac56d77bc3dffb83c47702e58f2ad6c 1100w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=1650&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=e4adac801ecd3acab797f22213fdfa48 1650w, https://mintcdn.com/trigger/TySlE0a_RvppyBcX/images/machines-resource-monitor-ffmpeg.png?w=2500&fit=max&auto=format&n=TySlE0a_RvppyBcX&q=85&s=d1a412cdf3a968599f08fb27deaf4007 2500w" />

### Explicit OOM errors

You can explicitly throw an Out Of Memory error in your task. This can be useful if you use a native package that detects it's going to run out of memory and then stops before it runs out. If you can detect this, you can then throw this error.

```ts /trigger/heavy-task.ts theme={null}
import { task } from "@trigger.dev/sdk";
import { OutOfMemoryError } from "@trigger.dev/sdk";

export const yourTask = task({
  id: "your-task",
  machine: "medium-1x",
  run: async (payload: any, { ctx }) => {
    //...

    throw new OutOfMemoryError();
  },
});
```

If OOM errors happen regularly you need to either optimize the memory-efficiency of your code, or increase the machine.

### Retrying with a larger machine

If you are seeing rare OOM errors, it might make sense to add a setting to your task to retry with a large machine when an OOM happens:

```ts /trigger/heavy-task.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const yourTask = task({
  id: "your-task",
  machine: "medium-1x",
  retry: {
    outOfMemory: {
      machine: "large-1x",
    },
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

<Note>
  This will only retry the task if you get an OOM error. It won't permanently change the machine
  that a new run starts on, so if you consistently see OOM errors you should change the machine in
  the `machine` property.
</Note>


# Advanced usage
Source: https://trigger.dev/docs/management/advanced-usage

Advanced usage of the Trigger.dev management API

### Accessing raw HTTP responses

All API methods return a `Promise` subclass `ApiPromise` that includes helpers for accessing the underlying HTTP response:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

async function main() {
  const { data: run, response: raw } = await runs.retrieve("run_1234").withResponse();

  console.log(raw.status);
  console.log(raw.headers);

  const response = await runs.retrieve("run_1234").asResponse(); // Returns a Response object

  console.log(response.status);
  console.log(response.headers);
}
```


# Authentication
Source: https://trigger.dev/docs/management/authentication

Authenticating with the Trigger.dev management API

There are two methods of authenticating with the management API: using a secret key associated with a specific environment in a project (`secretKey`), or using a personal access token (`personalAccessToken`). Both methods should only be used in a backend server, as they provide full access to the project.

<Note>
  There is a separate authentication strategy when making requests from your frontend application.
  See the [Realtime guide](/realtime/overview) for more information. This guide is for backend usage
  only.
</Note>

Certain API functions work with both authentication methods, but require different arguments depending on the method used. For example, the `runs.list` function can be called using either a `secretKey` or a `personalAccessToken`, but the `projectRef` argument is required when using a `personalAccessToken`:

```ts  theme={null}
import { configure, runs } from "@trigger.dev/sdk";

// Using secretKey authentication
configure({
  secretKey: process.env["TRIGGER_SECRET_KEY"], // starts with tr_dev_ or tr_prod_
});

function secretKeyExample() {
  return runs.list({
    limit: 10,
    status: ["COMPLETED"],
  });
}

// Using personalAccessToken authentication
configure({
  secretKey: process.env["TRIGGER_ACCESS_TOKEN"], // starts with tr_pat_
});

function personalAccessTokenExample() {
  // Notice the projectRef argument is required when using a personalAccessToken
  return runs.list("prof_1234", {
    limit: 10,
    status: ["COMPLETED"],
    projectRef: "tr_proj_1234567890",
  });
}
```

<Accordion title="View endpoint support">
  Consult the following table to see which endpoints support each authentication method.

  | Endpoint               | Secret key | Personal Access Token |
  | ---------------------- | ---------- | --------------------- |
  | `task.trigger`         | âœ…          |                       |
  | `task.batchTrigger`    | âœ…          |                       |
  | `runs.list`            | âœ…          | âœ…                     |
  | `runs.retrieve`        | âœ…          |                       |
  | `runs.cancel`          | âœ…          |                       |
  | `runs.replay`          | âœ…          |                       |
  | `envvars.list`         | âœ…          | âœ…                     |
  | `envvars.retrieve`     | âœ…          | âœ…                     |
  | `envvars.upload`       | âœ…          | âœ…                     |
  | `envvars.create`       | âœ…          | âœ…                     |
  | `envvars.update`       | âœ…          | âœ…                     |
  | `envvars.del`          | âœ…          | âœ…                     |
  | `schedules.list`       | âœ…          |                       |
  | `schedules.create`     | âœ…          |                       |
  | `schedules.retrieve`   | âœ…          |                       |
  | `schedules.update`     | âœ…          |                       |
  | `schedules.activate`   | âœ…          |                       |
  | `schedules.deactivate` | âœ…          |                       |
  | `schedules.del`        | âœ…          |                       |
</Accordion>

### Secret key

Secret key authentication scopes the API access to a specific environment in a project, and works with certain endpoints. You can read our [API Keys guide](/apikeys) for more information.

### Personal Access Token (PAT)

A PAT is a token associated with a specific user, and gives access to all the orgs, projects, and environments that the user has access to. You can identify a PAT by the `tr_pat_` prefix. Because a PAT does not scope access to a specific environment, you must provide the `projectRef` argument when using a PAT (and sometimes the environment as well).

For example, when uploading environment variables using a PAT, you must provide the `projectRef` and `environment` arguments:

```ts  theme={null}
import { configure, envvars } from "@trigger.dev/sdk";

configure({
  secretKey: process.env["TRIGGER_ACCESS_TOKEN"], // starts with tr_pat_
});

await envvars.upload("proj_1234", "dev", {
  variables: {
    MY_ENV_VAR: "MY_ENV_VAR_VALUE",
  },
  override: true,
});
```

### Preview branch targeting

When working with preview branches, you may need to target a specific branch when making API calls. This is particularly useful for managing environment variables or other resources that are scoped to individual preview branches.

<Tabs>
  <Tab title="SDK">
    To target a specific preview branch, include the `previewBranch` option in your SDK configuration:

    ```ts  theme={null}
    import { configure, envvars } from "@trigger.dev/sdk";

    configure({
      secretKey: process.env["TRIGGER_ACCESS_TOKEN"], // starts with tr_pat_
      previewBranch: "feature-xyz",
    });

    await envvars.update("proj_1234", "preview", "DATABASE_URL", {
      value: "your_preview_database_url",
    });
    ```
  </Tab>

  <Tab title="cURL">
    To target a specific preview branch, include the `x-trigger-branch` header in your API requests with the branch name as the value:

    ```bash  theme={null}
    curl --request PUT \
      --url https://api.trigger.dev/api/v1/projects/{projectRef}/envvars/preview/DATABASE_URL \
      --header 'Authorization: Bearer <token>' \
      --header 'x-trigger-branch: feature-xyz' \
      --header 'Content-Type: application/json' \
      --data '{
        "value": "your_preview_database_url"
      }'
    ```
  </Tab>
</Tabs>

This will set the `DATABASE_URL` environment variable specifically for the `feature-xyz` preview branch.

<Note>
  The `x-trigger-branch` header is only relevant when working with the `preview` environment (`{env}
    ` parameter set to `preview`). It has no effect when working with `dev`, `staging`, or `prod`
  environments.
</Note>

#### SDK usage with preview branches

When using the SDK to manage preview branch environment variables, the branch targeting is handled automatically when you're running in a preview environment with the `TRIGGER_PREVIEW_BRANCH` environment variable set. However, you can also specify the branch explicitly:

```ts  theme={null}
import { configure, envvars } from "@trigger.dev/sdk";

configure({
  secretKey: process.env["TRIGGER_ACCESS_TOKEN"], // starts with tr_pat_
  previewBranch: "feature-xyz", // Optional: specify the branch
});

await envvars.update("proj_1234", "preview", "DATABASE_URL", {
  value: "your_preview_database_url",
});
```


# Auto-pagination
Source: https://trigger.dev/docs/management/auto-pagination

Using auto-pagination with the Trigger.dev management API

All list endpoints in the management API support auto-pagination.
You can use `for await â€¦ of` syntax to iterate through items across all pages:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

async function fetchAllRuns() {
  const allRuns = [];

  for await (const run of runs.list({ limit: 10 })) {
    allRuns.push(run);
  }

  return allRuns;
}
```

You can also use helpers on the return value from any `list` method to get the next/previous page of results:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

async function main() {
  let page = await runs.list({ limit: 10 });

  for (const run of page.data) {
    console.log(run);
  }

  while (page.hasNextPage()) {
    page = await page.getNextPage();
    // ... do something with the next page
  }
}
```


# Create Env Var
Source: https://trigger.dev/docs/management/envvars/create

v3-openapi POST /api/v1/projects/{projectRef}/envvars/{env}
Create a new environment variable for a specific project and environment.



# Delete Env Var
Source: https://trigger.dev/docs/management/envvars/delete

v3-openapi DELETE /api/v1/projects/{projectRef}/envvars/{env}/{name}
Delete a specific environment variable for a specific project and environment.



# Import Env Vars
Source: https://trigger.dev/docs/management/envvars/import

v3-openapi POST /api/v1/projects/{projectRef}/envvars/{env}/import
Upload mulitple environment variables for a specific project and environment.



# List Env Vars
Source: https://trigger.dev/docs/management/envvars/list

v3-openapi GET /api/v1/projects/{projectRef}/envvars/{env}
List all environment variables for a specific project and environment.



# Retrieve Env Var
Source: https://trigger.dev/docs/management/envvars/retrieve

v3-openapi GET /api/v1/projects/{projectRef}/envvars/{env}/{name}
Retrieve a specific environment variable for a specific project and environment.



# Update Env Var
Source: https://trigger.dev/docs/management/envvars/update

v3-openapi PUT /api/v1/projects/{projectRef}/envvars/{env}/{name}
Update a specific environment variable for a specific project and environment.



# Errors and retries
Source: https://trigger.dev/docs/management/errors-and-retries

Handling errors and retries with the Trigger.dev management API

## Handling errors

When the SDK method is unable to connect to the API server, or the API server returns a non-successful response, the SDK will throw an `ApiError` that you can catch and handle:

```ts  theme={null}
import { runs, APIError } from "@trigger.dev/sdk";

async function main() {
  try {
    const run = await runs.retrieve("run_1234");
  } catch (error) {
    if (error instanceof ApiError) {
      console.error(`API error: ${error.status}, ${error.headers}, ${error.body}`);
    } else {
      console.error(`Unknown error: ${error.message}`);
    }
  }
}
```

## Retries

The SDK will automatically retry requests that fail due to network errors or server errors. By default, the SDK will retry requests up to 3 times, with an exponential backoff delay between retries.

You can customize the retry behavior by passing a `requestOptions` option to the `configure` function:

```ts  theme={null}
import { configure } from "@trigger.dev/sdk";

configure({
  requestOptions: {
    retry: {
      maxAttempts: 5,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 5000,
      factor: 1.8,
      randomize: true,
    },
  },
});
```

All SDK functions also take a `requestOptions` parameter as the last argument, which can be used to customize the request options. You can use this to disable retries for a specific request:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

async function main() {
  const run = await runs.retrieve("run_1234", {
    retry: {
      maxAttempts: 1, // Disable retries
    },
  });
}
```

<Note>
  When running inside a task, the SDK ignores customized retry options for certain functions (e.g.,
  `task.trigger`, `task.batchTrigger`), and uses retry settings optimized for task execution.
</Note>


# Overview
Source: https://trigger.dev/docs/management/overview

Using the Trigger.dev management API

## Installation

The management API is available through the same `@trigger.dev/sdk` package used in defining and triggering tasks. If you have already installed the package in your project, you can skip this step.

<CodeGroup>
  ```bash npm theme={null}
  npm i @trigger.dev/sdk@latest
  ```

  ```bash pnpm theme={null}
  pnpm add @trigger.dev/sdk@latest
  ```

  ```bash yarn theme={null}
  yarn add @trigger.dev/sdk@latest
  ```
</CodeGroup>

## Usage

All `v3` functionality is provided through the `@trigger.dev/sdk` module. You can import the entire module or individual resources as needed.

```ts  theme={null}
import { configure, runs } from "@trigger.dev/sdk";

configure({
  // this is the default and if the `TRIGGER_SECRET_KEY` environment variable is set, can omit calling configure
  secretKey: process.env["TRIGGER_SECRET_KEY"],
});

async function main() {
  const runs = await runs.list({
    limit: 10,
    status: ["COMPLETED"],
  });
}

main().catch(console.error);
```


# Cancel run
Source: https://trigger.dev/docs/management/runs/cancel

v3-openapi POST /api/v2/runs/{runId}/cancel
Cancels an in-progress run. If the run is already completed, this will have no effect.



# List runs
Source: https://trigger.dev/docs/management/runs/list

v3-openapi GET /api/v1/runs
List runs in a specific environment. You can filter the runs by status, created at, task identifier, version, and more.



# Replay run
Source: https://trigger.dev/docs/management/runs/replay

v3-openapi POST /api/v1/runs/{runId}/replay
Creates a new run with the same payload and options as the original run.



# Reschedule run
Source: https://trigger.dev/docs/management/runs/reschedule

v3-openapi POST /api/v1/runs/{runId}/reschedule
Updates a delayed run with a new delay. Only valid when the run is in the DELAYED state.



# Retrieve run
Source: https://trigger.dev/docs/management/runs/retrieve

v3-openapi GET /api/v3/runs/{runId}
Retrieve information about a run, including its status, payload, output, and attempts. If you authenticate with a Public API key, we will omit the payload and output fields for security reasons.




# Update metadata
Source: https://trigger.dev/docs/management/runs/update-metadata

v3-openapi PUT /api/v1/runs/{runId}/metadata
Update the metadata of a run.



# Activate Schedule
Source: https://trigger.dev/docs/management/schedules/activate

v3-openapi POST /api/v1/schedules/{schedule_id}/activate
Activate a schedule by its ID. This will only work on `IMPERATIVE` schedules that were created in the dashboard or using the imperative SDK functions like `schedules.create()`.



# Create Schedule
Source: https://trigger.dev/docs/management/schedules/create

v3-openapi POST /api/v1/schedules
Create a new `IMPERATIVE` schedule based on the specified options.



# Deactivate Schedule
Source: https://trigger.dev/docs/management/schedules/deactivate

v3-openapi POST /api/v1/schedules/{schedule_id}/deactivate
Deactivate a schedule by its ID. This will only work on `IMPERATIVE` schedules that were created in the dashboard or using the imperative SDK functions like `schedules.create()`.



# Delete Schedule
Source: https://trigger.dev/docs/management/schedules/delete

v3-openapi DELETE /api/v1/schedules/{schedule_id}
Delete a schedule by its ID. This will only work on `IMPERATIVE` schedules that were created in the dashboard or using the imperative SDK functions like `schedules.create()`.



# List Schedules
Source: https://trigger.dev/docs/management/schedules/list

v3-openapi GET /api/v1/schedules
List all schedules. You can also paginate the results.



# Retrieve Schedule
Source: https://trigger.dev/docs/management/schedules/retrieve

v3-openapi GET /api/v1/schedules/{schedule_id}
Get a schedule by its ID.



# Get timezones
Source: https://trigger.dev/docs/management/schedules/timezones

v3-openapi GET /api/v1/timezones
Get all supported timezones that schedule tasks support.



# Update Schedule
Source: https://trigger.dev/docs/management/schedules/update

v3-openapi PUT /api/v1/schedules/{schedule_id}
Update a schedule by its ID. This will only work on `IMPERATIVE` schedules that were created in the dashboard or using the imperative SDK functions like `schedules.create()`.



# Batch trigger
Source: https://trigger.dev/docs/management/tasks/batch-trigger

v3-openapi POST /api/v1/tasks/batch
Batch trigger tasks with up to 500 payloads.



# Trigger
Source: https://trigger.dev/docs/management/tasks/trigger

v3-openapi POST /api/v1/tasks/{taskIdentifier}/trigger
Trigger a task by its identifier.



# Manual setup
Source: https://trigger.dev/docs/manual-setup

How to manually setup Trigger.dev in your project.

This guide covers how to manually set up Trigger.dev in your project, including configuration for different package managers, monorepos, and build extensions. This guide replicates all the steps performed by the `trigger.dev init` command. Follow our [Quickstart](/quick-start) for a more streamlined setup.

## Prerequisites

* Node.js 18.20+ (or Bun runtime)
* A Trigger.dev account (sign up at [trigger.dev](https://trigger.dev))
* TypeScript 5.0.4 or later (for TypeScript projects)

## CLI Authentication

Before setting up your project, you need to authenticate the CLI with Trigger.dev:

```bash  theme={null}
# Login to Trigger.dev
npx trigger.dev@latest login

# Or with a specific API URL (for self-hosted instances)
npx trigger.dev@latest login --api-url https://your-trigger-instance.com
```

This will open your browser to authenticate. Once authenticated, you'll need to select or create a project in the Trigger.dev dashboard to get your project reference (e.g., `proj_abc123`).

## Package installation

Install the required packages based on your package manager:

<CodeGroup>
  ```bash npm theme={null}
  npm add @trigger.dev/sdk@latest
  npm add --save-dev @trigger.dev/build@latest
  ```

  ```bash pnpm theme={null}
  pnpm add @trigger.dev/sdk@latest
  pnpm add -D @trigger.dev/build@latest
  ```

  ```bash yarn theme={null}
  yarn add @trigger.dev/sdk@latest
  yarn add -D @trigger.dev/build@latest
  ```

  ```bash bun theme={null}
  bun add @trigger.dev/sdk@latest
  bun add -D @trigger.dev/build@latest
  ```
</CodeGroup>

## Environment variables

For local development, you need to set up the `TRIGGER_SECRET_KEY` environment variable. This key authenticates your application with Trigger.dev.

1. Go to your project dashboard in Trigger.dev
2. Navigate to the "API Keys" page
3. Copy the **DEV** secret key
4. Add it to your local environment file:

```bash  theme={null}
TRIGGER_SECRET_KEY=tr_dev_xxxxxxxxxx
```

### Self-hosted instances

If you're using a self-hosted Trigger.dev instance, also set:

```bash  theme={null}
TRIGGER_API_URL=https://your-trigger-instance.com
```

## CLI setup

You can run the Trigger.dev CLI in two ways:

### Option 1: Using npx/pnpm dlx/yarn dlx

```bash  theme={null}
# npm
npx trigger.dev@latest dev

# pnpm
pnpm dlx trigger.dev@latest dev

# yarn
yarn dlx trigger.dev@latest dev
```

### Option 2: Add as dev dependency

Add the CLI to your `package.json`:

```json  theme={null}
{
  "devDependencies": {
    "trigger.dev": "^4.0.0"
  }
}
```

Then add scripts to your `package.json`:

```json  theme={null}
{
  "scripts": {
    "dev:trigger": "trigger dev",
    "deploy:trigger": "trigger deploy"
  }
}
```

### Version pinning

Make sure to pin the version of the CLI to the same version as the SDK that you are using:

```json  theme={null}
"devDependencies": {
  "trigger.dev": "^4.0.0",
  "@trigger.dev/build": "^4.0.0"
},
"dependencies": {
  "@trigger.dev/sdk": "^4.0.0"
}
```

While running the CLI `dev` or `deploy` commands, the CLI will automatically detect mismatched versions and warn you.

## Configuration file

Create a `trigger.config.ts` file in your project root (or `trigger.config.mjs` for JavaScript projects):

```typescript  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  // Your project ref from the Trigger.dev dashboard
  project: "<your-project-ref>", // e.g., "proj_abc123"

  // Directories containing your tasks
  dirs: ["./src/trigger"], // Customize based on your project structure

  // Retry configuration
  retries: {
    enabledInDev: false, // Enable retries in development
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },

  // Build configuration (optional)
  build: {
    extensions: [], // Build extensions go here
  },

  // Max duration of a task in seconds
  maxDuration: 3600,
});
```

### Using the Bun runtime

By default, Trigger.dev will use the Node.js runtime. If you're using Bun, you can specify the runtime:

```typescript  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<your-project-ref>",
  runtime: "bun",
  dirs: ["./src/trigger"],
});
```

See our [Bun runtime documentation](/guides/frameworks/bun) for more information.

## Add your first task

Create a `trigger` directory (matching the `dirs` in your config) and add an example task:

```typescript src/trigger/example.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const helloWorld = task({
  id: "hello-world",
  run: async (payload: { name: string }) => {
    console.log(`Hello ${payload.name}!`);

    return {
      message: `Hello ${payload.name}!`,
      timestamp: new Date().toISOString(),
    };
  },
});
```

See our [Tasks](/tasks/overview) docs for more information on how to create tasks.

## TypeScript config

If you're using TypeScript, add `trigger.config.ts` to your `tsconfig.json` include array:

```json  theme={null}
{
  "compilerOptions": {
    // ... your existing options
  },
  "include": [
    // ... your existing includes
    "trigger.config.ts"
  ]
}
```

## Git config

Add `.trigger` to your `.gitignore` file to exclude Trigger.dev's local development files:

```bash  theme={null}
# Trigger.dev
.trigger
```

If you don't have a `.gitignore` file, create one with this content.

## React hooks setup

If you're building a React frontend application and want to display task status in real-time, install the React hooks package:

### Installation

```bash  theme={null}
# npm
npm install @trigger.dev/react-hooks@latest

# pnpm
pnpm add @trigger.dev/react-hooks@latest

# yarn
yarn add @trigger.dev/react-hooks@latest

# bun
bun add @trigger.dev/react-hooks@latest
```

### Basic usage

1. **Generate a Public Access Token** in your backend:

```typescript  theme={null}
import { auth } from "@trigger.dev/sdk";

// In your backend API
export async function getPublicAccessToken() {
  const publicAccessToken = await auth.createPublicToken({
    scopes: ["read:runs"], // Customize based on needs
  });

  return publicAccessToken;
}
```

2. **Use hooks to monitor tasks**:

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function TaskStatus({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!run) return <div>Loading...</div>;

  return (
    <div>
      <p>Status: {run.status}</p>
      <p>Progress: {run.completedAt ? "Complete" : "Running..."}</p>
    </div>
  );
}
```

For more information, see the [React Hooks documentation](/realtime/react-hooks/overview).

## Build extensions

Build extensions allow you to customize the build process. Ensure you have the `@trigger.dev/build` package installed in your project (see [package installation](#package-installation)).

Now you can use any of the built-in extensions:

```typescript  theme={null}
import { defineConfig } from "@trigger.dev/sdk";
import { prismaExtension } from "@trigger.dev/build/extensions/prisma";

export default defineConfig({
  project: "<project-ref>",
  build: {
    extensions: [
      prismaExtension({
        schema: "prisma/schema.prisma",
        migrate: true, // Run migrations on deploy
      }),
    ],
  },
});
```

See our [Build extensions](/config/extensions/overview) docs for more information on how to use build extensions and the available extensions.

## Monorepo setup

There are two main approaches for setting up Trigger.dev in a monorepo:

1. **Tasks as a package**: Create a separate package for your Trigger.dev tasks that can be shared across apps
2. **Tasks in apps**: Install Trigger.dev directly in individual apps that need background tasks

Both approaches work well depending on your needs. Use the tasks package approach if you want to share tasks across multiple applications, or the app-based approach if tasks are specific to individual apps.

### Approach 1: Tasks as a package (Turborepo)

This approach creates a dedicated tasks package that can be consumed by multiple apps in your monorepo.

#### 1. Set up workspace configuration

**Root `package.json`**:

```json  theme={null}
{
  "name": "my-monorepo",
  "private": true,
  "scripts": {
    "build": "turbo run build",
    "dev": "turbo run dev",
    "lint": "turbo run lint"
  },
  "devDependencies": {
    "turbo": "^2.4.4",
    "typescript": "5.8.2"
  },
  "packageManager": "pnpm@9.0.0"
}
```

**`pnpm-workspace.yaml`**:

```yaml  theme={null}
packages:
  - "apps/*"
  - "packages/*"
```

**`turbo.json`**:

```json  theme={null}
{
  "$schema": "https://turbo.build/schema.json",
  "ui": "tui",
  "tasks": {
    "build": {
      "dependsOn": ["^build"],
      "outputs": [".next/**", "!.next/cache/**"]
    },
    "dev": {
      "cache": false,
      "persistent": true
    },
    "lint": {
      "dependsOn": ["^lint"]
    }
  }
}
```

#### 2. Create the tasks package

**`packages/tasks/package.json`**:

```json  theme={null}
{
  "name": "@repo/tasks",
  "version": "0.0.0",
  "dependencies": {
    "@trigger.dev/sdk": "^4.0.0"
  },
  "devDependencies": {
    "@trigger.dev/build": "^4.0.0"
  },
  "exports": {
    ".": "./src/trigger/index.ts",
    "./trigger": "./src/index.ts"
  }
}
```

**`packages/tasks/trigger.config.ts`**:

```typescript  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<your-project-ref>", // Replace with your project reference
  dirs: ["./src/trigger"],
  retries: {
    enabledInDev: true,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
  maxDuration: 3600,
});
```

**`packages/tasks/src/index.ts`**:

```typescript  theme={null}
export * from "@trigger.dev/sdk"; // Export values and types from the Trigger.dev sdk
```

**`packages/tasks/src/trigger/index.ts`**:

```typescript  theme={null}
// Export tasks
export * from "./example";
```

**`packages/tasks/src/trigger/example.ts`**:

```typescript  theme={null}
import { task } from "@trigger.dev/sdk";

export const helloWorld = task({
  id: "hello-world",
  run: async (payload: { name: string }) => {
    console.log(`Hello ${payload.name}!`);

    return {
      message: `Hello ${payload.name}!`,
      timestamp: new Date().toISOString(),
    };
  },
});
```

See our [turborepo-prisma-tasks-package example](https://github.com/triggerdotdev/examples/tree/main/monorepos/turborepo-prisma-tasks-package) for a more complete example.

#### 3. Use tasks in your apps

**`apps/web/package.json`**:

```json  theme={null}
{
  "name": "web",
  "dependencies": {
    "@repo/tasks": "workspace:*",
    "next": "^15.2.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  }
}
```

**`apps/web/app/api/actions.ts`**:

```typescript  theme={null}
"use server";

import { tasks } from "@repo/tasks/trigger";
import type { helloWorld } from "@repo/tasks";
//     ðŸ‘† type only import

export async function triggerHelloWorld(name: string) {
  try {
    const handle = await tasks.trigger<typeof helloWorld>("hello-world", {
      name: name,
    });

    return handle.id;
  } catch (error) {
    console.error(error);
    return { error: "something went wrong" };
  }
}
```

#### 4. Development workflow

Run the development server for the tasks package:

```bash  theme={null}
# From the root of your monorepo
cd packages/tasks
npx trigger.dev@latest dev

# Or using turbo (if you add dev:trigger script to tasks package.json)
turbo run dev:trigger --filter=@repo/tasks
```

### Approach 2: Tasks in apps (Turborepo)

This approach installs Trigger.dev directly in individual apps that need background tasks.

#### 1. Install in your app

**`apps/web/package.json`**:

```json  theme={null}
{
  "name": "web",
  "dependencies": {
    "@trigger.dev/sdk": "^4.0.0",
    "next": "^15.2.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@trigger.dev/build": "^4.0.0"
  }
}
```

#### 2. Add configuration

**`apps/web/trigger.config.ts`**:

```typescript  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<your-project-ref>", // Replace with your project reference
  dirs: ["./src/trigger"],
  retries: {
    enabledInDev: true,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
  maxDuration: 3600,
});
```

#### 3. Create tasks

**`apps/web/src/trigger/example.ts`**:

```typescript  theme={null}
import { task } from "@trigger.dev/sdk";

export const helloWorld = task({
  id: "hello-world",
  run: async (payload: { name: string }) => {
    console.log(`Hello ${payload.name}!`);

    return {
      message: `Hello ${payload.name}!`,
      timestamp: new Date().toISOString(),
    };
  },
});
```

#### 4. Use tasks in your app

**`apps/web/app/api/actions.ts`**:

```typescript  theme={null}
"use server";

import { tasks } from "@trigger.dev/sdk";
import type { helloWorld } from "../../src/trigger/example";
//     ðŸ‘† type only import

export async function triggerHelloWorld(name: string) {
  try {
    const handle = await tasks.trigger<typeof helloWorld>("hello-world", {
      name: name,
    });

    return handle.id;
  } catch (error) {
    console.error(error);
    return { error: "something went wrong" };
  }
}
```

#### 5. Development workflow

```bash  theme={null}
# From the app directory
cd apps/web
npx trigger.dev@latest dev

# Or from the root using turbo
turbo run dev:trigger --filter=web
```

## Example projects

You can find a growing list of example projects in our [examples](/guides/introduction) section.

## Troubleshooting

If you run into any issues, please check our [Troubleshooting](/troubleshooting) page.

## Feedback

If you have any feedback, please let us know by [opening an issue](https://github.com/triggerdotdev/trigger.dev/issues).


# Agent rules
Source: https://trigger.dev/docs/mcp-agent-rules

Learn how to use the Trigger.dev agent rules with the MCP server

## What are Trigger.dev agent rules?

Trigger.dev agent rules are comprehensive instruction sets that guide AI assistants to write optimal Trigger.dev code. These rules ensure your AI assistant understands best practices, current APIs, and recommended patterns when working with Trigger.dev projects.

## Installation

Install the agent rules with the following command:

```bash  theme={null}
npx trigger.dev@latest install-rules
```

## Available rule sets

We provide five specialized rule sets, each optimized for different aspects of Trigger.dev development:

| Rule set            | Tokens | Description                                                                                  | GitHub                                                                                        |
| :------------------ | :----- | :------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------- |
| **Basic tasks**     | 1,200  | Essential rules for writing basic Trigger.dev tasks and fundamental patterns                 | [View](https://github.com/triggerdotdev/trigger.dev/blob/main/rules/4.0.0/basic-tasks.md)     |
| **Advanced tasks**  | 3,000  | Comprehensive rules for complex workflows, error handling, and advanced task patterns        | [View](https://github.com/triggerdotdev/trigger.dev/blob/main/rules/4.0.0/advanced-tasks.md)  |
| **Scheduled tasks** | 780    | Specialized guidance for cron jobs, scheduled workflows, and time-based triggers             | [View](https://github.com/triggerdotdev/trigger.dev/blob/main/rules/4.0.0/scheduled-tasks.md) |
| **Configuration**   | 1,900  | Complete guide for trigger.config.ts setup, environment configuration, and project structure | [View](https://github.com/triggerdotdev/trigger.dev/blob/main/rules/4.0.0/config.md)          |
| **Realtime**        | 1,700  | Using Trigger.dev Realtime features and frontend integration patterns                        | [View](https://github.com/triggerdotdev/trigger.dev/blob/main/rules/4.0.0/realtime.md)        |

## Claude Code subagent

For Claude Code users, we provide a subagent called `trigger-dev-expert` that's an expert at writing well-structured Trigger.dev code.

### Installation

The subagent is available as an option when running the rules installation command. Select "Claude Code" as your client and choose to include the subagent when prompted.

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=b7f4183abcbb79c59c90c237785698e6" alt="Claude Code subagent installation" data-og-width="1266" width="1266" data-og-height="453" height="453" data-path="images/claude-code-subagent.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=12592c023c19a48eee359bd1183224f4 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=2795072f21c5476d692131c412f96e63 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=fc4edc5a38551eb12ee4a648532789a2 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=84c3a2320c38582ddf77c63f0dfe0436 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=26e679c491757b7752fd5a32829d5c04 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/claude-code-subagent.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9f3a4c7f02920316780502de6b643449 2500w" />

### Usage

Activate the subagent in your prompts by requesting it explicitly:

```markdown  theme={null}
use the trigger-dev-expert subagent to create a trigger.dev job that accepts a video url, processes it with ffmpeg to extract the audio, runs the audio through a text-to-speech API like openai, and then uploads both the transcription and the audio to s3
```

The subagent works best when combined with the appropriate rule sets installed alongside it, providing both high-level architectural guidance and detailed implementation knowledge.

## Supported AI clients

The Trigger.dev rules work across a wide range of AI coding assistants and editors:

| Client              | Rule activation                                          | Docs                                                              |
| :------------------ | :------------------------------------------------------- | :---------------------------------------------------------------- |
| **Cursor**          | Automatic when working in trigger directories            | [Link](https://docs.cursor.com/en/context/rules#rules/)           |
| **Claude Code**     | Context-aware activation + custom subagent               | [Link](https://docs.anthropic.com/en/docs/claude-code)            |
| **VSCode Copilot**  | Integration with GitHub Copilot chat                     | [Link](https://code.visualstudio.com/docs/copilot/overview)       |
| **Windsurf**        | Automatic activation in Trigger.dev projects             | [Link](https://docs.windsurf.com/windsurf/cascade/memories#rules) |
| **Gemini CLI**      | Command-line integration                                 | [Link](https://ai.google.dev/gemini-api/docs)                     |
| **Cline**           | Automatic context detection                              | [Link](https://github.com/cline/cline)                            |
| **Sourcegraph AMP** | Code intelligence integration                            | [Link](https://sourcegraph.com/docs)                              |
| **Kilo**            | Custom rule integration                                  | [Link](https://kilocode.ai/docs/advanced-usage/custom-rules)      |
| **Ruler**           | Rule management                                          | [Link](https://github.com/intellectronica/ruler)                  |
| **AGENTS.md**       | Universal format for OpenAI Codex, Jules, OpenCode, etc. |                                                                   |

### Rule activation behavior

Different AI tools handle rules differently:

* **Automatic Activation**: Cursor, Windsurf, VSCode Copilot, and Cline automatically apply relevant rules when working in Trigger.dev projects or when `trigger.config.ts` is detected
* **Context-Aware**: Claude Code intelligently applies rules based on the current context and file types
* **Manual Integration**: AGENTS.md clients and others append rules to configuration files for manual activation

## Keeping rules updated

Trigger.dev rules are regularly updated to reflect new features, API changes, and best practices. The CLI includes automatic update detection.

### Automatic update notifications

When running `npx trigger.dev@latest dev`, you'll receive notifications when newer rule versions are available with a simple update command.

### Manual updates

Update rules anytime with:

```bash  theme={null}
npx trigger.dev@latest install-rules
```

The update process replaces existing rules without creating duplicates, keeping your configuration files clean and organized.

### Why updates matter

* **Current API patterns**: Access the latest Trigger.dev APIs and features
* **Performance optimizations**: Benefit from improved patterns and practices
* **Deprecated pattern avoidance**: Prevent AI assistants from generating outdated code
* **New feature support**: Immediate access to newly released capabilities

## Getting started

1. Install the rules:

```bash  theme={null}
npx trigger.dev@latest install-rules
```

2. Follow the prompts to install the rules for your AI client.

3. Consider installing the `trigger-dev-expert` subagent if using Claude Code.

## Next steps

* [Install the MCP server](/mcp-introduction) for complete Trigger.dev integration
* [Explore MCP tools](/mcp-tools) for project management and task execution


# MCP Introduction
Source: https://trigger.dev/docs/mcp-introduction

Learn how to install and configure the Trigger.dev MCP Server

## What is the Trigger.dev MCP Server?

The Trigger.dev MCP (Model Context Protocol) Server enables AI assistants to interact directly with your Trigger.dev projects. It provides a comprehensive set of tools to:

* Search Trigger.dev documentation
* Initialize new Trigger.dev projects
* List and manage your projects and organizations
* Get task information and trigger task runs
* Deploy projects to different environments
* Monitor run details and list runs with filtering options

## Installation

### Automatic Installation (Recommended)

The easiest way to install the Trigger.dev MCP Server is using the interactive installation wizard:

```bash  theme={null}
npx trigger.dev@latest install-mcp
```

This command will guide you through:

1. Selecting which MCP clients to configure
2. Choosing installation scope (user, project, or local)
3. Automatically configuring the selected clients

## Command Line Options

The `install-mcp` command supports the following options:

### Core Options

* `-p, --project-ref <project ref>` - Scope the MCP server to a specific Trigger.dev project by providing its project ref
* `-t, --tag <package tag>` - The version of the trigger.dev CLI package to use for the MCP server (default: latest or v4-beta)
* `--dev-only` - Restrict the MCP server to the dev environment only
* `--yolo` - Install the MCP server into all supported clients automatically
* `--scope <scope>` - Choose the scope of the MCP server: `user`, `project`, or `local`
* `--client <clients...>` - Choose specific client(s) to install into

### Configuration Options

* `--log-file <log file>` - Configure the MCP server to write logs to a file
* `-a, --api-url <value>` - Configure a custom Trigger.dev API URL
* `-l, --log-level <level>` - Set CLI log level (debug, info, log, warn, error, none)

## Authentication

You can use the MCP server without authentication with the `search_docs` tool, but for any other tool call you will need to authenticate the MCP server via the same method as the [Trigger.dev CLI](/cli-login-commands).The first time you attempt to use a tool that requires authentication, you will be prompted to authenticate the MCP server via the MCP client.

### Examples

Install for all supported clients:

```bash  theme={null}
npx trigger.dev@latest install-mcp --yolo
```

Install for specific clients:

```bash  theme={null}
npx trigger.dev@latest install-mcp --client claude-code cursor --scope user
```

Install with development environment restriction:

```bash  theme={null}
npx trigger.dev@latest install-mcp --dev-only --project-ref proj_abc123
```

## Supported MCP Clients

The Trigger.dev MCP Server supports the following clients:

| Client               | Scope Options        | Configuration File                                                                                              | Documentation                                                                                                                                    |
| -------------------- | -------------------- | --------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Claude Code**      | user, project, local | `~/.claude.json` or `./.mcp.json` (project/local scope)                                                         | [Claude Code MCP Docs](https://docs.anthropic.com/en/docs/claude-code/mcp)                                                                       |
| **Cursor**           | user, project        | `~/.cursor/mcp.json` (user) or `./.cursor/mcp.json` (project)                                                   | [Cursor MCP Docs](https://docs.cursor.com/features/mcp)                                                                                          |
| **VSCode**           | user, project        | `~/Library/Application Support/Code/User/mcp.json` (user) or `./.vscode/mcp.json` (project)                     | [VSCode MCP Docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)                                                                   |
| **Zed**              | user                 | `~/.config/zed/settings.json`                                                                                   | [Zed Context Servers Docs](https://zed.dev/docs/context-servers)                                                                                 |
| **Windsurf**         | user                 | `~/.codeium/windsurf/mcp_config.json`                                                                           | [Windsurf MCP Docs](https://docs.codeium.com/windsurf/mcp)                                                                                       |
| **Gemini CLI**       | user, project        | `~/.gemini/settings.json` (user) or `./.gemini/settings.json` (project)                                         | [Gemini CLI MCP Tutorial](https://medium.com/@joe.njenga/gemini-cli-mcp-tutorial-setup-commands-practical-use-step-by-step-example-b57f55db5f4a) |
| **Charm Crush**      | user, project, local | `~/.config/crush/crush.json` (user), `./crush.json` (project), or `./.crush.json` (local)                       | [Charm MCP Docs](https://github.com/charmbracelet/mcp)                                                                                           |
| **Cline**            | user                 | `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` | [Cline MCP Docs](https://github.com/saoudrizwan/claude-dev#mcp)                                                                                  |
| **OpenAI Codex CLI** | user                 | `~/.codex/config.toml`                                                                                          | See OpenAI Codex CLI documentation for MCP configuration                                                                                         |
| **Sourcegraph AMP**  | user                 | `~/.config/amp/settings.json`                                                                                   | [Sourcegraph AMP MCP Docs](https://docs.sourcegraph.com/amp/mcp)                                                                                 |
| **opencode**         | user, project        | `~/.config/opencode/opencode.json` (user) or `./opencode.json` (project)                                        | [opencode MCP Docs](https://opencode.ai/docs/mcp-servers/)                                                                                       |

## Manual Configuration

If your client isn't directly supported by the installer, you can configure it manually. The MCP server uses the following configuration:

**Server Name:** `trigger`

**Command:** `npx`

**Arguments:** `["trigger.dev@latest", "mcp"]`

### Example JSON Configuration

```json  theme={null}
{
  "mcpServers": {
    "trigger": {
      "command": "npx",
      "args": ["trigger.dev@latest", "mcp"]
    }
  }
}
```

### Example TOML Configuration (for Codex CLI)

```toml  theme={null}
[mcp_servers.trigger]
command = "npx"
args = ["trigger.dev@latest", "mcp"]
```

### Additional Options

You can add these optional arguments to customize the server behavior:

* `--log-file <path>` - Log to a specific file
* `--api-url <url>` - Use a custom Trigger.dev API URL
* `--dev-only` - Restrict to dev environment only
* `--project-ref <ref>` - Scope to a specific project

## Environment-Specific Configuration

### Development Only

To restrict the MCP server to only work with the development environment:

```json  theme={null}
{
  "mcpServers": {
    "trigger": {
      "command": "npx",
      "args": ["trigger.dev@latest", "mcp", "--dev-only"]
    }
  }
}
```

### Project-Scoped

To scope the server to a specific project:

```json  theme={null}
{
  "mcpServers": {
    "trigger": {
      "command": "npx",
      "args": ["trigger.dev@latest", "mcp", "--project-ref", "proj_your_project_ref"]
    }
  }
}
```

## Verification

After installation, restart your MCP client and look for a server named "trigger". The server should connect automatically and provide access to all Trigger.dev tools.

## Getting Started

Once installed, you can start using the MCP server by asking your AI assistant questions like:

* `"Search the trigger docs for a ffmpeg example"`
* `"Initialize trigger.dev in my project"`
* `"Get all tasks in my project"`
* `"Trigger my foobar task with a sample payload"`
* `"Get the details of the latest run for my foobar task"`
* `"List all runs for my foobar task"`
* `"Deploy my project to staging"`
* `"Deploy my project to production"`

## Next Steps

* [Explore available MCP tools](/mcp-tools)


# MCP Tools
Source: https://trigger.dev/docs/mcp-tools

Learn about the tools available in the Trigger.dev MCP Server

The Trigger.dev MCP Server provides a comprehensive set of tools that enable AI assistants to interact with your Trigger.dev projects. These tools cover everything from project management to task execution and monitoring.

## Documentation and Search Tools

### search\_docs

Search across the Trigger.dev documentation to find relevant information, code examples, API references, and guides.

<ParamField query="query" type="string" required>
  The search query to find information in the Trigger.dev documentation
</ParamField>

**Usage Examples:**

* "How do I create a scheduled task?"
* "webhook examples"
* "deployment configuration"
* "error handling patterns"

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "search_docs",
    "arguments": {
      "query": "webhook examples"
    }
  }
  ```
</CodeGroup>

## Project Management Tools

### list\_projects

List all projects in your Trigger.dev account.

**No parameters required**

<ResponseField name="projects" type="array">
  Array of project objects containing project details, IDs, and metadata
</ResponseField>

<CodeGroup>
  ```json Example Response theme={null}
  {
    "projects": [
      {
        "id": "proj_abc123",
        "name": "My App",
        "slug": "my-app",
        "organizationId": "org_xyz789"
      }
    ]
  }
  ```
</CodeGroup>

### list\_orgs

List all organizations you have access to.

**No parameters required**

<ResponseField name="orgs" type="array">
  Array of organization objects containing organization details and metadata
</ResponseField>

### create\_project\_in\_org

Create a new project in an organization.

<ParamField query="orgParam" type="string" required>
  The organization to create the project in, can either be the organization slug or the ID. Use the
  `list_orgs` tool to get a list of organizations and ask the user to select one.
</ParamField>

<ParamField query="name" type="string" required>
  The name of the project to create
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "create_project_in_org",
    "arguments": {
      "orgParam": "my-org",
      "name": "New Project"
    }
  }
  ```
</CodeGroup>

### initialize\_project

Initialize Trigger.dev in your project with automatic setup and configuration.

<ParamField query="orgParam" type="string" required>
  The organization to create the project in, can either be the organization slug or the ID. Use the
  `list_orgs` tool to get a list of organizations and ask the user to select one.
</ParamField>

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="projectName" type="string" required>
  The name of the project to create. If projectRef is not provided, we will use this name to create
  a new project in the organization you select.
</ParamField>

<ParamField query="cwd" type="string" required>
  The current working directory of the project
</ParamField>

## Task Management Tools

### get\_tasks

Get all tasks in a project.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup). If not provided, we will try to find the config file in the
  current working directory.
</ParamField>

<ParamField query="environment" type="string" default="dev">
  The environment to get tasks for. Options: `dev`, `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to get tasks for, only used for preview environments
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "get_tasks",
    "arguments": {
      "projectRef": "proj_abc123",
      "environment": "dev"
    }
  }
  ```
</CodeGroup>

### trigger\_task

Trigger a task to run.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="dev">
  The environment to trigger the task in. Options: `dev`, `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to trigger the task in, only used for preview environments
</ParamField>

<ParamField query="taskId" type="string" required>
  The ID/slug of the task to trigger. Use the `get_tasks` tool to get a list of tasks and ask the
  user to select one if it's not clear which one to use.
</ParamField>

<ParamField query="payload" type="string" required>
  The payload to trigger the task with, must be a valid JSON string
</ParamField>

<ParamField query="options" type="object" optional>
  Additional options for the task run

  <Expandable title="options properties">
    <ParamField query="queue.name" type="string" optional>
      The name of the queue to trigger the task in, by default will use the queue configured in the
      task
    </ParamField>

    <ParamField query="delay" type="string | datetime" optional>
      The delay before the task run is executed
    </ParamField>

    <ParamField query="idempotencyKey" type="string" optional>
      The idempotency key to use for the task run
    </ParamField>

    <ParamField query="machine" type="string" optional>
      The machine preset to use for the task run. Options: `micro`, `small-1x`, `small-2x`,
      `medium-1x`, `medium-2x`, `large-1x`, `large-2x`
    </ParamField>

    <ParamField query="maxAttempts" type="integer" optional>
      The maximum number of attempts to retry the task run
    </ParamField>

    <ParamField query="maxDuration" type="number" optional>
      The maximum duration in seconds of the task run
    </ParamField>

    <ParamField query="tags" type="array" optional>
      Tags to add to the task run. Must be less than 128 characters and cannot have more than 5
    </ParamField>

    <ParamField query="ttl" type="string | integer" default="10m">
      The time to live of the task run. If the run doesn't start executing within this time, it will
      be automatically cancelled.
    </ParamField>
  </Expandable>
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "trigger_task",
    "arguments": {
      "projectRef": "proj_abc123",
      "taskId": "email-notification",
      "payload": "{\"email\": \"user@example.com\", \"subject\": \"Hello World\"}",
      "options": {
        "tags": ["urgent"],
        "maxAttempts": 3
      }
    }
  }
  ```
</CodeGroup>

## Run Monitoring Tools

### get\_run\_details

Get the details of a specific task run.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="dev">
  The environment to get the run details from. Options: `dev`, `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to get the run details from, only used for preview environments
</ParamField>

<ParamField query="runId" type="string" required>
  The ID of the run to get the details of, starts with `run_`
</ParamField>

<ParamField query="debugMode" type="boolean" optional>
  Enable debug mode to get more detailed information about the run, including the entire trace (all logs and spans for the run and any child run). Set this to true if prompted to debug a run.
</ParamField>

### cancel\_run

Cancel a running task.

<ParamField query="runId" type="string" required>
  The ID of the run to cancel, starts with `run_`
</ParamField>

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="dev">
  The environment to cancel the run in. Options: `dev`, `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to cancel the run in, only used for preview environments
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "cancel_run",
    "arguments": {
      "runId": "run_abc123",
      "projectRef": "proj_abc123"
    }
  }
  ```
</CodeGroup>

### list\_runs

List all runs for a project with comprehensive filtering options.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="dev">
  The environment to list runs from. Options: `dev`, `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to list runs from, only used for preview environments
</ParamField>

<ParamField query="cursor" type="string" optional>
  The cursor to use for pagination, starts with `run_`
</ParamField>

<ParamField query="limit" type="integer" optional>
  The number of runs to list in a single page. Up to 100
</ParamField>

<ParamField query="status" type="string" optional>
  Filter for runs with this run status. Options: `PENDING_VERSION`, `QUEUED`, `DEQUEUED`,
  `EXECUTING`, `WAITING`, `COMPLETED`, `CANCELED`, `FAILED`, `CRASHED`, `SYSTEM_FAILURE`, `DELAYED`,
  `EXPIRED`, `TIMED_OUT`
</ParamField>

<ParamField query="taskIdentifier" type="string" optional>
  Filter for runs that match this task identifier
</ParamField>

<ParamField query="version" type="string" optional>
  Filter for runs that match this version, e.g. `20250808.3`
</ParamField>

<ParamField query="tag" type="string" optional>
  Filter for runs that include this tag
</ParamField>

<ParamField query="from" type="string" optional>
  Filter for runs created after this ISO 8601 timestamp
</ParamField>

<ParamField query="to" type="string" optional>
  Filter for runs created before this ISO 8601 timestamp
</ParamField>

<ParamField query="period" type="string" optional>
  Filter for runs created in the last N time period. Examples: `7d`, `30d`, `365d`
</ParamField>

<ParamField query="machine" type="string" optional>
  Filter for runs that match this machine preset. Options: `micro`, `small-1x`, `small-2x`,
  `medium-1x`, `medium-2x`, `large-1x`, `large-2x`
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "list_runs",
    "arguments": {
      "projectRef": "proj_abc123",
      "status": "COMPLETED",
      "limit": 10,
      "period": "7d"
    }
  }
  ```
</CodeGroup>

## Deployment Tools

### deploy

Deploy a project to staging or production environments.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="prod">
  The environment to deploy to. Options: `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to deploy, only used for preview environments
</ParamField>

<ParamField query="skipPromotion" type="boolean" optional>
  Skip promoting the deployment to the current deployment for the environment
</ParamField>

<ParamField query="skipSyncEnvVars" type="boolean" optional>
  Skip syncing environment variables when using the syncEnvVars extension
</ParamField>

<ParamField query="skipUpdateCheck" type="boolean" optional>
  Skip checking for @trigger.dev package updates
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "deploy",
    "arguments": {
      "projectRef": "proj_abc123",
      "environment": "prod",
      "skipUpdateCheck": true
    }
  }
  ```
</CodeGroup>

### list\_deployments

List deployments for a project with comprehensive filtering options.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup).
</ParamField>

<ParamField query="environment" type="string" default="prod">
  The environment to list deployments for. Options: `staging`, `prod`, `preview`
</ParamField>

<ParamField query="branch" type="string" optional>
  The branch to list deployments from, only used for preview environments
</ParamField>

<ParamField query="cursor" type="string" optional>
  The deployment ID to start the search from, to get the next page
</ParamField>

<ParamField query="limit" type="number" optional>
  The number of deployments to return, defaults to 20 (max 100)
</ParamField>

<ParamField query="status" type="string" optional>
  Filter deployments that are in this status. Options: `PENDING`, `BUILDING`, `DEPLOYING`, `DEPLOYED`, `FAILED`, `CANCELED`, `TIMED_OUT`
</ParamField>

<ParamField query="from" type="string" optional>
  The date to start the search from, in ISO 8601 format
</ParamField>

<ParamField query="to" type="string" optional>
  The date to end the search, in ISO 8601 format
</ParamField>

<ParamField query="period" type="string" optional>
  The period to search within. Examples: `1d`, `7d`, `3h`
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "list_deployments",
    "arguments": {
      "projectRef": "proj_abc123",
      "environment": "prod",
      "status": "DEPLOYED",
      "limit": 10
    }
  }
  ```
</CodeGroup>

### list\_preview\_branches

List all preview branches in the project.

<ParamField query="projectRef" type="string" optional>
  The trigger.dev project ref, starts with `proj_`. We will attempt to automatically detect the
  project ref if running inside a directory that includes a trigger.config.ts file.
</ParamField>

<ParamField query="configPath" type="string" optional>
  The path to the trigger.config.ts file. Only used when the trigger.config.ts file is not at the
  root dir (like in a monorepo setup). If not provided, we will try to find the config file in the
  current working directory.
</ParamField>

<CodeGroup>
  ```json Example Usage theme={null}
  {
    "tool": "list_preview_branches",
    "arguments": {
      "projectRef": "proj_abc123"
    }
  }
  ```
</CodeGroup>

<Callout type="warning">
  The deploy tool and list\_preview\_branches tool are not available when the MCP server is running with the `--dev-only` flag.
</Callout>


# Migrating from v3
Source: https://trigger.dev/docs/migrating-from-v3

What's new in v4, how to migrate, and breaking changes.

## What's new in v4?

| Feature                                                              | Description                                                                                                                                                                                                |
| :------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Wait for token](/wait-for-token)                                    | Create and wait for tokens to be completed, enabling approval workflows and waiting for arbitrary external conditions.                                                                                     |
| Wait idempotency                                                     | Skip waits if the same idempotency key is used again when using [wait for](/wait-for#wait-idempotency), [wait until](/wait-until#wait-idempotency), or [wait for token](/wait-for-token#wait-idempotency). |
| [Priority](/runs/priority)                                           | Specify a priority when triggering a task.                                                                                                                                                                 |
| [Global lifecycle hooks](/tasks/overview#global-lifecycle-hooks)     | Register global lifecycle hooks that are executed for all runs, regardless of the task.                                                                                                                    |
| [onWait and onResume](/tasks/overview#onwait-and-onresume-functions) | Run code when a run is paused or resumed because of a wait.                                                                                                                                                |
| [onComplete](/tasks/overview#oncomplete-function)                    | Run code when a run completes, regardless of whether it succeeded or failed.                                                                                                                               |
| [onCancel](/tasks/overview#oncancel-function)                        | Run code when a run is cancelled.                                                                                                                                                                          |
| [Hidden tasks](/hidden-tasks)                                        | Create tasks that are not exported from your trigger files but can still be executed.                                                                                                                      |
| [Middleware & locals](#middleware-and-locals)                        | The middleware system runs at the top level, executing before and after all lifecycle hooks. The locals API allows sharing data between middleware and hooks.                                              |
| [useWaitToken](/realtime/react-hooks/use-wait-token)                 | Use the useWaitToken hook to complete a wait token from a React component.                                                                                                                                 |
| [ai.tool](/tasks/schemaTask#ai-tool)                                 | Create an AI tool from an existing `schemaTask` to use with the Vercel [AI SDK](https://vercel.com/docs/ai-sdk).                                                                                           |

## Node.js support

Trigger.dev runs your tasks on specific Node.js versions:

### v3

* Node.js `21.7.3`

### v4

* Node.js `21.7.3` (default)
* Node.js `22.16.0` (`node-22`)
* Bun `1.2.20` (`bun`)

You can change the runtime by setting the `runtime` field in your `trigger.config.ts` file.

```ts  theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  // "node", "node-22" or "bun"
  runtime: "node-22",
  project: "<your-project-ref>",
});
```

## How to migrate to v4

First read the deprecations and breaking changes sections below.

We recommend the following steps to migrate to v4:

1. Install the v4 package.
2. Run the `trigger dev` CLI command and test your tasks locally, fixing any breaking changes.
3. Deploy to the staging environment and test your tasks in staging, fixing any breaking changes. (this step is optional, but highly recommended)
4. Once you've verified that v4 is working as expected, you should deploy your application backend with the updated v4 package.
5. Once you've deployed your application backend, you should deploy your tasks to the production environment.

Note that between steps 4 and 5, runs triggered with the v4 package will continue using v3, and only new runs triggered after step 5 is complete will use v4.

<Warning>
  Once v4 is activated in your environment, there will be a period of time where old runs will
  continue to execute using v3, while new runs will use v4. Because these engines use completely
  different underlying queues and concurrency models, it's possible you may have up to double the
  amount of concurrently executing runs. Once the runs drain from the old run engine, the
  concurrency will return to normal.
</Warning>

## Migrate using AI

Use the prompt in the accordion below to help you migrate your v3 tasks to v4. The prompt gives good results when using Claude 4 Sonnet. Youâ€™ll need a relatively large token limit.

<Accordion title="Copy paste this prompt in full" icon="sparkles">
  ```md  theme={null}

  I would like you to help me migrate my v3 task code to v4. Here are the important differences:

  We've deprecated the `@trigger.dev/sdk/v3` import path and moved to a new path:

  // This is the old path
  import { task } from "@trigger.dev/sdk/v3";

  // This is the new path, use this instead
  import { task } from "@trigger.dev/sdk";

  We've renamed the `handleError` hook to `catchError`. Use this instead of `handleError`.

  `init` was previously used to initialize data used in the run function. This is the old version:

  import { task } from "@trigger.dev/sdk";

  const myTask = task({
    init: async () => {
      return {
        myClient: new MyClient(),
      };
    },
    run: async (payload: any, { ctx, init }) => {
      const client = init.myClient;
      await client.doSomething();
    },
  });

  This is the new version using middleware and locals:

  import { task, locals, tasks } from "@trigger.dev/sdk";

  // Create a local for your client
  const MyClientLocal = locals.create<MyClient>("myClient");

  // Set up middleware to initialize the client
  tasks.middleware("my-client", async ({ next }) => {
    const client = new MyClient();
    locals.set(MyClientLocal, client);
    await next();
  });

  // Helper function to get the client
  function getMyClient() {
    return locals.getOrThrow(MyClientLocal);
  }

  const myTask = task({
    run: async (payload: any, { ctx }) => {
      const client = getMyClient();
      await client.doSomething();
    },
  });

  Weâ€™ve deprecated the `toolTask` function and replaced it with the `ai.tool` function, which creates an AI tool from an existing `schemaTask`. This is the old version:

  import { toolTask, schemaTask } from "@trigger.dev/sdk";
  import { z } from "zod";
  import { generateText } from "ai";

  const myToolTask = toolTask({
    id: "my-tool-task",
    run: async (payload: any, { ctx }) => {},
  });

  export const myAiTask = schemaTask({
    id: "my-ai-task",
    schema: z.object({
      text: z.string(),
    }),
    run: async (payload, { ctx }) => {
      const { text } = await generateText({
        prompt: payload.text,
        model: openai("gpt-4o"),
        tools: {
          myToolTask,
        },
      });
    },
  });

  This is the new version:

  import { schemaTask, ai } from "@trigger.dev/sdk";
  import { z } from "zod";
  import { generateText } from "ai";

  // Convert toolTask to schemaTask with a schema
  const myToolTask = schemaTask({
    id: "my-tool-task",
    schema: z.object({
      // Add appropriate schema for your tool's payload
      input: z.string(),
    }),
    run: async (payload, { ctx }) => {},
  });

  // Create an AI tool from the schemaTask
  const myTool = ai.tool(myToolTask);

  export const myAiTask = schemaTask({
    id: "my-ai-task",
    schema: z.object({
      text: z.string(),
    }),
    run: async (payload, { ctx }) => {
      const { text } = await generateText({
        prompt: payload.text,
        model: openai("gpt-4o"),
        tools: {
          myTool, // Use the ai.tool created from schemaTask
        },
      });
    },
  });

  We've made several breaking changes that require code updates:

  **Queue changes**: Queues must now be defined ahead of time using the `queue` function. You can no longer create queues "on-demand" when triggering tasks. This is the old version:


  // Old v3 way - creating queue on-demand
  await myTask.trigger({ foo: "bar" }, { queue: { name: "my-queue", concurrencyLimit: 10 } });


  This is the new version:


  // New v4 way - define queue first
  import { queue, task } from "@trigger.dev/sdk";

  const myQueue = queue({
    name: "my-queue",
    concurrencyLimit: 10,
  });

  export const myTask = task({
    id: "my-task",
    queue: myQueue, // Set queue on task
    run: async (payload: any, { ctx }) => {},
  });

  // Now trigger without queue options
  await myTask.trigger({ foo: "bar" });

  // Or specify queue by name
  await myTask.trigger({ foo: "bar" }, { queue: "my-queue" });


  **Lifecycle hooks**: Function signatures have changed to use a single object parameter instead of separate parameters. This is the old version:


  // Old v3 way
  export const myTask = task({
    id: "my-task",
    onStart: (payload, { ctx }) => {},
    onSuccess: (payload, output, { ctx }) => {},
    onFailure: (payload, error, { ctx }) => {},
    catchError: (payload, { ctx, error, retry }) => {},
    run: async (payload, { ctx }) => {},
  });


  This is the new version:


  // New v4 way - single object parameter for hooks
  export const myTask = task({
    id: "my-task",
    onStart: ({ payload, ctx }) => {},
    onSuccess: ({ payload, output, ctx }) => {},
    onFailure: ({ payload, error, ctx }) => {},
    catchError: ({ payload, ctx, error, retry }) => {},
    run: async (payload, { ctx }) => {}, // run function unchanged
  });


  **BatchTrigger changes**: The `batchTrigger` function no longer returns runs directly. This is the old version:


  // Old v3 way
  const batchHandle = await tasks.batchTrigger([
    [myTask, { foo: "bar" }],
    [myOtherTask, { baz: "qux" }],
  ]);

  console.log(batchHandle.runs); // Direct access


  This is the new version:


  // New v4 way
  const batchHandle = await tasks.batchTrigger([
    [myTask, { foo: "bar" }],
    [myOtherTask, { baz: "qux" }],
  ]);

  const batch = await batch.retrieve(batchHandle.batchId); // Use batch.retrieve()
  console.log(batch.runs);


  Can you help me convert the following code from v3 to v4? Please include the full converted code in the answer, do not truncate it anywhere.

  ```
</Accordion>

## Installation

To opt-in to using v4, you will need to update your dependencies to the latest version:

<CodeGroup>
  ```bash npx theme={null}
  npx trigger.dev@latest update
  ```

  ```bash yarn theme={null}
  yarn dlx trigger.dev@latest update
  ```

  ```bash pnpm theme={null}
  pnpm dlx trigger.dev@latest update
  ```
</CodeGroup>

This command should update all of your `@trigger.dev/*` packages to a `4.x` version.

## Deprecations

We've deprecated the following APIs:

### @trigger.dev/sdk/v3

We've deprecated the `@trigger.dev/sdk/v3` import path and moved to a new path:

```ts  theme={null}
// This still works, but will be removed in a future version
import { task } from "@trigger.dev/sdk/v3";

// This is the new path
import { task } from "@trigger.dev/sdk";
```

### `handleError` and `init`

We've renamed the `handleError` hook to `catchError` to better reflect that it can catch and react to errors. `handleError` will be removed in a future version.

`init` was previously used to initialize data used in the run function:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";

const myTask = task({
  init: async () => {
    return {
      myClient: new MyClient(),
    };
  },
  run: async (payload: any, { ctx, init }) => {
    const client = init.myClient;
    await client.doSomething();
  },
});
```

This has now been deprecated in favor of the `locals` API and middleware. See the [Improved middleware and locals](/tasks/overview#middleware-and-locals-functions) section for more details.

### toolTask

We've deprecated the `toolTask` function, which created both a Trigger.dev task and a tool compatible with the Vercel [AI SDK](https://vercel.com/docs/ai-sdk):

```ts  theme={null}
import { toolTask, schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";
import { generateText } from "ai";

const myToolTask = toolTask({
  id: "my-tool-task",
  run: async (payload: any, { ctx }) => {},
});

export const myAiTask = schemaTask({
  id: "my-ai-task",
  schema: z.object({
    text: z.string(),
  }),
  run: async (payload, { ctx }) => {
    const { text } = await generateText({
      prompt: payload.text,
      model: openai("gpt-4o"),
      tools: {
        myToolTask,
      },
    });
  },
});
```

We've replaced the `toolTask` function with the `ai.tool` function, which creates an AI tool from an existing `schemaTask`. See the [ai.tool](/tasks/schemaTask#ai-tool) page for more details.

## Breaking changes

### Queue changes

Previously, it was possible to specify a queue name of a queue that did not exist, along with a concurrency limit. The queue would then be created "on-demand" with the specified concurrency limit. If the queue did exist, the concurrency limit of the queue would be updated to the specified value:

```ts  theme={null}
await myTask.trigger({ foo: "bar" }, { queue: { name: "my-queue", concurrencyLimit: 10 } });
```

This is no longer possible, and queues must now be defined ahead of time using the `queue` function:

```ts  theme={null}
import { queue } from "@trigger.dev/sdk";

const myQueue = queue({
  name: "my-queue",
  concurrencyLimit: 10,
});
```

Now when you trigger a task, you can only specify the queue by name:

```ts  theme={null}
await myTask.trigger({ foo: "bar" }, { queue: "my-queue" });
```

Or you can set the queue on the task:

```ts  theme={null}
import { queue, task } from "@trigger.dev/sdk";

const myQueue = queue({
  name: "my-queue",
  concurrencyLimit: 10,
});

export const myTask = task({
  id: "my-task",
  queue: myQueue,
  run: async (payload: any, { ctx }) => {},
});

// You can optionally specify the queue directly on the task
export const myTask2 = task({
  id: "my-task-2",
  queue: {
    name: "my-queue-2",
    concurrencyLimit: 50,
  },
  run: async (payload: any, { ctx }) => {},
});
```

Now you can trigger these tasks without having to specify the queue name in the trigger options:

```ts  theme={null}
await myTask.trigger({ foo: "bar" }); // Will use the queue defined on the task
await myTask2.trigger({ foo: "bar" }); // Will use the queue defined on the task
```

If you're using `concurrencyKey` you can specify the `queue` and `concurrencyKey` like this:

```ts  theme={null}
const handle = await generatePullRequest.trigger(data, {
  queue: "paid-users",
  concurrencyKey: data.userId,
});
```

For each unique value of `concurrencyKey`, a new queue will be created using the `concurrencyLimit` from the queue. This allows you to have a queue per user.

### Lifecycle hooks

We've changed the function signatures of the lifecycle hooks to be more consistent and easier to use, by unifying all the parameters into a single object that can be destructured.

Previously, hooks received a payload as the first argument and then an additional object as the second argument:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  onStart: ({ payload, ctx }) => {},
  run: async (payload, { ctx }) => {},
});
```

Now, all the parameters are passed in a single object:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  onStart: ({ payload, ctx }) => {},
  // The run function still uses separate parameters
  run: async (payload, { ctx }) => {},
});
```

This is true for all the lifecycle hooks:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  onStart: ({ payload, ctx, task }) => {},
  onSuccess: ({ payload, ctx, task, output }) => {},
  onFailure: ({ payload, ctx, task, error }) => {},
  onWait: ({ payload, ctx, task, wait }) => {},
  onResume: ({ payload, ctx, task, wait }) => {},
  onComplete: ({ payload, ctx, task, result }) => {},
  catchError: ({ payload, ctx, task, error, retry, retryAt, retryDelayInMs }) => {},
  run: async (payload, { ctx }) => {},
});
```

### Context changes

We've made a few small changes to the `ctx` object:

* `ctx.attempt.id` and `ctx.attempt.status` have been removed. `ctx.attempt.number` is still available.
* `ctx.task.exportName` has been removed (since we no longer require tasks to be exported to be triggered).

### BatchTrigger changes

The `batchTrigger` function no longer returns a `runs` list directly. In v3, you could access the runs directly from the batch handle:

```ts  theme={null}
// In v3
const batchHandle = await tasks.batchTrigger([
  [myTask, { foo: "bar" }],
  [myOtherTask, { baz: "qux" }],
]);

// You could access runs directly
console.log(batchHandle.runs);
```

In v4, you now need to use the `batch.retrieve()` method to get the batch with its runs:

```ts  theme={null}
// In v4
const batchHandle = await tasks.batchTrigger([
  [myTask, { foo: "bar" }],
  [myOtherTask, { baz: "qux" }],
]);

// Now you need to retrieve the batch to get the runs
const batch = await batch.retrieve(batchHandle.batchId);
console.log(batch.runs);
```

### OpenTelemetry

We are now using newer versions of the OpenTelemetry packages. This means that if you're using custom exporters you may need to update the packages:

| Package                                   | Previous Version | New Version | Change Type  |
| ----------------------------------------- | ---------------- | ----------- | ------------ |
| `@opentelemetry/api-logs`                 | 0.52.1           | 0.203.0     | Major update |
| `@opentelemetry/exporter-logs-otlp-http`  | 0.52.1           | 0.203.0     | Major update |
| `@opentelemetry/exporter-trace-otlp-http` | 0.52.1           | 0.203.0     | Major update |
| `@opentelemetry/instrumentation`          | 0.52.1           | 0.203.0     | Major update |


# Migrating from Mergent
Source: https://trigger.dev/docs/migration-mergent

A guide for migrating from Mergent to Trigger.dev

Mergent is being absorbed into Resend, so if youâ€™re running background jobs or scheduled tasks on Mergent, now is a good time to migrate. Trigger.dev is a modern, developer-friendly platform for background jobs, workflows, and scheduling.

### Why Trigger.dev?

* **Long-running, reliable tasks:** Write typical async code, no unfamiliar syntax to learn.
* **Automatic retries, concurrency, and scheduling:** Configure your tasks in your `trigger.config.ts` file.
* **Local dev that matches prod:** Run and debug jobs locally and view everything in the dashboard.
* **Scales with you:** Deploy your tasks to Trigger.dev Cloud with no infrastructure to manage. Or self-host.

## How to migrate to Trigger.dev

### Step 1: Set up Trigger.dev

1. **Create an account** at [Trigger.dev Cloud](https://cloud.trigger.dev).
2. **Create an organization and a project.**
3. **Install the CLI** and run the local dev server:

```bash  theme={null}
npx trigger.dev@latest init
npx trigger.dev@latest dev
```

Youâ€™ll get a local server that behaves just like production, and youâ€™ll see your runs in the dashboard.

### Step 2: Convert your Mergent task to a Trigger.dev task

#### Example: Basic Mergent Task

Hereâ€™s a simple Mergent task that processes an image:

```ts processVideo.ts theme={null}
export async function processVideoTask(req: { body: { videoUrl: string } }) {
  const { videoUrl } = req.body;
  // Do some video processing
  const result = await processVideo(videoUrl);
  return { success: true, processedUrl: result.url };
}
```

This is typically called by Mergent via HTTP POST, and youâ€™d register the endpoint in the Mergent dashboard.

#### The same task in Trigger.dev

```ts trigger/processVideo.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const processVideoTask = task({
  id: "process-video",
  run: async (payload: { videoUrl: string }) => {
    const result = await processVideo(payload.videoUrl);
    return { success: true, processedUrl: result.url };
  },
});
```

**Key differences:**

* In Mergent, your task is an HTTP handler; in Trigger.dev, itâ€™s a `task()` function that gets deployed on a managed worker for you.
* Trigger.dev gives you a typed payload, not a raw HTTP request.
* No need to handle HTTP status codes or errorsâ€”Trigger.dev handles retries and failures for you.
* You can export multiple tasks from a single file.

***

#### Scheduled task example

**Mergent scheduled task:**

Youâ€™d set up a schedule in the Mergent dashboard to hit your HTTP endpoint on a cron.

```ts dailyReport.ts theme={null}
export async function dailyReportTask(req) {
  await sendDailyReport();
}
```

**Trigger.dev scheduled task:**

```ts trigger/dailyReport.ts theme={null}
import { schedules } from "@trigger.dev/sdk";

export const dailyReportTask = schedules.task({
  id: "daily-report",
  cron: "0 0 * * *", // every day at midnight UTC
  run: async () => {
    await sendDailyReport();
  },
});
```

* In Trigger.dev, you can define the schedule right in your code (or attach it in the dashboard).
* No need to set up HTTP endpoints for each scheduled job.

## Triggering your tasks

**Mergent:** Youâ€™d trigger a task by calling the Mergent API, specifying the URL and payload.

```ts  theme={null}
const Mergent = require("mergent");
const mergent = new Mergent("API_KEY");

mergent.tasks.create({
  request: {
    url: "https://your-app.com/api/processImage",
    body: JSON.stringify({ imageUrl: "...", filters: ["blur"] }),
    headers: { "Content-Type": "application/json" },
  },
  delay: { minutes: 5 },
});
```

**Trigger.dev:** You trigger a task directly from your codebase, no HTTP endpoint needed.

```ts  theme={null}
import { processImageTask } from "@/trigger/processImage";

await processImageTask.trigger({
  imageUrl: "...",
  filters: ["blur"],
}, {
  delay: "5m",
});
```

* You can trigger tasks immediately, or add logic inside the task to delay execution (using `wait.for` or `wait.until`).
* No need to expose HTTP endpoints for every task.

**Summary:**

* Mergent tasks are HTTP handlers; Trigger.dev tasks are functions that get deployed on a managed worker for you.
* Scheduling and retries are built-in and configured in code.
* Trigger.dev tasks are type-safe, and easy to debug.
* You donâ€™t need to manage endpoints or handle HTTP manually.

Thatâ€™s it. Youâ€™re ready to migrate. If you need more advanced features such as concurrency, retries, metadata, chaining tasks, and more, check out the [Trigger.dev docs](https://trigger.dev/docs).


# Contributing
Source: https://trigger.dev/docs/open-source-contributing

You can contribute to Trigger.dev in many ways.

Go to our [GitHub repository](https://github.com/triggerdotdev/trigger.dev) and open an issue or a pull request. We are always looking for contributors to help us improve Trigger.dev. You can contribute in many ways, including:

* Reporting bugs
* Suggesting new features
* Writing documentation
* Writing code
* Reviewing code
* Translating the app
* Sharing the app with others
* Giving feedback
* And more!


# Docker (legacy)
Source: https://trigger.dev/docs/open-source-self-hosting

Self-host Trigger.dev on your own infrastructure using Docker.

<Note>This is a legacy guide for self-hosting v3 using Docker, you can find the v4 guide [here](/self-hosting/docker).</Note>

<Warning>Security, scaling, and reliability concerns are not fully addressed here. This guide is meant for evaluation purposes and won't result in a production-ready deployment.</Warning>

## Overview

<Frame>
  <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a0735cf11099c554fc16fbc1b49721e2" alt="Self-hosting architecture" data-og-width="1862" width="1862" data-og-height="1018" height="1018" data-path="images/self-hosting.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c248d1eef681ff4ef201b8f87644a795 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c1747b95e39b05b281de308d6c1c7cd5 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=978ef7e35a8202c64f7a1a09f023c31d 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=34072a757d06ab1653e481e95b44df77 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=de8a2a20758e1d26e6b8b4d9729561e4 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/self-hosting.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=86b4df1644f0d2ab7226937dffcf5c36 2500w" />
</Frame>

The self-hosting guide covers two alternative setups. The first option uses a simple setup where you run everything on one server. With the second option, the webapp and worker components are split on two separate machines.

You're going to need at least one Debian (or derivative) machine with Docker and Docker Compose installed. We'll also use Ngrok to expose the webapp to the internet.

## Support

It's dangerous to go alone! Join the self-hosting channel on our [Discord server](https://discord.gg/NQTxt5NA7s).

## Caveats

<Note>The v3 worker components don't have ARM support yet.</Note>

This guide outlines a quick way to start self-hosting Trigger.dev for evaluation purposes - it won't result in a production-ready deployment. Security, scaling, and reliability concerns are not fully addressed here.

As self-hosted deployments tend to have unique requirements and configurations, we don't provide specific advice for securing your deployment, scaling up, or improving reliability.

Should the burden ever get too much, we'd be happy to see you on [Trigger.dev cloud](https://trigger.dev/pricing) where we deal with these concerns for you.

<Accordion title="Please consider these additional warnings">
  * The [docker checkpoint](https://docs.docker.com/reference/cli/docker/checkpoint/) command is an experimental feature which may not work as expected. It won't be enabled by default. Instead, the containers will stay up and their processes frozen. They won't consume CPU but they *will* consume RAM.
  * The `docker-provider` does not currently enforce any resource limits. This means your tasks can consume up to the total machine CPU and RAM. Having no limits may be preferable when self-hosting, but can impact the performance of other services.
  * The worker components (not the tasks!) have direct access to the Docker socket. This means they can run any Docker command. To restrict access, you may want to consider using [Docker Socket Proxy](https://github.com/Tecnativa/docker-socket-proxy).
  * The task containers are running with host networking. This means there is no network isolation between them and the host machine. They will be able to access any networked service on the host.
  * There is currently no support for adding multiple worker machines, but we're working on it.
</Accordion>

## Requirements

* 4 CPU
* 8 GB RAM
* Debian or derivative
* Optional: A separate machine for the worker components

You will also need a way to expose the webapp to the internet. This can be done with a reverse proxy, or with a service like Ngrok. We will be using the latter in this guide.

## Option 1: Single server

This is the simplest setup. You run everything on one server. It's a good option if you have spare capacity on an existing machine, and have no need to independently scale worker capacity.

### Server setup

Some very basic steps to get started:

1. [Install Docker](https://docs.docker.com/get-docker/)
2. [Install Docker Compose](https://docs.docker.com/compose/install/)
3. [Install Ngrok](https://ngrok.com/download)

<Accordion title="On a Debian server, you can run these commands">
  ```bash  theme={null}
  # add ngrok repo
  curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | \
      sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && \
      echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | \
      sudo tee /etc/apt/sources.list.d/ngrok.list

  # add docker repo
  curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc && \
      sudo chmod a+r /etc/apt/keyrings/docker.asc && \
      echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \
        $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
        sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

  # update and install
  sudo apt-get update
  sudo apt-get install -y \
      docker.io \
      docker-compose-plugin \
      ngrok
  ```
</Accordion>

### Trigger.dev setup

1. Clone the [Trigger.dev docker repository](https://github.com/triggerdotdev/docker)

```bash  theme={null}
git clone https://github.com/triggerdotdev/docker
cd docker
```

2. Run the start script and follow the prompts

```bash  theme={null}
./start.sh # hint: you can append -d to run in detached mode
```

#### Manual

Alternatively, you can follow these manual steps after cloning the docker repo:

1. Create the `.env` file

```bash  theme={null}
cp .env.example .env
```

2. Generate the required secrets

```bash  theme={null}
echo MAGIC_LINK_SECRET=$(openssl rand -hex 16)
echo SESSION_SECRET=$(openssl rand -hex 16)
echo ENCRYPTION_KEY=$(openssl rand -hex 16)
echo PROVIDER_SECRET=$(openssl rand -hex 32)
echo COORDINATOR_SECRET=$(openssl rand -hex 32)
```

3. Replace the default secrets in the `.env` file with the generated ones

4. Run docker compose to start the services

```bash  theme={null}
. lib.sh # source the helper function
docker_compose -p=trigger up
```

### Tunnelling

You will need to expose the webapp to the internet. You can use Ngrok for this. If you already have a working reverse proxy setup and a domain, you can skip to the last step.

1. Start Ngrok. You may get prompted to sign up - it's free.

```bash  theme={null}
./tunnel.sh
```

2. Copy the domain from the output, for example: `1234-42-42-42-42.ngrok-free.app`

3. Uncomment the `TRIGGER_PROTOCOL` and `TRIGGER_DOMAIN` lines in the `.env` file. Set it to the domain you copied.

```bash  theme={null}
TRIGGER_PROTOCOL=https
TRIGGER_DOMAIN=1234-42-42-42-42.ngrok-free.app
```

4. Quit the start script and launch it again, or run this:

```bash  theme={null}
./stop.sh && ./start.sh
```

### Registry setup

If you want to deploy v3 projects, you will need access to a Docker registry. The [CLI deploy](/cli-deploy) command will push the images, and then the worker machine can pull them when needed. We will use Docker Hub as an example.

1. Sign up for a free account at [Docker Hub](https://hub.docker.com/)

2. Edit the `.env` file and add the registry details

```bash  theme={null}
DEPLOY_REGISTRY_HOST=docker.io
DEPLOY_REGISTRY_NAMESPACE=<your_dockerhub_username>
```

3. Log in to Docker Hub both locally and your server. For the split setup, this will be the worker machine. You may want to create an [access token](https://hub.docker.com/settings/security) for this.

```bash  theme={null}
docker login -u <your_dockerhub_username> docker.io
```

4. Required on some systems: Run the login command inside the `docker-provider` container so it can pull deployment images to run your tasks.

```bash  theme={null}
docker exec -ti \
  trigger-docker-provider-1 \
  docker login -u <your_dockerhub_username> docker.io
```

5. Restart the services

```bash  theme={null}
./stop.sh && ./start.sh
```

6. You can now deploy v3 projects using the CLI with these flags:

```
npx trigger.dev@latest deploy --self-hosted --push
```

## Option 2: Split services

With this setup, the webapp will run on a different machine than the worker components. This allows independent scaling of your workload capacity.

### Webapp setup

All steps are the same as for a single server, except for the following:

1. **Startup.** Run the start script with the `webapp` argument

```bash  theme={null}
./start.sh webapp
```

2. **Tunnelling.** This is now *required*. Please follow the [tunnelling](/open-source-self-hosting#tunnelling) section.

### Worker setup

1. **Environment variables.** Copy your `.env` file from the webapp to the worker machine:

```bash  theme={null}
# an example using scp
scp -3 root@<webapp_machine>:docker/.env root@<worker_machine>:docker/.env
```

2. **Startup.** Run the start script with the `worker` argument

```bash  theme={null}
./start.sh worker
```

3. **Tunnelling.** This is *not* required for the worker components.

4. **Registry setup.** Follow the [registry setup](/open-source-self-hosting#registry-setup) section but run the last command on the worker machine - note the container name is different:

```bash  theme={null}
docker exec -ti \
  trigger-worker-docker-provider-1 \
  docker login -u <your_dockerhub_username> docker.io
```

## Additional features

### Large payloads

By default, payloads over 512KB will be offloaded to S3-compatible storage. If you don't provide the required env vars, runs with payloads larger than this will fail.

For example, using Cloudflare R2:

```bash  theme={null}
OBJECT_STORE_BASE_URL="https://<bucket>.<account>.r2.cloudflarestorage.com"
OBJECT_STORE_ACCESS_KEY_ID="<r2 access key with read/write access to bucket>"
OBJECT_STORE_SECRET_ACCESS_KEY="<r2 secret key>"
```

Alternatively, you can increase the threshold:

```bash  theme={null}
# size in bytes, example with 5MB threshold
TASK_PAYLOAD_OFFLOAD_THRESHOLD=5242880
```

### Version locking

There are several reasons to lock the version of your Docker images:

* **Backwards compatibility.** We try our best to maintain compatibility with older CLI versions, but it's not always possible. If you don't want to update your CLI, you can lock your Docker images to that specific version.
* **Ensuring full feature support.** Sometimes, new CLI releases will also require new or updated platform features. Running unlocked images can make any issues difficult to debug. Using a specific tag can help here as well.

By default, the images will point at the latest versioned release via the `v3` tag. You can override this by specifying a different tag in your `.env` file. For example:

```bash  theme={null}
TRIGGER_IMAGE_TAG=v3.0.4
```

### Auth options

By default, magic link auth is the only login option. If the `EMAIL_TRANSPORT` env var is not set, the magic links will be logged by the webapp container and not sent via email.

Depending on your choice of mail provider/transport, you will want to configure a set of variables like one of the following:

##### Resend:

```bash  theme={null}
EMAIL_TRANSPORT=resend
FROM_EMAIL=
REPLY_TO_EMAIL=
RESEND_API_KEY=<your_resend_api_key>
```

##### SMTP

Note that setting `SMTP_SECURE=false` does *not* mean the email is sent insecurely.
This simply means that the connection is secured using the modern STARTTLS protocol command instead of implicit TLS.
You should only set this to true when the SMTP server host directs you to do so (generally when using port 465)

```bash  theme={null}
EMAIL_TRANSPORT=smtp
FROM_EMAIL=
REPLY_TO_EMAIL=
SMTP_HOST=<your_smtp_server>
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=<your_smtp_username>
SMTP_PASSWORD=<your_smtp_password>
```

##### AWS Simple Email Service

Credentials are to be supplied as with any other program using the AWS SDK.
In this scenario, you would likely either supply the additional environment variables `AWS_REGION`, `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` or, when running on AWS, use credentials supplied by the EC2 IMDS.

```bash  theme={null}
EMAIL_TRANSPORT=aws-ses
FROM_EMAIL=
REPLY_TO_EMAIL=
```

All email addresses can sign up and log in this way. If you would like to restrict this, you can use the `WHITELISTED_EMAILS` env var. For example:

```bash  theme={null}
# every email that does not match this regex will be rejected
WHITELISTED_EMAILS="authorized@yahoo\.com|authorized@gmail\.com"
```

It's currently impossible to restrict GitHub OAuth logins by account name or email like above, so this method is *not recommended* for self-hosted instances. It's also very easy to lock yourself out of your own instance.

<Warning>Only enable GitHub auth if you understand the risks! We strongly advise you against this.</Warning>

Your GitHub OAuth app needs a callback URL `https://<your_domain>/auth/github/callback` and you will have to set the following env vars:

```bash  theme={null}
AUTH_GITHUB_CLIENT_ID=<your_client_id>
AUTH_GITHUB_CLIENT_SECRET=<your_client_secret>
```

### Checkpoint support

<Warning>
  This requires an *experimental Docker feature*. Successfully checkpointing a task today, does not
  mean you will be able to restore it tomorrow. Your data may be lost. You've been warned!
</Warning>

Checkpointing allows you to save the state of a running container to disk and restore it later. This can be useful for
long-running tasks that need to be paused and resumed without losing state. Think fan-out and fan-in, or long waits in email campaigns.

The checkpoints will be pushed to the same registry as the deployed images. Please see the [registry setup](#registry-setup) section for more information.

#### Requirements

* Debian, **NOT** a derivative like Ubuntu
* Additional storage space for the checkpointed containers

#### Setup

Underneath the hood this uses Checkpoint and Restore in Userspace, or [CRIU](https://github.com/checkpoint-restore/criu) in short. We'll have to do a few things to get this working:

1. Install CRIU

```bash  theme={null}
sudo apt-get update
sudo apt-get install criu
```

2. Tweak the config so we can successfully checkpoint our workloads

```bash  theme={null}
mkdir -p /etc/criu

cat << EOF >/etc/criu/runc.conf
tcp-close
EOF
```

3. Make sure everything works

```bash  theme={null}
sudo criu check
```

3. Enable Docker experimental features, by adding the following to `/etc/docker/daemon.json`

```json  theme={null}
{
  "experimental": true
}
```

4. Restart the Docker daemon

```bash  theme={null}
sudo systemctl restart docker
```

5. Uncomment `FORCE_CHECKPOINT_SIMULATION=0` in your `.env` file. Alternatively, run this:

```bash  theme={null}
echo "FORCE_CHECKPOINT_SIMULATION=0" >> .env
```

6. Restart the services

```bash  theme={null}
# if you're running everything on the same machine
./stop.sh && ./start.sh

# if you're running the worker on a different machine
./stop.sh worker && ./start.sh worker
```

## Updating

Once you have everything set up, you will periodically want to update your Docker images. You can easily do this by running the update script and restarting your services:

```bash  theme={null}
./update.sh
./stop.sh && ./start.sh
```

Sometimes, we will make more extensive changes that require pulling updated compose files, scripts, etc from our docker repo:

```bash  theme={null}
git pull
./stop.sh && ./start.sh
```

Occasionally, you may also have to update your `.env` file, but we will try to keep these changes to a minimum. Check the `.env.example` file for new variables.

### From beta

If you're coming from the beta CLI package images, you will need to:

* **Stash you changes.** If you made any changes, stash them with `git stash`.
* **Switch branches.** We moved back to main. Run `git checkout main` in your docker repo.
* **Pull in updates.** We've added a new container for [Electric](https://github.com/electric-sql/electric) and made some other improvements. Run `git pull` to get the latest updates.
* **Apply your changes.** If you stashed your changes, apply them with `git stash pop`.
* **Update your images.** We've also published new images. Run `./update.sh` to pull them.
* **Restart all services.** Run `./stop.sh && ./start.sh` and you're good to go.

In summary, run this wherever you cloned the docker repo:

```bash  theme={null}
# if you made changes
git stash

# switch to the main branch and pull the latest changes
git checkout main
git pull

# if you stashed your changes
git stash pop

# update and restart your services
./update.sh
./stop.sh && ./start.sh
```

## Troubleshooting

* **Deployment fails at the push step.** The machine running `deploy` needs registry access:

```bash  theme={null}
docker login -u <username> <registry>
# this should now succeed
npx trigger.dev@latest deploy --self-hosted --push
```

* **Prod runs fail to start.** The `docker-provider` needs registry access:

```bash  theme={null}
# single server? run this:
docker exec -ti \
  trigger-docker-provider-1 \
  docker login -u <your_dockerhub_username> docker.io

# split webapp and worker? run this on the worker:
docker exec -ti \
  trigger-worker-docker-provider-1 \
  docker login -u <your_dockerhub_username> docker.io
```

## CLI usage

This section highlights some of the CLI commands and options that are useful when self-hosting. Please check the [CLI reference](/cli-introduction) for more in-depth documentation.

### Login

To avoid being redirected to the [Trigger.dev Cloud](https://cloud.trigger.dev) login page when using the CLI, you can specify the URL of your self-hosted instance with the `--api-url` or `-a` flag. For example:

```bash  theme={null}
npx trigger.dev@latest login -a http://trigger.example.com
```

Once you've logged in, the CLI will remember your login details and you won't need to specify the URL again with other commands.

#### Custom profiles

You can specify a custom profile when logging in. This allows you to easily use the CLI with our cloud product and your self-hosted instance at the same time. For example:

```
npx trigger.dev@latest login -a http://trigger.example.com --profile my-profile
```

You can then use this profile with other commands:

```
npx trigger.dev@latest dev --profile my-profile
```

To list all your profiles, use the `list-profiles` command:

```
npx trigger.dev@latest list-profiles
```

#### Verify login

It can be useful to check you have successfully logged in to the correct instance. You can do this with the `whoami` command, which will also show the API URL:

```bash  theme={null}
npx trigger.dev@latest whoami

# with a custom profile
npx trigger.dev@latest whoami --profile my-profile
```

### Deploy

On [Trigger.dev Cloud](https://cloud.trigger.dev), we build deployments remotely and push those images for you. When self-hosting you will have to do that locally yourself. This can be done with the `--self-hosted` and `--push` flags. For example:

```
npx trigger.dev@latest deploy --self-hosted --push
```

### CI / GitHub Actions

When running the CLI in a CI environment, your login profiles won't be available. Instead, you can use the `TRIGGER_API_URL` and `TRIGGER_ACCESS_TOKEN` environment
variables to point at your self-hosted instance and authenticate.

For more detailed instructions, see the [GitHub Actions guide](/github-actions).

## Telemetry

By default, the Trigger.dev webapp sends telemetry data to our servers. This data is used to improve the product and is not shared with third parties. If you would like to opt-out of this, you can set the `TRIGGER_TELEMETRY_DISABLED` environment variable in your `.env` file. The value doesn't matter, it just can't be empty. For example:

```bash  theme={null}
TRIGGER_TELEMETRY_DISABLED=1
```


# Concurrency & Queues
Source: https://trigger.dev/docs/queue-concurrency

Configure what you want to happen when there is more than one run at a time.

When you trigger a task, it isn't executed immediately. Instead, the task [run](/runs) is placed into a queue for execution.

By default, each task gets its own queue and the concurrency is only limited by your environment concurrency limit. If you need more control (for example, to limit concurrency or share limits across multiple tasks), you can define a custom queue as described later.

Controlling concurrency is useful when you have a task that can't be run concurrently, or when you want to limit the number of runs to avoid overloading a resource.

It's important to note that only actively executing runs count towards concurrency limits. Runs that are delayed or waiting in a queue do not consume concurrency slots until they begin execution.

## Default concurrency

By default, all tasks have an unbounded concurrency limit, limited only by the overall concurrency limits of your environment.

<Note>
  Your environment has a base concurrency limit and a burstable limit (default burst factor of 2.0x
  the base limit). Individual queues are limited by the base concurrency limit, not the burstable
  limit. For example, if your base limit is 10, your environment can burst up to 20 concurrent runs,
  but any single queue can have at most 10 concurrent runs. If you're a paying customer you can
  request higher burst limits by [contacting us](https://www.trigger.dev/contact).
</Note>

## Setting task concurrency

You can set the concurrency limit for a task by setting the `concurrencyLimit` property on the task's queue. This limits the number of runs that can be executing at any one time:

```ts /trigger/one-at-a-time.ts theme={null}
// This task will only run one at a time
export const oneAtATime = task({
  id: "one-at-a-time",
  queue: {
    concurrencyLimit: 1,
  },
  run: async (payload) => {
    //...
  },
});
```

This is useful if you need to control access to a shared resource, like a database or an API that has rate limits.

## Sharing concurrency between tasks

As well as putting queue settings directly on a task, you can define a queue and reuse it across multiple tasks. This allows you to share the same concurrency limit:

```ts /trigger/queue.ts theme={null}
export const myQueue = queue({
  name: "my-queue",
  concurrencyLimit: 1,
});

export const task1 = task({
  id: "task-1",
  queue: myQueue,
  run: async (payload: { message: string }) => {
    // ...
  },
});

export const task2 = task({
  id: "task-2",
  queue: myQueue,
  run: async (payload: { message: string }) => {
    // ...
  },
});
```

In this example, `task1` and `task2` share the same queue, so only one of them can run at a time.

## Setting the queue when you trigger a run

When you trigger a task you can override the default queue. This is really useful if you sometimes have high priority runs.

The task and queue definition:

```ts /trigger/override-concurrency.ts theme={null}
const paidQueue = queue({
  name: "paid-users",
  concurrencyLimit: 10,
});

export const generatePullRequest = task({
  id: "generate-pull-request",
  queue: {
    //normally when triggering this task it will be limited to 1 run at a time
    concurrencyLimit: 1,
  },
  run: async (payload) => {
    //todo generate a PR using OpenAI
  },
});
```

Triggering from your backend and overriding the queue:

```ts app/api/push/route.ts theme={null}
import { generatePullRequest } from "~/trigger/override-concurrency";

export async function POST(request: Request) {
  const data = await request.json();

  if (data.branch === "main") {
    //trigger the task, with the paid users queue
    const handle = await generatePullRequest.trigger(data, {
      // Set the paid users queue
      queue: "paid-users",
    });

    return Response.json(handle);
  } else {
    //triggered with the default queue (concurrency of 1)
    const handle = await generatePullRequest.trigger(data);
    return Response.json(handle);
  }
}
```

## Concurrency keys and per-tenant queuing

If you're building an application where you want to run tasks for your users, you might want a separate queue for each of your users (or orgs, projects, etc.).

You can do this by using `concurrencyKey`. It creates a copy of the queue for each unique value of the key.

Your backend code:

```ts app/api/pr/route.ts theme={null}
import { generatePullRequest } from "~/trigger/override-concurrency";

export async function POST(request: Request) {
  const data = await request.json();

  if (data.isFreeUser) {
    //the "free-users" queue has a concurrency limit of 1
    const handle = await generatePullRequest.trigger(data, {
      queue: "free-users",
      //this creates a free-users queue for each user
      concurrencyKey: data.userId,
    });

    //return a success response with the handle
    return Response.json(handle);
  } else {
    //the "paid-users" queue has a concurrency limit of 10
    const handle = await generatePullRequest.trigger(data, {
      queue: "paid-users",
      //this creates a paid-users queue for each user
      concurrencyKey: data.userId,
    });

    //return a success response with the handle
    return Response.json(handle);
  }
}
```

## Concurrency and subtasks

When you trigger a task that has subtasks, the subtasks will not inherit the queue from the parent task. Unless otherwise specified, subtasks will run on their own queue

```ts /trigger/subtasks.ts theme={null}
export const parentTask = task({
  id: "parent-task",
  run: async (payload) => {
    //trigger a subtask
    await subtask.triggerAndWait(payload);
  },
});

// This subtask will run on its own queue
export const subtask = task({
  id: "subtask",
  run: async (payload) => {
    //...
  },
});
```

## Waits and concurrency

With our [task checkpoint system](/how-it-works#the-checkpoint-resume-system), tasks can wait at various waitpoints (like waiting for subtasks to complete, delays, or external events). The way this system interacts with the concurrency system is important to understand.

Concurrency is only released when a run reaches a waitpoint and is checkpointed. When a run is checkpointed, it transitions to the `WAITING` state and releases its concurrency slot back to both the queue and the environment, allowing other runs to execute or resume.

This means that:

* Only actively executing runs count towards concurrency limits
* Runs in the `WAITING` state (checkpointed at waitpoints) do not consume concurrency slots
* You can have more runs in the `WAITING` state than your queue's concurrency limit
* When a waiting run resumes (e.g., when a subtask completes), it must re-acquire a concurrency slot

For example, if you have a queue with a `concurrencyLimit` of 1:

* You can only have exactly 1 run executing at a time
* You may have multiple runs in the `WAITING` state that belong to that queue
* When the executing run reaches a waitpoint and checkpoints, it releases its slot
* The next queued run can then begin execution

### Waiting for a subtask on a different queue

When a parent task triggers and waits for a subtask on a different queue, the parent task will checkpoint and release its concurrency slot once it reaches the wait point. This prevents environment deadlocks where all concurrency slots would be occupied by waiting tasks.

```ts /trigger/waiting.ts theme={null}
export const parentTask = task({
  id: "parent-task",
  queue: {
    concurrencyLimit: 1,
  },
  run: async (payload) => {
    //trigger a subtask and wait for it to complete
    await subtask.triggerAndWait(payload);
    // The parent task checkpoints here and releases its concurrency slot
    // allowing other tasks to execute while waiting
  },
});

export const subtask = task({
  id: "subtask",
  run: async (payload) => {
    //...
  },
});
```

When the parent task reaches the `triggerAndWait` call, it checkpoints and transitions to the `WAITING` state, releasing its concurrency slot back to both its queue and the environment. Once the subtask completes, the parent task will resume and re-acquire a concurrency slot.


# Quick start
Source: https://trigger.dev/docs/quick-start

How to get started in 3 minutes using the CLI and SDK.

In this guide we will:

1. Create a `trigger.config.ts` file and a `/trigger` directory with an example task.
2. Get you to run the task using the CLI.
3. Show you how to view the run logs for that task.

<Steps titleSize="h3">
  <Step title="Create a Trigger.dev account">
    You can either:

    * Use the [Trigger.dev Cloud](https://cloud.trigger.dev).
    * Or [self-host](/open-source-self-hosting) the service.
  </Step>

  <Step title="Create your first project">
    Once you've created an account, follow the steps in the app to:

    1. Complete your account details.
    2. Create your first Organization and Project.
  </Step>

  <Step title="Run the CLI `init` command">
    The easiest way to get started is to use the CLI. It will add Trigger.dev to your existing project, create a `/trigger` folder and give you an example task.

    Run this command in the root of your project to get started:

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest init
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest init
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest init
      ```
    </CodeGroup>

    It will do a few things:

    1. Log you into the CLI if you're not already logged in.
    2. Create a `trigger.config.ts` file in the root of your project.
    3. Ask where you'd like to create the `/trigger` directory.
    4. Create the `/trigger` directory with an example task, `/trigger/example.[ts/js]`.

    Install the "Hello World" example task when prompted. We'll use this task to test the setup.
  </Step>

  <Step title="Run the CLI `dev` command">
    The CLI `dev` command runs a server for your tasks. It watches for changes in your `/trigger` directory and communicates with the Trigger.dev platform to register your tasks, perform runs, and send data back and forth.

    It can also update your `@trigger.dev/*` packages to prevent version mismatches and failed deploys. You will always be prompted first.

    <CodeGroup>
      ```bash npm theme={null}
      npx trigger.dev@latest dev
      ```

      ```bash pnpm theme={null}
      pnpm dlx trigger.dev@latest dev
      ```

      ```bash yarn theme={null}
      yarn dlx trigger.dev@latest dev
      ```
    </CodeGroup>
  </Step>

  <Step title="Perform a test run using the dashboard">
    The CLI `dev` command spits out various useful URLs. Right now we want to visit the Test page.

    You should see our Example task in the list <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" />, select it. Most tasks have a "payload" which you enter in the JSON editor <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" />, but our example task doesn't need any input.

    You can configure options on the run <Icon icon="circle-3" iconType="solid" size={20} color="F43F47" />, view recent payloads <Icon icon="circle-4" iconType="solid" size={20} color="F43F47" />, and create run templates <Icon icon="circle-5" iconType="solid" size={20} color="F43F47" />.

    Press the "Run test" button <Icon icon="circle-6" iconType="solid" size={20} color="F43F47" />.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Test page" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />
  </Step>

  <Step title="View your run">
    Congratulations, you should see the run page which will live reload showing you the current state of the run.

        <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4b0bb5f9b181499cf324cdb8d5d673a8" alt="Run page" data-og-width="2978" width="2978" data-og-height="2110" height="2110" data-path="images/run-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d7f419295b621c779c6a9a10b9152958 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c66995702aace3888813ee1a66d33f97 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c6c36408dc85f156d15a333ddb849d26 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2c1d7275465749eeae32196698f4a1b5 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6965f3e2263296fb6529384021ce362a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-page.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7d890c5d199be7feaddc9162435bcc17 2500w" />

    If you go back to your terminal you'll see that the dev command also shows the task status and links to the run log.

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a9284c5228343b72d798c6e36f5acb24" alt="Terminal showing completed run" data-og-width="955" width="955" data-og-height="197" height="197" data-path="images/terminal-completed-run.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62826752155594bd580ae51582870cce 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5270d0e823346fe8517fcc356cc5d20c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8ae13acb781c5d08e2351af3c2cbb70a 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=da9e9f485055786210b6d7ce3812b9cf 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=dd59fd38559b7b7ca865a015d029e0de 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/terminal-completed-run.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4de391f21eb74db6e3f7c174d86b4b71 2500w" />
  </Step>
</Steps>

## Next steps

<CardGroup>
  <Card title="How to trigger your tasks" icon="bolt" href="/triggering">
    Learn how to trigger tasks from your code.
  </Card>

  <Card title="Writing tasks" icon="wand-magic-sparkles" href="/tasks/overview">
    Tasks are the core of Trigger.dev. Learn what they are and how to write them.
  </Card>
</CardGroup>


# Realtime authentication
Source: https://trigger.dev/docs/realtime/auth

Authenticating real-time API requests with Public Access Tokens or Trigger Tokens

To use the Realtime API, you need to authenticate your requests with Public Access Tokens or Trigger Tokens. These tokens provide secure, scoped access to your runs and can be used in both frontend and backend applications.

## Token Types

There are two types of tokens you can use with the Realtime API:

* **[Public Access Tokens](#public-access-tokens-for-subscribing-to-runs)** - Used to read and subscribe to run data. Can be used in both the frontend and backend.
* **[Trigger Tokens](#trigger-tokens-for-frontend-triggering-only)** - Used to trigger tasks from your frontend. These are more secure, single-use tokens that can only be used in the frontend.

## Public Access Tokens (for subscribing to runs)

Use Public Access Tokens to subscribe to runs and receive real-time updates in your frontend or backend.

### Creating Public Access Tokens

You can create a Public Access Token using the `auth.createPublicToken` function in your **backend** code:

```tsx  theme={null}
// Somewhere in your backend code
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken(); // ðŸ‘ˆ this public access token has no permissions, so is pretty useless!
```

### Scopes

By default a Public Access Token has no permissions. You must specify the scopes you need when creating a Public Access Token:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: true, // âŒ this token can read all runs, possibly useful for debugging/testing
    },
  },
});
```

This will allow the token to read all runs, which is probably not what you want. You can specify only certain runs by passing an array of run IDs:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: ["run_1234", "run_5678"], // âœ… this token can read only these runs
    },
  },
});
```

You can scope the token to only read certain tasks:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      tasks: ["my-task-1", "my-task-2"], // ðŸ‘ˆ this token can read all runs of these tasks
    },
  },
});
```

Or tags:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      tags: ["my-tag-1", "my-tag-2"], // ðŸ‘ˆ this token can read all runs with these tags
    },
  },
});
```

Or a specific batch of runs:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      batch: "batch_1234", // ðŸ‘ˆ this token can read all runs in this batch
    },
  },
});
```

You can also combine scopes. For example, to read runs with specific tags and for specific tasks:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      tasks: ["my-task-1", "my-task-2"],
      tags: ["my-tag-1", "my-tag-2"],
    },
  },
});
```

### Expiration

By default, Public Access Token's expire after 15 minutes. You can specify a different expiration time when creating a Public Access Token:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

const publicToken = await auth.createPublicToken({
  expirationTime: "1hr",
});
```

* If `expirationTime` is a string, it will be treated as a time span
* If `expirationTime` is a number, it will be treated as a Unix timestamp
* If `expirationTime` is a `Date`, it will be treated as a date

The format used for a time span is the same as the [jose package](https://github.com/panva/jose), which is a number followed by a unit. Valid units are: "sec", "secs", "second", "seconds", "s", "minute", "minutes", "min", "mins", "m", "hour", "hours", "hr", "hrs", "h", "day", "days", "d", "week", "weeks", "w", "year", "years", "yr", "yrs", and "y". It is not possible to specify months. 365.25 days is used as an alias for a year. If the string is suffixed with "ago", or prefixed with a "-", the resulting time span gets subtracted from the current unix timestamp. A "from now" suffix can also be used for readability when adding to the current unix timestamp.

### Auto-generated tokens

When you [trigger tasks](/triggering) from your backend, the `handle` received includes a `publicAccessToken` field. This token can be used to authenticate real-time requests in your frontend application.

By default, auto-generated tokens expire after 15 minutes and have a read scope for the specific run(s) that were triggered. You can customize the expiration by passing a `publicTokenOptions` object to the trigger function.

See our [triggering documentation](/triggering) for detailed examples of how to trigger tasks and get auto-generated tokens.

### Subscribing to runs with Public Access Tokens

Once you have a Public Access Token, you can use it to authenticate requests to the Realtime API in both backend and frontend applications.

**Backend usage:** See our [backend documentation](/realtime/backend) for examples of what you can do with Realtime in your backend once you have authenticated with a token.

**Frontend usage:** See our [React hooks documentation](/realtime/react-hooks) for examples of using tokens with frontend components.

## Trigger Tokens (for frontend triggering only)

For triggering tasks from your frontend, you need special "trigger" tokens. These tokens can only be used once to trigger a task and are more secure than regular Public Access Tokens.

### Creating Trigger Tokens

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

// Somewhere in your backend code
const triggerToken = await auth.createTriggerPublicToken("my-task");
```

### Multiple tasks

You can pass multiple tasks to create a token that can trigger multiple tasks:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

// Somewhere in your backend code
const triggerToken = await auth.createTriggerPublicToken(["my-task-1", "my-task-2"]);
```

### Multiple use

You can also create tokens that can be used multiple times:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

// Somewhere in your backend code
const triggerToken = await auth.createTriggerPublicToken("my-task", {
  multipleUse: true, // âŒ Use this with caution!
});
```

### Expiration

These tokens also expire, with the default expiration time being 15 minutes. You can specify a custom expiration time:

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

// Somewhere in your backend code
const triggerToken = await auth.createTriggerPublicToken("my-task", {
  expirationTime: "24hr",
});
```

### Triggering tasks from the frontend with Trigger Tokens

Check out our [React hooks documentation](/realtime/react-hooks) for examples of how to use Trigger Tokens in your frontend applications.


# Backend overview
Source: https://trigger.dev/docs/realtime/backend/overview

Using the Trigger.dev realtime API from your backend code

Use these backend functions to subscribe to runs and streams from your server-side code or other tasks.

## Overview

There are three main categories of functionality:

* **[Subscribe functions](/realtime/backend/subscribe)** - Subscribe to run updates using async iterators
* **[Metadata](/realtime/backend/subscribe#subscribe-to-metadata-updates-from-your-tasks)** - Update and subscribe to run metadata in real-time
* **[Streams](/realtime/backend/streams)** - Read and consume real-time streaming data from your tasks

<Note>
  To learn how to emit streams from your tasks, see our [Realtime Streams](/tasks/streams) documentation.
</Note>

## Authentication

All backend functions support both server-side and client-side authentication:

* **Server-side**: Use your API key (automatically handled in tasks)
* **Client-side**: Generate a Public Access Token with appropriate scopes

See our [authentication guide](/realtime/auth) for detailed information on creating and using tokens.

## Quick example

Subscribe to a run:

```ts  theme={null}
import { runs, tasks } from "@trigger.dev/sdk";

// Trigger a task
const handle = await tasks.trigger("my-task", { some: "data" });

// Subscribe to real-time updates
for await (const run of runs.subscribeToRun(handle.id)) {
  console.log(`Run ${run.id} status: ${run.status}`);
}
```


# Streams
Source: https://trigger.dev/docs/realtime/backend/streams

Read and consume real-time streaming data from your tasks in your backend

The Streams API allows you to read streaming data from your Trigger.dev tasks in your backend code. This is particularly useful for consuming AI/LLM outputs, progress updates, or any other real-time data that your tasks emit.

<Note>
  To learn how to emit streams from your tasks, see our [Realtime Streams](/tasks/streams) documentation. For frontend applications using React, see our [React hooks streams documentation](/realtime/react-hooks/streams).
</Note>

## Reading streams

### Using defined streams (Recommended)

The recommended approach is to use [defined streams](/tasks/streams#defining-typed-streams-recommended) for full type safety:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function consumeStream(runId: string) {
  // Read from the defined stream
  const stream = await aiStream.read(runId);

  let fullText = "";

  for await (const chunk of stream) {
    console.log("Received chunk:", chunk); // chunk is typed!
    fullText += chunk;
  }

  console.log("Final text:", fullText);
}
```

### Direct stream reading

If you prefer not to use defined streams, you can read directly by specifying the stream key:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";

async function consumeStream(runId: string) {
  // Read from a stream by key
  const stream = await streams.read<string>(runId, "ai-output");

  for await (const chunk of stream) {
    console.log("Received chunk:", chunk);
  }
}
```

### Reading from the default stream

Every run has a default stream, so you can omit the stream key:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";

async function consumeDefaultStream(runId: string) {
  // Read from the default stream
  const stream = await streams.read<string>(runId);

  for await (const chunk of stream) {
    console.log("Received chunk:", chunk);
  }
}
```

## Stream options

The `read()` method accepts several options for controlling stream behavior:

### Timeout

Set a timeout to stop reading if no data is received within a specified time:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function consumeWithTimeout(runId: string) {
  const stream = await aiStream.read(runId, {
    timeoutInSeconds: 120, // Wait up to 2 minutes for data
  });

  try {
    for await (const chunk of stream) {
      console.log("Received chunk:", chunk);
    }
  } catch (error) {
    if (error.name === "TimeoutError") {
      console.log("Stream timed out");
    }
  }
}
```

### Start index

Resume reading from a specific chunk index (useful for reconnection scenarios):

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function resumeStream(runId: string, lastChunkIndex: number) {
  // Start reading from the chunk after the last one we received
  const stream = await aiStream.read(runId, {
    startIndex: lastChunkIndex + 1,
  });

  for await (const chunk of stream) {
    console.log("Received chunk:", chunk);
  }
}
```

### Abort signal

Use an `AbortSignal` to cancel stream reading:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function consumeWithCancellation(runId: string) {
  const controller = new AbortController();

  // Cancel after 30 seconds
  setTimeout(() => controller.abort(), 30000);

  const stream = await aiStream.read(runId, {
    signal: controller.signal,
  });

  try {
    for await (const chunk of stream) {
      console.log("Received chunk:", chunk);

      // Optionally abort based on content
      if (chunk.includes("STOP")) {
        controller.abort();
      }
    }
  } catch (error) {
    if (error.name === "AbortError") {
      console.log("Stream was cancelled");
    }
  }
}
```

### Combining options

You can combine multiple options:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function advancedStreamConsumption(runId: string) {
  const controller = new AbortController();

  const stream = await aiStream.read(runId, {
    timeoutInSeconds: 300, // 5 minute timeout
    startIndex: 0, // Start from the beginning
    signal: controller.signal, // Allow cancellation
  });

  try {
    for await (const chunk of stream) {
      console.log("Received chunk:", chunk);
    }
  } catch (error) {
    if (error.name === "AbortError") {
      console.log("Stream was cancelled");
    } else if (error.name === "TimeoutError") {
      console.log("Stream timed out");
    } else {
      console.error("Stream error:", error);
    }
  }
}
```

## Practical examples

### Reading AI streaming responses

Here's a complete example of consuming an AI stream from your backend:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function consumeAIStream(runId: string) {
  const stream = await aiStream.read(runId, {
    timeoutInSeconds: 300, // AI responses can take time
  });

  let fullResponse = "";
  const chunks: string[] = [];

  for await (const chunk of stream) {
    chunks.push(chunk);
    fullResponse += chunk;

    // Process each chunk as it arrives
    console.log("Chunk received:", chunk);

    // Could send to websocket, SSE, etc.
    // await sendToClient(chunk);
  }

  console.log("Stream complete!");
  console.log("Total chunks:", chunks.length);
  console.log("Full response:", fullResponse);

  return { fullResponse, chunks };
}
```

### Reading multiple streams

If a task emits multiple streams, you can read them concurrently or sequentially:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream, progressStream } from "./trigger/streams";

async function consumeMultipleStreams(runId: string) {
  // Read streams concurrently
  const [aiData, progressData] = await Promise.all([
    consumeStream(aiStream, runId),
    consumeStream(progressStream, runId),
  ]);

  return { aiData, progressData };
}

async function consumeStream<T>(
  streamDef: { read: (runId: string) => Promise<AsyncIterableStream<T>> },
  runId: string
): Promise<T[]> {
  const stream = await streamDef.read(runId);
  const chunks: T[] = [];

  for await (const chunk of stream) {
    chunks.push(chunk);
  }

  return chunks;
}
```

### Piping streams to HTTP responses

You can pipe streams directly to HTTP responses for server-sent events (SSE):

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";
import type { NextRequest } from "next/server";

export async function GET(request: NextRequest) {
  const runId = request.nextUrl.searchParams.get("runId");

  if (!runId) {
    return new Response("Missing runId", { status: 400 });
  }

  const stream = await aiStream.read(runId, {
    timeoutInSeconds: 300,
  });

  // Create a readable stream for SSE
  const encoder = new TextEncoder();
  const readableStream = new ReadableStream({
    async start(controller) {
      try {
        for await (const chunk of stream) {
          // Format as SSE
          const data = `data: ${JSON.stringify({ chunk })}\n\n`;
          controller.enqueue(encoder.encode(data));
        }
        controller.close();
      } catch (error) {
        controller.error(error);
      }
    },
  });

  return new Response(readableStream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
    },
  });
}
```

### Implementing retry logic

Handle transient errors with retry logic:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function consumeStreamWithRetry(
  runId: string,
  maxRetries = 3
): Promise<string[]> {
  let lastChunkIndex = 0;
  const allChunks: string[] = [];
  let attempt = 0;

  while (attempt < maxRetries) {
    try {
      const stream = await aiStream.read(runId, {
        startIndex: lastChunkIndex,
        timeoutInSeconds: 120,
      });

      for await (const chunk of stream) {
        allChunks.push(chunk);
        lastChunkIndex++;
      }

      // Success! Break out of retry loop
      break;
    } catch (error) {
      attempt++;

      if (attempt >= maxRetries) {
        throw new Error(`Failed after ${maxRetries} attempts: ${error.message}`);
      }

      console.log(`Retry attempt ${attempt} after error:`, error.message);

      // Wait before retrying (exponential backoff)
      await new Promise((resolve) => setTimeout(resolve, 1000 * Math.pow(2, attempt)));
    }
  }

  return allChunks;
}
```

### Processing streams in chunks

Process streams in batches for efficiency:

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { aiStream } from "./trigger/streams";

async function processStreamInBatches(runId: string, batchSize = 10) {
  const stream = await aiStream.read(runId);

  let batch: string[] = [];

  for await (const chunk of stream) {
    batch.push(chunk);

    if (batch.length >= batchSize) {
      // Process the batch
      await processBatch(batch);
      batch = [];
    }
  }

  // Process remaining chunks
  if (batch.length > 0) {
    await processBatch(batch);
  }
}

async function processBatch(chunks: string[]) {
  console.log(`Processing batch of ${chunks.length} chunks`);
  // Do something with the batch
  // e.g., save to database, send to queue, etc.
}
```

## Using with `runs.subscribeToRun()`

For more advanced use cases where you need both the run status and streams, you can use the `runs.subscribeToRun()` method with `.withStreams()`:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/myTask";

async function subscribeToRunAndStreams(runId: string) {
  for await (const update of runs.subscribeToRun<typeof myTask>(runId).withStreams()) {
    switch (update.type) {
      case "run":
        console.log("Run update:", update.run.status);
        break;
      case "default":
        console.log("Stream chunk:", update.chunk);
        break;
    }
  }
}
```

<Note>
  For most use cases, we recommend using `streams.read()` with defined streams for better type safety and clearer code. Use `runs.subscribeToRun().withStreams()` only when you need to track both run status and stream data simultaneously.
</Note>


# Subscribe functions
Source: https://trigger.dev/docs/realtime/backend/subscribe

Subscribe to run updates using async iterators

These functions allow you to subscribe to run updates from your backend code. Each function returns an async iterator that yields run objects as they change.

## runs.subscribeToRun

Subscribes to all changes to a specific run.

```ts Example theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.subscribeToRun("run_1234")) {
  console.log(run);
}
```

This function subscribes to all changes to a run. It returns an async iterator that yields the run object whenever the run is updated. The iterator will complete when the run is finished.

**Authentication**: This function supports both server-side and client-side authentication. For server-side authentication, use your API key. For client-side authentication, you must generate a public access token with read access to the specific run. See our [authentication guide](/realtime/auth) for details.

**Response**: The AsyncIterator yields the [run object](/realtime/run-object).

## runs.subscribeToRunsWithTag

Subscribes to all changes to runs with a specific tag.

```ts Example theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.subscribeToRunsWithTag("user:1234")) {
  console.log(run);
}
```

This function subscribes to all changes to runs with a specific tag. It returns an async iterator that yields the run object whenever a run with the specified tag is updated. This iterator will never complete, so you must manually break out of the loop when you no longer want to receive updates.

**Authentication**: This function supports both server-side and client-side authentication. For server-side authentication, use your API key. For client-side authentication, you must generate a public access token with read access to the specific tag. See our [authentication guide](/realtime/auth) for details.

**Response**: The AsyncIterator yields the [run object](/realtime/run-object).

## runs.subscribeToBatch

Subscribes to all changes for runs in a batch.

```ts Example theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.subscribeToBatch("batch_1234")) {
  console.log(run);
}
```

This function subscribes to all changes for runs in a batch. It returns an async iterator that yields a run object whenever a run in the batch is updated. The iterator does not complete on its own, you must manually `break` the loop when you want to stop listening for updates.

**Authentication**: This function supports both server-side and client-side authentication. For server-side authentication, use your API key. For client-side authentication, you must generate a public access token with read access to the specific batch. See our [authentication guide](/realtime/auth) for details.

**Response**: The AsyncIterator yields the [run object](/realtime/run-object).

## Type safety

You can infer the types of the run's payload and output by passing the type of the task to the subscribe functions:

```ts  theme={null}
import { runs, tasks } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/my-task";

async function myBackend() {
  const handle = await tasks.trigger("my-task", { some: "data" });

  for await (const run of runs.subscribeToRun<typeof myTask>(handle.id)) {
    // run.payload and run.output are now typed
    console.log(run.payload.some);

    if (run.output) {
      console.log(run.output.some);
    }
  }
}
```

When using `subscribeToRunsWithTag`, you can pass a union of task types:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { myTask, myOtherTask } from "./trigger/my-task";

for await (const run of runs.subscribeToRunsWithTag<typeof myTask | typeof myOtherTask>("my-tag")) {
  // Narrow down the type based on the taskIdentifier
  switch (run.taskIdentifier) {
    case "my-task": {
      console.log("Run output:", run.output.foo); // Type-safe
      break;
    }
    case "my-other-task": {
      console.log("Run output:", run.output.bar); // Type-safe
      break;
    }
  }
}
```

## Subscribe to metadata updates from your tasks

The metadata API allows you to update custom metadata on runs and receive real-time updates when metadata changes. This is useful for tracking progress, storing intermediate results, or adding custom status information that can be monitored in real-time.

<Note>
  For frontend applications using React, see our [React hooks metadata
  documentation](/realtime/react-hooks/subscribe#using-metadata-to-show-progress-in-your-ui) for
  consuming metadata updates in your UI.
</Note>

When you update metadata from within a task using `metadata.set()`, `metadata.append()`, or other metadata methods, all subscribers to that run will automatically receive the updated run object containing the new metadata.

This makes metadata perfect for:

* Progress tracking
* Status updates
* Intermediate results
* Custom notifications

Use the metadata API within your task to update metadata in real-time. In this basic example task, we're updating the progress of a task as it processes items.

### How to subscribe to metadata updates

This example task updates the progress of a task as it processes items.

```ts  theme={null}
// Your task code
import { task, metadata } from "@trigger.dev/sdk";

export const progressTask = task({
  id: "progress-task",
  run: async (payload: { items: string[] }) => {
    const total = payload.items.length;

    for (let i = 0; i < payload.items.length; i++) {
      // Update progress metadata
      metadata.set("progress", {
        current: i + 1,
        total: total,
        percentage: Math.round(((i + 1) / total) * 100),
        currentItem: payload.items[i],
      });

      // Process the item
      await processItem(payload.items[i]);
    }

    metadata.set("status", "completed");
    return { processed: total };
  },
});

async function processItem(item: string) {
  // Simulate work
  await new Promise((resolve) => setTimeout(resolve, 1000));
}
```

We can now subscribe to the runs and receive real-time metadata updates.

```ts  theme={null}
// Somewhere in your backend code
import { runs } from "@trigger.dev/sdk";
import type { progressTask } from "./trigger/progress-task";

async function monitorProgress(runId: string) {
  for await (const run of runs.subscribeToRun<typeof progressTask>(runId)) {
    console.log(`Run ${run.id} status: ${run.status}`);

    if (run.metadata?.progress) {
      const progress = run.metadata.progress as {
        current: number;
        total: number;
        percentage: number;
        currentItem: string;
      };

      console.log(`Progress: ${progress.current}/${progress.total} (${progress.percentage}%)`);
      console.log(`Processing: ${progress.currentItem}`);
    }

    if (run.metadata?.status === "completed") {
      console.log("Task completed!");
      break;
    }
  }
}
```

For more information on how to write tasks that use the metadata API, as well as more examples, see our [run metadata docs](/runs/metadata#more-metadata-task-examples).

### Type safety

You can get type safety for your metadata by defining types:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { progressTask } from "./trigger/progress-task";

interface ProgressMetadata {
  progress?: {
    current: number;
    total: number;
    percentage: number;
    currentItem: string;
  };
  status?: "running" | "completed" | "failed";
}

async function monitorTypedProgress(runId: string) {
  for await (const run of runs.subscribeToRun<typeof progressTask>(runId)) {
    const metadata = run.metadata as ProgressMetadata;

    if (metadata?.progress) {
      // Now you have full type safety
      console.log(`Progress: ${metadata.progress.percentage}%`);
    }
  }
}
```


# How it works
Source: https://trigger.dev/docs/realtime/how-it-works

Technical details about how the Trigger.dev Realtime API works

## Architecture

The Realtime API is built on top of [Electric SQL](https://electric-sql.com/), an open-source PostgreSQL syncing engine. The Trigger.dev API wraps Electric SQL and provides a simple API to subscribe to [runs](/runs) and get real-time updates.

## Run changes

You will receive updates whenever a run changes for the following reasons:

* The run moves to a new state. See our [run lifecycle docs](/runs#the-run-lifecycle) for more information.
* [Run tags](/tags) are added or removed.
* [Run metadata](/runs/metadata) is updated.

## Run object

The run object returned by Realtime subscriptions is optimized for streaming updates and differs from the management API's run object. See [the run object](/realtime/run-object) page for the complete schema and field descriptions.

## Basic usage

After you trigger a task, you can subscribe to the run using the `runs.subscribeToRun` function. This function returns an async iterator that you can use to get updates on the run status.

```ts  theme={null}
import { runs, tasks } from "@trigger.dev/sdk";

// Somewhere in your backend code
async function myBackend() {
  const handle = await tasks.trigger("my-task", { some: "data" });

  for await (const run of runs.subscribeToRun(handle.id)) {
    // This will log the run every time it changes
    console.log(run);
  }
}
```

Every time the run changes, the async iterator will yield the updated run. You can use this to update your UI, log the run status, or take any other action.

Alternatively, you can subscribe to changes to any run that includes a specific tag (or tags) using the `runs.subscribeToRunsWithTag` function.

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

// Somewhere in your backend code
for await (const run of runs.subscribeToRunsWithTag("user:1234")) {
  // This will log the run every time it changes, for all runs with the tag "user:1234"
  console.log(run);
}
```

If you've used `batchTrigger` to trigger multiple runs, you can also subscribe to changes to all the runs triggered in the batch using the `runs.subscribeToBatch` function.

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

// Somewhere in your backend code
for await (const run of runs.subscribeToBatch("batch-id")) {
  // This will log the run every time it changes, for all runs in the batch with the ID "batch-id"
  console.log(run);
}
```

## Run metadata

The run metadata API gives you the ability to add or update custom metadata on a run, which will cause the run to be updated. This allows you to extend the Realtime API with custom data attached to a run that can be used for various purposes. Some common use cases include:

* Adding a link to a related resource
* Adding a reference to a user or organization
* Adding a custom status with progress information

See our [run metadata docs](/runs/metadata) for more on how to write tasks that use the metadata API.

### Using metadata with Realtime & React hooks

You can combine run metadata with the Realtime API to bridge the gap between your trigger.dev tasks and your applications in two ways:

1. Using our [React hooks](/realtime/react-hooks/subscribe#using-metadata) to subscribe to metadata updates and update your UI in real-time.
2. Using our [backend functions](/realtime/backend) to subscribe to metadata updates in your backend.

## Limits

The Realtime API in the Trigger.dev Cloud limits the number of concurrent subscriptions, depending on your plan. If you exceed the limit, you will receive an error when trying to subscribe to a run. For more information, see our [pricing page](https://trigger.dev/pricing).

## Learn more

* Read our Realtime blog post ["How we built a real-time service that handles 20,000 updates per second](https://trigger.dev/blog/how-we-built-realtime)
* Using Realtime: [React Hooks (frontend)](/realtime/react-hooks)
* Using [Backend (server-side)](/realtime/backend)


# Realtime overview
Source: https://trigger.dev/docs/realtime/overview

Using the Trigger.dev Realtime API to trigger and/or subscribe to runs in real-time.

Trigger.dev Realtime allows you to trigger, subscribe to, and get real-time updates for runs. This is useful for monitoring runs, updating UIs, and building real-time dashboards.

You can subscribe to real-time updates for different scopes of runs:

* **Specific runs** - Monitor individual run progress by run ID
* **Runs with specific tags** - Track all runs that have certain [tags](/tags) (e.g., all runs tagged with `user:123`)
* **Batch runs** - All runs within a specific batch
* **Trigger + subscribe combos** - Trigger a task and immediately subscribe to its run (frontend only)

Once subscribed, you'll receive the complete [run object](/realtime/run-object) with automatic real-time updates whenever the [run changes](/realtime/how-it-works#run-changes), including:

* **Status changes** - queued â†’ executing â†’ completed, etc.
* **Metadata updates** - Custom progress tracking, status updates, user data, etc. ([React hooks](/realtime/react-hooks/subscribe#using-metadata-to-show-progress-in-your-ui) | [backend](/realtime/backend/subscribe#subscribe-to-metadata-updates-from-your-tasks))
* **Tag changes** - When [tags](/tags) are added or removed from the run
* **Realtime Streams** - Stream real-time data from your tasks, perfect for AI/LLM outputs and progress updates. ([Learn more](/tasks/streams) | [React hooks](/realtime/react-hooks/streams) | [Backend](/realtime/backend/streams))

## Using Realtime in your applications

### Authentication

All Realtime subscriptions require authentication so you can securely trigger and subscribe to runs. See our [authentication guide](/realtime/auth) for more details.

### Frontend implementation

Use our React hooks to build real-time UIs that update as runs execute. Ideal for progress bars, status indicators, and live dashboards.

â†’ **[See our React hooks guide](/realtime/react-hooks/)**

### Backend implementation

Use our server-side SDK to subscribe to runs from your backend code, other tasks, or serverless functions. Perfect for triggering workflows, sending notifications, or updating databases based on run status changes.

â†’ **[See our Backend guide](/realtime/backend)**


# React hooks overview
Source: https://trigger.dev/docs/realtime/react-hooks/overview

Using the Trigger.dev Realtime API from your React applications.

Our React hooks package provides a set of hooks that make it easy to interact with the Trigger.dev Realtime API from your React applications. You can use these hooks to subscribe to real-time updates, and trigger tasks from your frontend.

## Installation

Install the `@trigger.dev/react-hooks` package in your project:

<CodeGroup>
  ```bash npm theme={null}
  npm add @trigger.dev/react-hooks
  ```

  ```bash pnpm theme={null}
  pnpm add @trigger.dev/react-hooks
  ```

  ```bash yarn theme={null}
  yarn install @trigger.dev/react-hooks
  ```
</CodeGroup>

## Authentication

All hooks require authentication with a Public Access Token. Pass the token via the `accessToken` option:

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
    baseURL: "https://your-trigger-dev-instance.com", // optional, only needed if you are self-hosting Trigger.dev
  });

  // ...
}
```

Learn more about [generating and managing tokens in our authentication guide](/realtime/auth).

## Available hooks

We provide several categories of hooks:

* **[Triggering hooks](/realtime/react-hooks/triggering)** - Trigger tasks from your frontend application
* **[Subscribe hooks](/realtime/react-hooks/subscribe)** - Subscribe to runs, batches, metadata, and more
* **[Streams hooks](/realtime/react-hooks/streams)** - Subscribe to real-time streams from your tasks
* **[SWR hooks](/realtime/react-hooks/swr)** - Fetch data once and cache it using SWR

## SWR vs Realtime hooks

We offer two "styles" of hooks: SWR and Realtime. The SWR hooks use the [swr](https://swr.vercel.app/) library to fetch data once and cache it. The Realtime hooks use [Trigger.dev Realtime](/realtime) to subscribe to updates in real-time.

<Note>
  It can be a little confusing which one to use because [swr](https://swr.vercel.app/) can also be
  configured to poll for updates. But because of rate-limits and the way the Trigger.dev API works,
  we recommend using the Realtime hooks for most use-cases.
</Note>


# Streams hooks
Source: https://trigger.dev/docs/realtime/react-hooks/streams

Subscribe to real-time streams from your tasks in React components

These hooks allow you to consume real-time streams from your tasks. Streams are useful for displaying AI/LLM outputs as they're generated, or any other real-time data from your tasks.

<Note>
  To learn how to emit streams from your tasks, see our [Realtime Streams](/tasks/streams)
  documentation.
</Note>

## useRealtimeStream (Recommended)

<Note>
  Available in SDK version **4.1.0 or later**. This is the recommended way to consume streams in
  your React components.
</Note>

The `useRealtimeStream` hook allows you to subscribe to a specific stream by its run ID and stream key. This hook is designed to work seamlessly with [defined streams](/tasks/streams#defining-typed-streams-recommended) for full type safety.

### Basic Usage

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";

export function StreamViewer({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { parts, error } = useRealtimeStream<string>(runId, "ai-output", {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### With Defined Streams

The recommended approach is to use defined streams for full type safety:

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function StreamViewer({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  // Pass the defined stream directly - full type safety!
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken: publicAccessToken,
    timeoutInSeconds: 600,
    onData: (chunk) => {
      console.log("New chunk:", chunk); // chunk is typed!
    },
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### Streaming AI Responses

Here's a complete example showing how to display streaming AI responses:

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/trigger/streams";
import { Streamdown } from "streamdown";

export function AIStreamViewer({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken: publicAccessToken,
    timeoutInSeconds: 300,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading stream...</div>;

  const text = parts.join("");

  return (
    <div className="prose">
      <Streamdown isAnimating={true}>{text}</Streamdown>
    </div>
  );
}
```

### Options

The `useRealtimeStream` hook accepts the following options:

```tsx  theme={null}
const { parts, error } = useRealtimeStream(streamOrRunId, streamKeyOrOptions, {
  accessToken: "pk_...", // Required: Public access token
  baseURL: "https://api.trigger.dev", // Optional: Custom API URL
  timeoutInSeconds: 60, // Optional: Timeout (default: 60)
  startIndex: 0, // Optional: Start from specific chunk
  throttleInMs: 16, // Optional: Throttle updates (default: 16ms)
  onData: (chunk) => {}, // Optional: Callback for each chunk
});
```

### Using Default Stream

You can omit the stream key to use the default stream:

```tsx  theme={null}
const { parts, error } = useRealtimeStream<string>(runId, {
  accessToken: publicAccessToken,
});
```

For more information on defining and using streams, see the [Realtime Streams v2](/tasks/streams) documentation.

## useRealtimeRunWithStreams

<Note>
  For new projects, we recommend using `useRealtimeStream` instead (available in SDK 4.1.0+). This
  hook is still supported for backward compatibility and use cases where you need to subscribe to
  both the run and all its streams at once.
</Note>

The `useRealtimeRunWithStreams` hook allows you to subscribe to a run by its ID and also receive any streams that are emitted by the task. This is useful when you need to access both the run metadata and multiple streams simultaneously.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeRunWithStreams } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, streams, error } = useRealtimeRunWithStreams(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;

  return (
    <div>
      <div>Run: {run.id}</div>
      <div>
        {Object.keys(streams).map((stream) => (
          <div key={stream}>Stream: {stream}</div>
        ))}
      </div>
    </div>
  );
}
```

You can also provide the type of the streams to the `useRealtimeRunWithStreams` hook to get type-safety:

```tsx  theme={null}
import { useRealtimeRunWithStreams } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

type STREAMS = {
  openai: string; // this is the type of each "part" of the stream
};

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, streams, error } = useRealtimeRunWithStreams<typeof myTask, STREAMS>(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;

  const text = streams.openai?.map((part) => part).join("");

  return (
    <div>
      <div>Run: {run.id}</div>
      <div>{text}</div>
    </div>
  );
}
```

As you can see above, each stream is an array of the type you provided, keyed by the stream name. If instead of a pure text stream you have a stream of objects, you can provide the type of the object:

```tsx  theme={null}
import type { TextStreamPart } from "ai";
import type { myTask } from "@/trigger/myTask";

type STREAMS = { openai: TextStreamPart<{}> };

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, streams, error } = useRealtimeRunWithStreams<typeof myTask, STREAMS>(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;

  const text = streams.openai
    ?.filter((stream) => stream.type === "text-delta")
    ?.map((part) => part.text)
    .join("");

  return (
    <div>
      <div>Run: {run.id}</div>
      <div>{text}</div>
    </div>
  );
}
```

### Streaming AI responses with useRealtimeRunWithStreams

Here's an example showing how to display streaming OpenAI responses using `useRealtimeRunWithStreams`:

```tsx  theme={null}
import { useRealtimeRunWithStreams } from "@trigger.dev/react-hooks";
import type { aiStreaming, STREAMS } from "./trigger/ai-streaming";

function MyComponent({ runId, publicAccessToken }: { runId: string; publicAccessToken: string }) {
  const { streams } = useRealtimeRunWithStreams<typeof aiStreaming, STREAMS>(runId, {
    accessToken: publicAccessToken,
  });

  if (!streams.openai) {
    return <div>Loading...</div>;
  }

  const text = streams.openai.join(""); // `streams.openai` is an array of strings

  return (
    <div>
      <h2>OpenAI response:</h2>
      <p>{text}</p>
    </div>
  );
}
```

### AI SDK with tools

When using the AI SDK with tools with `useRealtimeRunWithStreams`, you can access tool calls and results:

```tsx  theme={null}
import { useRealtimeRunWithStreams } from "@trigger.dev/react-hooks";
import type { aiStreamingWithTools, STREAMS } from "./trigger/ai-streaming";

function MyComponent({ runId, publicAccessToken }: { runId: string; publicAccessToken: string }) {
  const { streams } = useRealtimeRunWithStreams<typeof aiStreamingWithTools, STREAMS>(runId, {
    accessToken: publicAccessToken,
  });

  if (!streams.openai) {
    return <div>Loading...</div>;
  }

  // streams.openai is an array of TextStreamPart
  const toolCall = streams.openai.find(
    (stream) => stream.type === "tool-call" && stream.toolName === "getWeather"
  );
  const toolResult = streams.openai.find((stream) => stream.type === "tool-result");
  const textDeltas = streams.openai.filter((stream) => stream.type === "text-delta");

  const text = textDeltas.map((delta) => delta.textDelta).join("");
  const weatherLocation = toolCall ? toolCall.args.location : undefined;
  const weather = toolResult ? toolResult.result.temperature : undefined;

  return (
    <div>
      <h2>OpenAI response:</h2>
      <p>{text}</p>
      <h2>Weather:</h2>
      <p>
        {weatherLocation
          ? `The weather in ${weatherLocation} is ${weather} degrees.`
          : "No weather data"}
      </p>
    </div>
  );
}
```

### Throttling updates

The `useRealtimeRunWithStreams` hook accepts an `experimental_throttleInMs` option to throttle the updates from the server. This can be useful if you are getting too many updates and want to reduce the number of updates.

```tsx  theme={null}
import { useRealtimeRunWithStreams } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, streams, error } = useRealtimeRunWithStreams(runId, {
    accessToken: publicAccessToken,
    experimental_throttleInMs: 1000, // Throttle updates to once per second
  });

  if (error) return <div>Error: {error.message}</div>;

  return (
    <div>
      <div>Run: {run.id}</div>
      {/* Display streams */}
    </div>
  );
}
```

All other options (accessToken, baseURL, enabled, id) work the same as the other realtime hooks.

For the newer `useRealtimeStream` hook, use the `throttleInMs` option instead (see [options above](#options)).


# Subscribing to runs
Source: https://trigger.dev/docs/realtime/react-hooks/subscribe

Get live updates from runs, batches, metadata, and more in your frontend application.

These hooks allow you to subscribe to runs, batches, and streams using [Trigger.dev Realtime](/realtime). They automatically include real-time updates for run status, metadata, output, and other properties.

## Hooks

## Triggering + Realtime hooks

For triggering tasks and immediately subscribing to their runs, we provide combo hooks, details on how to use them can be found in the [triggering](/realtime/react-hooks/triggering) section.

* **[`useRealtimeTaskTrigger`](/realtime/react-hooks/triggering#userealtimetasktrigger)** - Trigger a task and subscribe to the run
* **[`useRealtimeTaskTriggerWithStreams`](/realtime/react-hooks/triggering#userealtimetasktriggerwithstreams)** - Trigger a task and subscribe to both run updates and streams

## Other Realtime subscription hooks

### useRealtimeRun

The `useRealtimeRun` hook allows you to subscribe to a run by its ID.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

To correctly type the run's payload and output, you can provide the type of your task to the `useRealtimeRun` hook:

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun<typeof myTask>(runId, {
    accessToken: publicAccessToken,
  });

  if (error) return <div>Error: {error.message}</div>;

  // Now run.payload and run.output are correctly typed

  return <div>Run: {run.id}</div>;
}
```

You can supply an `onComplete` callback to the `useRealtimeRun` hook to be called when the run is completed or errored. This is useful if you want to perform some action when the run is completed, like navigating to a different page or showing a notification.

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
    onComplete: (run, error) => {
      console.log("Run completed", run);
    },
  });

  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

See our [run object reference](/realtime/run-object) for the complete schema and [How it Works documentation](/realtime/how-it-works) for more technical details.

### useRealtimeRunsWithTag

The `useRealtimeRunsWithTag` hook allows you to subscribe to multiple runs with a specific tag.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeRunsWithTag } from "@trigger.dev/react-hooks";

export function MyComponent({ tag }: { tag: string }) {
  const { runs, error } = useRealtimeRunsWithTag(tag);

  if (error) return <div>Error: {error.message}</div>;

  return (
    <div>
      {runs.map((run) => (
        <div key={run.id}>Run: {run.id}</div>
      ))}
    </div>
  );
}
```

To correctly type the runs payload and output, you can provide the type of your task to the `useRealtimeRunsWithTag` hook:

```tsx  theme={null}
import { useRealtimeRunsWithTag } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

export function MyComponent({ tag }: { tag: string }) {
  const { runs, error } = useRealtimeRunsWithTag<typeof myTask>(tag);

  if (error) return <div>Error: {error.message}</div>;

  // Now runs[i].payload and runs[i].output are correctly typed

  return (
    <div>
      {runs.map((run) => (
        <div key={run.id}>Run: {run.id}</div>
      ))}
    </div>
  );
}
```

If `useRealtimeRunsWithTag` could return multiple different types of tasks, you can pass a union of all the task types to the hook:

```tsx  theme={null}
import { useRealtimeRunsWithTag } from "@trigger.dev/react-hooks";
import type { myTask1, myTask2 } from "@/trigger/myTasks";

export function MyComponent({ tag }: { tag: string }) {
  const { runs, error } = useRealtimeRunsWithTag<typeof myTask1 | typeof myTask2>(tag);

  if (error) return <div>Error: {error.message}</div>;

  // You can narrow down the type of the run based on the taskIdentifier
  for (const run of runs) {
    if (run.taskIdentifier === "my-task-1") {
      // run is correctly typed as myTask1
    } else if (run.taskIdentifier === "my-task-2") {
      // run is correctly typed as myTask2
    }
  }

  return (
    <div>
      {runs.map((run) => (
        <div key={run.id}>Run: {run.id}</div>
      ))}
    </div>
  );
}
```

### useRealtimeBatch

The `useRealtimeBatch` hook allows you to subscribe to a batch of runs by its the batch ID.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeBatch } from "@trigger.dev/react-hooks";

export function MyComponent({ batchId }: { batchId: string }) {
  const { runs, error } = useRealtimeBatch(batchId);

  if (error) return <div>Error: {error.message}</div>;

  return (
    <div>
      {runs.map((run) => (
        <div key={run.id}>Run: {run.id}</div>
      ))}
    </div>
  );
}
```

See our [Realtime documentation](/realtime) for more information.

## Using metadata to show progress in your UI

All realtime hooks automatically include metadata updates. Whenever your task updates metadata using `metadata.set()`, `metadata.append()`, or other metadata methods, your component will re-render with the updated data.

<Note>To learn how to write tasks using metadata, see our [metadata](/runs/metadata) guide.</Note>

### Progress monitoring

This example demonstrates how to create a progress monitor component that can be used to display the progress of a run:

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function ProgressMonitor({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error, isLoading } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  if (isLoading) return <div>Loading run...</div>;
  if (error) return <div>Error: {error.message}</div>;
  if (!run) return <div>Run not found</div>;

  const progress = run.metadata?.progress as
    | {
        current: number;
        total: number;
        percentage: number;
        currentItem: string;
      }
    | undefined;

  return (
    <div className="space-y-4">
      <div>
        <h3>Run Status: {run.status}</h3>
        <p>Run ID: {run.id}</p>
      </div>

      {progress && (
        <div className="space-y-2">
          <div className="flex justify-between text-sm">
            <span>Progress</span>
            <span>{progress.percentage}%</span>
          </div>
          <div className="w-full bg-gray-200 rounded-full h-2">
            <div
              className="bg-blue-600 h-2 rounded-full transition-all duration-300"
              style={{ width: `${progress.percentage}%` }}
            />
          </div>
          <p className="text-sm text-gray-600">
            Processing: {progress.currentItem} ({progress.current}/{progress.total})
          </p>
        </div>
      )}
    </div>
  );
}
```

### Reusable progress bar

This example demonstrates how to create a reusable progress bar component that can be used to display the percentage progress of a run:

```tsx  theme={null}
"use client";

import { useRealtimeRun } from "@trigger.dev/react-hooks";

interface ProgressBarProps {
  runId: string;
  publicAccessToken: string;
  title?: string;
}

export function ProgressBar({ runId, publicAccessToken, title }: ProgressBarProps) {
  const { run } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  const progress = run?.metadata?.progress as
    | {
        current?: number;
        total?: number;
        percentage?: number;
        currentItem?: string;
      }
    | undefined;

  const percentage = progress?.percentage ?? 0;
  const isComplete = run?.status === "COMPLETED";
  const isFailed = run?.status === "FAILED";

  return (
    <div className="w-full space-y-2">
      {title && <h4 className="font-medium">{title}</h4>}

      <div className="w-full bg-gray-200 rounded-full h-3">
        <div
          className={`h-3 rounded-full transition-all duration-500 ${
            isFailed ? "bg-red-500" : isComplete ? "bg-green-500" : "bg-blue-500"
          }`}
          style={{ width: `${percentage}%` }}
        />
      </div>

      <div className="flex justify-between text-sm text-gray-600">
        <span>
          {progress?.current && progress?.total
            ? `${progress.current}/${progress.total} items`
            : "Processing..."}
        </span>
        <span>{percentage}%</span>
      </div>

      {progress?.currentItem && (
        <p className="text-sm text-gray-500 truncate">Current: {progress.currentItem}</p>
      )}
    </div>
  );
}
```

### Status indicator with logs

This example demonstrates how to create a status indicator component that can be used to display the status of a run, and also logs that are emitted by the task:

```tsx  theme={null}
"use client";

import { useRealtimeRun } from "@trigger.dev/react-hooks";

interface StatusIndicatorProps {
  runId: string;
  publicAccessToken: string;
}

export function StatusIndicator({ runId, publicAccessToken }: StatusIndicatorProps) {
  const { run } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  const status = run?.metadata?.status as string | undefined;
  const logs = run?.metadata?.logs as string[] | undefined;

  const getStatusColor = (status: string | undefined) => {
    switch (status) {
      case "completed":
        return "text-green-600 bg-green-100";
      case "failed":
        return "text-red-600 bg-red-100";
      case "running":
        return "text-blue-600 bg-blue-100";
      default:
        return "text-gray-600 bg-gray-100";
    }
  };

  return (
    <div className="space-y-4">
      <div className="flex items-center space-x-2">
        <span className={`px-3 py-1 rounded-full text-sm font-medium ${getStatusColor(status)}`}>
          {status || run?.status || "Unknown"}
        </span>
        <span className="text-sm text-gray-500">Run {run?.id}</span>
      </div>

      {logs && logs.length > 0 && (
        <div className="bg-gray-50 rounded-lg p-4">
          <h4 className="font-medium mb-2">Logs</h4>
          <div className="space-y-1 max-h-48 overflow-y-auto">
            {logs.map((log, index) => (
              <div key={index} className="text-sm text-gray-700 font-mono">
                {log}
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

### Multi-stage deployment monitor

This example demonstrates how to create a multi-stage deployment monitor component that can be used to display the progress of a deployment:

```tsx  theme={null}
"use client";

import { useRealtimeRun } from "@trigger.dev/react-hooks";

interface DeploymentMonitorProps {
  runId: string;
  publicAccessToken: string;
}

const DEPLOYMENT_STAGES = [
  "initializing",
  "building",
  "testing",
  "deploying",
  "verifying",
  "completed",
] as const;

export function DeploymentMonitor({ runId, publicAccessToken }: DeploymentMonitorProps) {
  const { run } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  const status = run?.metadata?.status as string | undefined;
  const logs = run?.metadata?.logs as string[] | undefined;
  const currentStageIndex = DEPLOYMENT_STAGES.indexOf(status as any);

  return (
    <div className="space-y-6">
      <h3 className="text-lg font-semibold">Deployment Progress</h3>

      {/* Stage indicators */}
      <div className="space-y-4">
        {DEPLOYMENT_STAGES.map((stage, index) => {
          const isActive = currentStageIndex === index;
          const isCompleted = currentStageIndex > index;
          const isFailed = run?.status === "FAILED" && currentStageIndex === index;

          return (
            <div key={stage} className="flex items-center space-x-3">
              <div
                className={`w-6 h-6 rounded-full flex items-center justify-center text-sm font-medium ${
                  isFailed
                    ? "bg-red-500 text-white"
                    : isCompleted
                    ? "bg-green-500 text-white"
                    : isActive
                    ? "bg-blue-500 text-white"
                    : "bg-gray-200 text-gray-600"
                }`}
              >
                {isCompleted ? "âœ“" : index + 1}
              </div>
              <span
                className={`capitalize ${
                  isActive
                    ? "font-medium text-blue-600"
                    : isCompleted
                    ? "text-green-600"
                    : isFailed
                    ? "text-red-600"
                    : "text-gray-500"
                }`}
              >
                {stage}
              </span>
              {isActive && (
                <div className="animate-spin w-4 h-4 border-2 border-blue-500 border-t-transparent rounded-full" />
              )}
            </div>
          );
        })}
      </div>

      {/* Recent logs */}
      {logs && logs.length > 0 && (
        <div className="bg-black text-green-400 rounded-lg p-4 font-mono text-sm">
          <div className="space-y-1 max-h-32 overflow-y-auto">
            {logs.slice(-5).map((log, index) => (
              <div key={index}>
                <span className="text-gray-500">$ </span>
                {log}
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
```

### Type safety

Define TypeScript interfaces for your metadata to get full type safety:

```tsx  theme={null}
"use client";

import { useRealtimeRun } from "@trigger.dev/react-hooks";

interface TaskMetadata {
  progress?: {
    current: number;
    total: number;
    percentage: number;
    currentItem: string;
  };
  status?: "initializing" | "processing" | "completed" | "failed";
  user?: {
    id: string;
    name: string;
  };
  logs?: string[];
}

export function TypedMetadataComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
  });

  // Type-safe metadata access
  const metadata = run?.metadata as TaskMetadata | undefined;

  return (
    <div>
      {metadata?.progress && <p>Progress: {metadata.progress.percentage}%</p>}

      {metadata?.user && (
        <p>
          User: {metadata.user.name} ({metadata.user.id})
        </p>
      )}

      {metadata?.status && <p>Status: {metadata.status}</p>}
    </div>
  );
}
```

## Common options

### accessToken & baseURL

You can pass the `accessToken` option to the Realtime hooks to authenticate the subscription.

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
}: {
  runId: string;
  publicAccessToken: string;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
    baseURL: "https://my-self-hosted-trigger.com", // Optional if you are using a self-hosted Trigger.dev instance
  });

  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

### enabled

You can pass the `enabled` option to the Realtime hooks to enable or disable the subscription.

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  runId,
  publicAccessToken,
  enabled,
}: {
  runId: string;
  publicAccessToken: string;
  enabled: boolean;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
    enabled,
  });

  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

This allows you to conditionally disable using the hook based on some state.

### id

You can pass the `id` option to the Realtime hooks to change the ID of the subscription.

```tsx  theme={null}
import { useRealtimeRun } from "@trigger.dev/react-hooks";

export function MyComponent({
  id,
  runId,
  publicAccessToken,
  enabled,
}: {
  id: string;
  runId: string;
  publicAccessToken: string;
  enabled: boolean;
}) {
  const { run, error } = useRealtimeRun(runId, {
    accessToken: publicAccessToken,
    enabled,
    id,
  });

  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

This allows you to change the ID of the subscription based on some state. Passing in a different ID will unsubscribe from the current subscription and subscribe to the new one (and remove any cached data).


# SWR hooks
Source: https://trigger.dev/docs/realtime/react-hooks/swr

Fetch and cache data using SWR-based hooks

SWR hooks use the [swr](https://swr.vercel.app/) library to fetch data once and cache it. These hooks are useful when you need to fetch data without real-time updates.

<Note>
  While SWR can be configured to poll for updates, we recommend using our other [Realtime
  hooks](/realtime/react-hooks/) for most use-cases due to rate-limits and the way the Trigger.dev
  API works.
</Note>

## useRun

The `useRun` hook allows you to fetch a run by its ID.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRun } from "@trigger.dev/react-hooks";

export function MyComponent({ runId }: { runId: string }) {
  const { run, error, isLoading } = useRun(runId);

  if (isLoading) return <div>Loading...</div>;
  if (error) return <div>Error: {error.message}</div>;

  return <div>Run: {run.id}</div>;
}
```

The `run` object returned is the same as the [run object](/management/runs/retrieve) returned by the Trigger.dev API. To correctly type the run's payload and output, you can provide the type of your task to the `useRun` hook:

```tsx  theme={null}
import { useRun } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

export function MyComponent({ runId }: { runId: string }) {
  const { run, error, isLoading } = useRun<typeof myTask>(runId, {
    refreshInterval: 0, // Disable polling
  });

  if (isLoading) return <div>Loading...</div>;
  if (error) return <div>Error: {error.message}</div>;

  // Now run.payload and run.output are correctly typed

  return <div>Run: {run.id}</div>;
}
```

## Common SWR options

You can pass the following options to the all SWR hooks:

<ParamField path="revalidateOnFocus" type="boolean">
  Revalidate the data when the window regains focus.
</ParamField>

<ParamField path="revalidateOnReconnect" type="boolean">
  Revalidate the data when the browser regains a network connection.
</ParamField>

<ParamField path="refreshInterval" type="number">
  Poll for updates at the specified interval (in milliseconds). Polling is not recommended for most
  use-cases. Use the Realtime hooks instead.
</ParamField>

## Common SWR return values

<ResponseField name="error" type="Error">
  An error object if an error occurred while fetching the data.
</ResponseField>

<ResponseField name="isLoading" type="boolean">
  A boolean indicating if the data is currently being fetched.
</ResponseField>

<ResponseField name="isValidating" type="boolean">
  A boolean indicating if the data is currently being revalidated.
</ResponseField>

<ResponseField name="isError" type="boolean">
  A boolean indicating if an error occurred while fetching the data.
</ResponseField>

{" "}


# Trigger hooks
Source: https://trigger.dev/docs/realtime/react-hooks/triggering

Triggering tasks from your frontend application.

We provide a set of hooks that can be used to trigger tasks from your frontend application.

<Note>
  For triggering tasks from your frontend, you need to use â€œtriggerâ€ tokens. These can only be used
  once to trigger a task and are more secure than regular Public Access Tokens. To learn more about
  how to create and use these tokens, see our [Trigger
  Tokens](/realtime/auth#trigger-tokens-for-frontend-triggering-only) documentation.
</Note>

## Hooks

We provide three hooks for triggering tasks from your frontend application:

* `useTaskTrigger` - Trigger a task from your frontend application.
* `useRealtimeTaskTrigger` - Trigger a task from your frontend application and subscribe to the run.
* `useRealtimeTaskTriggerWithStreams` - Trigger a task from your frontend application and subscribe to the run, and also receive any streams that are emitted by the task.

### useTaskTrigger

The `useTaskTrigger` hook allows you to trigger a task from your frontend application.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useTaskTrigger } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";
//     ðŸ‘† This is the type of your task, include this to get type-safety

export function MyComponent({ publicAccessToken }: { publicAccessToken: string }) {
  //                         pass the type of your task here ðŸ‘‡
  const { submit, handle, error, isLoading } = useTaskTrigger<typeof myTask>("my-task", {
    accessToken: publicAccessToken, // ðŸ‘ˆ this is the "trigger" token
  });

  if (error) {
    return <div>Error: {error.message}</div>;
  }

  if (handle) {
    return <div>Run ID: {handle.id}</div>;
  }

  return (
    <button onClick={() => submit({ foo: "bar" })} disabled={isLoading}>
      {isLoading ? "Loading..." : "Trigger Task"}
    </button>
  );
}
```

`useTaskTrigger` returns an object with the following properties:

* `submit`: A function that triggers the task. It takes the payload of the task as an argument.
* `handle`: The run handle object. This object contains the ID of the run that was triggered, along with a Public Access Token that can be used to access the run.
* `isLoading`: A boolean that indicates whether the task is currently being triggered.
* `error`: An error object that contains any errors that occurred while triggering the task.

The `submit` function triggers the task with the specified payload. You can additionally pass an optional [options](/triggering#options) argument to the `submit` function:

```tsx  theme={null}
submit({ foo: "bar" }, { tags: ["tag1", "tag2"] });
```

#### Using the handle object

You can use the `handle` object to initiate a subsequent [Realtime hook](/realtime/react-hooks/subscribe#userealtimerun) to subscribe to the run.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useTaskTrigger, useRealtimeRun } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";
//     ðŸ‘† This is the type of your task

export function MyComponent({ publicAccessToken }: { publicAccessToken: string }) {
  //                         pass the type of your task here ðŸ‘‡
  const { submit, handle, error, isLoading } = useTaskTrigger<typeof myTask>("my-task", {
    accessToken: publicAccessToken, // ðŸ‘ˆ this is the "trigger" token
  });

  //     use the handle object to preserve type-safety ðŸ‘‡
  const { run, error: realtimeError } = useRealtimeRun(handle, {
    accessToken: handle?.publicAccessToken,
    enabled: !!handle, // Only subscribe to the run if the handle is available
  });

  if (error) {
    return <div>Error: {error.message}</div>;
  }

  if (handle) {
    return <div>Run ID: {handle.id}</div>;
  }

  if (realtimeError) {
    return <div>Error: {realtimeError.message}</div>;
  }

  if (run) {
    return <div>Run ID: {run.id}</div>;
  }

  return (
    <button onClick={() => submit({ foo: "bar" })} disabled={isLoading}>
      {isLoading ? "Loading..." : "Trigger Task"}
    </button>
  );
}
```

We've also created some additional hooks that allow you to trigger tasks and subscribe to the run in one step:

### useRealtimeTaskTrigger

The `useRealtimeTaskTrigger` hook allows you to trigger a task from your frontend application and then subscribe to the run in using Realtime:

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeTaskTrigger } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

export function MyComponent({ publicAccessToken }: { publicAccessToken: string }) {
  const { submit, run, error, isLoading } = useRealtimeTaskTrigger<typeof myTask>("my-task", {
    accessToken: publicAccessToken,
  });

  if (error) {
    return <div>Error: {error.message}</div>;
  }

  // This is the Realtime run object, which will automatically update when the run changes
  if (run) {
    return <div>Run ID: {run.id}</div>;
  }

  return (
    <button onClick={() => submit({ foo: "bar" })} disabled={isLoading}>
      {isLoading ? "Loading..." : "Trigger Task"}
    </button>
  );
}
```

### useRealtimeTaskTriggerWithStreams

The `useRealtimeTaskTriggerWithStreams` hook allows you to trigger a task from your frontend application and then subscribe to the run in using Realtime, and also receive any streams that are emitted by the task.

```tsx  theme={null}
"use client"; // This is needed for Next.js App Router or other RSC frameworks

import { useRealtimeTaskTriggerWithStreams } from "@trigger.dev/react-hooks";
import type { myTask } from "@/trigger/myTask";

type STREAMS = {
  openai: string; // this is the type of each "part" of the stream
};

export function MyComponent({ publicAccessToken }: { publicAccessToken: string }) {
  const { submit, run, streams, error, isLoading } = useRealtimeTaskTriggerWithStreams<
    typeof myTask,
    STREAMS
  >("my-task", {
    accessToken: publicAccessToken,
  });

  if (error) {
    return <div>Error: {error.message}</div>;
  }

  if (streams && run) {
    const text = streams.openai?.map((part) => part).join("");

    return (
      <div>
        <div>Run ID: {run.id}</div>
        <div>{text}</div>
      </div>
    );
  }

  return (
    <button onClick={() => submit({ foo: "bar" })} disabled={isLoading}>
      {isLoading ? "Loading..." : "Trigger Task"}
    </button>
  );
}
```


# useWaitToken
Source: https://trigger.dev/docs/realtime/react-hooks/use-wait-token

Use the useWaitToken hook to complete a wait token from a React component

We've added a new `useWaitToken` react hook that allows you to complete a wait token from a React component, using a Public Access Token.

```ts backend.ts theme={null}
import { wait } from "@trigger.dev/sdk";

// Somewhere in your code, you'll need to create the token and then pass the token ID and the public token to the frontend
const token = await wait.createToken({
  timeout: "10m",
});

return {
  tokenId: token.id,
  publicToken: token.publicAccessToken, // An automatically generated public access token that expires in 1 hour
};
```

Now you can use the `useWaitToken` hook in your frontend code:

```tsx frontend.tsx theme={null}
import { useWaitToken } from "@trigger.dev/react-hooks";

export function MyComponent({ publicToken, tokenId }: { publicToken: string; tokenId: string }) {
  const { complete } = useWaitToken(tokenId, {
    accessToken: publicToken,
  });

  return <button onClick={() => complete({ foo: "bar" })}>Complete</button>;
}
```


# The run object
Source: https://trigger.dev/docs/realtime/run-object

The run object schema for Realtime subscriptions

The [run object](/realtime/run-object#the-run-object) is the main object returned by Realtime subscriptions (e.g., `runs.subscribeToRun()`). It contains all the information about the run, including the run ID, task identifier, payload, output, and more.

Type-safety is supported for the run object, so you can infer the types of the run's payload and output. See [type-safety](#type-safety) for more information.

## The run object

### Properties

<ParamField path="id" type="string" required>
  The run ID.
</ParamField>

<ParamField path="taskIdentifier" type="string" required>
  The task identifier.
</ParamField>

<ParamField path="payload" type="object" required>
  The input payload for the run.
</ParamField>

<ParamField path="output" type="object">
  The output result of the run.
</ParamField>

<ParamField path="createdAt" type="Date" required>
  Timestamp when the run was created.
</ParamField>

<ParamField path="updatedAt" type="Date" required>
  Timestamp when the run was last updated.
</ParamField>

<ParamField path="number" type="number" required>
  Sequential number assigned to the run.
</ParamField>

<ParamField path="status" type="RunStatus" required>
  Current status of the run.

  <Accordion title="RunStatus enum">
    | Status               | Description                                                                                               |
    | -------------------- | --------------------------------------------------------------------------------------------------------- |
    | `WAITING_FOR_DEPLOY` | Task hasn't been deployed yet but is waiting to be executed                                               |
    | `QUEUED`             | Run is waiting to be executed by a worker                                                                 |
    | `EXECUTING`          | Run is currently being executed by a worker                                                               |
    | `REATTEMPTING`       | Run has failed and is waiting to be retried                                                               |
    | `FROZEN`             | Run has been paused by the system, and will be resumed by the system                                      |
    | `COMPLETED`          | Run has been completed successfully                                                                       |
    | `CANCELED`           | Run has been canceled by the user                                                                         |
    | `FAILED`             | Run has been completed with errors                                                                        |
    | `CRASHED`            | Run has crashed and won't be retried, most likely the worker ran out of resources, e.g. memory or storage |
    | `INTERRUPTED`        | Run was interrupted during execution, mostly this happens in development environments                     |
    | `SYSTEM_FAILURE`     | Run has failed to complete, due to an error in the system                                                 |
    | `DELAYED`            | Run has been scheduled to run at a specific time                                                          |
    | `EXPIRED`            | Run has expired and won't be executed                                                                     |
    | `TIMED_OUT`          | Run has reached it's maxDuration and has been stopped                                                     |
  </Accordion>
</ParamField>

<ParamField path="durationMs" type="number" required>
  Duration of the run in milliseconds.
</ParamField>

<ParamField path="costInCents" type="number" required>
  Total cost of the run in cents.
</ParamField>

<ParamField path="baseCostInCents" type="number" required>
  Base cost of the run in cents before any additional charges.
</ParamField>

<ParamField path="tags" type="string[]" required>
  Array of tags associated with the run.
</ParamField>

<ParamField path="idempotencyKey" type="string">
  Key used to ensure idempotent execution.
</ParamField>

<ParamField path="expiredAt" type="Date">
  Timestamp when the run expired.
</ParamField>

<ParamField path="ttl" type="string">
  Time-to-live duration for the run.
</ParamField>

<ParamField path="finishedAt" type="Date">
  Timestamp when the run finished.
</ParamField>

<ParamField path="startedAt" type="Date">
  Timestamp when the run started.
</ParamField>

<ParamField path="delayedUntil" type="Date">
  Timestamp until which the run is delayed.
</ParamField>

<ParamField path="queuedAt" type="Date">
  Timestamp when the run was queued.
</ParamField>

<ParamField path="metadata" type="Record<string, DeserializedJson>">
  Additional metadata associated with the run.
</ParamField>

<ParamField path="error" type="SerializedError">
  Error information if the run failed.
</ParamField>

<ParamField path="isTest" type="boolean" required>
  Indicates whether this is a test run.
</ParamField>

## Type-safety

You can infer the types of the run's payload and output by passing the type of the task to the `subscribeToRun` function. This will give you type-safe access to the run's payload and output.

```ts  theme={null}
import { runs, tasks } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/my-task";

// Somewhere in your backend code
async function myBackend() {
  const handle = await tasks.trigger("my-task", { some: "data" });

  for await (const run of runs.subscribeToRun<typeof myTask>(handle.id)) {
    // This will log the run every time it changes
    console.log(run.payload.some);

    if (run.output) {
      // This will log the output if it exists
      console.log(run.output.some);
    }
  }
}
```

When using `subscribeToRunsWithTag`, you can pass a union of task types for all the possible tasks that can have the tag.

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { myTask, myOtherTask } from "./trigger/my-task";

// Somewhere in your backend code
for await (const run of runs.subscribeToRunsWithTag<typeof myTask | typeof myOtherTask>("my-tag")) {
  // You can narrow down the type based on the taskIdentifier
  switch (run.taskIdentifier) {
    case "my-task": {
      console.log("Run output:", run.output.foo); // This will be type-safe
      break;
    }
    case "my-other-task": {
      console.log("Run output:", run.output.bar); // This will be type-safe
      break;
    }
  }
}
```

This works with all realtime subscription functions:

* `runs.subscribeToRun<TaskType>()`
* `runs.subscribeToRunsWithTag<TaskType>()`
* `runs.subscribeToBatch<TaskType>()`


# Replaying
Source: https://trigger.dev/docs/replaying

A replay is a copy of a run with the same payload but against the latest version in that environment. This is useful if something went wrong and you want to try again with the latest version of your code.

### Replaying from the UI

<Tabs>
  <Tab title="From a run">
    <Steps>
      <Step title="Click the Replay button in the top right">
                <img
                  src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=64e19da4dca5b249adee459a1eeb62e1"
                  alt="Select a task, then in the bottom right
        click &#x22;Replay&#x22;"
                  data-og-width="1600"
                  width="1600"
                  data-og-height="1119"
                  height="1119"
                  data-path="images/replay-run-action.png"
                  data-optimize="true"
                  data-opv="3"
                  srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=79d76f07ffc53d8ca2e0f9d476916a6c 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f7c001e785f946cfa10509bd5bdf10fe 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=93b7290ab8123c1791c07213bd372962 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=84ee5b71497a635461e2c19aea572c50 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=38d6e4c8e61a571835e9d2f87bacf235 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-action.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=baf3c7d6f105cc3208d5e9f34957ee33 2500w"
                />
      </Step>

      <Step title="Confirm replay settings">
        You can edit the payload <Icon icon="circle-1" iconType="solid" size={20} color="F43F47" /> (if available) and choose the environment <Icon icon="circle-2" iconType="solid" size={20} color="F43F47" /> to replay the run in.

                <img
                  src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9891cc5d05792c57d3e58a06171113f4"
                  alt="Select a task, then in the bottom right
        click &#x22;Replay&#x22;"
                  data-og-width="1600"
                  width="1600"
                  data-og-height="1291"
                  height="1291"
                  data-path="images/replay-run-modal.png"
                  data-optimize="true"
                  data-opv="3"
                  srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ed05fc9706ae81cf14f68927d22b8f73 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=21442bda61813c50bb4314681440cfa7 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7c569aa440d06fb02a3f9159693e52d3 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6b25d98591108c1fd2912dee60156ffa 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f60049686106e4efc377ae6eaf306cb6 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-run-modal.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=39aa7ae272cbfb43d480db2e186ed885 2500w"
                />
      </Step>
    </Steps>
  </Tab>

  <Tab title="Runs list">
    <Steps>
      <Step title="Click the action button on a run">
                <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a9dc0c82c7053753ab620237be1fc63d" alt="On the runs page, press the triple dot button" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/replay-runs-list.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3a536d96cc682dc2c30d5199eb5cab7f 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=debd27af5b2f2740fbcf9f8b2dd55c81 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=5367f46371c0cc1b002f0922ffb318ce 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e5950600d946e5ae7a86a804fe31a823 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f04257d4a23c3d09cc824cefb8e58024 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=49aaa6bfaa1c1a3e2f7a37d0c8c0ccac 2500w" />
      </Step>

      <Step title="Click replay">      <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=41ea417523f3a85b6dfbe0946911ee98" alt="Click replay" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/replay-runs-list-popover.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a209714c65dd764887340b4e74982e31 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4878f0b2ef8a6f0454c5de06fa93afae 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8ae5e94682543b0635843fa4a53cb78f 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=01dccbbc607bfce636f9741b0fcd2a60 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=82675f2f8ab5c55decf4820ceae8bb2e 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/replay-runs-list-popover.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f3a61382a15ee4515bd4cfaf35a397d2 2500w" /></Step>
    </Steps>
  </Tab>
</Tabs>

### Replaying using the SDK

You can replay a run using the SDK:

```ts  theme={null}
const replayedRun = await runs.replay(run.id);
```

When you call `trigger()` or `batchTrigger()` on a task you receive back a run handle which has an `id` property. You can use that `id` to replay the run.

You can also access the run id from inside a run. You could write this to your database and then replay it later.

```ts  theme={null}
export const simpleChildTask = task({
  id: "simple-child-task",
  run: async (payload, { ctx }) => {
    // the run ID (and other useful info) is in ctx
    const runId = ctx.run.id;
  },
});
```

### Bulk replaying

See [Bulk actions](/bulk-actions) for more information.


# Request a feature
Source: https://trigger.dev/docs/request-feature



If you have a feature request or idea for Trigger, we'd love to hear it! You can submit your ideas on our [public roadmap](https://feedback.trigger.dev/). We're always looking for feedback on what to build next, so feel free to submit your ideas or vote on existing ones.


# Roadmap
Source: https://trigger.dev/docs/roadmap



See what's coming up next on our [public roadmap](https://feedback.trigger.dev/roadmap). We're always looking for feedback on what to build next, so feel free to submit your ideas or vote on existing ones.


# Run tests
Source: https://trigger.dev/docs/run-tests

You can use the dashboard to run a test of your tasks.

From the "Test" page in the side menu of the dashboard you can run a test for any of your tasks from any environment.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=92c810690f961d0033dd94d758c6bbfb" alt="Select an environment" data-og-width="2254" width="2254" data-og-height="1367" height="1367" data-path="images/test-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=970cc3e2d58a06fbf197fce5d6d0664b 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=10d36ffd64e1f455f45a20d5e39f7bca 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=62b4ec2301d11e645d3ebe45b2e3adc2 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=2db30f2ebfe494c81f5965a014e4fc6e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67b24a2d00bde47226c4db88c4f7ac51 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/test-dashboard.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e44fddf5357449c582b92cd3d434e43d 2500w" />

<Icon icon="circle-1" iconType="solid" color="#FF2D6B" size="20" /> Select a task to test

<Icon icon="circle-2" iconType="solid" color="#FF2D6B" size="20" /> Include a payload or metadata

<Icon icon="circle-3" iconType="solid" color="#FF2D6B" size="20" /> Configure any additional options like the machine size, queue or delay

<Icon icon="circle-4" iconType="solid" color="#FF2D6B" size="20" /> Select from previous test runs

<Icon icon="circle-5" iconType="solid" color="#FF2D6B" size="20" /> Save the current test configuration as a template for later

<Icon icon="circle-6" iconType="solid" color="#FF2D6B" size="20" /> Run the test


# Usage
Source: https://trigger.dev/docs/run-usage

Get compute duration and cost from inside a run, or for a specific block of code.

## Getting the run cost and duration

You can get the cost and duration of the current including retries of the same run.

```ts  theme={null}
export const heavyTask = task({
  id: "heavy-task",
  machine: {
    preset: "medium-2x",
  },
  run: async (payload, { ctx }) => {
    // Do some compute
    const result = await convertVideo(payload.videoUrl);

    // Get the current cost and duration up until this line of code
    // This includes the compute time of the previous lines
    let currentUsage = usage.getCurrent();
    /* currentUsage = {
        compute: {
          attempt: {
            costInCents: 0.01700,
            durationMs: 1000,
          },
          total: {
            costInCents: 0.0255,
            durationMs: 1500,
          },
        },
        baseCostInCents: 0.0025,
        totalCostInCents: 0.028,
      } 
      */

    // In the cloud product we do not count waits towards the compute cost or duration.
    // We also don't include time between attempts or before the run starts executing your code.
    // So this line does not affect the cost or duration.
    await wait.for({ seconds: 5 });

    // This will give the same result as before the wait.
    currentUsage = usage.getCurrent();

    // Do more compute
    const result = await convertVideo(payload.videoUrl);

    // This would give a different value
    currentUsage = usage.getCurrent();
  },
});
```

<Note>
  In Trigger.dev cloud we do not include time between attempts, before your code executes, or waits
  towards the compute cost or duration.
</Note>

## Getting the run cost and duration from your backend

You can use [runs.retrieve()](/management/runs/retrieve) to get a single run or [runs.list()](/management/runs/list) to get a list of runs. The response will include `costInCents` `baseCostInCents` and `durationMs` fields.

```ts single run theme={null}
import { runs } from "@trigger.dev/sdk";

const run = await runs.retrieve("run-id");
console.log(run.costInCents, run.baseCostInCents, run.durationMs);
const totalCost = run.costInCents + run.baseCostInCents;
```

```ts multiple runs theme={null}
import { runs } from "@trigger.dev/sdk";

let totalCost = 0;
for await (const run of runs.list({ tag: "user_123456" })) {
  totalCost += run.costInCents + run.baseCostInCents;
  console.log(run.costInCents, run.baseCostInCents, run.durationMs);
}

console.log("Total cost", totalCost);
```

## Getting the cost and duration of a block of code

You can also wrap code with `usage.measure` to get the cost and duration of that block of code:

```ts  theme={null}
// Inside a task run function, or inside a function that's called from there.
const { result, compute } = await usage.measure(async () => {
  //...Do something for 1 second
  return {
    foo: "bar",
  };
});

logger.info("Result", { result, compute });
/* result = {
    foo: "bar"
  }
  compute = {
    costInCents: 0.01700,
    durationMs: 1000,
  }
*/
```

This will work from inside the `run` function, our lifecycle hooks (like `onStart`, `onFailure`, `onSuccess`, etc.), or any function you're calling from the `run` function. It won't work for code that's not executed using Trigger.dev.


# Runs
Source: https://trigger.dev/docs/runs

Understanding the lifecycle of task run execution in Trigger.dev

In Trigger.dev, the concepts of runs and attempts are fundamental to understanding how tasks are executed and managed. This article explains these concepts in detail and provides insights into the various states a run can go through during its lifecycle.

## What are runs?

A run is created when you trigger a task (e.g. calling `yourTask.trigger({ foo: "bar" })`). It represents a single instance of a task being executed and contains the following key information:

* A unique run ID
* The current status of the run
* The payload (input data) for the task
* Lots of other metadata

## The run lifecycle

A run can go through **various** states during its lifecycle. The following diagram illustrates a typical state transition where a single run is triggered and completes successfully:

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a8936884740688be9f52dd5d7356fb44" alt="Run Lifecycle" data-og-width="1430" width="1430" data-og-height="549" height="549" data-path="images/run-lifecycle.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3af5089f036381cbacc1749c212eb0f4 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cace40b5bbab66d38031fed3e28a9182 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f177c420bee7020b3a0e0e4ff73a1ee0 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cba5c92e5b76a9651c89376826b1b34c 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=74a0627ced1962111e7b78debaa3bcb8 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-lifecycle.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7850d8f28313b615293b27dc6d4bf428 2500w" />

Runs can also find themselves in lots of other states depending on what's happening at any given time. The following sections describe all the possible states in more detail.

### Initial states

<Icon icon="rectangle-history" iconType="solid" color="#FBBF24" size={17} /> **Pending version**:
The task is waiting for a version update because it cannot execute without additional information (task, queue, etc.).

<Icon icon="clock" iconType="solid" color="#878C99" size={17} /> **Delayed**: When a run is triggered
with a delay, it enters this state until the specified delay period has passed.

<Icon icon="rectangle-history" iconType="solid" color="#878C99" size={17} /> **Queued**: The run is ready
to be executed and is waiting in the queue.

<Icon icon="rectangle-history" iconType="solid" color="#878C99" size={17} /> **Dequeued**: The task has been dequeued and is being sent to a worker to start executing.

### Execution states

<Icon icon="spinner-third" iconType="duotone" color="#3B82F6" size={17} /> **Executing**: The task is
currently being executed by a worker.

<Icon icon="hourglass" iconType="solid" color="#878C99" size={17} /> **Waiting**: You have used a
[triggerAndWait()](/triggering#yourtask-triggerandwait), [batchTriggerAndWait()](/triggering#yourtask-batchtriggerandwait) or a [wait function](/wait). When the wait is complete, the task will resume execution.

### Final states

<Icon icon="circle-check" iconType="solid" color="#28BF5C" size={17} /> **Completed**: The task has successfully
finished execution.

<Icon icon="ban" iconType="solid" color="#878C99" size={17} /> **Canceled**: The run was manually canceled
by the user.

<Icon icon="circle-xmark" iconType="solid" color="#E11D48" size={17} /> **Failed**: The task has failed
to complete successfully due to an error in the task code.

<Icon icon="alarm-exclamation" iconType="solid" color="#E11D48" size={17} /> **Timed out**: Task has
failed because it exceeded its `maxDuration`.

<Icon icon="fire" iconType="solid" color="#E11D48" size={17} /> **Crashed**: The worker process crashed
during execution (likely due to an Out of Memory error) and wonâ€™t be retried.

<Icon icon="bug" iconType="solid" color="#E11D48" size={17} /> **System failure**: An unrecoverable system
error has occurred.

<Icon icon="trash-can" iconType="solid" color="#878C99" size={17} /> **Expired**: The run's [Time-to-Live](#time-to-live-ttl)
(TTL) has passed before it could start executing.

## Attempts

An attempt represents a single execution of a task within a run. A run can have one or more attempts, depending on the task's retry settings and whether it fails. Each attempt has:

* A unique attempt ID
* A status
* An output (if successful) or an error (if failed)

When a task fails, it will be retried according to its retry settings, creating new attempts until it either succeeds or reaches the retry limit.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=520a05470d031b8117b2780405964153" alt="Run with retries" data-og-width="1430" width="1430" data-og-height="585" height="585" data-path="images/run-with-retries.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f9d43bd7b37a9fffaa342cc4d05bb89a 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ace34edfe0154bcff7c2555e6ae3bf83 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a3a7478cfd71ede3194dd2ae2226ac12 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2dd91c524cf54fe9c6b3960afb7e3ad6 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8a2680c03a1515e3f25ac1f36bc25377 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-retries.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6c0a8c1b610d5befaf82b583e2adcedf 2500w" />

## Run completion

A run is considered finished when:

1. The last attempt succeeds, or
2. The task has reached its retry limit and all attempts have failed

At this point, the run will have either an output (if successful) or an error (if failed).

## Boolean helpers

Run objects returned from the API and Realtime include convenient boolean helper methods to check the run's status:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

const run = await runs.retrieve("run_1234");

if (run.isCompleted) {
  console.log("Run completed successfully");
}
```

* **`isQueued`**: Returns `true` when the status is `QUEUED`, `PENDING_VERSION`, or `DELAYED`
* **`isExecuting`**: Returns `true` when the status is `EXECUTING` or `DEQUEUED`. These count against your concurrency limits.
* **`isWaiting`**: Returns `true` when the status is `WAITING`. These do not count against your concurrency limits.
* **`isCompleted`**: Returns `true` when the status is any of the completed statuses
* **`isCanceled`**: Returns `true` when the status is `CANCELED`
* **`isFailed`**: Returns `true` when the status is any of the failed statuses
* **`isSuccess`**: Returns `true` when the status is `COMPLETED`

These helpers are also available when subscribing to Realtime run updates:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.subscribeToRun("run_1234")) {
  if (run.isCompleted) {
    console.log("Run completed successfully!");
    break;
  }
}
```

## Advanced run features

### Idempotency Keys

When triggering a task, you can provide an idempotency key to ensure the task is executed only once, even if triggered multiple times. This is useful for preventing duplicate executions in distributed systems.

```ts  theme={null}
await yourTask.trigger({ foo: "bar" }, { idempotencyKey: "unique-key" });
```

* If a run with the same idempotency key is already in progress, the new trigger will be ignored.
* If the run has already finished, the previous output or error will be returned.

See our [Idempotency docs](/idempotency) for more information.

### Canceling runs

You can cancel an in-progress run using the API or the dashboard:

```ts  theme={null}
await runs.cancel(runId);
```

When a run is canceled:

â€“ The task execution is stopped

â€“ The run is marked as canceled

â€“ The task will not be retried

â€“ Any in-progress child runs are also canceled

### Time-to-live (TTL)

TTL is a time-to-live setting that defines the maximum duration a run can remain in a queued state before being automatically expired. You can set a TTL when triggering a run:

```ts  theme={null}
await yourTask.trigger({ foo: "bar" }, { ttl: "10m" });
```

If the run hasn't started within the specified TTL, it will automatically expire, returning the status `Expired`. This is useful for time-sensitive tasks where immediate execution is important. For example, when you queue many runs simultaneously and exceed your concurrency limits, some runs might be delayed - using TTL ensures they only execute if they can start within your specified timeframe.

Note that dev runs automatically have a 10-minute TTL. In Staging and Production environments, no TTL is set by default.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2a3663f4cf4d7c4249c5c82f54859a76" alt="Run with TTL" data-og-width="1406" width="1406" data-og-height="453" height="453" data-path="images/run-with-ttl.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c596effb593c6533723019ba62d72cf9 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fd441b76d258f5d8ad83b17a42dfeb1c 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a1ba26b44a1b1fb0822eb7142aaf69ef 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=477990ac794bc64d536becff619cdd81 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=56720e4a594907f52dabc475dd663b03 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-ttl.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f3c577f8ef1ee2bcb22bf66259d88869 2500w" />

### Delayed runs

You can schedule a run to start after a specified delay:

```ts  theme={null}
await yourTask.trigger({ foo: "bar" }, { delay: "1h" });
```

This is useful for tasks that need to be executed at a specific time in the future.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fe68bf64bab17c12f0c1c532bdb48ab4" alt="Run with delay" data-og-width="1430" width="1430" data-og-height="581" height="581" data-path="images/run-with-delay.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e185434d9cd2a26155dee5ac5e94f370 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=829277bb21bc824019d68fc8f755ce2c 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7e88e6325a8559caca3c76a573f5523c 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ce7e12e3199088a1c7316918bb6fb3a7 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0cf1c7ecc525f8f8f5c4550cdd463df3 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-delay.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=03fc83ca451c8b58faf1c79c34bdface 2500w" />

### Replaying runs

You can create a new run with the same payload as a previous run:

```ts  theme={null}
await runs.replay(runId);
```

This is useful for re-running a task with the same input, especially for debugging or recovering from failures. The new run will use the latest version of the task.

You can also replay runs from the dashboard using the same or different payload. Learn how to do this [here](/replaying).

### Waiting for runs

#### triggerAndWait()

The `triggerAndWait()` function triggers a task and then lets you wait for the result before continuing. [Learn more about triggerAndWait()](/triggering#yourtask-triggerandwait).

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b7175cd727983b76dc998fa76cdc7279" alt="Run with triggerAndWait" data-og-width="1617" width="1617" data-og-height="735" height="735" data-path="images/run-with-triggerAndWait().png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b6c6add3e9f09f52eb4b63e1e723175a 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6d78b248fdc52ef7833f4ba71713b3f0 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0f69ee104ab1e7afb9fde3d69b9b6d7a 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=292ec187be08fefd76f30c3a768b7449 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c3cedaa32be6515ab9738df67c87276a 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-triggerAndWait().png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c8e309d749162c08006a9baca616ef74 2500w" />

#### batchTriggerAndWait()

Similar to `triggerAndWait()`, the `batchTriggerAndWait()` function lets you batch trigger a task and wait for all the results [Learn more about batchTriggerAndWait()](/triggering#yourtask-batchtriggerandwait).

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=26974085e23f5dd55ea301234b477655" alt="Run with batchTriggerAndWait" data-og-width="1617" width="1617" data-og-height="940" height="940" data-path="images/run-with-batchTriggerAndWait().png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=96d696e99dec5085efd8327dce107618 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8c926544b58cd261021928eeda461bf4 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8f412df861d962ccaba445a95971daca 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=e590ab7550353f53a6e3b62972c38771 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=cc03c2493a62ae36b30ecad5ce3889ab 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-with-batchTriggerAndWait().png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7863f7505ba010ae2b1f0f998f57cf35 2500w" />

### Runs API

#### runs.list()

List runs in a specific environment. You can filter the runs by status, created at, task identifier, version, and more:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

// Get the first page of runs, returning up to 20 runs
let page = await runs.list({ limit: 20 });

for (const run of page.data) {
  console.log(run);
}

// Keep getting the next page until there are no more runs
while (page.hasNextPage()) {
  page = await page.getNextPage();
  // Do something with the next page of runs
}
```

You can also use an Async Iterator to get all runs:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.list({ limit: 20 })) {
  console.log(run);
}
```

You can provide multiple filters to the `list()` function to narrow down the results:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

const response = await runs.list({
  status: ["QUEUED", "EXECUTING"], // Filter by status
  taskIdentifier: ["my-task", "my-other-task"], // Filter by task identifier
  from: new Date("2024-04-01T00:00:00Z"), // Filter by created at
  to: new Date(),
  version: "20241127.2", // Filter by deployment version,
  tag: ["tag1", "tag2"], // Filter by tags
  batch: "batch_1234", // Filter by batch ID
  schedule: "sched_1234", // Filter by schedule ID
});
```

#### runs.retrieve()

Fetch a single run by it's ID:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

const run = await runs.retrieve(runId);
```

You can provide the type of the task to correctly type the `run.payload` and `run.output`:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/myTask";

const run = await runs.retrieve<typeof myTask>(runId);

console.log(run.payload.foo); // string
console.log(run.output.bar); // string
```

If you have just triggered a run, you can pass the entire response object to `retrieve()` and the response will already be typed:

```ts  theme={null}
import { runs, tasks } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/myTask";

const response = await tasks.trigger<typeof myTask>({ foo: "bar" });
const run = await runs.retrieve(response);

console.log(run.payload.foo); // string
console.log(run.output.bar); // string
```

#### runs.cancel()

Cancel a run:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

await runs.cancel(runId);
```

#### runs.replay()

Replay a run:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

await runs.replay(runId);
```

#### runs.reschedule()

Updates a delayed run with a new delay. Only valid when the run is in the DELAYED state.

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

await runs.reschedule(runId, { delay: "1h" });
```

### Real-time updates

Subscribe to changes to a specific run in real-time:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

for await (const run of runs.subscribeToRun(runId)) {
  console.log(run);
}
```

Similar to `runs.retrieve()`, you can provide the type of the task to correctly type the `run.payload` and `run.output`:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";
import type { myTask } from "./trigger/myTask";

for await (const run of runs.subscribeToRun<typeof myTask>(runId)) {
  console.log(run.payload.foo); // string
  console.log(run.output?.bar); // string | undefined
}
```

For more on real-time updates, see the [Realtime](/realtime) documentation.

### Triggering runs for undeployed tasks

It's possible to trigger a run for a task that hasn't been deployed yet. The run will enter the "Waiting for deploy" state until the task is deployed. Once deployed, the run will be queued and executed normally.
This feature is particularly useful in CI/CD pipelines where you want to trigger tasks before the deployment is complete.


# Max duration
Source: https://trigger.dev/docs/runs/max-duration

Set a maximum duration for a task to run.

The `maxDuration` parameter sets a maximum compute time limit for tasks. When a task exceeds this duration, it will be automatically stopped. This helps prevent runaway tasks and manage compute resources effectively.

You must set a default maxDuration in your `trigger.config.ts` file, which will apply to all tasks unless overridden:

```ts /config/trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "proj_gtcwttqhhtlasxgfuhxs",
  maxDuration: 60, // 60 seconds or 1 minute
});
```

<Note>
  The minimum maxDuration is 5 seconds. If you want to avoid timeouts, set this value to a very large number of seconds.
</Note>

You can set the `maxDuration` for a run in the following ways:

* Across all your tasks in the [config](/config/config-file#max-duration)
* On a specific task
* On a specific run when you [trigger a task](/triggering#maxduration)

## How it works

The `maxDuration` is set in seconds, and is compared to the CPU time elapsed since the start of a single execution (which we call [attempts](/runs#attempts)) of the task. The CPU time is the time that the task has been actively running on the CPU, and does not include time spent waiting during the following:

* `wait.for` calls
* `triggerAndWait` calls
* `batchTriggerAndWait` calls

You can inspect the CPU time of a task inside the run function with our `usage` utility:

```ts /trigger/max-duration.ts theme={null}
import { task, usage } from "@trigger.dev/sdk";

export const maxDurationTask = task({
  id: "max-duration-task",
  maxDuration: 300, // 300 seconds or 5 minutes
  run: async (payload: any, { ctx }) => {
    let currentUsage = usage.getCurrent();

    currentUsage.attempt.durationMs; // The CPU time in milliseconds since the start of the run
  },
});
```

The above value will be compared to the `maxDuration` you set. If the task exceeds the `maxDuration`, it will be stopped with the following error:

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fb10afcfe6aae4eff9556065464a32c7" alt="Max duration error" data-og-width="924" width="924" data-og-height="316" height="316" data-path="runs/max-duration-error.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3771ebf9e1f4eeb6a91a83deddea89a8 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8d994f357524f61a993ac1313cd923fc 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=bbde11e079e057cb0ce80660c865df75 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=68ff4023f21611a3157356341efe9759 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=9dba8f836e6c38da8d8425a775b13d14 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/runs/max-duration-error.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=67a18c013e6fe596764caea1ef7d9cf6 2500w" />

## Configuring for a task

You can set a `maxDuration` on a specific task:

```ts /trigger/max-duration-task.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const maxDurationTask = task({
  id: "max-duration-task",
  maxDuration: 300, // 300 seconds or 5 minutes
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

This will override the default `maxDuration` set in the config file. If you have a config file with a default `maxDuration` of 60 seconds, and you set a `maxDuration` of 300 seconds on a task, the task will run for 300 seconds.

You can "turn off" the Max duration set in your config file for a specific task like so:

```ts /trigger/max-duration-task.ts theme={null}
import { task, timeout } from "@trigger.dev/sdk";

export const maxDurationTask = task({
  id: "max-duration-task",
  maxDuration: timeout.None, // No max duration
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

## Configuring for a run

You can set a `maxDuration` on a specific run when you trigger a task:

```ts /trigger/max-duration.ts theme={null}
import { maxDurationTask } from "./trigger/max-duration-task";

// Trigger the task with a maxDuration of 300 seconds
const run = await maxDurationTask.trigger(
  { foo: "bar" },
  {
    maxDuration: 300, // 300 seconds or 5 minutes
  }
);
```

You can also set the `maxDuration` to `timeout.None` to turn off the max duration for a specific run:

```ts /trigger/max-duration.ts theme={null}
import { maxDurationTask } from "./trigger/max-duration-task";
import { timeout } from "@trigger.dev/sdk";

// Trigger the task with no maxDuration
const run = await maxDurationTask.trigger(
  { foo: "bar" },
  {
    maxDuration: timeout.None, // No max duration
  }
);
```

## maxDuration in run context

You can access the `maxDuration` set for a run in the run context:

```ts /trigger/max-duration-task.ts theme={null}
import { task } from "@trigger.dev/sdk";

export const maxDurationTask = task({
  id: "max-duration-task",
  maxDuration: 300, // 300 seconds or 5 minutes
  run: async (payload: any, { ctx }) => {
    console.log(ctx.run.maxDuration); // 300
  },
});
```

## maxDuration and lifecycle functions

When a task run exceeds the `maxDuration`, the lifecycle functions `cleanup`, `onSuccess`, and `onFailure` will not be called.


# Run metadata
Source: https://trigger.dev/docs/runs/metadata

Attach a small amount of data to a run and update it as the run progresses.

You can attach up to 256KB of metadata to a run, which you can then access from inside the run function, via the API, Realtime, and in the dashboard. You can use metadata to store additional, structured information on a run. For example, you could store your userâ€™s full name and corresponding unique identifier from your system on every task that is associated with that user. Or you could store the progress of a long-running task, or intermediate results that you want to access later.

## Usage

Add metadata to a run when triggering by passing it as an object to the `trigger` function:

```ts  theme={null}
const handle = await myTask.trigger(
  { message: "hello world" },
  { metadata: { user: { name: "Eric", id: "user_1234" } } }
);
```

You can get the current metadata at any time by calling `metadata.get()` or `metadata.current()` (only inside a run):

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Get the whole metadata object
    const currentMetadata = metadata.current();
    console.log(currentMetadata);

    // Get a specific key
    const user = metadata.get("user");
    console.log(user.name); // "Eric"
  },
});
```

Any of these methods can be called anywhere "inside" the run function, or a function called from the run function:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    doSomeWork();
  },
});

async function doSomeWork() {
  // Set the value of a specific key
  metadata.set("progress", 0.5);
}
```

If you call any of the metadata methods outside of the run function, they will have no effect:

```ts  theme={null}
import { metadata } from "@trigger.dev/sdk";

// Somewhere outside of the run function
function doSomeWork() {
  metadata.set("progress", 0.5); // This will do nothing
}
```

This means it's safe to call these methods anywhere in your code, and they will only have an effect when called inside the run function.

<Note>
  Calling `metadata.current()` or `metadata.get()` outside of the run function will always return
  undefined.
</Note>

These methods also work inside any task lifecycle hook, either attached to the specific task or the global hooks defined in your `trigger.config.ts` file.

<CodeGroup>
  ```ts myTasks.ts theme={null}
  import { task, metadata } from "@trigger.dev/sdk";

  export const myTask = task({
    id: "my-task",
    run: async (payload: { message: string }) => {
      // Your run function work here
    },
    onStart: async () => {
      metadata.set("progress", 0.5);
    },
    onSuccess: async () => {
      metadata.set("progress", 1.0);
    },
  });
  ```

  ```ts trigger.config.ts theme={null}
  import { defineConfig, metadata } from "@trigger.dev/sdk";

  export default defineConfig({
    project: "proj_1234",
    onStart: async () => {
      metadata.set("progress", 0.5);
    },
  });
  ```
</CodeGroup>

## Updates API

One of the more powerful features of metadata is the ability to update it as the run progresses. This is useful for tracking the progress of a run, storing intermediate results, or storing any other information that changes over time. (Combining metadata with [Realtime](/realtime) can give you a live view of the progress of your runs.)

All metadata update methods (accept for `flush` and `stream`) are synchronous and will not block the run function. We periodically flush metadata to the database in the background, so you can safely update the metadata inside a run as often as you need to, without worrying about impacting the run's performance.

### set

Set the value of a key in the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Do some more work
    metadata.set("progress", 0.5);

    // Do even more work
    metadata.set("progress", 1.0);
  },
});
```

### del

Delete a key from the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Do some more work
    metadata.set("progress", 0.5);

    // Remove the progress key
    metadata.del("progress");
  },
});
```

### replace

Replace the entire metadata object with a new object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Replace the metadata object
    metadata.replace({ user: { name: "Eric", id: "user_1234" } });
  },
});
```

### append

Append a value to an array in the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Append a value to an array
    metadata.append("logs", "Step 1 complete");

    console.log(metadata.get("logs")); // ["Step 1 complete"]
  },
});
```

### remove

Remove a value from an array in the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Append a value to an array
    metadata.append("logs", "Step 1 complete");

    // Remove a value from the array
    metadata.remove("logs", "Step 1 complete");

    console.log(metadata.get("logs")); // []
  },
});
```

### increment

Increment a numeric value in the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Increment a value
    metadata.increment("progress", 0.4);

    console.log(metadata.get("progress")); // 0.5
  },
});
```

### decrement

Decrement a numeric value in the metadata object:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.5);

    // Decrement a value
    metadata.decrement("progress", 0.4);

    console.log(metadata.get("progress")); // 0.1
  },
});
```

### stream

<Note>
  As of SDK version **4.1.0**, `metadata.stream()` has been replaced by [Realtime Streams
  v2](/tasks/streams). We recommend using the new `streams.pipe()` API for better reliability,
  unlimited stream length, and improved developer experience. The examples below are provided for
  backward compatibility.
</Note>

Capture a stream of values and make the stream available when using Realtime. See our [Realtime Streams v2](/tasks/streams) documentation for the recommended approach.

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    const readableStream = new ReadableStream({
      start(controller) {
        controller.enqueue("Step 1 complete");
        controller.enqueue("Step 2 complete");
        controller.enqueue("Step 3 complete");
        controller.close();
      },
    });

    // IMPORTANT: you must await the stream method
    const stream = await metadata.stream("logs", readableStream);

    // You can read from the returned stream locally
    for await (const value of stream) {
      console.log(value);
    }
  },
});
```

`metadata.stream` accepts any `AsyncIterable` or `ReadableStream` object. The stream will be captured and made available in the Realtime API. So for example, you could pass the body of a fetch response to `metadata.stream` to capture the response body and make it available in Realtime:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { url: string }) => {
    logger.info("Streaming response", { url });

    const response = await fetch(url);

    if (!response.body) {
      throw new Error("Response body is not readable");
    }

    const stream = await metadata.stream(
      "fetch",
      response.body.pipeThrough(new TextDecoderStream())
    );

    let text = "";

    for await (const chunk of stream) {
      logger.log("Received chunk", { chunk });

      text += chunk;
    }

    return { text };
  },
});
```

Or the results of a streaming call to the OpenAI SDK:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export const myTask = task({
  id: "my-task",
  run: async (payload: { prompt: string }) => {
    const completion = await openai.chat.completions.create({
      messages: [{ role: "user", content: payload.prompt }],
      model: "gpt-3.5-turbo",
      stream: true,
    });

    const stream = await metadata.stream("openai", completion);

    let text = "";

    for await (const chunk of stream) {
      logger.log("Received chunk", { chunk });

      text += chunk.choices.map((choice) => choice.delta?.content).join("");
    }

    return { text };
  },
});
```

### flush

Flush the metadata to the database. The SDK will automatically flush the metadata periodically, so you don't need to call this method unless you need to ensure that the metadata is persisted immediately.

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Flush the metadata to the database
    await metadata.flush();
  },
});
```

## Fluent API

All of the update methods can be chained together in a fluent API:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    metadata
      .set("progress", 0.1)
      .append("logs", "Step 1 complete")
      .increment("progress", 0.4)
      .decrement("otherProgress", 0.1);
  },
});
```

## Parent & root updates

Tasks that have been triggered by a parent task (a.k.a. a "child task") can update the metadata of the parent task. This is useful for propagating progress information up the task hierarchy. You can also update the metadata of the root task (root = the initial task that was triggered externally, like from your backend).

To update the parent task's metadata, use the `metadata.parent` accessor:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myParentTask = task({
  id: "my-parent-task",
  run: async (payload: { message: string }) => {
    // Do some work
    metadata.set("progress", 0.1);

    // Trigger a child task
    await childTask.triggerAndWait({ message: "hello world" });
  },
});

export const childTask = task({
  id: "child-task",
  run: async (payload: { message: string }) => {
    // This will update the parent task's metadata
    metadata.parent.set("progress", 0.5);
  },
});
```

All of the update methods are available on `metadata.parent` and `metadata.root`:

```ts  theme={null}
metadata.parent.set("progress", 0.5);
metadata.parent.append("logs", "Step 1 complete");
metadata.parent.remove("logs", "Step 1 complete");
metadata.parent.increment("progress", 0.4);
metadata.parent.decrement("otherProgress", 0.1);
metadata.parent.stream("llm", readableStream); // Use streams.pipe() instead (v4.1+)

metadata.root.set("progress", 0.5);
metadata.root.append("logs", "Step 1 complete");
metadata.root.remove("logs", "Step 1 complete");
metadata.root.increment("progress", 0.4);
metadata.root.decrement("otherProgress", 0.1);
metadata.root.stream("llm", readableStream); // Use streams.pipe() instead (v4.1+)
```

You can also chain the update methods together:

```ts  theme={null}
metadata.parent
  .set("progress", 0.1)
  .append("logs", "Step 1 complete")
  .increment("progress", 0.4)
  .decrement("otherProgress", 0.1);
```

### Example

An example of where you might use parent and root updates is in a task that triggers multiple child tasks in parallel. You could use the parent metadata to track the progress of the child tasks and update the parent task's progress as each child task completes:

```ts  theme={null}
import { CSVRow, UploadedFileData, parseCSVFromUrl } from "@/utils";
import { batch, logger, metadata, schemaTask } from "@trigger.dev/sdk";

export const handleCSVRow = schemaTask({
  id: "handle-csv-row",
  schema: CSVRow,
  run: async (row, { ctx }) => {
    // Do some work with the row

    // Update the parent task's metadata with the progress of this row
    metadata.parent.increment("processedRows", 1).append("rowRuns", ctx.run.id);

    return row;
  },
});

export const handleCSVUpload = schemaTask({
  id: "handle-csv-upload",
  schema: UploadedFileData,
  run: async (file, { ctx }) => {
    metadata.set("status", "fetching");

    const rows = await parseCSVFromUrl(file.url);

    metadata.set("status", "processing").set("totalRows", rows.length);

    const results = await batch.triggerAndWait<typeof handleCSVRow>(
      rows.map((row) => ({ id: "handle-csv-row", payload: row }))
    );

    metadata.set("status", "complete");

    return {
      file,
      rows,
      results,
    };
  },
});
```

Combined with [Realtime](/realtime), you could use this to show a live progress bar of the CSV processing in your frontend, like this:

<video src="https://content.trigger.dev/csv-upload-realtime.mp4" preload="auto" controls={true} loop muted autoPlay={true} width="100%" height="100%" />

## More metadata task examples

Using metadata updates in conjunction with our [Realtime React hooks](/realtime/react-hooks/overview) can be a powerful way to build real-time UIs. Here are some example tasks demonstrating how to use metadata in your tasks to track progress, status, and more:

### Progress tracking

Track progress with percentage and current step:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const batchProcessingTask = task({
  id: "batch-processing",
  run: async (payload: { records: any[] }) => {
    for (let i = 0; i < payload.records.length; i++) {
      const record = payload.records[i];

      // Update progress
      metadata.set("progress", {
        step: i + 1,
        total: payload.records.length,
        percentage: Math.round(((i + 1) / payload.records.length) * 100),
        currentRecord: record.id,
      });

      await processRecord(record);
    }
  },
});
```

### Status updates with logs

Append log entries while maintaining status:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const deploymentTask = task({
  id: "deployment",
  run: async (payload: { version: string }) => {
    metadata.set("status", "initializing");
    metadata.append("logs", "Starting deployment...");

    // Step 1
    metadata.set("status", "building");
    metadata.append("logs", "Building application...");
    await buildApplication();

    // Step 2
    metadata.set("status", "deploying");
    metadata.append("logs", "Deploying to production...");
    await deployToProduction();

    // Step 3
    metadata.set("status", "verifying");
    metadata.append("logs", "Running health checks...");
    await runHealthChecks();

    metadata.set("status", "completed");
    metadata.append("logs", "Deployment successful!");
  },
});
```

### User context and notifications

Store user information and notification preferences:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const userTask = task({
  id: "user-task",
  run: async (payload: { userId: string; action: string }) => {
    // Set user context in metadata
    metadata.set("user", {
      id: payload.userId,
      action: payload.action,
      startedAt: new Date().toISOString(),
    });

    // Update status for user notifications
    metadata.set("notification", {
      type: "info",
      message: `Starting ${payload.action} for user ${payload.userId}`,
    });

    await performUserAction(payload);

    metadata.set("notification", {
      type: "success",
      message: `${payload.action} completed successfully`,
    });
  },
});
```

## Metadata propagation

Metadata is NOT propagated to child tasks. If you want to pass metadata to a child task, you must do so explicitly:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    await metadata.set("progress", 0.5);
    await childTask.trigger(payload, { metadata: metadata.current() });
  },
});
```

## Type-safe metadata

The metadata APIs are currently loosely typed, accepting any object that is JSON-serializable:

```ts  theme={null}
// âŒ You can't pass a top-level array
const handle = await myTask.trigger(
  { message: "hello world" },
  { metadata: [{ user: { name: "Eric", id: "user_1234" } }] }
);

// âŒ You can't pass a string as the entire metadata:
const handle = await myTask.trigger(
  { message: "hello world" },
  { metadata: "this is the metadata" }
);

// âŒ You can't pass in a function or a class instance
const handle = await myTask.trigger(
  { message: "hello world" },
  { metadata: { user: () => "Eric", classInstance: new HelloWorld() } }
);

// âœ… You can pass in dates and other JSON-serializable objects
const handle = await myTask.trigger(
  { message: "hello world" },
  { metadata: { user: { name: "Eric", id: "user_1234" }, date: new Date() } }
);
```

<Note>
  If you pass in an object like a Date, it will be serialized to a string when stored in the
  metadata. That also means that when you retrieve it using `metadata.get()` or
  `metadata.current()`, you will get a string back. You will need to deserialize it back to a Date
  object if you need to use it as a Date.
</Note>

We recommend wrapping the metadata API in a [Zod](https://zod.dev) schema (or your validator library of choice) to provide type safety:

```ts  theme={null}
import { task, metadata } from "@trigger.dev/sdk";
import { z } from "zod";

const Metadata = z.object({
  user: z.object({
    name: z.string(),
    id: z.string(),
  }),
  date: z.coerce.date(), // Coerce the date string back to a Date object
});

type Metadata = z.infer<typeof Metadata>;

// Helper function to get the metadata object in a type-safe way
// Note: you would probably want to use .safeParse instead of .parse in a real-world scenario
function getMetadata() {
  return Metadata.parse(metadata.current());
}

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }) => {
    const metadata = getMetadata();
    console.log(metadata.user.name); // "Eric"
    console.log(metadata.user.id); // "user_1234"
    console.log(metadata.date); // Date object
  },
});
```

## Inspecting metadata

### Dashboard

You can view the metadata for a run in the Trigger.dev dashboard. The metadata will be displayed in the run details view:

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0757a26d7412cfb5601e0d453bf3a8f1" alt="View run metadata dashboard" data-og-width="5344" width="5344" data-og-height="3054" height="3054" data-path="images/run-metadata.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2ae28f6184036b57d8fee2756bd06696 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a3b6dbc7975cd49a9549288acd1d92e4 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=b5b871c055ec8e1bac8aa77448bd8fa2 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=2f841aeba8a44c815d7f8e01792b0635 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4ea3487ad669414e26fd8b2a0c37bf94 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/run-metadata.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c3a80b27fecbba819ef452436df571ff 2500w" />

### API

You can use the `runs.retrieve()` SDK function to get the metadata for a run:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

const run = await runs.retrieve("run_1234");

console.log(run.metadata);
```

See the [API reference](/management/runs/retrieve) for more information.

## Size limit

The maximum size of the metadata object is 256KB. If you exceed this limit, the SDK will throw an error. If you are self-hosting Trigger.dev, you can increase this limit by setting the `TASK_RUN_METADATA_MAXIMUM_SIZE` environment variable. For example, to increase the limit to 16KB, you would set `TASK_RUN_METADATA_MAXIMUM_SIZE=16384`.


# Priority
Source: https://trigger.dev/docs/runs/priority

Specify a priority when triggering a run.

You can set a priority when you trigger a run. This allows you to prioritize some of your runs over others, so they are started sooner. This is very useful when:

* You have critical work that needs to start more quickly (and you have long queues).
* You want runs for your premium users to take priority over free users.

The value for priority is a time offset in seconds that determines the order of dequeuing.

<img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=36b348760cb05a1c7af1b8625beddf24" alt="Priority runs" data-og-width="1243" width="1243" data-og-height="1333" height="1333" data-path="images/priority-runs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=98dd1c09b0da112db56fed9c27fb1dde 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=bd9ed1ea970f1cfa642f7c1d1c9c01ba 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=69b0bd28f1825e9fbfc3337e60355276 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=9f5fe734ac451bde5a6187f856515d30 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=756b8d9cd6835143ca95f7fefbc7f609 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/priority-runs.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c1003b28761e476969bb0b226e589ec9 2500w" />

If you specify a priority of `10` the run will dequeue before runs that were triggered with no priority 8 seconds ago, like in this example:

```ts  theme={null}
// no priority = 0
await myTask.trigger({ foo: "bar" });

//... imagine 8s pass by

// this run will start before the run above that was triggered 8s ago (with no priority)
await myTask.trigger({ foo: "bar" }, { priority: 10 });
```

If you passed a value of `3600` the run would dequeue before runs that were triggered an hour ago (with no priority).

<Note>
  Setting a high priority will not allow you to beat runs from other organizations. It will only affect the order of your own runs.
</Note>


# Docker compose
Source: https://trigger.dev/docs/self-hosting/docker

You can self-host Trigger.dev on your own infrastructure using Docker.

The following instructions will use docker compose to spin up a Trigger.dev instance. Make sure to read the self-hosting [overview](/self-hosting/overview) first.

As self-hosted deployments tend to have unique requirements and configurations, we don't provide specific advice for securing your deployment, scaling up, or improving reliability.

Should the burden ever get too much, we'd be happy to see you on [Trigger.dev cloud](https://trigger.dev/pricing) where we deal with these concerns for you.

**Warning:** This guide alone is unlikely to result in a production-ready deployment. Security, scaling, and reliability concerns are not fully addressed here.

## What's new?

Goodbye v3, hello v4! We made quite a few changes:

* **Much simpler setup.** The provider and coordinator are now combined into a single supervisor. No more startup scripts, just `docker compose up`.
* **Automatic container cleanup.** The supervisor will automatically clean up containers that are no longer needed.
* **Support for multiple worker machines.** This is a big one, and we're very excited about it! You can now scale your workers horizontally as needed.
* **Resource limits enforced by default.** This means that tasks will be limited to the total CPU and RAM of the machine preset, preventing noisy neighbours.
* **No direct Docker socket access.** The compose file now comes with [Docker Socket Proxy](https://github.com/Tecnativa/docker-socket-proxy) by default. Yes, you want this.
* **No host networking.** All containers are now running with network isolation, using only the network access they need.
* **No checkpoint support.** This was only ever experimental when self-hosting and not recommended. It caused a bunch of issues. We decided to focus on the core features instead.
* **Built-in container registry and object storage.** You can now deploy and execute tasks without needing third party services for this.
* **Improved CLI commands.** You don't need any additional flags to deploy anymore, and there's a new command to easily `switch` between profiles.
* **Whitelisting for GitHub OAuth.** Any whitelisted email addresses will now also apply to sign ins via GitHub, unlike v3 where they only applied to magic links.

## Requirements

These are the minimum requirements for running the webapp and worker components. They can run on the same, or on separate machines.

It's fine to run everything on the same machine for testing. To be able to scale your workers, you will want to run them separately.

### Prerequisites

To run the webapp and worker components, you will need:

* [Docker](https://docs.docker.com/get-docker/) 20.10.0+
* [Docker Compose](https://docs.docker.com/compose/install/) 2.20.0+

### Webapp

This machine will host the webapp, postgres, redis, and related services.

* 3+ vCPU
* 6+ GB RAM

### Worker

This machine will host the supervisor and all of the runs.

* 4+ vCPU
* 8+ GB RAM

How many workers and resources you need will depend on your workloads and concurrency requirements.

For example:

* 10 concurrency x `small-1x` (0.5 vCPU, 0.5 GB RAM) = 5 vCPU and 5 GB RAM
* 20 concurrency x `small-1x` (0.5 vCPU, 0.5 GB RAM) = 10 vCPU and 10 GB RAM
* 100 concurrency x `small-1x` (0.5 vCPU, 0.5 GB RAM) = 50 vCPU and 50 GB RAM
* 100 concurrency x `small-2x` (1 vCPU, 1 GB RAM) = 100 vCPU and 100 GB RAM

You may need to spin up multiple workers to handle peak concurrency. The good news is you don't have to know the exact numbers upfront. You can start with a single worker and add more as needed.

## Setup

### Webapp

1. Clone the repository

```bash  theme={null}
git clone --depth=1 https://github.com/triggerdotdev/trigger.dev
cd trigger.dev/hosting/docker
```

2. Create a `.env` file

```bash  theme={null}
cp .env.example .env
```

3. Start the webapp

```bash  theme={null}
cd webapp
docker compose up -d
```

4. Configure the webapp using the [environment variables](/self-hosting/env/webapp) in your `.env` file, then apply the changes:

```bash  theme={null}
docker compose up -d
```

5. You should now be able to access the webapp at `http://localhost:8030`. When logging in, check the container logs for the magic link:

```bash  theme={null}
docker compose logs -f webapp
```

6. (optional) To initialize a new project, run the following command:

```bash  theme={null}
npx trigger.dev@latest init -p <project-ref> -a http://localhost:8030
```

### Worker

1. Clone the repository

```bash  theme={null}
git clone --depth=1 https://github.com/triggerdotdev/trigger.dev
cd trigger.dev/hosting/docker
```

2. Create a `.env` file

```bash  theme={null}
cp .env.example .env
```

3. Start the worker

```bash  theme={null}
cd worker
docker compose up -d
```

4. Configure the supervisor using the [environment variables](/self-hosting/env/supervisor) in your `.env` file, including the [worker token](#worker-token).

5. Apply the changes:

```bash  theme={null}
docker compose up -d
```

6. Repeat as needed for additional workers.

### Combined

If you want to run the webapp and worker on the same machine, just replace the `up` command with the following:

```bash  theme={null}
# Run this from the /hosting/docker directory
docker compose -f webapp/docker-compose.yml -f worker/docker-compose.yml up -d
```

## Worker token

When running the combined stack, worker bootstrap is handled automatically. When running the webapp and worker separately, you will need to manually set the worker token.

On the first run, the webapp will generate a worker token and store it in a shared volume. It will also print the token to the console. It should look something like this:

```bash  theme={null}
==========================
Trigger.dev Bootstrap - Worker Token

WARNING: This will only be shown once. Save it now!

Worker group:
bootstrap

Token:
tr_wgt_fgfAEjsTmvl4lowBLTbP7Xo563UlnVa206mr9uW6

If using docker compose, set:
TRIGGER_WORKER_TOKEN=tr_wgt_fgfAEjsTmvl4lowBLTbP7Xo563UlnVa206mr9uW6

Or, if using a file:
TRIGGER_WORKER_TOKEN=file:///home/node/shared/worker_token

==========================
```

You can then uncomment and set the `TRIGGER_WORKER_TOKEN` environment variable in your `.env` file.

Don't forget to restart the worker container for the changes to take effect:

```bash  theme={null}
# Run this from the /hosting/docker/worker directory
docker compose down
docker compose up -d
```

## Registry setup

The registry is used to store and pull deployment images. When testing the stack locally, the defaults should work out of the box.

When deploying to production, you will need to set the correct URL and generate secure credentials for the registry.

### Default settings

The default settings for the registry are:

* Registry: `localhost:5000`
* Username: `registry-user`
* Password: `very-secure-indeed`

You should change these before deploying to production, especially the password. You can find more information about how to do this in the official [registry docs](https://github.com/distribution/distribution/blob/735c161b53e7faf81a21ba94c55ac9edee081cd9/docs/deploying.md#native-basic-auth).

**Note:** This will require modifying the default `.htpasswd` file located at `./hosting/docker/registry/auth.htpasswd` of the repo root.

### Logging in

When self-hosting, builds run locally. You will have to login to the registry on every machine that runs the `deploy` command. You should only have to do this once:

```bash  theme={null}
docker login -u <username> <registry>
```

This will prompt for the password. Afterwards, the deploy command should work as expected.

## Object storage

This is mainly used for large payloads and outputs. There are a few simple steps to follow to get started.

### Default settings

The default settings for the object storage are:

* Endpoint: `http://localhost:9000`
* Username: `admin`
* Password: `very-safe-password`

You should change these before deploying to production, especially the password.

### Setup

<Note>
  The `packets` bucket is created by default. In case this doesn't work, you can create it manually.
</Note>

1. Login to the dashboard: `http://localhost:9001`

2. Create a bucket named `packets`.

3. For production, you will want to set up a dedicated user and not use the root credentials above.

## Authentication

The specific set of variables required will depend on your choice of email transport or alternative login methods like GitHub OAuth.

### Magic link

By default, magic link auth is the only login option. If the `EMAIL_TRANSPORT` env var is not set, the magic links will be logged by the webapp container and not sent via email.

#### Resend

```bash  theme={null}
EMAIL_TRANSPORT=resend
FROM_EMAIL=
REPLY_TO_EMAIL=
RESEND_API_KEY=<your_resend_api_key>
```

#### SMTP

Note that setting `SMTP_SECURE=false` does *not* mean the email is sent insecurely.
This simply means that the connection is secured using the modern STARTTLS protocol command instead of implicit TLS.
You should only set this to true when the SMTP server host directs you to do so (generally when using port 465)

```bash  theme={null}
EMAIL_TRANSPORT=smtp
FROM_EMAIL=
REPLY_TO_EMAIL=
SMTP_HOST=<your_smtp_server>
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=<your_smtp_username>
SMTP_PASSWORD=<your_smtp_password>
```

#### AWS SES

Credentials are to be supplied as with any other program using the AWS SDK.

In this scenario, you would likely either supply the additional environment variables `AWS_REGION`, `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` or, when running on AWS, use credentials supplied by the EC2 IMDS.

```bash  theme={null}
EMAIL_TRANSPORT=aws-ses
FROM_EMAIL=
REPLY_TO_EMAIL=
```

### GitHub OAuth

To authenticate with GitHub, you will need to set up a GitHub OAuth app. It needs a callback URL `https://<your_webapp_domain>/auth/github/callback` and you will have to set the following env vars:

```bash  theme={null}
AUTH_GITHUB_CLIENT_ID=<your_client_id>
AUTH_GITHUB_CLIENT_SECRET=<your_client_secret>
```

### Restricting access

All email addresses can sign up and log in this way. If you would like to restrict this, you can use the `WHITELISTED_EMAILS` env var. For example:

```bash  theme={null}
# every email that does not match this regex will be rejected
WHITELISTED_EMAILS="authorized@yahoo\.com|authorized@gmail\.com"
```

This will apply to all auth methods including magic link and GitHub OAuth.

## Version locking

There are several reasons to lock the version of your Docker images:

* **Backwards compatibility.** We try our best to maintain compatibility with older CLI versions, but it's not always possible. If you don't want to update your CLI, you can lock your Docker images to that specific version.
* **Ensuring full feature support.** Sometimes, new CLI releases will also require new or updated platform features. Running unlocked images can make any issues difficult to debug. Using a specific tag can help here as well.

By default, the images will point at the latest versioned release via the `latest` tag. You can override this by specifying a different tag in your `.env` file. For example:

```bash  theme={null}
TRIGGER_IMAGE_TAG=v4.0.0
```

## Troubleshooting

* **Deployment fails at the push step.** The machine running `deploy` needs registry access. See the [registry setup](#registry-setup) section for more details.

* **Magic links don't arrive.** The webapp container needs to be able to send emails. You probably need to set up an email transport. See the [authentication](#authentication) section for more details.

  You should check the logs of the webapp container to see the magic link:

  ```bash  theme={null}
  # Run this from the /hosting/docker/webapp directory
  docker compose logs -f webapp
  ```

## CLI usage

This section highlights some of the CLI commands and options that are useful when self-hosting. Please check the [CLI reference](/cli-introduction) for more in-depth documentation.

### Login

To avoid being redirected to [Trigger.dev Cloud](https://cloud.trigger.dev) when using the CLI, you need to specify the URL of your self-hosted instance with the `--api-url` or `-a` flag. For example:

```bash  theme={null}
npx trigger.dev@latest login -a http://trigger.example.com
```

Once you've logged in, you shouldn't have to specify the URL again with other commands.

### Profiles

You can specify a profile when logging in. This allows you to easily use the CLI with multiple instances of Trigger.dev. For example:

```bash  theme={null}
npx trigger.dev@latest login -a http://trigger.example.com \
    --profile self-hosted
```

Logging in with a new profile will also make it the new default profile.

To use a specific profile, you can use the `--profile` flag with other commands:

```bash  theme={null}
npx trigger.dev@latest dev --profile self-hosted
```

To list all your profiles, use the `list-profiles` command:

```bash  theme={null}
npx trigger.dev@latest list-profiles
```

To remove a profile, use the `logout` command:

```bash  theme={null}
npx trigger.dev@latest logout --profile self-hosted
```

To switch to a different profile, use the `switch` command:

```bash  theme={null}
# To run interactively
npx trigger.dev@latest switch

# To switch to a specific profile
npx trigger.dev@latest switch self-hosted
```

### Whoami

It can be useful to check you are logged into the correct instance. Running this will also show the API URL:

```bash  theme={null}
npx trigger.dev@latest whoami
```

## CI / GitHub Actions

When running the CLI in a CI environment, your login profiles won't be available. Instead, you can use the `TRIGGER_API_URL` and `TRIGGER_ACCESS_TOKEN` environment
variables to point at your self-hosted instance and authenticate.

For more detailed instructions, see the [GitHub Actions guide](/github-actions).

## Telemetry

By default, the Trigger.dev webapp sends telemetry data to our servers. This data is used to improve the product and is not shared with third parties. If you would like to opt-out of this, you can set the `TRIGGER_TELEMETRY_DISABLED` environment variable on the webapp container. The value doesn't matter, it just can't be empty. For example:

```yaml  theme={null}
services:
  webapp:
    ...
    environment:
      TRIGGER_TELEMETRY_DISABLED: 1
```


# Supervisor
Source: https://trigger.dev/docs/self-hosting/env/supervisor

Environment variables for the supervisor container.

| Name                                        | Required | Default     | Description                                                 |
| :------------------------------------------ | :------- | :---------- | :---------------------------------------------------------- |
| **Required settings**                       |          |             |                                                             |
| `TRIGGER_API_URL`                           | Yes      | â€”           | Trigger.dev API URL. Should point at the webapp.            |
| `TRIGGER_WORKER_TOKEN`                      | Yes      | â€”           | Worker token (can be a file path with file://).             |
| `MANAGED_WORKER_SECRET`                     | Yes      | â€”           | Managed worker secret. Needs to match webapp value.         |
| `OTEL_EXPORTER_OTLP_ENDPOINT`               | Yes      | â€”           | OTel exporter endpoint. Point at: `<webapp-url>/otel`       |
| **Worker instance**                         |          |             |                                                             |
| `TRIGGER_WORKER_INSTANCE_NAME`              | No       | random UUID | Worker instance name. Set to `spec.nodeName` on k8s.        |
| `TRIGGER_WORKER_HEARTBEAT_INTERVAL_SECONDS` | No       | 30          | Worker heartbeat interval (seconds).                        |
| **Workload API settings**                   |          |             |                                                             |
| `TRIGGER_WORKLOAD_API_ENABLED`              | No       | true        | Enable workload API. Runs use this to perform actions.      |
| `TRIGGER_WORKLOAD_API_PROTOCOL`             | No       | http        | Workload API protocol (http/https).                         |
| `TRIGGER_WORKLOAD_API_DOMAIN`               | No       | â€”           | Workload API domain. Keep empty for auto-detection.         |
| `TRIGGER_WORKLOAD_API_HOST_INTERNAL`        | No       | 0.0.0.0     | Workload API internal host.                                 |
| `TRIGGER_WORKLOAD_API_PORT_INTERNAL`        | No       | 8020        | Workload API internal port.                                 |
| `TRIGGER_WORKLOAD_API_PORT_EXTERNAL`        | No       | 8020        | Workload API external port.                                 |
| **Runner settings**                         |          |             |                                                             |
| `RUNNER_HEARTBEAT_INTERVAL_SECONDS`         | No       | â€”           | Runner heartbeat interval (seconds).                        |
| `RUNNER_SNAPSHOT_POLL_INTERVAL_SECONDS`     | No       | â€”           | Runner snapshot poll interval (seconds).                    |
| `RUNNER_ADDITIONAL_ENV_VARS`                | No       | â€”           | Additional runner env vars (CSV).                           |
| `RUNNER_PRETTY_LOGS`                        | No       | false       | Pretty logs for runner.                                     |
| **Dequeue settings**                        |          |             |                                                             |
| `TRIGGER_DEQUEUE_ENABLED`                   | No       | true        | Enable dequeue to pull runs from the queue.                 |
| `TRIGGER_DEQUEUE_INTERVAL_MS`               | No       | 250         | Dequeue interval (ms).                                      |
| `TRIGGER_DEQUEUE_IDLE_INTERVAL_MS`          | No       | 1000 (1s)   | Dequeue idle interval (ms).                                 |
| `TRIGGER_DEQUEUE_MAX_RUN_COUNT`             | No       | 10          | Max dequeue run count.                                      |
| `TRIGGER_DEQUEUE_MAX_CONSUMER_COUNT`        | No       | 1           | Max dequeue consumer count.                                 |
| **Docker settings**                         |          |             |                                                             |
| `DOCKER_API_VERSION`                        | No       | v1.41       | Docker API version. You should probably not touch this.     |
| `DOCKER_STRIP_IMAGE_DIGEST`                 | No       | true        | Strip image digest in Docker. Turning off can cause issues. |
| `DOCKER_ENFORCE_MACHINE_PRESETS`            | No       | true        | Enforce Docker machine cpu and memory limits.               |
| `DOCKER_AUTOREMOVE_EXITED_CONTAINERS`       | No       | true        | Auto-remove exited containers.                              |
| `DOCKER_RUNNER_NETWORKS`                    | No       | host        | Docker runner networks (CSV).                               |
| **Registry auth**                           |          |             |                                                             |
| `DOCKER_REGISTRY_URL`                       | No       | â€”           | Docker registry URL, e.g. `docker.io`.                      |
| `DOCKER_REGISTRY_USERNAME`                  | No       | â€”           | Docker registry username.                                   |
| `DOCKER_REGISTRY_PASSWORD`                  | No       | â€”           | Docker registry password.                                   |
| **Kubernetes settings**                     |          |             |                                                             |
| `KUBERNETES_FORCE_ENABLED`                  | No       | false       | Force Kubernetes mode.                                      |
| `KUBERNETES_NAMESPACE`                      | No       | default     | The namespace that runs should be in.                       |
| `KUBERNETES_WORKER_NODETYPE_LABEL`          | No       | v4-worker   | Nodes for runs need this label, e.g. `nodetype=v4-worker`.  |
| `KUBERNETES_IMAGE_PULL_SECRETS`             | No       | â€”           | Image pull secrets (CSV).                                   |
| `KUBERNETES_EPHEMERAL_STORAGE_SIZE_LIMIT`   | No       | 10Gi        | Ephemeral storage size limit. Applies to all runs.          |
| `KUBERNETES_EPHEMERAL_STORAGE_SIZE_REQUEST` | No       | 2Gi         | Ephemeral storage size request. Applies to all runs.        |
| **Metrics**                                 |          |             |                                                             |
| `METRICS_ENABLED`                           | No       | true        | Enable metrics.                                             |
| `METRICS_COLLECT_DEFAULTS`                  | No       | true        | Collect default metrics.                                    |
| `METRICS_HOST`                              | No       | 127.0.0.1   | Metrics host.                                               |
| `METRICS_PORT`                              | No       | 9090        | Metrics port.                                               |
| **Pod cleaner**                             |          |             |                                                             |
| `POD_CLEANER_ENABLED`                       | No       | true        | Enable pod cleaner.                                         |
| `POD_CLEANER_INTERVAL_MS`                   | No       | 10000 (10s) | Pod cleaner interval (ms). Best not to touch this.          |
| `POD_CLEANER_BATCH_SIZE`                    | No       | 500         | Pod cleaner batch size.                                     |
| **Failed pod handler**                      |          |             |                                                             |
| `FAILED_POD_HANDLER_ENABLED`                | No       | true        | Enable failed pod handler.                                  |
| `FAILED_POD_HANDLER_RECONNECT_INTERVAL_MS`  | No       | 1000 (1s)   | Failed pod handler reconnect interval (ms).                 |
| **Debug**                                   |          |             |                                                             |
| `DEBUG`                                     | No       | false       | Enable debug logs.                                          |
| `SEND_RUN_DEBUG_LOGS`                       | No       | false       | Send run debug logs to the platform.                        |
| **Not used for self-hosting**               |          |             |                                                             |
| `TRIGGER_WARM_START_URL`                    | No       | â€”           | Warm start URL.                                             |
| `TRIGGER_CHECKPOINT_URL`                    | No       | â€”           | Checkpoint URL.                                             |
| `TRIGGER_METADATA_URL`                      | No       | â€”           | Metadata URL.                                               |
| `RESOURCE_MONITOR_ENABLED`                  | No       | false       | Enable resource monitor.                                    |
| `RESOURCE_MONITOR_OVERRIDE_CPU_TOTAL`       | No       | â€”           | Override CPU total for resource monitor.                    |
| `RESOURCE_MONITOR_OVERRIDE_MEMORY_TOTAL_GB` | No       | â€”           | Override memory total (GB) for resource monitor.            |


# Webapp
Source: https://trigger.dev/docs/self-hosting/env/webapp

Environment variables for the webapp container.

| Name                                             | Required | Default                                        | Description                                                                                               |
| :----------------------------------------------- | :------- | :--------------------------------------------- | :-------------------------------------------------------------------------------------------------------- |
| **Secrets**                                      |          |                                                |                                                                                                           |
| `SESSION_SECRET`                                 | Yes      | â€”                                              | Session encryption secret. Run: `openssl rand -hex 16`                                                    |
| `MAGIC_LINK_SECRET`                              | Yes      | â€”                                              | Magic link encryption secret. Run: `openssl rand -hex 16`                                                 |
| `ENCRYPTION_KEY`                                 | Yes      | â€”                                              | Secret store encryption key. Run: `openssl rand -hex 16`                                                  |
| `MANAGED_WORKER_SECRET`                          | No       | managed-secret                                 | Managed worker secret. Should be changed and match supervisor.                                            |
| **Domains & ports**                              |          |                                                |                                                                                                           |
| `REMIX_APP_PORT`                                 | No       | 3030                                           | Remix app port.                                                                                           |
| `APP_ORIGIN`                                     | Yes      | [http://localhost:3030](http://localhost:3030) | App origin URL.                                                                                           |
| `LOGIN_ORIGIN`                                   | Yes      | [http://localhost:3030](http://localhost:3030) | Login origin URL. Most likely the same as `APP_ORIGIN`.                                                   |
| `API_ORIGIN`                                     | No       | `APP_ORIGIN`                                   | API origin URL.                                                                                           |
| `STREAM_ORIGIN`                                  | No       | `APP_ORIGIN`                                   | Realtime stream origin URL.                                                                               |
| `ELECTRIC_ORIGIN`                                | No       | [http://localhost:3060](http://localhost:3060) | Electric origin URL.                                                                                      |
| **Postgres**                                     |          |                                                |                                                                                                           |
| `DATABASE_URL`                                   | Yes      | â€”                                              | PostgreSQL connection string.                                                                             |
| `DIRECT_URL`                                     | Yes      | â€”                                              | Direct DB connection string used for migrations etc.                                                      |
| `DATABASE_CONNECTION_LIMIT`                      | No       | 10                                             | Max DB connections.                                                                                       |
| `DATABASE_POOL_TIMEOUT`                          | No       | 60                                             | DB pool timeout (s).                                                                                      |
| `DATABASE_CONNECTION_TIMEOUT`                    | No       | 20                                             | DB connect timeout (s).                                                                                   |
| `DATABASE_READ_REPLICA_URL`                      | No       | `DATABASE_URL`                                 | Read-replica DB string.                                                                                   |
| **Redis**                                        |          |                                                |                                                                                                           |
| `REDIS_HOST`                                     | Yes      | â€”                                              | Redis host.                                                                                               |
| `REDIS_PORT`                                     | Yes      | â€”                                              | Redis port.                                                                                               |
| `REDIS_READER_HOST`                              | No       | `REDIS_HOST`                                   | Redis reader host.                                                                                        |
| `REDIS_READER_PORT`                              | No       | `REDIS_PORT`                                   | Redis reader port.                                                                                        |
| `REDIS_USERNAME`                                 | No       | â€”                                              | Redis username.                                                                                           |
| `REDIS_PASSWORD`                                 | No       | â€”                                              | Redis password.                                                                                           |
| `REDIS_TLS_DISABLED`                             | No       | â€”                                              | Disable Redis TLS.                                                                                        |
| **Auth**                                         |          |                                                |                                                                                                           |
| `WHITELISTED_EMAILS`                             | No       | â€”                                              | Whitelisted emails regex.                                                                                 |
| `AUTH_GITHUB_CLIENT_ID`                          | No       | â€”                                              | GitHub client ID.                                                                                         |
| `AUTH_GITHUB_CLIENT_SECRET`                      | No       | â€”                                              | GitHub client secret.                                                                                     |
| **Email**                                        |          |                                                |                                                                                                           |
| `EMAIL_TRANSPORT`                                | No       | â€”                                              | Email transport type. One of `resend`, `smtp`, `aws-ses`.                                                 |
| `FROM_EMAIL`                                     | No       | â€”                                              | From email address.                                                                                       |
| `REPLY_TO_EMAIL`                                 | No       | â€”                                              | Reply-to email address.                                                                                   |
| `RESEND_API_KEY`                                 | No       | â€”                                              | Resend API key.                                                                                           |
| `SMTP_HOST`                                      | No       | â€”                                              | SMTP host.                                                                                                |
| `SMTP_PORT`                                      | No       | â€”                                              | SMTP port.                                                                                                |
| `SMTP_SECURE`                                    | No       | â€”                                              | SMTP secure flag.                                                                                         |
| `SMTP_USER`                                      | No       | â€”                                              | SMTP user.                                                                                                |
| `SMTP_PASSWORD`                                  | No       | â€”                                              | SMTP password.                                                                                            |
| `AWS_REGION`                                     | No       | â€”                                              | AWS region for SES.                                                                                       |
| `AWS_ACCESS_KEY_ID`                              | No       | â€”                                              | AWS access key ID for SES.                                                                                |
| `AWS_SECRET_ACCESS_KEY`                          | No       | â€”                                              | AWS secret access key for SES.                                                                            |
| **Graphile & Redis worker**                      |          |                                                |                                                                                                           |
| `WORKER_CONCURRENCY`                             | No       | 10                                             | Redis worker concurrency.                                                                                 |
| `WORKER_POLL_INTERVAL`                           | No       | 1000                                           | Redis worker poll interval (ms).                                                                          |
| `WORKER_SCHEMA`                                  | No       | graphile\_worker                               | Graphile worker schema.                                                                                   |
| `GRACEFUL_SHUTDOWN_TIMEOUT`                      | No       | 60000 (1m)                                     | Graphile graceful shutdown timeout (ms). Affects shutdown time.                                           |
| **Concurrency limits**                           |          |                                                |                                                                                                           |
| `DEFAULT_ENV_EXECUTION_CONCURRENCY_LIMIT`        | No       | 100                                            | Default env execution concurrency.                                                                        |
| `DEFAULT_ORG_EXECUTION_CONCURRENCY_LIMIT`        | No       | 300                                            | Default org execution concurrency, needs to be 3x env concurrency.                                        |
| **Dev**                                          |          |                                                |                                                                                                           |
| `DEV_MAX_CONCURRENT_RUNS`                        | No       | 25                                             | Sets the max concurrency for dev runs via the CLI.                                                        |
| `DEV_OTEL_EXPORTER_OTLP_ENDPOINT`                | No       | `APP_ORIGIN/otel`                              | OTel endpoint for dev runs.                                                                               |
| **Rate limiting**                                |          |                                                |                                                                                                           |
| `API_RATE_LIMIT_REFILL_INTERVAL`                 | No       | 10s                                            | API rate limit refill interval.                                                                           |
| `API_RATE_LIMIT_MAX`                             | No       | 750                                            | API rate limit max.                                                                                       |
| `API_RATE_LIMIT_REFILL_RATE`                     | No       | 250                                            | API rate limit refill rate.                                                                               |
| `API_RATE_LIMIT_REQUEST_LOGS_ENABLED`            | No       | 0                                              | API rate limit request logs.                                                                              |
| `API_RATE_LIMIT_REJECTION_LOGS_ENABLED`          | No       | 1                                              | API rate limit rejection logs.                                                                            |
| `API_RATE_LIMIT_LIMITER_LOGS_ENABLED`            | No       | 0                                              | API rate limit limiter logs.                                                                              |
| `API_RATE_LIMIT_JWT_WINDOW`                      | No       | 1m                                             | API rate limit JWT window.                                                                                |
| `API_RATE_LIMIT_JWT_TOKENS`                      | No       | 60                                             | API rate limit JWT tokens.                                                                                |
| **Deploy & Registry**                            |          |                                                |                                                                                                           |
| `DEPLOY_REGISTRY_HOST`                           | Yes      | â€”                                              | Deploy registry host.                                                                                     |
| `DEPLOY_REGISTRY_USERNAME`                       | No       | â€”                                              | Deploy registry username.                                                                                 |
| `DEPLOY_REGISTRY_PASSWORD`                       | No       | â€”                                              | Deploy registry password.                                                                                 |
| `DEPLOY_REGISTRY_NAMESPACE`                      | No       | trigger                                        | Deploy registry namespace.                                                                                |
| `DEPLOY_IMAGE_PLATFORM`                          | No       | linux/amd64                                    | Deploy image platform, same values as docker `--platform` flag.                                           |
| `DEPLOY_TIMEOUT_MS`                              | No       | 480000 (8m)                                    | Deploy timeout (ms).                                                                                      |
| **Object store (S3)**                            |          |                                                |                                                                                                           |
| `OBJECT_STORE_BASE_URL`                          | No       | â€”                                              | Object store base URL.                                                                                    |
| `OBJECT_STORE_ACCESS_KEY_ID`                     | No       | â€”                                              | Object store access key.                                                                                  |
| `OBJECT_STORE_SECRET_ACCESS_KEY`                 | No       | â€”                                              | Object store secret key.                                                                                  |
| `OBJECT_STORE_REGION`                            | No       | â€”                                              | Object store region.                                                                                      |
| `OBJECT_STORE_SERVICE`                           | No       | s3                                             | Object store service.                                                                                     |
| **Alerts**                                       |          |                                                |                                                                                                           |
| `ORG_SLACK_INTEGRATION_CLIENT_ID`                | No       | â€”                                              | Slack client ID. Required for Slack alerts.                                                               |
| `ORG_SLACK_INTEGRATION_CLIENT_SECRET`            | No       | â€”                                              | Slack client secret. Required for Slack alerts.                                                           |
| `ALERT_EMAIL_TRANSPORT`                          | No       | â€”                                              | Alert email transport.                                                                                    |
| `ALERT_FROM_EMAIL`                               | No       | â€”                                              | Alert from email.                                                                                         |
| `ALERT_REPLY_TO_EMAIL`                           | No       | â€”                                              | Alert reply-to email.                                                                                     |
| `ALERT_RESEND_API_KEY`                           | No       | â€”                                              | Alert Resend API key.                                                                                     |
| `ALERT_SMTP_HOST`                                | No       | â€”                                              | Alert SMTP host.                                                                                          |
| `ALERT_SMTP_PORT`                                | No       | â€”                                              | Alert SMTP port.                                                                                          |
| `ALERT_SMTP_SECURE`                              | No       | â€”                                              | Alert SMTP secure.                                                                                        |
| `ALERT_SMTP_USER`                                | No       | â€”                                              | Alert SMTP user.                                                                                          |
| `ALERT_SMTP_PASSWORD`                            | No       | â€”                                              | Alert SMTP password.                                                                                      |
| **Limits**                                       |          |                                                |                                                                                                           |
| `TASK_PAYLOAD_OFFLOAD_THRESHOLD`                 | No       | 524288 (512KB)                                 | Max task payload size before offloading to S3.                                                            |
| `TASK_PAYLOAD_MAXIMUM_SIZE`                      | No       | 3145728 (3MB)                                  | Max task payload size.                                                                                    |
| `BATCH_TASK_PAYLOAD_MAXIMUM_SIZE`                | No       | 1000000 (1MB)                                  | Max batch payload size.                                                                                   |
| `TASK_RUN_METADATA_MAXIMUM_SIZE`                 | No       | 262144 (256KB)                                 | Max metadata size.                                                                                        |
| `MAX_BATCH_V2_TRIGGER_ITEMS`                     | No       | 500                                            | Max batch size.                                                                                           |
| `MAXIMUM_DEV_QUEUE_SIZE`                         | No       | â€”                                              | Max dev queue size.                                                                                       |
| `MAXIMUM_DEPLOYED_QUEUE_SIZE`                    | No       | â€”                                              | Max deployed queue size.                                                                                  |
| **OTel limits**                                  |          |                                                |                                                                                                           |
| `TRIGGER_OTEL_SPAN_ATTRIBUTE_COUNT_LIMIT`        | No       | 1024                                           | OTel span attribute count limit.                                                                          |
| `TRIGGER_OTEL_LOG_ATTRIBUTE_COUNT_LIMIT`         | No       | 1024                                           | OTel log attribute count limit.                                                                           |
| `TRIGGER_OTEL_SPAN_ATTRIBUTE_VALUE_LENGTH_LIMIT` | No       | 131072                                         | OTel span attribute value length limit.                                                                   |
| `TRIGGER_OTEL_LOG_ATTRIBUTE_VALUE_LENGTH_LIMIT`  | No       | 131072                                         | OTel log attribute value length limit.                                                                    |
| `TRIGGER_OTEL_SPAN_EVENT_COUNT_LIMIT`            | No       | 10                                             | OTel span event count limit.                                                                              |
| `TRIGGER_OTEL_LINK_COUNT_LIMIT`                  | No       | 2                                              | OTel link count limit.                                                                                    |
| `TRIGGER_OTEL_ATTRIBUTE_PER_LINK_COUNT_LIMIT`    | No       | 10                                             | OTel attribute per link count limit.                                                                      |
| `TRIGGER_OTEL_ATTRIBUTE_PER_EVENT_COUNT_LIMIT`   | No       | 10                                             | OTel attribute per event count limit.                                                                     |
| `SERVER_OTEL_SPAN_ATTRIBUTE_VALUE_LENGTH_LIMIT`  | No       | 8192                                           | OTel span attribute value length limit.                                                                   |
| **Realtime**                                     |          |                                                |                                                                                                           |
| `REALTIME_STREAM_MAX_LENGTH`                     | No       | 1000                                           | Realtime stream max length.                                                                               |
| `REALTIME_STREAM_TTL`                            | No       | 86400 (1d)                                     | Realtime stream TTL (s).                                                                                  |
| **Bootstrap**                                    |          |                                                |                                                                                                           |
| `TRIGGER_BOOTSTRAP_ENABLED`                      | No       | 0                                              | Trigger bootstrap enabled.                                                                                |
| `TRIGGER_BOOTSTRAP_WORKER_GROUP_NAME`            | No       | â€”                                              | Trigger bootstrap worker group name.                                                                      |
| `TRIGGER_BOOTSTRAP_WORKER_TOKEN_PATH`            | No       | â€”                                              | Trigger bootstrap worker token path.                                                                      |
| **Run engine**                                   |          |                                                |                                                                                                           |
| `RUN_ENGINE_WORKER_COUNT`                        | No       | 4                                              | Run engine worker count.                                                                                  |
| `RUN_ENGINE_TASKS_PER_WORKER`                    | No       | 10                                             | Run engine tasks per worker.                                                                              |
| `RUN_ENGINE_WORKER_CONCURRENCY_LIMIT`            | No       | 10                                             | Run engine worker concurrency limit.                                                                      |
| `RUN_ENGINE_WORKER_POLL_INTERVAL`                | No       | 100                                            | Run engine worker poll interval (ms).                                                                     |
| `RUN_ENGINE_WORKER_IMMEDIATE_POLL_INTERVAL`      | No       | 100                                            | Run engine worker immediate poll interval (ms).                                                           |
| `RUN_ENGINE_WORKER_SHUTDOWN_TIMEOUT_MS`          | No       | 60000 (1m)                                     | Run engine worker shutdown timeout (ms).                                                                  |
| `RUN_ENGINE_RATE_LIMIT_REFILL_INTERVAL`          | No       | 10s                                            | Run engine rate limit refill interval.                                                                    |
| `RUN_ENGINE_RATE_LIMIT_MAX`                      | No       | 1200                                           | Run engine rate limit max.                                                                                |
| `RUN_ENGINE_RATE_LIMIT_REFILL_RATE`              | No       | 400                                            | Run engine rate limit refill rate.                                                                        |
| `RUN_ENGINE_RATE_LIMIT_REQUEST_LOGS_ENABLED`     | No       | 0                                              | Run engine rate limit request logs.                                                                       |
| `RUN_ENGINE_RATE_LIMIT_REJECTION_LOGS_ENABLED`   | No       | 1                                              | Run engine rate limit rejection logs.                                                                     |
| `RUN_ENGINE_RATE_LIMIT_LIMITER_LOGS_ENABLED`     | No       | 0                                              | Run engine rate limit limiter logs.                                                                       |
| **Misc**                                         |          |                                                |                                                                                                           |
| `TRIGGER_TELEMETRY_DISABLED`                     | No       | â€”                                              | Disable telemetry.                                                                                        |
| `NODE_MAX_OLD_SPACE_SIZE`                        | No       | 8192                                           | Maximum memory allocation for Node.js heap in MiB (e.g. "4096" for 4GB).                                  |
| `OPENAI_API_KEY`                                 | No       | â€”                                              | OpenAI API key.                                                                                           |
| `MACHINE_PRESETS_OVERRIDE_PATH`                  | No       | â€”                                              | Path to machine presets override file. See [machine overrides](/self-hosting/overview#machine-overrides). |
| `APP_ENV`                                        | No       | `NODE_ENV`                                     | App environment. Used for things like the title tag.                                                      |
| `ADMIN_EMAILS`                                   | No       | â€”                                              | Regex of user emails to automatically promote to admin.                                                   |
| `EVENT_LOOP_MONITOR_ENABLED`                     | No       | 1                                              | Node.js event loop lag monitor.                                                                           |


# Kubernetes
Source: https://trigger.dev/docs/self-hosting/kubernetes

You can self-host Trigger.dev in Kubernetes using our official Helm chart.

The following instructions will help you deploy Trigger.dev to Kubernetes using our official Helm chart. Make sure to read the self-hosting [overview](/self-hosting/overview) first.

As self-hosted deployments tend to have unique requirements and configurations, we don't provide specific advice for securing your deployment, scaling up, or improving reliability.

Should the burden ever get too much, we'd be happy to see you on [Trigger.dev cloud](https://trigger.dev/pricing) where we deal with these concerns for you.

**Warning:** This guide alone is unlikely to result in a production-ready deployment. Security, scaling, and reliability concerns are not fully addressed here.

## Requirements

### Prerequisites

* Kubernetes cluster 1.19+
* Helm 3.8+
* Kubectl with cluster access

### Resources

The following are minimum requirements for running the entire stack on Kubernetes:

**Cluster resources:**

* 6+ vCPU total
* 12+ GB RAM total
* Persistent volume support

**Individual components:**

* **Webapp**: 1 vCPU, 2 GB RAM
* **Supervisor**: 1 vCPU, 1 GB RAM
* **PostgreSQL**: 1 vCPU, 2 GB RAM
* **Redis**: 0.5 vCPU, 1 GB RAM
* **ClickHouse**: 1 vCPU, 2 GB RAM
* **Object Storage**: 0.5 vCPU, 1 GB RAM
* **Workers**: Depending on concurrency and machine preset

These requirements scale based on your task concurrency and can be adjusted via the `resources` section in your `values.yaml`. For example:

```yaml  theme={null}
webapp:
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi
```

## Installation

### Quick start

1. Install with default values (for testing only):

```bash  theme={null}
helm upgrade -n trigger --install trigger \
  oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "~4.0.0-beta" \
  --create-namespace
```

2. Access the webapp:

```bash  theme={null}
kubectl port-forward svc/trigger-webapp 3040:3030 -n trigger
```

3. Open the dashboard: `http://localhost:3040`

4. Login with the magic link:

```bash  theme={null}
# Check the webapp logs
kubectl logs -n trigger deployment/trigger-webapp | grep -A1 "magic link"
```

## Configuration

Most values map directly to the environment variables documented in the [webapp](/self-hosting/env/webapp) and [supervisor](/self-hosting/env/supervisor) environment variable overview.

**Naming convention:**

* Environment variables use `UPPER_SNAKE_CASE`
* Helm values use `camelCase`

**Example mapping:**

```bash  theme={null}
# Environment variable
APP_ORIGIN=https://trigger.example.com

# Becomes Helm value
config:
  appOrigin: "https://trigger.example.com"
```

### Default values

The following commands will display the default values:

```bash  theme={null}
# Specific version
helm show values oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "4.0.0-beta.5"

# Latest v4 beta
helm show values oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "~4.0.0-beta"
```

### Custom values

The default values are insecure and are only suitable for testing. You will need to configure your own secrets as a bare minimum.

Create a `values-custom.yaml` file to override the defaults. For example:

```yaml  theme={null}
# Generate new secrets with `openssl rand -hex 16`
# WARNING: You should probably use an existingSecret instead
secrets:
  enabled: true
  sessionSecret: "your-32-char-hex-secret-1"
  magicLinkSecret: "your-32-char-hex-secret-2"
  # ...

# Recommended: existingSecret, must contain at least the following keys:
# - SESSION_SECRET
# - MAGIC_LINK_SECRET
# - ENCRYPTION_KEY
# - MANAGED_WORKER_SECRET
# - OBJECT_STORE_ACCESS_KEY_ID
# - OBJECT_STORE_SECRET_ACCESS_KEY
secrets:
  enabled: false
  existingSecret: "your-existing-secret"

# Application URLs
config:
  appOrigin: "https://trigger.example.com"
  loginOrigin: "https://trigger.example.com"
  apiOrigin: "https://trigger.example.com"

# Resource limits
webapp:
  resources:
    requests:
      cpu: 1000m
      memory: 2Gi
    limits:
      cpu: 2000m
      memory: 4Gi

supervisor:
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi
```

Deploy with your custom values:

```bash  theme={null}
helm upgrade -n trigger --install trigger \
  oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "~4.0.0-beta" \
  --create-namespace \
  -f values-custom.yaml
```

### Extra env

You can set extra environment variables on all services. For example:

```yaml  theme={null}
webapp:
  extraEnvVars:
    - name: EXTRA_ENV_VAR
      value: "extra-value"
```

### Extra annotations

You can set extra annotations on all services. For example:

```yaml  theme={null}
webapp:
  podAnnotations:
    "my-annotation": "my-value"
```

### External services

You can disable the built-in services and use external services instead. The chart supports both direct configuration and existing Kubernetes secrets for secure credential management.

#### PostgreSQL

**Direct configuration:**

```yaml  theme={null}
postgres:
  deploy: false
  external:
    databaseUrl: "postgresql://user:password@host:5432/database?schema=public"
    directUrl: "" # Optional, defaults to databaseUrl
```

**Using existing secrets (recommended):**

```yaml  theme={null}
postgres:
  deploy: false
  external:
    existingSecret: "postgres-credentials"
    # Optional: Use secretKeys to specify the key names in the secret
    # secretKeys:
    #   databaseUrlKey: "postgres-database-url" # default
    #   directUrlKey: "postgres-direct-url"     # default
```

#### Redis

**Direct configuration:**

```yaml  theme={null}
redis:
  deploy: false
  external:
    host: "my-redis.example.com"
    port: 6379
    password: "my-password"
    tls:
      enabled: true
```

**Using existing secrets (recommended):**

```yaml  theme={null}
redis:
  deploy: false
  external:
    host: "my-redis.example.com"
    port: 6379
    existingSecret: "redis-credentials"
    # existingSecretPasswordKey: "redis-password" # default (optional)
    tls:
      enabled: true
```

#### ClickHouse

**Direct configuration:**

```yaml  theme={null}
clickhouse:
  deploy: false
  external:
    host: "my-clickhouse.example.com"
    port: 8123
    username: "my-username"
    password: "my-password"
```

**Using existing secrets (recommended):**

```yaml  theme={null}
clickhouse:
  deploy: false
  external:
    host: "my-clickhouse.example.com"
    port: 8123
    username: "my-username"
    existingSecret: "clickhouse-credentials"
    # existingSecretKey: "clickhouse-password" # default (optional)
```

#### S3 Object Storage

**Direct configuration:**

```yaml  theme={null}
minio:
  deploy: false
s3:
  external:
    endpoint: "https://s3.amazonaws.com"
    accessKeyId: "my-access-key"
    secretAccessKey: "my-secret-key"
```

**Using existing secrets (recommended):**

```yaml  theme={null}
minio:
  deploy: false
s3:
  external:
    endpoint: "https://s3.amazonaws.com"
    existingSecret: "s3-credentials"
    # Optional: Use secretKeys to specify the key names in the secret
    # secretKeys:
    #   accessKeyIdKey: "access-key-id"     # default
    #   secretAccessKeyKey: "secret-access-key" # default
```

### PostgreSQL SSL with custom CA certificates

When connecting to PostgreSQL instances that require custom CA certificates (such as AWS RDS with SSL verification), you can mount the CA certificate as a volume and configure the webapp to use it:

```yaml  theme={null}
postgres:
  deploy: false
  external:
    databaseUrl: "postgresql://user:password@mydb.example.com:5432/triggerdb?schema=public&sslmode=require"
    # Alternatively, use an existing secret
    existingSecret: "postgres-credentials"
    # secretKeys:
    #   databaseUrlKey: "postgres-database-url" # default
  connection:
    sslMode: "require"

# Webapp configuration with SSL CA certificate
webapp:
  extraEnvVars:
    - name: NODE_EXTRA_CA_CERTS
      value: "/etc/ssl/certs/postgres-ca.crt"

  extraVolumes:
    - name: postgres-ca-cert
      secret:
        secretName: postgres-ca-secret
        items:
          - key: ca.crt
            path: postgres-ca.crt

  extraVolumeMounts:
    - name: postgres-ca-cert
      mountPath: /etc/ssl/certs
      readOnly: true
```

**Benefits:**

* No plaintext credentials in `values.yaml` or Helm releases
* Complete `DATABASE_URL` stored securely in Kubernetes secrets
* Compatible with secret management tools (External Secrets Operator, etc.)
* Follows Kubernetes security best practices

## Worker token

When using the default bootstrap configuration, worker creation and authentication is handled automatically. The webapp generates a worker token and makes it available to the supervisor via a shared volume.

### Bootstrap (default)

```yaml  theme={null}
webapp:
  bootstrap:
    enabled: true
    workerGroupName: "bootstrap"
```

### Manual

If you need to set up workers separately or use a custom token:

1. Get the worker token from the webapp logs:

```bash  theme={null}
kubectl logs deployment/trigger-webapp -n trigger | grep -A15 "Worker Token"
```

2. Create a secret with the token:

```bash  theme={null}
kubectl create secret generic worker-token \
  --from-literal=token=tr_wgt_your_token_here \
  -n trigger
```

3. Configure the supervisor to use the secret:

```yaml  theme={null}
supervisor:
  bootstrap:
    enabled: false
    workerToken:
      secret:
        name: "worker-token"
        key: "token"
```

## Registry setup

See the [Docker registry setup](/self-hosting/docker#registry-setup) for conceptual information. The configuration is specified in your `values.yaml`:

```yaml  theme={null}
# Use external registry (recommended)
registry:
  deploy: false
  # Part of deployment image ref, for example: your-registry.example.com/your-company/proj_123:20250625.1.prod
  repositoryNamespace: "your-company"
  external:
    host: "your-registry.example.com"
    port: 5000
    auth:
      enabled: true
      username: "your-username"
      password: "your-password"
```

<Note>
  The internal registry (`registry.external: false`) is experimental and requires proper TLS setup
  and additional cluster configuration. Use an external registry for production.
</Note>

## Object storage

See the [Docker object storage setup](/self-hosting/docker#object-storage) for conceptual information. The defaults will use built-in MinIO, but you can use an external S3-compatible storage. The configuration is specified in your `values.yaml`:

```yaml  theme={null}
# Use external S3-compatible storage
minio:
  deploy: false
  external:
    url: "https://s3.amazonaws.com"
    # or: "https://your-minio.com:9000"

# Configure credentials
secrets:
  objectStore:
    accessKeyId: "admin"
    secretAccessKey: "very-safe-password"
```

## Authentication

Authentication options are identical to the [Docker-based installation](/self-hosting/docker#authentication). The configuration is specified in your `values.yaml`:

**GitHub OAuth:**

```yaml  theme={null}
webapp:
  extraEnvVars:
    - name: AUTH_GITHUB_CLIENT_ID
      value: "your-github-client-id"
    - name: AUTH_GITHUB_CLIENT_SECRET
      value: "your-github-client-secret"
```

**Email authentication (Resend):**

```yaml  theme={null}
webapp:
  extraEnvVars:
    - name: EMAIL_TRANSPORT
      value: "resend"
    - name: FROM_EMAIL
      value: "noreply@yourdomain.com"
    - name: REPLY_TO_EMAIL
      value: "support@yourdomain.com"
    - name: RESEND_API_KEY
      value: "your-resend-api-key"
```

**Restricting access:**

```yaml  theme={null}
webapp:
  extraEnvVars:
    - name: WHITELISTED_EMAILS
      value: "user1@company\\.com|user2@company\\.com"
```

## Version locking

You can lock versions in two ways:

**Helm chart version (recommended):**

```bash  theme={null}
# Pin to a specific version for production
helm upgrade -n trigger --install trigger \
  oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "4.0.0-beta.5"

# The app version will be different from the chart version
# This is the version of the Trigger.dev webapp and supervisor
# ..and should always match your Trigger.dev CLI version
helm show chart \
  oci://ghcr.io/triggerdotdev/charts/trigger \
  --version "4.0.0-beta.5" | grep appVersion
```

**Specific image tags:**

```yaml  theme={null}
webapp:
  image:
    tag: "v4.0.0"

supervisor:
  image:
    tag: "v4.0.0"
```

The chart version's `appVersion` field determines the default image tags. Newer image tags may be incompatible with older chart versions and vice versa.

## Troubleshooting

**Check logs:**

```bash  theme={null}
# Webapp logs
kubectl logs deployment/trigger-webapp -n trigger -f

# Supervisor logs
kubectl logs deployment/trigger-supervisor -n trigger -f

# All pods
kubectl logs -l app.kubernetes.io/instance=trigger -n trigger -f
```

**Check pod status:**

```bash  theme={null}
kubectl get pods -n trigger
kubectl describe pod <pod-name> -n trigger
```

**Start from scratch:**

```bash  theme={null}
# Delete the release
helm uninstall trigger -n trigger

# Delete persistent volumes (optional)
# WARNING: This will delete all your data!
kubectl delete pvc -l app.kubernetes.io/instance=trigger -n trigger

# Delete the namespace (optional)
kubectl delete namespace trigger
```

**Common issues:**

* **Magic links not working**: Check webapp logs for email delivery errors
* **Deploy fails**: Verify registry access and authentication
* **Pods stuck pending**: Describe the pod and check the events
* **Worker token issues**: Check webapp and supervisor logs for errors

See the [Docker troubleshooting](/self-hosting/docker#troubleshooting) section for more information.

## CLI usage

See the [Docker CLI usage](/self-hosting/docker#cli-usage) section, the commands are identical regardless of deployment method.

## CI / GitHub Actions

When running the CLI in a CI environment, your login profiles won't be available. Instead, you can use the `TRIGGER_API_URL` and `TRIGGER_ACCESS_TOKEN` environment
variables to point at your self-hosted instance and authenticate.

For more detailed instructions, see the [GitHub Actions guide](/github-actions).

## Telemetry

By default, the Trigger.dev webapp sends telemetry data to our servers. This data is used to improve the product and is not shared with third parties. To disable telemetry, set in your `values.yaml`:

```yaml  theme={null}
telemetry:
  enabled: false
```


# Overview
Source: https://trigger.dev/docs/self-hosting/overview

You can self-host Trigger.dev on your own infrastructure.

Self-hosting Trigger.dev means you run and manage the platform on your own infrastructure, giving you full control over your environment, deployment process, and the URLs you expose the service on.

You are responsible for provisioning resources, handling updates, and managing any security, scaling or reliability challenges that arise.

We provide version-tagged releases for self-hosted deployments. It's highly advised to use these tags exclusively and keep them locked with your CLI version.

## Should you self-host?

Trigger.dev Cloud is fully managed, scalable, and comes with dedicated support. For most users, it offers the best experience. However, if you have specific requirements around data residency, compliance, or infrastructure control, self-hosting may be the right choice for you.

The self-hosted version is functionally the same as Trigger.dev Cloud with [some exceptions](#feature-comparison), but our managed Cloud infrastructure is designed for high availability, security, and scale.

Because we don't manage self-hosted instances, we cannot guarantee how Trigger.dev will perform on your infrastructure. You assume all responsibility and risk for your deployment, including security, uptime, and data integrity.

For more details, carry on reading and follow our guides for instructions on setting up a self-hosted Trigger.dev instance. If you prefer a managed experience, you can [sign up](https://cloud.trigger.dev/login) for our Cloud offering instead - we have a generous [free tier](https://trigger.dev/pricing) for you to try it out.

## Architecture

The self-hosted version is a set of containers running on your own infrastructure. It's split into two parts that can be scaled independently:

* **Webapp**: includes the dashboard and other services like Redis and Postgres.
* **Worker**: includes the supervisor and the runners that execute your tasks.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=360a56141f8d28bc92c8e1a490771b05" alt="Self-hosting architecture" data-og-width="1444" width="1444" data-og-height="755" height="755" data-path="self-hosting/architecture.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=fac12c9c72c410958e51076185299a9d 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=56f369633a4108ebf60faa6a76db6802 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e6900b0544d65e7f3ef3a2c14cfdf36f 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3b063474bdaed77fbb1c8b56295ca6ed 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d25f4fae5e8acdd8899a849d2ec6036d 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/self-hosting/architecture.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ab59087b3ca60ad307e63882dba44756 2500w" />

## Feature comparison

While [limits](#limits) are generally configurable when self-hosting, some features are only available on Trigger.dev Cloud:

| Feature           | Cloud | Self-hosted | Description                             |
| :---------------- | :---- | :---------- | :-------------------------------------- |
| Warm starts       | âœ…     | âŒ           | Faster startups for consecutive runs    |
| Auto-scaling      | âœ…     | âŒ           | No need for manual worker node scaling  |
| Checkpoints       | âœ…     | âŒ           | Non-blocking waits, less resource usage |
| Dedicated support | âœ…     | âŒ           | Direct access to our support team       |
| Community support | âœ…     | âœ…           | Access to our Discord community         |
| ARM support       | âœ…     | âœ…           | ARM-based deployments                   |

## Limits

Most of the [limits](/limits) are configurable when self-hosting, with some hardcoded exceptions. You can configure them via environment variables on the [webapp](/self-hosting/env/webapp) container.

| Limit             | Configurable | Hardcoded value |
| :---------------- | :----------- | :-------------- |
| Concurrency       | âœ…            | â€”               |
| Rate limits       | âœ…            | â€”               |
| Queued tasks      | âœ…            | â€”               |
| Task payloads     | âœ…            | â€”               |
| Batch payloads    | âœ…            | â€”               |
| Task outputs      | âœ…            | â€”               |
| Batch size        | âœ…            | â€”               |
| Log size          | âœ…            | â€”               |
| Machines          | âœ…            | â€”               |
| OTel limits       | âœ…            | â€”               |
| Log retention     | â€”            | Never deleted   |
| I/O packet length | âŒ            | 128KB           |
| Alerts            | âŒ            | 100M            |
| Schedules         | âŒ            | 100M            |
| Team members      | âŒ            | 100M            |
| Preview branches  | âŒ            | 100M            |

### Machine overrides

You can override the machine type for a task by setting the `MACHINE_PRESETS_OVERRIDE_PATH` environment variable to a JSON file with the following structure.

```json  theme={null}
{
  "defaultMachine": "small-1x",
  "machines": {
    "micro": { "cpu": 0.25, "memory": 0.25 },
    "small-1x": { "cpu": 0.5, "memory": 0.5 },
    "small-2x": { "cpu": 1, "memory": 1 }
    // ...etc
  }
}
```

All fields are optional. Partial overrides are supported:

```json  theme={null}
{
  "defaultMachine": "small-2x",
  "machines": {
    "small-1x": { "memory": 2 }
  }
}
```

## Community support

It's dangerous to go alone! Join the self-hosting channel on our [Discord server](https://discord.gg/NQTxt5NA7s).

## Next steps

<CardGroup>
  <Card title="Docker compose" color="#2496ED" icon="docker" href="/self-hosting/docker">
    Learn how to self-host Trigger.dev with Docker compose.
  </Card>

  <Card title="Kubernetes" color="#326CE5" icon="dharmachakra" href="/self-hosting/kubernetes">
    Learn how to self-host Trigger.dev with Kubernetes.
  </Card>
</CardGroup>


# Tags
Source: https://trigger.dev/docs/tags

Tags allow you to easily filter runs in the dashboard and when using the SDK.

## What are tags?

We support up to 10 tags per run. Each one must be a string between 1 and 128 characters long.

We recommend prefixing your tags with their type and then an underscore or colon. For example, `user_123456` or `video:123`.

<Info>
  Many great APIs, like Stripe, already prefix their IDs with the type and an underscore. Like
  `cus_123456` for a customer.
</Info>

We don't enforce prefixes but if you use them you'll find it easier to filter and it will be clearer what the tag represents.

## How to add tags

There are two ways to add tags to a run:

1. When triggering the run.
2. Inside the `run` function, using `tags.add()`.

### 1. Adding tags when triggering the run

You can add tags when triggering a run using the `tags` option. All the different [trigger](/triggering) methods support this.

<CodeGroup>
  ```ts trigger theme={null}
  const handle = await myTask.trigger(
    { message: "hello world" },
    { tags: ["user_123456", "org_abcdefg"] }
  );
  ```

  ```ts batchTrigger theme={null}
  const batch = await myTask.batchTrigger([
    {
      payload: { message: "foo" },
      options: { tags: "product_123456" },
    },
    {
      payload: { message: "bar" },
      options: { tags: ["user_123456", "product_3456789"] },
    },
  ]);
  ```
</CodeGroup>

This will create a run with the tags `user_123456` and `org_abcdefg`. They look like this in the runs table:

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=95300055e21df2ac777716ee826b14a2" alt="How tags appear in the dashboard" data-og-width="500" width="500" data-og-height="213" height="213" data-path="images/tags-org-user.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4ee5ab06962f5838750401973f4b7fd4 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=934bb9dbccef3a395b8fc2b67b6bb627 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=b9f05a20db53d7f1ac1528fd24691440 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=aa50ecbbe7a15241f30cbcfc46a86fca 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=05e1b709d6f044b5fdd41060fc6429a6 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-org-user.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=a1103011e76a5348c37d7ad32d38b4f1 2500w" />

### 2. Adding tags inside the `run` function

Use the `tags.add()` function to add tags to a run from inside the `run` function. This will add the tag `product_1234567` to the run:

```ts  theme={null}
import { task, tags } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload: { message: string }, { ctx }) => {
    // Get the tags from when the run was triggered using the context
    // This is not updated if you add tags during the run
    logger.log("Tags from the run context", { tags: ctx.run.tags });

    // Add tags during the run (a single string or array of strings)
    await tags.add("product_1234567");
  },
});
```

Reminder: you can only have up to 10 tags per run. If you call `tags.add()` and the total number of tags will be more than 10 we log an error and ignore the new tags. That includes tags from triggering and from inside the run function.

### Propagating tags to child runs

Tags do not propagate to child runs automatically. By default runs have no tags and you have to set them explicitly.

It's easy to propagate tags if you want:

```ts  theme={null}
export const myTask = task({
  id: "my-task",
  run: async (payload: Payload, { ctx }) => {
    // Pass the tags from ctx into the child run
    const { id } = await otherTask.trigger(
      { message: "triggered from myTask" },
      { tags: ctx.run.tags }
    );
  },
});
```

## Filtering runs by tags

You can filter runs by tags in the dashboard and in the SDK.

### In the dashboard

On the Runs page open the filter menu, choose "Tags" and then start typing in the name of the tag you want to filter by. You can select it and it will restrict the results to only runs with that tag. You can add multiple tags to filter by more than one.

<img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=100b923c8d382ca830344a29cccd30ae" alt="Filter by tags" data-og-width="3162" width="3162" data-og-height="1874" height="1874" data-path="images/tags-filtering.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=cf5c3088aa5f5d500830a95352e2a613 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=5ad94f3537cf19214750398d8da82761 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=31f469bf812eeb4fe3e4255db8159702 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=bbb2f501b0fde07252bbc1756251cf18 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f56770191e9f191911d61a041b052413 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/tags-filtering.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ac42f439de4fb4d28c09e68185c21f8b 2500w" />

### Using `runs.list()`

You can provide filters to the `runs.list` SDK function, including an array of tags.

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

// Loop through all runs with the tag "user_123456" that have completed
for await (const run of runs.list({ tag: "user_123456", status: ["COMPLETED"] })) {
  console.log(run.id, run.taskIdentifier, run.finishedAt, run.tags);
}
```


# Tasks: Overview
Source: https://trigger.dev/docs/tasks/overview

Tasks are functions that can run for a long time and provide strong resilience to failure.

There are different types of tasks including regular tasks and [scheduled tasks](/tasks/scheduled).

## Hello world task and how to trigger it

Here's an incredibly simple task:

```ts /trigger/hello-world.ts theme={null}
import { task } from "@trigger.dev/sdk";

const helloWorld = task({
  //1. Use a unique id for each task
  id: "hello-world",
  //2. The run function is the main function of the task
  run: async (payload: { message: string }) => {
    //3. You can write code that runs for a long time here, there are no timeouts
    console.log(payload.message);
  },
});
```

You can trigger this in two ways:

1. From the dashboard [using the "Test" feature](/run-tests).
2. Trigger it from your backend code. See the [full triggering guide here](/triggering).

Here's how to trigger a single run from elsewhere in your code:

```ts Your backend code theme={null}
import { helloWorld } from "./trigger/hello-world";

async function triggerHelloWorld() {
  //This triggers the task and returns a handle
  const handle = await helloWorld.trigger({ message: "Hello world!" });

  //You can use the handle to check the status of the task, cancel and retry it.
  console.log("Task is running with handle", handle.id);
}
```

You can also [trigger a task from another task](/triggering), and wait for the result.

## Defining a `task`

The task function takes an object with the following fields.

### The `id` field

This is used to identify your task so it can be triggered, managed, and you can view runs in the dashboard. This must be unique in your project â€“ we recommend making it descriptive and unique.

### The `run` function

Your custom code inside `run()` will be executed when your task is triggered. Itâ€™s an async function that has two arguments:

1. The run payload - the data that you pass to the task when you trigger it.
2. An object with `ctx` about the run (Context), and any output from the optional `init` function that runs before every run attempt.

Anything you return from the `run` function will be the result of the task. Data you return must be JSON serializable: strings, numbers, booleans, arrays, objects, and null.

### `retry` options

A task is retried if an error is thrown, by default we retry 3 times.

You can set the number of retries and the delay between retries in the `retry` field:

```ts /trigger/retry.ts theme={null}
export const taskWithRetries = task({
  id: "task-with-retries",
  retry: {
    maxAttempts: 10,
    factor: 1.8,
    minTimeoutInMs: 500,
    maxTimeoutInMs: 30_000,
    randomize: false,
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

For more information read [the retrying guide](/errors-retrying).

It's also worth mentioning that you can [retry a block of code](/errors-retrying) inside your tasks as well.

### `queue` options

Queues allow you to control the concurrency of your tasks. This allows you to have one-at-a-time execution and parallel executions. There are also more advanced techniques like having different concurrencies for different sets of your users. For more information read [the concurrency & queues guide](/queue-concurrency).

```ts /trigger/one-at-a-time.ts theme={null}
export const oneAtATime = task({
  id: "one-at-a-time",
  queue: {
    concurrencyLimit: 1,
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

### `machine` options

Some tasks require more vCPUs or GBs of RAM. You can specify these requirements in the `machine` field. For more information read [the machines guide](/machines).

```ts /trigger/heavy-task.ts theme={null}
export const heavyTask = task({
  id: "heavy-task",
  machine: {
    preset: "large-1x", // 4 vCPU, 8 GB RAM
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

### `maxDuration` option

By default tasks can execute indefinitely, which can be great! But you also might want to set a `maxDuration` to prevent a task from running too long. You can set the `maxDuration` on a task, and all runs of that task will be stopped if they exceed the duration.

```ts /trigger/long-task.ts theme={null}
export const longTask = task({
  id: "long-task",
  maxDuration: 300, // 300 seconds or 5 minutes
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

See our [maxDuration guide](/runs/max-duration) for more information.

## Global lifecycle hooks

<Note>When specifying global lifecycle hooks, we recommend using the `init.ts` file.</Note>

You can register global lifecycle hooks that are executed for all runs, regardless of the task. While you can still define these in the `trigger.config.ts` file, you can also register them anywhere in your codebase:

```ts  theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onStart(({ ctx, payload, task }) => {
  console.log("Run started", ctx.run);
});

tasks.onSuccess(({ ctx, output }) => {
  console.log("Run finished", ctx.run);
});

tasks.onFailure(({ ctx, error }) => {
  console.log("Run failed", ctx.run);
});
```

### `init.ts`

If you create a `init.ts` file at the root of your trigger directory, it will be automatically loaded when a task is executed. This is useful if you want to register global lifecycle hooks, or initialize a database connection, etc.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onStart(({ ctx, payload, task }) => {
  console.log("Run started", ctx.run);
});
```

## Lifecycle functions

<img src="https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=6196168935d136c5440fea7793918591" alt="Lifecycle functions" data-og-width="1428" width="1428" data-og-height="1239" height="1239" data-path="images/lifecycle-functions.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=280&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=6ecf6b07768a33e17d335136564ccd54 280w, https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=560&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=80ed26958dfbbde07cb48612c37f0bc6 560w, https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=840&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=32495b4b321f9f790a4e6b3bfb99e550 840w, https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=1100&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=bb3d9791a3052a6c82ce6fc6c8194cdb 1100w, https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=1650&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=15e76db685781a56fe68c8e787a593b6 1650w, https://mintcdn.com/trigger/GRVvL72gYSoZFvP1/images/lifecycle-functions.png?w=2500&fit=max&auto=format&n=GRVvL72gYSoZFvP1&q=85&s=123bad89f02dae694d741c0ad186de64 2500w" />

### `middleware` and `locals` functions

Our task middleware system runs at the top level, executing before and after all lifecycle hooks. This allows you to wrap the entire task execution lifecycle with custom logic.

<Info>
  An error thrown in `middleware` is just like an uncaught error in the run function: it will
  propagate through to `catchError()` function and then will fail the attempt (either causing a
  retry or failing the run).
</Info>

The `locals` API allows you to share data between middleware and hooks.

```ts db.ts theme={null}
import { locals } from "@trigger.dev/sdk";
import { logger, tasks } from "@trigger.dev/sdk";

// This would be type of your database client here
const DbLocal = locals.create<{ connect: () => Promise<void>; disconnect: () => Promise<void> }>(
  "db"
);

export function getDb() {
  return locals.getOrThrow(DbLocal);
}

export function setDb(db: { connect: () => Promise<void> }) {
  locals.set(DbLocal, db);
}

tasks.middleware("db", async ({ ctx, payload, next, task }) => {
  // This would be your database client here
  const db = locals.set(DbLocal, {
    connect: async () => {
      logger.info("Connecting to the database");
    },
    disconnect: async () => {
      logger.info("Disconnecting from the database");
    },
  });

  await db.connect();

  await next();

  await db.disconnect();
});

// Disconnect when the run is paused
tasks.onWait("db", async ({ ctx, payload, task }) => {
  const db = getDb();
  await db.disconnect();
});

// Reconnect when the run is resumed
tasks.onResume("db", async ({ ctx, payload, task }) => {
  const db = getDb();
  await db.connect();
});
```

You can access the database client using `getDb()` in your tasks `run` function and all your hooks (global or task specific):

```ts  theme={null}
import { getDb } from "./db";

export const myTask = task({
  run: async (payload: any, { ctx }) => {
    const db = getDb();
    await db.query("SELECT 1");
  },
});
```

### `onStartAttempt` function

<Info>The `onStartAttempt` function was introduced in v4.1.0</Info>

Before a task run attempt starts, the `onStartAttempt` function is called. It's useful for sending notifications, logging, and other side effects.

```ts /trigger/on-start.ts theme={null}
export const taskWithOnStartAttempt = task({
  id: "task-with-on-start-attempt",
  onStartAttempt: async ({ payload, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

You can also define a global `onStartAttempt` function using `tasks.onStartAttempt()`.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onStartAttempt(({ ctx, payload, task }) => {
  console.log(
    `Run ${ctx.run.id} started on task ${task} attempt ${ctx.run.attempt.number}`,
    ctx.run
  );
});
```

<Info>Errors thrown in the `onStartAttempt` function will cause the attempt to fail.</Info>

If you want to execute code before just the first attempt, you can use the `onStartAttempt` function and check `ctx.run.attempt.number === 1`:

```ts /trigger/on-start-attempt.ts theme={null}
export const taskWithOnStartAttempt = task({
  id: "task-with-on-start-attempt",
  onStartAttempt: async ({ payload, ctx }) => {
    if (ctx.run.attempt.number === 1) {
      console.log("Run started on attempt 1", ctx.run);
    }
  },
});
```

### `onWait` and `onResume` functions

These lifecycle hooks allow you to run code when a run is paused or resumed because of a wait:

```ts  theme={null}
export const myTask = task({
  id: "my-task",
  onWait: async ({ wait }) => {
    console.log("Run paused", wait);
  },
  onResume: async ({ wait }) => {
    console.log("Run resumed", wait);
  },
  run: async (payload: any, { ctx }) => {
    console.log("Run started", ctx.run);

    await wait.for({ seconds: 10 });

    console.log("Run finished", ctx.run);
  },
});
```

You can also define global `onWait` and `onResume` functions using `tasks.onWait()` and `tasks.onResume()`:

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onWait(({ ctx, payload, wait, task }) => {
  console.log("Run paused", ctx.run, wait);
});

tasks.onResume(({ ctx, payload, wait, task }) => {
  console.log("Run resumed", ctx.run, wait);
});
```

### `onSuccess` function

When a task run succeeds, the `onSuccess` function is called. It's useful for sending notifications, logging, syncing state to your database, or other side effects.

```ts /trigger/on-success.ts theme={null}
export const taskWithOnSuccess = task({
  id: "task-with-on-success",
  onSuccess: async ({ payload, output, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

You can also define a global `onSuccess` function using `tasks.onSuccess()`.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onSuccess(({ ctx, payload, output }) => {
  console.log("Task succeeded", ctx.task.id);
});
```

<Info>
  Errors thrown in the `onSuccess` function will be ignored, but you will still be able to see them
  in the dashboard.
</Info>

### `onComplete` function

This hook is executed when a run completes, regardless of whether it succeeded or failed:

```ts /trigger/on-complete.ts theme={null}
export const taskWithOnComplete = task({
  id: "task-with-on-complete",
  onComplete: async ({ payload, output, ctx }) => {
  if (result.ok) {
    console.log("Run succeeded", result.data);
  } else {
    console.log("Run failed", result.error);
  }
});
```

You can also define a global `onComplete` function using `tasks.onComplete()`.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onComplete(({ ctx, payload, output }) => {
  console.log("Task completed", ctx.task.id);
});
```

<Info>
  Errors thrown in the `onComplete` function will be ignored, but you will still be able to see them
  in the dashboard.
</Info>

### `onFailure` function

When a task run fails, the `onFailure` function is called. It's useful for sending notifications, logging, or other side effects. It will only be executed once the task run has exhausted all its retries.

```ts /trigger/on-failure.ts theme={null}
export const taskWithOnFailure = task({
  id: "task-with-on-failure",
  onFailure: async ({ payload, error, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

You can also define a global `onFailure` function using `tasks.onFailure()`.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onFailure(({ ctx, payload, error }) => {
  console.log("Task failed", ctx.task.id);
});
```

<Info>
  Errors thrown in the `onFailure` function will be ignored, but you will still be able to see them
  in the dashboard.
</Info>

<Note>
  `onFailure` doesnâ€™t fire for some of the run statuses like `Crashed`, `System failures`, and
  `Canceled`.
</Note>

### `catchError` functions

You can define a function that will be called when an error is thrown in the `run` function, that allows you to control how the error is handled and whether the task should be retried.

Read more about `catchError` in our [Errors and Retrying guide](/errors-retrying).

<Info>Uncaught errors will throw a special internal error of the type `HANDLE_ERROR_ERROR`.</Info>

### `onCancel` function

You can define an `onCancel` hook that is called when a run is cancelled. This is useful if you want to clean up any resources that were allocated for the run.

```ts  theme={null}
tasks.onCancel(({ ctx, signal }) => {
  console.log("Run cancelled", signal);
});
```

You can use the `onCancel` hook along with the `signal` passed into the run function to interrupt a call to an external service, for example using the [streamText](https://ai-sdk.dev/docs/reference/ai-sdk-core/stream-text) function from the AI SDK:

```ts  theme={null}
import { logger, tasks, schemaTask } from "@trigger.dev/sdk";
import { streamText } from "ai";
import { z } from "zod";

export const interruptibleChat = schemaTask({
  id: "interruptible-chat",
  description: "Chat with the AI",
  schema: z.object({
    prompt: z.string().describe("The prompt to chat with the AI"),
  }),
  run: async ({ prompt }, { signal }) => {
    const chunks: TextStreamPart<{}>[] = [];

    // ðŸ‘‡ This is a global onCancel hook, but it's inside of the run function
    tasks.onCancel(async () => {
      // We have access to the chunks here, and can save them to the database
      await saveChunksToDatabase(chunks);
    });

    try {
      const result = streamText({
        model: getModel(),
        prompt,
        experimental_telemetry: {
          isEnabled: true,
        },
        tools: {},
        abortSignal: signal, // ðŸ‘ˆ Pass the signal to the streamText function, which aborts with the run is cancelled
        onChunk: ({ chunk }) => {
          chunks.push(chunk);
        },
      });

      const textParts = [];

      for await (const part of result.textStream) {
        textParts.push(part);
      }

      return textParts.join("");
    } catch (error) {
      if (error instanceof Error && error.name === "AbortError") {
        // streamText will throw an AbortError if the signal is aborted, so we can handle it here
      } else {
        throw error;
      }
    }
  },
});
```

The `onCancel` hook can optionally wait for the `run` function to finish, and access the output of the run:

```ts  theme={null}
import { logger, task } from "@trigger.dev/sdk";
import { setTimeout } from "node:timers/promises";

export const cancelExampleTask = task({
  id: "cancel-example",
  // Signal will be aborted when the task is cancelled ðŸ‘‡
  run: async (payload: { message: string }, { signal }) => {
    try {
      // We pass the signal to setTimeout to abort the timeout if the task is cancelled
      await setTimeout(10_000, undefined, { signal });
    } catch (error) {
      // Ignore the abort error
    }

    // Do some more work here

    return {
      message: "Hello, world!",
    };
  },
  onCancel: async ({ runPromise }) => {
    // You can await the runPromise to get the output of the task
    const output = await runPromise;
  },
});
```

<Note>
  You will have up to 30 seconds to complete the `runPromise` in the `onCancel` hook. After that
  point the process will be killed.
</Note>

### `onStart` function (deprecated)

<Info>The `onStart` function was deprecated in v4.1.0. Use `onStartAttempt` instead.</Info>

When a task run starts, the `onStart` function is called. It's useful for sending notifications, logging, and other side effects.

<Warning>
  This function will only be called once per run (not per attempt). If you want to run code before
  each attempt, use a middleware function or the `onStartAttempt` function.
</Warning>

```ts /trigger/on-start.ts theme={null}
export const taskWithOnStart = task({
  id: "task-with-on-start",
  onStart: async ({ payload, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

You can also define a global `onStart` function using `tasks.onStart()`.

```ts init.ts theme={null}
import { tasks } from "@trigger.dev/sdk";

tasks.onStart(({ ctx, payload, task }) => {
  console.log(`Run ${ctx.run.id} started on task ${task}`, ctx.run);
});
```

<Info>Errors thrown in the `onStart` function will cause the attempt to fail.</Info>

### `init` function (deprecated)

<Warning>
  The `init` hook is deprecated and will be removed in the future. Use
  [middleware](/tasks/overview#middleware-and-locals-functions) instead.
</Warning>

This function is called before a run attempt:

```ts /trigger/init.ts theme={null}
export const taskWithInit = task({
  id: "task-with-init",
  init: async ({ payload, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

You can also return data from the `init` function that will be available in the params of the `run`, `cleanup`, `onSuccess`, and `onFailure` functions.

```ts /trigger/init-return.ts theme={null}
export const taskWithInitReturn = task({
  id: "task-with-init-return",
  init: async ({ payload, ctx }) => {
    return { someData: "someValue" };
  },
  run: async (payload: any, { ctx, init }) => {
    console.log(init.someData); // "someValue"
  },
});
```

<Info>Errors thrown in the `init` function will cause the attempt to fail.</Info>

### `cleanup` function (deprecated)

<Warning>
  The `cleanup` hook is deprecated and will be removed in the future. Use
  [middleware](/tasks/overview#middleware-and-locals-functions) instead.
</Warning>

This function is called after the `run` function is executed, regardless of whether the run was successful or not. It's useful for cleaning up resources, logging, or other side effects.

```ts /trigger/cleanup.ts theme={null}
export const taskWithCleanup = task({
  id: "task-with-cleanup",
  cleanup: async ({ payload, ctx }) => {
    //...
  },
  run: async (payload: any, { ctx }) => {
    //...
  },
});
```

<Info>Errors thrown in the `cleanup` function will cause the attempt to fail.</Info>

## Next steps

<CardGroup>
  <Card title="Triggering" icon="bolt" href="/triggering">
    Learn how to trigger your tasks from your code.
  </Card>

  <Card title="Writing tasks" icon="wand-magic-sparkles" href="/writing-tasks-introduction">
    Tasks are the core of Trigger.dev. Learn how to write them.
  </Card>
</CardGroup>


# Scheduled tasks (cron)
Source: https://trigger.dev/docs/tasks/scheduled

A task that is triggered on a recurring schedule using cron syntax.

<Note>
  Scheduled tasks are only for recurring tasks. If you want to trigger a one-off task at a future
  time, you should [use the delay option](/triggering#delay).
</Note>

## Defining a scheduled task

This task will run when any of the attached schedules trigger. They have a predefined payload with some useful properties:

```ts  theme={null}
import { schedules } from "@trigger.dev/sdk";

export const firstScheduledTask = schedules.task({
  id: "first-scheduled-task",
  run: async (payload) => {
    //when the task was scheduled to run
    //note this will be slightly different from new Date() because it takes a few ms to run the task
    console.log(payload.timestamp); //is a Date object

    //when the task was last run
    //this can be undefined if it's never been run
    console.log(payload.lastTimestamp); //is a Date object or undefined

    //the timezone the schedule was registered with, defaults to "UTC"
    //this is in IANA format, e.g. "America/New_York"
    //See the full list here: https://cloud.trigger.dev/timezones
    console.log(payload.timezone); //is a string

    //If you want to output the time in the user's timezone do this:
    const formatted = payload.timestamp.toLocaleString("en-US", {
      timeZone: payload.timezone,
    });

    //the schedule id (you can have many schedules for the same task)
    //using this you can remove the schedule, update it, etc
    console.log(payload.scheduleId); //is a string

    //you can optionally provide an external id when creating the schedule
    //usually you would set this to a userId or some other unique identifier
    //this can be undefined if you didn't provide one
    console.log(payload.externalId); //is a string or undefined

    //the next 5 dates this task is scheduled to run
    console.log(payload.upcoming); //is an array of Date objects
  },
});
```

You can see from the comments that the payload has several useful properties:

* `timestamp` - the time the task was scheduled to run, as a UTC date.
* `lastTimestamp` - the time the task was last run, as a UTC date.
* `timezone` - the timezone the schedule was registered with, defaults to "UTC". In IANA format, e.g. "America/New\_York".
* `scheduleId` - the id of the schedule that triggered the task
* `externalId` - the external id you (optionally) provided when creating the schedule
* `upcoming` - the next 5 times the task is scheduled to run

<Note>
  This task will NOT get triggered on a schedule until you attach a schedule to it. Read on for how
  to do that.
</Note>

Like all tasks they don't have timeouts, they should be placed inside a [/trigger folder](/config/config-file), and you [can configure them](/tasks/overview#defining-a-task).

## How to attach a schedule

Now that we've defined a scheduled task, we need to define when it will actually run. To do this we need to attach one or more schedules.

There are two ways of doing this:

* **Declarative:** defined on your `schedules.task`. They sync when you run the dev command or deploy.
* **Imperative:** created from the dashboard or by using the imperative SDK functions like `schedules.create()`.

<Info>
  A scheduled task can have multiple schedules attached to it, including a declarative schedule
  and/or many imperative schedules.
</Info>

### Declarative schedules

These sync when you run the [dev](/cli-dev) or [deploy](/cli-deploy) commands.

To create them you add the `cron` property to your `schedules.task()`. This property is optional and is only used if you want to add a declarative schedule to your task:

```ts  theme={null}
export const firstScheduledTask = schedules.task({
  id: "first-scheduled-task",
  //every two hours (UTC timezone)
  cron: "0 */2 * * *",
  run: async (payload, { ctx }) => {
    //do something
  },
});
```

If you use a string it will be in UTC. Alternatively, you can specify a timezone like this:

```ts  theme={null}
export const secondScheduledTask = schedules.task({
  id: "second-scheduled-task",
  cron: {
    //5am every day Tokyo time
    pattern: "0 5 * * *",
    timezone: "Asia/Tokyo",
    //optional, defaults to all environments
    //possible values are "PRODUCTION", "STAGING", "PREVIEW" and "DEVELOPMENT"
    environments: ["PRODUCTION", "STAGING"],
  },
  run: async (payload) => {},
});
```

When you run the [dev](/cli-dev) or [deploy](/cli-deploy) commands, declarative schedules will be synced. If you add, delete or edit the `cron` property it will be updated when you run these commands. You can view your schedules on the Schedules page in the dashboard.

### Imperative schedules

Alternatively you can explicitly attach schedules to a `schedules.task`. You can do this in the Schedules page in the dashboard by just pressing the "New schedule" button, or you can use the SDK to create schedules.

The advantage of imperative schedules is that they can be created dynamically, for example, you could create a schedule for each user in your database. They can also be activated, disabled, edited, and deleted without deploying new code by using the SDK or dashboard.

To use imperative schedules you need to do two things:

1. Define a task in your code using `schedules.task()`.
2. Attach 1+ schedules to the task either using the dashboard or the SDK.

## Supported cron syntax

```
*    *    *    *    *
â”¬    â”¬    â”¬    â”¬    â”¬
â”‚    â”‚    â”‚    â”‚    |
â”‚    â”‚    â”‚    â”‚    â”” day of week (0 - 7, 1L - 7L) (0 or 7 is Sun)
â”‚    â”‚    â”‚    â””â”€â”€â”€â”€â”€ month (1 - 12)
â”‚    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of month (1 - 31, L)
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hour (0 - 23)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0 - 59)
```

"L" means the last. In the "day of week" field, 1L means the last Monday of the month. In the "day of month" field, L means the last day of the month.

We do not support seconds in the cron syntax.

## When schedules won't trigger

There are two situations when a scheduled task won't trigger:

* For Dev environments scheduled tasks will only trigger if you're running the dev CLI.
* For Staging/Production environments scheduled tasks will only trigger if the task is in the current deployment (latest version). We won't trigger tasks from previous deployments.

## Attaching schedules in the dashboard

You need to attach a schedule to a task before it will run on a schedule. You can attach static schedules in the dashboard:

<Steps>
  <Step title="Go to the Schedules page">
    In the sidebar select the "Schedules" page, then press the "New schedule" button. Or you can
    follow the onboarding and press the create in dashboard button. <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=43eb999c7adffee996282649787537ac" alt="Blank schedules
    page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/schedules-blank.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=fe91c092419f97fabd87bc978b02ef70 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=80f88b80434b611ce1c3d496563c6986 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=366e55c6afcfd9a36a16d94ef5bb7453 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=d3cc50242dbdd1bb6f035caeb20c91c6 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8b38dec234ab37de05949645ac5bd3e6 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-blank.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=bc86e5670d9c0b0c85cb3db0cde6bfbe 2500w" />
  </Step>

  <Step title="Create your schedule">
    Fill in the form and press "Create schedule" when you're done. <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=c958b2628029237508df655d4e893d1e" alt="Environment variables
    page" data-og-width="1600" width="1600" data-og-height="901" height="901" data-path="images/schedules-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=5ebfd52f0aa7804335db8b6cc77dd13f 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=a0bddf8862294445a0c3b6d2140ddffd 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=04fa4d04c0490f38d0b243f2588e00f3 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0895d4a4306bbd55f91173c4b365c6e2 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=21b3fc532d0bdce094542b94a20e915c 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-create.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=06ce41644450d0f6bc12745c26e8859b 2500w" />

    These are the options when creating a schedule:

    | Name              | Description                                                                                   |
    | ----------------- | --------------------------------------------------------------------------------------------- |
    | Task              | The id of the task you want to attach to.                                                     |
    | Cron pattern      | The schedule in cron format.                                                                  |
    | Timezone          | The timezone the schedule will run in. Defaults to "UTC"                                      |
    | External id       | An optional external id, usually you'd use a userId.                                          |
    | Deduplication key | An optional deduplication key. If you pass the same value, it will update rather than create. |
    | Environments      | The environments this schedule will run in.                                                   |
  </Step>
</Steps>

## Attaching schedules with the SDK

You call `schedules.create()` to create a schedule from your code. Here's the simplest possible example:

```ts  theme={null}
const createdSchedule = await schedules.create({
  //The id of the scheduled task you want to attach to.
  task: firstScheduledTask.id,
  //The schedule in cron format.
  cron: "0 0 * * *",
  //this is required, it prevents you from creating duplicate schedules. It will update the schedule if it already exists.
  deduplicationKey: "my-deduplication-key",
});
```

<Note>The `task` id must be a task that you defined using `schedules.task()`.</Note>

You can create many schedules with the same `task`, `cron`, and `externalId` but only one with the same `deduplicationKey`.

This means you can have thousands of schedules attached to a single task, but only one schedule per `deduplicationKey`. Here's an example with all the options:

```ts  theme={null}
const createdSchedule = await schedules.create({
  //The id of the scheduled task you want to attach to.
  task: firstScheduledTask.id,
  //The schedule in cron format.
  cron: "0 0 * * *",
  // Optional, it defaults to "UTC". In IANA format, e.g. "America/New_York".
  // In this case, the task will run at midnight every day in New York time.
  // If you specify a timezone it will automatically work with daylight saving time.
  timezone: "America/New_York",
  //Optionally, you can specify your own IDs (like a user ID) and then use it inside the run function of your task.
  //This allows you to have per-user cron tasks.
  externalId: "user_123456",
  //You can only create one schedule with this key.
  //If you use it twice, the second call will update the schedule.
  //This is useful because you don't want to create duplicate schedules for a user.
  deduplicationKey: "user_123456-todo_reminder",
});
```

See [the SDK reference](/management/schedules/create) for full details.

### Dynamic schedules (or multi-tenant schedules)

By using the `externalId` you can have schedules for your users. This is useful for things like reminders, where you want to have a schedule for each user.

A reminder task:

```ts /trigger/reminder.ts theme={null}
import { schedules } from "@trigger.dev/sdk";

//this task will run when any of the attached schedules trigger
export const reminderTask = schedules.task({
  id: "todo-reminder",
  run: async (payload) => {
    if (!payload.externalId) {
      throw new Error("externalId is required");
    }

    //get user using the externalId you used when creating the schedule
    const user = await db.getUser(payload.externalId);

    //send a reminder email
    await sendReminderEmail(user);
  },
});
```

Then in your backend code, you can create a schedule for each user:

```ts Next.js API route theme={null}
import { reminderTask } from "~/trigger/reminder";

//app/reminders/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  //create a schedule for the user
  const createdSchedule = await schedules.create({
    task: reminderTask.id,
    //8am every day
    cron: "0 8 * * *",
    //the user's timezone
    timezone: data.timezone,
    //the user id
    externalId: data.userId,
    //this makes it impossible to have two reminder schedules for the same user
    deduplicationKey: `${data.userId}-reminder`,
  });

  //return a success response with the schedule
  return Response.json(createdSchedule);
}
```

You can also retrieve, list, delete, deactivate and re-activate schedules using the SDK. More on that later.

## Testing schedules

You can test a scheduled task in the dashboard. Note that the `scheduleId` will always come through as `sched_1234` to the run.

<Steps>
  <Step title="Go to the Test page">
    In the sidebar select the "Test" page, then select a scheduled task from the list (they have a
    clock icon on them) <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=6591163dd3e4af384746705dffef6c92" alt="Test page" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/schedules-test.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=ec7027a656655d186e0ee7b8d4d858ad 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=7616d494747c8f9038be012668f3a238 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=23eb128eee342e40a3826b05c006c029 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f7fdc2ee3775b41361ae411022a37f53 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=4261839b6f2f2c8f1c2c360108c16f33 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=82ac96f5c94674e853545cb60285b38a 2500w" />
  </Step>

  <Step title="Create your schedule">
    Fill in the form \[1]. You can select from a recent run \[2] to pre-populate the fields. Press "Run
    test" when you're ready <img src="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=0b2a0947db2701825addb703f92748a1" alt="Schedule test form" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/schedules-test-form.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=280&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=3031563444d48852d76c67b95a4f5139 280w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=560&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=1455997fee472ae6934f5d96ba2e1a2e 560w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=840&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=5be53628561e1c9ae50228cef28ffac6 840w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=1100&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=aa2f6a789d838b7afb13ad77f6305143 1100w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=1650&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=f833cb1540671e10b2a9aebda6fd0b9c 1650w, https://mintcdn.com/trigger/5SxX7bFjJKRsidSL/images/schedules-test-form.png?w=2500&fit=max&auto=format&n=5SxX7bFjJKRsidSL&q=85&s=8878736225374e8cc8ddd0d8227a596a 2500w" />
  </Step>
</Steps>

## Managing schedules with the SDK

### Retrieving an existing schedule

```ts  theme={null}
const retrievedSchedule = await schedules.retrieve(scheduleId);
```

See [the SDK reference](/management/schedules/retrieve) for full details.

### Listing schedules

```ts  theme={null}
const allSchedules = await schedules.list();
```

See [the SDK reference](/management/schedules/list) for full details.

### Updating a schedule

```ts  theme={null}
const updatedSchedule = await schedules.update(scheduleId, {
  task: firstScheduledTask.id,
  cron: "0 0 1 * *",
  externalId: "ext_1234444",
  deduplicationKey: "my-deduplication-key",
});
```

See [the SDK reference](/management/schedules/update) for full details.

### Deactivating a schedule

```ts  theme={null}
const deactivatedSchedule = await schedules.deactivate(scheduleId);
```

See [the SDK reference](/management/schedules/deactivate) for full details.

### Activating a schedule

```ts  theme={null}
const activatedSchedule = await schedules.activate(scheduleId);
```

See [the SDK reference](/management/schedules/activate) for full details.

### Deleting a schedule

```ts  theme={null}
const deletedSchedule = await schedules.del(scheduleId);
```

See [the SDK reference](/management/schedules/delete) for full details.

### Getting possible timezones

You might want to show a dropdown menu in your UI so your users can select their timezone. You can get a list of all possible timezones using the SDK:

```ts  theme={null}
const timezones = await schedules.timezones();
```

See [the SDK reference](/management/schedules/timezones) for full details.


# schemaTask
Source: https://trigger.dev/docs/tasks/schemaTask

Define tasks with a runtime payload schema and validate the payload before running the task.

The `schemaTask` function allows you to define a task with a runtime payload schema. This schema is used to validate the payload before running the task or when triggering a task directly. If the payload does not match the schema, the task will not execute.

## Usage

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";

const myTask = schemaTask({
  id: "my-task",
  schema: z.object({
    name: z.string(),
    age: z.number(),
  }),
  run: async (payload) => {
    console.log(payload.name, payload.age);
  },
});
```

`schemaTask` takes all the same options as [task](/tasks/overview), with the addition of a `schema` field. The `schema` field is a schema parser function from a schema library or or a custom parser function.

<Note>
  We will probably eventually combine `task` and `schemaTask` into a single function, but because
  that would be a breaking change, we are keeping them separate for now.
</Note>

When you trigger the task directly, the payload will be validated against the schema before the [run](/runs) is created:

```ts  theme={null}
import { tasks } from "@trigger.dev/sdk";
import { myTask } from "./trigger/myTasks";

// This will call the schema parser function and validate the payload
await myTask.trigger({ name: "Alice", age: "oops" }); // this will throw an error

// This will NOT call the schema parser function
await tasks.trigger<typeof myTask>("my-task", { name: "Alice", age: "oops" }); // this will not throw an error
```

The error thrown when the payload does not match the schema will be the same as the error thrown by the schema parser function. For example, if you are using Zod, the error will be a `ZodError`.

We will also validate the payload every time before the task is run, so you can be sure that the payload is always valid. In the example above, the task would fail with a `TaskPayloadParsedError` error and skip retrying if the payload does not match the schema.

## Input/output schemas

Certain schema libraries, like Zod, split their type inference into "schema in" and "schema out". This means that you can define a single schema that will produce different types when triggering the task and when running the task. For example, you can define a schema that has a default value for a field, or a string coerced into a date:

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";

const myTask = schemaTask({
  id: "my-task",
  schema: z.object({
    name: z.string().default("John"),
    age: z.number(),
    dob: z.coerce.date(),
  }),
  run: async (payload) => {
    console.log(payload.name, payload.age);
  },
});
```

In this case, the trigger payload type is `{ name?: string, age: number; dob: string }`, but the run payload type is `{ name: string, age: number; dob: Date }`. So you can trigger the task with a payload like this:

```ts  theme={null}
await myTask.trigger({ age: 30, dob: "2020-01-01" }); // this is valid
await myTask.trigger({ name: "Alice", age: 30, dob: "2020-01-01" }); // this is also valid
```

## `ai.tool`

The `ai.tool` function allows you to create an AI tool from an existing `schemaTask` to use with the Vercel [AI SDK](https://vercel.com/docs/ai-sdk):

```ts  theme={null}
import { ai } from "@trigger.dev/sdk/ai";
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";
import { generateText } from "ai";

const myToolTask = schemaTask({
  id: "my-tool-task",
  schema: z.object({
    foo: z.string(),
  }),
  run: async (payload: any, { ctx }) => {},
});

const myTool = ai.tool(myToolTask);

export const myAiTask = schemaTask({
  id: "my-ai-task",
  schema: z.object({
    text: z.string(),
  }),
  run: async (payload, { ctx }) => {
    const { text } = await generateText({
      prompt: payload.text,
      model: openai("gpt-4o"),
      tools: {
        myTool,
      },
    });
  },
});
```

You can also pass the `experimental_toToolResultContent` option to the `ai.tool` function to customize the content of the tool result:

```ts  theme={null}
import { openai } from "@ai-sdk/openai";
import { Sandbox } from "@e2b/code-interpreter";
import { ai } from "@trigger.dev/sdk/ai";
import { schemaTask } from "@trigger.dev/sdk";
import { generateObject } from "ai";
import { z } from "zod";

const chartTask = schemaTask({
  id: "chart",
  description: "Generate a chart using natural language",
  schema: z.object({
    input: z.string().describe("The chart to generate"),
  }),
  run: async ({ input }) => {
    const code = await generateObject({
      model: openai("gpt-4o"),
      schema: z.object({
        code: z.string().describe("The Python code to execute"),
      }),
      system: `
        You are a helpful assistant that can generate Python code to be executed in a sandbox, using matplotlib.pyplot.

        For example: 
        
        import matplotlib.pyplot as plt
        plt.plot([1, 2, 3, 4])
        plt.ylabel('some numbers')
        plt.show()
        
        Make sure the code ends with plt.show()
      `,
      prompt: input,
    });

    const sandbox = await Sandbox.create();

    const execution = await sandbox.runCode(code.object.code);

    const firstResult = execution.results[0];

    if (firstResult.png) {
      return {
        chart: firstResult.png,
      };
    } else {
      throw new Error("No chart generated");
    }
  },
});

// This is useful if you want to return an image from the tool
export const chartTool = ai.tool(chartTask, {
  experimental_toToolResultContent: (result) => {
    return [
      {
        type: "image",
        data: result.chart,
        mimeType: "image/png",
      },
    ];
  },
});
```

You can access the current tool execution options inside the task run function using the `ai.currentToolOptions()` function:

```ts  theme={null}
import { ai } from "@trigger.dev/sdk/ai";
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";

const myToolTask = schemaTask({
  id: "my-tool-task",
  schema: z.object({
    foo: z.string(),
  }),
  run: async (payload, { ctx }) => {
    const toolOptions = ai.currentToolOptions();
    console.log(toolOptions);
  },
});

export const myAiTask = ai.tool(myToolTask);
```

See the [AI SDK tool execution options docs](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling#tool-execution-options) for more details on the tool execution options.

<Note>
  `ai.tool` is compatible with `schemaTask`'s defined with Zod and ArkType schemas, or any schemas
  that implement a `.toJsonSchema()` function.
</Note>

## Supported schema types

### Zod

You can use the [Zod](https://zod.dev) schema library to define your schema. The schema will be validated using Zod's `parse` function.

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { z } from "zod";

export const zodTask = schemaTask({
  id: "types/zod",
  schema: z.object({
    bar: z.string(),
    baz: z.string().default("foo"),
  }),
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### Yup

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import * as yup from "yup";

export const yupTask = schemaTask({
  id: "types/yup",
  schema: yup.object({
    bar: yup.string().required(),
    baz: yup.string().default("foo"),
  }),
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### Superstruct

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { object, string } from "superstruct";

export const superstructTask = schemaTask({
  id: "types/superstruct",
  schema: object({
    bar: string(),
    baz: string(),
  }),
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### ArkType

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { type } from "arktype";

export const arktypeTask = schemaTask({
  id: "types/arktype",
  schema: type({
    bar: "string",
    baz: "string",
  }).assert,
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### @effect/schema

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import * as Schema from "@effect/schema/Schema";

// For some funny typescript reason, you cannot pass the Schema.decodeUnknownSync directly to schemaTask
const effectSchemaParser = Schema.decodeUnknownSync(
  Schema.Struct({ bar: Schema.String, baz: Schema.String })
);

export const effectTask = schemaTask({
  id: "types/effect",
  schema: effectSchemaParser,
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### runtypes

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import * as T from "runtypes";

export const runtypesTask = schemaTask({
  id: "types/runtypes",
  schema: T.Record({
    bar: T.String,
    baz: T.String,
  }),
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### valibot

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";

import * as v from "valibot";

// For some funny typescript reason, you cannot pass the v.parser directly to schemaTask
const valibotParser = v.parser(
  v.object({
    bar: v.string(),
    baz: v.string(),
  })
);

export const valibotTask = schemaTask({
  id: "types/valibot",
  schema: valibotParser,
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### typebox

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";
import { Type } from "@sinclair/typebox";
import { wrap } from "@typeschema/typebox";

export const typeboxTask = schemaTask({
  id: "types/typebox",
  schema: wrap(
    Type.Object({
      bar: Type.String(),
      baz: Type.String(),
    })
  ),
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```

### Custom parser function

You can also define a custom parser function that will be called with the payload before the task is run. The parser function should return the parsed payload or throw an error if the payload is invalid.

```ts  theme={null}
import { schemaTask } from "@trigger.dev/sdk";

export const customParserTask = schemaTask({
  id: "types/custom-parser",
  schema: (data: unknown) => {
    // This is a custom parser, and should do actual parsing (not just casting)
    if (typeof data !== "object") {
      throw new Error("Invalid data");
    }

    const { bar, baz } = data as { bar: string; baz: string };

    return { bar, baz };
  },
  run: async (payload) => {
    console.log(payload.bar, payload.baz);
  },
});
```


# Realtime Streams
Source: https://trigger.dev/docs/tasks/streams

Stream data in realtime from your Trigger.dev tasks to your frontend or backend applications.

Realtime Streams allow you to pipe streaming data from your Trigger.dev tasks to your frontend or backend applications in real-time. This is perfect for use cases like streaming AI completions, progress updates, or any continuous data flow.

<Note>
  Streams v2 requires SDK version **4.1.0 or later**. Make sure to upgrade your `@trigger.dev/sdk`
  and `@trigger.dev/react-hooks` packages to use these features. If you're on an earlier version,
  see the [metadata.stream()](/runs/metadata#stream) documentation.
</Note>

## Overview

Streams v2 is a major upgrade that provides:

* **Unlimited stream length** (previously capped at 2000 chunks)
* **Unlimited active streams per run** (previously 5)
* **Improved reliability** with automatic resumption on connection loss
* **28-day stream retention** (previously 1 day)
* **Multiple client streams** can pipe to a single stream
* **Enhanced dashboard visibility** for viewing stream data in real-time

## Enabling Streams v2

Streams v2 is **automatically enabled** when triggering runs from the SDK using 4.1.0 or later. If you aren't triggering via the SDK, you'll need to explicitly enable v2 streams via setting the `x-trigger-realtime-streams-version=v2` header when triggering the task.

If you'd like to **opt-out** of the v2 streams, you can see so in one of the following two ways:

### Option 1: Configure the SDK

```ts  theme={null}
import { auth } from "@trigger.dev/sdk";

auth.configure({
  future: {
    v2RealtimeStreams: false,
  },
});
```

### Option 2: Environment Variable

Set the `TRIGGER_V2_REALTIME_STREAMS=0` environment variable in your backend code (where you trigger tasks).

## Limits Comparison

| Limit                            | Streams v1 | Streams v2 |
| -------------------------------- | ---------- | ---------- |
| Maximum stream length            | 2000       | Unlimited  |
| Number of active streams per run | 5          | Unlimited  |
| Maximum streams per run          | 10         | Unlimited  |
| Maximum stream TTL               | 1 day      | 28 days    |
| Maximum stream size              | 10MB       | 300 MiB    |

## Quick Start

The recommended workflow for using Realtime Streams v2:

1. **Define your streams** in a shared location using `streams.define()`
2. **Use the defined stream** in your tasks with `.pipe()`, `.append()`, or `.writer()`
3. **Read from the stream** using `.read()` or the `useRealtimeStream` hook in React

This approach gives you full type safety, better code organization, and easier maintenance as your application grows.

## Defining Typed Streams (Recommended)

The recommended way to work with streams is to define them once with `streams.define()`. This allows you to specify the chunk type and stream ID in one place, and then reuse that definition throughout your codebase with full type safety.

### Creating a Defined Stream

Define your streams in a shared location (like `app/streams.ts` or `trigger/streams.ts`):

```ts  theme={null}
import { streams, InferStreamType } from "@trigger.dev/sdk";

// Define a stream with a specific type
export const aiStream = streams.define<string>({
  id: "ai-output",
});

// Export the type for use in frontend components
export type AIStreamPart = InferStreamType<typeof aiStream>;
```

You can define streams for any JSON-serializable type:

```ts  theme={null}
import { streams, InferStreamType } from "@trigger.dev/sdk";
import { UIMessageChunk } from "ai";

// Stream for AI UI message chunks
export const aiStream = streams.define<UIMessageChunk>({
  id: "ai",
});

// Stream for progress updates
export const progressStream = streams.define<{ step: string; percent: number }>({
  id: "progress",
});

// Stream for simple text
export const logStream = streams.define<string>({
  id: "logs",
});

// Export types
export type AIStreamPart = InferStreamType<typeof aiStream>;
export type ProgressStreamPart = InferStreamType<typeof progressStream>;
export type LogStreamPart = InferStreamType<typeof logStream>;
```

### Using Defined Streams in Tasks

Once defined, you can use all stream methods on your defined stream:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { aiStream } from "./streams";

export const streamTask = task({
  id: "stream-task",
  run: async (payload: { prompt: string }) => {
    // Get a stream from an AI service, database, etc.
    const stream = await getAIStream(payload.prompt);

    // Pipe the stream using your defined stream
    const { stream: readableStream, waitUntilComplete } = aiStream.pipe(stream);

    // Option A: Iterate over the stream locally
    for await (const chunk of readableStream) {
      console.log("Received chunk:", chunk);
    }

    // Option B: Wait for the stream to complete
    await waitUntilComplete();

    return { message: "Stream completed" };
  },
});
```

#### Reading from a Stream

Use the defined stream's `read()` method to consume data from anywhere (frontend, backend, or another task):

```ts  theme={null}
import { aiStream } from "./streams";

const stream = await aiStream.read(runId);

for await (const chunk of stream) {
  console.log(chunk); // chunk is typed as the stream's chunk type
}
```

With options:

```ts  theme={null}
const stream = await aiStream.read(runId, {
  timeoutInSeconds: 60, // Stop if no data for 60 seconds
  startIndex: 10, // Start from the 10th chunk
});
```

#### Appending to a Stream

Use the defined stream's `append()` method to add a single chunk:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { aiStream, progressStream, logStream } from "./streams";

export const appendTask = task({
  id: "append-task",
  run: async (payload) => {
    // Append to different streams with full type safety
    await logStream.append("Processing started");
    await progressStream.append({ step: "Initialization", percent: 0 });

    // Do some work...

    await progressStream.append({ step: "Processing", percent: 50 });
    await logStream.append("Step 1 complete");

    // Do more work...

    await progressStream.append({ step: "Complete", percent: 100 });
    await logStream.append("All steps complete");
  },
});
```

#### Writing Multiple Chunks

Use the defined stream's `writer()` method for more complex stream writing:

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { logStream } from "./streams";

export const writerTask = task({
  id: "writer-task",
  run: async (payload) => {
    const { waitUntilComplete } = logStream.writer({
      execute: ({ write, merge }) => {
        // Write individual chunks
        write("Chunk 1");
        write("Chunk 2");

        // Merge another stream
        const additionalStream = ReadableStream.from(["Chunk 3", "Chunk 4", "Chunk 5"]);
        merge(additionalStream);
      },
    });

    await waitUntilComplete();
  },
});
```

### Using Defined Streams in React

Defined streams work seamlessly with the `useRealtimeStream` hook:

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  // Pass the defined stream directly - full type safety!
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 600,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

## Direct Stream Methods (Without Defining)

<Warning>
  We strongly recommend using `streams.define()` instead of direct methods. Defined streams provide
  better organization, full type safety, and make it easier to maintain your codebase as it grows.
</Warning>

If you have a specific reason to avoid defined streams, you can use stream methods directly by specifying the stream key each time.

### Direct Piping

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const directStreamTask = task({
  id: "direct-stream",
  run: async (payload: { prompt: string }) => {
    const stream = await getAIStream(payload.prompt);

    // Specify the stream key directly
    const { stream: readableStream, waitUntilComplete } = streams.pipe("ai-output", stream);

    await waitUntilComplete();
  },
});
```

### Direct Reading

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";

// Specify the stream key when reading
const stream = await streams.read(runId, "ai-output");

for await (const chunk of stream) {
  console.log(chunk);
}
```

### Direct Appending

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const directAppendTask = task({
  id: "direct-append",
  run: async (payload) => {
    // Specify the stream key each time
    await streams.append("logs", "Processing started");
    await streams.append("progress", "50%");
    await streams.append("logs", "Complete");
  },
});
```

### Direct Writing

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const directWriterTask = task({
  id: "direct-writer",
  run: async (payload) => {
    const { waitUntilComplete } = streams.writer("output", {
      execute: ({ write, merge }) => {
        write("Chunk 1");
        write("Chunk 2");
      },
    });

    await waitUntilComplete();
  },
});
```

## Default Stream

Every run has a "default" stream, allowing you to skip the stream key entirely. This is useful for simple cases where you only need one stream per run.

Using direct methods:

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const defaultStreamTask = task({
  id: "default-stream",
  run: async (payload) => {
    const stream = getDataStream();

    // No stream key needed - uses "default"
    const { waitUntilComplete } = streams.pipe(stream);

    await waitUntilComplete();
  },
});

// Reading from the default stream
const readStream = await streams.read(runId);
```

## Targeting Different Runs

You can pipe streams to parent, root, or any other run using the `target` option. This works with both defined streams and direct methods.

### With Defined Streams

```ts  theme={null}
import { task } from "@trigger.dev/sdk";
import { logStream } from "./streams";

export const childTask = task({
  id: "child-task",
  run: async (payload, { ctx }) => {
    const stream = getDataStream();

    // Pipe to parent run
    logStream.pipe(stream, { target: "parent" });

    // Pipe to root run
    logStream.pipe(stream, { target: "root" });

    // Pipe to self (default behavior)
    logStream.pipe(stream, { target: "self" });

    // Pipe to a specific run ID
    logStream.pipe(stream, { target: payload.otherRunId });
  },
});
```

### With Direct Methods

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const childTask = task({
  id: "child-task",
  run: async (payload, { ctx }) => {
    const stream = getDataStream();

    // Pipe to parent run
    streams.pipe("output", stream, { target: "parent" });

    // Pipe to root run
    streams.pipe("output", stream, { target: "root" });

    // Pipe to a specific run ID
    streams.pipe("output", stream, { target: payload.otherRunId });
  },
});
```

## Streaming from Outside a Task

If you specify a `target` run ID, you can pipe streams from anywhere (like a Next.js API route):

```ts  theme={null}
import { streams } from "@trigger.dev/sdk";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(req: Request) {
  const { messages, runId } = await req.json();

  const result = streamText({
    model: openai("gpt-4o"),
    messages,
  });

  // Pipe AI stream to a Trigger.dev run
  const { stream } = streams.pipe("ai-stream", result.toUIMessageStream(), {
    target: runId,
  });

  return new Response(stream as any, {
    headers: { "Content-Type": "text/event-stream" },
  });
}
```

## React Hook

Use the `useRealtimeStream` hook to subscribe to streams in your React components.

### With Defined Streams (Recommended)

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  // Pass the defined stream directly for full type safety
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 600,
    onData: (chunk) => {
      console.log("New chunk:", chunk); // chunk is typed!
    },
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### With Direct Stream Keys

If you prefer not to use defined streams, you can specify the stream key directly:

```tsx  theme={null}
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  const { parts, error } = useRealtimeStream<string>(runId, "ai-output", {
    accessToken,
    timeoutInSeconds: 600,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### Using Default Stream

```tsx  theme={null}
// Omit stream key to use the default stream
const { parts, error } = useRealtimeStream<string>(runId, {
  accessToken,
});
```

### Hook Options

```tsx  theme={null}
const { parts, error } = useRealtimeStream(streamDef, runId, {
  accessToken: "pk_...", // Required: Public access token
  baseURL: "https://api.trigger.dev", // Optional: Custom API URL
  timeoutInSeconds: 60, // Optional: Timeout (default: 60)
  startIndex: 0, // Optional: Start from specific chunk
  throttleInMs: 16, // Optional: Throttle updates (default: 16ms)
  onData: (chunk) => {}, // Optional: Callback for each chunk
});
```

## Complete Example: AI Streaming

### Define the stream

```ts  theme={null}
// app/streams.ts
import { streams, InferStreamType } from "@trigger.dev/sdk";
import { UIMessageChunk } from "ai";

export const aiStream = streams.define<UIMessageChunk>({
  id: "ai",
});

export type AIStreamPart = InferStreamType<typeof aiStream>;
```

### Create the task

```ts  theme={null}
// trigger/ai-task.ts
import { task } from "@trigger.dev/sdk";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";
import { aiStream } from "@/app/streams";

export const generateAI = task({
  id: "generate-ai",
  run: async (payload: { prompt: string }) => {
    const result = streamText({
      model: openai("gpt-4o"),
      prompt: payload.prompt,
    });

    const { waitUntilComplete } = aiStream.pipe(result.toUIMessageStream());

    await waitUntilComplete();

    return { success: true };
  },
});
```

### Frontend component

```tsx  theme={null}
// components/ai-stream.tsx
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function AIStream({ accessToken, runId }: { accessToken: string; runId: string }) {
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 300,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div className="prose">
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

## Migration from v1

If you're using the old `metadata.stream()` API, here's how to migrate to the recommended v2 approach:

### Step 1: Define Your Streams

Create a shared streams definition file:

```ts  theme={null}
// app/streams.ts or trigger/streams.ts
import { streams, InferStreamType } from "@trigger.dev/sdk";

export const myStream = streams.define<string>({
  id: "my-stream",
});

export type MyStreamPart = InferStreamType<typeof myStream>;
```

### Step 2: Update Your Tasks

Replace `metadata.stream()` with the defined stream's `pipe()` method:

```ts  theme={null}
// Before (v1)
import { metadata, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();
    await metadata.stream("my-stream", stream);
  },
});
```

```ts  theme={null}
// After (v2 - Recommended)
import { task } from "@trigger.dev/sdk";
import { myStream } from "./streams";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();

    // Don't await - returns immediately
    const { waitUntilComplete } = myStream.pipe(stream);

    // Optionally wait for completion
    await waitUntilComplete();
  },
});
```

### Step 3: Update Your Frontend

Use the defined stream with `useRealtimeStream`:

```tsx  theme={null}
// Before
const { parts, error } = useRealtimeStream<string>(runId, "my-stream", {
  accessToken,
});
```

```tsx  theme={null}
// After
import { myStream } from "@/app/streams";

const { parts, error } = useRealtimeStream(myStream, runId, {
  accessToken,
});
```

### Alternative: Direct Methods (Not Recommended)

If you prefer not to use defined streams, you can use direct methods:

```ts  theme={null}
import { streams, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();
    const { waitUntilComplete } = streams.pipe("my-stream", stream);
    await waitUntilComplete();
  },
});
```

## Reliability Features

Streams v2 includes automatic reliability improvements:

* **Automatic resumption**: If a connection is lost, both appending and reading will automatically resume from the last successful chunk
* **No data loss**: Network issues won't cause stream data to be lost
* **Idempotent operations**: Duplicate chunks are automatically handled

These improvements happen automatically - no code changes needed.

## Dashboard Integration

Streams are now visible in the Trigger.dev dashboard, allowing you to:

* View stream data in real-time as it's generated
* Inspect historical stream data for completed runs
* Debug streaming issues with full visibility into chunk delivery

<video src="https://content.trigger.dev/streams-v2-dashboard.mp4" controls muted autoPlay loop />

## Best Practices

1. **Always use `streams.define()`**: Define your streams in a shared location for better organization, type safety, and code reusability. This is the recommended approach for all streams.
2. **Export stream types**: Use `InferStreamType` to export types for your frontend components
3. **Handle errors gracefully**: Always check for errors when reading streams in your UI
4. **Set appropriate timeouts**: Adjust `timeoutInSeconds` based on your use case (AI completions may need longer timeouts)
5. **Target parent runs**: When orchestrating with child tasks, pipe to parent runs for easier consumption
6. **Throttle frontend updates**: Use `throttleInMs` in `useRealtimeStream` to prevent excessive re-renders
7. **Use descriptive stream IDs**: Choose clear, descriptive IDs like `"ai-output"` or `"progress"` instead of generic names

## Troubleshooting

### Stream not appearing in dashboard

* Ensure you've enabled Streams v2 via the future flag or environment variable
* Verify your task is actually writing to the stream
* Check that the stream key matches between writing and reading

### Stream timeout errors

* Increase `timeoutInSeconds` in your `read()` or `useRealtimeStream()` calls
* Ensure your stream source is actively producing data
* Check network connectivity between your application and Trigger.dev

### Missing chunks

* With v2, chunks should never be lost due to automatic resumption
* Verify you're reading from the correct stream key
* Check the `startIndex` option if you're not seeing expected chunks


# Triggering
Source: https://trigger.dev/docs/triggering

Tasks need to be triggered in order to run.

## Trigger functions

Trigger tasks **from your backend**:

| Function               | What it does                                                                                     |                             |
| :--------------------- | :----------------------------------------------------------------------------------------------- | --------------------------- |
| `tasks.trigger()`      | Triggers a task and returns a handle you can use to fetch and manage the run.                    | [Docs](#tasks-trigger)      |
| `tasks.batchTrigger()` | Triggers a single task in a batch and returns a handle you can use to fetch and manage the runs. | [Docs](#tasks-batchtrigger) |
| `batch.trigger()`      | Similar to `tasks.batchTrigger` but allows running multiple different tasks                      | [Docs](#batch-trigger)      |

Trigger tasks **from inside a another task**:

| Function                         | What it does                                                                                                                       |                                       |
| :------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------- |
| `yourTask.trigger()`             | Triggers a task and gets a handle you can use to monitor and manage the run. It does not wait for the result.                      | [Docs](#yourtask-trigger)             |
| `yourTask.batchTrigger()`        | Triggers a task multiple times and gets a handle you can use to monitor and manage the runs. It does not wait for the results.     | [Docs](#yourtask-batchtrigger)        |
| `yourTask.triggerAndWait()`      | Triggers a task and then waits until it's complete. You get the result data to continue with.                                      | [Docs](#yourtask-triggerandwait)      |
| `yourTask.batchTriggerAndWait()` | Triggers a task multiple times in parallel and then waits until they're all complete. You get the resulting data to continue with. | [Docs](#yourtask-batchtriggerandwait) |
| `batch.triggerAndWait()`         | Similar to `batch.trigger` but will wait on the triggered tasks to finish and return the results.                                  | [Docs](#batch-triggerandwait)         |
| `batch.triggerByTask()`          | Similar to `batch.trigger` but allows passing in task instances instead of task IDs.                                               | [Docs](#batch-triggerbytask)          |
| `batch.triggerByTaskAndWait()`   | Similar to `batch.triggerbyTask` but will wait on the triggered tasks to finish and return the results.                            | [Docs](#batch-triggerbytaskandwait)   |

## Triggering from your backend

When you trigger a task from your backend code, you need to set the `TRIGGER_SECRET_KEY` environment variable. If you're [using a preview branch](/deployment/preview-branches), you also need to set the `TRIGGER_PREVIEW_BRANCH` environment variable. You can find the value on the API keys page in the Trigger.dev dashboard. [More info on API keys](/apikeys).

<Note>
  If you are using Next.js Server Actions [you'll need to be careful with
  bundling](/guides/frameworks/nextjs#triggering-your-task-in-next-js).
</Note>

### tasks.trigger()

Triggers a single run of a task with the payload you pass in, and any options you specify, without needing to import the task.

<Note>
  By using `tasks.trigger()`, you can pass in the task type as a generic argument, giving you full
  type checking. Make sure you use a `type` import so that your task code is not imported into your
  application.
</Note>

```ts Your backend theme={null}
import { tasks } from "@trigger.dev/sdk";
import type { emailSequence } from "~/trigger/emails";
//     ðŸ‘† **type-only** import

//app/email/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass the task type to `trigger()` as a generic argument, giving you full type checking
  const handle = await tasks.trigger<typeof emailSequence>("email-sequence", {
    to: data.email,
    name: data.name,
  });

  //return a success response with the handle
  return Response.json(handle);
}
```

You can pass in options to the task using the third argument:

```ts Your backend theme={null}
import { tasks } from "@trigger.dev/sdk";
import type { emailSequence } from "~/trigger/emails";

//app/email/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass the task type to `trigger()` as a generic argument, giving you full type checking
  const handle = await tasks.trigger<typeof emailSequence>(
    "email-sequence",
    {
      to: data.email,
      name: data.name,
    },
    { delay: "1h" } // ðŸ‘ˆ Pass in the options here
  );

  //return a success response with the handle
  return Response.json(handle);
}
```

### tasks.batchTrigger()

Triggers multiple runs of a single task with the payloads you pass in, and any options you specify, without needing to import the task.

```ts Your backend theme={null}
import { tasks } from "@trigger.dev/sdk";
import type { emailSequence } from "~/trigger/emails";
//     ðŸ‘† **type-only** import

//app/email/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass the task type to `batchTrigger()` as a generic argument, giving you full type checking
  const batchHandle = await tasks.batchTrigger<typeof emailSequence>(
    "email-sequence",
    data.users.map((u) => ({ payload: { to: u.email, name: u.name } }))
  );

  //return a success response with the handle
  return Response.json(batchHandle);
}
```

You can pass in options to the `batchTrigger` function using the third argument:

```ts Your backend theme={null}
import { tasks } from "@trigger.dev/sdk";
import type { emailSequence } from "~/trigger/emails";

//app/email/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass the task type to `batchTrigger()` as a generic argument, giving you full type checking
  const batchHandle = await tasks.batchTrigger<typeof emailSequence>(
    "email-sequence",
    data.users.map((u) => ({ payload: { to: u.email, name: u.name } })),
    { idempotencyKey: "my-idempotency-key" } // ðŸ‘ˆ Pass in the options here
  );

  //return a success response with the handle
  return Response.json(batchHandle);
}
```

You can also pass in options for each run in the batch:

```ts Your backend theme={null}
import { tasks } from "@trigger.dev/sdk";
import type { emailSequence } from "~/trigger/emails";

//app/email/route.ts
export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass the task type to `batchTrigger()` as a generic argument, giving you full type checking
  const batchHandle = await tasks.batchTrigger<typeof emailSequence>(
    "email-sequence",
    data.users.map((u) => ({ payload: { to: u.email, name: u.name }, options: { delay: "1h" } })) // ðŸ‘ˆ Pass in options to each item like so
  );

  //return a success response with the handle
  return Response.json(batchHandle);
}
```

### batch.trigger()

Triggers multiple runs of different tasks with the payloads you pass in, and any options you specify. This is useful when you need to trigger multiple tasks at once.

```ts Your backend theme={null}
import { batch } from "@trigger.dev/sdk";
import type { myTask1, myTask2 } from "~/trigger/myTasks";

export async function POST(request: Request) {
  //get the JSON from the request
  const data = await request.json();

  // Pass a union of the tasks to `trigger()` as a generic argument, giving you full type checking
  const result = await batch.trigger<typeof myTask1 | typeof myTask2>([
    // Because we're using a union, we can pass in multiple tasks by ID
    { id: "my-task-1", payload: { some: data.some } },
    { id: "my-task-2", payload: { other: data.other } },
  ]);

  //return a success response with the result
  return Response.json(result);
}
```

## Triggering from inside another task

The following functions should only be used when running inside a task, for one of the following reasons:

* You need to **wait** for the result of the triggered task.
* You need to import the task instance. Importing a task instance from your backend code is not recommended, as it can pull in a lot of unnecessary code and dependencies.

### yourTask.trigger()

Triggers a single run of a task with the payload you pass in, and any options you specify.

<Note>
  If you need to call `trigger()` on a task in a loop, use
  [`batchTrigger()`](#yourTask-batchtrigger) instead which will trigger up to 500 runs in a single
  call.
</Note>

```ts ./trigger/my-task.ts theme={null}
import { runs } from "@trigger.dev/sdk";
import { myOtherTask } from "~/trigger/my-other-task";

export const myTask = task({
  id: "my-task",
  run: async (payload: string) => {
    const handle = await myOtherTask.trigger({ foo: "some data" });

    const run = await runs.retrieve(handle);
    // Do something with the run
  },
});
```

To pass options to the triggered task, you can use the second argument:

```ts ./trigger/my-task.ts theme={null}
import { runs } from "@trigger.dev/sdk";
import { myOtherTask } from "~/trigger/my-other-task";

export const myTask = task({
  id: "my-task",
  run: async (payload: string) => {
    const handle = await myOtherTask.trigger({ foo: "some data" }, { delay: "1h" });

    const run = await runs.retrieve(handle);
    // Do something with the run
  },
});
```

### yourTask.batchTrigger()

Triggers multiple runs of a single task with the payloads you pass in, and any options you specify.

```ts /trigger/my-task.ts theme={null}
import { batch } from "@trigger.dev/sdk";
import { myOtherTask } from "~/trigger/my-other-task";

export const myTask = task({
  id: "my-task",
  run: async (payload: string) => {
    const batchHandle = await myOtherTask.batchTrigger([{ payload: "some data" }]);

    //...do other stuff
    const batch = await batch.retrieve(batchHandle.id);
  },
});
```

If you need to pass options to `batchTrigger`, you can use the second argument:

```ts /trigger/my-task.ts theme={null}
import { batch } from "@trigger.dev/sdk";
import { myOtherTask } from "~/trigger/my-other-task";

export const myTask = task({
  id: "my-task",
  run: async (payload: string) => {
    const batchHandle = await myOtherTask.batchTrigger([{ payload: "some data" }], {
      idempotencyKey: "my-task-key",
    });

    //...do other stuff
    const batch = await batch.retrieve(batchHandle.id);
  },
});
```

You can also pass in options for each run in the batch:

```ts /trigger/my-task.ts theme={null}
import { batch } from "@trigger.dev/sdk";
import { myOtherTask } from "~/trigger/my-other-task";

export const myTask = task({
  id: "my-task",
  run: async (payload: string) => {
    const batchHandle = await myOtherTask.batchTrigger([
      { payload: "some data", options: { delay: "1h" } },
    ]);

    //...do other stuff
    const batch = await batch.retrieve(batchHandle.id);
  },
});
```

### yourTask.triggerAndWait()

This is where it gets interesting. You can trigger a task and then wait for the result. This is useful when you need to call a different task and then use the result to continue with your task.

<Accordion title="Don't use this in parallel, e.g. with `Promise.all()`">
  Instead, use `batchTriggerAndWait()` if you can, or a for loop if you can't.

  To control concurrency using batch triggers, you can set `queue.concurrencyLimit` on the child task.

  <CodeGroup>
    ```ts /trigger/batch.ts theme={null}
    export const batchTask = task({
      id: "batch-task",
      run: async (payload: string) => {
        const results = await childTask.batchTriggerAndWait([
          { payload: "item1" },
          { payload: "item2" },
        ]);
        console.log("Results", results);

        //...do stuff with the results
      },
    });
    ```

    ```ts /trigger/loop.ts theme={null}
    export const loopTask = task({
      id: "loop-task",
      run: async (payload: string) => {
        //this will be slower than the batch version
        //as we have to resume the parent after each iteration
        for (let i = 0; i < 2; i++) {
          const result = await childTask.triggerAndWait(`item${i}`);
          console.log("Result", result);

          //...do stuff with the result
        }
      },
    });
    ```
  </CodeGroup>
</Accordion>

```ts /trigger/parent.ts theme={null}
export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const result = await childTask.triggerAndWait("some-data");
    console.log("Result", result);

    //...do stuff with the result
  },
});
```

The `result` object is a "Result" type that needs to be checked to see if the child task run was successful:

```ts /trigger/parent.ts theme={null}
export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const result = await childTask.triggerAndWait("some-data");

    if (result.ok) {
      console.log("Result", result.output); // result.output is the typed return value of the child task
    } else {
      console.error("Error", result.error); // result.error is the error that caused the run to fail
    }
  },
});
```

If instead you just want to get the output of the child task, and throw an error if the child task failed, you can use the `unwrap` method:

```ts /trigger/parent.ts theme={null}
export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const output = await childTask.triggerAndWait("some-data").unwrap();
    console.log("Output", output);
  },
});
```

You can also catch the error if the child task fails and get more information about the error:

```ts /trigger/parent.ts theme={null}
import { task, SubtaskUnwrapError } from "@trigger.dev/sdk";
export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    try {
      const output = await childTask.triggerAndWait("some-data").unwrap();
      console.log("Output", output);
    } catch (error) {
      if (error instanceof SubtaskUnwrapError) {
        console.error("Error in fetch-post-task", {
          runId: error.runId,
          taskId: error.taskId,
          cause: error.cause,
        });
      }
    }
  },
});
```

<Warning>
  This method should only be used inside a task. If you use it outside a task, it will throw an
  error.
</Warning>

### yourTask.batchTriggerAndWait()

You can batch trigger a task and wait for all the results. This is useful for the fan-out pattern, where you need to call a task multiple times and then wait for all the results to continue with your task.

<Accordion title="Don't use this in parallel, e.g. with `Promise.all()`">
  Instead, pass in all items at once and set an appropriate `maxConcurrency`. Alternatively, use sequentially with a for loop.

  To control concurrency, you can set `queue.concurrencyLimit` on the child task.

  <CodeGroup>
    ```ts /trigger/batch.ts theme={null}
    export const batchTask = task({
      id: "batch-task",
      run: async (payload: string) => {
        const results = await childTask.batchTriggerAndWait([
          { payload: "item1" },
          { payload: "item2" },
        ]);
        console.log("Results", results);

        //...do stuff with the results
      },
    });
    ```

    ```ts /trigger/loop.ts theme={null}
    export const loopTask = task({
      id: "loop-task",
      run: async (payload: string) => {
        //this will be slower than a single batchTriggerAndWait()
        //as we have to resume the parent after each iteration
        for (let i = 0; i < 2; i++) {
          const result = await childTask.batchTriggerAndWait([
            { payload: `itemA${i}` },
            { payload: `itemB${i}` },
          ]);
          console.log("Result", result);

          //...do stuff with the result
        }
      },
    });
    ```
  </CodeGroup>
</Accordion>

<Accordion title="How to handle run failures">
  When using `batchTriggerAndWait`, you have full control over how to handle failures within the batch. The method returns an array of run results, allowing you to inspect each run's outcome individually and implement custom error handling.

  Here's how you can manage run failures:

  1. **Inspect individual run results**: Each run in the returned array has an `ok` property indicating success or failure.

  2. **Access error information**: For failed runs, you can examine the `error` property to get details about the failure.

  3. **Choose your failure strategy**: You have two main options:

     * **Fail the entire batch**: Throw an error if any run fails, causing the parent task to reattempt.
     * **Continue despite failures**: Process the results without throwing an error, allowing the parent task to continue.

  4. **Implement custom logic**: You can create sophisticated handling based on the number of failures, types of errors, or other criteria.

  Here's an example of how you might handle run failures:

  <CodeGroup>
    ```ts /trigger/batchTriggerAndWait.ts theme={null}
    const result = await batchChildTask.batchTriggerAndWait([
      { payload: "item1" },
      { payload: "item2" },
      { payload: "item3" },
    ]);

    // Result will contain the finished runs.
    // They're only finished if they have succeeded or failed.
    // "Failed" means all attempts failed

    for (const run of result.runs) {
      // Check if the run succeeded
      if (run.ok) {
        logger.info("Batch task run succeeded", { output: run.output });
      } else {
        logger.error("Batch task run error", { error: run.error });

        //You can choose if you want to throw an error and fail the entire run
        throw new Error(`Fail the entire run because ${run.id} failed`);
      }
    }
    ```
  </CodeGroup>
</Accordion>

```ts /trigger/nested.ts theme={null}
export const batchParentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const results = await childTask.batchTriggerAndWait([
      { payload: "item4" },
      { payload: "item5" },
      { payload: "item6" },
    ]);
    console.log("Results", results);

    //...do stuff with the result
  },
});
```

<Warning>
  This method should only be used inside a task. If you use it outside a task, it will throw an
  error.
</Warning>

### batch.triggerAndWait()

You can batch trigger multiple different tasks and wait for all the results:

```ts /trigger/batch.ts theme={null}
import { batch, task } from "@trigger.dev/sdk";

export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    //                                         ðŸ‘‡ Pass a union of all the tasks you want to trigger
    const results = await batch.triggerAndWait<typeof childTask1 | typeof childTask2>([
      { id: "child-task-1", payload: { foo: "World" } }, // ðŸ‘ˆ The payload is typed correctly based on the task `id`
      { id: "child-task-2", payload: { bar: 42 } }, // ðŸ‘ˆ The payload is typed correctly based on the task `id`
    ]);

    for (const result of results) {
      if (result.ok) {
        // ðŸ‘‡ Narrow the type of the result based on the taskIdentifier
        switch (result.taskIdentifier) {
          case "child-task-1":
            console.log("Child task 1 output", result.output); // ðŸ‘ˆ result.output is typed as a string
            break;
          case "child-task-2":
            console.log("Child task 2 output", result.output); // ðŸ‘ˆ result.output is typed as a number
            break;
        }
      } else {
        console.error("Error", result.error); // ðŸ‘ˆ result.error is the error that caused the run to fail
      }
    }
  },
});

export const childTask1 = task({
  id: "child-task-1",
  run: async (payload: { foo: string }) => {
    return `Hello ${payload}`;
  },
});

export const childTask2 = task({
  id: "child-task-2",
  run: async (payload: { bar: number }) => {
    return bar + 1;
  },
});
```

### batch.triggerByTask()

You can batch trigger multiple different tasks by passing in the task instances. This function is especially useful when you have a static set of tasks you want to trigger:

```ts /trigger/batch.ts theme={null}
import { batch, task, runs } from "@trigger.dev/sdk";

export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const results = await batch.triggerByTask([
      { task: childTask1, payload: { foo: "World" } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
      { task: childTask2, payload: { bar: 42 } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
    ]);

    // ðŸ‘‡ results.runs is a tuple, allowing you to get type safety without needing to narrow
    const run1 = await runs.retrieve(results.runs[0]); // ðŸ‘ˆ run1 is typed as the output of childTask1
    const run2 = await runs.retrieve(results.runs[1]); // ðŸ‘ˆ run2 is typed as the output of childTask2
  },
});

export const childTask1 = task({
  id: "child-task-1",
  run: async (payload: { foo: string }) => {
    return `Hello ${payload}`;
  },
});

export const childTask2 = task({
  id: "child-task-2",
  run: async (payload: { bar: number }) => {
    return bar + 1;
  },
});
```

### batch.triggerByTaskAndWait()

You can batch trigger multiple different tasks by passing in the task instances, and wait for all the results. This function is especially useful when you have a static set of tasks you want to trigger:

```ts /trigger/batch.ts theme={null}
import { batch, task, runs } from "@trigger.dev/sdk";

export const parentTask = task({
  id: "parent-task",
  run: async (payload: string) => {
    const { runs } = await batch.triggerByTaskAndWait([
      { task: childTask1, payload: { foo: "World" } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
      { task: childTask2, payload: { bar: 42 } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
    ]);

    if (runs[0].ok) {
      console.log("Child task 1 output", runs[0].output); // ðŸ‘ˆ runs[0].output is typed as the output of childTask1
    }

    if (runs[1].ok) {
      console.log("Child task 2 output", runs[1].output); // ðŸ‘ˆ runs[1].output is typed as the output of childTask2
    }

    // ðŸ’­ A nice alternative syntax is to destructure the runs array:
    const {
      runs: [run1, run2],
    } = await batch.triggerByTaskAndWait([
      { task: childTask1, payload: { foo: "World" } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
      { task: childTask2, payload: { bar: 42 } }, // ðŸ‘ˆ The payload is typed correctly based on the task instance
    ]);

    if (run1.ok) {
      console.log("Child task 1 output", run1.output); // ðŸ‘ˆ run1.output is typed as the output of childTask1
    }

    if (run2.ok) {
      console.log("Child task 2 output", run2.output); // ðŸ‘ˆ run2.output is typed as the output of childTask2
    }
  },
});

export const childTask1 = task({
  id: "child-task-1",
  run: async (payload: { foo: string }) => {
    return `Hello ${payload}`;
  },
});

export const childTask2 = task({
  id: "child-task-2",
  run: async (payload: { bar: number }) => {
    return bar + 1;
  },
});
```

## Triggering from your frontend

If you want to trigger a task directly from a frontend application, you can use our [React
hooks](/realtime/react-hooks/triggering).

## Options

All of the above functions accept an options object:

```ts  theme={null}
await myTask.trigger({ some: "data" }, { delay: "1h", ttl: "1h" });
await myTask.batchTrigger([{ payload: { some: "data" }, options: { delay: "1h" } }]);
```

The following options are available:

### `delay`

When you want to trigger a task now, but have it run at a later time, you can use the `delay` option:

```ts  theme={null}
// Delay the task run by 1 hour
await myTask.trigger({ some: "data" }, { delay: "1h" });
// Delay the task run by 88 seconds
await myTask.trigger({ some: "data" }, { delay: "88s" });
// Delay the task run by 1 hour and 52 minutes and 18 seconds
await myTask.trigger({ some: "data" }, { delay: "1h52m18s" });
// Delay until a specific time
await myTask.trigger({ some: "data" }, { delay: "2024-12-01T00:00:00" });
// Delay using a Date object
await myTask.trigger({ some: "data" }, { delay: new Date(Date.now() + 1000 * 60 * 60) });
// Delay using a timezone
await myTask.trigger({ some: "data" }, { delay: new Date("2024-07-23T11:50:00+02:00") });
```

Runs that are delayed and have not been enqueued yet will display in the dashboard with a "Delayed" status:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=38620549a2c6e61c37b4a8101b89f5d7" alt="Delayed run in the dashboard" data-og-width="1134" width="1134" data-og-height="200" height="200" data-path="images/delayed-runs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=79400cc072f698650aa953a6e049c94a 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=363695b013020cc0028c73247861ded3 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=366cf60b4ed03a71917fd46df9a381e5 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=0216d073946e5282d84650d81f07e8ac 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=6d77990fce1c4bdcb6444530f24ca7e8 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/delayed-runs.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=8a0e272b23ace6a933949758994b9fad 2500w" />

<Note>
  Delayed runs will be enqueued at the time specified, and will run as soon as possible after that
  time, just as a normally triggered run would.
</Note>

You can cancel a delayed run using the `runs.cancel` SDK function:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

await runs.cancel("run_1234");
```

You can also reschedule a delayed run using the `runs.reschedule` SDK function:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

// The delay option here takes the same format as the trigger delay option
await runs.reschedule("run_1234", { delay: "1h" });
```

The `delay` option is also available when using `batchTrigger`:

```ts  theme={null}
await myTask.batchTrigger([{ payload: { some: "data" }, options: { delay: "1h" } }]);
```

### `ttl`

You can set a TTL (time to live) when triggering a task, which will automatically expire the run if it hasn't started within the specified time. This is useful for ensuring that a run doesn't get stuck in the queue for too long.

<Note>
  All runs in development have a default `ttl` of 10 minutes. You can disable this by setting the
  `ttl` option.
</Note>

```ts  theme={null}
import { myTask } from "./trigger/myTasks";

// Expire the run if it hasn't started within 1 hour
await myTask.trigger({ some: "data" }, { ttl: "1h" });

// If you specify a number, it will be treated as seconds
await myTask.trigger({ some: "data" }, { ttl: 3600 }); // 1 hour
```

When a run is expired, it will be marked as "Expired" in the dashboard:

<img src="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=d984afe341eaacbe47b698dade27e445" alt="Expired runs in the dashboard" data-og-width="1364" width="1364" data-og-height="316" height="316" data-path="images/expired-runs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=280&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=33cefd04968f559f47ccb1fff85813fe 280w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=560&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=08409ef7f1fe02dc5aef3d13a8ce0fda 560w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=840&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9694db79f948a51792ac50d781e251a0 840w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=1100&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=899a2f4e90e3f0dbde8c1e3e42cfe42f 1100w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=1650&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=9d493a433aaf988c62e58bd036b2f802 1650w, https://mintcdn.com/trigger/uys6iMwf9B_ojh8r/images/expired-runs.png?w=2500&fit=max&auto=format&n=uys6iMwf9B_ojh8r&q=85&s=eb0e94a36fdb1d7d8e1adba0a0b2fd33 2500w" />

When you use both `delay` and `ttl`, the TTL will start counting down from the time the run is enqueued, not from the time the run is triggered.

So for example, when using the following code:

```ts  theme={null}
await myTask.trigger({ some: "data" }, { delay: "10m", ttl: "1h" });
```

The timeline would look like this:

1. The run is created at 12:00:00
2. The run is enqueued at 12:10:00
3. The TTL starts counting down from 12:10:00
4. If the run hasn't started by 13:10:00, it will be expired

For this reason, the `ttl` option only accepts durations and not absolute timestamps.

### `idempotencyKey`

You can provide an `idempotencyKey` to ensure that a task is only triggered once with the same key. This is useful if you are triggering a task within another task that might be retried:

```typescript  theme={null}
import { idempotencyKeys, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 4,
  },
  run: async (payload: any) => {
    // By default, idempotency keys generated are unique to the run, to prevent retries from duplicating child tasks
    const idempotencyKey = await idempotencyKeys.create("my-task-key");

    // childTask will only be triggered once with the same idempotency key
    await childTask.trigger(payload, { idempotencyKey });

    // Do something else, that may throw an error and cause the task to be retried
  },
});
```

For more information, see our [Idempotency](/idempotency) documentation.

<Warning>
  In version 3.3.0 and later, the `idempotencyKey` option is not available when using
  `triggerAndWait` or `batchTriggerAndWait`, due to a bug that would sometimes cause the parent task
  to become stuck. We are working on a fix for this issue.
</Warning>

### `idempotencyKeyTTL`

Idempotency keys automatically expire after 30 days, but you can set a custom TTL for an idempotency key when triggering a task:

```typescript  theme={null}
import { idempotencyKeys, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  retry: {
    maxAttempts: 4,
  },
  run: async (payload: any) => {
    // By default, idempotency keys generated are unique to the run, to prevent retries from duplicating child tasks
    const idempotencyKey = await idempotencyKeys.create("my-task-key");

    // childTask will only be triggered once with the same idempotency key
    await childTask.trigger(payload, { idempotencyKey, idempotencyKeyTTL: "1h" });

    // Do something else, that may throw an error and cause the task to be retried
  },
});
```

For more information, see our [Idempotency](/idempotency) documentation.

### `queue`

When you trigger a task you can override the concurrency limit. This is really useful if you sometimes have high priority runs.

The task:

```ts /trigger/override-concurrency.ts theme={null}
const generatePullRequest = task({
  id: "generate-pull-request",
  queue: {
    //normally when triggering this task it will be limited to 1 run at a time
    concurrencyLimit: 1,
  },
  run: async (payload) => {
    //todo generate a PR using OpenAI
  },
});
```

Triggering from your backend and overriding the concurrency:

```ts app/api/push/route.ts theme={null}
import { generatePullRequest } from "~/trigger/override-concurrency";

export async function POST(request: Request) {
  const data = await request.json();

  if (data.branch === "main") {
    //trigger the task, with a different queue
    const handle = await generatePullRequest.trigger(data, {
      queue: {
        //the "main-branch" queue will have a concurrency limit of 10
        //this triggered run will use that queue
        name: "main-branch",
        concurrencyLimit: 10,
      },
    });

    return Response.json(handle);
  } else {
    //triggered with the default (concurrency of 1)
    const handle = await generatePullRequest.trigger(data);
    return Response.json(handle);
  }
}
```

### `concurrencyKey`

If you're building an application where you want to run tasks for your users, you might want a separate queue for each of your users. (It doesn't have to be users, it can be any entity you want to separately limit the concurrency for.)

You can do this by using `concurrencyKey`. It creates a separate queue for each value of the key.

Your backend code:

```ts app/api/pr/route.ts theme={null}
import { generatePullRequest } from "~/trigger/override-concurrency";

export async function POST(request: Request) {
  const data = await request.json();

  if (data.isFreeUser) {
    //free users can only have 1 PR generated at a time
    const handle = await generatePullRequest.trigger(data, {
      queue: {
        //every free user gets a queue with a concurrency limit of 1
        name: "free-users",
        concurrencyLimit: 1,
      },
      concurrencyKey: data.userId,
    });

    //return a success response with the handle
    return Response.json(handle);
  } else {
    //trigger the task, with a different queue
    const handle = await generatePullRequest.trigger(data, {
      queue: {
        //every paid user gets a queue with a concurrency limit of 10
        name: "paid-users",
        concurrencyLimit: 10,
      },
      concurrencyKey: data.userId,
    });

    //return a success response with the handle
    return Response.json(handle);
  }
}
```

### `maxAttempts`

You can set the maximum number of attempts for a task run. If the run fails, it will be retried up to the number of attempts you specify.

```ts  theme={null}
await myTask.trigger({ some: "data" }, { maxAttempts: 3 });
await myTask.trigger({ some: "data" }, { maxAttempts: 1 }); // no retries
```

This will override the `retry.maxAttempts` value set in the task definition.

### `tags`

View our [tags doc](/tags) for more information.

### `metadata`

View our [metadata doc](/runs/metadata) for more information.

### `maxDuration`

View our [maxDuration doc](/runs/max-duration) for more information.

### `priority`

View our [priority doc](/runs/priority) for more information.

### `region`

You can override the default region when you trigger a run:

```ts  theme={null}
await yourTask.trigger(payload, { region: "eu-central-1" });
```

If you don't specify a region it will use the default for your project. Go to the "Regions" page in the dashboard to see available regions or switch your default.

The region is where your runs are executed, it does not change where the run payload, output, tags, logs, or are any other data is stored.

### `machine`

You can override the default machine preset when you trigger a run:

```ts  theme={null}
await yourTask.trigger(payload, { machine: "large-1x" });
```

If you don't specify a machine it will use the machine preset for your task (or the default for your project). For more information read [the machines guide](/machines).

## Large Payloads

We recommend keeping your task payloads as small as possible. We currently have a hard limit on task payloads above 10MB.

If your payload size is larger than 512KB, instead of saving the payload to the database, we will upload it to an S3-compatible object store and store the URL in the database.

When your task runs, we automatically download the payload from the object store and pass it to your task function. We also will return to you a `payloadPresignedUrl` from the `runs.retrieve` SDK function so you can download the payload if needed:

```ts  theme={null}
import { runs } from "@trigger.dev/sdk";

const run = await runs.retrieve(handle);

if (run.payloadPresignedUrl) {
  const response = await fetch(run.payloadPresignedUrl);
  const payload = await response.json();

  console.log("Payload", payload);
}
```

<Note>
  We also use this same system for dealing with large task outputs, and subsequently will return a
  corresponding `outputPresignedUrl`. Task outputs are limited to 100MB.
</Note>

If you need to pass larger payloads, you'll need to upload the payload to your own storage and pass a URL to the file in the payload instead. For example, uploading to S3 and then sending a presigned URL that expires in URL:

<CodeGroup>
  ```ts /yourServer.ts theme={null}
  import { myTask } from "./trigger/myTasks";
  import { s3Client, getSignedUrl, PutObjectCommand, GetObjectCommand } from "./s3";
  import { createReadStream } from "node:fs";

  // Upload file to S3
  await s3Client.send(
    new PutObjectCommand({
      Bucket: "my-bucket",
      Key: "myfile.json",
      Body: createReadStream("large-payload.json"),
    })
  );

  // Create presigned URL
  const presignedUrl = await getSignedUrl(
    s3Client,
    new GetObjectCommand({
      Bucket: "my-bucket",
      Key: "my-file.json",
    }),
    {
      expiresIn: 3600, // expires in 1 hour
    }
  );

  // Now send the URL to the task
  const handle = await myTask.trigger({
    url: presignedUrl,
  });
  ```

  ```ts /trigger/myTasks.ts theme={null}
  import { task } from "@trigger.dev/sdk";

  export const myTask = task({
    id: "my-task",
    run: async (payload: { url: string }) => {
      // Download the file from the URL
      const response = await fetch(payload.url);
      const data = await response.json();

      // Do something with the data
    },
  });
  ```
</CodeGroup>

### Batch Triggering

When using triggering a batch, the total size of all payloads cannot exceed 1MB. This means if you are doing a batch of 100 runs, each payload should be less than 100KB. The max batch size is 500 runs.


# Common problems
Source: https://trigger.dev/docs/troubleshooting

Some common problems you might experience and their solutions

## Development

### `EACCES: permission denied`

If you see this error:

```
6090 verbose stack Error: EACCES: permission denied, rename '/Users/user/.npm/_cacache/tmp/f1bfea11' -> '/Users/user/.npm/_cacache/content-v2/sha512/31/d8/e094a47a0105d06fd246892ed1736c02eae323726ec6a3f34734eeb71308895dfba4f4f82a88ffe7e480c90b388c91fc3d9f851ba7b96db4dc33fbc65528'
```

First, clear the npm cache:

```sh  theme={null}
npm cache clean --force
```

Then change the permissions of the npm folder (if 1 doesn't work):

```sh  theme={null}
sudo chown -R $(whoami) ~/.npm
```

### Clear the build cache

Ensure you have stopped your local dev server then locate the hidden `.trigger` folder in your project and delete it. You can then restart your local dev server.

### Yarn Plug'n'Play conflicts

If you see errors like this when running `trigger.dev dev`:

```
Could not resolve "@trigger.dev/core"
The Yarn Plug'n'Play manifest forbids importing "@trigger.dev/core" here because it's not listed as a dependency of this package
```

And you're using Yarn v1.22 or another package manager, check if you have a `.pnp.cjs` file in your home directory. This can happen if you previously had Yarn Plug'n'Play enabled globally. Remove the `.pnp.cjs` file to resolve the issue.

## Deployment

Running the \[trigger.dev deploy] command builds and deploys your code. Sometimes there can be issues building your code.

You can run the deploy command with `--log-level debug` at the end. This will spit out a lot of information about the deploy. If you can't figure out the problem from the information below please join [our Discord](https://trigger.dev/discord) and create a help forum post. Do NOT share the extended debug logs publicly as they might reveal private information about your project.

You can also review the build by supplying the `--dry-run` flag. This will build your project but not deploy it. You can then inspect the build output on your machine.

Here are some common problems and their solutions:

### `Failed to build project image: Error building image`

There should be a link below the error message to the full build logs on your machine. Take a look at these to see what went wrong. Join [our Discord](https://trigger.dev/discord) and you share it privately with us if you can't figure out what's going wrong. Do NOT share these publicly as the verbose logs might reveal private information about your project.

### `Error: failed to solve: failed to resolve source metadata for docker.io/docker/dockerfile:1`

If you see this error after uninstalling Docker Desktop:

```
Error: failed to solve: failed to resolve source metadata for docker.io/docker/dockerfile:1: error getting credentials - err: exec: "docker-credential-desktop": executable file not found in $PATH
```

This happens because Docker Desktop left behind a config file that's still trying to use its credential store. To fix this, remove or update the `~/.docker/config.json` file. You don't need Docker Desktop installed to use Trigger.dev.

### `Deployment encountered an error`

Usually there will be some useful guidance below this message. If you can't figure out what's going wrong then join [our Discord](https://trigger.dev/discord) and create a Help forum post with a link to your deployment.

### `No loader is configured for ".node" files`

This happens because `.node` files are native code and can't be bundled like other packages. To fix this, add your package to [`build.external`](/config/config-file#external) in the `trigger.config.ts` file like this:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    external: ["your-node-package"],
  },
});
```

### `Cannot find module '/app/lib/worker.js"` when using pino

If you see this error, add pino (and any other associated packages) to your `external` build settings in your `trigger.config.ts` file. Learn more about the `external` setting in the [config docs](/config/config-file#external).

### `reactDOMServer.renderToPipeableStream is not a function` when using react-email

If you see this error when using `@react-email/render`:

```
TypeError: reactDOMServer.renderToPipeableStream is not a function
    at __spreadValues.selectors (file:///node_modules/.pnpm/@react-email+render@1.0.6_react-dom@19.0.0_react@19.0.0/node_modules/@react-email/render/dist/node/index.mjs:162:37)
```

This happens because react-email packages have bundling conflicts with our build process. To fix this, add the react-email packages to your `external` build settings in your `trigger.config.ts` file:

```ts trigger.config.ts theme={null}
import { defineConfig } from "@trigger.dev/sdk";

export default defineConfig({
  project: "<project ref>",
  // Your other config settings...
  build: {
    external: ["react", "react-dom", "@react-email/render", "@react-email/components"],
  },
});
```

### `Cannot find matching keyid`

This error occurs when using Node.js v22 with corepack, as it's not yet compatible with the latest package manager signatures. To fix this, either:

1. Downgrade to Node.js v20 (LTS), or
2. Install corepack globally: `npm i -g corepack@latest`

The corepack bug and workaround are detailed in [this issue](https://github.com/npm/cli/issues/8075).

## Project setup issues

### `The requested module 'node:events' does not provide an export named 'addAbortListener'`

If you see this error it means you're not a supported version of Node:

```
SyntaxError: The requested module 'node:events' does not provide an export named 'addAbortListener'
at ModuleJob._instantiate (node:internal/modules/esm/module_job:123:21)
at async ModuleJob.run (node:internal/modules/esm/module_job:189:5)

Node.js v19.9.0
```

You need to be on at least these minor versions:

| Version | Minimum |
| ------- | ------- |
| 18      | 18.20+  |
| 20      | 20.5+   |
| 21      | 21.0+   |
| 22      | 22.0+   |

## Runtime issues

### `Environment variable not found:`

Your code is deployed separately from the rest of your app(s) so you need to make sure that you set any environment variables you use in your tasks in the Trigger.dev dashboard. [Read the guide](/deploy-environment-variables).

### `Error: @prisma/client did not initialize yet.`

Prisma uses code generation to create the client from your schema file. This means you need to add a bit of config so we can generate this file before your tasks run: [Read the guide](/config/extensions/prismaExtension).

### `Parallel waits are not supported`

In the current version, you can't perform more that one "wait" in parallel.

Waits include:

* `wait.for()`
* `wait.until()`
* `task.triggerAndWait()`
* `task.batchTriggerAndWait()`
* And any of our functions with `wait` in the name.

This restriction exists because we suspend the task server after a wait, and resume it when the wait is done. At the moment, if you do more than one wait, the run will never continue when deployed, so we throw this error instead.

The most common situation this happens is if you're using `Promise.all` around some of our wait functions. Instead of doing this use our built-in functions for [triggering tasks](/triggering#triggering-from-inside-another-task). We have functions that allow you to trigger different tasks in parallel.

### When triggering subtasks the parent task finishes too soon

Make sure that you always use `await` when you call `trigger`, `triggerAndWait`, `batchTrigger`, and `batchTriggerAndWait`. If you don't then it's likely the task(s) won't be triggered because the calling function process can be terminated before the networks calls are sent.

### Rate limit exceeded

The most common cause of hitting the API rate limit is if youâ€™re calling `trigger()` on a task in a loop, instead of doing this use `batchTrigger()` which will trigger multiple tasks in a single API call. You can have up to 500 tasks in a single batch trigger call.

View the [rate limits](/limits) page for more information.

### `Crypto is not defined`

This can happen in different situations, for example when using plain strings as idempotency keys. Support for `Crypto` without a special flag was added in Node `v19.0.0`. You will have to upgrade Node - we recommend even-numbered major releases, e.g. `v20` or `v22`. Alternatively, you can switch from plain strings to the `idempotencyKeys.create` SDK function. [Read the guide](/idempotency).

### Task run stalled executing

If you see a `TASK_RUN_STALLED_EXECUTING` error it means that we didn't receive a heartbeat from your task before the stall timeout. We automatically heartbeat runs every 30 seconds, and the heartbeat timeout is 5 minutes.

<Note>
  If this was a dev run, then most likely the `trigger.dev dev` CLI was stopped, and it wasn't an issue with your code.
</Note>

These errors can happen when code inside your task is blocking the event loop for too long. The most likely cause would be an accidental infinite loop. It could also be a CPU-heavy operation that's blocking the event loop, like nested loops with very large arrays. We recommend reading the [Don't Block the Event Loop](https://nodejs.org/en/learn/asynchronous-work/dont-block-the-event-loop) guide from Node.js for common patterns that can cause this.

If you are doing a continuous CPU-heavy task, then we recommend you try using our `heartbeats.yield` function to automatically yield to the event loop periodically:

```ts  theme={null}
import { heartbeats } from "@trigger.dev/sdk";

// code inside your task
for (const row of bigDataset) {
  await heartbeats.yield(); // safe to call every iteration, we will only actually yield when we need to
  process(row); // this is a synchronous operation
}
```

<Note>
  You could also offload the CPU-heavy work to a Node.js worker thread, but this is more complex to setup currently. We are planning on adding support for this in the future.
</Note>

If the above doesn't work, then we recommend you try increasing the machine size of your task. See our [machines guide](/machines) for more information.

## Framework specific issues

### NestJS swallows all errors/exceptions

If you're using NestJS and you add code like this into your tasks you will prevent any errors from being surfaced:

```ts  theme={null}
export const simplestTask = task({
  id: "nestjs-example",
  run: async (payload) => {
    //by doing this you're swallowing any errors
    const app = await NestFactory.createApplicationContext(AppModule);
    await app.init();

    //etc...
  },
});
```

NestJS has a global exception filter that catches all errors and swallows them, so we can't receive them. Our current recommendation is to not use NestJS inside your tasks. If you're a NestJS user you can still use Trigger.dev but just don't use NestJS inside your tasks like this.

### React is not defined

If you see this error:

```
Worker failed to start ReferenceError: React is not defined
```

Either add this to your file:

```ts  theme={null}
import React from "react";
```

Or change the tsconfig jsx setting:

```json  theme={null}
{
  "compilerOptions": {
    //...
    "jsx": "react-jsx"
  }
}
```

### Next.js build failing due to missing API key in GitHub CI

This issue occurs during the Next.js app build process on GitHub CI where the Trigger.dev SDK is expecting the TRIGGER\_SECRET\_KEY environment variable to be set at build time. Next.js attempts to compile routes and creates static pages, which can cause issues with SDKs that require runtime environment variables. The solution is to mark the relevant pages as dynamic to prevent Next.js from trying to make them static. You can do this by adding the following line to the route file:

```ts  theme={null}
export const dynamic = "force-dynamic";
```

### Correctly passing event handlers to React components

An issue can sometimes arise when you try to pass a function directly to the `onClick` prop. This is because the function may require specific arguments or context that are not available when the event occurs. By wrapping the function call in an arrow function, you ensure that the handler is called with the correct context and any necessary arguments. For example:

This works:

```tsx  theme={null}
<Button onClick={() => myTask()}>Trigger my task</Button>
```

Whereas this does not work:

```tsx  theme={null}
<Button onClick={myTask}>Trigger my task</Button>
```


# Alerts
Source: https://trigger.dev/docs/troubleshooting-alerts

Get alerted when runs or deployments fail, or when deployments succeed.

We support receiving alerts for the following events:

* Run fails
* Deployment fails
* Deployment succeeds

## How to setup alerts

<Steps>
  <Step title="Create a new alert">
    Click on "Alerts" in the left hand side menu, then click on "New alert" to open the new alert modal.
    <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=66c28b50c37b92057afb4100948a6636" alt="Email alerts" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/troubleshooting-alerts-blank.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4b176aea4b6f3e15ffafca6e6929fa2d 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=7af7993456f897b29380e66137621443 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=095859343aefb995f836a40ecf8d637c 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=90f54ae0228df8ab27f24c1d0e2f5565 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=e1e789dd4b16aa5fc5e40572c68878c5 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-blank.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=6a45670b1c9e59da3cf3bfa6264af742 2500w" />
  </Step>

  <Step title="Choose your alert method">
    Choose to be notified by email, Slack notification or webhook whenever:

    * a run fails
    * a deployment fails
    * a deployment succeeds

      <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=69b2a564572a6b1fb1c5e3ee77d68c4a" alt="Email alerts" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/troubleshooting-alerts-modal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=3aaa12fe0241588d4f157848c12c60a9 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=d019d5515cecb2e093eff24458c9b18c 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=c2a0eefbce2ea17136c9ac531f2db3be 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=8bcfd8fcb725b464a6f26bd468c7907d 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=08cbccd0804107670b39370c6acaa828 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-modal.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f6289e4f7dde170ab8b5ad4dab7b3fd0 2500w" />
  </Step>

  <Step title="Delete or disable alerts">
    Click on the triple dot menu on the right side of the table row and select "Disable" or "Delete".

        <img src="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f3455ed01b0d4c7a66c855a3b7d0cc53" alt="Disable and delete alerts" data-og-width="1600" width="1600" data-og-height="900" height="900" data-path="images/troubleshooting-alerts-disable-delete.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=280&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=4a113eb9f70076a7e01425611f730ac4 280w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=560&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=c0b37bb579300563f46764736b233bf2 560w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=840&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=7651daf08e2fbaec97c7e31794814803 840w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=1100&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=0db4fa3993c9ef5bd1e4b853e1a2f07e 1100w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=1650&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=f1d0e716322507096dc7f4ffed03d3fe 1650w, https://mintcdn.com/trigger/0bD0UfsjaINxS6Tw/images/troubleshooting-alerts-disable-delete.png?w=2500&fit=max&auto=format&n=0bD0UfsjaINxS6Tw&q=85&s=ee5bf9572279a5a571b6cc33fc2d2a59 2500w" />
  </Step>
</Steps>

## Alert webhooks

For the alert webhooks you can use the SDK to parse them. Here is an example of how to parse the webhook payload in Remix:

```ts  theme={null}
import { ActionFunctionArgs, json } from "@remix-run/server-runtime";
import { webhooks, WebhookError } from "@trigger.dev/sdk";

export async function action({ request }: ActionFunctionArgs) {
  // Make sure this is a POST request
  if (request.method !== "POST") {
    return json({ error: "Method not allowed" }, { status: 405 });
  }

  try {
    // Construct and verify the webhook event
    // This secret can be found on your Alerts page when you create a webhook alert
    const event = await webhooks.constructEvent(request, process.env.ALERT_WEBHOOK_SECRET!);

    // Process the event based on its type
    switch (event.type) {
      case "alert.run.failed": {
        console.log("[Webhook Internal Test] Run failed alert webhook received", { event });
        break;
      }
      case "alert.deployment.success": {
        console.log("[Webhook Internal Test] Deployment success alert webhook received", { event });
        break;
      }
      case "alert.deployment.failed": {
        console.log("[Webhook Internal Test] Deployment failed alert webhook received", { event });
        break;
      }
      default: {
        console.log("[Webhook Internal Test] Unhandled webhook type", { event });
      }
    }

    // Return a success response
    return json({ received: true }, { status: 200 });
  } catch (err) {
    // Handle webhook errors
    if (err instanceof WebhookError) {
      console.error("Webhook error:", { message: err.message });
      return json({ error: err.message }, { status: 400 });
    }

    if (err instanceof Error) {
      console.error("Error processing webhook:", { message: err.message });
      return json({ error: err.message }, { status: 400 });
    }

    // Handle other errors
    console.error("Error processing webhook:", { err });
    return json({ error: "Internal server error" }, { status: 500 });
  }
}
```

### Common properties

When you create a webhook alert, you'll receive different payloads depending on the type of alert. All webhooks share some common properties:

<ParamField path="id" type="string">
  A unique identifier for this webhook event
</ParamField>

<ParamField path="created" type="datetime">
  When this webhook event was created
</ParamField>

<ParamField path="webhookVersion" type="string">
  The version of the webhook payload format
</ParamField>

<ParamField path="type" type="string">
  The type of alert webhook. One of: `alert.run.failed`, `alert.deployment.success`, or `alert.deployment.failed`
</ParamField>

### Run Failed Alert

This webhook is sent when a run fails. The payload is available on the `object` property:

<ParamField path="object.task.id" type="string">
  Unique identifier for the task
</ParamField>

<ParamField path="object.task.filePath" type="string">
  File path where the task is defined
</ParamField>

<ParamField path="object.task.exportName" type="string">
  Name of the exported task function
</ParamField>

<ParamField path="object.task.version" type="string">
  Version of the task
</ParamField>

<ParamField path="object.task.sdkVersion" type="string">
  Version of the SDK used
</ParamField>

<ParamField path="object.task.cliVersion" type="string">
  Version of the CLI used
</ParamField>

<ParamField path="object.run.id" type="string">
  Unique identifier for the run
</ParamField>

<ParamField path="object.run.number" type="number">
  Run number
</ParamField>

<ParamField path="object.run.status" type="string">
  Current status of the run
</ParamField>

<ParamField path="object.run.createdAt" type="datetime">
  When the run was created
</ParamField>

<ParamField path="object.run.startedAt" type="datetime">
  When the run started executing
</ParamField>

<ParamField path="object.run.completedAt" type="datetime">
  When the run finished executing
</ParamField>

<ParamField path="object.run.isTest" type="boolean">
  Whether this is a test run
</ParamField>

<ParamField path="object.run.idempotencyKey" type="string">
  Idempotency key for the run
</ParamField>

<ParamField path="object.run.tags" type="string[]">
  Associated tags
</ParamField>

<ParamField path="object.run.error" type="object">
  Error information
</ParamField>

<ParamField path="object.run.isOutOfMemoryError" type="boolean">
  Whether the run was an out-of-memory error
</ParamField>

<ParamField path="object.run.machine" type="string">
  Machine preset used for the run
</ParamField>

<ParamField path="object.run.dashboardUrl" type="string">
  URL to view the run in the dashboard
</ParamField>

<ParamField path="object.environment.id" type="string">
  Environment ID
</ParamField>

<ParamField path="object.environment.type" type="string">
  Environment type (STAGING or PRODUCTION)
</ParamField>

<ParamField path="object.environment.slug" type="string">
  Environment slug
</ParamField>

<ParamField path="object.organization.id" type="string">
  Organization ID
</ParamField>

<ParamField path="object.organization.slug" type="string">
  Organization slug
</ParamField>

<ParamField path="object.organization.name" type="string">
  Organization name
</ParamField>

<ParamField path="object.project.id" type="string">
  Project ID
</ParamField>

<ParamField path="object.project.ref" type="string">
  Project reference
</ParamField>

<ParamField path="object.project.slug" type="string">
  Project slug
</ParamField>

<ParamField path="object.project.name" type="string">
  Project name
</ParamField>

### Deployment Success Alert

This webhook is sent when a deployment succeeds. The payload is available on the `object` property:

<ParamField path="object.deployment.id" type="string">
  Deployment ID
</ParamField>

<ParamField path="object.deployment.status" type="string">
  Deployment status
</ParamField>

<ParamField path="object.deployment.version" type="string">
  Deployment version
</ParamField>

<ParamField path="object.deployment.shortCode" type="string">
  Short code identifier
</ParamField>

<ParamField path="object.deployment.deployedAt" type="datetime">
  When the deployment completed
</ParamField>

<ParamField path="object.tasks" type="array">
  Array of deployed tasks with properties: id, filePath, exportName, and triggerSource
</ParamField>

<ParamField path="object.environment.id" type="string">
  Environment ID
</ParamField>

<ParamField path="object.environment.type" type="string">
  Environment type (STAGING or PRODUCTION)
</ParamField>

<ParamField path="object.environment.slug" type="string">
  Environment slug
</ParamField>

<ParamField path="object.organization.id" type="string">
  Organization ID
</ParamField>

<ParamField path="object.organization.slug" type="string">
  Organization slug
</ParamField>

<ParamField path="object.organization.name" type="string">
  Organization name
</ParamField>

<ParamField path="object.project.id" type="string">
  Project ID
</ParamField>

<ParamField path="object.project.ref" type="string">
  Project reference
</ParamField>

<ParamField path="object.project.slug" type="string">
  Project slug
</ParamField>

<ParamField path="object.project.name" type="string">
  Project name
</ParamField>

### Deployment Failed Alert

This webhook is sent when a deployment fails. The payload is available on the `object` property:

<ParamField path="object.deployment.id" type="string">
  Deployment ID
</ParamField>

<ParamField path="object.deployment.status" type="string">
  Deployment status
</ParamField>

<ParamField path="object.deployment.version" type="string">
  Deployment version
</ParamField>

<ParamField path="object.deployment.shortCode" type="string">
  Short code identifier
</ParamField>

<ParamField path="object.deployment.failedAt" type="datetime">
  When the deployment failed
</ParamField>

<ParamField path="object.error.name" type="string">
  Error name
</ParamField>

<ParamField path="object.error.message" type="string">
  Error message
</ParamField>

<ParamField path="object.error.stack" type="string">
  Error stack trace (optional)
</ParamField>

<ParamField path="object.error.stderr" type="string">
  Standard error output (optional)
</ParamField>

<ParamField path="object.environment.id" type="string">
  Environment ID
</ParamField>

<ParamField path="object.environment.type" type="string">
  Environment type (STAGING or PRODUCTION)
</ParamField>

<ParamField path="object.environment.slug" type="string">
  Environment slug
</ParamField>

<ParamField path="object.organization.id" type="string">
  Organization ID
</ParamField>

<ParamField path="object.organization.slug" type="string">
  Organization slug
</ParamField>

<ParamField path="object.organization.name" type="string">
  Organization name
</ParamField>

<ParamField path="object.project.id" type="string">
  Project ID
</ParamField>

<ParamField path="object.project.ref" type="string">
  Project reference
</ParamField>

<ParamField path="object.project.slug" type="string">
  Project slug
</ParamField>

<ParamField path="object.project.name" type="string">
  Project name
</ParamField>


# Debugging in VS Code
Source: https://trigger.dev/docs/troubleshooting-debugging-in-vscode



Debugging your task code in `dev` is supported via VS Code, without having to pass in any additional flags. Create a launch configuration in `.vscode/launch.json`:

```json launch.json theme={null}
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Trigger.dev: Dev",
      "type": "node",
      "request": "launch",
      "cwd": "${workspaceFolder}",
      "runtimeExecutable": "npx",
      "runtimeArgs": ["trigger.dev@latest", "dev"],
      "skipFiles": ["<node_internals>/**"],
      "sourceMaps": true
    }
  ]
}
```

Then you can start debugging your tasks code by selecting the `Trigger.dev: Dev` configuration in the debug panel, and set breakpoints in your tasks code.


# GitHub Issues
Source: https://trigger.dev/docs/troubleshooting-github-issues



Please [join our community on Discord](https://github.com/triggerdotdev/trigger.dev/issues) to ask questions, share your projects, and get help from other developers.


# Uptime Status
Source: https://trigger.dev/docs/troubleshooting-uptime-status



Get email notifications when Trigger.dev creates, updates or resolves a platform incident.
[Subscribe](https://status.trigger.dev/)


# How to upgrade the Trigger.dev packages
Source: https://trigger.dev/docs/upgrading-packages

When we release fixes and new features we recommend you upgrade your Trigger.dev packages.

## Update command

Run this command in your project:

```sh  theme={null}
npx trigger.dev@latest update
```

This will update all of the Trigger.dev packages in your project to the latest version.

## Running the CLI locally

When you run the CLI locally use the latest version for the `dev` and `deploy` commands:

```sh  theme={null}
npx trigger.dev@latest dev
```

```sh  theme={null}
npx trigger.dev@latest deploy
```

These commands will also give you the option to upgrade if you are behind on versions.

## Deploying with GitHub Actions

You can deploy using [GitHub Actions](/github-actions). We recommend that you lock your version in the workflow file so make sure to upgrade.

<Warning>
  The deploy step will fail if version mismatches are detected. It's important that you update the
  version using the steps below.
</Warning>

<Steps>
  <Step title="Find your workflow file">
    In your `.githubs/workflows` folder you can find your workflow yml files. You may have a prod
    and staging one.
  </Step>

  <Step title="Update the version for the run command">
    In the steps you'll see a `run` command. It will run the trigger.dev deploy CLI command. Make
    sure to update this version to the latest version (e.g. `npx trigger.dev@3.0.0 deploy`).
  </Step>
</Steps>

## package.json dev dependency

Instead of using `npx`, `pnpm dlx` or `yarn dlx` you can add the Trigger.dev CLI as a dev dependency to your package.json file.

For example:

```json  theme={null}
{
  "devDependencies": {
    "trigger.dev": "3.0.0"
  }
}
```

If you've done this make sure to update the version to match the `@trigger.dev/sdk` package.

Once you have added the `trigger.dev` package to your `devDependencies`, you can use `npm exec trigger.dev`, `pnpm exec trigger.dev`, or `yarn exec trigger.dev` to run the CLI.

But we recommend adding your dev and deploy commands to the `scripts` section of your `package.json` file:

```json  theme={null}
{
  "scripts": {
    "dev:trigger": "trigger dev",
    "deploy:trigger": "trigger deploy"
  }
}
```

Then you can run `npm run dev:trigger` and `npm run deploy:trigger` to run the CLI.


# Vercel integration
Source: https://trigger.dev/docs/vercel-integration

When you deploy to Vercel, automatically deploy your associated tasks.

<Note>This feature is in review. Stay up to date with progress and vote on its priority on our [Roadmap](https://feedback.trigger.dev/roadmap).</Note>


# Versioning
Source: https://trigger.dev/docs/versioning

We use atomic versioning to ensure that started tasks are not affected by changes to the task code.

A version is a bundle of tasks at a certain point in time.

## Version identifiers

Version identifiers look like this:

* `20240313.1` - March 13th, 2024, version 1
* `20240313.2` - March 13th, 2024, version 2
* `20240314.1` - March 14th, 2024, version 1

You can see there are two parts to the version identifier:

* The date (in reverse format)
* The version number

Versions numbers are incremented each time a new version is created for that date and environment. So it's possible to have `20240313.1` in both the `dev` and `prod` environments.

## Version locking

When a task run starts it is locked to the latest version of the code (for that environment). Once locked it won't change versions, even if you deploy new versions. This is to ensure that a task run is not affected by changes to the code.

### Child tasks and version locking

Trigger and wait functions version lock child task runs to the parent task run version. This ensures the results from child runs match what the parent task is expecting. If you don't wait then version locking doesn't apply.

| Trigger function        | Parent task version | Child task version | isLocked |
| ----------------------- | ------------------- | ------------------ | -------- |
| `trigger()`             | `20240313.2`        | Latest             | No       |
| `batchTrigger()`        | `20240313.2`        | Latest             | No       |
| `triggerAndWait()`      | `20240313.2`        | `20240313.2`       | Yes      |
| `batchTriggerAndWait()` | `20240313.2`        | `20240313.2`       | Yes      |

## Local development

When running the local server (using `npx trigger.dev dev`), every relevant code change automatically creates a new version of all tasks.

So a task run will continue running on the version it was locked to. We do this by spawning a new process for each task run. This ensures that the task run is not affected by changes to the code.

## Deployment

Every deployment creates a new version of all tasks for that environment.

## Retries and reattempts

When a task has an uncaught error it will [retry](/errors-retrying), assuming you have not set `maxAttempts` to 0. Retries are locked to the original version of the run.

## Replays

A "replay" is a new run of a task that uses the same inputs but will use the latest version of the code. This is useful when you fix a bug and want to re-run a task with the same inputs. See [replaying](/replaying) for more information.


# Video walkthrough
Source: https://trigger.dev/docs/video-walkthrough

Go from zero to a working task in your Next.js app in 10 minutes.

{" "}

<iframe width="100%" height="315" src="https://www.youtube.com/embed/YH_4c0K7fGM?si=5JzZmZseuqI5aciM" title="Trigger.dev walkthrough" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerPolicy="strict-origin-when-cross-origin" allowFullScreen />

### In this video we cover the following topics:

* [0:00](https://youtu.be/YH_4c0K7fGM?si=J8svVzotZtyTXDap\&t=0) â€“ [Install Trigger.dev](/quick-start) in an existing Next.js project
* [1:44](https://youtu.be/YH_4c0K7fGM?si=J8svVzotZtyTXDap\&t=104) â€“ [Run and test](/run-tests) the "Hello, world!" example project
* [2:09](https://youtu.be/YH_4c0K7fGM?si=FMTP8ep_cDBCU0_x\&t=128) â€“ Create and run an AI image generation task that uses [Fal.ai](https://fal.ai) â€“ ([View the code](/guides/examples/fal-ai-image-to-cartoon))
* [6:25](https://youtu.be/YH_4c0K7fGM?si=pPc8iLI2Y9FGD3yo\&t=385) â€“ Create and run a [Realtime](/realtime/overview) example using [React hooks](/realtime/react-hooks) â€“ ([View the code](/guides/examples/fal-ai-realtime))
* [11:10](https://youtu.be/YH_4c0K7fGM?si=Mjd0EvvNsNlVouvY\&t=670) â€“ [Deploy your task](/cli-deploy) to the Trigger.dev Cloud


# Wait: Overview
Source: https://trigger.dev/docs/wait

During your run you can wait for a period of time or for something to happen.

Waiting allows you to write complex tasks as a set of async code, without having to schedule another task or poll for changes.

In the Trigger.dev Cloud we automatically pause execution of tasks when they are waiting for
longer than a few seconds.

When triggering and waiting for subtasks, the parent is checkpointed and while waiting does not count towards compute usage. When waiting for a time period (`wait.for` or `wait.until`), if the wait is longer than 5 seconds we checkpoint and it does not count towards compute usage.

| Function                           | What it does                                     |
| :--------------------------------- | :----------------------------------------------- |
| [wait.for()](/wait-for)            | Waits for a specific period of time, e.g. 1 day. |
| [wait.until()](/wait-until)        | Waits until the provided `Date`.                 |
| [wait.forToken()](/wait-for-token) | Pauses runs until a token is completed.          |


# Wait for
Source: https://trigger.dev/docs/wait-for

Wait for a period of time, then continue execution.

Inside your tasks you can wait for a period of time before you want execution to continue.

```ts /trigger/long-task.ts theme={null}
export const veryLongTask = task({
  id: "very-long-task",
  run: async (payload) => {
    await wait.for({ seconds: 5 });

    await wait.for({ minutes: 10 });

    await wait.for({ hours: 1 });

    await wait.for({ days: 1 });

    await wait.for({ weeks: 1 });

    await wait.for({ months: 1 });

    await wait.for({ years: 1 });
  },
});
```

This allows you to write linear code without having to worry about the complexity of scheduling or managing cron jobs.

In the Trigger.dev Cloud we automatically pause execution of tasks when they are waiting for
longer than a few seconds.

When triggering and waiting for subtasks, the parent is checkpointed and while waiting does not count towards compute usage. When waiting for a time period (`wait.for` or `wait.until`), if the wait is longer than 5 seconds we checkpoint and it does not count towards compute usage.

## Wait idempotency

You can pass an idempotency key to any wait function, allowing you to skip waits if the same idempotency key is used again. This can be useful if you want to skip waits when retrying a task, for example:

```ts  theme={null}
// Specify the idempotency key and TTL when waiting for a duration:
await wait.for({ seconds: 10 }, { idempotencyKey: "my-idempotency-key", idempotencyKeyTTL: "1h" });
```


# Wait for token
Source: https://trigger.dev/docs/wait-for-token

Wait until a token is completed using waitpoint tokens.

Waitpoint tokens pause task runs until you complete the token. They're commonly used for approval workflows and other scenarios where you need to wait for external confirmation, such as human-in-the-loop processes.

You can complete a token using the SDK or by making a POST request to the token's URL.

## Usage

To get started using wait tokens, you need to first create a token using the `wait.createToken` function:

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

// This can be called anywhere in your codebase, either in a task or in your backend code
const token = await wait.createToken({
  timeout: "10m", // you can optionally specify a timeout for the token
});
```

Once you have a token, you can wait for it to be completed using the `wait.forToken` function:

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

type ApprovalToken = {
  status: "approved" | "rejected";
};

// This must be called inside a task run function
const result = await wait.forToken<ApprovalToken>(tokenId);

if (result.ok) {
  console.log("Token completed", result.output.status); // "approved" or "rejected"
} else {
  console.log("Token timed out", result.error);
}
```

To complete a token, you can use the `wait.completeToken` function:

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";
// This can be called anywhere in your codebase, or from an external service,
// passing in the token ID and the output of the token
await wait.completeToken<ApprovalToken>(tokenId, {
  status: "approved",
});
```

Or you can make an HTTP POST request to the `url` it returns. This is an HTTP callback:

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

const token = await wait.createToken({
  timeout: "10m",
});

const call = await replicate.predictions.create({
  version: "27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478",
  input: {
    prompt: "A painting of a cat by Andy Warhol",
  },
  // pass the provided URL to Replicate's webhook, so they can "callback"
  webhook: token.url,
  webhook_events_filter: ["completed"],
});

const prediction = await wait.forToken<Prediction>(token).unwrap();
// unwrap() throws a timeout error or returns the result   ðŸ‘†
```

## wait.createToken

Create a waitpoint token.

### options

The `createToken` function accepts an object with the following properties:

<ParamField query="timeout" type="string" optional>
  The maximum amount of time to wait for the token to be completed. Defaults to "10m".
</ParamField>

<ParamField query="idempotencyKey" type="string" optional>
  An idempotency key for the token. If provided, the token will be completed with the same payload
  if the same idempotency key is used again.
</ParamField>

<ParamField query="idempotencyKeyTTL" type="string" optional>
  The time to live for the idempotency key. Defaults to "1h".
</ParamField>

<ParamField query="tags" type="string[]" optional>
  Tags to attach to the token. Tags can be used to filter waitpoints in the dashboard.
</ParamField>

### returns

The `createToken` function returns a token object with the following properties:

<ParamField query="id" type="string">
  The ID of the token. Starts with `waitpoint_`.
</ParamField>

<ParamField query="url" type="string">
  The URL of the token. This is the URL you can make a POST request to in order to complete the token.

  The JSON body of the POST request will be used as the output of the token. If there's no body the output will be an empty object `{}`.
</ParamField>

<ParamField query="isCached" type="boolean">
  Whether the token is cached. Will return true if the token was created with an idempotency key and
  the same idempotency key was used again.
</ParamField>

<ParamField query="publicAccessToken" type="string">
  A Public Access Token that can be used to complete the token from a client-side application (or
  another backend). See our [Realtime docs](/realtime/auth) for more details.
</ParamField>

### Example

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

const token = await wait.createToken({
  timeout: "10m",
  idempotencyKey: "my-idempotency-key",
  tags: ["my-tag"],
});
```

## wait.completeToken

Complete a waitpoint token.

### parameters

<ParamField query="id" type="string">
  The ID of the token to complete.
</ParamField>

<ParamField query="output" type="any">
  The data to complete the token with.
</ParamField>

### returns

The `completeToken` function returns an object with the following properties:

<ParamField query="success" type="boolean">
  Whether the token was completed successfully.
</ParamField>

### Example

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

await wait.completeToken<ApprovalToken>(tokenId, {
  status: "approved",
});
```

### From another language

You can complete a token using a raw HTTP request or from another language.

<CodeGroup>
  ```bash curl theme={null}
  curl -X POST "https://api.trigger.dev/api/v1/waitpoints/tokens/{tokenId}/complete" \
    -H "Authorization: Bearer {token}" \
    -H "Content-Type: application/json" \
    -d '{"output": { "status": "approved"}}'
  ```

  ```python python theme={null}
  import requests

  response = requests.post(
    "https://api.trigger.dev/api/v1/waitpoints/tokens/{tokenId}/complete",
    headers={"Authorization": f"Bearer {token}"},
    json={"output": { "status": "approved"}}
  )
  ```

  ```ruby ruby theme={null}
  require "net/http"

  uri = URI("https://api.trigger.dev/api/v1/waitpoints/tokens/{tokenId}/complete")

  http = Net::HTTP.new(uri.host, uri.port)
  request = Net::HTTP::Post.new(uri)
  request["Authorization"] = "Bearer {token}"
  request["Content-Type"] = "application/json"
  request.body = JSON.generate({ output: { status: "approved" } })

  response = http.request(request)
  ```

  ```go go theme={null}
  package main

  import (
  	"bytes"
  	"encoding/json"
  	"fmt"
  	"net/http"
  )

  func main() {
  	url := "https://api.trigger.dev/api/v1/waitpoints/tokens/{tokenId}/complete"

  	payload := map[string]interface{}{
  		"output": map[string]interface{}{
  			"status": "approved",
  		},
  	}

  	jsonData, err := json.Marshal(payload)
  	if err != nil {
  		fmt.Println("Error marshalling payload:", err)
  		return
  	}

  	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
  	if err != nil {
  		fmt.Println("Error creating request:", err)
  		return
  	}

  	req.Header.Set("Authorization", "Bearer {token}")
  	req.Header.Set("Content-Type", "application/json")

  	client := &http.Client{}
  	resp, err := client.Do(req)
  	if err != nil {
  		fmt.Println("Error sending request:", err)
  		return
  	}

  	defer resp.Body.Close()

  	fmt.Println("Response status:", resp.Status)
  }
  ```
</CodeGroup>

## wait.forToken

Wait for a token to be completed.

### parameters

<ParamField query="token" type="string | { id: string }">
  The token to wait for.
</ParamField>

### returns

The `forToken` function returns a result object with the following properties:

<ParamField query="ok" type="boolean">
  Whether the token was completed successfully.
</ParamField>

<ParamField query="output" type="any">
  If `ok` is `true`, this will be the output of the token.
</ParamField>

<ParamField query="error" type="Error">
  If `ok` is `false`, this will be the error that occurred. The only error that can occur is a
  timeout error.
</ParamField>

### unwrap()

We provide a handy `.unwrap()` method that will throw an error if the result is not ok. This means your happy path is a lot cleaner.

```ts  theme={null}
const approval = await wait.forToken<ApprovalToken>(tokenId).unwrap();
// unwrap means an error will throw if the waitpoint times out ðŸ‘†

// This is the actual data you sent to the token now, not a result object
console.log("Approval", approval);
```

### Example

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

const result = await wait.forToken<ApprovalToken>(tokenId);

if (result.ok) {
  console.log("Token completed", result.output.status); // "approved" or "rejected"
} else {
  console.log("Token timed out", result.error);
}
```

## wait.listTokens

List all tokens for an environment.

### parameters

The `listTokens` function accepts an object with the following properties:

<ParamField query="status" type="string | string[]" optional>
  Statuses to filter by. Can be one or more of: `WAITING`, `COMPLETED`, `TIMED_OUT`.
</ParamField>

<ParamField query="idempotencyKey" type="string" optional>
  The idempotency key to filter by.
</ParamField>

<ParamField query="tags" type="string | string[]" optional>
  Tags to filter by.
</ParamField>

<ParamField query="period" type="string" optional>
  The period to filter by. Can be one of: `1h`, `1d`, `7d`, `30d`.
</ParamField>

<ParamField query="from" type="Date | number" optional>
  The start date to filter by.
</ParamField>

<ParamField query="to" type="Date | number" optional>
  The end date to filter by.
</ParamField>

### returns

The `listTokens` function returns a list of tokens that can be iterated over using a for-await-of loop.

Each token is an object with the following properties:

<ParamField query="id" type="string">
  The ID of the token.
</ParamField>

<ParamField query="url" type="string">
  The URL of the token. This is the URL you can make a POST request to in order to complete the token.

  The JSON body of the POST request will be used as the output of the token. If there's no body the output will be an empty object `{}`.
</ParamField>

<ParamField query="status" type="string">
  The status of the token.
</ParamField>

<ParamField query="completedAt" type="Date">
  The date and time the token was completed.
</ParamField>

<ParamField query="timeoutAt" type="Date">
  The date and time the token will timeout.
</ParamField>

<ParamField query="idempotencyKey" type="string">
  The idempotency key of the token.
</ParamField>

<ParamField query="idempotencyKeyExpiresAt" type="Date">
  The date and time the idempotency key will expire.
</ParamField>

<ParamField query="tags" type="string[]">
  The tags of the token.
</ParamField>

<ParamField query="createdAt" type="Date">
  The date and time the token was created.
</ParamField>

<Note>
  The output of the token is not included in the list. To get the output, you need to retrieve the
  token using the `wait.retrieveToken` function.
</Note>

### Example

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

const tokens = await wait.listTokens({
  status: "COMPLETED",
  tags: ["user:123"],
});

for await (const token of tokens) {
  console.log(token);
}
```

## wait.retrieveToken

Retrieve a token by ID.

### parameters

<ParamField query="id" type="string">
  The ID of the token to retrieve.
</ParamField>

### returns

The `retrieveToken` function returns a token object with the following properties:

<ParamField query="id" type="string">
  The ID of the token.
</ParamField>

<ParamField query="url" type="string">
  The URL of the token. This is the URL you can make a POST request to in order to complete the token.

  The JSON body of the POST request will be used as the output of the token. If there's no body the output will be an empty object `{}`.
</ParamField>

<ParamField query="status" type="string">
  The status of the token.
</ParamField>

<ParamField query="completedAt" type="Date">
  The date and time the token was completed.
</ParamField>

<ParamField query="timeoutAt" type="Date">
  The date and time the token will timeout.
</ParamField>

<ParamField query="idempotencyKey" type="string">
  The idempotency key of the token.
</ParamField>

<ParamField query="idempotencyKeyExpiresAt" type="Date">
  The date and time the idempotency key will expire.
</ParamField>

<ParamField query="tags" type="string[]">
  The tags of the token.
</ParamField>

<ParamField query="createdAt" type="Date">
  The date and time the token was created.
</ParamField>

<ParamField query="output" type="any">
  The output of the token.
</ParamField>

<ParamField query="error" type="Error">
  The error that occurred.
</ParamField>

### Example

```ts  theme={null}
import { wait } from "@trigger.dev/sdk";

const token = await wait.retrieveToken(tokenId);

console.log(token);
```

## Wait idempotency

You can pass an idempotency key to any wait function, allowing you to skip waits if the same idempotency key is used again. This can be useful if you want to skip waits when retrying a task, for example:

```ts  theme={null}
// Specify the idempotency key and TTL when creating a wait token
const token = await wait.createToken({
  idempotencyKey: "my-idempotency-key",
  idempotencyKeyTTL: "1h",
});
```


# Wait until
Source: https://trigger.dev/docs/wait-until

Wait until a date, then continue execution.

This example sends a reminder email to a user at the specified datetime.

```ts /trigger/reminder-email.ts theme={null}
export const sendReminderEmail = task({
  id: "send-reminder-email",
  run: async (payload: { to: string; name: string; date: string }) => {
    //wait until the date
    await wait.until({ date: new Date(payload.date) });

    //todo send email
    const { data, error } = await resend.emails.send({
      from: "hello@trigger.dev",
      to: payload.to,
      subject: "Don't forgetâ€¦",
      html: `<p>Hello ${payload.name},</p><p>...</p>`,
    });
  },
});
```

This allows you to write linear code without having to worry about the complexity of scheduling or managing cron jobs.

In the Trigger.dev Cloud we automatically pause execution of tasks when they are waiting for
longer than a few seconds.

When triggering and waiting for subtasks, the parent is checkpointed and while waiting does not count towards compute usage. When waiting for a time period (`wait.for` or `wait.until`), if the wait is longer than 5 seconds we checkpoint and it does not count towards compute usage.

## `throwIfInThePast`

You can optionally throw an error if the date is already in the past when the function is called:

```ts  theme={null}
await wait.until({ date: new Date(date), throwIfInThePast: true });
```

You can of course use try/catch if you want to do something special in this case.

## Wait idempotency

You can pass an idempotency key to any wait function, allowing you to skip waits if the same idempotency key is used again. This can be useful if you want to skip waits when retrying a task, for example:

```ts  theme={null}
// Specify the idempotency key and TTL when waiting until a date:
await wait.until({
  date: futureDate,
  idempotencyKey: "my-idempotency-key",
  idempotencyKeyTTL: "1h",
});
```


# Writing tasks: Overview
Source: https://trigger.dev/docs/writing-tasks-introduction

Tasks are the core of Trigger.dev. They are long-running processes that are triggered by events.

Before digging deeper into the details of writing tasks, you should read the [fundamentals of tasks](/tasks/overview) to understand what tasks are and how they work.

## Writing tasks

| Topic                                        | Description                                                                                         |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- |
| [Logging](/logging)                          | View and send logs and traces from your tasks.                                                      |
| [Errors & retrying](/errors-retrying)        | How to deal with errors and write reliable tasks.                                                   |
| [Wait](/wait)                                | Wait for periods of time or for external events to occur before continuing.                         |
| [Concurrency & Queues](/queue-concurrency)   | Configure what you want to happen when there is more than one run at a time.                        |
| [Realtime notifications](/realtime/overview) | Send realtime notifications from your task that you can subscribe to from your backend or frontend. |
| [Versioning](/versioning)                    | How versioning works.                                                                               |
| [Machines](/machines)                        | Configure the CPU and RAM of the machine your task runs on                                          |
| [Idempotency](/idempotency)                  | Protect against mutations happening twice.                                                          |
| [Replaying](/replaying)                      | You can replay a single task or many at once with a new version of your code.                       |
| [Max duration](/runs/max-duration)           | Set a maximum duration for your task to run.                                                        |
| [Tags](/tags)                                | Tags allow you to easily filter runs in the dashboard and when using the SDK.                       |
| [Metadata](/runs/metadata)                   | Attach a small amount of data to a run and update it as the run progresses.                         |
| [Usage](/run-usage)                          | Get compute duration and cost from inside a run, or for a specific block of code.                   |
| [Context](/context)                          | Access the context of the task run.                                                                 |
| [Bulk actions](/bulk-actions)                | Run actions on many task runs at once.                                                              |
| [Priority](/runs/priority)                   | Specify a priority when triggering a task.                                                          |
| [Hidden tasks](/hidden-tasks)                | Create tasks that are not exported from your trigger files but can still be executed.               |

## Our library of examples, guides and projects

<CardGroup cols={2}>
  <Card title="Walkthrough guides" icon="book" href="/guides/introduction">
    Detailed guides for setting up Trigger.dev with popular frameworks and services, including
    Next.js, Remix, Supabase, Stripe and more.
  </Card>

  <Card title="Example tasks" icon="code" href="/guides/introduction#example-tasks">
    Task code you can copy and paste to use in your own projects, including OpenAI, Vercel AI SDK,
    Deepgram, FFmpeg, Puppeteer, Stripe, Supabase and more.
  </Card>

  <Card title="Webhook guides" icon="code" href="/guides/frameworks/webhooks-guides-overview">
    Learn how to trigger tasks from webhooks, including Next.js, Remix, Supabase and Stripe and
    more.
  </Card>

  <Card title="Example projects" icon="GitHub" href="/guides/introduction#example-projects">
    Full-stack projects demonstrating how to use Trigger.dev. Fork them in GitHub as a starting
    point for your own projects.
  </Card>
</CardGroup>


