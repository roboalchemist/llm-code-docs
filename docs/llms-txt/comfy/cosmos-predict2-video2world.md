# Source: https://docs.comfy.org/tutorials/video/cosmos/cosmos-predict2-video2world.md

# Cosmos Predict2 Video2World  ComfyUI Official Example

> This guide demonstrates how to complete Cosmos-Predict2 Video2World workflows in ComfyUI

Cosmos-Predict2 is NVIDIA's next-generation physical world foundation model, specifically designed for high-quality visual generation and prediction tasks in physical AI scenarios.
The model features exceptional physical accuracy, environmental interactivity, and detail reproduction capabilities, enabling realistic simulation of complex physical phenomena and dynamic scenes.

Cosmos-Predict2 supports various generation methods including Text-to-Image (Text2Image) and Video-to-World (Video2World),
and is widely used in industrial simulation, autonomous driving, urban planning, scientific research, and other fields.
It serves as a crucial foundational tool for promoting deep integration of intelligent vision and the physical world.

GitHub:[Cosmos-predict2](https://github.com/nvidia-cosmos/cosmos-predict2)
huggingface: [Cosmos-Predict2](https://huggingface.co/collections/nvidia/cosmos-predict2-68028efc052239369a0f2959)

This guide will walk you through completing **Video2World** generation in ComfyUI.

For the text-to-image section, please refer to the following part:

<Card title="Cosmos Predict2 Text to Image" icon="book" href="/tutorials/image/cosmos/cosmos-predict2-t2i">
  Using Cosmos-Predict2 for text-to-image generation
</Card>
