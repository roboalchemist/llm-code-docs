# Source: https://docs.avaamo.com/user-guide/outreach/overview.md

# Source: https://docs.avaamo.com/user-guide/live-agent-console/overview.md

# Source: https://docs.avaamo.com/user-guide/how-to/build-agents/learning-continuous-improvement/overview.md

# Source: https://docs.avaamo.com/user-guide/how-to/build-agents/configure-agents/deploy/web-channel/overview.md

# Source: https://docs.avaamo.com/user-guide/llamb/llamb-filters/overview.md

# Source: https://docs.avaamo.com/user-guide/outreach/overview.md

# Source: https://docs.avaamo.com/user-guide/live-agent-console/overview.md

# Source: https://docs.avaamo.com/user-guide/how-to/build-agents/learning-continuous-improvement/overview.md

# Source: https://docs.avaamo.com/user-guide/how-to/build-agents/configure-agents/deploy/web-channel/overview.md

# Source: https://docs.avaamo.com/user-guide/llamb/llamb-filters/overview.md

# Overview

Avaamo's LLaMB is a new low-code framework designed to enable the safe, secure, and rapid development of powerful generative AI agents for enterprise use. Leveraging large language model (LLM) technology, LLaMB delivers personalized and summarized results while ensuring the necessary levels of security and compliance for enterprise applications. It provides a practical and secure solution for deploying LLMs, enhancing knowledge search experiences for both employees and customers.

However, implementing LLaMB introduces substantial challenges such as,

* Data security&#x20;
* Mitigating prompt injection attacks, where malicious inputs manipulate the model into generating harmful outputs.&#x20;
* Instances of jailbreaks, where users bypass safety mechanisms to elicit inappropriate or dangerous responses from the AI, further expose system vulnerabilities.
* Safeguarding against the disclosure of sensitive information and managing the generation of insecure or biased outputs are critical concerns.

This section details the filters and tools in LLaMB that provide robust and comprehensive safeguards essential for enterprise-grade LLM applications:

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Social filters</strong></td><td>Detect and filter harmful content in both user prompts and generated outputs in the following categories</td><td><ul><li>Racism</li><li>Hate</li><li>Violence</li><li>Self-harm</li><li>Sexual harassment</li><li>Discrimination</li><li>Drugs</li></ul></td><td><a href="social-filters">social-filters</a></td></tr><tr><td><strong>Grounding filters</strong></td><td>Ensures the quality, accuracy, and relevance of the generated output, and helps to "ground" the models in the context of the specific use-case to obtain accurate and relevant output.</td><td></td><td><a href="grounding-filters">grounding-filters</a></td></tr><tr><td><strong>Brand Protection filters</strong></td><td><p>Protect your brand, and ensure that your content is safely and ethically used. </p><ul><li>Brand Awareness</li><li>Business taxonomy </li></ul><p><br></p></td><td></td><td><a href="brand-protection-filters">brand-protection-filters</a></td></tr><tr><td></td><td><strong>Hallucination filters</strong></td><td>Eliminate hallucinations and help in the detection and correction of fabricated or false content generated by the model.</td><td><a href="hallucination-filters">hallucination-filters</a></td></tr></tbody></table>

By integrating these rigorous input validation, continuous monitoring, and strict data privacy measures, LLaMB offers a secure and efficient approach to enterprise AI deployment.
