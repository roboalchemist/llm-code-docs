# Upstash Documentation

Source: https://upstash.com/docs/llms-full.txt

---

# null
Source: https://upstash.com/docs/README



# Mintlify Starter Kit

Click on `Use this template` to copy the Mintlify starter kit. The starter kit
contains examples including

* Guide pages
* Navigation
* Customizations
* API Reference pages
* Use of popular components

### üë©‚Äçüíª Development

Install the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview
the documentation changes locally. To install, use the following command

```
npm i -g mintlify
```

Run the following command at the root of your documentation (where mint.json is)

```
mintlify dev
```

### üòé Publishing Changes

Changes will be deployed to production automatically after pushing to the
default branch.

You can also preview changes using PRs, which generates a preview link of the
docs.

#### Troubleshooting

* Mintlify dev isn't running - Run `mintlify install` it'll re-install
  dependencies.
* Page loads as a 404 - Make sure you are running in a folder with `mint.json`


# Get QStash
Source: https://upstash.com/docs/api-reference/qstash/get-qstash

devops/developer-api/openapi.yml get /qstash/user
Retrieves detailed information about the authenticated user's QStash, including plan details, limits, and configuration



# Get QStash Stats
Source: https://upstash.com/docs/api-reference/qstash/get-qstash-stats

devops/developer-api/openapi.yml get /qstash/stats
Retrieves detailed usage statistics for the QStash account including 
daily requests, billing, bandwidth, and workflow metrics over time.




# Reset QStash Token
Source: https://upstash.com/docs/api-reference/qstash/reset-qstash-token

devops/developer-api/openapi.yml post /qstash/user/rotatetoken
Resets the authentication credentials for the QStash user account. 
This invalidates the old password and token, and generates new ones.
Returns the updated user information with new credentials.




# Set QStash Plan
Source: https://upstash.com/docs/api-reference/qstash/set-qstash-plan

devops/developer-api/openapi.yml post /qstash-upgrade
Changes the QStash account to a different plan type.
This operation changes the plan and associated limits for the QStash account.




# Create Search Index
Source: https://upstash.com/docs/api-reference/search/create-search-index

devops/developer-api/openapi.yml post /search
Creates a new search index with the specified configuration



# Delete Search Index
Source: https://upstash.com/docs/api-reference/search/delete-search-index

devops/developer-api/openapi.yml delete /search/{id}
Permanently deletes a search index and all its data



# Get Index Stats
Source: https://upstash.com/docs/api-reference/search/get-index-stats

devops/developer-api/openapi.yml get /search/{id}/stats
Retrieves statistics and metrics for a specific search index



# Get Search Index
Source: https://upstash.com/docs/api-reference/search/get-search-index

devops/developer-api/openapi.yml get /search/{id}
Retrieves detailed information about a specific search index



# Get Search Stats
Source: https://upstash.com/docs/api-reference/search/get-search-stats

devops/developer-api/openapi.yml get /search/stats
Get search statistics for all the search indices associated with the authenticated user



# List Search Indexes
Source: https://upstash.com/docs/api-reference/search/list-search-indexes

devops/developer-api/openapi.yml get /search
Returns a list of all search indices belonging to the authenticated user.



# Rename Search Index
Source: https://upstash.com/docs/api-reference/search/rename-search-index

devops/developer-api/openapi.yml post /search/{id}/rename
Renames a search index.



# Reset Password
Source: https://upstash.com/docs/api-reference/search/reset-password

devops/developer-api/openapi.yml post /search/{id}/reset-password
This endpoint resets the regular and readonly tokens of a search index.



# Transfer Search Index
Source: https://upstash.com/docs/api-reference/search/transfer-search-index

devops/developer-api/openapi.yml post /search/{id}/transfer
Transfers ownership of a search index to another team.
Transferring to a personal account is not supported.
However, transferring from a personal account to a team is allowed.




# Get Index Stats
Source: https://upstash.com/docs/api-reference/vector/get-index-stats

devops/developer-api/openapi.yml get /vector/index/{id}/stats
Retrieves statistics and metrics for a specific vector index



# Get Vector Stats
Source: https://upstash.com/docs/api-reference/vector/get-vector-stats

devops/developer-api/openapi.yml get /vector/index/stats
Get vector statistics for all the vector indices associated with the authenticated user



# Add a Payment Method
Source: https://upstash.com/docs/common/account/addapaymentmethod



Upstash does not require a credit card for Free databases. However, for paid databases, you need to add at least one payment method. To add a payment method, follow these steps:

1. Click on your profile at the top right.
2. Select ¬†`Account` from the dropdown menu.
3. Navigate to the `Billing` tab.
4. On the screen, click the `Add Your Card` button.
5. Enter your name and credit card information in the following form:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d529602ff8617dfecbc9b8a16217d079" data-og-width="1038" width="1038" data-og-height="916" height="916" data-path="img/addpaymentmethod/ccform.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0974386c623cc6405ba23a3cb51c51bc 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4a08068a39ebf70b0d40bc7eae427c0d 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a32927bf7dff3f761ee0082309797b3c 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b2abc75c9299696973324850fa786b12 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6b6f854b4c26ea2da950cfc2a7c53ff7 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/ccform.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=ceb266e767cd7cd9ccd6023a0577cadd 2500w" />
</Frame>

You can enter multiple credit cards and set one of them as the default one. The
payments will be charged from the default credit card.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a4dfcacfd1b22925465f659c600946d4" data-og-width="2086" width="2086" data-og-height="750" height="750" data-path="img/addpaymentmethod/cardlist.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fade5e7e071d9fbab5d4a41cfd81ff48 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=8b857d2e9171988c0998d43f5b40ecb9 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=8751314fc5bcd9cc421fa93d3f69bd35 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5b06f4bc4c41e3723a962aeceec1d21c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3f7fb18b875881a16a2c8c1c87da5661 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/addpaymentmethod/cardlist.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c3b35f10f1760be67d2fa908ffd167a6 2500w" />
</Frame>

## Payment Security

Upstash does not store users' credit card information in its servers. We use
Stripe Inc payment processing company to handle payments. You can read more
about payment security in Stripe
[here](https://stripe.com/docs/security/stripe).


# Audit Logs
Source: https://upstash.com/docs/common/account/auditlogs



Audit logs give you a chronological set of activity records that have affected
your databases and Upstash account. You can see the list of all activities on a
single page. You can access your audit logs under `Account > Audit Logs` in your
console:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a1f7bdb500057b952aae98ae04f15e78" data-og-width="2082" width="2082" data-og-height="978" height="978" data-path="img/auditlogs/audit.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bedfa2c84d30469398105a583090524e 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5a89ea16be9559b0e9b3bbde56c85fe3 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f9b7e364704446997beacce5ee41faa3 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=20743e4ba4cbac1722195f8a6ba588da 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=50c179cdda75724cd1e2e63fd33c514d 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auditlogs/audit.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0b090d4b57972436502d749a42f6b194 2500w" />
</Frame>

Here the `Source` column shows if the action has been called by the console or via
an API key. The `Entity` column gives you the name of the resource that has been
affected by the action. For example, when you delete a database, the name of the
database will be shown here. Also, you can see the IP address which performed the
action.

## Security

You can track your audit logs to detect any unusual activity on your account and
databases. When you suspect any security breach, you should delete the API key
related to suspicious activity and inform us by emailing
[support@upstash.com](mailto:support@upstash.com)

## Retention period

After the retention period, the audit logs are deleted. The retention period for free databases is 7 days, for pay-as-you-go databases, it is 30 days, and for the Pro tier, it is one year.


# AWS Marketplace
Source: https://upstash.com/docs/common/account/awsmarketplace



<Check>
  **Prerequisite**

  You need an Upstash account before subscribing on AWS, create one
  [here](https://console.upstash.com).
</Check>

Upstash is available on the AWS Marketplace, which is particularly beneficial for users who already get other services from AWS Marketplace and can consolidate Upstash under a single bill.

You can search "Upstash" on AWS Marketplace or just click [here](https://aws.amazon.com/marketplace/pp/prodview-fssqvkdcpycco).

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=140323250d06d2d56e85d3b03a65b04a" data-og-width="3016" width="3016" data-og-height="1432" height="1432" data-path="img/awsmarketplace/AWS-marketplace-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1dc56ddd387ca2ad9ff7b88e12308bfc 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=cf5b47d3c63696b25f0a171fa26650e8 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0da61e11afb962d627b177e42a106ece 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3956600d773c3cd00b802b855a7ac75c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=685df02205d8691ec65ce945edd7b200 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-1.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=220662fd1a004a3635fadedd75409179 2500w" />
</Frame>

Once you click subscribe, you will be prompted to select which personal or team account you wish to link with your AWS Subscription.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=257f8711f4270c2991172b08706339f0" data-og-width="912" width="912" data-og-height="716" height="716" data-path="img/awsmarketplace/AWS-marketplace-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=308472e14e6595fb2a58a549eb8e271d 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=994138f3becd5849b214fd831a13e76b 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9a26ab775abe59138b34fdcfdea94c84 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0646307bcc1860139e7a9a549a57d37d 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=cf07ce26b66d1683609b38fdecd5eb5a 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-2.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=96dcb8fc0f3f427201e8ac3ce6ba97f5 2500w" />
</Frame>

Once your account is linked, regardless of which Upstash product you use, all of your usage will be billed to your AWS Account. You can also upgrade or downgrade your subscription through Upstash console.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=94a883e03cb5c31dc74535d761df6a98" data-og-width="724" width="724" data-og-height="204" height="204" data-path="img/awsmarketplace/AWS-marketplace-3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fccd4a2253a6d4172803a7247224e519 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9152eb86ab31b84f85261b9081c95d0f 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4092ae448b27da0e42b6179edaa2486a 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c3123b7e44707f7609e84fedb3347d56 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=ee231b733c61b8496419373a8cc9ae10 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awsmarketplace/AWS-marketplace-3.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9a8b4160898fabaa07d24cae952ca46a 2500w" />
</Frame>


# Cost Explorer
Source: https://upstash.com/docs/common/account/costexplorer



The Cost Explorer pages allow you to view your current and previous months‚Äô costs. To access the Cost Explorer, navigate to the left menu and select Account > Cost Explorer. Below is an example report:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=334bd9ff88b617ad2ff32b20a3a61dfd" data-og-width="2096" width="2096" data-og-height="1118" height="1118" data-path="img/costexplorer/costexplorer.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=ac8adc206a255dcc4ad82a8c587b8e0e 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=684c64dddffae9a5bd894d447114c9e0 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=2eb1b8f3a8e3a263eb0e70aa3da4f601 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=aba07654a32cfedacf05456c6875a20c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f11730619209988320c08c52fc6a9a11 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/costexplorer/costexplorer.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5384167a9557b39c2db10a8976967298 2500w" />
</Frame>

You can select a specific month to view the cost breakdown for that period. Here's the explanation of the fields in the report:

**Request:** This represents the total number of requests sent to the database.

**Storage:** This indicates the average size of the total storage consumed. Upstash database includes a persistence layer for data durability. For example, if you have 1 GB of data in your database throughout the entire month, this value will be 1 GB. Even if your database is empty for the first 29 days of the month and then expands to 30 GB on the last day, this value will still be 1 GB.

**Cost:** This field represents the total cost of your database in US Dollars.

> The values for the current month is updated hourly, so values can be stale up
> to 1 hour.


# Create an Account
Source: https://upstash.com/docs/common/account/createaccount



You can sign up for <a href="https://console.upstash.com" target="_blank">Upstash</a> using your Amazon, Github or Google accounts. Alternatively, if you prefer not to use these authentication providers or want to sign up with a corporate email address, you can also sign up using email and password.

<Note>
  We do not access your information other than:

  * Your email
  * Your name
  * Your profile picture and we never share your information with third parties.
</Note>


# Developer API
Source: https://upstash.com/docs/common/account/developerapi



Using Upstash API, you can develop applications that can create and manage
Upstash databases and Upstash Vector Indexes. You can automate everything that
you can do in the console. To use developer API, you need to create an API key
in the console.

Note: The Developer API is only available to native Upstash accounts. Accounts created via third-party platforms like Vercel or Fly.io are not supported.

See [DevOps](/devops) for details.


# Account and Billing FAQ
Source: https://upstash.com/docs/common/account/faq



## How can I delete my account?

You can delete your account from `Account` > `Settings` > `Delete Account`. You should first delete all your databases and clusters. After you delete your account, all your data and payment information will be deleted and you will not be able to recover it.

## How can I delete my credit card?

You can delete your credit card from `Account` > `Billing` page. However, you should first add a new credit card to be able to delete the existing one. If you want to delete all of your payment information, you should delete your account.

## How can I change my email address?

You can change your account e-mail address in `Account` > `Settings` page. In order to change your billing e-mail adress, please see `Account` > `Billing` page. If you encounter any issues, please contact us at [support@upstash.com](mailto:support@upstash.com) to change your email address.

## Can I set an upper spending limit, so I don't get surprises after an unexpected amount of high traffic?

On Pay as You Go model, you can set a budget for your Redis instances. When your monthly cost reaches the max budget, we send an email to inform you and throttle your instance. You will not be charged beyond your set budget.

To set the budget, you can go to the "Usage" tab of your Redis instance and click "Change Budget" under the cost metric.

## What happens if my payment fails?

If a payment failure occurs, we will retry the payment three more times before suspending the account. During this time, you will receive email notifications about the payment failure. If the account is suspended, all resources in the account will be inaccessible. If you add a valid payment method after the account suspension, your account will be automatically unsuspended during the next payment attempt.

## What happens if I unsubscribe from AWS Marketplace but I don't have any other payment methods?

We send a warning email three times before suspending an account. If no valid payment method is added, we suspend the account. Once the account is suspended, all resources within the account will be inaccessible. If you add a valid payment method after the account suspension, your account will be automatically unsuspended during the next system check.

## I have a question about my bill, who should I contact?

Please contact us at [support@upstash.com](mailto:support@upstash.com).


# Payment History
Source: https://upstash.com/docs/common/account/paymenthistory



The Payment History page gives you information about your payments. You can open your
payment history in the left menu under Account > Payment History. Here an example
report:

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=59cd54677fb1fe7ef140529a38240d60" data-og-width="2102" width="2102" data-og-height="1244" height="1244" data-path="img/paymenthistory/paymenthistory.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=28ed2e21d8df4778e5bbc8a9868a906a 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d30d9769c8fd492d5fae52d4377c25b5 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8c59b4730f10cfe754d442e099713cb0 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ab8252caf2cc5d3a717dfd8f26cce2d6 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b4fd4bbc6cb2dbc0159f74bcde9578d2 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/paymenthistory/paymenthistory.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=75bb9256ea72ae5109d973af7e553a14 2500w" />
</Frame>

You can download receipt. If one of your payments failed, you can retry your
payment on this page.


# Teams and Users
Source: https://upstash.com/docs/common/account/teams



Team management enables collaboration with other users. You can create a team and invite people to join by using their email addresses. Team members will have access to databases created under the team based on their assigned roles.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bc3cf60ab755331d665576c03c037579" data-og-width="2058" width="2058" data-og-height="1112" height="1112" data-path="img/teams/team-member.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2a2391b9e93c1bdc264559a5ee539e28 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=28037e45cef7f6323ecf262d696ba5f1 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ee688b9a5c101c433782c1bc9da637cc 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5e6e7cf3b989b6bd24edb43e88cbe66e 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cb367e35c494c5fa22d443085f0ecc1e 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a367d93486a13a5ce4d3659437edf120 2500w" />
</Frame>

## Create Team

You can create a team using the menu `Account > Teams`

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=45d8621fefc7358b8398beaab2be8d14" data-og-width="2084" width="2084" data-og-height="980" height="980" data-path="img/teams/team-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f296830291da245234bf9161d895329d 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cbf537f95087cf9a71e37ae9535b0d82 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f8cf292806083996ed9ae1e797b0499f 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5bf74870eb958d0244ca85814868cc26 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=12e1b764780ac11190aff98a57c767cb 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a90dcb3cab5dfb076782f529b405e418 2500w" />
</Frame>

<br />

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=14efcd70711ab4b22bbafc8c22052e32" data-og-width="1038" width="1038" data-og-height="530" height="530" data-path="img/teams/team-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=69ad03dfb2011a759403c8a7123d7b31 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=eba4bcda4d1680f08ea89fe585659662 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5482dcf72810e487430ed2b329b8bebb 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=efb545ab803ceb70a76919d767a54eaa 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f93fec94014fb67ef13f9ca77138146f 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e61d83496be8ba674fd2d6802bfa4faf 2500w" />
</Frame>

> A user can create up to 5 teams. You can be part of even more teams but only
> be the owner of 5 teams. If you need to own more teams please email us at
> [support@upstash.com](mailto:support@upstash.com).

You can still continue using your personal account or switch to a team.

> The databases in your personal account are not shared with anyone. If you want
> your database to be accessible by other users, you need to create it under a
> team.

## Switch Team

You need to switch to the team to create databases shared with other team
members. You can switch to the team via the switch button in the team table. Or
you can click your profile pic in the top right and switch to any team listed
there.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3782f2f2855491e1e080ac5b1918a771" data-og-width="902" width="902" data-og-height="546" height="546" data-path="img/teams/change-team.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=48e744717e0424e4b33bbafd59331e0e 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d595823ca2ef0c3dd63b9743f6772197 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=9e875ba20601d1644e28745042088319 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e987598f3aeb99d2bf29ca7d6a64349d 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2c9a67cf5bb85053f1e23c027fba9eac 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3f0999a7fc3a5f4c77cd1723172efac4 2500w" />
</Frame>

## Add/Remove Team Member

After switching to a team, if you are the Owner or an Admin of the team, you can add team members by navigating to `Account > Teams`. Simply enter their email addresses.It's not an issue if the email addresses are not yet registered with Upstash. Once the user registers with that email, they will gain access to the team. We do not send invitations; when you add a member, they become a member directly. You can also remove members from the same page.

> Only Admins or the Owner can add/remove users.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=daf226a3560d9ef46ab370dfc194076e" data-og-width="1040" width="1040" data-og-height="1158" height="1158" data-path="img/teams/team-member-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d2d33d778ae2102aeafcf9f971c99aaf 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=781bd793ea31c855249865c9e0243c52 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e8de31900c5cc26bfae41bf46080fe8a 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4a43b6cbcacf79a751f1d069d4e2f1ad 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=27cdea1d2d92d998965aebf6c69425ec 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c9b69a73c8b26889fa17b62f9fd94853 2500w" />
</Frame>

## Roles

While adding a team member, you will need to select a role. Here are the access rights associated with each role:

* Admin: This role has full access, including the ability to add and remove members, manage databases, and payment methods.

* Dev: This role can create, manage, and delete databases but cannot manage users or payment methods.

* Finance: This role is limited to managing payment methods and cannot manage databases or users.

* Owner: The Owner role has all the access rights of an Admin and, in addition to having the ability to delete the team. This role is automatically assigned to the user who created the team, and you cannot assign it to other members.

> If you want to change a user's role, you will need to delete and re-add them with the desired access rights.

## Delete Team

Only the original creator (owner) can delete a team. Also the team should not
have any active databases, namely all databases under the team should be deleted
first. To delete your team, first you need to switch your personal account then
you can delete your team in the team list under `Account > Teams`.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bc3cf60ab755331d665576c03c037579" data-og-width="2058" width="2058" data-og-height="1112" height="1112" data-path="img/teams/team-member.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2a2391b9e93c1bdc264559a5ee539e28 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=28037e45cef7f6323ecf262d696ba5f1 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ee688b9a5c101c433782c1bc9da637cc 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5e6e7cf3b989b6bd24edb43e88cbe66e 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cb367e35c494c5fa22d443085f0ecc1e 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a367d93486a13a5ce4d3659437edf120 2500w" />
</Frame>


# Access Anywhere
Source: https://upstash.com/docs/common/concepts/access-anywhere



Upstash has integrated REST APIs into all its products to facilitate access from various runtime environments. This integration is particularly beneficial for edge runtimes like Cloudflare Workers and Vercel Edge, which do not permit TCP connections, and for serverless functions such as AWS Lambda, which are stateless and do not retain connection information between invocations.

### Rationale

The absence of TCP connection support in edge runtimes and the stateless nature of serverless functions necessitate a different approach for persistent connections typically used in traditional server setups. The stateless REST API provided by Upstash addresses this gap, enabling consistent and reliable communication with data stores from these platforms.

### REST API Design

The REST APIs for Upstash services are thoughtfully designed to align closely with the conventions of each product. This ensures that users who are already familiar with these services will find the interactions intuitive and familiar. Our API endpoints are self-explanatory, following standard REST practices to guarantee ease of use and seamless integration.

<img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f43d16d28819cb7fcfc638d0ff3f1bcd" data-og-width="1794" width="1794" data-og-height="1068" height="1068" data-path="img/access-anywhere/restclient.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=95619248d2e0708920b3bea3dd63b708 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=de7b8b47d89984545fdf6ba920d0051a 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=126149df464792fdcb207bbeb754e762 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=53fca51a6018d81c20597422924dc19e 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6a6d36def36560186aa9ce2261f78d2d 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/access-anywhere/restclient.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=859e252db002c24c77e77f1470f0f180 2500w" />

### SDKs for Popular Languages

To enhance the developer experience, Upstash is developing SDKs in various popular programming languages. These SDKs simplify the process of integrating Upstash services with your applications by providing straightforward methods and functions that abstract the underlying REST API calls.

### Resources

[Redis REST API Docs](/redis/features/restapi)

[QStash REST API Docs](/qstash/api/authentication)

[Redis SDK - Typescript](https://github.com/upstash/upstash-redis)

[Redis SDK - Python](https://github.com/upstash/redis-python)

[QStash SDK - Typescript](https://github.com/upstash/sdk-qstash-ts)


# Global Replication
Source: https://upstash.com/docs/common/concepts/global-replication

Global Replication for Low Latency and High Availability

Upstash Redis automatically replicates your data to the regions you choose, so your application stays fast and responsive-no matter where your users are.

Add or remove regions from a database at any time with zero downtime. Each region acts as a replica, holding a copy of your data for low latency and high availability.

***

## Built for Modern Serverless Architectures

In serverless computing, performance isn't just about fast code‚Äîit's also about fast, reliable data access from anywhere in the world. Whether you're using Vercel Functions, Cloudflare Workers, Fastly Compute, or Deno Deploy, your data layer needs to be as distributed and flexible as your compute for best performance.

Upstash Global replicates your Redis data across multiple regions to:

* Minimize round-trip latency
* Guarantee high availability at scale

...even under heavy or dynamic workloads. Our HTTP-based Redis¬Æ client is optimized for serverless environments and delivers consistent performance under high concurrency or variable workloads.

As serverless platforms evolve with features like in-function concurrency (e.g. [Vercel's Fluid Compute](https://vercel.com/fluid)), you need a data layer that can keep up. Upstash Redis is a globally distributed, low-latency database that scales with your compute, wherever it runs.

***

## How Global Replication Works

To minimize latency for read operations, we use a replica model. Our tests show sub-millisecond latency for read commands in the same AWS region as the Upstash Redis¬Æ instance.

**Read commands are automatically served from the geographically closest replica**:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=05494e62471be046bd28d67cf1512d76" data-og-width="1875" width="1875" data-og-height="1080" height="1080" data-path="img/global-replication/reads.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e1c5fa1c9318a0a61be5e03fccaed448 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3db4f635f9731992361c68e8df7078a4 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a176acbe9614747a547ce738e7d03af3 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a08820e00abf2150a38dd5f9d88e744c 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=fd01b30bf0644990a6ec868ea77bc946 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/reads.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d93bb0f07197513fa4eb58aefd9ccb2f 2500w" />
</Frame>

**Write commands go to the primary database** for consistency. After a successful write, they are replicated to all read replicas:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b31700f08a8eb664796af4d6988fc1fc" data-og-width="1875" width="1875" data-og-height="1080" height="1080" data-path="img/global-replication/writes.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c919bf353cd650f5ca18310a4a8f96f7 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=adb9b77e0d43d568baf7e143d825a261 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a37546d0af4da9b10e3612432200bf7d 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=56173635091569ba3787e188c69218d6 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=faa467a7ae8e72eff11753733e800a06 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/writes.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=947703a4e20b64048a6242ef2171debd 2500w" />
</Frame>

***

## Available Regions

To create a globally distributed database, select a primary region and the number of read regions:

* Select a primary region for most write operations for best performance.
* Select read regions close to your users for optimized read speeds.

Each request is then automatically served by the closest read replica for maximum performance and minimum latency:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3a5942c2dd718dcf3fccf8ddb6f46359" data-og-width="1875" width="1875" data-og-height="1080" height="1080" data-path="img/global-replication/replication.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=89b4a8f2b9146283bdc6d409444b1faf 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9a8f70e543ae9ec07b2c43df05937373 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b1641dd97bf53fed8bd23b9323d5ac17 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=efbac6a590f767fda4335603a87adc39 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1b1ee1fdf0c6150362c60dd17d880817 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/global-replication/replication.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=968984eebce41c2948e84fe6b083f35f 2500w" />
</Frame>

**You can create read replicas in the following regions:**

* AWS US-East-1 (North Virginia)
* AWS US-East-2 (Ohio)
* AWS US-West-1 (North California)
* AWS US-West-2 (Oregon)
* AWS EU-West-1 (Ireland)
* AWS EU-West-2 (London)
* AWS EU-Central-1 (Frankfurt)
* AWS AP-South-1 (Mumbai)
* AWS AP-Northeast-1 (Tokyo)
* AWS AP-Southeast-1 (Singapore)
* AWS AP-Southeast-2 (Sydney)
* AWS SA-East-1 (S√£o Paulo)

Check out [our blog post](https://upstash.com/blog/global-database) to learn more about our global replication philosophy. You can also explore our [live benchmark](https://latency.upstash.com/) to see Upstash Redis latency from different locations around the world.


# Scale to Zero
Source: https://upstash.com/docs/common/concepts/scale-to-zero

Only pay for what you really use.

Traditionally, cloud services required users to predict their resource needs and provision servers or instances based on those predictions. This often led to over-provisioning to handle potential peak loads, resulting in paying for unused resources during periods of low demand.

By *scaling to zero*, our pricing model aligns more closely with actual usage.

## Pay for usage

You're only charged for the resources you actively use. When your application experiences low activity or no incoming requests, the system automatically scales down resources to a minimal level. This means you're no longer paying for idle capacity, resulting in cost savings.

<img src="https://upstash.com/blog/awsmsk/charts.png" />

## Flexibility

"Scaling to zero" offers flexibility in scaling both up and down. As your application experiences traffic spikes, the system scales up resources to meet demand. Conversely, during quiet periods, resources scale down.

## Focus on Innovation

Developers can concentrate on building and improving the application without constantly worrying about resource optimization. Upstash handles the scaling, allowing developers to focus on creating features that enhance user experiences.

In essence, this aligns pricing with actual utilization, increases cost efficiency, and promotes a more sustainable approach to resource consumption. This model empowers businesses to leverage cloud resources without incurring unnecessary expenses, making cloud computing more accessible and attractive to a broader range of organizations.


# Serverless
Source: https://upstash.com/docs/common/concepts/serverless

What do we mean by serverless?

Upstash is a modern serverless data platform. But what do we mean by serverless?

## No Server Management

In a serverless setup, developers don't need to worry about configuring or managing servers. We take care of server provisioning, scaling, and maintenance.

## Automatic Scaling

As traffic or demand increases, Upstash automatically scales the required resources to handle the load. This means applications can handle sudden spikes in traffic without manual intervention.

## Granular Billing

We charge based on the actual usage of resources rather than pre-allocated capacity. This can lead to more cost-effective solutions, as users only pay for what they consume. [Read more](/common/concepts/scale-to-zero)

## Stateless Functions

In serverless architectures, functions are typically stateless. However, the traditional approach involves establishing long-lived connections to databases, which can lead to issues in serverless environments if connections aren't properly managed after use. Additionally, there are scenarios where TCP connections may not be feasible. Upstash addresses this issue by offering access via HTTP, a universally available protocol across all platforms.

## Rapid Deployment

Fast iteration is the key to success in today's competitive environment. You can create a new Upstash database in seconds, with minimal required configuration.


# Account & Teams
Source: https://upstash.com/docs/common/help/account



## Create an Account

You can sign up to <a href="https://console.upstash.com" target="_blank">Upstash</a> using your Amazon, Github or Google accounts. Alternatively you can sign up using
email/password registration if you don't want to use these auth providers, or you
want to sign up using a corporate email address.

<Note>
  We do not access your information other than:

  * Your email
  * Your name
  * Your profile picture and we never share your information with third parties.
</Note>

Team management allows you collaborate with other users. You can create a team
and invite people to the team by email addresses. The team members will have
access to the databases created under the team depending on their roles.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bc3cf60ab755331d665576c03c037579" data-og-width="2058" width="2058" data-og-height="1112" height="1112" data-path="img/teams/team-member.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2a2391b9e93c1bdc264559a5ee539e28 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=28037e45cef7f6323ecf262d696ba5f1 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ee688b9a5c101c433782c1bc9da637cc 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5e6e7cf3b989b6bd24edb43e88cbe66e 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cb367e35c494c5fa22d443085f0ecc1e 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a367d93486a13a5ce4d3659437edf120 2500w" />
</Frame>

## Teams

### Create Team

You can create a team using the menu `Account > Teams`

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=45d8621fefc7358b8398beaab2be8d14" data-og-width="2084" width="2084" data-og-height="980" height="980" data-path="img/teams/team-page.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f296830291da245234bf9161d895329d 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cbf537f95087cf9a71e37ae9535b0d82 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f8cf292806083996ed9ae1e797b0499f 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5bf74870eb958d0244ca85814868cc26 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=12e1b764780ac11190aff98a57c767cb 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-page.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a90dcb3cab5dfb076782f529b405e418 2500w" />
</Frame>

<br />

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=14efcd70711ab4b22bbafc8c22052e32" data-og-width="1038" width="1038" data-og-height="530" height="530" data-path="img/teams/team-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=69ad03dfb2011a759403c8a7123d7b31 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=eba4bcda4d1680f08ea89fe585659662 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5482dcf72810e487430ed2b329b8bebb 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=efb545ab803ceb70a76919d767a54eaa 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f93fec94014fb67ef13f9ca77138146f 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-create.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e61d83496be8ba674fd2d6802bfa4faf 2500w" />
</Frame>

> A user can create up to 5 teams. You can be part of even more teams but only
> be the owner of 5 teams. If you need to own more teams please email us at
> [support@upstash.com](mailto:support@upstash.com).

You can still continue using your personal account or switch to a team.

> The databases in your personal account are not shared with anyone. If you want
> your database to be accessible by other users, you need to create it under a
> team.

### Switch Team

You need to switch to the team to create databases shared with other team
members. You can switch to the team via the switch button in the team table. Or
you can click your profile pic in the top right and switch to any team listed
there.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3782f2f2855491e1e080ac5b1918a771" data-og-width="902" width="902" data-og-height="546" height="546" data-path="img/teams/change-team.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=48e744717e0424e4b33bbafd59331e0e 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d595823ca2ef0c3dd63b9743f6772197 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=9e875ba20601d1644e28745042088319 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e987598f3aeb99d2bf29ca7d6a64349d 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2c9a67cf5bb85053f1e23c027fba9eac 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/change-team.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3f0999a7fc3a5f4c77cd1723172efac4 2500w" />
</Frame>

### Add/Remove Team Member

Once you switched to a team, you can add team members in `Account > Teams` if
you are Owner or Admin for of the team. Entering email will be enough. The email
may not registered to Upstash yet, it is not a problem. Once the user registers
with that email, he/she will be able to switch to the team. We do not send
invitation, so when you add a member, he/she becomes a member directly. You can
remove the members from the same page.

> Only Admins or the Owner can add/remove users.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=daf226a3560d9ef46ab370dfc194076e" data-og-width="1040" width="1040" data-og-height="1158" height="1158" data-path="img/teams/team-member-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d2d33d778ae2102aeafcf9f971c99aaf 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=781bd793ea31c855249865c9e0243c52 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e8de31900c5cc26bfae41bf46080fe8a 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4a43b6cbcacf79a751f1d069d4e2f1ad 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=27cdea1d2d92d998965aebf6c69425ec 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member-create.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c9b69a73c8b26889fa17b62f9fd94853 2500w" />
</Frame>

### Roles

While adding a team member you need to select a role. Here the privileges of
each role:

* Admin: This role has full access including adding removing members, databases,
  payment methods.

* Dev: This role can create, manage and delete databases. It can not manage
  users and payment methods.

* Finance: This role can only manage payment methods. It can not manage the
  databases and users.

* Owner: Owner has all the privileges that admin has. In addition he is the only
  person who can delete the team. This role is assigned to the user who created
  the team. So you can not create a member with Owner role.

> If you want change role of a user, you need to delete and add again.

### Delete Team

Only the original creator (owner) can delete a team. Also the team should not
have any active databases, namely all databases under the team should be deleted
first. To delete your team, first you need to switch your personal account then
you can delete your team in the team list under `Account > Teams`.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bc3cf60ab755331d665576c03c037579" data-og-width="2058" width="2058" data-og-height="1112" height="1112" data-path="img/teams/team-member.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2a2391b9e93c1bdc264559a5ee539e28 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=28037e45cef7f6323ecf262d696ba5f1 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ee688b9a5c101c433782c1bc9da637cc 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5e6e7cf3b989b6bd24edb43e88cbe66e 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cb367e35c494c5fa22d443085f0ecc1e 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/teams/team-member.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a367d93486a13a5ce4d3659437edf120 2500w" />
</Frame>


# Announcements
Source: https://upstash.com/docs/common/help/announcements

Upstash Announcements!

Removal of GraphQL API and edge caching (Redis) (October 1, 2022) These two
features have been already deprecated. We are planning to deactivate them
completely on November 1st. We recommend use of REST API to replace GraphQL API
and Global databases instead of Edge caching.

Removal of strong consistency (Redis) (October 1, 2022) Upstash supported Strong
Consistency mode for the single region databases. We decided to deprecate this
feature because its effect on latency started to conflict with the performance
expectations of Redis use cases. Moreover, we improved the consistency of
replication to guarantee Read-Your-Writes consistency. Strong consistency will
be disabled on existing databases on November 1st.

#### Redis pay-as-you-go usage cap (October 1, 2022)

We are increasing the max usage cap to \$160 from \$120 as of October 1st. This
update is needed because of the increasing infrastructure cost due to
replicating all databases to multiple instances. After your database exceeds the
max usage cost, your database might be rate limited.

#### Replication is enabled (Sep 29, 2022)

All new and existing paid databases will be replicated to multiple replicas.
Replication enables high availability in case of system and infrastructure
failures. Starting from October 1st, we will gradually upgrade all databases
without downtime. Free databases will stay single replica.

<hr />

#### QStash Price Decrease (Sep 15, 2022)

The price is \$1 per 100K requests.

<hr />

#### [Pulumi Provider is available](https://upstash.com/blog/upstash-pulumi-provider)  (August 4, 2022)

<hr />

#### [QStash is released and announced](https://upstash.com/blog/qstash-announcement)  (July 18, 2022)

<hr />

#### [Announcing Upstash CLI](https://upstash.com/blog/upstash-cli)  (May 16, 2022)

<hr />

#### [Introducing Redis 6 Compatibility](https://upstash.com/blog/redis-6)  (April 10, 2022)

<hr />

#### Strong Consistency Deprecated (March 29, 2022)

We have deprecated Strong Consistency mode for Redis databases due to its
performance impact. This will not be available for new databases. We are
planning to disable it on existing databases before the end of 2023. The
database owners will be notified via email.

<hr />

#### [Announcing Upstash Redis SDK v1.0.0](https://upstash.com/blog/upstash-redis-sdk-v1) (March 14, 2022)

<hr />

#### Support for Google Cloud (June 8, 2021)

Google Cloud is available for Upstash Redis databases. We initially support
US-Central-1 (Iowa) region. Check the
[get started guide](https://docs.upstash.com/redis/howto/getstartedgooglecloudfunctions).

<hr />

#### Support for AWS Japan (March 1, 2021)

„Åì„Çì„Å´„Å°„ÅØÊó•Êú¨

Support for AWS Tokyo Region was the most requested feature by our users. Now
our users can create their database in AWS Asia Pacific (Tokyo) region
(ap-northeast-1). In addition to Japan, Upstash is available in the regions
us-west-1, us-east-1, eu-west-1.

Click [here](https://console.upstash.com) to start your database for free.

Click [here](https://roadmap.upstash.com) to request new regions to be
supported.

<hr />

#### Vercel Integration (February 22, 2021)

Upstash\&Vercel integration has been released. Now you are able to integrate
Upstash to your project easily. We believe Upstash is the perfect database for
your applications thanks to its:

* Low latency data
* Per request pricing
* Durable storage
* Ease of use

Below are the resources about the integration:

See [how to guide](https://docs.upstash.com/redis/howto/vercelintegration).

See [integration page](https://vercel.com/integrations/upstash).

See
[Roadmap Voting app](https://github.com/upstash/roadmap)
as a showcase for the integration.


# Compliance
Source: https://upstash.com/docs/common/help/compliance



## Upstash Legal & Security Documents

* [Upstash Terms of Service](https://upstash.com/static/trust/terms.pdf)
* [Upstash Privacy Policy](https://upstash.com/static/trust/privacy.pdf)
* [Upstash Data Processing Agreement](https://upstash.com/static/trust/dpa.pdf)
* [Upstash Technical and Organizational Security Measures](https://upstash.com/static/trust/security-measures.pdf)
* [Upstash Subcontractors](https://upstash.com/static/trust/subprocessors.pdf)

## Is Upstash SOC2 Compliant?

Upstash Redis databases under Pro and Enterprise support plans are SOC2 compliant. Check our [trust page](https://trust.upstash.com/) for details.

## Is Upstash ISO-27001 Compliant?

We are in process of getting this certification. Contact us
([support@upstash.com](mailto:support@upstash.com)) to learn about the expected
date.

## Is Upstash GDPR Compliant?

Yes. For more information, see our
[Privacy Policy](https://upstash.com/static/trust/privacy.pdf). We acquire DPAs
from each [subcontractor](https://upstash.com/static/trust/subprocessors.pdf)
that we work with.

## Is Upstash HIPAA Compliant?

We are in process of getting this certification. Contact us
([support@upstash.com](mailto:support@upstash.com)) to learn about the expected
date.

## Is Upstash PCI Compliant?

Upstash does not store personal credit card information. We use Stripe for
payment processing. Stripe is a certified PCI Service Provider Level 1, which is
the highest level of certification in the payments industry.

## Does Upstash conduct vulnerability scanning and penetration tests?

Yes, we use third party tools and work with pen testers. We share the results
with Enterprise customers. Contact us
([support@upstash.com](mailto:support@upstash.com)) for more information.

## Does Upstash take backups?

Yes, we take regular snapshots of the data cluster to the AWS S3 platform.

## Does Upstash encrypt data?

Customers can enable TLS when creating a database or cluster, and we recommend this for production environments. Additionally, we encrypt data at rest upon customer request.


# Legal
Source: https://upstash.com/docs/common/help/legal



## Upstash Legal Documents

* [Upstash Terms of Service](https://upstash.com/trust/terms.pdf)
* [Upstash Privacy Policy](https://upstash.com/trust/privacy.pdf)
* [Upstash Subcontractors](https://upstash.com/trust/subprocessors.pdf)
* [Context7 Addendum](https://upstash.com/trust/context7addendum.pdf)
* [Data Processing Addendum](https://upstash.com/static/trust/dpa.pdf)


# Production Checklist
Source: https://upstash.com/docs/common/help/production-checklist



This checklist provides essential recommendations for securing and optimizing your Upstash databases for production workloads.

## Security Features

### Enable Prod Pack

Prod Pack provides enterprise-grade security and monitoring features:

* 99.99% uptime SLA
* SOC-2 Type 2 report available
* Role-Based Access Control (RBAC)
* Encryption at Rest
* Advanced monitoring (Prometheus, Datadog)
* High availability for read regions

<Note>
  Prod Pack is available as a \$200/month add-on per database for all paid plans except Free tier.
</Note>

### Enable Credential Protection

Protect your database credentials (Prod Pack feature):

* Credentials are never stored in Upstash infrastructure
* Credentials are displayed only once during enablement
* Console features requiring database access are disabled

<Warning>
  Disabling this feature will permanently revoke current credentials and generate new ones.
</Warning>

### Configure IP Allowlist

Restrict database access to specific IP addresses:

* Available on all plans except Free tier
* Supports IPv4 addresses and CIDR blocks
* Multiple IP ranges can be configured

### Implement Redis ACL

Use Redis Access Control Lists to restrict user access:

* Create users with minimal required permissions
* Available for both TCP connections and REST API
* Use `ACL RESTTOKEN` command to generate REST tokens

### Enable Multi-Factor Authentication

Enable MFA on your Upstash account for enhanced security:

* Use your existing authentication provider (Google, GitHub, Amazon)
* Consider using a dedicated email/password account for production
* Force MFA for all team members to ensure consistent security
* Regularly review account access and team member permissions

### Secure Credential Management

Follow these best practices:

* Never hardcode credentials in your application code
* Use environment variables or secret management systems
* Reset passwords immediately if credentials are compromised
* Use Read-Only tokens for public-facing applications

## Network Security

### TLS Encryption

TLS is always enabled on Upstash Redis databases.

### VPC Peering (Enterprise)

Connect databases to your VPCs using private IP:

* Database becomes inaccessible from public networks
* Minimizes data transfer costs
* Available for Enterprise customers

## Monitoring & Observability

### Enable Advanced Monitoring

Prod Pack includes comprehensive monitoring:

* Prometheus integration
* Datadog integration
* Extended console metrics (up to one month)

## High Availability & Backup

### Enable Daily Backups

Configure automated daily backups for data protection:

* Available on all paid plans
* Backup retention up to 3 days with Prod Pack
* Hourly backups with customizable retention (Enterprise)

### Global Replication

For global applications, consider using Global Database:

* Distribute data across multiple regions
* Minimize latency for users worldwide
* Enhanced disaster recovery capabilities

## Compliance & Governance

### SOC-2 Compliance

Prod Pack and Enterprise plans include SOC-2 Type 2 compliance:

* Request SOC-2 report from [trust.upstash.com](https://trust.upstash.com/)
* Available for production workloads

### Enterprise Features

For enterprise customers:

* HIPAA compliance available
* SAML SSO integration
* Access logs available
* Custom resource allocation

## Pre-Production Checklist

Before going live, ensure you have:

* [ ] Prod Pack enabled (recommended)
* [ ] Credential Protection enabled
* [ ] IP Allowlist configured
* [ ] MFA enabled on your account
* [ ] Daily backups enabled
* [ ] Monitoring and alerts configured
* [ ] Environment variables secured
* [ ] Error handling tested

## Additional Resources

* [Security Features](/redis/features/security)
* [Prod Pack & Enterprise](/redis/overall/enterprise)
* [Backup & Restore](/redis/features/backup)
* [Global Database](/redis/features/globaldatabase)
* [Monitoring & Metrics](/redis/howto/metricsandcharts)
* [Compliance Information](/common/help/compliance)
* [Professional Support](/common/help/prosupport)

For additional assistance with production deployment, contact our support team at [support@upstash.com](mailto:support@upstash.com).


# Professional Support
Source: https://upstash.com/docs/common/help/prosupport



For all Upstash products, we manage everything for you and let you focus on more important things. If you ever need further help, our dedicated Professional Support team are here to ensure you get the most out of our platform, whether you‚Äôre just starting or scaling to new heights.

Professional Support is strongly recommended especially for customers who use Upstash as part of their production systems.

# Expert Guidance

Get direct access to our team of specialists who can provide insights, troubleshooting, and best practices tailored to your unique use case. In any urgent incident you might have, our Support team will be standing by and ready to join you for troubleshooting.

Professional Support package includes:

* **Guaranteed Response Time:** Rapid Response Time SLA to urgent support requests, ensuring your concerns are addressed promptly with a **24/7 coverage**.
* **Customer Onboarding:** A personalized session to guide you through utilizing our support services and reviewing your specific use case for a seamless start.
* **Quarterly Use Case Review & Health Check:** On-request sessions every quarter to review your use case and ensure optimal performance.
* **Dedicated Slack Channel:** Direct access to our team via a private Slack channel, so you can reach out whenever you need assistance.
* **Incident Support:** Video call support during critical incidents to provide immediate help and resolution.
* **Root Cause Analysis:** Comprehensive investigation and post-mortem analysis of critical incidents to identify and address the root cause.

# Response Time SLA

We understand that timely assistance is critical for production workloads, so your access to our Support team comes with 24/7 coverage and below SLA:

| Severity                        | Response Time |
| ------------------------------- | ------------- |
| P1 - Production system down     | 30 minutes    |
| P2 - Production system impaired | 2 hours       |
| P3 - Minor issue                | 12 hours      |
| P4 - General guidance           | 24 hours      |

## How to Reach Out?

As a Professional Support Customer, below are the **two methods** to reach out to Upstash Support Team, in case you need to utilize our services:

#### Starting a Chat

You will see a chatbox on the bottom right when viewing Upstash console, docs and website. Once you initiate a chat, Professional Support customers will be prompted to select a severity level:

<img noZoom width="300" height="100" src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a1ad636c47b05611214a0345e11eec3e" data-og-width="802" data-og-height="1416" data-path="img/pro-support/image.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6bb402a261987a15b1604dcfa54ff470 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ae7b14d8bd3dbd6afb46f4e905775077 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=770709aaad824a69682bf5a447b90fea 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=33e039a3c90eae07f1b846103599f69f 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bef88e175b5406a533f63297db51aa29 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/pro-support/image.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4690e136e4a80b000f38612935603b0a 2500w" />

<Note>
  To be able to see these options in chat, remember to sign into your Upstash Account first.
</Note>

If you select "P1 - Production down, no workaround", or "P2 - Production impaired with workaround" options, you will be triggering an alert for our team to urgently step in.

#### Sending an Email

Sending an email with details to [support@upstash.com](mailto:support@upstash.com) is another way to submit a support request. In case of an urgency, sending an email with details by using "urgent" keyword in email subject is another alternative to alert our team about a possible incident.

# Pricing

For pricing and further details about Professional Support, please contact us at [support@upstash.com](mailto:support@upstash.com)


# Uptime SLA
Source: https://upstash.com/docs/common/help/sla



This Service Level Agreement ("SLA") applies to Upstash resources with the Prod Pack add-on or Enterprise plans. It is clarified that this SLA is subject to the [terms of the Agreement](https://upstash.com/trust/terms.pdf), and does not derogate therefrom (capitalized terms, unless otherwise indicated herein, have the meaning specified in the Agreement).

To receive uptime SLA guarantees, you need to enable the Prod Pack add-on or be on an Enterprise plan for your resource. Learn more about [Prod Pack and Enterprise features](/redis/overall/enterprise).

Upstash reserves the right to change the terms of this SLA by publishing updated
terms on its website, such change to be effective as of the date of publication.

### Uptime Guarantee

Upstash will use commercially reasonable efforts to make resources with Prod Pack add-on or Enterprise plans available with a Monthly Uptime Percentage of at least **99.99%**.

In the event any of the services do not meet the SLA, you will be eligible to
receive a Service Credit as described below.

| Monthly Uptime Percentage                           | Service Credit Percentage |
| --------------------------------------------------- | ------------------------- |
| Less than 99.99% but equal to or greater than 99.0% | 10%                       |
| Less than 99.0% but equal to or greater than 95.0%  | 30%                       |
| Less than 95.0%                                     | 60%                       |

### SLA Credits

Service Credits are calculated as a percentage of the monthly bill (excluding
one-time payments such as upfront payments) for the resource in the affected
region that did not meet the SLA.

Uptime percentages are recorded and published in the
[Upstash Status Page](https://status.upstash.com).

To receive a Service Credit, you should submit a claim by sending an email to
[support@upstash.com](mailto:support@upstash.com). Your credit request should be
received by us before the end of the second billing cycle after the incident
occurred.

We will apply any service credits against future payments for the applicable
services. At our discretion, we may issue the Service Credit to the credit card
you used. Service Credits will not entitle you to any refund or other payment. A
Service Credit will be applicable and issued only if the credit amount for the
applicable monthly billing cycle is greater than one dollar (\$1 USD). Service
Credits may not be transferred or applied to any other account.

### Getting Uptime SLA Coverage

To receive uptime SLA guarantees for your resources, you need to upgrade to either:

* **Prod Pack**: An add-on per resource available to both pay-as-you-go and fixed-price plans
* **Enterprise Plan**: A custom plan that can cover one or more of your resources

You can activate Prod Pack on the resource details page in the console. For Enterprise plans, contact [support@upstash.com](mailto:support@upstash.com).

Learn more about [Prod Pack and Enterprise features](/redis/overall/enterprise).


# Support & Contact Us
Source: https://upstash.com/docs/common/help/support



## Community

[Upstash Discord Channel](https://upstash.com/discord) is the best way to
interact with the community.

## Team

Regardless of your subscription plan, you can contact the team
via [support@upstash.com](mailto:support@upstash.com) for technical support as
well as questions and feedback.

## Follow Us

Follow us on [X](https://x.com/upstash).

## Enterprise Support

Get [Enterprise Support](/common/help/prosupport) for your organization from the Upstash team.


# Uptime Monitor
Source: https://upstash.com/docs/common/help/uptime



## Status Page

You can track the uptime status of Upstash databases in
[Upstash Status Page](https://status.upstash.com)

## Latency Monitor

You can see the average latencies for different regions in
[Upstash Latency Monitoring](https://latency.upstash.com) page


# Trials
Source: https://upstash.com/docs/common/trials



<Info>
  If you want to try Upstash paid and pro plans, we can offer **Free
  Trials**. Email us at [support@upstash.com](mailto:support@upstash.com)
</Info>


# Overview
Source: https://upstash.com/docs/devops/cli/overview



Manage Upstash resources in your terminal or CI.

You can find the Github Repository [here](https://github.com/upstash/cli).

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=937abb7a6ac182220417755140c1a552" data-og-width="2048" width="2048" data-og-height="1414" height="1414" data-path="img/oss/cli/banner.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=539308726a2f9892a345d9b706b944ff 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2ff1ff319b6f77b3b994b2dab8a2dd49 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=69085bd86ca2af13ac25016635e09bb4 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=121513fcc45c291dc2f68217900ad93b 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0a8989255b1e309d60414658a3a68bba 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/oss/cli/banner.svg?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=249344a05e443b79f630cf8f022dc3ce 2500w" />
</Frame>

<br />

# Installation

## npm

You can install upstash's cli directly from npm

```bash  theme={"system"}
npm i -g @upstash/cli
```

It will be added as `upstash` to your system's path.

## Compiled binaries:

`upstash` is also available from the
[releases page](https://github.com/upstash/cli/releases/latest) compiled
for windows, linux and mac (both intel and m1).

# Usage

```bash  theme={"system"}
> upstash

  Usage:   upstash
  Version: development

  Description:

    Official cli for Upstash products

  Options:

    -h, --help               - Show this help.
    -V, --version            - Show the version number for this program.
    -c, --config   <string>  - Path to .upstash.json file

  Commands:

    auth   - Login and logout
    redis  - Manage redis database instances
    team   - Manage your teams and their members

  Environment variables:

    UPSTASH_EMAIL    <string>  - The email you use on upstash
    UPSTASH_API_KEY  <string>  - The api key from upstash
```

## Authentication

When running `upstash` for the first time, you should log in using
`upstash auth login`. Provide your email and an api key.
[See here for how to get a key.](https://docs.upstash.com/redis/howto/developerapi#api-development)

As an alternative to logging in, you can provide `UPSTASH_EMAIL` and
`UPSTASH_API_KEY` as environment variables.

## Usage

Let's create a new redis database:

```
> upstash redis create --name=my-db --region=eu-west-1
  Database has been created

  database_id          a3e25299-132a-45b9-b026-c73f5a807859
  database_name        my-db
  database_type        Pay as You Go
  region               eu-west-1
  type                 paid
  port                 37090
  creation_time        1652687630
  state                active
  password             88ae6392a1084d1186a3da37fb5f5a30
  user_email           andreas@upstash.com
  endpoint             eu1-magnetic-lacewing-37090.upstash.io
  edge                 false
  multizone            false
  rest_token           AZDiASQgYTNlMjUyOTktMTMyYS00NWI5LWIwMjYtYzczZjVhODA3ODU5ODhhZTYzOTJhMTA4NGQxMTg2YTNkYTM3ZmI1ZjVhMzA=
  read_only_rest_token ApDiASQgYTNlMjUyOTktMTMyYS00NWI5LWIwMjYtYzczZjVhODA3ODU5O_InFjRVX1XHsaSjq1wSerFCugZ8t8O1aTfbF6Jhq1I=


  You can visit your database details page: https://console.upstash.com/redis/a3e25299-132a-45b9-b026-c73f5a807859

  Connect to your database with redis-cli: redis-cli -u redis://88ae6392a1084d1186a3da37fb5f5a30@eu1-magnetic-lacewing-37090.upstash.io:37090
```

## Output

Most commands support the `--json` flag to return the raw api response as json,
which you can parse and automate your system.

```bash  theme={"system"}
> upstash  redis create --name=test2113 --region=us-central1 --json | jq '.endpoint'

 "gusc1-clean-gelding-30208.upstash.io"
```


# Authentication
Source: https://upstash.com/docs/devops/developer-api/authentication

Authentication for the Upstash Developer API

The Upstash API requires API keys to authenticate requests. You can view and
manage API keys at the Upstash Console.

Upstash API uses HTTP Basic authentication. You should pass `EMAIL` and
`API_KEY` as basic authentication username and password respectively.

With a client such as `curl`, you can pass your credentials with the `-u`
option, as the following example shows:

```curl  theme={"system"}
curl https://api.upstash.com/v2/redis/databases -u EMAIL:API_KEY
```

Replace `EMAIL` and `API_KEY` with your email and API key.


# HTTP Status Codes
Source: https://upstash.com/docs/devops/developer-api/http_status_codes

The Upstash API uses the following HTTP Status codes:

| Code | Description               |                                                                                 |
| ---- | ------------------------- | ------------------------------------------------------------------------------- |
| 200  | **OK**                    | Indicates that a request completed successfully and the response contains data. |
| 400  | **Bad Request**           | Your request is invalid.                                                        |
| 401  | **Unauthorized**          | Your API key is wrong.                                                          |
| 403  | **Forbidden**             | The kitten requested is hidden for administrators only.                         |
| 404  | **Not Found**             | The specified kitten could not be found.                                        |
| 405  | **Method Not Allowed**    | You tried to access a kitten with an invalid method.                            |
| 406  | **Not Acceptable**        | You requested a format that isn't JSON.                                         |
| 429  | **Too Many Requests**     | You're requesting too many kittens! Slow down!                                  |
| 500  | **Internal Server Error** | We had a problem with our server. Try again later.                              |
| 503  | **Service Unavailable**   | We're temporarily offline for maintenance. Please try again later.              |


# Getting Started
Source: https://upstash.com/docs/devops/developer-api/introduction



Using Upstash API, you can develop applications that can create and manage
Upstash products and resources. You can automate everything that
you can do in the console. To use developer API, you need to create an API key
in the console.

<Note>
  The Developer API is only available to native Upstash accounts. Accounts created via third-party platforms like Vercel or Fly.io are not supported.
</Note>

### Create an API key

1. Log in to the console then in the left menu click the
   `Account > Management API` link.

2. Click the `Create API Key` button.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0ee4011eb149892c533eecbd904e2934" data-og-width="2068" width="2068" data-og-height="1102" height="1102" data-path="img/developerapi/api-key-list.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=660c631a8f49489a3ff8948dd6db41c3 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=8e561d91ca284d7c7819a8ad74dcea65 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9e19189fe974b4c4179a70ea8282fdca 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2029bc6f2d13a1d7854a795f272c2c1f 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=287f08f34a7857d56af29a6c0c3ad26f 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-list.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5af51a63b067e72e902977c040bc8864 2500w" />
</Frame>

3. Enter a name for your key. You can not use the same name for multiple keys.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=db586a9d35310683c8537cca2fce7d50" data-og-width="1040" width="1040" data-og-height="484" height="484" data-path="img/developerapi/api-key-create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=463a076f8898851266fc937cdc661ca0 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5f96cb6172a2670f5b5a8f450a71b7d7 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4cb381cdd6e18a43ddde322bd06286bc 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=13b331fc613dd29cfa0a427ad33b93e4 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2ef3c3b3232336133c710e078386d2b8 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-create.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2e0928223a4eea7b19677222be91d184 2500w" />
</Frame>

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1295912b886ea491e71da0c6c0675d87" data-og-width="1040" width="1040" data-og-height="608" height="608" data-path="img/developerapi/api-key-secret.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c9c20a789894acb2b466be8cfb85b5f1 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6f15c1a8c536e0a1c85505d4487abaec 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=76fd28466dfc601b999b31da9d40d3b2 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4d7039e531cbf706acbdc3fb62083d4e 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5d65db7ea62cfc1a988bcc91c0b3ba97 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/developerapi/api-key-secret.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9f653bc215ca2eb53aad4c07a8ca0f2b 2500w" />
</Frame>

You need to download or copy/save your API key. Upstash does not remember or
keep your API for security reasons. So if you forget your API key, it becomes
useless; you need to create a new one.

<br />

You can create multiple keys. It is recommended to use different keys in
different applications. By default one user can create up to 37 API keys. If you
need more than that, please send us an email at
[support@upstash.com](mailto:support@upstash.com)

### Deleting an API key

When an API key is exposed (e.g. accidentally shared in a public repository) or
not being used anymore; you should delete it. You can delete the API keys in
`Account > API Keys` screen.

### Roadmap

**Role based access:** You will be able to create API keys with specific
privileges. For example you will be able to create a key with read-only access.

**Stats:** We will provide reports based on usage of your API keys.


# Create Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/create_backup

devops/developer-api/openapi.yml post /redis/create-backup/{id}
This endpoint creates a backup for a Redis database.



# Delete Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/delete_backup

devops/developer-api/openapi.yml delete /redis/delete-backup/{id}/{backup_id}
This endpoint deletes a backup of a Redis database.



# Disable Daily Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/disable_dailybackup

devops/developer-api/openapi.yml patch /redis/disable-dailybackup/{id}
This endpoint disables daily backup for a Redis database.



# Enable Daily Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/enable_dailybackup

devops/developer-api/openapi.yml patch /redis/enable-dailybackup/{id}
This endpoint enables daily backup for a Redis database.



# List Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/list_backup

devops/developer-api/openapi.yml get /redis/list-backup/{id}
This endpoint lists all backups for a Redis database.



# Restore Backup
Source: https://upstash.com/docs/devops/developer-api/redis/backup/restore_backup

devops/developer-api/openapi.yml post /redis/restore-backup/{id}
This endpoint restores data from an existing backup.



# Change Database Plan
Source: https://upstash.com/docs/devops/developer-api/redis/change_plan

devops/developer-api/openapi.yml post /redis/change-plan/{id}
This endpoint changes the plan of a Redis database.



# Create Redis Database
Source: https://upstash.com/docs/devops/developer-api/redis/create_database_global

devops/developer-api/openapi.yml post /redis/database
This endpoint creates a new Redis database.



# Delete Database
Source: https://upstash.com/docs/devops/developer-api/redis/delete_database

devops/developer-api/openapi.yml delete /redis/database/{id}
This endpoint deletes a database.



# Disable Auto Upgrade
Source: https://upstash.com/docs/devops/developer-api/redis/disable_autoscaling

devops/developer-api/openapi.yml post /redis/disable-autoupgrade/{id}
This endpoint disables Auto Upgrade for given database.



# Disable Eviction
Source: https://upstash.com/docs/devops/developer-api/redis/disable_eviction

devops/developer-api/openapi.yml post /redis/disable-eviction/{id}
This endpoint disables eviction for given database.



# Enable Auto Upgrade
Source: https://upstash.com/docs/devops/developer-api/redis/enable_autoscaling

devops/developer-api/openapi.yml post /redis/enable-autoupgrade/{id}
This endpoint enables Auto Upgrade for given database.



# Enable Eviction
Source: https://upstash.com/docs/devops/developer-api/redis/enable_eviction

devops/developer-api/openapi.yml post /redis/enable-eviction/{id}
This endpoint enables eviction for given database.



# Enable TLS
Source: https://upstash.com/docs/devops/developer-api/redis/enable_tls

devops/developer-api/openapi.yml post /redis/enable-tls/{id}
This endpoint enables tls on a database.



# Get Database
Source: https://upstash.com/docs/devops/developer-api/redis/get_database

devops/developer-api/openapi.yml get /redis/database/{id}
This endpoint gets details of a database.



# Get Database Stats
Source: https://upstash.com/docs/devops/developer-api/redis/get_database_stats

devops/developer-api/openapi.yml get /redis/stats/{id}
This endpoint gets detailed stats of a database.



# List Databases
Source: https://upstash.com/docs/devops/developer-api/redis/list_databases

devops/developer-api/openapi.yml get /redis/databases
This endpoint list all databases of user.



# Move To Team
Source: https://upstash.com/docs/devops/developer-api/redis/moveto_team

devops/developer-api/openapi.yml post /redis/move-to-team
This endpoint moves database under a target team



# Rename Database
Source: https://upstash.com/docs/devops/developer-api/redis/rename_database

devops/developer-api/openapi.yml post /redis/rename/{id}
This endpoint renames a database.



# Reset Password
Source: https://upstash.com/docs/devops/developer-api/redis/reset_password

devops/developer-api/openapi.yml post /redis/reset-password/{id}
This endpoint updates the password of a database.



# Update Database Budget
Source: https://upstash.com/docs/devops/developer-api/redis/update_budget

devops/developer-api/openapi.yml patch /redis/update-budget/{id}
This endpoint updates the monthly budget of a Redis database.



# Update Regions
Source: https://upstash.com/docs/devops/developer-api/redis/update_regions

devops/developer-api/openapi.yml post /redis/update-regions/{id}
Update the regions of a database



# Add Team Member
Source: https://upstash.com/docs/devops/developer-api/teams/add_team_member

devops/developer-api/openapi.yml post /teams/member
This endpoint adds a new team member to the specified team.



# Create Team
Source: https://upstash.com/docs/devops/developer-api/teams/create_team

devops/developer-api/openapi.yml post /team
This endpoint creates a new team.



# Delete Team
Source: https://upstash.com/docs/devops/developer-api/teams/delete_team

devops/developer-api/openapi.yml delete /team/{id}
This endpoint deletes a team.



# Delete Team Member
Source: https://upstash.com/docs/devops/developer-api/teams/delete_team_member

devops/developer-api/openapi.yml delete /teams/member
This endpoint deletes a team member from the specified team.



# Get Team Members
Source: https://upstash.com/docs/devops/developer-api/teams/get_team_members

devops/developer-api/openapi.yml get /teams/{team_id}
This endpoint list all members of a team.



# List Teams
Source: https://upstash.com/docs/devops/developer-api/teams/list_teams

devops/developer-api/openapi.yml get /teams
This endpoint lists all teams of user.



# Create Index
Source: https://upstash.com/docs/devops/developer-api/vector/create_index

devops/developer-api/openapi.yml post /vector/index
This endpoint creates an index.



# Delete Index
Source: https://upstash.com/docs/devops/developer-api/vector/delete_index

devops/developer-api/openapi.yml delete /vector/index/{id}
This endpoint deletes an index.



# Get Index
Source: https://upstash.com/docs/devops/developer-api/vector/get_index

devops/developer-api/openapi.yml get /vector/index/{id}
This endpoint returns the data associated to a index.



# List Indices
Source: https://upstash.com/docs/devops/developer-api/vector/list_indices

devops/developer-api/openapi.yml get /vector/index
This endpoint returns the data related to all indices of an account as a list.



# Rename Index
Source: https://upstash.com/docs/devops/developer-api/vector/rename_index

devops/developer-api/openapi.yml post /vector/index/{id}/rename
This endpoint is used to change the name of an index.



# Reset Index Passwords
Source: https://upstash.com/docs/devops/developer-api/vector/reset_index_passwords

devops/developer-api/openapi.yml post /vector/index/{id}/reset-password
This endpoint is used to reset regular and readonly tokens of an index.



# Set Index Plan
Source: https://upstash.com/docs/devops/developer-api/vector/set_index_plan

devops/developer-api/openapi.yml post /vector/index/{id}/setplan
This endpoint is used to change the plan of an index.



# Transfer Index
Source: https://upstash.com/docs/devops/developer-api/vector/transfer_index

devops/developer-api/openapi.yml post /vector/index/{id}/transfer
This endpoint is used to transfer an index to another team. 
Transferring to a personal account is not supported. However, transferring an index from a personal account to a team is allowed.




# Overview
Source: https://upstash.com/docs/devops/pulumi/overview



The Upstash Pulumi Provider lets you manage [Upstash](https://upstash.com) Redis resources programmatically.

You can find the Github Repository [here](https://github.com/upstash/pulumi-upstash).

## Installing

This package is available for several languages/platforms:

### Node.js (JavaScript/TypeScript)

To use from JavaScript or TypeScript in Node.js, install using either `npm`:

```bash  theme={"system"}
npm install @upstash/pulumi
```

or `yarn`:

```bash  theme={"system"}
yarn add @upstash/pulumi
```

### Python

To use from Python, install using `pip`:

```bash  theme={"system"}
pip install upstash_pulumi
```

### Go

To use from Go, use `go get` to grab the latest version of the library:

```bash  theme={"system"}
go get github.com/upstash/pulumi-upstash/sdk/go/...
```

## Configuration

The following configuration points are available for the `upstash` provider:

* `upstash:apiKey` (environment: `UPSTASH_API_KEY`) - the API key for `upstash`. Can be obtained from the [console](https://console.upstash.com).
* `upstash:email` (environment: `UPSTASH_EMAIL`) - owner email of the resources

## Some Examples

### TypeScript:

```typescript  theme={"system"}
import * as pulumi from "@pulumi/pulumi";
import * as upstash from "@upstash/pulumi";

// multiple redis databases in a single for loop

for (let i = 0; i < 5; i++) {
  new upstash.RedisDatabase("mydb" + i, {
    databaseName: "pulumi-ts-db" + i,
    region: "eu-west-1",
    tls: true,
  });
}
```

### Go:

```go  theme={"system"}
package main

import (
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	"github.com/upstash/pulumi-upstash/sdk/go/upstash"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {

		createdTeam, err := upstash.NewTeam(ctx, "exampleTeam", &upstash.TeamArgs{
			TeamName: pulumi.String("pulumi go team"),
			CopyCc:   pulumi.Bool(false),
			TeamMembers: pulumi.StringMap{
				"<owner-email>": pulumi.String("owner"),
				"<some-other-user-email>":   pulumi.String("dev"),
			},

		})
		if err != nil {
			return err
		}
		return nil
	})
}

```


# null
Source: https://upstash.com/docs/devops/terraform





# upstash_qstash_endpoint_data
Source: https://upstash.com/docs/devops/terraform/data_sources/upstash_qstash_endpoint_data



<RequestExample>
  ```hcl example.tf theme={"system"}
  data "upstash_qstash_endpoint_data" "exampleQStashEndpointData" {
    endpoint_id = resource.upstash_qstash_endpoint.exampleQStashEndpoint.endpoint_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="topic_id" type="string" required>
  Topic Id that the endpoint is added to
</ParamField>

### Read-Only

<ResponseField name="endpoint_id" type="string">
  Unique QStash Endpoint ID
</ResponseField>

<ResponseField name="id" type="number">
  The ID of this resource.
</ResponseField>

<ResponseField name="url" type="string">
  Unique QStash Topic Name for Endpoint
</ResponseField>


# upstash_qstash_schedule_data
Source: https://upstash.com/docs/devops/terraform/data_sources/upstash_qstash_schedule_data



<RequestExample>
  ```hcl example.tf theme={"system"}
  data "upstash_qstash_schedule_data" "exampleQStashScheduleData" {
    schedule_id = resource.upstash_qstash_schedule.exampleQStashSchedule.schedule_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="schedule_id" type="string" required>
  Unique QStash Schedule ID for requested schedule
</ParamField>

### Read-Only

<ResponseField name="body" type="string">
  Body to send for the POST request in string format. Needs escaping () double
  quotes.
</ResponseField>

<ResponseField name="created_at" type="number">
  Creation time for QStash Schedule
</ResponseField>

<ResponseField name="cron" type="string">
  Cron string for QStash Schedule
</ResponseField>

<ResponseField name="destination" type="string">
  Destination for QStash Schedule. Either Topic ID or valid URL
</ResponseField>

<ResponseField name="forward_headers" type="map(string)">
  Forward headers to your API
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="not_before" type="number">
  Start time for QStash Scheduling.
</ResponseField>

<ResponseField name="retries" type="number">
  Retries for QStash Schedule requests.
</ResponseField>


# upstash_qstash_topic_data
Source: https://upstash.com/docs/devops/terraform/data_sources/upstash_qstash_topic_data



<RequestExample>
  ```hcl example.tf theme={"system"}
  data "upstash_qstash_topic_data" "exampleQstashTopicData" {
    topic_id = resource.upstash_qstash_topic.exampleQstashTopic.topic_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="topic_id" type="string" required>
  Unique QStash Topic ID for requested topic
</ParamField>

### Read-Only

<ResponseField name="endpoints" type="list(map(string))">
  Endpoints for the QStash Topic
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="name" type="string">
  Name of the QStash Topic
</ResponseField>


# upstash_redis_database_data
Source: https://upstash.com/docs/devops/terraform/data_sources/upstash_redis_database_data



<RequestExample>
  ```hcl example.tf theme={"system"}
  data "upstash_redis_database_data" "exampleDBData" {
    database_id = resource.upstash_redis_database.exampleDB.database_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="database_id" type="string" required>
  Unique Database ID for created database
</ParamField>

### Read-Only

<ResponseField name="auto_scale" type="bool">
  Upgrade to higher plans automatically when it hits quotas
</ResponseField>

<ResponseField name="creation_time" type="number">
  Creation time of the database
</ResponseField>

<ResponseField name="database_name" type="string">
  Name of the database
</ResponseField>

<ResponseField name="database_type" type="string">
  Type of the database
</ResponseField>

<ResponseField name="db_daily_bandwidth_limit" type="number">
  Daily bandwidth limit for the database
</ResponseField>

<ResponseField name="db_disk_threshold" type="number">
  Disk threshold for the database
</ResponseField>

<ResponseField name="db_max_clients" type="number">
  Max clients for the database
</ResponseField>

<ResponseField name="db_max_commands_per_second" type="number">
  Max commands per second for the database
</ResponseField>

<ResponseField name="db_max_entry_size" type="number">
  Max entry size for the database
</ResponseField>

<ResponseField name="db_max_request_size" type="number">
  Max request size for the database
</ResponseField>

<ResponseField name="db_memory_threshold" type="number">
  Memory threshold for the database
</ResponseField>

<ResponseField name="endpoint" type="string">
  Database URL for connection
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="password" type="string">
  Password of the database
</ResponseField>

<ResponseField name="port" type="number">
  Port of the endpoint
</ResponseField>

<ResponseField name="primary_region" type="string">
  Primary region for the database (Only works if region='global'. Can be one of
  \[us-east-1, us-west-1, us-west-2, eu-central-1, eu-west-1, sa-east-1,
  ap-southeast-1, ap-southeast-2])
</ResponseField>

<ResponseField name="read_only_rest_token" type="string">
  Rest Token for the database.
</ResponseField>

<ResponseField name="read_regions" type="set(string)">
  Read regions for the database (Only works if region='global' and
  primary\_region is set. Can be any combination of \[us-east-1, us-west-1,
  us-west-2, eu-central-1, eu-west-1, sa-east-1, ap-southeast-1,
  ap-southeast-2], excluding the one given as primary.)
</ResponseField>

<ResponseField name="region" type="string">
  Region of the database. Possible values are: `global`, `eu-west-1`,
  `us-east-1`, `us-west-1`, `ap-northeast-1` , `eu-central1`
</ResponseField>

<ResponseField name="rest_token" type="string">
  Rest Token for the database.
</ResponseField>

<ResponseField name="state" type="string">
  State of the database
</ResponseField>

<ResponseField name="tls" type="bool">
  When enabled, data is encrypted in transit. (If changed to false from true,
  results in deletion and recreation of the resource)
</ResponseField>

<ResponseField name="user_email" type="string">
  User email for the database
</ResponseField>


# upstash_team_data
Source: https://upstash.com/docs/devops/terraform/data_sources/upstash_team_data



<RequestExample>
  ```hcl example.tf theme={"system"}
  data "upstash_team_data" "teamData" {
    team_id = resource.upstash_team.exampleTeam.team_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="team_id" type="string" required>
  Unique Cluster ID for created cluster
</ParamField>

### Read-Only

<ResponseField name="copy_cc" type="bool">
  Whether Credit Card is copied
</ResponseField>

<ResponseField name="id" type="number">
  The ID of this resource.
</ResponseField>

<ResponseField name="team_members" type="map(string)">
  Members of the team. (Owner must be specified, which is the owner of the api
  key.)
</ResponseField>

<ResponseField name="team_name" type="string">
  Name of the team
</ResponseField>


# Overview
Source: https://upstash.com/docs/devops/terraform/overview



The Upstash Terraform Provider lets you manage Upstash Redis resources programmatically.

You can find the Github Repository for the Terraform Provider [here](https://github.com/upstash/terraform-provider-upstash).

## Installation

```hcl  theme={"system"}
terraform {
  required_providers {
    upstash = {
      source = "upstash/upstash"
      version = "x.x.x"
    }
  }
}

provider "upstash" {
  email    = var.email
  api_key  = var.api_key
}
```

`email` is your registered email in Upstash.

`api_key` can be generated from Upstash Console. For more information please check our [docs](https://docs.upstash.com/howto/developerapi).

## Create Database Using Terraform

Here example code snippet that creates database:

```hcl  theme={"system"}
resource "upstash_redis_database" "redis" {
  database_name = "db-name"
  region        = "eu-west-1"
  tls           = "true"
  multi_zone    = "false"
}
```

## Import Resources From Outside of Terraform

To import resources created outside of the terraform provider, simply create the resource in .tf file as follows:

```hcl  theme={"system"}
resource "upstash_redis_database" "redis" {}
```

after this, you can run the command:

```
terraform import upstash_redis_database.redis <db-id>
```

Above example is given for an Upstash Redis database. You can import all of the resources by changing the resource type and providing the resource id.

You can check full spec and [doc from here](https://registry.terraform.io/providers/upstash/upstash/latest/docs).

## Support, Bugs Reports, Feature Requests

If you need support then you can ask your questions Upstash Team in [upstash.com](https://upstash.com) chat widget.

There is also discord channel available for community. [Please check here](https://docs.upstash.com/help/support) for more information.


# upstash_qstash_endpoint
Source: https://upstash.com/docs/devops/terraform/resources/upstash_qstash_endpoint

Create and manage QStash endpoints.

<RequestExample>
  ```hcl example.tf theme={"system"}
  resource "upstash_qstash_endpoint" "exampleQStashEndpoint" {
    url      = "https://***.***"
    topic_id = resource.upstash_qstash_topic.exampleQstashTopic.topic_id
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="topic_id" type="string" required>
  Topic ID that the endpoint is added to
</ParamField>

<ParamField query="url" type="string" required>
  URL of the endpoint
</ParamField>

### Read-Only

<ResponseField name="endpoint_id" type="string">
  Unique QStash endpoint ID
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="topic_name" type="string">
  Unique QStash topic name for endpoint
</ResponseField>


# upstash_qstash_schedule
Source: https://upstash.com/docs/devops/terraform/resources/upstash_qstash_schedule

Create and manage QStash schedules.

<RequestExample>
  ```hcl example.tf theme={"system"}
  resource "upstash_qstash_schedule" "exampleQStashSchedule" {
    destination = resource.upstash_qstash_topic.exampleQstashTopic.topic_id
    cron        = "* * * * */2"

    # or simply provide a link
    # destination = "https://***.***"
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="cron" type="string" required>
  Cron string for QStash Schedule
</ParamField>

<ParamField query="destination" type="string" required>
  Destination for QStash Schedule. Either Topic ID or valid URL
</ParamField>

### Optional

<ParamField query="body" type="string">
  Body to send for the POST request in string format. Needs escaping () double
  quotes.
</ParamField>

<ParamField query="callback" type="string">
  Callback URL for QStash Schedule.
</ParamField>

<ParamField query="content_based_deduplication" type="bool">
  Content based deduplication for QStash Scheduling.
</ParamField>

<ParamField query="content_type" type="string">
  Content type for QStash Scheduling.
</ParamField>

<ParamField query="deduplicatoin_id" type="string">
  Deduplication ID for QStash Scheduling.
</ParamField>

<ParamField query="delay" type="string">
  Delay for QStash Schedule.
</ParamField>

<ParamField query="forward_headers" type="map(string)">
  Forward headers to your API
</ParamField>

<ParamField query="not_before" type="number">
  Start time for QStash Scheduling.
</ParamField>

<ParamField query="retries" type="number">
  Retries for QStash Schedule requests.
</ParamField>

### Read-Only

<ResponseField name="created_at" type="number">
  Creation time for QStash Schedule.
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="schedule_id" type="string">
  Unique QStash Schedule ID for requested schedule
</ResponseField>


# upstash_qstash_topic
Source: https://upstash.com/docs/devops/terraform/resources/upstash_qstash_topic

Create and manage QStash topics

<RequestExample>
  ```hcl example.tf theme={"system"}
  resource "upstash_qstash_topic" "exampleQStashTopic" {
    name = "exampleQStashTopicName"
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="name" type="string" required>
  Name of the QStash topic
</ParamField>

### Read-Only

<ResponseField name="endpoints" type="list(map(string))">
  Endpoints for the QStash topic
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="topic_id" type="string">
  Unique QStash topic ID for requested topic
</ResponseField>


# upstash_redis_database
Source: https://upstash.com/docs/devops/terraform/resources/upstash_redis_database

Create and manage Upstash Redis databases.

<RequestExample>
  ```hcl example.tf theme={"system"}
  resource "upstash_redis_database" "exampleDB" {
    database_name = "Terraform DB6"
    region        = "eu-west-1"
    tls           = "true"
    multizone     = "true"
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="database_name" type="string" required>
  Name of the database
</ParamField>

<ParamField query="region" type="string" required>
  Region of the database. Possible values are: `global`, `eu-west-1`,
  `us-east-1`, `us-west-1`, `ap-northeast-1` , `eu-central1`
</ParamField>

### Optional

<ParamField query="auto_scale" type="bool">
  Upgrade to higher plans automatically when it hits quotas
</ParamField>

<ParamField query="eviction" type="bool">
  Enable eviction, to evict keys when your database reaches the max size
</ParamField>

<ParamField query="primary_region" type="string">
  Primary region for the database (Only works if region='global'. Can be one of
  \[us-east-1, us-west-1, us-west-2, eu-central-1, eu-west-1, sa-east-1,
  ap-southeast-1, ap-southeast-2])
</ParamField>

<ParamField query="read_regions" type="set(string)">
  Read regions for the database (Only works if region='global' and
  primary\_region is set. Can be any combination of \[us-east-1, us-west-1,
  us-west-2, eu-central-1, eu-west-1, sa-east-1, ap-southeast-1,
  ap-southeast-2], excluding the one given as primary.)
</ParamField>

<ParamField query="tls" type="bool">
  When enabled, data is encrypted in transit. (If changed to false from true,
  results in deletion and recreation of the resource)
</ParamField>

### Read-Only

<ResponseField name="creation_time" type="number">
  Creation time of the database
</ResponseField>

<ResponseField name="database_id" type="string">
  Unique Database ID for created database
</ResponseField>

<ResponseField name="database_type" type="string">
  Type of the database
</ResponseField>

<ResponseField name="db_daily_bandwidth_limit" type="number">
  Daily bandwidth limit for the database
</ResponseField>

<ResponseField name="db_disk_threshold" type="number">
  Disk threshold for the database
</ResponseField>

<ResponseField name="db_max_clients" type="number">
  Max clients for the database
</ResponseField>

<ResponseField name="db_max_commands_per_second" type="number">
  Max commands per second for the database
</ResponseField>

<ResponseField name="db_max_entry_size" type="number">
  Max entry size for the database
</ResponseField>

<ResponseField name="db_max_request_size" type="number">
  Max request size for the database
</ResponseField>

<ResponseField name="db_memory_threshold" type="number">
  Memory threshold for the database
</ResponseField>

<ResponseField name="endpoint" type="string">
  Database URL for connection
</ResponseField>

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="password" type="string">
  Password of the database
</ResponseField>

<ResponseField name="port" type="number">
  Port of the endpoint
</ResponseField>

<ResponseField name="read_only_rest_token" type="string">
  Rest Token for the database.
</ResponseField>

<ResponseField name="rest_token" type="string">
  Rest Token for the database.
</ResponseField>

<ResponseField name="state" type="string">
  State of the database
</ResponseField>

<ResponseField name="user_email" type="string">
  User email for the database
</ResponseField>


# upstash_team
Source: https://upstash.com/docs/devops/terraform/resources/upstash_team

Create and manage teams on Upstash.

<RequestExample>
  ```hcl example.tf theme={"system"}
  resource "upstash_team" "exampleTeam" {
    team_name    = "TerraformTeam"
    copy_cc      = false
    team_members = {
        # Owner is the owner of the api_key.
        "X@Y.Z": "owner",
        "A@B.C": "dev",
        "E@E.F": "finance",
      }
  }
  ```
</RequestExample>

## Schema

### Required

<ParamField query="copy_cc" type="bool" required>
  Whether Credit Card is copied
</ParamField>

<ParamField query="team_members" type="map(string)" required>
  Members of the team. (Owner must be specified, which is the owner of the api
  key.)
</ParamField>

<ParamField query="team_name" type="string" required>
  Name of the team
</ParamField>

### Read-Only

<ResponseField name="id" type="string">
  The ID of this resource.
</ResponseField>

<ResponseField name="team_id" type="string">
  Unique Cluster ID for created cluster
</ResponseField>


# null
Source: https://upstash.com/docs/img/bg-color-codes



Recommended Background Color Transition:

Primary: #34D399 (Emerald Green)
Secondary: #00E9A3 (Cyan Green)


# Get Started
Source: https://upstash.com/docs/introduction



<CardGroup cols={2}>
  <Card title="Serverless Redis" href="/redis/overall/getstarted">
    Create a Redis Database within seconds
  </Card>

  <Card title="Serverless Vector" href="/vector/overall/getstarted">
    Create a Vector Database for AI & LLMs
  </Card>

  <Card title="QStash" href="/qstash/overall/getstarted">
    Publish your first message
  </Card>

  <Card title="Upstash Workflow" href="/workflow/getstarted">
    Write durable serverless functions
  </Card>
</CardGroup>

## Concepts

<CardGroup cols={2}>
  <Card title="Serverless" href="/common/concepts/serverless">
    Upstash is serverless. You don't need to provision any infrastructure. Just
    create a database and start using it.
  </Card>

  <Card title="Scale to Zero" href="/common/concepts/scale-to-zero">
    Price scales to zero. You don't pay for idle or unused resources. You pay
    only for what you use.
  </Card>

  <Card title="Global Replication" href="/common/concepts/global-replication">
    Upstash Redis replicates your data for the best latency all over the world.
  </Card>

  <Card title="Access Anywhere" href="/common/concepts/access-anywhere">
    Upstash REST APIs enable access from all types of runtimes.
  </Card>
</CardGroup>

## Get In touch

<CardGroup cols={2}>
  <Card title="X" icon="x-twitter" href="https://x.com/upstash">
    Follow us on X for the latest news and updates.
  </Card>

  <Card title="Discord" icon="discord" href="https://upstash.com/discord">
    Join our Discord Community and ask your questions to the team and other
    developers.
  </Card>
</CardGroup>


# API Rate Limit Response
Source: https://upstash.com/docs/qstash/api/api-ratelimiting

This page documents the rate limiting behavior of our API and explains how to handle different types of rate limit errors.

## Overview

There is no request per second limit for operational API's as listed below:

* trigger, publish, enqueue, notify, wait, batch
* Other endpoints (like logs,listing flow-controls, queues, schedules etc) have rps limit. This is a short-term limit **per second** to prevent rapid bursts of requests.

**Headers**:

* `Burst-RateLimit-Limit`: Maximum number of requests allowed in the burst window (1 second)
* `Burst-RateLimit-Remaining`: Remaining number of requests in the burst window (1 second)
* `Burst-RateLimit-Reset`: Time (in unix timestamp) when the burst limit will reset

### Example Rate Limit Error Handling

```typescript Handling Daily Rate Limit Error theme={"system"}
import { QstashDailyRatelimitError } from "@upstash/qstash";

try {
  // Example of a publish request that could hit the daily rate limit
  const result = await client.publishJSON({
    url: "https://my-api...",
    // or urlGroup: "the name or id of a url group"
    body: {
      hello: "world",
    },
  });
} catch (error) {
  if (error instanceof QstashDailyRatelimitError) {
    console.log("Daily rate limit exceeded. Retry after:", error.reset);
    // Implement retry logic or notify the user
  } else {
    console.error("An unexpected error occurred:", error);
  }
}
```

```typescript Handling Burst Rate Limit Error theme={"system"}
import { QstashRatelimitError } from "@upstash/qstash";

try {
  // Example of a request that could hit the burst rate limit
  const result = await client.publishJSON({
    url: "https://my-api...",
    // or urlGroup: "the name or id of a url group"
    body: {
      hello: "world",
    },
  });
} catch (error) {
  if (error instanceof QstashRatelimitError) {
    console.log("Burst rate limit exceeded. Retry after:", error.reset);
    // Implement exponential backoff or delay before retrying
  } else {
    console.error("An unexpected error occurred:", error);
  }
}
```


# Authentication
Source: https://upstash.com/docs/qstash/api/authentication

Authentication for the QStash API

You'll need to authenticate your requests to access any of the endpoints in the
QStash API. In this guide, we'll look at how authentication works.

## Bearer Token

When making requests to QStash, you will need your `QSTASH_TOKEN` ‚Äî you will
find it in the [console](https://console.upstash.com/qstash). Here's how to add
the token to the request header using cURL:

```bash  theme={"system"}
curl https://qstash.upstash.io/v2/publish/... \
  -H "Authorization: Bearer <QSTASH_TOKEN>"
```

## Query Parameter

In environments where setting the header is not possible, you can use the `qstash_token` query parameter instead.

```bash  theme={"system"}
curl https://qstash.upstash.io/v2/publish/...?qstash_token=<QSTASH_TOKEN>
```

Always keep your token safe and reset it if you suspect it has been compromised.


# Delete a message from the DLQ
Source: https://upstash.com/docs/qstash/api/dlq/deleteMessage

DELETE https://qstash.upstash.io/v2/dlq/{dlqId}
Manually remove a message

Delete a message from the DLQ.

## Request

<ParamField path="dlqId" type="string">
  The dlq id of the message you want to remove. You will see this id when
  listing all messages in the dlq with the [/v2/dlq](/qstash/api/dlq/listMessages) endpoint.
</ParamField>

## Response

The endpoint doesn't return anything, a status code of 200 means the message is removed from the DLQ.
If the message is not found in the DLQ, (either is has been removed by you, or automatically), the endpoint returns a 404 status code.

<RequestExample>
  ```sh  theme={"system"}
  curl -X DELETE https://qstash.upstash.io/v2/dlq/my-dlq-id \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# Delete multiple messages from the DLQ
Source: https://upstash.com/docs/qstash/api/dlq/deleteMessages

DELETE https://qstash.upstash.io/v2/dlq
Manually remove messages

Delete multiple messages from the DLQ.

<Info>
  You can get the `dlqId` from the [list DLQs endpoint](/qstash/api/dlq/listMessages).
</Info>

## Request

<ParamField body="dlqIds" type="string[]" required>
  The list of DLQ message IDs to remove.
</ParamField>

## Response

A deleted object with the number of deleted messages.

```JSON  theme={"system"}
{
  "deleted": number
}
```

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "deleted": 3
  }
  ```
</ResponseExample>

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/dlq \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
       "dlqIds": ["11111-0", "22222-0", "33333-0"]
      }'
  ```

  ```js Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/dlq", {
    method: "DELETE",
    headers: {
      Authorization: "Bearer <token>",
      "Content-Type": "application/json",
    },
    body: {
      dlqIds: [
        "11111-0",
        "22222-0",
        "33333-0",
      ],
    },
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  data = {
    "dlqIds": [
      "11111-0",
      "22222-0",
      "33333-0"
    ]
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/dlq',
    headers=headers,
    data=data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{
    "dlqIds": [
      "11111-0",
      "22222-0",
      "33333-0"
    ]
  }`)
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/dlq", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Get a message from the DLQ
Source: https://upstash.com/docs/qstash/api/dlq/getMessage

GET https://qstash.upstash.io/v2/dlq/{dlqId}
Get a message from the DLQ

Get a message from DLQ.

## Request

<ParamField path="dlqId" type="string">
  The dlq id of the message you want to retrieve. You will see this id when
  listing all messages in the dlq with the [/v2/dlq](/qstash/api/dlq/listMessages) endpoint,
  as well as in the content of [the failure callback](https://docs.upstash.com/qstash/features/callbacks#what-is-a-failure-callback)
</ParamField>

## Response

If the message is not found in the DLQ, (either is has been removed by you, or automatically), the endpoint returns a 404 status code.

<Snippet file="qstash-dlq-message-type.mdx" />

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/dlq/my-dlq-id \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# List messages in the DLQ
Source: https://upstash.com/docs/qstash/api/dlq/listMessages

GET https://qstash.upstash.io/v2/dlq
List and paginate through all messages currently inside the DLQ

List all messages currently inside the DLQ

## Request

<ParamField query="cursor" type="string">
  By providing a cursor you can paginate through all of the messages in the DLQ
</ParamField>

<ParamField query="messageId" type="string">
  Filter DLQ messages by message id.
</ParamField>

<ParamField query="url" type="string">
  Filter DLQ messages by url.
</ParamField>

<ParamField query="topicName" type="string">
  Filter DLQ messages by url group.
</ParamField>

<ParamField query="scheduleId" type="string">
  Filter DLQ messages by schedule id.
</ParamField>

<ParamField query="queueName" type="string">
  Filter DLQ messages by queue name.
</ParamField>

<ParamField query="api" type="string">
  Filter DLQ messages by API name.
</ParamField>

<ParamField query="fromDate" type="number">
  Filter DLQ messages by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="toDate" type="number">
  Filter DLQ messages by ending date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="responseStatus" type="number">
  Filter DLQ messages by HTTP response status code.
</ParamField>

<ParamField query="callerIp" type="string">
  Filter DLQ messages by IP address of the publisher.
</ParamField>

<ParamField query="count" type="number">
  The number of messages to return. Default and maximum is 100.
</ParamField>

<ParamField query="order" type="string">
  The sorting order of DLQ messages by timestamp. Valid values are "earliestFirst" and "latestFirst". The default is "earliestFirst".
</ParamField>

<ResponseField name="label" type="string">
  Filter DLQ messages by the label of the message assigned by the user.
</ResponseField>

## Response

<ResponseField name="cursor" type="string">
  A cursor which you can use in subsequent requests to paginate through all
  messages. If no cursor is returned, you have reached the end of the messages.
</ResponseField>

<ResponseField name="messages" type="Array">
  <Expandable defaultOpen title="message">
    <Snippet file="qstash-dlq-message-type.mdx" />
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl https://qstash.upstash.io/v2/dlq \
    -H "Authorization: Bearer <token>"
  ```

  ```sh with cursor theme={"system"}
  curl https://qstash.upstash.io/v2/dlq?cursor=xxx \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  { 
    "messages": [
      {
        "messageId": "msg_123",
        "topicId": "tpc_123",
        "url":"https://example.com",
        "method": "POST",
        "header": {
          "My-Header": ["my-value"]
        },
        "body": "{\"foo\":\"bar\"}",
        "createdAt": 1620000000000,
        "state": "failed"
      }
    ]
  }
  ```
</ResponseExample>


# Enqueue a Message
Source: https://upstash.com/docs/qstash/api/enqueue

POST https://qstash.upstash.io/v2/enqueue/{queueName}/{destination}
Enqueue a message

## Request

<ParamField path="queueName" type="string" required>
  The name of the queue that message will be enqueued on.
  If doesn't exist, it will be created automatically.
</ParamField>

<ParamField path="destination" type="string" required>
  Destination can either be a topic name or id that you configured in the
  Upstash console, a valid url where the message gets sent to, or a valid
  QStash API name like `api/llm`. If the destination is a URL, make sure
  the URL is prefixed with a valid protocol (`http://` or `https://`)
</ParamField>

<Snippet file="qstash-common-request.mdx" />

<ParamField header="Upstash-Deduplication-Id" type="string">
  Id to use while deduplicating messages, so that only one message with
  the given deduplication id is published.
</ParamField>

<ParamField header="Upstash-Content-Based-Deduplication" type="boolean">
  When set to true, automatically deduplicates messages based on their content,
  so that only one message with the same content is published.

  Content based deduplication creates unique deduplication ids based on the
  following message fields:

  * Destination
  * Body
  * Headers
</ParamField>

## Response

<Snippet file="qstash-publish-response.mdx" />

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST "https://qstash.upstash.io/v2/enqueue/myQueue/https://www.example.com" \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -H "Upstash-Method: POST" \
    -H "Upstash-Retries: 3" \
    -H "Upstash-Forward-Custom-Header: custom-value" \
    -d '{"message":"Hello, World!"}'
  ```

  ```js Node theme={"system"}
  const response = await fetch(
    "https://qstash.upstash.io/v2/enqueue/myQueue/https://www.example.com",
    {
      method: "POST",
      headers: {
        Authorization: "Bearer <token>",
        "Content-Type": "application/json",
        "Upstash-Method": "POST",
        "Upstash-Retries": "3",
        "Upstash-Forward-Custom-Header": "custom-value",
      },
      body: JSON.stringify({
        message: "Hello, World!",
      }),
    }
  );
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
      'Upstash-Method': 'POST',
      'Upstash-Retries': '3',
      'Upstash-Forward-Custom-Header': 'custom-value',
  }

  json_data = {
      'message': 'Hello, World!',
  }

  response = requests.post(
    'https://qstash.upstash.io/v2/enqueue/myQueue/https://www.example.com',
     headers=headers,
     json=json_data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{"message":"Hello, World!"}`)
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/enqueue/myQueue/https://www.example.com", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  req.Header.Set("Upstash-Method", "POST")
  req.Header.Set("Upstash-Retries", "3")
  req.Header.Set("Upstash-Forward-Custom-Header", "custom-value")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json URL theme={"system"}
  {
    "messageId": "msd_1234",
    "url": "https://www.example.com"
  }
  ```

  ```json URL Group theme={"system"}
  [
    {
      "messageId": "msd_1234",
      "url": "https://www.example.com"
    },
    {
      "messageId": "msd_5678",
      "url": "https://www.somewhere-else.com",
      "deduplicated": true
    }
  ]
  ```
</ResponseExample>


# List Events
Source: https://upstash.com/docs/qstash/api/events/list

GET https://qstash.upstash.io/v2/events
List all events that happened, such as message creation or delivery

<Warning>
  QStash events are being renamed to [Logs](/qstash/api/logs/list) to better reflect their purpose and to not get confused with [Workflow Events](/workflow/howto/events).
</Warning>

## Request

<ParamField query="cursor" type="string">
  By providing a cursor you can paginate through all of the events.
</ParamField>

<ParamField query="messageId" type="string">
  Filter events by message id.
</ParamField>

<ParamField query="state" type="string">
  Filter events by [state](/qstash/howto/debug-logs)

  | Value              | Description                                                                              |
  | ------------------ | ---------------------------------------------------------------------------------------- |
  | `CREATED`          | The message has been accepted and stored in QStash                                       |
  | `ACTIVE`           | The task is currently being processed by a worker.                                       |
  | `RETRY`            | The task has been scheduled to retry.                                                    |
  | `ERROR`            | The execution threw an error and the task is waiting to be retried or failed.            |
  | `IN_PROGRESS`      | The task is in one of `ACTIVE`, `RETRY` or `ERROR` state.                                |
  | `DELIVERED`        | The message was successfully delivered.                                                  |
  | `FAILED`           | The task has errored too many times or encountered an error that it cannot recover from. |
  | `CANCEL_REQUESTED` | The cancel request from the user is recorded.                                            |
  | `CANCELLED`        | The cancel request from the user is honored.                                             |
</ParamField>

<ParamField query="url" type="string">
  Filter events by url.
</ParamField>

<ParamField query="topicName" type="string">
  Filter events by URL Group (topic) name.
</ParamField>

<ParamField query="scheduleId" type="string">
  Filter events by schedule id.
</ParamField>

<ParamField query="queueName" type="string">
  Filter events by queue name.
</ParamField>

<ParamField query="fromDate" type="number">
  Filter events by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="toDate" type="number">
  Filter events by ending date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="count" type="number">
  The number of events to return. Default and max is 1000.
</ParamField>

<ParamField query="order" type="string">
  The sorting order of events by timestamp. Valid values are "earliestFirst" and "latestFirst". The default is "latestFirst".
</ParamField>

## Response

<ResponseField name="cursor" type="string">
  A cursor which you can use in subsequent requests to paginate through all events.
  If no cursor is returned, you have reached the end of the events.
</ResponseField>

<ResponseField name="events" type="Array">
  <Expandable defaultOpen>
    <ResponseField name="time" type="int" required>
      Timestamp of this log entry, in milliseconds
    </ResponseField>

    <ResponseField name="messageId" type="string" required>
      The associated message id
    </ResponseField>

    <ResponseField name="header" type="Record<string, string[]>" required>
      The headers of the message.
    </ResponseField>

    <ResponseField name="body" type="string" required>
      Base64 encoded body of the message.
    </ResponseField>

    <ResponseField name="state" type="string" required>
      The current state of the message at this point in time.

      | Value              | Description                                                                              |
      | ------------------ | ---------------------------------------------------------------------------------------- |
      | `CREATED`          | The message has been accepted and stored in QStash                                       |
      | `ACTIVE`           | The task is currently being processed by a worker.                                       |
      | `RETRY`            | The task has been scheduled to retry.                                                    |
      | `ERROR`            | The execution threw an error and the task is waiting to be retried or failed.            |
      | `DELIVERED`        | The message was successfully delivered.                                                  |
      | `FAILED`           | The task has errored too many times or encountered an error that it cannot recover from. |
      | `CANCEL_REQUESTED` | The cancel request from the user is recorded.                                            |
      | `CANCELLED`        | The cancel request from the user is honored.                                             |
    </ResponseField>

    <ResponseField name="error" type="string" optional>
      An explanation what went wrong
    </ResponseField>

    <ResponseField name="nextDeliveryTime" type="int">
      The next scheduled time of the message.
      (Unix timestamp in milliseconds)
    </ResponseField>

    <ResponseField name="url" type="string">
      The destination url
    </ResponseField>

    <ResponseField name="topicName" type="string">
      The name of the URL Group (topic) if this message was sent through a topic
    </ResponseField>

    <ResponseField name="endpointName" type="int">
      The name of the endpoint if this message was sent through a URL Group
    </ResponseField>

    <ResponseField name="scheduleId" type="string">
      The scheduleId of the message if the message is triggered by a schedule
    </ResponseField>

    <ResponseField name="queueName" type="string">
      The name of the queue if this message is enqueued on a queue
    </ResponseField>

    <ResponseField name="header" type="string">
      The headers that are forwarded to the users endpoint
    </ResponseField>

    <ResponseField name="body" type="string">
      Base64 encoded body of the message
    </ResponseField>

    <ResponseField name="responseStatus" type="int">
      The status code of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="responseBody" type="string">
      The base64 encoded body of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="responseHeaders" type="Record<string, string[]>">
      The headers of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="timeout" type="int">
      The timeout(in milliseconds) of the outgoing http requests, after which Qstash cancels the request
    </ResponseField>

    <ResponseField name="method" type="string">
      Method is the HTTP method of the message for outgoing request
    </ResponseField>

    <ResponseField name="callback" type="string">
      Callback is the URL address where QStash sends the response of a publish
    </ResponseField>

    <ResponseField name="callbackHeaders" type="Record<string, string[]>">
      The headers that are passed to the callback url
    </ResponseField>

    <ResponseField name="failureCallback" type="string">
      Failure Callback is the URL address where QStash sends the response of a publish
    </ResponseField>

    <ResponseField name="failureCallbackHeaders" type="Record<string, string[]>">
      The headers that are passed to the failure callback url
    </ResponseField>

    <ResponseField name="maxRetries" type="int">
      The number of retries that should be attempted in case of delivery failure
    </ResponseField>

    <ResponseField name="retryDelayExpression" type="string">
      The mathematical expression used to calculate delay between retry attempts. If not set, [the default backoff](/qstash/features/retry) is used.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/events \
    -H "Authorization: Bearer <token>"
  ```

  ```javascript Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/events", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests
  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/events',
     headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/events", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "cursor": "1686652644442-12",
    "events":[
      {
        "time": "1686652644442",
        "messageId": "msg_123",
        "state": "delivered",
        "url": "https://example.com",
        "header": { "Content-Type": [ "application/x-www-form-urlencoded" ] },
        "body": "bWVyaGFiYSBiZW5pbSBhZGltIHNhbmNhcg=="
      }
    ] 
  }
  ```
</ResponseExample>


# Get Flow-Control Keys
Source: https://upstash.com/docs/qstash/api/flow-control/get

GET https://qstash.upstash.io/v2/flowControl/{flowControlKey}
Get Information on Flow-Control

## Request

<ParamField path="flowControlKey" type="string">
  The key of the flow control. See the [flow control](/qstash/features/flowcontrol) for more details.
</ParamField>

## Response

<ResponseField name="flowControlKey" type="string">
  The key of of the flow control.
</ResponseField>

<ResponseField name="waitListSize" type="integer">
  The number of messages in the wait list that waits for `parallelism` set in the flow control.
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/YOUR_FLOW_CONTROL_KEY  -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# List Flow-Control Keys
Source: https://upstash.com/docs/qstash/api/flow-control/list

GET https://qstash.upstash.io/v2/flowControl/
List all Flow Control keys

## Response

<ResponseField name="flowControls" type="Array">
  <Expandable>
    <ResponseField name="flowControlKey" type="string">
      The key of the flow control. See the [flow control](/qstash/features/flowcontrol) for more details.
    </ResponseField>

    <ResponseField name="waitListSize" type="integer">
      The number of messages in the wait list that waits for `parallelism` set in the flow control.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/  -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# List Logs
Source: https://upstash.com/docs/qstash/api/logs/list

GET https://qstash.upstash.io/v2/logs
Paginate through logs of published messages

## Request

<ParamField query="cursor" type="string">
  By providing a cursor you can paginate through all of the logs.
</ParamField>

<ParamField query="messageId" type="string">
  Filter logs by message id.
</ParamField>

<ParamField query="state" type="string">
  Filter logs by [state](/qstash/howto/debug-logs)

  | Value              | Description                                                                              |
  | ------------------ | ---------------------------------------------------------------------------------------- |
  | `CREATED`          | The message has been accepted and stored in QStash                                       |
  | `ACTIVE`           | The task is currently being processed by a worker.                                       |
  | `RETRY`            | The task has been scheduled to retry.                                                    |
  | `ERROR`            | The execution threw an error and the task is waiting to be retried or failed.            |
  | `IN_PROGRESS`      | The task is in one of `ACTIVE`, `RETRY` or `ERROR` state.                                |
  | `DELIVERED`        | The message was successfully delivered.                                                  |
  | `FAILED`           | The task has errored too many times or encountered an error that it cannot recover from. |
  | `CANCEL_REQUESTED` | The cancel request from the user is recorded.                                            |
  | `CANCELLED`        | The cancel request from the user is honored.                                             |
</ParamField>

<ParamField query="url" type="string">
  Filter logs by url.
</ParamField>

<ParamField query="topicName" type="string">
  Filter logs by URL Group (topic) name.
</ParamField>

<ParamField query="scheduleId" type="string">
  Filter logs by schedule id.
</ParamField>

<ParamField query="queueName" type="string">
  Filter logs by queue name.
</ParamField>

<ParamField query="fromDate" type="number">
  Filter logs by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="toDate" type="number">
  Filter logs by ending date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="count" type="number">
  The number of logs to return. Default and max is 1000.
</ParamField>

<ParamField query="order" type="string">
  The sorting order of logs by timestamp. Valid values are "earliestFirst" and "latestFirst". The default is "latestFirst".
</ParamField>

<ResponseField name="label" type="string">
  Filter event by the label of the message assigned by the user.
</ResponseField>

## Response

<ResponseField name="cursor" type="string">
  A cursor which you can use in subsequent requests to paginate through all logs.
  If no cursor is returned, you have reached the end of the logs.
</ResponseField>

<ResponseField name="events" type="Array">
  <Expandable defaultOpen>
    <ResponseField name="time" type="int" required>
      Timestamp of this log entry, in milliseconds
    </ResponseField>

    <ResponseField name="messageId" type="string" required>
      The associated message id
    </ResponseField>

    <ResponseField name="header" type="Record<string, string[]>" required>
      The headers of the message.
    </ResponseField>

    <ResponseField name="body" type="string" required>
      Base64 encoded body of the message.
    </ResponseField>

    <ResponseField name="state" type="string" required>
      The current state of the message at this point in time.

      | Value              | Description                                                                              |
      | ------------------ | ---------------------------------------------------------------------------------------- |
      | `CREATED`          | The message has been accepted and stored in QStash                                       |
      | `ACTIVE`           | The task is currently being processed by a worker.                                       |
      | `RETRY`            | The task has been scheduled to retry.                                                    |
      | `ERROR`            | The execution threw an error and the task is waiting to be retried or failed.            |
      | `DELIVERED`        | The message was successfully delivered.                                                  |
      | `FAILED`           | The task has errored too many times or encountered an error that it cannot recover from. |
      | `CANCEL_REQUESTED` | The cancel request from the user is recorded.                                            |
      | `CANCELLED`        | The cancel request from the user is honored.                                             |
    </ResponseField>

    <ResponseField name="error" type="string" optional>
      An explanation what went wrong
    </ResponseField>

    <ResponseField name="nextDeliveryTime" type="int">
      The next scheduled time of the message.
      (Unix timestamp in milliseconds)
    </ResponseField>

    <ResponseField name="url" type="string">
      The destination url
    </ResponseField>

    <ResponseField name="topicName" type="string">
      The name of the URL Group (topic) if this message was sent through a topic
    </ResponseField>

    <ResponseField name="endpointName" type="int">
      The name of the endpoint if this message was sent through a URL Group
    </ResponseField>

    <ResponseField name="scheduleId" type="string">
      The scheduleId of the message if the message is triggered by a schedule
    </ResponseField>

    <ResponseField name="queueName" type="string">
      The name of the queue if this message is enqueued on a queue
    </ResponseField>

    <ResponseField name="header" type="string">
      The headers that are forwarded to the users endpoint
    </ResponseField>

    <ResponseField name="body" type="string">
      Base64 encoded body of the message
    </ResponseField>

    <ResponseField name="responseStatus" type="int">
      The status code of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="responseBody" type="string">
      The base64 encoded body of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="responseHeaders" type="Record<string, string[]>">
      The headers of the response. Only set if the state is `ERROR`
    </ResponseField>

    <ResponseField name="timeout" type="int">
      The timeout(in milliseconds) of the outgoing http requests, after which Qstash cancels the request
    </ResponseField>

    <ResponseField name="method" type="string">
      Method is the HTTP method of the message for outgoing request
    </ResponseField>

    <ResponseField name="callback" type="string">
      Callback is the URL address where QStash sends the response of a publish
    </ResponseField>

    <ResponseField name="callbackHeaders" type="Record<string, string[]>">
      The headers that are passed to the callback url
    </ResponseField>

    <ResponseField name="failureCallback" type="string">
      Failure Callback is the URL address where QStash sends the response of a publish
    </ResponseField>

    <ResponseField name="failureCallbackHeaders" type="Record<string, string[]>">
      The headers that are passed to the failure callback url
    </ResponseField>

    <ResponseField name="maxRetries" type="int">
      The number of retries that should be attempted in case of delivery failure
    </ResponseField>

    <ResponseField name="retryDelayExpression" type="string">
      The mathematical expression used to calculate delay between retry attempts. If not set, [the default backoff](/qstash/features/retry) is used.
    </ResponseField>

    <ResponseField name="label" type="string">
      The label of the message assigned by the user.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/logs \
    -H "Authorization: Bearer <token>"
  ```

  ```javascript Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/logs", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests
  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/logs',
     headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/logs", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "cursor": "1686652644442-12",
    "events":[
      {
        "time": "1686652644442",
        "messageId": "msg_123",
        "state": "delivered",
        "url": "https://example.com",
        "header": { "Content-Type": [ "application/x-www-form-urlencoded" ] },
        "body": "bWVyaGFiYSBiZW5pbSBhZGltIHNhbmNhcg=="
      }
    ] 
  }
  ```
</ResponseExample>


# Batch Messages
Source: https://upstash.com/docs/qstash/api/messages/batch

POST https://qstash.upstash.io/v2/batch
Send multiple messages in a single request

You can learn more about batching in the [batching section](/qstash/features/batch).

<Note>
  API playground is not available for this endpoint. You can use the cURL example below.
</Note>

<Info>You can publish to destination, URL Group or queue in the same batch request.</Info>

## Request

The endpoint is `POST https://qstash.upstash.io/v2/batch` and the body is an array of
messages. Each message has the following fields:

```
destination: string
headers: headers object
body: string
```

The headers are identical to the headers in the [create](/qstash/api/publish#request) endpoint.

```shell cURL theme={"system"}
curl -XPOST https://qstash.upstash.io/v2/batch   -H "Authorization: Bearer XXX" \
    -H "Content-Type: application/json" \
    -d '
    [
      {
          "destination": "myUrlGroup",
          "headers":{
            "Upstash-Delay":"5s",
            "Upstash-Forward-Hello":"123456"
          },
          "body": "Hello World"
      },
      {
          "queue": "test",
          "destination": "https://example.com/destination",
          "headers":{
            "Upstash-Forward-Hello":"789"
          }
      },
      {
          "destination": "https://example.com/destination1",
          "headers":{
            "Upstash-Delay":"7s",
            "Upstash-Forward-Hello":"789"
          }
      },
      {
          "destination": "https://example.com/destination2",
          "headers":{
            "Upstash-Delay":"9s",
            "Upstash-Forward-Hello":"again"
          }
      }
    ]'
```

## Response

```json  theme={"system"}
[
  [
    {
      "messageId": "msg_...",
      "url": "https://myUrlGroup-endpoint1.com"
    },
    {
      "messageId": "msg_...",
      "url": "https://myUrlGroup-endpoint2.com"
    }
  ],
  {
    "messageId": "msg_...",
  },
  {
    "messageId": "msg_..."
  },
  {
    "messageId": "msg_..."
  }
]
```


# Bulk Cancel Messages
Source: https://upstash.com/docs/qstash/api/messages/bulk-cancel

DELETE https://qstash.upstash.io/v2/messages
Stop delivery of multiple messages at once

Bulk cancel allows you to cancel multiple messages at once.

<Note>
  Cancelling a message will remove it from QStash and stop it from being delivered
  in the future. If a message is in flight to your API, it might be too late to
  cancel.
</Note>

<Warning>
  If you provide a set of message IDs in the body of the request, only those messages will be cancelled.

  If you include filter parameters in the request body, only the messages that match the filters will be canceled.

  If the `messageIds` array is empty, QStash will cancel all of your messages.

  If no body is sent, QStash will also cancel all of your messages.
</Warning>

This operation scans all your messages and attempts to cancel them.
If an individual message cannot be cancelled, it will not continue and will return an error message.
Therefore, some messages may not be cancelled at the end.
In such cases, you can run the bulk cancel operation multiple times.

<Note>
  You can filter the messages to cancel by including filter parameters in the request body.
</Note>

## Request

<ParamField body="messageIds" type="Array">
  The list of message IDs to cancel.
</ParamField>

<ParamField body="queueName" type="string">
  Filter messages to cancel by queue name.
</ParamField>

<ParamField body="url" type="string">
  Filter messages to cancel by destination URL.
</ParamField>

<ParamField body="topicName" type="string">
  Filter messages to cancel by URL Group (topic) name.
</ParamField>

<ParamField body="fromDate" type="number">
  Filter messages to cancel by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField body="toDate" type="number">
  Filter messages to cancel by ending date, specified in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField body="scheduleId" type="string">
  Filter messages to cancel by schedule ID.
</ParamField>

<ParamField body="callerIP" type="string">
  Filter messages to cancel by IP address of publisher.
</ParamField>

## Response

A cancelled object with the number of cancelled messages.

```JSON  theme={"system"}
{
  "cancelled": number
}
```

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/messages/ \
     -H "Content-Type: application/json" \
    -H "Authorization: Bearer <token>" \
    -d '{"messageIds": ["msg_id_1", "msg_id_2", "msg_id_3"]}'
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/messages', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
      body: {
          messageIds: [
              "msg_id_1",
              "msg_id_2",
              "msg_id_3",
          ],
      },
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  data = {
    "messageIds": [
      "msg_id_1",
      "msg_id_2",
      "msg_id_3"
    ]
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/messages',
    headers=headers,
    data=data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{
    "messageIds": [
      "msg_id_1",
      "msg_id_2",
      "msg_id_3"
    ]
  }`)
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/messages", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 202 Accepted theme={"system"}
  {
    "cancelled": 10
  }
  ```
</ResponseExample>


# Cancel Message
Source: https://upstash.com/docs/qstash/api/messages/cancel

DELETE https://qstash.upstash.io/v2/messages/{messageId}
Stop delivery of an existing message

Cancelling a message will remove it from QStash and stop it from being delivered
in the future. If a message is in flight to your API, it might be too late to
cancel.

## Request

<ParamField path="messageId" type="string" required>
  The id of the message to cancel.
</ParamField>

## Response

This endpoint only returns `202 OK`

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/messages/msg_123 \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/messages/msg_123', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/messages/msg_123', 
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/messages/msg_123", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```text 202 Accepted theme={"system"}
  OK
  ```
</ResponseExample>


# Get Message
Source: https://upstash.com/docs/qstash/api/messages/get

GET https://qstash.upstash.io/v2/messages/{messageId}
Retrieve a message by its id

## Request

<ParamField path="messageId" type="string" required>
  The id of the message to retrieve.
</ParamField>

<Warning>
  Messages are removed from the database shortly after they're delivered, so you
  will not be able to retrieve a message after. This endpoint is intended to be used
  for accessing messages that are in the process of being delivered/retried.
</Warning>

## Response

<Snippet file="qstash-message-type.mdx" />

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/messages/msg_123 \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/messages/msg_123", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/messages/msg_123',
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/messages/msg_123", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "messageId": "msg_123",
    "topicName": "myTopic",
    "url":"https://example.com",
    "method": "POST",
    "header": {
      "My-Header": ["my-value"]
    },
    "body": "{\"foo\":\"bar\"}",
    "createdAt": 1620000000000
  }
  ```
</ResponseExample>


# Publish a Message
Source: https://upstash.com/docs/qstash/api/publish

POST https://qstash.upstash.io/v2/publish/{destination}
Publish a message

## Request

<ParamField path="destination" type="string" required>
  Destination can either be a topic name or id that you configured in the
  Upstash console, a valid url where the message gets sent to, or a valid
  QStash API name like `api/llm`. If the destination is a URL, make sure
  the URL is prefixed with a valid protocol (`http://` or `https://`)
</ParamField>

<Snippet file="qstash-common-request.mdx" />

<ParamField header="Upstash-Delay" type="string">
  Delay the message delivery.

  Format for this header is a number followed by duration abbreviation, like
  `10s`. Available durations are `s` (seconds), `m` (minutes), `h` (hours), `d`
  (days).

  example: "50s" | "3m" | "10h" | "1d"
</ParamField>

<ParamField header="Upstash-Not-Before" type="int">
  Delay the message delivery until a certain time in the future.

  The format is a unix timestamp in seconds, based on the UTC timezone.

  When both `Upstash-Not-Before` and `Upstash-Delay` headers are provided,
  `Upstash-Not-Before` will be used.
</ParamField>

<ParamField header="Upstash-Deduplication-Id" type="string">
  Id to use while deduplicating messages, so that only one message with
  the given deduplication id is published.
</ParamField>

<ParamField header="Upstash-Content-Based-Deduplication" type="boolean">
  When set to true, automatically deduplicates messages based on their content,
  so that only one message with the same content is published.

  Content based deduplication creates unique deduplication ids based on the
  following message fields:

  * Destination
  * Body
  * Headers
</ParamField>

## Response

<Snippet file="qstash-publish-response.mdx" />

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST "https://qstash.upstash.io/v2/publish/https://www.example.com" \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -H "Upstash-Method: POST" \
    -H "Upstash-Delay: 10s" \
    -H "Upstash-Retries: 3" \
    -H "Upstash-Retry-Delay: pow(2, retried) * 1000" \
    -H "Upstash-Forward-Custom-Header: custom-value" \
    -d '{"message":"Hello, World!"}'
  ```

  ```js Node theme={"system"}
  const response = await fetch(
    "https://qstash.upstash.io/v2/publish/https://www.example.com",
    {
      method: "POST",
      headers: {
        Authorization: "Bearer <token>",
        "Content-Type": "application/json",
        "Upstash-Method": "POST",
        "Upstash-Delay": "10s",
        "Upstash-Retries": "3",
        "Upstash-Retry-Delay": "pow(2, retried) * 1000",
        "Upstash-Forward-Custom-Header": "custom-value",
      },
      body: JSON.stringify({
        message: "Hello, World!",
      }),
    }
  );
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
      'Upstash-Method': 'POST',
      'Upstash-Delay': '10s',
      'Upstash-Retries': '3',
      'Upstash-Retry-Delay': 'pow(2, retried) * 1000',
      'Upstash-Forward-Custom-Header': 'custom-value',
  }

  json_data = {
      'message': 'Hello, World!',
  }

  response = requests.post(
    'https://qstash.upstash.io/v2/publish/https://www.example.com',
     headers=headers,
     json=json_data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{"message":"Hello, World!"}`)
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/publish/https://www.example.com", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  req.Header.Set("Upstash-Method", "POST")
  req.Header.Set("Upstash-Delay", "10s")
  req.Header.Set("Upstash-Retries", "3")
  req.Header.Set("Upstash-Retry-Delay", "pow(2, retried) * 1000")
  req.Header.Set("Upstash-Forward-Custom-Header", "custom-value")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json URL theme={"system"}
  {
    "messageId": "msd_1234",
    "url": "https://www.example.com"
  }
  ```

  ```json URL Group theme={"system"}
  [
    {
      "messageId": "msd_1234",
      "url": "https://www.example.com"
    },
    {
      "messageId": "msd_5678",
      "url": "https://www.somewhere-else.com",
      "deduplicated": true
    }
  ]
  ```
</ResponseExample>


# Get a Queue
Source: https://upstash.com/docs/qstash/api/queues/get

GET https://qstash.upstash.io/v2/queues/{queueName}
Retrieves a queue

## Request

<ParamField path="queueName" type="string" required>
  The name of the queue to retrieve.
</ParamField>

## Response

<ResponseField name="createdAt" type="int" required>
  The creation time of the queue. UnixMilli
</ResponseField>

<ResponseField name="updatedAt" type="int" required>
  The update time of the queue. UnixMilli
</ResponseField>

<ResponseField name="name" type="string" required>
  The name of the queue.
</ResponseField>

<ResponseField name="parallelism" type="int" required>
  The number of parallel consumers consuming from [the queue](/qstash/features/queues).
</ResponseField>

<ResponseField name="lag" type="int" required>
  The number of unprocessed messages that exist in [the queue](/qstash/features/queues).
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/queues/my-queue \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/queue/my-queue', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/queue/my-queue',
     headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/queue/my-queue", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
   
    "createdAt": 1623345678001,
    "updatedAt": 1623345678001,
    "name": "my-queue",
    "parallelism" : 5, 
    "lag" : 100
  }
  ```
</ResponseExample>


# List Queues
Source: https://upstash.com/docs/qstash/api/queues/list

GET https://qstash.upstash.io/v2/queues
List all your queues

## Request

No parameters

## Response

<ResponseField name="" type="Array" required>
  <Expandable defaultOpen>
    <ResponseField name="createdAt" type="int" required>
      The creation time of the queue. UnixMilli
    </ResponseField>

    <ResponseField name="updatedAt" type="int" required>
      The update time of the queue. UnixMilli
    </ResponseField>

    <ResponseField name="name" type="string" required>
      The name of the queue.
    </ResponseField>

    <ResponseField name="parallelism" type="int" required>
      The number of parallel consumers consuming from [the queue](/qstash/features/queues).
    </ResponseField>

    <ResponseField name="lag" type="int" required>
      The number of unprocessed messages that exist in [the queue](/qstash/features/queues).
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/queues \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/queues", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/queues',
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/queues", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  [
    {
      "createdAt": 1623345678001,
      "updatedAt": 1623345678001,
      "name": "my-queue",
      "parallelism" : 5, 
      "lag" : 100
    },
    // ...
  ]
  ```
</ResponseExample>


# Pause Queue
Source: https://upstash.com/docs/qstash/api/queues/pause

POST https://qstash.upstash.io/v2/queues/{queueName}/pause
Pause an active queue

Pausing a queue stops the delivery of enqueued messages.
The queue will still accept new messages, but they will wait until the queue becomes active for delivery.
If the queue is already paused, this action has no effect.

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>

## Request

<ParamField path="queueName" type="string" required>
  The name of the queue to pause.
</ParamField>

## Response

This endpoint simply returns 200 OK if the queue is paused successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/queues/queue_1234/pause \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  import { Client } from "@upstash/qstash";
  /**
   * Import a fetch polyfill only if you are using node prior to v18.
   * This is not necessary for nextjs, deno or cloudflare workers.
   */
  import "isomorphic-fetch";

  const c = new Client({
    token: "<QSTASH_TOKEN>",
  });

  c.queue({ queueName: "<QUEUE_NAME>" }).pause()
  ```

  ```python Python  theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")

  client.queue.pause("<QUEUE_NAME>")
  ```

  ```go Go theme={"system"}
  package main

  import (
  	"github.com/upstash/qstash-go"
  )

  func main() {
  	client := qstash.NewClient("<QSTASH_TOKEN>")

  	// error checking is omitted for brevity
  	err := client.Queues().Pause("<QUEUE_NAME>")
  }
  ```
</RequestExample>


# Remove a Queue
Source: https://upstash.com/docs/qstash/api/queues/remove

DELETE https://qstash.upstash.io/v2/queues/{queueName}
Removes a queue

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>

## Request

<ParamField path="queueName" type="string" required>
  The name of the queue to remove.
</ParamField>

## Response

This endpoint returns 200 if the queue is removed successfully,
or it doesn't exist.

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/queues/my-queue \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/queue/my-queue', {
    method: "DELETE",
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/queue/my-queue',
     headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/queue/my-queue", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Resume Queue
Source: https://upstash.com/docs/qstash/api/queues/resume

POST https://qstash.upstash.io/v2/queues/{queueName}/resume
Resume a paused queue

Resuming a queue starts the delivery of enqueued messages from the earliest undelivered message.
If the queue is already active, this action has no effect.

## Request

<ParamField path="queueName" type="string" required>
  The name of the queue to resume.
</ParamField>

## Response

This endpoint simply returns 200 OK if the queue is resumed successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/queues/queue_1234/resume \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  import { Client } from "@upstash/qstash";
  /**
   * Import a fetch polyfill only if you are using node prior to v18.
   * This is not necessary for nextjs, deno or cloudflare workers.
   */
  import "isomorphic-fetch";

  const c = new Client({
    token: "<QSTASH_TOKEN>",
  });

  c.queue({ queueName: "<QUEUE_NAME>" }).resume()
  ```

  ```python Python  theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")

  client.queue.resume("<QUEUE_NAME>")
  ```

  ```go Go theme={"system"}
  package main

  import (
  	"github.com/upstash/qstash-go"
  )

  func main() {
  	client := qstash.NewClient("<QSTASH_TOKEN>")

  	// error checking is omitted for brevity
  	err := client.Queues().Resume("<QUEUE_NAME>")
  }
  ```
</RequestExample>


# Upsert a Queue
Source: https://upstash.com/docs/qstash/api/queues/upsert

POST https://qstash.upstash.io/v2/queues/
Updates or creates a queue

## Request

<ParamField body="queueName" type="string" required>
  The name of the queue.
</ParamField>

<ParamField body="parallelism" type="int" required>
  The number of parallel consumers consuming from [the queue](/qstash/features/queues).

  <Warning>
    For the parallelism limit, we introduced an easier and less limited API with publish.
    Please check the [Flow Control](/qstash/features/flowcontrol) page for the detailed information.

    Setting parallelism with queues will be deprecated at some point.
  </Warning>
</ParamField>

## Response

This endpoint returns

* 200 if the queue is added successfully.
* 412 if it fails because of the the allowed number of queues limit

<RequestExample>
  ```sh curl theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/queues/ \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
      "queueName": "my-queue" , 
      "parallelism" : 5,
    }'
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/queues/', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      "queueName": "my-queue" , 
      "parallelism" : 5,
    })
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  json_data = {
      "queueName": "my-queue" , 
      "parallelism" : 5,
    }

  response = requests.post(
    'https://qstash.upstash.io/v2/queues/',
    headers=headers, 
    json=json_data
  )
  ```

  ```go Go  theme={"system"}
  var data = strings.NewReader(`{
      "queueName": "my-queue" , 
      "parallelism" : 5,
    }`)
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/queues/", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Create Schedule
Source: https://upstash.com/docs/qstash/api/schedules/create

POST https://qstash.upstash.io/v2/schedules/{destination}
Create a schedule to send messages periodically

## Request

<ParamField path="destination" type="string" required>
  Destination can either be a topic name or id that you configured in the
  Upstash console or a valid url where the message gets sent to.
  If the destination is a URL, make sure
  the URL is prefixed with a valid protocol (`http://` or `https://`)
</ParamField>

<ParamField header="Upstash-Cron" type="string" required>
  Cron allows you to send this message periodically on a schedule.

  Add a Cron expression and we will requeue this message automatically whenever
  the Cron expression triggers. We offer an easy to use UI for creating Cron
  expressions in our [console](https://console.upstash.com/qstash) or you can
  check out [Crontab.guru](https://crontab.guru).

  Note: it can take up to 60 seconds until the schedule is registered on an
  available qstash node.

  Example: `*/5 * * * *`

  Timezones are also supported. You can specify timezone together with cron expression
  as follows:

  Example: `CRON_TZ=America/New_York 0 4 * * *`
</ParamField>

<Snippet file="qstash-common-request.mdx" />

<ParamField header="Upstash-Delay" type="string">
  Delay the message delivery.

  Delay applies to the delivery of the scheduled messages.
  For example, with the delay set to 10 minutes for a schedule
  that runs everyday at 00:00, the scheduled message will be
  created at 00:00 and it will be delivered at 00:10.

  Format for this header is a number followed by duration abbreviation, like
  `10s`. Available durations are `s` (seconds), `m` (minutes), `h` (hours), `d`
  (days).

  example: "50s" | "3m" | "10h" | "1d"
</ParamField>

<ParamField header="Upstash-Schedule-Id" type="string">
  Assign a schedule id to the created schedule.

  This header allows you to set the schedule id yourself instead of QStash assigning
  a random id.

  If a schedule with the provided id exists, the settings of the existing schedule
  will be updated with the new settings.
</ParamField>

## Response

<ResponseField name="scheduleId" type="string" required>
  The unique id of this schedule. You can use it to delete the schedule later.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/schedules/https://www.example.com/endpoint \
    -H "Authorization: Bearer <token>" \
    -H "Upstash-Cron: */5 * * * *"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/schedules/https://www.example.com/endpoint', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer <token>',
      'Upstash-Cron': '*/5 * * * *'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Upstash-Cron': '*/5 * * * *'
  }

  response = requests.post(
    'https://qstash.upstash.io/v2/schedules/https://www.example.com/endpoint',
     headers=headers
  )
  ```

  ```go Go  theme={"system"}
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/schedules/https://www.example.com/endpoint", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Upstash-Cron", "*/5 * * * *")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "scheduleId": "scd_1234"
  }
  ```
</ResponseExample>


# Get Schedule
Source: https://upstash.com/docs/qstash/api/schedules/get

GET https://qstash.upstash.io/v2/schedules/{scheduleId}
Retrieves a schedule by id.

## Request

<ParamField path="scheduleId" type="string" required>
  The id of the schedule to retrieve.
</ParamField>

## Response

<ResponseField name="scheduleId" type="string" required>
  The id of the schedule.
</ResponseField>

<ResponseField name="cron" type="string" required>
  The cron expression used to schedule the message.
</ResponseField>

<ResponseField name="createdAt" type="int" required>
  The creation time of the object. UnixMilli
</ResponseField>

<ResponseField name="destination" type="string" required>
  Url or URL Group name
</ResponseField>

<ResponseField name="method" type="string" required>
  The HTTP method to use for the message.
</ResponseField>

<ResponseField name="header" type="Record<string, string[]>">
  The headers of the message.
</ResponseField>

<ResponseField name="body" type="string">
  The body of the message.
</ResponseField>

<ResponseField name="bodyBase64" type="string">
  The base64 encoded body of the message.
</ResponseField>

<ResponseField name="retries" type="int">
  The number of retries that should be attempted in case of delivery failure.
</ResponseField>

<ResponseField name="delay" type="int">
  The delay in seconds before the message is delivered.
</ResponseField>

<ResponseField name="callback" type="string">
  The url where we send a callback to after the message is delivered
</ResponseField>

<ResponseField name="failureCallback" type="string">
  The url where we send a callback to after the message delivery fails
</ResponseField>

<ResponseField name="callerIp" type="string">
  IP address where this schedule was created from.
</ResponseField>

<ResponseField name="isPaused" type="boolean" required>
  Whether the schedule is paused or not.
</ResponseField>

<ResponseField name="flowControlKey" type="string">
  The flow control key for rate limiting.
</ResponseField>

<ResponseField name="parallelism" type="int">
  The maximum number of parallel executions.
</ResponseField>

<ResponseField name="rate" type="int">
  The rate limit for this schedule.
</ResponseField>

<ResponseField name="period" type="int">
  The time interval during which the specified rate of requests can be activated using the same flow control key. In seconds.
</ResponseField>

<ResponseField name="retryDelayExpression" type="string">
  The retry delay expression for this schedule, if retry\_delay was set when creating the schedule.
</ResponseField>

<ResponseField name="label" type="string">
  The label assigned to the schedule for filtering purposes.
</ResponseField>

<ResponseField name="lastScheduleTime" type="int">
  The timestamp of the last scheduled execution.
</ResponseField>

<ResponseField name="nextScheduleTime" type="int">
  The timestamp of the next scheduled execution.
</ResponseField>

<ResponseField name="lastScheduleStates" type="Record<string, string>">
  The states of the last scheduled messages. Maps message id to state (IN\_PROGRESS, SUCCESS, FAIL).
</ResponseField>

<ResponseField name="callerIP" type="string">
  The IP address of the caller who created the schedule.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/schedules/scd_1234 \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/schedules/scd_1234', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/schedules/scd_1234', 
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/schedules/scd_1234", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    createdAt: 1754565618803,
    scheduleId: "schedule-id",
    cron: "* * * * *",
    destination: "https://your-website/api",
    method: "GET",
    header: {
      "Content-Type": [ "application/json" ],
    },
    retries: 3,
    delay: 25,
    lastScheduleTime: 1755095280020,
    nextScheduleTime: 1759909800000,
    lastScheduleStates: {
      msg_7YoJxFpwk: "SUCCESS",
    },
    callerIP: "127.43.12.54",
    isPaused: true,
    parallelism: 0,
  }
  ```
</ResponseExample>


# List Schedules
Source: https://upstash.com/docs/qstash/api/schedules/list

GET https://qstash.upstash.io/v2/schedules
List all your schedules

## Response

<ResponseField name="array" type="Object[]">
  <ResponseField name="scheduleId" type="string" required>
    The id of the schedule.
  </ResponseField>

  <ResponseField name="cron" type="string" required>
    The cron expression used to schedule the message.
  </ResponseField>

  <ResponseField name="createdAt" type="int" required>
    The creation time of the object. UnixMilli
  </ResponseField>

  <ResponseField name="destination" type="string" required>
    Url or URL Group (topic) name
  </ResponseField>

  <ResponseField name="method" type="string" required>
    The HTTP method to use for the message.
  </ResponseField>

  <ResponseField name="header" type="Record<string, string[]>">
    The headers of the message.
  </ResponseField>

  <ResponseField name="body" type="string">
    The body of the message.
  </ResponseField>

  <ResponseField name="retries" type="int">
    The number of retries that should be attempted in case of delivery failure.
  </ResponseField>

  <ResponseField name="delay" type="int">
    The delay in seconds before the message is delivered.
  </ResponseField>

  <ResponseField name="callback" type="string">
    The url where we send a callback to after the message is delivered
  </ResponseField>

  <ResponseField name="failureCallback" type="string">
    The url where we send a callback to after the message delivery fails
  </ResponseField>

  <ResponseField name="callerIp" type="string">
    IP address where this schedule was created from.
  </ResponseField>

  <ResponseField name="isPaused" type="boolean" required>
    Whether the schedule is paused or not.
  </ResponseField>

  <ResponseField name="flowControlKey" type="string">
    The flow control key for rate limiting.
  </ResponseField>

  <ResponseField name="parallelism" type="int">
    The maximum number of parallel executions.
  </ResponseField>

  <ResponseField name="rate" type="int">
    The rate limit for this schedule.
  </ResponseField>

  <ResponseField name="period" type="int">
    The time interval during which the specified rate of requests can be activated using the same flow control key. In seconds.
  </ResponseField>

  <ResponseField name="retryDelayExpression" type="string">
    The retry delay expression for this schedule, if retry\_delay was set when creating the schedule.
  </ResponseField>

  <ResponseField name="label" type="string">
    The label assigned to the schedule for filtering purposes.
  </ResponseField>

  <ResponseField name="lastScheduleTime" type="int">
    The timestamp of the last scheduled execution.
  </ResponseField>

  <ResponseField name="nextScheduleTime" type="int">
    The timestamp of the next scheduled execution.
  </ResponseField>

  <ResponseField name="lastScheduleStates" type="Record<string, string>">
    The states of the last scheduled messages. Maps message id to state (IN\_PROGRESS, SUCCESS, FAIL).
  </ResponseField>

  <ResponseField name="callerIP" type="string">
    The IP address of the caller who created the schedule.
  </ResponseField>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/schedules \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/schedules', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/schedules', 
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/schedules", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  [
    {
      createdAt: 1754565618803,
      scheduleId: "schedule-id",
      cron: "* * * * *",
      destination: "https://your-website/api",
      method: "GET",
      header: {
        "Content-Type": [ "application/json" ],
      },
      retries: 3,
      delay: 25,
      lastScheduleTime: 1755095280020,
      nextScheduleTime: 1759909800000,
      lastScheduleStates: {
        msg_7YoJxFpwk: "SUCCESS",
      },
      callerIP: "127.43.12.54",
      isPaused: true,
      parallelism: 0,
    }
  ]
  ```
</ResponseExample>


# Pause Schedule
Source: https://upstash.com/docs/qstash/api/schedules/pause

POST https://qstash.upstash.io/v2/schedules/{scheduleId}/pause
Pause an active schedule

Pausing a schedule will not change the next delivery time, but the delivery will be ignored.
If the schedule is already paused, this action has no effect.

## Request

<ParamField path="scheduleId" type="string" required>
  The id of the schedule to pause.
</ParamField>

## Response

This endpoint simply returns 200 OK if the schedule is paused successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/schedules/scd_1234/pause \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  import { Client } from "@upstash/qstash";
  /**
   * Import a fetch polyfill only if you are using node prior to v18.
   * This is not necessary for nextjs, deno or cloudflare workers.
   */
  import "isomorphic-fetch";

  const c = new Client({
    token: "<QSTASH_TOKEN>",
  });

  c.schedules.pause({
    schedule: "<SCHEDULE_ID>"
  });

  ```

  ```python Python  theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")

  client.schedule.pause("<SCHEDULE_ID>")
  ```

  ```go Go theme={"system"}
  package main

  import "github.com/upstash/qstash-go"

  func main() {

  	client := qstash.NewClient("<QSTASH_TOKEN>")

  	// error checking is omitted for brevity
  	err := client.Schedules().Pause("<SCHEDULE_ID>")
  }
  ```
</RequestExample>


# Remove Schedule
Source: https://upstash.com/docs/qstash/api/schedules/remove

DELETE https://qstash.upstash.io/v2/schedules/{scheduleId}
Remove a schedule

## Request

<ParamField path="scheduleId" type="string">
  The schedule id to remove
</ParamField>

## Response

This endpoint simply returns 200 OK if the schedule is removed successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/schedules/scd_123 \
    -H "Authorization: Bearer <token>"
  ```

  ```javascript Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/schedules/scd_123', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/schedules/scd_123', 
    headers=headers
  )
  ```

  ```go Go  theme={"system"}
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/schedules/scd_123", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Resume Schedule
Source: https://upstash.com/docs/qstash/api/schedules/resume

POST https://qstash.upstash.io/v2/schedules/{scheduleId}/resume
Resume a paused schedule

Resuming a schedule marks the schedule as active.
This means the upcoming messages will be delivered and will not be ignored.
If the schedule is already active, this action has no effect.

## Request

<ParamField path="scheduleId" type="string" required>
  The id of the schedule to resume.
</ParamField>

## Response

This endpoint simply returns 200 OK if the schedule is resumed successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/schedules/scd_1234/resume \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  import { Client } from "@upstash/qstash";
  /**
   * Import a fetch polyfill only if you are using node prior to v18.
   * This is not necessary for nextjs, deno or cloudflare workers.
   */
  import "isomorphic-fetch";

  const c = new Client({
    token: "<QSTASH_TOKEN>",
  });

  c.schedules.resume({
    schedule: "<SCHEDULE_ID>"
  });

  ```

  ```python Python  theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")

  client.schedule.resume("<SCHEDULE_ID>")
  ```

  ```go Go theme={"system"}
  package main

  import "github.com/upstash/qstash-go"

  func main() {

  	client := qstash.NewClient("<QSTASH_TOKEN>")

  	// error checking is omitted for brevity
  	err := client.Schedules().Resume("<SCHEDULE_ID>")
  }
  ```
</RequestExample>


# Get Signing Keys
Source: https://upstash.com/docs/qstash/api/signingKeys/get

GET https://qstash.upstash.io/v2/keys
Retrieve your signing keys

## Response

<ResponseField name="current" type="string" required>
  Your current signing key.
</ResponseField>

<ResponseField name="next" type="string" required>
  The next signing key.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/keys \
    -H "Authorization: Bearer <token>"
  ```

  ```javascript Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/keys', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/keys',
     headers=headers
  )
  ```

  ```go Go  theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/keys", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  { "current": "sig_123", "next": "sig_456" }
  ```
</ResponseExample>


# Rotate Signing Keys
Source: https://upstash.com/docs/qstash/api/signingKeys/rotate

POST https://qstash.upstash.io/v2/keys/rotate
Rotate your signing keys

## Response

<ResponseField name="current" type="string" required>
  Your current signing key.
</ResponseField>

<ResponseField name="next" type="string" required>
  The next signing key.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/keys/rotate \
    -H "Authorization: Bearer <token>"
  ```

  ```javascript Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/keys/rotate', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }
  response = requests.get(
    'https://qstash.upstash.io/v2/keys/rotate', 
    headers=headers
  )
  ```

  ```go Go  theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/keys/rotate", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  { "current": "sig_123", "next": "sig_456" }
  ```
</ResponseExample>


# Upsert URL Group and Endpoint
Source: https://upstash.com/docs/qstash/api/url-groups/add-endpoint

POST https://qstash.upstash.io/v2/topics/{urlGroupName}/endpoints
Add an endpoint to a URL Group

If the URL Group does not exist, it will be created. If the endpoint does not exist, it will be created.

## Request

<ParamField path="urlGroupName" type="string" required>
  The name of your URL Group (topic). If it doesn't exist yet, it will be created.
</ParamField>

<ParamField body="endpoints" type="Array" required>
  The endpoints to add to the URL Group.

  <Expandable defaultOpen>
    <ParamField body="name" type="string">
      The name of the endpoint
    </ParamField>

    <ParamField body="url" type="string" required>
      The URL of the endpoint
    </ParamField>
  </Expandable>
</ParamField>

## Response

This endpoint returns 200 if the endpoints are added successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
      "endpoints": [
        {
          "name": "endpoint1",
          "url": "https://example.com"
        },
        {
          "name": "endpoint2",
          "url": "https://somewhere-else.com"
        }
      ]
    }'
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      'endpoints': [
        {
          'name': 'endpoint1',
          'url': 'https://example.com'
        },
        {
          'name': 'endpoint2',
          'url': 'https://somewhere-else.com'
        }
      ]
    })
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  json_data = {
      'endpoints': [
          {
              'name': 'endpoint1',
              'url': 'https://example.com',
          },
          {
              'name': 'endpoint2',
              'url': 'https://somewhere-else.com',
          },
      ],
  }

  response = requests.post(
    'https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints',
    headers=headers, 
    json=json_data
  )
  ```

  ```go Go  theme={"system"}
  var data = strings.NewReader(`{
    "endpoints": [
      {
        "name": "endpoint1",
        "url": "https://example.com"
      },
      {
        "name": "endpoint2",
        "url": "https://somewhere-else.com"
      }
    ]
  }`)
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Get a URL Group
Source: https://upstash.com/docs/qstash/api/url-groups/get

GET https://qstash.upstash.io/v2/topics/{urlGroupName}
Retrieves a URL Group

## Request

<ParamField path="urlGroupName" type="string" required>
  The name of the URL Group (topic) to retrieve.
</ParamField>

## Response

<ResponseField name="createdAt" type="int" required>
  The creation time of the URL Group. UnixMilli
</ResponseField>

<ResponseField name="updatedAt" type="int" required>
  The update time of the URL Group. UnixMilli
</ResponseField>

<ResponseField name="name" type="string" required>
  The name of the URL Group.
</ResponseField>

<ResponseField name="endpoints" type="Array" required>
  <Expandable openDefault>
    <ParamField body="name" type="string">
      The name of the endpoint
    </ParamField>

    <ParamField body="url" type="string" required>
      The URL of the endpoint
    </ParamField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/topics/my-url-group \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/topics/my-url-group', {
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python  theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/topics/my-url-group',
     headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/topics/my-url-group", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
   
    "createdAt": 1623345678001,
    "updatedAt": 1623345678001,
    "name": "my-url-group",
    "endpoints": [
      {
        "name": "my-endpoint",
        "url": "https://my-endpoint.com"
      }
    ]
  }
  ```
</ResponseExample>


# List URL Groups
Source: https://upstash.com/docs/qstash/api/url-groups/list

GET https://qstash.upstash.io/v2/topics
List all your URL Groups

## Request

No parameters

## Response

<ResponseField name="" type="Array" required>
  <Expandable defaultOpen>
    <ResponseField name="createdAt" type="int" required>
      The creation time of the URL Group. UnixMilli
    </ResponseField>

    <ResponseField name="updatedAt" type="int" required>
      The update time of the URL Group. UnixMilli
    </ResponseField>

    <ResponseField name="name" type="string" required>
      The name of the URL Group.
    </ResponseField>

    <ResponseField name="endpoints" type="Array" required>
      <Expandable defaultOpen>
        <ParamField body="name" type="string" required>
          The name of the endpoint.
        </ParamField>

        <ParamField body="url" type="string" required>
          The URL of the endpoint
        </ParamField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/topics \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/topics", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/topics',
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/topics", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  [
    {
    
      "createdAt": 1623345678001,
      "updatedAt": 1623345678001,
      "name": "my-url-group",
      "endpoints": [
        {
          "name": "my-endpoint",
          "url": "https://my-endpoint.com"
        }
      ]
    },
    // ...
  ]
  ```
</ResponseExample>


# Remove URL Group
Source: https://upstash.com/docs/qstash/api/url-groups/remove

DELETE https://qstash.upstash.io/v2/topics/{urlGroupName}
Remove a URL group and all its endpoints

The URL Group and all its endpoints are removed. In flight messages in the URL Group are not removed but you will not be able to send messages to the topic anymore.

## Request

<ParamField path="urlGroupName" type="string" required>
  The name of the URL Group to remove.
</ParamField>

## Response

This endpoint returns 200 if the URL Group is removed successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/topics/my-url-group \
    -H "Authorization: Bearer <token>"
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/topics/my-url-group', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/topics/my-url-group', 
    headers=headers
  )
  ```

  ```go Go  theme={"system"}
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/topics/my-url-group", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Remove Endpoints
Source: https://upstash.com/docs/qstash/api/url-groups/remove-endpoint

DELETE https://qstash.upstash.io/v2/topics/{urlGroupName}/endpoints
Remove one or more endpoints

Remove one or multiple endpoints from a URL Group. If all endpoints have been removed, the URL Group will be deleted.

## Request

<ParamField path="urlGroupName" type="string" required>
  The name of your URL Group. If it doesn't exist, we return an error.
</ParamField>

<ParamField body="endpoints" type="Array" required>
  The endpoints to be removed from to the URL Group.

  <Expandable defaultOpen>
    Either `name` or `url` must be provided

    <ParamField body="name" type="string">
      The name of the endpoint
    </ParamField>

    <ParamField body="url" type="string">
      The URL of the endpoint
    </ParamField>
  </Expandable>
</ParamField>

## Response

This endpoint simply returns 200 OK if the endpoints have been removed successfully.

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
      "endpoints": [
        {
          "name": "endpoint1",
        },
        {
          "url": "https://somewhere-else.com"
        }
      ]
    }'
  ```

  ```js Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints", {
    method: "DELETE",
    headers: {
      Authorization: "Bearer <token>",
      "Content-Type": "application/json",
    },
    body: {
      endpoints: [
        {
          name: "endpoint1",
        },
        {
          url: "https://somewhere-else.com",
        },
      ],
    },
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  data = {
     "endpoints": [
        {
          "name": "endpoint1",
        },
        {
          "url": "https://somewhere-else.com"
        }
      ]
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints',
    headers=headers,
    data=data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{
    "endpoints": [
      {
        "name": "endpoint1",
      },
      {
        "url": "https://somewhere-else.com"
      }
    ]
  }`)
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>


# Background Jobs
Source: https://upstash.com/docs/qstash/features/background-jobs



## When do you need background jobs

Background jobs are essential for executing tasks that are too time-consuming to run in the
main execution thread without affecting the user experience.

These tasks might include data processing, sending batch emails, performing scheduled maintenance,
or any other operations that are not immediately required to respond to user requests.

Utilizing background jobs allows your application to remain responsive and scalable, handling more requests simultaneously by offloading
heavy lifting to background processes.

<Note>
  In Serverless frameworks, your hosting provider will likely have a limit for how long each task can last. Try searching
  for the maximum execution time for your hosting provider to find out more.
</Note>

## How to use QStash for background jobs

QStash provides a simple and efficient way to run background jobs, you can understand it as a 2 step process:

1. **Public API** Create a public API endpoint within your application. The endpoint should contain the logic for the background job.

<Warning>
  QStash requires a public endpoint to trigger background jobs, which means it cannot directly access localhost APIs.
  To get around this, you have two options:

  * Run QStash [development server](/qstash/howto/local-development) locally
  * Set up a [local tunnel](/qstash/howto/local-tunnel) for your API
</Warning>

2. **QStash Request** Invoke QStash to start/schedule the execution of the API endpoint.

Here's what this looks like in a simple Next.js application:

<CodeGroup>
  ```tsx app/page.tsx theme={"system"}
  "use client"

  export default function Home() {
    async function handleClick() {
      // Send a request to our server to start the background job.
      // For proper error handling, refer to the quick start.
      // Note: This can also be a server action instead of a route handler
      await fetch("/api/start-email-job", {
        method: "POST",
        body: JSON.stringify({
          users: ["a@gmail.com", "b@gmail.com", "c.gmail.com"]
        }),
      })

    }

    return (
      <main>
        <button onClick={handleClick}>Run background job</button>
      </main>
    );
  }
  ```

  ```typescript app/api/start-email-job/route.ts theme={"system"}
  import { Client } from "@upstash/qstash";

  const qstashClient = new Client({
    token: "YOUR_TOKEN",
  });

  export async function POST(request: Request) {
    const body = await request.json();
    const users: string[] = body.users;
    // If you know the public URL of the email API, you can use it directly
    const rootDomain = request.url.split('/').slice(0, 3).join('/');
    const emailAPIURL = `${rootDomain}/api/send-email`; // ie: https://yourapp.com/api/send-email

    // Tell QStash to start the background job.
    // For proper error handling, refer to the quick start.
    await qstashClient.publishJSON({
      url: emailAPIURL,
      body: {
        users
      }
    });

    return new Response("Job started", { status: 200 });
  }

  ```

  ```typescript app/api/send-email/route.ts theme={"system"}
  // This is a public API endpoint that will be invoked by QStash.
  // It contains the logic for the background job and may take a long time to execute.
  import { sendEmail } from "your-email-library";

  export async function POST(request: Request) {
    const body = await request.json();
    const users: string[] = body.users;

    // Send emails to the users
    for (const user of users) {
      await sendEmail(user);
    }

    return new Response("Job started", { status: 200 });
  }
  ```
</CodeGroup>

To better understand the application, let's break it down:

1. **Client**: The client application contains a button that, when clicked, sends a request to the server to start the background job.
2. **Next.js server**: The first endpoint, `/api/start-email-job`, is invoked by the client to start the background job.
3. **QStash**: The QStash client is used to invoke the `/api/send-email` endpoint, which contains the logic for the background job.

Here is a visual representation of the process:

<Frame>
  <img className="block dark:hidden" src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=aa9487634c406fd5c7f3a2b593fc0dee" alt="Background job diagram" data-og-width="1070" width="1070" data-og-height="819" height="819" data-path="img/qstash/qstash-bgjob-light.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6cbaf9e2ce208d02ff0d9538aaac34d4 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3d2094dcccb410fa7535874565d53701 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=66f5862f5a040808dd16e3dd95bd598d 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6426a63ae8498a72ae057635a12cf504 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=525291d041378c2bbe375e44aa75a713 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-light.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8d580e6461ecc72241208eeef797cbcf 2500w" />

  <img className="hidden dark:block" src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1bea175814a7bad996157f57e517c113" alt="Background job diagram" data-og-width="1070" width="1070" data-og-height="819" height="819" data-path="img/qstash/qstash-bgjob-dark.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d68d7341ceb59aee05176e2985e536d8 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8ae3bccbc31cb9fe526bf2d323c1b026 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f86bc83bb30c79844d3eedf9d0988ff9 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=050504a93d42ed7ff6c4b987a30bacf8 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=360782daae0f8c9b888742a97fa6df62 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-bgjob-dark.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=38015fa7e22e6464e45ca66f2cfca893 2500w" />
</Frame>

To view a more detailed Next.js quick start guide for setting up QStash, refer to the [quick start](/qstash/quickstarts/vercel-nextjs) guide.

It's also possible to schedule a background job to run at a later time using [schedules](/qstash/features/schedules).

If you'd like to invoke another endpoint when the background job is complete, you can use [callbacks](/qstash/features/callbacks).


# Batching
Source: https://upstash.com/docs/qstash/features/batch



[Publishing](/qstash/howto/publishing) is great for sending one message
at a time, but sometimes you want to send a batch of messages at once.

This can be useful to send messages to a single or multiple destinations.
QStash provides the `batch` endpoint to help
you with this.

If the format of the messages are valid, the response will be an array of
responses for each message in the batch. When batching URL Groups, the response
will be an array of responses for each destination in the URL Group. If one
message fails to be sent, that message will have an error response, but the
other messages will still be sent.

<Note>You can publish to destination, URL Group or queue in the same batch request.</Note>

## Batching messages with destinations

<Info>You can also send messages to the same destination!</Info>

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/batch \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -d '
       [
        {
          "destination": "https://example.com/destination1"
        },
        {
          "destination": "https://example.com/destination2"
        }
       ]'
  ```

  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/qstash";

  // Each message is the same as the one you would send with the publish endpoint
  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.batchJSON([
    {
      url: "https://example.com/destination1",
    },
    {
      url: "https://example.com/destination2",
    },
  ]);
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH-TOKEN>")
  client.message.batch_json(
      [
          {"url": "https://example.com/destination1"},
          {"url": "https://example.com/destination2"},
      ]
  )
  ```
</CodeGroup>

## Batching messages with URL Groups

If you have a [URL Group](/qstash/howto/url-group-endpoint), you can batch send with
the URL Group as well.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/batch \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -d '
       [
        {
          "destination": "myUrlGroup"
        },
        {
          "destination": "https://example.com/destination2"
        }
       ]'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  // Each message is the same as the one you would send with the publish endpoint
  const res = await client.batchJSON([
    {
      urlGroup: "myUrlGroup",
    },
    {
      url: "https://example.com/destination2",
    },
  ]);
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH-TOKEN>")
  client.message.batch_json(
      [
          {"url_group": "my-url-group"},
          {"url": "https://example.com/destination2"},
      ]
  )
  ```
</CodeGroup>

## Batching messages with queue

If you have a [queue](/qstash/features/queues), you can batch send with
the queue. It is the same as publishing to a destination, but you need to set the queue name.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/batch \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -d '
       [
        {
          "queue": "my-queue",
          "destination": "https://example.com/destination1"
        },
        {
          "queue": "my-second-queue",
          "destination": "https://example.com/destination2"
        }
       ]'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  const res = await client.batchJSON([
    {
      queueName: "my-queue",
      url: "https://example.com/destination1",
    },
    {
      queueName: "my-second-queue",
      url: "https://example.com/destination2",
    },
  ]);
  ```

  ```python Python theme={"system"}
  from upstash_qstash import QStash
  from upstash_qstash.message import BatchRequest

  qstash = QStash("<QSTASH_TOKEN>")

  messages = [
      BatchRequest(
          queue="my-queue",
          url="https://httpstat.us/200",
          body=f"hi 1",
          retries=0
      ),
      BatchRequest(
          queue="my-second-queue",
          url="https://httpstat.us/200",
          body=f"hi 2",
          retries=0
      ),
  ]

  qstash.message.batch(messages)
  ```
</CodeGroup>

## Batching messages with headers and body

You can provide custom headers and a body for each message in the batch.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/batch   -H "Authorization: Bearer XXX" \
      -H "Content-Type: application/json" \
      -d '
      [
        {
            "destination": "myUrlGroup",
            "headers":{
              "Upstash-Delay":"5s",
              "Upstash-Forward-Hello":"123456"
            },
            "body": "Hello World"
        },
        {
            "destination": "https://example.com/destination1",
            "headers":{
              "Upstash-Delay":"7s",
              "Upstash-Forward-Hello":"789"
            }
        },
        {
            "destination": "https://example.com/destination2",
            "headers":{
              "Upstash-Delay":"9s",
              "Upstash-Forward-Hello":"again"
            }
        }
      ]'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  // Each message is the same as the one you would send with the publish endpoint
  const msgs = [
    {
      urlGroup: "myUrlGroup",
      delay: 5,
      body: "Hello World",
      headers: {
        hello: "123456",
      },
    },
    {
      url: "https://example.com/destination1",
      delay: 7,
      headers: {
        hello: "789",
      },
    },
    {
      url: "https://example.com/destination2",
      delay: 9,
      headers: {
        hello: "again",
      },
      body: {
        Some: "Data",
      },
    },
  ];

  const res = await client.batchJSON(msgs);
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH-TOKEN>")
  client.message.batch_json(
      [
          {
              "url_group": "my-url-group",
              "delay": "5s",
              "body": {"hello": "world"},
              "headers": {"random": "header"},
          },
          {
              "url": "https://example.com/destination1",
              "delay": "1m",
          },
          {
              "url": "https://example.com/destination2",
              "body": {"hello": "again"},
          },
      ]
  )
  ```
</CodeGroup>

#### The response for this will look like

```json  theme={"system"}
[
  [
    {
      "messageId": "msg_...",
      "url": "https://myUrlGroup-endpoint1.com"
    },
    {
      "messageId": "msg_...",
      "url": "https://myUrlGroup-endpoint2.com"
    }
  ],
  {
    "messageId": "msg_..."
  },
  {
    "messageId": "msg_..."
  }
]
```


# Callbacks
Source: https://upstash.com/docs/qstash/features/callbacks



All serverless function providers have a maximum execution time for each
function. Usually you can extend this time by paying more, but it's still
limited. QStash provides a way to go around this problem by using callbacks.

## What is a callback?

A callback allows you to call a long running function without having to wait for
its response. Instead of waiting for the request to finish, you can add a
callback url to your published message and when the request finishes, we will
call your callback URL with the response.

<img className="block h-32 dark:hidden" src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9f0250ec6be5fab7f0725ca9414f3625" data-og-width="1952" width="1952" data-og-height="472" height="472" data-path="img/qstash/callbacks.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a32bb193cbff8a0990c757242ee8697d 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=79f97f7832a197bbd6ca1658b67ce2fb 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d520b1a4e7778180056e5b5582b563b2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fad37f01afe4c1541754d060b9f9ece4 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fd84f5d263fb7b41d7806694dc740f41 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callbacks.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=aee3cf71eb58efd7bbc0e21f2df41b03 2500w" />

<img className="hidden h-40 dark:block" src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c8ff0fd52e8896e529a79a776d69ff7a" data-og-width="2234" width="2234" data-og-height="725" height="725" data-path="img/qstash/callback_dark.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c778a32a111846209dd953c0d41d5266 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=26b194dab1855728225776b631d5bee3 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9767654e2a9d70b5320a442b11eb2710 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=008355a069975305e80db9201aebf87c 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b38d815bfa5003644179436b6ec7915c 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/callback_dark.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3219b39dac8894ba457e200eb32eac3 2500w" />

1. You publish a message to QStash using the `/v2/publish` endpoint
2. QStash will enqueue the message and deliver it to the destination
3. QStash waits for the response from the destination
4. When the response is ready, QStash calls your callback URL with the response

Callbacks publish a new message with the response to the callback URL. Messages
created by callbacks are charged as any other message.

## How do I use Callbacks?

You can add a callback url in the `Upstash-Callback` header when publishing a
message. The value must be a valid URL.

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -X POST \
    https://qstash.upstash.io/v2/publish/https://my-api... \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer <QSTASH_TOKEN>' \
    -H 'Upstash-Callback: <CALLBACK_URL>' \
    -d '{ "hello": "world" }'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    callback: "https://my-callback...",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      callback="https://my-callback...",
  )
  ```
</CodeGroup>

The callback body sent to you will be a JSON object with the following fields:

```json  theme={"system"}
{
  "status": 200,
  "header": { "key": ["value"] },         // Response header
  "body": "YmFzZTY0IGVuY29kZWQgcm9keQ==", // base64 encoded response body
  "retried": 2,                           // How many times we retried to deliver the original message
  "maxRetries": 3,                        // Number of retries before the message assumed to be failed to delivered.
  "sourceMessageId": "msg_xxx",           // The ID of the message that triggered the callback
  "topicName": "myTopic",                 // The name of the URL Group (topic) if the request was part of a URL Group
  "endpointName": "myEndpoint",           // The endpoint name if the endpoint is given a name within a topic
  "url": "http://myurl.com",              // The destination url of the message that triggered the callback
  "method": "GET",                        // The http method of the message that triggered the callback
  "sourceHeader": { "key": "value" },     // The http header of the message that triggered the callback
  "sourceBody": "YmFzZTY0kZWQgcm9keQ==",  // The base64 encoded body of the message that triggered the callback
  "notBefore": "1701198458025",           // The unix timestamp of the message that triggered the callback is/will be delivered in milliseconds
  "createdAt": "1701198447054",           // The unix timestamp of the message that triggered the callback is created in milliseconds
  "scheduleId": "scd_xxx",                // The scheduleId of the message if the message is triggered by a schedule
  "callerIP": "178.247.74.179"            // The IP address where the message that triggered the callback is published from
}
```

In Next.js you could use the following code to handle the callback:

```js  theme={"system"}
// pages/api/callback.js

import { verifySignature } from "@upstash/qstash/nextjs";

function handler(req, res) {
  // responses from qstash are base64-encoded
  const decoded = atob(req.body.body);
  console.log(decoded);

  return res.status(200).end();
}

export default verifySignature(handler);

export const config = {
  api: {
    bodyParser: false,
  },
};
```

We may truncate the response body if it exceeds your plan limits. You can check
your `Max Message Size` in the
[console](https://console.upstash.com/qstash?tab=details).

Make sure you verify the authenticity of the callback request made to your API
by
[verifying the signature](/qstash/features/security/#request-signing-optional).

# What is a Failure-Callback?

Failure callbacks are similar to callbacks but they are called only when all the retries are exhausted and still
the message can not be delivered to the given endpoint.

This is designed to be an serverless alternative to [List messages to DLQ](/qstash/api/dlq/listMessages).

You can add a failure callback URL in the `Upstash-Failure-Callback` header when publishing a
message. The value must be a valid URL.

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -X POST \
    https://qstash.upstash.io/v2/publish/<DESTINATION_URL> \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer <QSTASH_TOKEN>' \
    -H 'Upstash-Failure-Callback: <CALLBACK_URL>' \
    -d '{ "hello": "world" }'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    failureCallback: "https://my-callback...",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      failure_callback="https://my-callback...",
  )
  ```
</CodeGroup>

The callback body sent to you will be a JSON object with the following fields:

```json  theme={"system"}
{
  "status": 400,
  "header": { "key": ["value"] },         // Response header
  "body": "YmFzZTY0IGVuY29kZWQgcm9keQ==", // base64 encoded response body
  "retried": 3,                           // How many times we retried to deliver the original message
  "maxRetries": 3,                        // Number of retries before the message assumed to be failed to delivered.
  "dlqId": "1725323658779-0",             // Dead Letter Queue id. This can be used to retrieve/remove the related message from DLQ.
  "sourceMessageId": "msg_xxx",           // The ID of the message that triggered the callback
  "topicName": "myTopic",                 // The name of the URL Group (topic) if the request was part of a topic
  "endpointName": "myEndpoint",           // The endpoint name if the endpoint is given a name within a topic
  "url": "http://myurl.com",              // The destination url of the message that triggered the callback
  "method": "GET",                        // The http method of the message that triggered the callback
  "sourceHeader": { "key": "value" },     // The http header of the message that triggered the callback
  "sourceBody": "YmFzZTY0kZWQgcm9keQ==",  // The base64 encoded body of the message that triggered the callback
  "notBefore": "1701198458025",           // The unix timestamp of the message that triggered the callback is/will be delivered in milliseconds
  "createdAt": "1701198447054",           // The unix timestamp of the message that triggered the callback is created in milliseconds
  "scheduleId": "scd_xxx",                // The scheduleId of the message if the message is triggered by a schedule
  "callerIP": "178.247.74.179"            // The IP address where the message that triggered the callback is published from
}
```

You can also use a callback and failureCallback together!

## Configuring Callbacks

Publishes/enqueues for callbacks can also be configured with the same HTTP headers that are used to configure direct publishes/enqueues.

<Tip> You can refer to headers that are used to configure `publishes` [here](/qstash/api/publish) and for `enqueues`
[here](/qstash/api/enqueue) </Tip>

Instead of the `Upstash` prefix for headers, the `Upstash-Callback`/`Upstash-Failure-Callback` prefix can be used to configure callbacks as follows:

```
Upstash-Callback-Timeout 
Upstash-Callback-Retries
Upstash-Callback-Delay 
Upstash-Callback-Method 
Upstash-Failure-Callback-Timeout 
Upstash-Failure-Callback-Retries
Upstash-Failure-Callback-Delay
Upstash-Failure-Callback-Method
```

You can also forward headers to your callback endpoints as follows:

```
Upstash-Callback-Forward-MyCustomHeader 
Upstash-Failure-Callback-Forward-MyCustomHeader  
```


# Deduplication
Source: https://upstash.com/docs/qstash/features/deduplication



Messages can be deduplicated to prevent duplicate messages from being sent. When
a duplicate message is detected, it is accepted by QStash but not enqueued. This
can be useful when the connection between your service and QStash fails, and you
never receive the acknowledgement. You can simply retry publishing and can be
sure that the message will enqueued only once.

In case a message is a duplicate, we will accept the request and return the
messageID of the existing message. The only difference will be the response
status code. We'll send HTTP `202 Accepted` code in case of a duplicate message.

## Deduplication ID

To deduplicate a message, you can send the `Upstash-Deduplication-Id` header
when publishing the message.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Deduplication-Id: abcdef" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://my-api..."'
  ```

  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    deduplicationId: "abcdef",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      deduplication_id="abcdef",
  )
  ```
</CodeGroup>

## Content Based Deduplication

If you want to deduplicate messages automatically, you can set the
`Upstash-Content-Based-Deduplication` header to `true`.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Content-Based-Deduplication: true" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/...'
  ```

  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    contentBasedDeduplication: true,
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      content_based_deduplication=True,
  )
  ```
</CodeGroup>

Content based deduplication creates a unique deduplication ID for the message
based on the following fields:

* **Destination**: The URL Group or endpoint you are publishing the message to.

* **Body**: The body of the message.

* **Header**: This includes the `Content-Type` header and all headers, that you
  forwarded with the `Upstash-Forward-` prefix. See
  [custom HTTP headers section](/qstash/howto/publishing#sending-custom-http-headers).

<Info>
  The deduplication window is 10 minutes. After that, messages with the same ID or content can be sent again.
</Info>


# Delay
Source: https://upstash.com/docs/qstash/features/delay



When publishing a message, you can delay it for a certain amount of time before
it will be delivered to your API. See the [pricing table](https://upstash.com/pricing/qstash) for more information

<Warning>
  For free: The maximum allowed delay is  **7 days**.

  For pay-as-you-go: The maximum allowed delay is  **1 year**.

  For fixed pricing: The maximum allowed delay is  **Custom(you may delay as much as needed)**.
</Warning>

## Relative Delay

Delay a message by a certain amount of time relative to the time the message was
published.

The format for the duration is `<number><unit>`. Here are some examples:

* `10s` = 10 seconds
* `1m` = 1 minute
* `30m` = half an hour
* `2h` = 2 hours
* `7d` = 7 days

You can send this duration inside the `Upstash-Delay` header.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Delay: 1m" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://my-api...'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    delay: 60,
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      headers={
          "test-header": "test-value",
      },
      delay="60s",
  )
  ```
</CodeGroup>

<Warning>
  `Upstash-Delay` will get overridden by `Upstash-Not-Before` header when both are
  used together.
</Warning>

## Absolute Delay

Delay a message until a certain time in the future. The format is a unix
timestamp in seconds, based on the UTC timezone.

You can send the timestamp inside the `Upstash-Not-Before` header.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Not-Before: 1657104947" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://my-api...'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    notBefore: 1657104947,
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      headers={
          "test-header": "test-value",
      },
      not_before=1657104947,
  )
  ```
</CodeGroup>

<Info>
  `Upstash-Not-Before` will override the `Upstash-Delay` header when both are used
  together.
</Info>

## Delays in Schedules

Adding a delay in schedules is only possible via `Upstash-Delay`. The
delay will affect the messages that will be created by the schedule and not the
schedule itself.

For example when you create a new schedule with a delay of `30s`, the messages
will be created when the schedule triggers but only delivered after 30 seconds.


# Dead Letter Queues
Source: https://upstash.com/docs/qstash/features/dlq



At times, your API may fail to process a request. This could be due to a bug in your code, a temporary issue with a third-party service, or even network issues.
QStash automatically retries messages that fail due to a temporary issue but eventually stops and moves the message to a dead letter queue to be handled manually.

Read more about retries [here](/qstash/features/retry).

## How to Use the Dead Letter Queue

You can manually republish messages from the dead letter queue in the console.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1db8b3071c6c2c5081b72b3af8ae308c" data-og-width="1766" width="1766" data-og-height="754" height="754" data-path="img/qstash-dlq/dlq.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=61d0988d24307fa3cd18e92bbdc8ea3c 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=29e07e23a9bd232736824d2e7c1987ae 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=7bcd4f12dad7d2b087dec72e8df6773e 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=aabf97d59621bd4e4ff30dd0752f6f49 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5d733a24f42737e1abdb415f88d9cb36 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-dlq/dlq.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d142326784affec2a50f680cd44bc6d9 2500w" />
</Frame>

1. **Retry** - Republish the message and remove it from the dead letter queue. Republished messages are just like any other message and will be retried automatically if they fail.
2. **Delete** - Delete the message from the dead letter queue.

## Limitations

Dead letter queues are subject only to a retention period that depends on your plan. Messages are deleted when their retention period expires. See the ‚ÄúMax DLQ Retention‚Äù row on the [QStash Pricing](https://upstash.com/pricing/qstash) page.


# Flow Control
Source: https://upstash.com/docs/qstash/features/flowcontrol



FlowControl enables you to limit the number of messages sent to your endpoint via delaying the delivery.
There are two limits that you can set with the FlowControl feature: [Rate](#rate-limit) and [Parallelism](#parallelism-limit).
And if needed both parameters can be [combined](#rate-and-parallelism-together).

For the `FlowControl`, you need to choose a key first. This key is used to count the number of calls made to your endpoint.

There are not limits to number of keys you can use.

<Warning>
  The rate/parallelism limits are not applied per `url`, they are applied per `Flow-Control-Key`.
</Warning>

<Warning>
  Keep in mind that rate/period and parallelism info are kept on each publish separately. That means
  if you change the rate/period or parallelism on a new publish, the old fired ones will not be affected. They will keep their flowControl config.
  During the period that old `publishes` has not delivered but there are also the `publishes` with the new rates, QStash will effectively allow
  the highest rate/period or highest parallelism. Eventually(after the old publishes are delivered), the new rate/period and parallelism will be used.
</Warning>

## Rate and Period Parameters

The `rate` parameter specifies the maximum number of calls allowed within a given period. The `period` parameter allows you to specify the time window over which the rate limit is enforced. By default, the period is set to 1 second, but you can adjust it to control how frequently calls are allowed. For example, you can set a rate of 10 calls per minute as follows:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  await client.publishJSON({
      url: "https://example.com",
      body: { hello: "world" },
      flowControl: { key: "USER_GIVEN_KEY", rate: 10, period: "1m" },
  });
  ```

  ```bash cURL theme={"system"}
  curl -XPOST -H 'Authorization: Bearer XXX' \
              -H "Content-type: application/json" \
              -H "Upstash-Flow-Control-Key:USER_GIVEN_KEY"  \
              -H "Upstash-Flow-Control-Value:rate=10,period=1m" \
             'https://qstash.upstash.io/v2/publish/https://example.com' \
              -d '{"message":"Hello, World!"}'
  ```
</CodeGroup>

## Parallelism Limit

The parallelism limit is the number of calls that can be active at the same time.
Active means that the call is made to your endpoint and the response is not received yet.

You can set the parallelism limit to 10 calls active at the same time as follows:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  await client.publishJSON({
      url: "https://example.com",
      body: { hello: "world" },
      flowControl: { key: "USER_GIVEN_KEY", parallelism: 10 },
  });
  ```

  ```bash cURL theme={"system"}
  curl -XPOST -H 'Authorization: Bearer XXX' \
              -H "Content-type: application/json" \
              -H "Upstash-Flow-Control-Key:USER_GIVEN_KEY"  \
              -H "Upstash-Flow-Control-Value:parallelism=10" \
             'https://qstash.upstash.io/v2/publish/https://example.com' \ 
              -d '{"message":"Hello, World!"}'
  ```
</CodeGroup>

You can also use the Rest API to get information how many messages waiting for parallelism limit.
See the [API documentation](/qstash/api/flow-control/get) for more details.

### Rate, Parallelism, and Period Together

All three parameters can be combined. For example, with a rate of 10 per minute, parallelism of 20, and a period of 1 minute, QStash will trigger 10 calls in the first minute and another 10 in the next. Since none of them will have finished, the system will wait until one completes before triggering another.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  await client.publishJSON({
      url: "https://example.com",
      body: { hello: "world" },
      flowControl: { key: "USER_GIVEN_KEY", rate: 10, parallelism: 20, period: "1m" },
  });
  ```

  ```bash cURL theme={"system"}
  curl -XPOST -H 'Authorization: Bearer XXX' \
              -H "Content-type: application/json" \
              -H "Upstash-Flow-Control-Key:USER_GIVEN_KEY"  \
              -H "Upstash-Flow-Control-Value:rate=10,parallelism=20,period=1m" \
             'https://qstash.upstash.io/v2/publish/https://example.com' \
              -d '{"message":"Hello, World!"}'
  ```
</CodeGroup>


# Queues
Source: https://upstash.com/docs/qstash/features/queues



The queue concept in QStash allows ordered delivery (FIFO).
See the [API doc](/qstash/api/queues/upsert) for the full list of related Rest APIs.
Here we list common use cases for Queue and how to use them.

## Ordered Delivery

With Queues, the ordered delivery is guaranteed by default.
This means:

* Your messages will be queued without blocking the REST API and sent one by one in FIFO order. Queued means [CREATED](/qstash/howto/debug-logs) event will be logged.
* The next message will wait for retries of the current one if it can not be delivered because your endpoint returns non-2xx code.
  In other words, the next message will be [ACTIVE](/qstash/howto/debug-logs) only after the last message is either [DELIVERED](/qstash/howto/debug-logs) or
  [FAILED](/qstash/howto/debug-logs).
* Next message will wait for [callbacks](/qstash/features/callbacks#what-is-a-callback) or [failure callbacks](/qstash/features/callbacks#what-is-a-failure-callback) to finish.

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -XPOST -H 'Authorization: Bearer XXX' \
              -H "Content-type: application/json" \
    'https://qstash.upstash.io/v2/enqueue/my-queue/https://example.com' -d '{"message":"Hello, World!"}'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  const queue = client.queue({
    queueName: "my-queue"
  })

  await queue.enqueueJSON({
    url: "https://example.com",
    body: {
      "Hello": "World"
    }
  })
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.enqueue_json(
      queue="my-queue",
      url="https://example.com",
      body={
          "Hello": "World",
      },
  )
  ```
</CodeGroup>

## Controlled Parallelism

<Warning>
  For the parallelism limit, we introduced an easier and less limited API with publish.
  Please check the [Flow Control](/qstash/features/flowcontrol) page for the detailed information.

  Setting parallelism with queues will be deprecated at some point.
</Warning>

To ensure that your endpoint is not overwhelmed and also you want more than one-by-one delivery for better throughput,
you can achieve controlled parallelism with queues.

By default, queues have parallelism 1.
Depending on your [plan](https://upstash.com/pricing/qstash), you can configure the parallelism of your queues as follows:

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/queues/ \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
      "queueName": "my-queue", 
      "parallelism": 5,
    }'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  const queue = client.queue({
    queueName: "my-queue"
  })

  await queue.upsert({
    parallelism: 1,
  })
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.queue.upsert("my-queue", parallelism=5)
  ```
</CodeGroup>

After that, you can use the `enqueue` path to send your messages.

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -XPOST -H 'Authorization: Bearer XXX' \ 
              -H "Content-type: application/json" \
    'https://qstash.upstash.io/v2/enqueue/my-queue/https://example.com' -d '{"message":"Hello, World!"}'
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  const queue = QStashClient.queue({
    queueName: "my-queue"
  })

  await queue.enqueueJSON({
    url: "https://example.com",
    body: {
      "Hello": "World"
    }
  })
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.enqueue_json(
      queue="my-queue",
      url="https://example.com",
      body={
          "Hello": "World",
      },
  )
  ```
</CodeGroup>

You can check the parallelism of your queues with the following API:

<CodeGroup>
  ```bash cURL theme={"system"}
  curl https://qstash.upstash.io/v2/queues/my-queue \
    -H "Authorization: Bearer <token>"
  ```

  ```typescript TypeScript theme={"system"}
  const client = new Client({ token: "<QSTASH_TOKEN>" });

  const queue = client.queue({
    queueName: "my-queue"
  })

  const res = await queue.get()
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.queue.get("my-queue")
  ```
</CodeGroup>


# Retry
Source: https://upstash.com/docs/qstash/features/retry



<Warning title="Max HTTP Response Duration">
  QStash will abort a delivery attempt if **the HTTP call to your endpoint does not return within the plan-specific Max HTTP Response Duration**.\
  See the current limits on the <a href="https://upstash.com/pricing/qstash" target="_blank" rel="noopener">QStash pricing page</a>.
</Warning>

Many things can go wrong in a serverless environment. If your API does not
respond with a success status code (2XX), we retry the request to ensure every
message will be delivered.

The maximum number of retries depends on your current plan. By default, we retry
the maximum amount of times, but you can set it lower by sending the
`Upstash-Retries` header:

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Retries: 2" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://my-api...'
  ```

  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    retries: 2,
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      retries=2,
  )
  ```
</CodeGroup>

The backoff algorithm calculates the retry delay based on the number of retries.
Each delay is capped at 1 day.

```
n = how many times this request has been retried
delay =  min(86400, e ** (2.5*n)) // in seconds
```

| n | delay  |
| - | ------ |
| 1 | 12s    |
| 2 | 2m28s  |
| 3 | 30m8ss |
| 4 | 6h7m6s |
| 5 | 24h    |
| 6 | 24h    |

## Custom Retry Delay

You can customize the delay between retry attempts by using the `Upstash-Retry-Delay` header when publishing a message. This allows you to override the default exponential backoff with your own mathematical expressions.

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Retries: 3" \
      -H "Upstash-Retry-Delay: pow(2, retried) * 1000" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://my-api...'
  ```

  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    retries: 3,
    retryDelay: "pow(2, retried) * 1000", // 2^retried * 1000ms
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      retries=3,
      retry_delay="pow(2, retried) * 1000",  # 2^retried * 1000ms
  )
  ```
</CodeGroup>

The `retryDelay` expression can use mathematical functions and the special variable `retried` (current retry attempt count starting from 0).

**Supported functions:**

* `pow` - Power function
* `sqrt` - Square root
* `abs` - Absolute value
* `exp` - Exponential
* `floor` - Floor function
* `ceil` - Ceiling function
* `round` - Rounding function
* `min` - Minimum of values
* `max` - Maximum of values

**Examples:**

* `1000` - Fixed 1 second delay
* `1000 * (1 + retried)` - Linear backoff: 1s, 2s, 3s, 4s...
* `pow(2, retried) * 1000` - Exponential backoff: 1s, 2s, 4s, 8s...
* `max(1000, pow(2, retried) * 100)` - Exponential with minimum 1s delay

## Retry-After Headers

Instead of using the default backoff algorithm, you can specify when QStash should retry your message.
To do this, include one of the following headers in your response to QStash request.

* Retry-After
* X-RateLimit-Reset
* X-RateLimit-Reset-Requests
* X-RateLimit-Reset-Tokens

These headers can be set to a value in seconds, the RFC1123 date format, or a duration format (e.g., 6m5s).
For the duration format, valid time units are "ns", "us" (or "¬µs"), "ms", "s", "m", "h".

Note that you can only delay retries up to the maximum value of the default backoff algorithm, which is one day.
If you specify a value beyond this limit, the backoff algorithm will be applied.

This feature is particularly useful if your application has rate limits, ensuring retries are scheduled appropriately without wasting attempts during restricted periods.

```
Retry-After: 0                             // Next retry will be scheduled immediately without any delay.
Retry-After: 10                            // Next retry will be scheduled after a 10-second delay.
Retry-After: 6m5s                          // Next retry will be scheduled after 6 minutes 5 seconds delay.
Retry-After: Sun, 27 Jun 2024 12:16:24 GMT // Next retry will be scheduled for the specified date, within the allowable limits.
```

## Upstash-Retried Header

QStash adds the `Upstash-Retried` header to requests sent to your API. This
indicates how many times the request has been retried.

```
Upstash-Retried: 0 // This is the first attempt
Upstash-Retried: 1 // This request has been sent once before and now is the second attempt
Upstash-Retried: 2 // This request has been sent twice before and now is the third attempt
```

## Non-Retryable Error

By default, QStash retries requests for any response that does not return a successful 2XX status code.
To explicitly disable retries for a given message, respond with a 489 status code and include the header `Upstash-NonRetryable-Error: true`.

When this header is present, QStash will immediately mark the message as failed and skip any further retry attempts. The message will then be forwarded to the Dead Letter Queue (DLQ) for manual review and resolution.

This mechanism is particularly useful in scenarios where retries are generally enabled but should be bypassed for specific known errors‚Äîsuch as invalid payloads or non-recoverable conditions.


# Schedules
Source: https://upstash.com/docs/qstash/features/schedules



In addition to sending a message once, you can create a schedule, and we will
publish the message in the given period. To create a schedule, you simply need
to add the `Upstash-Cron` header to your `publish` request.

Schedules can be configured using `cron` expressions.
[crontab.guru](https://crontab.guru/) is a great tool for understanding and
creating cron expressions.

By default, we evaluate cron expressions in `UTC`.\
If you want to run your schedule in a specific timezone, see the section on
[Timezones](#timezones).

The following request would create a schedule that will automatically publish
the message every minute:

<CodeGroup>
  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.create({
    destination: "https://example.com",
    cron: "* * * * *",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.schedule.create(
      destination="https://example.com",
      cron="* * * * *",
  )
  ```

  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Cron: * * * * *" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/schedules/https://example.com'
  ```
</CodeGroup>

All of the [other config options](/qstash/howto/publishing#optional-parameters-and-configuration)
can still be used.

<Info>
  It can take up to 60 seconds for the schedule to be loaded on an active node and
  triggered for the first time.
</Info>

You can see and manage your schedules in the
[Upstash Console](https://console.upstash.com/qstash).

### Scheduling to a URL Group

Instead of scheduling a message to a specific URL, you can also create a
schedule, that publishes to a URL Group. Simply use either the URL Group name or its id:

<CodeGroup>
  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.create({
    destination: "urlGroupName",
    cron: "* * * * *",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.schedule.create(
      destination="url-group-name",
      cron="* * * * *",
  )
  ```

  ```bash cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Cron: * * * * *" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/schedules/<URL_GROUP_ID_OR_NAME>'
  ```
</CodeGroup>

### Scheduling to a Queue

You can schedule an item to be added to a queue at a specified time.

<CodeGroup>
  ```bash typescript theme={"system"}
  curl -XPOST \
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.create({
    destination: "https://example.com",
    cron: "* * * * *",
    queueName: "yourQueueName",
  });
  ```

  ```bash cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Cron: * * * * *" \
      -H "Upstash-Queue-Name: yourQueueName" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/schedules/https://example.com'
  ```
</CodeGroup>

### Overwriting an existing schedule

You can pass scheduleId explicitly to overwrite an existing schedule or just simply create the schedule
with the given schedule id.

<CodeGroup>
  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.create({
    destination: "https://example.com",
    scheduleId: "existingScheduleId",
    cron: "* * * * *",
  });
  ```

  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Cron: * * * * *" \
      -H "Upstash-Schedule-Id: existingScheduleId" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/schedules/https://example.com'
  ```
</CodeGroup>

### Timezones

By default, cron expressions are evaluated in `UTC`.\
You can specify a different timezone using the `CRON_TZ` prefix directly inside
the cron expression.  All [IANA timezones](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)
are supported.

For example, this schedule runs every day at `04:00 AM` in New York time:

<CodeGroup>
  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.create({
    destination: "https://example.com",
    cron: "CRON_TZ=America/New_York 0 4 * * *",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.schedule.create(
      destination="https://example.com",
      cron="CRON_TZ=America/New_York 0 4 * * *",
  )
  ```

  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -H "Upstash-Cron: CRON_TZ=America/New_York 0 4 * * *" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/schedules/https://example.com'
  ```
</CodeGroup>


# Security
Source: https://upstash.com/docs/qstash/features/security



### Request Authorization

When interacting with the QStash API, you will need an authorization token. You
can get your token from the [Console](https://console.upstash.com/qstash).

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b0bda5d8c30d60c36bcaaf49accce9b1" data-og-width="1090" width="1090" data-og-height="402" height="402" data-path="img/qstash/rest_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ad32156275de5c4b5c17f8351d03dfd7 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2b05f661b26af08e75cb7bd29b94530a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c7b6ff4e398e7adff1f6901c991f4c92 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c8b639fac03f93107b378b3699c55803 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=18008b9741588917fd62e0efe903be95 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=245f6b9806e7b523b8a4a2ace3dad5c2 2500w" />
</Frame>

Send this token along with every request made to `QStash` inside the
`Authorization` header like this:

```
"Authorization": "Bearer <QSTASH_TOKEN>"
```

### Request Signing (optional)

Because your endpoint needs to be publicly available, we recommend you verify
the authenticity of each incoming request.

#### The `Upstash-Signature` header

With each request we are sending a JWT inside the `Upstash-Signature` header.
You can learn more about them [here](https://jwt.io).

An example token would be:

**Header**

```json  theme={"system"}
{
  "alg": "HS256",
  "typ": "JWT"
}
```

**Payload**

```json  theme={"system"}
{
  "iss": "Upstash",
  "sub": "https://qstash-remote.requestcatcher.com/test",
  "exp": 1656580612,
  "nbf": 1656580312,
  "iat": 1656580312,
  "jti": "jwt_67kxXD6UBAk7DqU6hzuHMDdXFXfP",
  "body": "qK78N0k3pNKI8zN62Fq2Gm-_LtWkJk1z9ykio3zZvY4="
}
```

The JWT is signed using `HMAC SHA256` algorithm with your current signing key
and includes the following claims:

#### Claims

##### `iss`

The issuer field is always `Upstash`.

##### `sub`

The url of your endpoint, where this request is sent to.

For example when you are using a nextjs app on vercel, this would look something
like `https://my-app.vercel.app/api/endpoint`

##### `exp`

A unix timestamp in seconds after which you should no longer accept this
request. Our JWTs have a lifetime of 5 minutes by default.

##### `iat`

A unix timestamp in seconds when this JWT was created.

##### `nbf`

A unix timestamp in seconds before which you should not accept this request.

##### `jti`

A unique id for this token.

##### `body`

The body field is a base64 encoded sha256 hash of the request body. We use url
encoding as specified in
[RFC 4648](https://datatracker.ietf.org/doc/html/rfc4648#section-5).

#### Verifying the signature

See [how to verify the signature](/qstash/howto/signature).


# URL Groups
Source: https://upstash.com/docs/qstash/features/url-groups



Sending messages to a single endpoint and not having to worry about retries is
already quite useful, but we also added the concept of URL Groups to QStash.

In short, a URL Group is just a namespace where you can publish messages to, the
same way as publishing a message to an endpoint directly.

After creating a URL Group, you can create one or multiple endpoints. An endpoint is
defined by a publicly available URL where the request will be sent to each
endpoint after it is published to the URL Group.

When you publish a message to a URL Group, it will be fanned out and sent to all the
subscribed endpoints.

## When should I use URL Groups?

URL Groups decouple your message producers from consumers by grouping one or more
endpoints into a single namespace.

Here's an example: You have a serverless function which is invoked with each
purchase in your e-commerce site. You want to send email to the customer after
the purchase. Inside the function, you submit the URL `api/sendEmail` to the
QStash. Later, if you want to send a Slack notification, you need to update the
serverless function adding another call to QStash to submit
`api/sendNotification`. In this example, you need to update and redeploy the
Serverless function at each time you change (or add) the endpoints.

If you create a URL Group `product-purchase` and produce messages to that URL Group in
the function, then you can add or remove endpoints by only updating the URL Group.
URL Groups give you freedom to modify endpoints without touching the backend
implementation.

Check [here](/qstash/howto/publishing#publish-to-url-group) to learn how to publish
to URL Groups.

## How URL Groups work

When you publish a message to a URL Group, we will enqueue a unique task for each
subscribed endpoint and guarantee successful delivery to each one of them.

[![](https://mermaid.ink/img/pako:eNp1kl1rgzAUhv9KyOWoddXNtrkYVNdf0F0U5ijRHDVMjctHoRT_-2KtaztUQeS8j28e8JxxKhhggpWmGt45zSWtnKMX13GN7PX59IUc5w19iIanBDUmKbkq-qwfXuKdSVQqeQLssK1ZI3itVQ9dekdzdO6Ja9ntKKq-DxtEoP4xYGCIr-OOGCoOG4IYlPwIcqBu0V0XQRK0PE0w9lyCvP1-iB1n1CgcNwofjcJpo_Cua8ooHDWadIrGnaJHp2jaKbrrmnKK_jl1d9s98AxXICvKmd2fy8-MsS6gghgT-5oJCUrH2NKWNA2zi7BlXAuJSUZLBTNMjRa7U51ioqWBAbpu4R9VCsrAfnTG-tR0u5pzpW1lKuqM593cyNKOC60bRVy3i-c514VJ5qmoXMVZQaUujuvADbxgRT0fgqVPX32fpclivcq8l0XGls8Lj-K2bX8Bx2nzPg)](https://mermaid.live/edit#pako:eNp1kl1rgzAUhv9KyOWoddXNtrkYVNdf0F0U5ijRHDVMjctHoRT_-2KtaztUQeS8j28e8JxxKhhggpWmGt45zSWtnKMX13GN7PX59IUc5w19iIanBDUmKbkq-qwfXuKdSVQqeQLssK1ZI3itVQ9dekdzdO6Ja9ntKKq-DxtEoP4xYGCIr-OOGCoOG4IYlPwIcqBu0V0XQRK0PE0w9lyCvP1-iB1n1CgcNwofjcJpo_Cua8ooHDWadIrGnaJHp2jaKbrrmnKK_jl1d9s98AxXICvKmd2fy8-MsS6gghgT-5oJCUrH2NKWNA2zi7BlXAuJSUZLBTNMjRa7U51ioqWBAbpu4R9VCsrAfnTG-tR0u5pzpW1lKuqM593cyNKOC60bRVy3i-c514VJ5qmoXMVZQaUujuvADbxgRT0fgqVPX32fpclivcq8l0XGls8Lj-K2bX8Bx2nzPg)

Consider this scenario: You have a URL Group and 3 endpoints that are subscribed to
it. Now when you publish a message to the URL Group, internally we will create a
task for each subscribed endpoint and handle all retry mechanism isolated from
each other.

## How to create a URL Group

Please refer to the howto [here](/qstash/howto/url-group-endpoint).


# Debug Logs
Source: https://upstash.com/docs/qstash/howto/debug-logs



To debug the logs, first you need to understand the different states a message can
be in.

Only the last 10.000 logs are kept and older logs are removed automatically.

## Lifecycle of a Message

To understand the lifecycle of each message, we'll look at the following chart:

[comment]: # "https://mermaid.live/edit#pako:eNptU9uO2jAQ_RXLjxVXhyTED5UQpBUSZdtAK7VNtfLGTmIpsZHjrEoR_17HBgLdztPMmXPm4ssJZpIyiGGjiWYrTgpF6uErSgUw9vPdLzAcvgfLJF7s45UDL4FNbEnN6FLWB9lwzVz-EbO0xXK__hb_L43Bevv8OXn6mMS7nSPYSf6tcgIXc5zOkniffH9TvrM4SZ4Sm3GcXne-rLDYLuPNcxJ_-Rrvrrs4cGMiRxLS9K1YroHM3yowqFnTkIKBjIiMVYA3xqsqRp3azWQLu3EwaFUFFNOtEg3ICa9uU91xV_HGuIltcM9v2iwz_fpN-u0_LNYbyzdcdQQVr7k2PsnK6yx90Y5vLtXBF-ED1h_CA5wKOICF4hRirVo2gDVTNelCeOoYKdQlq1kKsXEpy0lb6RSm4mxkByJ-SFlflUq2RQlxTqrGRO2B9u_uhpJWy91RZFeNY8WUa6lupEoSykx4gvp46J5wwRtt-mVS5LzocHOABi61PjR4PO7So4Lrsn0ZZbIeN5yWROnyNQrGAQrmBHksCD3iex7NXqbRPEezaU7DyRQReD4PILP9P7n_Yr-N2YYJM8RStkJDHHqRXbfr_RviaDbyQg9NJz7yg9ksCAfwCHGARn6AfC9CKJqiiT83lf_Y85mM5uEsurfzX7VrENs"

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8794ba1b556ec2da5c84c5481e375d3d" data-og-width="1708" width="1708" data-og-height="1458" height="1458" data-path="img/qstash/debuglogs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a7cb1ab4658833c74c3991ebe5994d3b 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=01e2f4073c606f313c6dbe2fc6166f0f 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=65b8788cab4b77dd22115de91063e20a 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=15eee57803a433362aafad9b0b27b093 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=075a8e581dd28315103286f20c5a28cf 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/debuglogs.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3e63559550c097d6f961d769edabe453 2500w" />
</Frame>

Either you or a previously setup schedule will create a message.

When a message is ready for execution, it will be become `ACTIVE` and a delivery to
your API is attempted.

If you API responds with a status code between `200 - 299`, the task is
considered successful and will be marked as `DELIVERED`.

Otherwise the message is being retried if there are any retries left and moves to `RETRY`. If all retries are exhausted, the task has `FAILED` and the message will be moved to the DLQ.

During all this a message can be cancelled via [DELETE /v2/messages/:messageId](https://docs.upstash.com/qstash/api/messages/cancel). When the request is received, `CANCEL_REQUESTED` will be logged first.
If retries are not exhausted yet, in the next deliver time, the message will be marked as `CANCELLED` and will be completely removed from the system.

## Console

Head over to the [Upstash Console](https://console.upstash.com/qstash) and go to
the `Logs` tab, where you can see the latest status of your messages.


# Delete Schedules
Source: https://upstash.com/docs/qstash/howto/delete-schedule



Deleting schedules can be done using the [schedules api](/qstash/api/schedules/remove).

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XDELETE \
      -H 'Authorization: Bearer XXX' \
      'https://qstash.upstash.io/v2/schedules/<schedule_id>'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  await client.schedules.delete("<scheduleId>");
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.schedule.delete("<scheduleId>")
  ```
</CodeGroup>

Deleting a schedule does not stop existing messages from being delivered. It
only stops the schedule from creating new messages.

## Schedule ID

If you don't know the schedule ID, you can get a list of all of your schedules
from [here](/qstash/api/schedules/list).

<CodeGroup>
  ```shell cURL theme={"system"}
  curl \
      -H 'Authorization: Bearer XXX' \
      'https://qstash.upstash.io/v2/schedules'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const allSchedules = await client.schedules.list();
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.schedule.list()
  ```
</CodeGroup>


# Handling Failures
Source: https://upstash.com/docs/qstash/howto/handling-failures



Sometimes, endpoints fail due to various reasons such as network issues or server issues.
In such cases, QStash offers a few options to handle these failures.

## Failure Callbacks

When publishing a message, you can provide a failure callback that will be called if the message fails to be published.
You can read more about callbacks [here](/qstash/features/callbacks).

With the failure callback, you can add custom logic such as logging the failure or sending an alert to the team.
Once you handle the failure, you can [delete it from the dead letter queue](/qstash/api/dlq/deleteMessage).

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -X POST \
    https://qstash.upstash.io/v2/publish/<DESTINATION_URL> \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer <QSTASH_TOKEN>' \
    -H 'Upstash-Failure-Callback: <CALLBACK_URL>' \
    -d '{ "hello": "world" }'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://my-api...",
    body: { hello: "world" },
    failureCallback: "https://my-callback...",
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      failure_callback="https://my-callback...",
  )
  ```
</CodeGroup>

## Dead Letter Queue

If you don't want to handle the failure immediately, you can use the dead letter queue (DLQ) to store the failed messages.
You can read more about the dead letter queue [here](/qstash/features/dlq).

Failed messages are automatically moved to the dead letter queue upon failure, and can be retried from the console or
the API by [retrieving the message](/qstash/api/dlq/getMessage) then [publishing it](/qstash/api/publish).

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=19f34bc4484b4d6b8542e4d0a439409a" alt="DLQ from console" data-og-width="2064" width="2064" data-og-height="1302" height="1302" data-path="img/qstash/dlq-console.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b64d919c6f58b24416bf0c2abba5f197 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5049e7623f66b16e8517545a7c2780db 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5c6ae4279cd00f1c77e16449e01ed3e4 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=47fccebcd8c9f50452799d5857d20aac 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1dadf8ad6af4713f9e900a28d5cd5c45 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/dlq-console.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2ede823dab238e7043f605df32a9aa6f 2500w" />
</Frame>


# Local Development
Source: https://upstash.com/docs/qstash/howto/local-development



QStash requires a publicly available API to send messages to.
During development when applications are not yet deployed, developers typically need to expose their local API by creating a public tunnel.
While local tunneling works seamlessly, it requires code changes between development and production environments and increase friction for developers.
To simplify the development process, Upstash provides QStash CLI, which allows you to run a development server locally for testing and development.

<Check>The development server fully supports all QStash features including Schedules, URL Groups, Workflows, and Event Logs.</Check>

<Note>Since the development server operates entirely in-memory, all data is reset when the server restarts.</Note>

You can download and run the QStash CLI executable binary in several ways:

## NPX (Node Package Executable)

Install the binary via the `@upstash/qstash-cli` NPM package:

```javascript  theme={"system"}
npx @upstash/qstash-cli dev

// Start on a different port
npx @upstash/qstash-cli dev -port=8081
```

Once you start the local server, you can go to the QStash tab on Upstash Console and enable local mode, which will allow you to publish requests and monitor messages with the local server.

<img src="https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=20d1ab6f53a1b4b9c8f24a64af6a32d6" data-og-width="1210" width="1210" data-og-height="685" height="685" data-path="img/qstash/local-mode-qstash.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=280&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=1a0ef1c06088f89ee1fe510841972291 280w, https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=560&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=f89f092b33563c1fa6dc042e2345885f 560w, https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=840&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=8684c719b514bea30defa1691cfe7470 840w, https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=1100&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=a91cf6673fb6d2f605d3c8b8d846a970 1100w, https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=1650&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=6939a3d2fe01dc2dd65c64af8bd52d97 1650w, https://mintcdn.com/upstash/6b7_cWf_Wv8tb6kI/img/qstash/local-mode-qstash.png?w=2500&fit=max&auto=format&n=6b7_cWf_Wv8tb6kI&q=85&s=14ca23e0fd7512f4129006282380460b 2500w" />

## Docker

QStash CLI is available as a Docker image through our public AWS ECR repository:

```javascript  theme={"system"}
// Pull the image
docker pull public.ecr.aws/upstash/qstash:latest

// Run the image
docker run -p 8080:8080 public.ecr.aws/upstash/qstash:latest qstash dev
```

## Artifact Repository

You can download the binary directly from our artifact repository without using a package manager:

[https://artifacts.upstash.com/#qstash/versions/](https://artifacts.upstash.com/#qstash/versions/)

Select the appropriate version, architecture, and operating system for your platform.
After extracting the archive file, run the executable:

```
$ ./qstash dev
```

## QStash CLI

Currently, the only available command for QStash CLI is `dev`, which starts a development server instance.

```
$ ./qstash dev --help
Usage of dev:
  -port int
        The port to start HTTP server at [env QSTASH_DEV_PORT] (default 8080)
  -quota string
        The quota of users [env QSTASH_DEV_QUOTA] (default "payg")
```

There are predefined test users available. You can configure the quota type of users using the `-quota` option, with available options being `payg` and `pro`.
These quotas don't affect performance but allow you to simulate different server limits based on the subscription tier.

After starting the development server using any of the methods above, it will display the necessary environment variables.
Select and copy the credentials from one of the following test users:

<CodeGroup>
  ```javascript User 1 theme={"system"}
  QSTASH_URL="http://localhost:8080"
  QSTASH_TOKEN="eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0="
  QSTASH_CURRENT_SIGNING_KEY="sig_7kYjw48mhY7kAjqNGcy6cr29RJ6r"
  QSTASH_NEXT_SIGNING_KEY="sig_5ZB6DVzB1wjE8S6rZ7eenA8Pdnhs"
  ```

  ```javascript User 2 theme={"system"}
  QSTASH_URL="http://localhost:8080"
  QSTASH_TOKEN="eyJVc2VySUQiOiJ0ZXN0VXNlcjEiLCJQYXNzd29yZCI6InRlc3RQYXNzd29yZCJ9"
  QSTASH_CURRENT_SIGNING_KEY="sig_7GVPjvuwsfqF65iC8fSrs1dfYruM"
  QSTASH_NEXT_SIGNING_KEY="sig_5NoELc3EFnZn4DVS5bDs2Nk4b7Ua"
  ```

  ```javascript User 3 theme={"system"}
  QSTASH_URL="http://localhost:8080"
  QSTASH_TOKEN="eyJVc2VySUQiOiJ0ZXN0VXNlcjIiLCJQYXNzd29yZCI6InRlc3RQYXNzd29yZCJ9"
  QSTASH_CURRENT_SIGNING_KEY="sig_6jWGaWRxHsw4vMSPJprXadyvrybF"
  QSTASH_NEXT_SIGNING_KEY="sig_7qHbvhmahe5GwfePDiS5Lg3pi6Qx"
  ```

  ```javascript User 4 theme={"system"}
  QSTASH_URL="http://localhost:8080"
  QSTASH_TOKEN="eyJVc2VySUQiOiJ0ZXN0VXNlcjMiLCJQYXNzd29yZCI6InRlc3RQYXNzd29yZCJ9"
  QSTASH_CURRENT_SIGNING_KEY="sig_5T8FcSsynBjn9mMLBsXhpacRovJf"
  QSTASH_NEXT_SIGNING_KEY="sig_7GFR4YaDshFcqsxWRZpRB161jguD"
  ```
</CodeGroup>

<Info>Currently, there is no GUI client available for the development server. You can use QStash SDKs to fetch resources like event logs.</Info>

## License

The QStash development server is licensed under the [Development Server License](/qstash/misc/license), which restricts its use to development and testing purposes only.
It is not permitted to use it in production environments. Please refer to the full license text for details.


# Local Tunnel
Source: https://upstash.com/docs/qstash/howto/local-tunnel



QStash requires a publicly available API to send messages to.
The recommended approach is to run a [development server](/qstash/howto/local-development) locally and use it for development purposes.

Alternatively, you can set up a local tunnel to expose your API, enabling QStash to send requests directly to your application during development.

## localtunnel.me

[localtunnel.me](https://github.com/localtunnel/localtunnel) is a free service to provide
a public endpoint for your local development.

It's as simple as running

```
npx localtunnel --port 3000
```

replacing `3000` with the port your application is running on.

This will give you a public URL like `https://good-months-leave.loca.lt` which can be used
as your QStash URL.

If you run into issues, you may need to set the `Upstash-Forward-bypass-tunnel-reminder` header to
any value to bypass the reminder message.

## ngrok

[ngrok](https://ngrok.com) is a free service, that provides you with a public
endpoint and forwards all traffic to your localhost.

### Sign up

Create a new account on
[dashboard.ngrok.com/signup](https://dashboard.ngrok.com/signup) and follow the
[instructions](https://dashboard.ngrok.com/get-started/setup) to download the
ngrok CLI and connect your account:

```bash  theme={"system"}
ngrok config add-authtoken XXX
```

### Start the tunnel

Choose the port where your application is running. Here I'm forwarding to port
3000, because Next.js is using it.

```bash  theme={"system"}
$ ngrok http 3000



Session Status                online
Account                       Andreas Thomas (Plan: Free)
Version                       3.1.0
Region                        Europe (eu)
Latency                       -
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://e02f-2a02-810d-af40-5284-b139-58cc-89df-b740.eu.ngrok.io -> http://localhost:3000

Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00
```

### Publish a message

Now copy the `Forwarding` url and use it as destination in QStash. Make sure to
add the path of your API at the end. (`/api/webhooks` in this case)

```
curl -XPOST \
    -H 'Authorization: Bearer XXX' \
    -H "Content-type: application/json" \
    -d '{ "hello": "world" }' \
    'https://qstash.upstash.io/v2/publish/https://e02f-2a02-810d-af40-5284-b139-58cc-89df-b740.eu.ngrok.io/api/webhooks'
```

### Debug

In case messages are not delivered or something else doesn't work as expected,
you can go to [http://127.0.0.1:4040](http://127.0.0.1:4040) to see what ngrok
is doing.


# Publish Messages
Source: https://upstash.com/docs/qstash/howto/publishing



Publishing a message is as easy as sending a HTTP request to the `/publish`
endpoint. All you need is a valid url of your destination.

<Frame caption="Send a message via the Upstash Console">
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=34af4ca73af11c3a278154d311c1f272" width="688" data-og-width="1958" data-og-height="1156" data-path="img/qstash/publish.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=de442b024ca2787bbfdd2f9f8299fc26 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b4bf014f3904960271f623e3c1372467 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=484598462ab064a3dca9eefcde4b0764 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5cd3d343c2b7a2d927b3cea24ca14c02 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=54a6ebe407f902fb9920e8a524b63e65 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/publish.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e719ac302629a4a69d6014457dc66f87 2500w" />
</Frame>

<Info>
  Destination URLs must always include the protocol (`http://` or `https://`)
</Info>

## The message

The message you want to send is passed in the request body. Upstash does not
use, parse, or validate the body, so you can send any kind of data you want. We
suggest you add a `Content-Type` header to your request to make sure your
destination API knows what kind of data you are sending.

## Sending custom HTTP headers

In addition to sending the message itself, you can also forward HTTP headers.
Simply add them prefixed with `Upstash-Forward-` and we will include them in the
message.

#### Here's an example

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H 'Upstash-Forward-My-Header: my-value' \
      -H "Content-type: application/json" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://example.com'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    url: "https://example.com",
    body: { "hello": "world" },
    headers: { "my-header": "my-value" },
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url="https://my-api...",
      body={
          "hello": "world",
      },
      headers={
          "my-header": "my-value",
      },
  )
  ```
</CodeGroup>

In this case, we would deliver a `POST` request to `https://example.com` with
the following body and headers:

```json  theme={"system"}
// body
{ "hello": "world" }

// headers
My-Header:      my-value
Content-Type:   application/json
```

#### What happens after publishing?

When you publish a message, it will be durably stored in an
[Upstash Redis database](https://upstash.com/redis). Then we try to deliver the
message to your chosen destination API. If your API is down or does not respond
with a success status code (200-299), the message will be retried and delivered
when it comes back online. You do not need to worry about retrying messages or
ensuring that they are delivered.

By default, the multiple messages published to QStash are sent to your API in parallel.

## Publish to URL Group

URL Groups allow you to publish a single message to more than one API endpoints. To
learn more about URL Groups, check [URL Groups section](/qstash/features/url-groups).

Publishing to a URL Group is very similar to publishing to a single destination. All
you need to do is replace the `URL` in the `/publish` endpoint with the URL Group
name.

```
https://qstash.upstash.io/v2/publish/https://example.com
https://qstash.upstash.io/v2/publish/my-url-group
```

<CodeGroup>
  ```shell cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer XXX' \
      -H "Content-type: application/json" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/my-url-group'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const res = await client.publishJSON({
    urlGroup: "my-url-group",
    body: { "hello": "world" },
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.message.publish_json(
      url_group="my-url-group",
      body={
          "hello": "world",
      },
  )
  ```
</CodeGroup>

## Optional parameters and configuration

QStash supports a number of optional parameters and configuration that you can
use to customize the delivery of your message. All configuration is done using
HTTP headers.


# Receiving Messages
Source: https://upstash.com/docs/qstash/howto/receiving

What do we send to your API?

When you publish a message, QStash will deliver it to your chosen destination. This is a brief overview of how a request to your API looks like.

## Headers

We are forwarding all headers that have been prefixed with `Upstash-Forward-` to your API. [Learn more](/qstash/howto/publishing#sending-custom-http-headers)

In addition to your custom headers, we're sending these headers as well:

| Header                | Description                                                          |
| --------------------- | -------------------------------------------------------------------- |
| `User-Agent`          | Will be set to `Upstash-QStash`                                      |
| `Content-Type`        | The original `Content-Type` header                                   |
| `Upstash-Topic-Name`  | The URL Group (topic) name if sent to a URL Group                    |
| `Upstash-Signature`   | The signature you need to verify [See here](/qstash/howto/signature) |
| `Upstash-Retried`     | How often the message has been retried so far. Starts with 0.        |
| `Upstash-Message-Id`  | The message id of the message.                                       |
| `Upstash-Schedule-Id` | The schedule id of the message if it is related to a schedule.       |
| `Upstash-Caller-Ip`   | The IP address of the publisher of this message.                     |

## Body

The body is passed as is, we do not modify it at all. If you send a JSON body, you will receive a JSON body. If you send a string, you will receive a string.

## Verifying the signature

[See here](/qstash/howto/signature)


# Reset Token
Source: https://upstash.com/docs/qstash/howto/reset-token



Your token is used to interact with the QStash API. You need it to publish
messages as well as create, read, update or delete other resources, such as
URL Groups and endpoints.

Resetting your token will invalidate your current token and all future requests
with the old token will be rejected.

To reset your token, simply click on the "Reset token" button at the bottom in
the [QStash UI](https://console.upstash.com/qstash) and confirm the dialog.

<img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5be6bc283c3cf5f3d0927aebf8f6a76f" alt="" data-og-width="2008" width="2008" data-og-height="298" height="298" data-path="img/qstash/reset_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3b200b2b79f88f4345e1fb8286ec1382 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=7e5e92de759332c2bf299ca7d8b4bc12 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=73c2bd7214af2fee4cac20ebba39acb4 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9c4b0af95d3c71ea54b081bebaf89ff2 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2c8cd214567212e1b9bc74670cf20cd5 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reset_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e099b312a0f6775fa9e2aac6a3ca7810 2500w" />

Afterwards you should immediately update your token in all your applications.


# Roll Your Signing Keys
Source: https://upstash.com/docs/qstash/howto/roll-signing-keys



Because your API needs to be publicly accessible from the internet, you should
make sure to verify the authenticity of each request.

Upstash provides a JWT with each request. This JWT is signed by your individual
secret signing keys. [Read more](/qstash/howto/signature).

We are using 2 signing keys:

* current: This is the key used to sign the JWT.
* next: This key will be used to sign after you have rolled your keys.

If we were using only a single key, there would be some time between when you
rolled your keys and when you can edit the key in your applications. In order to
minimize downtime, we use 2 keys and you should always try to verify with both
keys.

## What happens when I roll my keys?

When you roll your keys, the current key will be replaced with the next key and
a new next key will be generated.

```
currentKey = nextKey
nextKey = generateNewKey()
```

<Warning>
  Rolling your keys twice without updating your applications will cause your apps
  to reject all requests, because both the current and next keys will have been
  replaced.
</Warning>

## How to roll your keys

Rolling your keys can be done by going to the
[QStash UI](https://console.upstash.com/qstash) and clicking on the "Roll keys"
button.

<img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d94642cddf6fbb5b61929a31c8efee31" alt="" data-og-width="2008" width="2008" data-og-height="298" height="298" data-path="img/qstash/roll_keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0754e3790b9dbcd40f9630bac6818fc5 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=eff2fb051bf97c992f5d8dcba4fd605e 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=116dd392bab3a652fb4b19417cc87e3b 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=65e6213926395514858b718cb13508bf 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=699c83e814b5f07d35e3364c97c1c9e4 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/roll_keys.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0c618e0b0c2d364d62fdacccd37b7cab 2500w" />


# Verify Signatures
Source: https://upstash.com/docs/qstash/howto/signature



We send a JWT with each request. This JWT is signed by your individual secret
signing key and sent in the `Upstash-Signature` HTTP header.

You can use this signature to verify the request is coming from QStash.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4f2a27e3244e694dce6b3c3f9b64f9d7" alt="" data-og-width="1178" width="1178" data-og-height="419" height="419" data-path="img/qstash/signing-key-logic.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=01630c1e0e7b17b0829d83390698fa66 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=bae37f3a791b85e8c21b57ad6ee99102 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=aaf8f0b21b736d320e546db3be730053 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=216221b2c4f005976ede5e6571bd0812 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=44720ddcf414f81ba22a68dc11f26f7a 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/signing-key-logic.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=1cdfc23987612a6ad3d648e509ed1e14 2500w" />

<Warning>
  You need to keep your signing keys in a secure location.
  Otherwise some malicious actor could use them to send requests to your API as if they were coming from QStash.
</Warning>

## Verifying

You can use the official QStash SDKs or implement a custom verifier either by using [an open source library](https://jwt.io/libraries) or by processing the JWT manually.

### Via SDK (Recommended)

QStash SDKs provide a `Receiver` type that simplifies signature verification.

<CodeGroup>
  ```typescript Typescript theme={"system"}
  import { Receiver } from "@upstash/qstash";

  const receiver = new Receiver({
    currentSigningKey: "YOUR_CURRENT_SIGNING_KEY",
    nextSigningKey: "YOUR_NEXT_SIGNING_KEY",
  });

  // ... in your request handler

  const signature = req.headers["Upstash-Signature"];
  const body = req.body;

  const isValid = await receiver.verify({
    body,
    signature,
    url: "YOUR-SITE-URL",
  });
  ```

  ```python Python theme={"system"}
  from qstash import Receiver

  receiver = Receiver(
      current_signing_key="YOUR_CURRENT_SIGNING_KEY",
      next_signing_key="YOUR_NEXT_SIGNING_KEY",
  )

  # ... in your request handler

  signature, body = req.headers["Upstash-Signature"], req.body

  receiver.verify(
      body=body,
      signature=signature,
      url="YOUR-SITE-URL",
  )
  ```

  ```go Golang theme={"system"}
  import "github.com/qstash/qstash-go"

  receiver := qstash.NewReceiver("<CURRENT_SIGNING_KEY>", "NEXT_SIGNING_KEY")

  // ... in your request handler

  signature := req.Header.Get("Upstash-Signature")
  body, err := io.ReadAll(req.Body)
  // handle err

  err := receiver.Verify(qstash.VerifyOptions{
      Signature: signature,
      Body:      string(body),
      Url:       "YOUR-SITE-URL", // optional
  })
  // handle err
  ```
</CodeGroup>

<Warning>Depending on the environment, the body might be parsed into an object by the HTTP handler if it is JSON.
Ensure you use the raw body string as is. For example, converting the parsed object back to a string (e.g., JSON.stringify(object)) may cause inconsistencies and result in verification failure.</Warning>

### Manual verification

If you don't want to use the SDKs, you can implement your own verifier either by using an open-source library or by manually processing the JWT.

The exact implementation depends on the language of your choice and the library if you use one.
Instead here are the steps you need to follow:

1. Split the JWT into its header, payload and signature
2. Verify the signature
3. Decode the payload and verify the claims
   * `iss`: The issuer must be`Upstash`.
   * `sub`: The subject must the url of your API.
   * `exp`: Verify the token has not expired yet.
   * `nbf`: Verify the token is already valid.
   * `body`: Hash the raw request body using `SHA-256` and compare it with the
     `body` claim.

You can also reference the implementation in our
[Typescript SDK](https://github.com/upstash/sdk-qstash-ts/blob/main/src/receiver.ts#L82).

After you have verified the signature and the claims, you can be sure the
request came from Upstash and process it accordingly.

## Claims

All claims in the JWT are listed [here](/qstash/features/security#claims)


# Create URL Groups and Endpoints
Source: https://upstash.com/docs/qstash/howto/url-group-endpoint



QStash allows you to group multiple APIs together into a single namespace,
called a `URL Group` (Previously, it was called `Topics`).
Read more about URL Groups [here](/qstash/features/url-groups).

There are two ways to create endpoints and URL Groups: The UI and the REST API.

## UI

Go to [console.upstash.com/qstash](https://console.upstash.com/qstash) and click
on the `URL Groups` tab. Afterwards you can create a new URL Group by giving it a name.
Keep in mind that URL Group names are restricted to alphanumeric, underscore, hyphen
and dot characters.

<img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=68c281bd86e518fce7f6018d6a38160b" alt="" data-og-width="1996" width="1996" data-og-height="864" height="864" data-path="img/qstash/create_topic.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=908f1973fd926d6172c75d854193a385 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=80665304d01412bbf0ed3bb7590912e5 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4b2ebbf61a9a38b45e55521568f53584 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3c02da12cb02666fe0c62a898432dc24 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=211dae323006945ee942903033f08cf7 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_topic.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fb00f65816c97514b4075de0484ed73c 2500w" />

After creating the URL Group, you can add endpoints to it:

<img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e40121a341fc89481d4a565d8a1b4914" alt="" data-og-width="2032" width="2032" data-og-height="744" height="744" data-path="img/qstash/create_endpoint.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1e1b84f2ea55ee98c305b249ffa49be1 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d5d2c9de6268c73dcfb24a3ac09b3516 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=69517e5abb5f8dc5f78a0710b642ddfe 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2bd9ce24b74e39b8cc72674c2d4e142e 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f0b5a0f10b451ed0e4ba4abc5bb0b630 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/create_endpoint.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fffde447eba91eedb319aa1f74c2b41b 2500w" />

## API

You can create a URL Group and endpoint using the [console](https://console.upstash.com/qstash) or [REST API](/qstash/api/url-groups/add-endpoint).

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -XPOST https://qstash.upstash.io/v2/topics/:urlGroupName/endpoints \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{
      "endpoints": [
        {
          "name": "endpoint1",
          "url": "https://example.com"
        },
        {
          "name": "endpoint2",
          "url": "https://somewhere-else.com"
        }
      ]
    }'
  ```

  ```typescript Typescript theme={"system"}
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: "<QSTASH_TOKEN>" });
  const urlGroups = client.urlGroups;
  await urlGroups.addEndpoints({
    name: "urlGroupName",
    endpoints: [
      { name: "endpoint1", url: "https://example.com" },
      { name: "endpoint2", url: "https://somewhere-else.com" },
    ],
  });
  ```

  ```python Python theme={"system"}
  from qstash import QStash

  client = QStash("<QSTASH_TOKEN>")
  client.url_group.upsert_endpoints(
      url_group="url-group-name",
      endpoints=[
          {"name": "endpoint1", "url": "https://example.com"},
          {"name": "endpoint2", "url": "https://somewhere-else.com"},
      ],
  )
  ```
</CodeGroup>


# Use as Webhook Receiver
Source: https://upstash.com/docs/qstash/howto/webhook



You can configure QStash to receive and process your webhook calls.

Instead of having the webhook service call your endpoint directly, QStash acts as an intermediary, receiving the request and forwarding it to your endpoint.
QStash provides additional control over webhook requests, allowing you to configure properties such as delay, retries, timeouts, callbacks, and flow control.

There are multiple ways to configure QStash to receive webhook requests.

## 1. Publish

You can configure your webhook URL as a QStash publish request.

For example, if your webhook endpoint is:

`https://example.com/api/webhook`

Instead of using this URL directly as the webhook address, use:

`https://qstash.upstash.io/v2/publish/https://example.com/api/webhook?qstash_token=<QSTASH_TOKEN>`

<Note>
  Request configurations such as custom retries, timeouts, and other settings can be specified using HTTP headers in the publish request.
  Refer to the [REST API documentation](/qstash/api/publish) for a full list of available configuration headers.

  It‚Äôs also possible to pass configuration via query parameters. You can use the lowercase format of headers as the key, such as ?upstash-retries=3\&upstash-delay=100s. This makes it easier to configure webhook messages.
</Note>

<Tip>
  By default, any headers in the publish request that are prefixed with `Upstash-Forward-` will be forwarded to your endpoint.

  However, since most webhook services do not allow header prefixing, we introduced a configuration option to enable forwarding all incoming request headers.

  To enable this, set `Upstash-Header-Forward: true` in the publish request or append the query parameter `?upstash-header-forward=true` to the request URL. This ensures that all headers are forwarded to your endpoint without requiring the `Upstash-Forward-` prefix.
</Tip>

## 2. URL Group

URL Groups allow you to define server-side templates for publishing messages. You can create a URL Group either through the UI or programmatically.

For example, if your webhook endpoint is:

`https://example.com/api/webhook`

Instead of using this URL directly, you can create a URL Group and add this URL as an endpoint.

`https://qstash.upstash.io/v2/publish/<URL_GROUP_NAME>?qstash_token=<QSTASH_TOKEN>`

You can define default headers for a URL Group, which will automatically apply to all requests sent to that group.

```
curl -X PATCH https://qstash.upstash.io/v2/topics/<URL_GROUP_NAME> \
    -H "Authorizarion: Bearer <QSTASH_TOKEN>"
    -d '{
        "headers": {
            "Upstash-Header-Forward": ["true"],
            "Upstash-Retries": "3"
        }
    }'
```

When you save this header for your URL Group, it ensures that all headers are forwarded as needed for your webhook processing.

A URL Group also enables you to define multiple endpoints within group.
When a publish request is made to a URL Group, all associated endpoints will be triggered, allowing you to fan-out a single webhook call to multiple destinations.


# LLM with Anthropic
Source: https://upstash.com/docs/qstash/integrations/anthropic



QStash integrates smoothly with Anthropic's API, allowing you to send LLM requests and leverage QStash features like retries, callbacks, and batching. This is especially useful when working in serverless environments where LLM response times vary and traditional timeouts may be limiting. QStash provides an HTTP timeout of up to 2 hours, which is ideal for most LLM cases.

### Example: Publishing and Enqueueing Requests

Specify the `api` as `llm` with the provider set to `anthropic()` when publishing requests. Use the `Upstash-Callback` header to handle responses asynchronously, as streaming completions aren‚Äôt supported for this integration.

#### Publishing a Request

```typescript  theme={"system"}
import { anthropic, Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.publishJSON({
  api: { name: "llm", provider: anthropic({ token: "<ANTHROPIC_TOKEN>" }) },
  body: {
    model: "claude-3-5-sonnet-20241022",
    messages: [{ role: "user", content: "Summarize recent tech trends." }],
  },
  callback: "https://example.com/callback",
});
```

### Enqueueing a Chat Completion Request

Use `enqueueJSON` with Anthropic as the provider to enqueue requests for asynchronous processing.

```typescript  theme={"system"}
import { anthropic, Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });

const result = await client.queue({ queueName: "your-queue-name" }).enqueueJSON({
  api: { name: "llm", provider: anthropic({ token: "<ANTHROPIC_TOKEN>" }) },
  body: {
    model: "claude-3-5-sonnet-20241022",
    messages: [
      {
        role: "user",
        content: "Generate ideas for a marketing campaign.",
      },
    ],
  },
  callback: "https://example.com/callback",
});

console.log(result);
```

### Sending Chat Completion Requests in Batches

Use `batchJSON` to send multiple requests at once. Each request in the batch specifies the same Anthropic provider and includes a callback URL.

```typescript  theme={"system"}
import { anthropic, Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });

const result = await client.batchJSON([
  {
    api: { name: "llm", provider: anthropic({ token: "<ANTHROPIC_TOKEN>" }) },
    body: {
      model: "claude-3-5-sonnet-20241022",
      messages: [
        {
          role: "user",
          content: "Describe the latest in AI research.",
        },
      ],
    },
    callback: "https://example.com/callback1",
  },
  {
    api: { name: "llm", provider: anthropic({ token: "<ANTHROPIC_TOKEN>" }) },
    body: {
      model: "claude-3-5-sonnet-20241022",
      messages: [
        {
          role: "user",
          content: "Outline the future of remote work.",
        },
      ],
    },
    callback: "https://example.com/callback2",
  },
  // Add more requests as needed
]);

console.log(result);
```

#### Analytics with Helicone

To monitor usage, include Helicone analytics by passing your Helicone API key under `analytics`:

```typescript  theme={"system"}
await client.publishJSON({
  api: {
    name: "llm",
    provider: anthropic({ token: "<ANTHROPIC_TOKEN>" }),
    analytics: { name: "helicone", token: process.env.HELICONE_API_KEY! },
  },
  body: { model: "claude-3-5-sonnet-20241022", messages: [{ role: "user", content: "Hello!" }] },
  callback: "https://example.com/callback",
});
```

With this setup, Anthropic can be used seamlessly in any LLM workflows in QStash.


# Datadog - Upstash QStash Integration
Source: https://upstash.com/docs/qstash/integrations/datadog



This guide walks you through connecting your Datadog account with Upstash QStash for monitoring and analytics of your message delivery, retries, DLQ, and schedules.

<Check>
  **Integration Scope**

  Upstash Datadog Integration covers Prod Pack.
</Check>

## **Step 1: Log in to Your Datadog Account**

1. Go to [Datadog](https://www.datadoghq.com/) and sign in.

## **Step 2: Install Upstash Application**

1. In Datadog, open the Integrations page.
2. Search for "Upstash" and open the integration.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1d4018e79c0fedb23a2c8d21bc3b6a43" alt="integration-tab.png" data-og-width="2880" width="2880" data-og-height="1028" height="1028" data-path="img/datadog/integration-tab.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e20319650673fc0c2ddb267c8c521d59 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5eceb4e5af82406788781e8098229cf3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1e0ba16abd0046c3e8a65815eaa3fc19 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5ade8ad371aaf59d811824c6310887a2 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80c8644a9d8d417d9138d13143afaba0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eda063436df126a626dd96a87f22a050 2500w" />

Click "Install" to add Upstash to your Datadog account.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=add4288783757921f62353223fbf39b5" alt="installation.png" data-og-width="2802" width="2802" data-og-height="1384" height="1384" data-path="img/datadog/installation.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=142c3fcc921b90a0abc94bbeb8a7bae3 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b7a6aae307da8f8b9757e84cff0db8d3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=413d45cfe27a64e38c4e422c97984c8e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=ba35ec57c2be78e999358a701e533812 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=52b29977b08a6500f380adea36c6881c 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=811d297b670fc274b74322f932c80475 2500w" />

## **Step 3: Connect Accounts**

After installing Upstash, click "Connect Accounts". Datadog will redirect you to Upstash to complete account linking.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=64d0abd76d3037f01a3811cd531c46d4" alt="connect-acc.png" data-og-width="1756" width="1756" data-og-height="936" height="936" data-path="img/datadog/connect-acc.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=085212af402a08e0f7e89ba644529d48 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f379315b18a9f213fa92aa119ca32f81 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3a7dadd01cdd15abded31929223a534e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6b2fa6785253ca09d38a1c24cc081e4e 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f6630bbfe1b49efa9f4b6fc4f4cc3a22 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80054d3b9fa019a5bf1c1ee60334b116 2500w" />

## **Step 4: Select Account to Integrate**

1. On Upstash, select the Datadog account to integrate.
2. Personal and team accounts are supported.

**Caveats**

* The integration can be established once at a time. To change the account scope (e.g., add/remove teams), re-establish the integration from scratch.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7d332ed4228eaba275329f458d1dbd2f" alt="personal.png" data-og-width="886" width="886" data-og-height="1026" height="1026" data-path="img/datadog/personal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f665cc6a4bbcf6d9d639c0b2b953fa0d 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a1f4954abf4877df690e05633d0e0142 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=be4a2b8f7e038b224d48dada4132866c 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b18d7807fa6df65216f98ed0d3526f5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4791a82eeec9a917746a8684751e99f0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d5cc8d1e39f3ab8058127a7bfc5a4f84 2500w" />

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=91af03309be7ba54f5c1e605052fe3cd" alt="team.png" data-og-width="950" width="950" data-og-height="1104" height="1104" data-path="img/datadog/team.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e0bcf3f87626d2f35dad5e349d8d530a 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e5a7d1921331a83c3b2b6d0485b418df 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=575a5ad465eaa4e5ff17a202f0dce775 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=67232bca77ab58e0be7a9ea6788caab9 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=71654ac0f72319d20778dacd0c9c2c3d 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6326dfc48f62069c3cb19a0f6b96a7ed 2500w" />

## **Step 5: Wait for Metrics Availability**

Once the integration is completed, metrics from QStash (publish counts, success/error rates, retries, DLQ, schedule executions) will start appearing in Datadog dashboards shortly.

<img src="https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=e4dbab20b620a015f5978e1ebce6ef18" alt="upstash-dashboard.png" data-og-width="2728" width="2728" data-og-height="1508" height="1508" data-path="img/datadog/upstash-qstash-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=280&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=2d5604424145437d8c65bf1f29961276 280w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=560&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=50b7cabece58a0ca711f1109a9ebee7a 560w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=840&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=60f1c33f2de64434705dc452a0f43c1e 840w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=1100&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=a69c642498a7621fcad8a236bd925534 1100w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=1650&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=a6e1d7ebfa95dc9f58e05c49eadb3868 1650w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=2500&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=d910a6cc1be7ac4d7a3f813694484808 2500w" />

## **Step 6: Datadog Integration Removal Process**

From Datadog ‚Üí Integrations ‚Üí Upstash, press "Remove" to break the connection.

### Confirm Removal

Upstash will stop publishing metrics after removal. Ensure any Datadog API keys/configurations for this integration are also removed on the Datadog side.

## **Conclusion**

You‚Äôve connected Datadog with Upstash QStash. Explore Datadog dashboards to monitor message delivery performance and reliability.

If you need help, contact support.


# LLM - OpenAI
Source: https://upstash.com/docs/qstash/integrations/llm



QStash has built-in support for calling LLM APIs. This allows you to take advantage of QStash features such as retries, callbacks, and batching while using LLM APIs.

QStash is especially useful for LLM processing because LLM response times are often highly variable. When accessing LLM APIs from serverless runtimes, invocation timeouts are a common issue. QStash offers an HTTP timeout of 2 hours, which is sufficient for most LLM use cases. By using callbacks and the workflows, you can easily manage the asynchronous nature of LLM APIs.

## QStash LLM API

You can publish (or enqueue) single LLM request or batch LLM requests using all existing QStash features natively. To do this, specify the destination `api` as `llm` with a valid provider. The body of the published or enqueued message should contain a valid chat completion request. For these integrations, you must specify the `Upstash-Callback` header so that you can process the response asynchronously. Note that streaming chat completions cannot be used with them. Use [the chat API](#chat-api) for streaming completions.

All the examples below can be used with **OpenAI-compatible LLM providers**.

### Publishing a Chat Completion Request

<CodeGroup>
  ```js JavaScript theme={"system"}
  import { Client, upstash } from "@upstash/qstash";

  const client = new Client({
      token: "<QSTASH_TOKEN>",
  });

  const result = await client.publishJSON({
      api: { name: "llm", provider: openai({ token: "_OPEN_AI_TOKEN_"}) },
      body: {
          model: "gpt-3.5-turbo",
          messages: [
              {
              role: "user",
              content: "Write a hello world program in Rust.",
              },
          ],
      },
      callback: "https://abc.requestcatcher.com/",
  });

  console.log(result);
  ```

  ```python Python theme={"system"}
  from qstash import QStash
  from qstash.chat import upstash

  q = QStash("<QSTASH_TOKEN>")

  result = q.message.publish_json(
      api={"name": "llm", "provider": openai("<OPENAI_API_KEY>")},
      body={
          "model": "gpt-3.5-turbo",
          "messages": [
              {
                  "role": "user",
                  "content": "Write a hello world program in Rust.",
              }
          ],
      },
      callback="https://abc.requestcatcher.com/",
  )

  print(result)
  ```
</CodeGroup>

### Enqueueing a Chat Completion Request

<CodeGroup>
  ```js JavaScript theme={"system"}
  import { Client, upstash } from "@upstash/qstash";

  const client = new Client({
      token: "<QSTASH_TOKEN>",
  });

  const result = await client.queue({ queueName: "queue-name" }).enqueueJSON({
      api: { name: "llm", provider: openai({ token: "_OPEN_AI_TOKEN_"}) },
      body: {
          "model": "gpt-3.5-turbo",
          messages: [
              {
                  role: "user",
                  content: "Write a hello world program in Rust.",
              },
          ],
      },
      callback: "https://abc.requestcatcher.com",
  });

  console.log(result);
  ```

  ```python Python theme={"system"}
  from qstash import QStash
  from qstash.chat import upstash

  q = QStash("<QSTASH_TOKEN>")

  result = q.message.enqueue_json(
      queue="queue-name",
      api={"name": "llm", "provider": openai("<OPENAI_API_KEY>")},
      body={
          "model": "gpt-3.5-turbo",
          "messages": [
              {
                  "role": "user",
                  "content": "Write a hello world program in Rust.",
              }
          ],
      },
      callback="https://abc.requestcatcher.com",
  )

  print(result)
  ```
</CodeGroup>

### Sending Chat Completion Requests in Batches

<CodeGroup>
  ```js JavaScript theme={"system"}
  import { Client, upstash } from "@upstash/qstash";

  const client = new Client({
      token: "<QSTASH_TOKEN>",
  });

  const result = await client.batchJSON([
      {
          api: { name: "llm", provider: openai({ token: "_OPEN_AI_TOKEN_" }) },
          body: { ... },
          callback: "https://abc.requestcatcher.com",
      },
      ...
  ]);

  console.log(result);
  ```

  ```python Python theme={"system"}
  from qstash import QStash
  from qstash.chat import upstash

  q = QStash("<QSTASH_TOKEN>")

  result = q.message.batch_json(
      [
          {
              "api":{"name": "llm", "provider": openai("<OPENAI_API_KEY>")},
              "body": {...},
              "callback": "https://abc.requestcatcher.com",
          },
          ...
      ]
  )

  print(result)
  ```

  ```shell curl theme={"system"}
  curl "https://qstash.upstash.io/v2/batch" \
      -X POST \
      -H "Authorization: Bearer QSTASH_TOKEN" \
      -H "Content-Type: application/json" \
      -d '[
          {
              "destination": "api/llm",
              "body": {...},
              "callback": "https://abc.requestcatcher.com"
          },
          ...
      ]'
  ```
</CodeGroup>

### Retrying After Rate Limit Resets

When the rate limits are exceeded, QStash automatically schedules the retry of
publish or enqueue of chat completion tasks depending on the reset time
of the rate limits. That helps with not doing retries prematurely
when it is definitely going to fail due to exceeding rate limits.

## Analytics via Helicone

Helicone is a powerful observability platform that provides valuable insights into your LLM usage. Integrating Helicone with QStash is straightforward.

To enable Helicone observability in QStash, you simply need to pass your Helicone API key when initializing your model. Here's how to do it for both custom models and OpenAI:

```ts  theme={"system"}
import { Client, custom } from "@upstash/qstash";

const client = new Client({
  token: "<QSTASH_TOKEN>",
});

await client.publishJSON({
  api: {
    name: "llm",
    provider: custom({
      token: "XXX",
      baseUrl: "https://api.together.xyz",
    }),
    analytics: { name: "helicone", token: process.env.HELICONE_API_KEY! },
  },
  body: {
    model: "meta-llama/Llama-3-8b-chat-hf",
    messages: [
      {
        role: "user",
        content: "hello",
      },
    ],
  },
  callback: "https://oz.requestcatcher.com/",
});
```


# n8n with QStash
Source: https://upstash.com/docs/qstash/integrations/n8n



Leverage your n8n workflow with Upstash Qstash, here is how you can make those requests using HTTP Request node.

### Step 1: Set Up an n8n Project

1. Go to [https://n8n.io](https://n8n.io) and create a new project
2. Create a Trigger as Webhook with default settings, this will be our entry point.
3. Create a HTTP Request Node
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=e505e6282963f1f865da419500a32ce4" data-og-width="1940" width="1940" data-og-height="1106" height="1106" data-path="img/n8n/qstash-http.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=bd445fb8cec48f72eb794b0712fcafa5 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=d9d1d136ca766c3f2772c6b18851e224 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=5a7c9dfa9b55fed8c31d76bee97e9e06 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=289f56dada160fdc5939851140b74ce8 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=e64bbe650b7779b08abb82109cbdb6f7 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-http.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=e21dd591f834cf97f45cac1e369c778e 2500w" />

***

### Step 2: Import QStash Configurations to HTTP Node

1. Go to Upstash Console and open QStash Request Builder Tab.
2. Fill out the fields to create an QStash Request. (Publish, Enqueue, Schedule)
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=e49f1750a82b10600a8099491ef7cec7" data-og-width="1940" width="1940" data-og-height="1186" height="1186" data-path="img/n8n/qstash-request-builder.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=b3ffd35a9947d10cce948319e2e5795a 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=70922c48cff83f3d3c5094196f12198d 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=36aad1fce07b0336ff6cab700bc4c64d 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=81a46ed684c1186e4581a3753ebd650b 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=7a4363ddf645e59cf4a61927dfc88b38 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-request-builder.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=e372fe4811da5d2eed732219cc879000 2500w" />
3. Copy the cURL snippet created for you, representing your request.
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=3d15b621d1485e7b0ef2b7b5523fdde0" data-og-width="1940" width="1940" data-og-height="1184" height="1184" data-path="img/n8n/qstash-curl.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=5d7df29d904d7d86015c34fd436a2a32 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=79e437282d780c9748c76e1d9e834d13 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=9fe55118cf0dd843a097ea488acc914c 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=5d84ca81093404bd4362383c3ade406f 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=b9d21d1be7832a781132fba7435f0f7e 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-curl.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=144c4d386dc689a66c02c168b032ca5d 2500w" />
4. Back to the n8n, in HTTP Request Parameters tab, use import cURL.
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=7474c42107e2f5f739d5927be43fa8f8" data-og-width="1940" width="1940" data-og-height="1182" height="1182" data-path="img/n8n/qstash-import-button.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=7f2e4845d8bbf4d84396dddeab086fa7 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=77ebaafbefb445130356bf896f1c98da 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=fd0b1a5c6fe97338381092560a65f095 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=23a8543465dd3b8b9c55a0006d595693 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=bfaf86dea0b13e0da303b8b6e52de702 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import-button.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=07aa93d7edb0d60a890cac6d2d87f2f6 2500w" />
5. Paste the cURL snippet that you copied in the console, and let n8n to fill out the form for you.
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=556482904e5bcdb5c2c5e58fdbf19793" data-og-width="1940" width="1940" data-og-height="1090" height="1090" data-path="img/n8n/qstash-import.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=777448123b26122d81aa4887212a177d 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=a93828b17ac4f7c5589a30a1ceca2ee2 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=09bcf959c21764bb9f98173f626bd122 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=1637926c6f2dea07245f779dc2060e31 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=bfa4575fd56aa6d095158c1bf186d196 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-import.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=8e32280b91885d59a7440daebf54d7a0 2500w" />

***

### Step 3: Test the Workflow

1. Execute workflow.
2. Visit the Webhook URL.
3. That's it! You can check the logs in the Qstash Console to confirm your QStash Request is working.
   <img src="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=76d88d4ec0176f8cbb124cc50fc7bd0d" data-og-width="1940" width="1940" data-og-height="1078" height="1078" data-path="img/n8n/qstash-logs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=280&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=1ad51a2f2d404487ab7595d07dc1a43d 280w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=560&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=15fde1375e8b3cb74d1ac6f21eed8aab 560w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=840&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=f4386d0b5377b119fb0990f1336171c3 840w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=1100&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=051df821a7614396a8fd8240527b7352 1100w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=1650&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=9a26ff0dd485abf61804a6a8b3b5eadb 1650w, https://mintcdn.com/upstash/6gcRj3LcBRmprTmw/img/n8n/qstash-logs.png?w=2500&fit=max&auto=format&n=6gcRj3LcBRmprTmw&q=85&s=6a261f05959055d1dbf0525c477ea08a 2500w" />


# Pipedream
Source: https://upstash.com/docs/qstash/integrations/pipedream

Build and run workflows with 1000s of open source triggers and actions across 900+ apps.

[Pipedream](https://pipedream.com) allows you to build and run workflows with
1000s of open source triggers and actions across 900+ apps.

Check out the [official integration](https://pipedream.com/apps/qstash).

## Trigger a Pipedream workflow from a QStash topic message

This is a step by step guide on how to trigger a Pipedream workflow from a
QStash topic message.

Alternatively [click here](https://pipedream.com/new?h=tch_3egfAX) to create a
new workflow with this QStash topic trigger added.

### 1. Create a Topic in QStash

If you haven't yet already, create a **Topic** in the
[QStash dashboard](https://console.upstash.com/qstash?tab=topics).

### 2. Create a new Pipedream workflow

Sign into [Pipedream](https://pipedream.com) and create a new workflow.

### 3. Add QStash Topic Message as a trigger

In the workflow **Trigger** search for QStash and select the **Create Topic
Endpoint** trigger.

![Select the QStash Create Topic Endpoint trigger](https://res.cloudinary.com/pipedreamin/image/upload/v1664298855/docs/components/CleanShot_2022-09-27_at_13.13.56_x6gzgk.gif)

Then, connect your QStash account by clicking the QStash prop and retrieving
your token from the
[QStash dashboard](https://console.upstash.com/qstash?tab=details).

After connecting your QStash account, click the **Topic** prop, a dropdown will
appear containing the QStash topics on your account.

Then *click* on a specific topic to listen for new messages on.

![Selecting a QStash topic to subscribe to](https://res.cloudinary.com/pipedreamin/image/upload/v1664299016/docs/components/CleanShot_2022-09-27_at_13.16.35_rewzbo.gif)

Finally, *click* **Continue**. Pipedream will create a unique HTTP endpoint and
add it to your QStash topic.

### 4. Test with a sample message

Use the *Request Builder* in the
[QStash dashboard](https://console.upstash.com/qstash?tab=details) to publish a
test message to your topic.

Alternatively, you can use the **Create topic message** action in a Pipedream
workflow to send a message to your topic.

*Don't forget* to use this action in a separate workflow, otherwise you might
cause an infinite loop of messages between QStash and Pipedream.

### 5. Add additional steps

Add additional steps to the workflow by clicking the plus icon beneath the
Trigger step.

Build a workflow with the 1,000+ pre-built components available in Pipedream,
including [Airtable](https://pipedream.com/apps/airtable),
[Google Sheets](https://pipedream.com/apps/google-sheets),
[Slack](https://pipedream.com/apps/slack) and many more.

Alternatively, use [Node.js](https://pipedream.com/docs/code/nodejs) or
[Python](https://pipedream.com/docs/code/python) code steps to retrieve,
transform, or send data to other services.

### 6. Deploy your Pipedream workflow

After you're satisfied with your changes, click the **Deploy** button in the
top right of your Pipedream workflow. Your deployed workflow will not
automatically process new messages to your QStash topic. Collapse
quickstart-trigger-pipedream-workflow-from-topic.md 3 KB

### Video tutorial

If you prefer video, you can check out this tutorial by
[pipedream](https://pipedream.com).

[![Video](https://img.youtube.com/vi/-oXlWuxNG5A/0.jpg)](https://www.youtube.com/watch?v=-oXlWuxNG5A)

## Trigger a Pipedream workflow from a QStash topic message

This is a step by step guide on how to trigger a Pipedream workflow from a
QStash endpoint message.

Alternatively [click here](https://pipedream.com/new?h=tch_m5ofX6) to create a
pre-configured workflow with the HTTP trigger and QStash webhook verification
step already added.

### 1. Create a new Pipedream workflow

Sign into [Pipedream](https://pipedream.com) and create a new workflow.

### 2. Configure the workflow with an HTTP trigger

In the workflow **Trigger** select the **New HTTP / Webhook Requests** option.

![Create new HTTP Webhook trigger](https://res.cloudinary.com/pipedreamin/image/upload/v1664296111/docs/components/CleanShot_2022-09-27_at_12.27.42_cqzolg.png)

Pipedream will create a unique HTTP endpoint for your workflow.

Then configure the HTTP trigger to *return a custom response*. By default
Pipedream will always return a 200 response, which allows us to return a non-200
response to QStash to retry the workflow again if there's an error during the
execution of the QStash message.

![Configure the webhook to return a custom response](https://res.cloudinary.com/pipedreamin/image/upload/v1664296210/docs/components/CleanShot_2022-09-27_at_12.29.45_jbwtcm.png)

Lastly, set the **Event Body** to be a **Raw request**. This will make sure the
QStash verify webhook action receives the data in the correct format.

![Set the event body to a raw body](https://res.cloudinary.com/pipedreamin/image/upload/v1664302540/docs/components/CleanShot_2022-09-27_at_14.15.15_o4xinz.png)

### 3. Test with a sample message

Use the *Request Builder* in the
[QStash dashboard](https://console.upstash.com/qstash?tab=details) to publish a
test message to your topic.

Alternatively, you can use the **Create topic message** action in a Pipedream
workflow to send a message to your topic.

*Don't forget* to use this action in a separate workflow, otherwise you might
cause an infinite loop of messages between QStash and Pipedream.

### 4. Verify the QStash webhook

Pipedream has a pre-built QStash action that will verify the content of incoming
webhooks from QStash.

First, search for **QStash** in the step search bar, then select the QStash app.

Of the available actions, select the **Verify Webhook** action.

Then connect your QStash account and select the **HTTP request** prop. In the
dropdown, click **Enter custom expression** and then paste in
`{{ steps.trigger.event }}`.

This step will automatically verify the incoming HTTP requests and exit the
workflow early if requests are not from QStash.

### 5. Add additional steps

Add additional steps to the workflow by clicking the plus icon beneath the
Trigger step.

Build a workflow with the 1,000+ pre-built components available in Pipedream,
including [Airtable](https://pipedream.com/apps/airtable),
[Google Sheets](https://pipedream.com/apps/google-sheets),
[Slack](https://pipedream.com/apps/slack) and many more.

Alternatively, use [Node.js](https://pipedream.com/docs/code/nodejs) or
[Python](https://pipedream.com/docs/code/python) code steps to retrieve,
transform, or send data to other services.

### 6. Return a 200 response

In the final step of your workflow, return a 200 response by adding a new step
and selecting **Return an HTTP Response**.

![Returning an HTTP response](https://res.cloudinary.com/pipedreamin/image/upload/v1664296812/docs/components/CleanShot_2022-09-27_at_12.39.25_apkngf.png)

This will generate Node.js code to return an HTTP response to QStash using the
`$.respond` helper in Pipedream.

### 7. Deploy your Pipedream workflow

After you're satisfied with your changes, click the **Deploy** button in the
top right of your Pipedream workflow. Your deployed workflow will not
automatically process new messages to your QStash topic.

### Video tutorial

If you prefer video, you can check out this tutorial by
[pipedream](https://pipedream.com).

[![Video](https://img.youtube.com/vi/uG8eO7BNok4/0.jpg)](https://youtu.be/uG8eO7BNok4)


# Prometheus - Upstash QStash Integration
Source: https://upstash.com/docs/qstash/integrations/prometheus



To monitor your QStash metrics in Prometheus and visualize in Grafana, follow these steps:

<Check>
  **Integration Scope**

  Upstash Prometheus Integration covers Prod Pack.
</Check>

## **Step 1: Enable Prometheus in Upstash Console**

1. Open the Upstash Console and navigate to QStash.
2. Go to Settings ‚Üí Monitoring.
3. Enable Prometheus to allow scraping QStash metrics.

<img src="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=09012029cd0b26d17391faadd590d250" alt="configuration.png" data-og-width="1956" width="1956" data-og-height="680" height="680" data-path="img/prometheus/configuration-qstash.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=280&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=9a8b41e736632ca22cdb6a9c1418be24 280w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=560&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=017a60eb3cd76ca2167b565acd8cffcd 560w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=840&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=465c0808c488881e9e7b75ab2630eca4 840w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=1100&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=ad55da6d698ba3afbe35a4e2f583bfb8 1100w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=1650&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=3ca73f05137987eeac02f6f8da3f2b8f 1650w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=2500&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=096f8dd337e73b3b37232fd14646eed8 2500w" />

## **Step 2: Copy Monitoring Token**

1. After enabling, a monitoring token is generated and displayed.
2. Copy the token. It will be used to authenticate Prometheus requests.

<Check>
  **Header Format**

  Send the token as `Authorization: Bearer <MONITORING_TOKEN>`.
</Check>

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2618f754b9209f28f30d27b16a652786" alt="monitoring-token.png" data-og-width="950" width="950" data-og-height="520" height="520" data-path="img/prometheus/monitoring-token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bd809c06e4421719c1195a3542a16cfb 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2721266c30939e15e371087ba8d8531 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=dbf58ef63addcf094f3cd2ea1e4ddd2b 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=65e3183a923ab6bfcb7c1e55cbce5a27 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0d9ad474b754c5a3ac37fff5155f22c0 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bb17a652adc3478d3b68704d29886aa4 2500w" />

## **Step 3: Configure Prometheus (via Grafana Data Source)**

1. In Grafana, add a Prometheus data source.
2. Set the address to `https://api.upstash.com/monitoring/prometheus`.
3. In HTTP headers, add the monitoring token.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3dce2b10059a2eb96d8d560bdabb7303" alt="datasource.png" data-og-width="1848" width="1848" data-og-height="464" height="464" data-path="img/prometheus/datasource.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=325217df537ca2f7269c4d38803b952f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9264339789011443e61167e443c0ae8a 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c1a7c769e5b857d21a733aec149233a8 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1e156eabf6c5c92c9ab2aa54d175667a 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eb464cb41c5bc5d8906f09c6a70f5c2b 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9a0c6ef2b3f5989c557a6b9d054dc0b7 2500w" />

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f32611d6c8cedb2b6a73d21e9b8a1cd5" alt="headers.png" data-og-width="1322" width="1322" data-og-height="346" height="346" data-path="img/prometheus/headers.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=613ce8cdff83bfadfbd95e40fac9548f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3edb89b53a21ffc79173c03e0c0bd7b 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d624ffcce430e3014319386a7de649d5 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4fb91d8f22449f95fc91704839fb1eb5 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6a5a66bed411dde641fbcf8a6111de7d 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1f60d9ffdf856ad140c8f470e1e9028e 2500w" />

Click <b>Test and Save</b>.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6e3f9cc214486c59085fe036a0dd6a28" alt="datasource-final.png" data-og-width="1560" width="1560" data-og-height="412" height="412" data-path="img/prometheus/datasource-final.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a97d2c20d4cae7002e57524de561937b 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e93e44229ab80a44a9115225b65c8742 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2d542697335e6b8e3ca346cd5371292d 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bde3d4b76f3d4f0f4712a307d1d90f12 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a15201c139e232a3ca6a6599e35a119a 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2950933a8fb225e5ddfc04143a36a111 2500w" />

## **Step 4: Import Dashboard**

You can use the Upstash Grafana dashboard to visualize QStash metrics.

Open the import dialog and use: <a href="https://grafana.com/grafana/dashboards/24206-upstash-qstash-dashboard/">Upstash QStash Dashboard</a>

<img src="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=e5deb2b23457a82d894690267e19fc7f" alt="grafana-dashboard.png" data-og-width="2978" width="2978" data-og-height="1250" height="1250" data-path="img/prometheus/grafana-qstash-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=280&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=8604c43b9ff9932d5546baf4ae13c91f 280w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=560&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d9655dfabe3b43851627c919ff25a307 560w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=840&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d9c01c7d9cb73274aa769c592f2e32c2 840w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=1100&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d6326a999c61be656b3f516de281d338 1100w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=1650&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=ff94bf6ba50c4bb30d3af1d4545c5459 1650w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=2500&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d0a6c38bf6890cc44aa95843ffc952d5 2500w" />

## **Conclusion**

You‚Äôve integrated QStash with Prometheus. Use Grafana to explore message throughput, retries, DLQ, schedules, and Upstash Workflows.

If you encounter issues, contact support.


# Email - Resend
Source: https://upstash.com/docs/qstash/integrations/resend



The `qstash-js` SDK offers an integration to easily send emails using [Resend](https://resend.com/), streamlining email delivery in your applications.

## Basic Email Sending

To send a single email, use the `publishJSON` method with the `resend` provider. Ensure your `QSTASH_TOKEN` and `RESEND_TOKEN` are set for authentication.

```typescript  theme={"system"}
import { Client, resend } from "@upstash/qstash";
const client = new Client({ token: "<QSTASH_TOKEN>" });

await client.publishJSON({
  api: {
    name: "email",
    provider: resend({ token: "<RESEND_TOKEN>" }),
  },
  body: {
    from: "Acme <onboarding@resend.dev>",
    to: ["delivered@resend.dev"],
    subject: "Hello World",
    html: "<p>It works!</p>",
  },
});
```

In the `body` field, specify any parameters supported by [the Resend Send Email API](https://resend.com/docs/api-reference/emails/send-email), such as `from`, `to`, `subject`, and `html`.

## Sending Batch Emails

To send multiple emails at once, use Resend‚Äôs [Batch Email API](https://resend.com/docs/api-reference/emails/send-batch-emails). Set the `batch` option to `true` to enable batch sending. Each email configuration is defined as an object within the `body` array.

```typescript  theme={"system"}
await client.publishJSON({
  api: {
    name: "email",
    provider: resend({ token: "<RESEND_TOKEN>", batch: true }),
  },
  body: [
    {
      from: "Acme <onboarding@resend.dev>",
      to: ["foo@gmail.com"],
      subject: "Hello World",
      html: "<h1>It works!</h1>",
    },
    {
      from: "Acme <onboarding@resend.dev>",
      to: ["bar@outlook.com"],
      subject: "World Hello",
      html: "<p>It works!</p>",
    },
  ],
});
```

Each entry in the `body` array represents an individual email, allowing customization of `from`, `to`, `subject`, `html`, and any other Resend-supported fields.


# Development Server License Agreement
Source: https://upstash.com/docs/qstash/misc/license



## 1. Purpose and Scope

This software is a development server implementation of QStash API ("Development Server") provided for testing and development purposes only. It is not intended for production use, commercial deployment, or as a replacement for the official QStash service.

## 2. Usage Restrictions

By using this Development Server, you agree to the following restrictions:

a) The Development Server may only be used for:

* Local development and testing
* Continuous Integration (CI) testing
* Educational purposes
* API integration development

b) The Development Server may NOT be used for:

* Production environments
* Commercial service offerings
* Public-facing applications
* Operating as a Software-as-a-Service (SaaS)
* Reselling or redistributing as a service

## 3. Restrictions on Modification and Reverse Engineering

You may not:

* Decompile, reverse engineer, disassemble, or attempt to derive the source code of the Development Server
* Modify, adapt, translate, or create derivative works based upon the Development Server
* Remove, obscure, or alter any proprietary rights notices within the Development Server
* Attempt to bypass or circumvent any technical limitations or security measures in the Development Server

## 4. Technical Limitations

Users acknowledge that the Development Server:

* Operates entirely in-memory without persistence
* Provides limited functionality compared to the official service
* Offers no data backup or recovery mechanisms
* Has no security guarantees
* May have performance limitations
* Does not implement all features of the official service

## 5. Warranty Disclaimer

THE DEVELOPMENT SERVER IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. THE AUTHORS OR COPYRIGHT HOLDERS SHALL NOT BE LIABLE FOR ANY CLAIMS, DAMAGES, OR OTHER LIABILITY ARISING FROM THE USE OF THE SOFTWARE IN VIOLATION OF THIS LICENSE.

## 6. Termination

Your rights under this license will terminate automatically if you fail to comply with any of its terms. Upon termination, you must cease all use of the Development Server.

## 7. Acknowledgment

By using the Development Server, you acknowledge that you have read this license, understand it, and agree to be bound by its terms.


# API Examples
Source: https://upstash.com/docs/qstash/overall/apiexamples



### Use QStash via:

* cURL
* [Typescript SDK](https://github.com/upstash/sdk-qstash-ts)
* [Python SDK](https://github.com/upstash/qstash-python)

Below are some examples to get you started. You can also check the [how to](/qstash/howto/publishing) section for
more technical details or the [API reference](/qstash/api/messages) to test the API.

### Publish a message to an endpoint

Simple example to [publish](/qstash/howto/publishing) a message to an endpoint.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Publish a message to a URL Group

The [URL Group](/qstash/features/url-groups) is a way to publish a message to multiple endpoints in a
fan out pattern.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/myUrlGroup'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      urlGroup: "myUrlGroup",
      body: {
        hello: "world",
      },
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url_group="my-url-group",
        body={
            "hello": "world",
        },
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Publish a message with 5 minutes delay

Add a delay to the message to be published. After QStash receives the message,
it will wait for the specified time (5 minutes in this example) before sending the message to the endpoint.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Content-type: application/json" \
        -H "Upstash-Delay: 5m" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
      delay: 300,
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
        delay="5m",
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Send a custom header

Add a custom header to the message to be published.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H 'Upstash-Forward-My-Header: my-value' \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
      headers: {
        "My-Header": "my-value",
      },
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
        headers={
            "My-Header": "my-value",
        },
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Schedule to run once a day

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Upstash-Cron: 0 0 * * *" \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/schedules/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.schedules.create({
      destination: "https://example.com",
      cron: "0 0 * * *",
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.schedule.create(
        destination="https://example.com",
        cron="0 0 * * *",
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Publish messages to a FIFO queue

By default, messges are published concurrently. With a [queue](/qstash/features/queues), you can enqueue messages in FIFO order.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST -H 'Authorization: Bearer XXX' \
                -H "Content-type: application/json" \
                'https://qstash.upstash.io/v2/enqueue/my-queue/https://example.com' 
                -d '{"message":"Hello, World!"}'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });

    const queue = client.queue({
      queueName: "my-queue"
    })

    await queue.enqueueJSON({
      url: "https://example.com",
      body: {
        "Hello": "World"
      }
    })
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.enqueue_json(
        queue="my-queue",
        url="https://example.com",
        body={
            "Hello": "World",
        },
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Publish messages in a [batch](/qstash/features/batch)

Publish multiple messages in a single request.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST https://qstash.upstash.io/v2/batch \
        -H 'Authorization: Bearer XXX' \
        -H "Content-type: application/json" \
        -d '
         [
          {
            "destination": "https://example.com/destination1"
          },
          {
            "destination": "https://example.com/destination2"
          }
         ]'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    import { Client } from "@upstash/qstash";

    const client = new Client({ token: "<QSTASH_TOKEN>" });
    const res = await client.batchJSON([
      {
        url: "https://example.com/destination1",
      },
      {
        url: "https://example.com/destination2",
      },
    ]);
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.batch_json(
        [
            {
                "url": "https://example.com/destination1",
            },
            {
                "url": "https://example.com/destination2",
            },
        ]
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Set max retry count to 3

Configure how many times QStash should retry to send the message to the endpoint before
sending it to the [dead letter queue](/qstash/features/dlq).

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Upstash-Retries: 3" \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
      retries: 3,
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
        retries=3,
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Set custom retry delay

Configure the delay between retry attempts when message delivery fails. [By default, QStash uses exponential backoff](/qstash/features/retry). You can customize this using mathematical expressions with the special variable `retried` (current retry attempt count starting from 0).

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Upstash-Retries: 3" \
        -H "Upstash-Retry-Delay: pow(2, retried) * 1000" \
        -H "Content-type: application/json" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
      retries: 3,
      retryDelay: "pow(2, retried) * 1000", // 2^retried * 1000ms
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
        retries=3,
        retry_delay="pow(2, retried) * 1000",  # 2^retried * 1000ms
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

**Supported functions for retry delay expressions:**

* `pow` - Power function
* `sqrt` - Square root
* `abs` - Absolute value
* `exp` - Exponential
* `floor` - Floor function
* `ceil` - Ceiling function
* `round` - Rounding function
* `min` - Minimum of values
* `max` - Maximum of values

**Examples:**

* `1000` - Fixed 1 second delay
* `1000 * (1 + retried)` - Linear backoff: 1s, 2s, 3s, 4s...
* `pow(2, retried) * 1000` - Exponential backoff: 1s, 2s, 4s, 8s...
* `max(1000, pow(2, retried) * 100)` - Exponential with minimum 1s delay

### Set callback url

Receive a response from the endpoint and send it to the specified callback URL.
If the endpoint does not return a response, QStash will send it to the failure callback URL.

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl -XPOST \
        -H 'Authorization: Bearer XXX' \
        -H "Content-type: application/json" \
        -H "Upstash-Callback: https://example.com/callback" \
        -H "Upstash-Failure-Callback: https://example.com/failure" \
        -d '{ "hello": "world" }' \
        'https://qstash.upstash.io/v2/publish/https://example.com'
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    await client.publishJSON({
      url: "https://example.com",
      body: {
        hello: "world",
      },
      callback: "https://example.com/callback",
      failureCallback: "https://example.com/failure",
    });
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.message.publish_json(
        url="https://example.com",
        body={
            "hello": "world",
        },
        callback="https://example.com/callback",
        failure_callback="https://example.com/failure",
    )
    # Async version is also available
    ```
  </Tab>
</Tabs>

### Get message logs

Retrieve logs for all messages that have been published (filtering is also available).

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl https://qstash.upstash.io/v2/logs \
        -H "Authorization: Bearer XXX"
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    const logs = await client.logs()
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.event.list()
    # Async version is also available
    ```
  </Tab>
</Tabs>

### List all schedules

<Tabs>
  <Tab title="cURL">
    ```shell  theme={"system"}
    curl https://qstash.upstash.io/v2/schedules \
        -H "Authorization: Bearer XXX"
    ```
  </Tab>

  <Tab title="Typescript SDK">
    ```typescript  theme={"system"}
    const client = new Client({ token: "<QSTASH_TOKEN>" });
    const scheds = await client.schedules.list();
    ```
  </Tab>

  <Tab title="Python SDK">
    ```python  theme={"system"}
    from qstash import QStash

    client = QStash("<QSTASH_TOKEN>")
    client.schedule.list()
    # Async version is also available
    ```
  </Tab>
</Tabs>


# Changelog
Source: https://upstash.com/docs/qstash/overall/changelog



<Note>
  We have moved the roadmap and the changelog to [Github Discussions](https://github.com/orgs/upstash/discussions) starting from October 2025.Now you can follow `In Progress` features. You can see that your `Feature Requests` are recorded. You can vote for them and comment your specific use-cases to shape the feature to your needs.
</Note>

<Update label="September 2025">
  * **TypeScript SDK (`qstash-js`):**
    * `Label` feature is added. This will enable our users to label their publishes so that
      * Logs can be filtered with user given label.
      * DLQ can be filtered with user given label.
  * **Console:**
    * `Flat view` on the `Logs` tab is removed. The purpose is to simplify the `Logs` tab.
      All the information is already available on the default(grouped) view. Let us know if there is something missing
      via Discord/Support so that we can fill in the gaps.
</Update>

<Update label="August 2025">
  * **Console:**
    * Added ability to hide/show columns on the Schedules tab.
    * Local mode is added to enable our users to use the console with their local development envrionment. See [docs](http://localhost:3000/qstash/howto/local-development) for details.
</Update>

<Update label="July 2025">
  * **TypeScript SDK (`qstash-js`):**
    * Added `retryDelay` option to dynamicaly program the retry duration of a failed message.
      The new parameter is available in publish/batch/enqueue/schedules. See [here](/qstash/features/retry#custom-retry-delay)
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/qstash-js/compare/v2.8.1...v2.8.2).
</Update>

<Update label="June 2025">
  * No new features for QStash this month. We are mostly focused on stability and performance.
</Update>

<Update label="May 2025">
  * **TypeScript SDK (`qstash-js`):**
    * Added `flow control period` and deprecated `ratePerSecond`. See [here](https://github.com/upstash/qstash-js/pull/237).
    * Added `IN_PROGRESS` state filter. See [here](https://github.com/upstash/qstash-js/pull/236).
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/qstash-js/compare/v2.7.23...v2.8.1).
  * **Python SDK (`qstash-py`):**
    * Added `IN_PROGRESS` state filter. See [here](https://github.com/upstash/qstash-js/pull/236).
    * Added various missing features: Callback Headers, Schedule with Queue, Overwrite Schedule ID, Flow Control Period. See [here](https://github.com/upstash/qstash-py/pull/41).
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/qstash-py/compare/v2.0.5...v3.0.0).
  * **Console:**
    * Improved logs tab behavior to prevent collapsing or unnecessary refreshes, increasing usability.
  * **QStash Server:**
    * Added support for filtering messages by `FlowControlKey` (Console and SDK support in progress).
    * Applied performance improvements for bulk cancel operations.
    * Applied performance improvements for bulk publish operations.
    * Fixed an issue where scheduled publishes with queues would reset queue parallelism to 1.
    * Added support for updating existing queue parallelisms even when the max queue limit is reached.
    * Applied several additional performance optimizations.
</Update>

<Update label="April 2025">
  * **QStash Server:**
    * Added support for `flow-control period`, allowing users to define a period for a given rate‚Äîup to 1 week.\
      Previously, the period was fixed at 1 second.\
      For example, `rate: 3 period: 1d` means publishes will be throttled to 3 per day.
    * Applied several performance optimizations.
  * **Console:**
    * Added `IN_PROGRESS` as a filter option when grouping by message ID, making it easier to query in-flight messages.\
      See [here](/qstash/howto/debug-logs#lifecycle-of-a-message) for an explanation of message states.
</Update>

<Update label="March 2025">
  * **TypeScript SDK (`qstash-js`):**
    * Renamed `events` to `logs` for clarity when referring to QStash features. `client.events()` is now deprecated, and `client.logs()` has been introduced. See [details here](https://github.com/upstash/qstash-js/pull/225).
    * For all fixes, see the full changelog [here](https://github.com/upstash/qstash-js/compare/v2.7.22...v2.7.23).
  * **QStash Server:**
    * Fixed an issue where messages with delayed callbacks were silently failing. Now, such messages are explicitly rejected during insertion.
</Update>

<Update label="February 2025">
  * **Python SDK (`qstash-py`):**
    * Flow Control Parallelism and Rate. See [here](https://github.com/upstash/qstash-py/pull/36)
    * Addressed a few minor bugs. See the full changelog [here](https://github.com/upstash/qstash-py/compare/v2.0.3...v2.0.5)
  * **QStash Server:**
    * Introduced RateLimit and Parallelism controls to manage the rate and concurrency of message processing. Learn more [here](/qstash/features/flowcontrol).
    * Improved connection timeout detection mechanism to enhance scalability.
    * Added several new features to better support webhook use cases:
      * Support for saving headers in a URL group. See [here](/qstash/howto/webhook#2-url-group).
      * Ability to pass configuration parameters via query strings instead of headers. See [here](/qstash/howto/webhook#1-publish).
      * Introduced a new `Upstash-Header-Forward` header to forward all headers from the incoming request. See [here](/qstash/howto/webhook#1-publish).
</Update>

<Update label="January 2025">
  * **Python SDK (`qstash-py`):**
    * Addressed a few minor bugs. See the full changelog [here](https://github.com/upstash/qstash-py/compare/v2.0.2...v2.0.3).
  * **Local Development Server:**
    * The local development server is now publicly available. This server allows you to test your Qstash setup locally. Learn more about the local development server [here](/qstash/howto/local-development).
  * **Console:**
    * Separated the Workflow and QStash consoles for an improved user experience.
    * Separated their DLQ messages as well.
  * **QStash Server:**
    * The core team focused on RateLimit and Parallelism features. These features are ready on the server and will be announced next month after the documentation and SDKs are completed.
</Update>

<Update label="December 2024">
  * **TypeScript SDK (`qstash-js`):**
    * Added global headers to the client, which are automatically included in every publish request.
    * Resolved issues related to the Anthropics and Resend integrations.
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/qstash-js/compare/v2.7.17...v2.7.20).

  * **Python SDK (`qstash-py`):**
    * Introduced support for custom `schedule_id` values.
    * Enabled passing headers to callbacks using the `Upstash-Callback-Forward-...` prefix.
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/qstash-py/compare/v2.0.0...v2.0.1).

  * **Qstash Server:**
    * Finalized the local development server, now almost ready for public release.
    * Improved error reporting by including the field name in cases of invalid input.
    * Increased the maximum response body size for batch use cases to 100 MB per REST call.
    * Extended event retention to up to 14 days, instead of limiting to the most recent 10,000 events. Learn more on the [Pricing page](https://upstash.com/pricing/qstash).
</Update>

<Update label="November 2024">
  * **TypeScript SDK (qstash-js):**
    * Added support for the Anthropics provider and refactored the `api` field of `publishJSON`. See the documentation [here](/qstash/integrations/anthropic).
    * Full changelog, including fixes, is available [here](https://github.com/upstash/qstash-js/compare/v2.7.14...v2.7.17).
  * **Qstash Server:**
    * Fixed a bug in schedule reporting. The Upstash-Caller-IP header now correctly reports the user‚Äôs IP address instead of an internal IP for schedules.
    * Validated the scheduleId parameter. The scheduleId must now be alphanumeric or include hyphens, underscores, or periods.
    * Added filtering support to bulk message cancellation. Users can now delete messages matching specific filters. See Rest API [here](/qstash/api/messages/bulk-cancel).
    * Resolved a bug that caused the DLQ Console to become unusable when data was too large.
    * Fixed an issue with queues that caused them to stop during temporary network communication problems with the storage layer.
</Update>

<Update label="October 2024">
  * **TypeScript SDK (qstash-js):**
    * Fixed a bug on qstash-js where we skipped using the next signing key when the current signing key fails to verify the `upstash-signature`. Released with qstash-js v2.7.14.
    * Added resend API. See [here](/qstash/integrations/resend). Released with qstash-js v2.7.14.
    * Added `schedule to queues` feature to the qstash-js. See [here](/qstash/features/schedules#scheduling-to-a-queue). Released with qstash-js v2.7.14.
  * **Console:**
    * Optimized the console by trimming event bodies, reducing resource usage and enabling efficient querying of events with large payloads.
  * **Qstash Server:**
    * Began development on a new architecture to deliver faster event processing on the server.
    * Added more fields to events in the [REST API](/qstash/api/events/list), including `Timeout`, `Method`, `Callback`, `CallbackHeaders`, `FailureCallback`, `FailureCallbackHeaders`, and `MaxRetries`.
    * Enhanced retry backoff logic by supporting additional headers for retry timing. Along with `Retry-After`, Qstash now recognizes `X-RateLimit-Reset`, `X-RateLimit-Reset-Requests`, and `X-RateLimit-Reset-Tokens` as backoff time indicators. See [here](/qstash/features/retry#retry-after-headers) for more details.
</Update>

<Update label="September 2024">
  * Improved performance, resulting in reduced latency for average publish times.
  * Set the `nbf` (not before) claim on Signing Keys to 0. This claim specifies the time before which the JWT must not be processed. Previously, this was incorrectly used, causing validation issues when there were minor clock discrepancies between systems.
  * Fixed queue name validation. Queue names must now be alphanumeric or include hyphens, underscores, or periods, consistent with other API resources.
  * Resolved bugs related to [overwriting a schedule](/qstash/features/schedules#overwriting-an-existing-schedule).
</Update>

<Update label="August 2024">
  * Released [Upstash Workflow](/qstash/workflow).
  * Fixed a bug where paused schedules were mistakenly resumed after a process restart (typically occurring during new version releases).
</Update>

<Update label="July 2024">
  * Big update on the UI, where all the Rest functinality exposed in the Console.
  * Addded order query parameter to [/v2/events](/qstash/api/events/list) and [/v2/dlq](/qstash/api/dlq/listMessages) endpoints.
  * Added [ability to configure](/qstash/features/callbacks#configuring-callbacks) callbacks(/failure\_callbacks)
  * A critical fix for schedule pause and resume Rest APIs where the endpoints were not working at all before the fix.
</Update>

<Update label="June 2024">
  * Pause and resume for scheduled messages
  * Pause and resume for queues
  * [Bulk cancel](/qstash/api/messages/bulk-cancel) messages
  * Body and headers on [events](/qstash/api/events/list)
  * Fixed inaccurate queue lag
</Update>

<Update label="May 2024">
  * [Retry-After](/qstash/features/retry#retry-after-header) support for rate-limited endpoints
  * [Upstash-Timeout](/qstash/api/publish) header
</Update>

<Update label="April 2024">
  * [Queues and parallelism](/qstash/features/queues)
  * [Event filtering](/qstash/api/events/list)
</Update>

<Update label="March 2024">
  * [Batch publish messages](/qstash/api/messages/batch)
  * [Bulk delete](/qstash/api/dlq/deleteMessages) for DLQ
</Update>

<Update label="February 2024">
  * Added [failure callback support](/qstash/api/schedules/create) to scheduled messages
  * Added Upstash-Caller-IP header to outgoing messages. See \[[https://upstash.com/docs/qstash/howto/receiving](https://upstash.com/docs/qstash/howto/receiving)] for all headers
  * Added Schedule ID to [events](/qstash/api/events/list) and [messages](/qstash/api/messages/get)
</Update>

<Update label="November 2023">
  * Put last response in DLQ
  * DLQ [get message](/qstash/api/dlq/getMessage)
  * Pass schedule ID to the header when calling the user's endpoint
  * Added more information to [callbacks](/qstash/features/callbacks)
</Update>

<Update label="October 2023">
  * Added [Upstash-Failure-Callback](/qstash/features/callbacks#what-is-a-failure-callback)
</Update>


# Compare
Source: https://upstash.com/docs/qstash/overall/compare



In this section, we will compare QStash with alternative solutions.

### BullMQ

BullMQ is a message queue for NodeJS based on Redis. BullMQ is open source
project, you can run BullMQ yourself.

* Using BullMQ in serverless environments is problematic due to stateless nature
  of serverless. QStash is designed for serverless environments.

* With BullMQ, you need to run a stateful application to consume messages.
  QStash calls the API endpoints, so you do not need your application to consume
  messages continuously.

* You need to run and maintain BullMQ and Redis yourself. QStash is completely
  serverless, you maintain nothing and pay for just what you use.

### Zeplo

Zeplo is a message queue targeting serverless. Just like QStash it allows users
to queue and schedule HTTP requests.

While Zeplo targets serverless, it has a fixed monthly price in paid plans which
is \$39/month. In QStash, price scales to zero, you do not pay if you are not
using it.

With Zeplo, you can send messages to a single endpoint. With QStash, in addition
to endpoint, you can submit messages to a URL Group which groups one or more
endpoints into a single namespace. Zeplo does not have URL Group functionality.

### Quirrel

Quirrel is a job queueing service for serverless. It has a similar functionality
with QStash.

Quirrel is acquired by Netlify, some of its functionality is available as
Netlify scheduled functions. QStash is platform independent, you can use it
anywhere.


# Getting Started
Source: https://upstash.com/docs/qstash/overall/getstarted



QStash is a **serverless messaging and scheduling solution**. It fits easily into your existing workflow and allows you to build reliable systems without managing infrastructure.

Instead of calling an endpoint directly, QStash acts as a middleman between you and an API to guarantee delivery, perform automatic retries on failure, and more.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a49cf2890891033348a5493f7c299762" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash/qstash-benefits.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4d44a587b83b5b388afa187f97eb7fa3 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e81daccf4cbbc98af3ce1a941dfeea32 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8bb628a3e84bdd997685a3e33d49db16 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5924aa1542968662d0300c025baff453 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4a6eb0397de0769fab6c4fbff8e2be50 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/qstash-benefits.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3060b417eb7928821a5a4149bdc3ee7 2500w" />
</Frame>

<Tip href="/workflow/getstarted">
  We have a new SDK called [Upstash Workflow](/workflow/getstarted).

  **Upstash Workflow SDK** is **QStash** simplified for your complex applications

  * Skip the details of preparing a complex dependent endpoints.
  * Focus on the essential parts.
  * Enjoy automatic retries and delivery guarantees.
  * Avoid platform-specific timeouts.

  Check out [Upstash Workflow Getting Started](/workflow/getstarted) for more.
</Tip>

## Quick Start

Check out these Quick Start guides to get started with QStash in your application.

<CardGroup cols={2}>
  <Card title="Next.js" icon="node-js" href="/qstash/quickstarts/vercel-nextjs">
    Build a Next application that uses QStash to start a long-running job on your platform
  </Card>

  <Card title="Python" icon="python" href="/qstash/quickstarts/python-vercel">
    Build a Python application that uses QStash to schedule a daily job that clean up a database
  </Card>
</CardGroup>

Or continue reading to learn how to send your first message!

## Send your first message

<Check>
  **Prerequisite**

  You need an Upstash account before publishing messages, create one
  [here](https://console.upstash.com).
</Check>

### Public API

Make sure you have a publicly available HTTP API that you want to send your
messages to. If you don't, you can use something like
[requestcatcher.com](https://requestcatcher.com/), [webhook.site](https://webhook.site/) or
[webhook-test.com](https://webhook-test.com/) to try it out.

For example, you can use this URL to test your messages: [https://firstqstashmessage.requestcatcher.com](https://firstqstashmessage.requestcatcher.com)

### Get your token

Go to the [Upstash Console](https://console.upstash.com/qstash) and copy the
`QSTASH_TOKEN`.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b0bda5d8c30d60c36bcaaf49accce9b1" data-og-width="1090" width="1090" data-og-height="402" height="402" data-path="img/qstash/rest_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ad32156275de5c4b5c17f8351d03dfd7 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2b05f661b26af08e75cb7bd29b94530a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c7b6ff4e398e7adff1f6901c991f4c92 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c8b639fac03f93107b378b3699c55803 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=18008b9741588917fd62e0efe903be95 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/rest_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=245f6b9806e7b523b8a4a2ace3dad5c2 2500w" />
</Frame>

### Publish a message

A message can be any shape or form: json, xml, binary, anything, that can be
transmitted in the http request body. We do not impose any restrictions other
than a size limit of 1 MB (which can be customized at your request).

In addition to the request body itself, you can also send HTTP headers. Learn
more about this in the [message publishing section](/qstash/howto/publishing).

<CodeGroup>
  ```bash cURL theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer <QSTASH_TOKEN>' \
      -H "Content-type: application/json" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://<your-api-url>'
  ```

  ```bash cURL RequestCatcher theme={"system"}
  curl -XPOST \
      -H 'Authorization: Bearer <QSTASH_TOKEN>' \
      -H "Content-type: application/json" \
      -d '{ "hello": "world" }' \
      'https://qstash.upstash.io/v2/publish/https://firstqstashmessage.requestcatcher.com/test'
  ```
</CodeGroup>

Don't worry, we have SDKs for different languages so you don't
have to make these requests manually.

### Check Response

You should receive a response with a unique message ID.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f68c3043856bf77c5e55786a54d57cd7" data-og-width="1456" width="1456" data-og-height="580" height="580" data-path="img/qstash/reqcatcher.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=84c76a371ea1a6af224a61c7897176e4 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=337d1aa2277b60b314a69122ba24bfa0 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f8d5a20e4e1a735bb579791f474d891b 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2fcbc86f518555b08b306ff0d4c64045 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f5f8791bc3df089e26bac1e742505b9c 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=26a972e97932d8f03f8183da39996063 2500w" />
</Frame>

### Check Message Status

Head over to [Upstash Console](https://console.upstash.com/qstash) and go to the
`Logs` tab where you can see your message activities.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=beb5fcdfa587a89b438d2db22938f6df" data-og-width="2026" width="2026" data-og-height="660" height="660" data-path="img/qstash/log.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=acfc44f8f71fec5480334c50076ba5f6 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=46be420ad548bc8d1549ac4eb572ad46 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=506308270b92f95e63fb412cb14835ca 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b51df20dcd9047a2f1c8043db306e1b1 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5482ee85fa85b78af2d8eab873024a00 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3800e49a97e6c19fcdadef691c25dcd9 2500w" />
</Frame>

Learn more about different states [here](/qstash/howto/debug-logs).

## Features and Use Cases

<CardGroup cols={2}>
  <Card title="Background Jobs" icon="share-all" href="/qstash/features/background-jobs">
    Run long-running tasks in the background, without blocking your application
  </Card>

  <Card title="Schedules" icon="calendar-days" href="/qstash/features/schedules">
    Schedule messages to be delivered at a time in the future
  </Card>

  <Card title="Fan out" icon="arrows-maximize" href="/qstash/features/url-groups">
    Publish messages to multiple endpoints, in parallel, using URL Groups
  </Card>

  <Card title="FIFO" icon="right-left" href="/qstash/features/queues#ordered-delivery">
    Enqueue messages to be delivered one by one in the order they have enqueued.
  </Card>

  <Card title="Flow Control" icon="arrows-up-to-line" href="/qstash/features/flowcontrol">
    Custom rate per second and parallelism limits to avoid overflowing your endpoint.
  </Card>

  <Card title="Callbacks" icon="phone" href="/qstash/features/callbacks">
    Get a response delivered to your API when a message is delivered
  </Card>

  <Card title="Retry Failed Jobs" icon="repeat" href="/qstash/features/dlq">
    Use a Dead Letter Queue to have full control over failed messages
  </Card>

  <Card title="Deduplication" icon="copy" href="/qstash/features/deduplication">
    Prevent duplicate messages from being delivered
  </Card>

  <Card title="LLM Integrations" icon="shapes" href="/qstash/integrations/llm">
    Publish, enqueue, or batch chat completion requests using large language models with QStash
    features.
  </Card>
</CardGroup>


# llms.txt
Source: https://upstash.com/docs/qstash/overall/llms-txt





# Pricing & Limits
Source: https://upstash.com/docs/qstash/overall/pricing



Please check our [pricing page](https://upstash.com/pricing/qstash) for the most up-to-date information on pricing and limits.


# Roadmap
Source: https://upstash.com/docs/qstash/overall/roadmap



<Note>
  We have moved the roadmap and the changelog to [Github Discussions](https://github.com/orgs/upstash/discussions) starting from October 2025.Now you can follow `In Progress` features. You can see that your `Feature Requests` are recorded. You can vote for them and comment your specific use-cases to shape the feature to your needs.
</Note>


# Use Cases
Source: https://upstash.com/docs/qstash/overall/usecases



TODO: andreas: rework and reenable this page after we have 2 use cases ready
[https://linear.app/upstash/issue/QSTH-84/use-cases-summaryhighlights-of-recipes](https://linear.app/upstash/issue/QSTH-84/use-cases-summaryhighlights-of-recipes)

This section is still a work in progress.

We will be adding detailed tutorials for each use case soon.

Tell us on [Discord](https://discord.gg/w9SenAtbme) or
[X](https://x.com/upstash) what you would like to see here.

### Triggering Nextjs Functions on a schedule

Create a schedule in QStash that runs every hour and calls a Next.js serverless
function hosted on Vercel.

### Reset Billing Cycle in your Database

Once a month, reset database entries to start a new billing cycle.

### Fanning out alerts to Slack, email, Opsgenie, etc.

Createa QStash URL Group that receives alerts from a single source and delivers them
to multiple destinations.

### Send delayed message when a new user signs up

Publish delayed messages whenever a new user signs up in your app. After a
certain delay (e.g. 10 minutes), QStash will send a request to your API,
allowing you to email the user a welcome message.


# AWS Lambda (Node)
Source: https://upstash.com/docs/qstash/quickstarts/aws-lambda/nodejs



## Setting up a Lambda

The [AWS CDK](https://aws.amazon.com/cdk/) is the most convenient way to create a new project on AWS Lambda. For example, it lets you directly define integrations such as APIGateway, a tool to make our lambda publicly available as an API, in your code.

```bash Terminal theme={"system"}
mkdir my-app
cd my-app
cdk init app -l typescript
npm i esbuild @upstash/qstash
mkdir lambda
touch lambda/index.ts
```

## Webhook verification

### Using the SDK (recommended)

Edit `lambda/index.ts`, the file containing our core lambda logic:

```ts lambda/index.ts theme={"system"}
import { Receiver } from "@upstash/qstash"
import type { APIGatewayProxyEvent, APIGatewayProxyResult } from "aws-lambda"

const receiver = new Receiver({
  currentSigningKey: process.env.QSTASH_CURRENT_SIGNING_KEY ?? "",
  nextSigningKey: process.env.QSTASH_NEXT_SIGNING_KEY ?? "",
})

export const handler = async (
  event: APIGatewayProxyEvent
): Promise<APIGatewayProxyResult> => {
  const signature = event.headers["upstash-signature"]
  const lambdaFunctionUrl = `https://${event.requestContext.domainName}`

  if (!signature) {
    return {
      statusCode: 401,
      body: JSON.stringify({ message: "Missing signature" }),
    }
  }

  try {
    await receiver.verify({
      signature: signature,
      body: event.body ?? "",
      url: lambdaFunctionUrl,
    })
  } catch (err) {
    return {
      statusCode: 401,
      body: JSON.stringify({ message: "Invalid signature" }),
    }
  }

  // Request is valid, perform business logic

  return {
    statusCode: 200,
    body: JSON.stringify({ message: "Request processed successfully" }),
  }
}
```

We'll set the `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` environment variables together when deploying our Lambda.

### Manual Verification

In this section, we'll manually verify our incoming QStash requests without additional packages. Also see our [manual verification example](https://github.com/upstash/qstash-examples/tree/main/aws-lambda).

1. Implement the handler function

```ts lambda/index.ts theme={"system"}
import type { APIGatewayEvent, APIGatewayProxyResult } from "aws-lambda"
import { createHash, createHmac } from "node:crypto"

export const handler = async (
  event: APIGatewayEvent,
): Promise<APIGatewayProxyResult> => {
  const signature = event.headers["upstash-signature"] ?? ""
  const currentSigningKey = process.env.QSTASH_CURRENT_SIGNING_KEY ?? ""
  const nextSigningKey = process.env.QSTASH_NEXT_SIGNING_KEY ?? ""

  const url = `https://${event.requestContext.domainName}`

  try {
    // Try to verify the signature with the current signing key and if that fails, try the next signing key
    // This allows you to roll your signing keys once without downtime
    await verify(signature, currentSigningKey, event.body, url).catch((err) => {
      console.error(
        `Failed to verify signature with current signing key: ${err}`
      )

      return verify(signature, nextSigningKey, event.body, url)
    })
  } catch (err) {
    const message = err instanceof Error ? err.toString() : err

    return {
      statusCode: 400,
      body: JSON.stringify({ error: message }),
    }
  }

  // Add your business logic here

  return {
    statusCode: 200,
    body: JSON.stringify({ message: "Request processed successfully" }),
  }
}
```

2. Implement the `verify` function:

```ts lambda/index.ts theme={"system"}
/**
 * @param jwt - The content of the `upstash-signature` header (JWT)
 * @param signingKey - The signing key to use to verify the signature (Get it from Upstash Console)
 * @param body - The raw body of the request
 * @param url - The public URL of the lambda function
 */
async function verify(
  jwt: string,
  signingKey: string,
  body: string | null,
  url: string
): Promise<void> {
  const split = jwt.split(".")
  if (split.length != 3) {
    throw new Error("Invalid JWT")
  }
  const [header, payload, signature] = split

  if (
    signature !=
    createHmac("sha256", signingKey)
      .update(`${header}.${payload}`)
      .digest("base64url")
  ) {
    throw new Error("Invalid JWT signature")
  }

  // JWT is verified, start looking at payload claims
  const p: {
    sub: string
    iss: string
    exp: number
    nbf: number
    body: string
  } = JSON.parse(Buffer.from(payload, "base64url").toString())

  if (p.iss !== "Upstash") {
    throw new Error(`invalid issuer: ${p.iss}, expected "Upstash"`)
  }
  if (p.sub !== url) {
    throw new Error(`invalid subject: ${p.sub}, expected "${url}"`)
  }

  const now = Math.floor(Date.now() / 1000)
  if (now > p.exp) {
    throw new Error("token has expired")
  }
  if (now < p.nbf) {
    throw new Error("token is not yet valid")
  }

  if (body != null) {
    if (
      p.body.replace(/=+$/, "") !=
      createHash("sha256").update(body).digest("base64url")
    ) {
      throw new Error("body hash does not match")
    }
  }
}
```

You can find the complete example
[here](https://github.com/upstash/qstash-examples/blob/main/aws-lambda/typescript-example/index.ts).

## Deploying a Lambda

### Using the AWS CDK (recommended)

Because we used the AWS CDK to initialize our project, deployment is straightforward. Edit the `lib/<your-stack-name>.ts` file the CDK created when bootstrapping the project. For example, if our lambda webhook does video processing, it could look like this:

```ts lib/<your-stack-name>.ts theme={"system"}
import * as cdk from "aws-cdk-lib";
import * as lambda from "aws-cdk-lib/aws-lambda";
import { NodejsFunction } from "aws-cdk-lib/aws-lambda-nodejs";
import { Construct } from "constructs";
import path from "path";
import * as apigateway from 'aws-cdk-lib/aws-apigateway';

export class VideoProcessingStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props)

    // Create the Lambda function
    const videoProcessingLambda = new NodejsFunction(this, 'VideoProcessingLambda', {
      runtime: lambda.Runtime.NODEJS_20_X,
      handler: 'handler',
      entry: path.join(__dirname, '../lambda/index.ts'),
    });

    // Create the API Gateway
    const api = new apigateway.RestApi(this, 'VideoProcessingApi', {
      restApiName: 'Video Processing Service',
      description: 'This service handles video processing.',
      defaultMethodOptions: {
        authorizationType: apigateway.AuthorizationType.NONE,
      },
    });

    api.root.addMethod('POST', new apigateway.LambdaIntegration(videoProcessingLambda));
  }
}
```

Every time we now run the following deployment command in our terminal, our changes are going to be deployed right to a publicly available API, authorized by our QStash webhook logic from before.

```bash Terminal theme={"system"}
cdk deploy
```

You may be prompted to confirm the necessary AWS permissions during this process, for example allowing APIGateway to invoke your lambda function.

Once your code has been deployed to Lambda, you'll receive a live URL to your endpoint via the CLI and can see the new APIGateway connection in your AWS dashboard:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f07b1c8472eec7faff846c05dabf5f6d" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash/aws/api-gateway.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=058d384f8e63bd1c5ffb53ee9c56a521 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ccf60c328fb20a8275494169228369ef 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9aa4a9694db70a918ee5790811ae5abc 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=eb2e309a525baee49722fabe084bb1dc 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a41d328f4a909e95a3358c42bdb02b51 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/api-gateway.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=44e80904cad9bb76988e82377ecbcd2e 2500w" />
</Frame>

The URL you use to invoke your function typically follows this format, especially if you follow the same stack configuration as shown above:

`https://<API-GATEWAY-ID>.execute-api.<API-REGION>.amazonaws.com/prod/`

To provide our `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` environment variables, navigate to your QStash dashboard:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=80587de8e955411f9c092d3348056af3" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_signing_keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9aff13ae1e92d8e869d002ed08a9da07 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=796060edf979b7ce1e6710b9a4cdf78b 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=185f283f737442f131d8f3de95f88cc8 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=773c19bc5a6f25f3fa5f3616c7f7919f 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cf56a1e230831d2bfdd539d8118df910 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e42354e5503790f53e952804d7ca0ead 2500w" />
</Frame>

and make these two variables available to your Lambda in your function configuration:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8bc62c641000e9e128a9b37198d1906d" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/qstash/aws/environment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=71cbd9ef3b59d2548192de531eb1595d 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ea9d015c40cad5e2cc8582553ec09754 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f162de686cf6ef6f7984d8fe553d33ed 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e4181a1e22541d08903375e3f59d67aa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=591592bbcc823643cdb5fcb8a9d467ef 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ced801202130219f8c75ed907c931cb0 2500w" />
</Frame>

Tada, we just deployed a live Lambda with the AWS CDK! üéâ

### Manual Deployment

1. Create a new Lambda function by going to the [AWS dashboard](https://us-east-1.console.aws.amazon.com/lambda/home?region=us-east-1#/create/function) for your desired lambda region. Give your new function a name and select `Node.js 20.x` as runtime, then create the function.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3582c906c9bd8316714abd84cfc36d7a" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash/aws/create_lambda.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cc123cbcec268d316e9c9c0df1f18dfe 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1d4707c9406ba6493b85d19820df4330 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=616fa0ff8b3ba1d5390535ab4a1b4cc8 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3f23acd71afa860a8eb89e80903025b4 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d321923e425b60e7caa62f44c53947a5 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_lambda.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ebf5b50e8ac995899825aed7a44956f9 2500w" />
</Frame>

2. To make this Lambda available under a public URL, navigate to the `Configuration` tab and click `Function URL`:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f4f927ec6e24d6309406a53874b37c53" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/qstash/aws/create_url.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0d3d39f60f188ecd0551852ff0d916af 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=89e086b38e2f965514586a687dff234b 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=76b1e5f09bd966a99968cac2b640631e 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5a00bcb5625d71deda3b2b7eba61c318 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a72303771729bc260c0633ec61b562e3 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=13a5a1547d723fb2296710e738dfd7db 2500w" />
</Frame>

3. In the following dialog, you'll be asked to select one of two authentication types. Select `NONE`, because we are handling authentication ourselves. Then, click `Save`.

   You'll see the function URL on the right side of your function overview:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=94d488280830a5843d265040a7e8842d" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash/aws/overview.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2abfa43675d0a24c01282b5ef7f50a25 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8707939c6fe6f98d2286358a7473c2a8 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a07632d24f62047f83995bdb527e1431 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=7d7cddc5865e3ce07eda28ac247e47b0 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2f16c346e178fcadb5ef4fca6ab4f9bc 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/overview.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=57715f8c175f946456661920f91ce292 2500w" />
</Frame>

4. Get your current and next signing key from the
   [Upstash Console](https://console.upstash.com/qstash).

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=80587de8e955411f9c092d3348056af3" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_signing_keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9aff13ae1e92d8e869d002ed08a9da07 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=796060edf979b7ce1e6710b9a4cdf78b 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=185f283f737442f131d8f3de95f88cc8 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=773c19bc5a6f25f3fa5f3616c7f7919f 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cf56a1e230831d2bfdd539d8118df910 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e42354e5503790f53e952804d7ca0ead 2500w" />
</Frame>

5. Still under the `Configuration` tab, set the `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY`
   environment variables:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8bc62c641000e9e128a9b37198d1906d" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/qstash/aws/environment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=71cbd9ef3b59d2548192de531eb1595d 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ea9d015c40cad5e2cc8582553ec09754 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f162de686cf6ef6f7984d8fe553d33ed 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e4181a1e22541d08903375e3f59d67aa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=591592bbcc823643cdb5fcb8a9d467ef 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ced801202130219f8c75ed907c931cb0 2500w" />
</Frame>

6. Add the following script to your `package.json` file to build and zip your code:

```json package.json theme={"system"}
{
  "scripts": {
    "build": "rm -rf ./dist; esbuild index.ts --bundle --minify --sourcemap --platform=node --target=es2020 --outfile=dist/index.js && cd dist && zip -r index.zip index.js*"
  }
}
```

7. Click the `Upload from` button for your Lambda and
   deploy the code to AWS. Select `./dist/index.zip` as the upload file.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=04c254761fc6695610e756635a41ccc0" data-og-width="1918" width="1918" data-og-height="1080" height="1080" data-path="img/qstash/aws/upload.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fccd08e6810f18706d56aa6b7ab3cd1b 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=546e032f292909dca00c7df011cb1e44 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=65e76cbea01afcdfdbd2c616adda1fe2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4c8a3e6ecb1a67b80e7e7c0e5f39900b 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b31331ce2c780a2aed9df74802b503ac 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=043a7652099f9c97ca4f3dcbf0f3ccc1 2500w" />
</Frame>

Tada, you've manually deployed a zip file to AWS Lambda! üéâ

## Testing the Integration

To make sure everything works as expected, navigate to your QStash request builder and send a request to your freshly deployed Lambda function:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=21446d89f9624bc1a32b9d66a227368b" data-og-width="1253" width="1253" data-og-height="752" height="752" data-path="img/qstash/aws/verify-integration.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=7ba80e9eee665c3434aa445c046df602 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=bbfd54dc0d771368d4365f8e1359b5b0 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5b7db6102b578a20729c7a0caac693dd 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=398676b5df8e4f78a565b8f528255650 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cbadedc9f3a0a52b4239e144b1614227 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/verify-integration.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9253d2e5f2a1e331415f033beb222b2f 2500w" />
</Frame>

Alternatively, you can also send a request via CURL:

```bash Terminal theme={"system"}
curl --request POST "https://qstash.upstash.io/v2/publish/<YOUR-LAMBDA-URL>" \
-H "Authorization: Bearer <QSTASH_TOKEN>" \
-H "Content-Type: application/json" \
-d "{ \"hello\": \"world\"}"
```


# AWS Lambda (Python)
Source: https://upstash.com/docs/qstash/quickstarts/aws-lambda/python



[Source Code](https://github.com/upstash/qstash-examples/tree/main/aws-lambda/python-example)

This is a step by step guide on how to receive webhooks from QStash in your
Lambda function on AWS.

### 1. Create a new project

Let's create a new folder called `aws-lambda` and initialize a new project by
creating `lambda_function.py` This example uses Makefile, but the scripts can
also be written for `Pipenv`.

```bash  theme={"system"}
mkdir aws-lambda
cd aws-lambda
touch lambda_function.py
```

### 2. Dependencies

We are using `PyJwt` for decoding the JWT token in our code. We will install the
package in the zipping stage.

### 3. Creating the handler function

In this example we will show how to receive a webhook from QStash and verify the
signature.

First, let's import everything we need:

```python  theme={"system"}
import json
import os
import hmac
import hashlib
import base64
import time
import jwt
```

Now, we create the handler function. In the handler we will prepare all
necessary variables that we need for verification. This includes the signature,
the signing keys and the url of the lambda function. Then we try to verify the
request using the current signing key and if that fails we will try the next
one. If the signature could be verified, we can start processing the request.

```python  theme={"system"}
def lambda_handler(event, context):

    # parse the inputs
    current_signing_key = os.environ['QSTASH_CURRENT_SIGNING_KEY']
    next_signing_key = os.environ['QSTASH_NEXT_SIGNING_KEY']

    headers = event['headers']
    signature = headers['upstash-signature']
    url = "https://{}{}".format(event["requestContext"]["domainName"], event["rawPath"])
    body = None
    if 'body' in event:
        body = event['body']


    # check verification now
    try:
        verify(signature, current_signing_key, body, url)
    except Exception as e:
        print("Failed to verify signature with current signing key:", e)
        try:
            verify(signature, next_signing_key, body, url)
        except Exception as e2:
            return {
                "statusCode": 400,
                "body": json.dumps({
                    "error": str(e2),
                }),
            }


    # Your logic here...

    return {
        "statusCode": 200,
        "body": json.dumps({
            "message": "ok",
        }),
    }
```

The `verify` function will handle the actual verification of the signature. The
signature itself is actually a [JWT](https://jwt.io) and includes claims about
the request. See [here](/qstash/features/security#claims).

```python  theme={"system"}
# @param jwt_token - The content of the `upstash-signature` header
# @param signing_key - The signing key to use to verify the signature (Get it from Upstash Console)
# @param body - The raw body of the request
# @param url - The public URL of the lambda function
def verify(jwt_token, signing_key, body, url):
    split = jwt_token.split(".")
    if len(split) != 3:
        raise Exception("Invalid JWT.")

    header, payload, signature = split

    message = header + '.' + payload
    generated_signature = base64.urlsafe_b64encode(hmac.new(bytes(signing_key, 'utf-8'), bytes(message, 'utf-8'), digestmod=hashlib.sha256).digest()).decode()

    if generated_signature != signature and signature + "=" != generated_signature :
        raise Exception("Invalid JWT signature.")

    decoded = jwt.decode(jwt_token, options={"verify_signature": False})
    sub = decoded['sub']
    iss = decoded['iss']
    exp = decoded['exp']
    nbf = decoded['nbf']
    decoded_body = decoded['body']

    if iss != "Upstash":
        raise Exception("Invalid issuer: {}".format(iss))

    if sub.rstrip("/") != url.rstrip("/"):
        raise Exception("Invalid subject: {}".format(sub))

    now = time.time()
    if now > exp:
        raise Exception("Token has expired.")

    if now < nbf:
        raise Exception("Token is not yet valid.")


    if body != None:
        while decoded_body[-1] == "=":
            decoded_body = decoded_body[:-1]

        m = hashlib.sha256()
        m.update(bytes(body, 'utf-8'))
        m = m.digest()
        generated_hash = base64.urlsafe_b64encode(m).decode()

        if generated_hash != decoded_body and generated_hash != decoded_body + "=" :
                raise Exception("Body hash doesn't match.")
```

You can find the complete file
[here](https://github.com/upstash/qstash-examples/tree/main/aws-lambda/python-example/lambda_function.py).

That's it, now we can create the function on AWS and test it.

### 4. Create a Lambda function on AWS

Create a new Lambda function from scratch by going to the
[AWS console](https://us-east-1.console.aws.amazon.com/lambda/home?region=us-east-1#/create/function).
(Make sure you select your desired region)

Give it a name and select `Python 3.8` as runtime, then create the function.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ef006f177bb6ac267678a2ef2218d685" data-og-width="1904" width="1904" data-og-height="907" height="907" data-path="img/qstash/aws/python/create_lambda.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=bb218a9b61e74e0d93db42640d0479ac 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0288d0ae3f89efc0d8a707188e0194a3 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1d8b14e68171cd9c5266bf16275782ea 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e5c5f5fad35aab353c2a8adad0246f02 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ca22c3f689ad2dc75e43f200ebca92d2 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/create_lambda.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2d0a68794faea77685f65455cd383e14 2500w" />
</Frame>

Afterwards we will add a public URL to this lambda by going to the
`Configuration` tab:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f4f927ec6e24d6309406a53874b37c53" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/qstash/aws/create_url.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0d3d39f60f188ecd0551852ff0d916af 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=89e086b38e2f965514586a687dff234b 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=76b1e5f09bd966a99968cac2b640631e 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5a00bcb5625d71deda3b2b7eba61c318 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a72303771729bc260c0633ec61b562e3 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/create_url.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=13a5a1547d723fb2296710e738dfd7db 2500w" />
</Frame>

Select `Auth Type = NONE` because we are handling authentication ourselves.

After creating the url, you should see it on the right side of the overview of
your function:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e9eda18e87d98ebc1057e15b21abcc2a" data-og-width="1904" width="1904" data-og-height="906" height="906" data-path="img/qstash/aws/python/overview.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8a74d2186aab480704bbcf058e6d291e 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=03949c0baba2a516294fab5403bb9e33 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=048ca2d00cef212ce2d9ea42cf78ccbf 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=982c0650915c75b771aaa3f487894a1a 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=08dd85b062fab8d46a216584ea46ef13 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/python/overview.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=27aab10a9c48121f29654ee47d41ffca 2500w" />
</Frame>

### 5. Set Environment Variables

Get your current and next signing key from the
[Upstash Console](https://console.upstash.com/qstash)

On the same `Configuration` tab from earlier, we will now set the required
environment variables:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8bc62c641000e9e128a9b37198d1906d" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/qstash/aws/environment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=71cbd9ef3b59d2548192de531eb1595d 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ea9d015c40cad5e2cc8582553ec09754 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f162de686cf6ef6f7984d8fe553d33ed 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e4181a1e22541d08903375e3f59d67aa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=591592bbcc823643cdb5fcb8a9d467ef 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/environment.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ced801202130219f8c75ed907c931cb0 2500w" />
</Frame>

### 6. Deploy your Lambda function

We need to bundle our code and zip it to deploy it to AWS.

Add the following script to your `Makefile` file (or corresponding pipenv
script):

```yaml  theme={"system"}
zip:
    rm -rf dist
	pip3 install --target ./dist pyjwt
	cp lambda_function.py ./dist/lambda_function.py
	cd dist && zip -r lambda.zip .
	mv ./dist/lambda.zip ./
```

When calling `make zip` this will install PyJwt and zip the code.

Afterwards we can click the `Upload from` button in the lower right corner and
deploy the code to AWS. Select `lambda.zip` as upload file.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=04c254761fc6695610e756635a41ccc0" data-og-width="1918" width="1918" data-og-height="1080" height="1080" data-path="img/qstash/aws/upload.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fccd08e6810f18706d56aa6b7ab3cd1b 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=546e032f292909dca00c7df011cb1e44 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=65e76cbea01afcdfdbd2c616adda1fe2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4c8a3e6ecb1a67b80e7e7c0e5f39900b 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b31331ce2c780a2aed9df74802b503ac 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/aws/upload.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=043a7652099f9c97ca4f3dcbf0f3ccc1 2500w" />
</Frame>

### 7. Publish a message

Open a different terminal and publish a message to QStash. Note the destination
url is the URL from step 4.

```bash  theme={"system"}
curl --request POST "https://qstash.upstash.io/v2/publish/https://urzdbfn4et56vzeasu3fpcynym0zerme.lambda-url.eu-west-1.on.aws" \
     -H "Authorization: Bearer <QSTASH_TOKEN>" \
     -H "Content-Type: application/json" \
     -d "{ \"hello\": \"world\"}"
```

## Next Steps

That's it, you have successfully created a secure AWS lambda function, that
receives and verifies incoming webhooks from qstash.

Learn more about publishing a message to qstash [here](/qstash/howto/publishing)


# Cloudflare Workers
Source: https://upstash.com/docs/qstash/quickstarts/cloudflare-workers



This is a step by step guide on how to receive webhooks from QStash in your
Cloudflare Worker.

### Project Setup

We will use **C3 (create-cloudflare-cli)** command-line tool to create our functions. You can open a new terminal window and run C3 using the prompt below.

<CodeGroup>
  ```shell npm theme={"system"}
  npm create cloudflare@latest
  ```

  ```shell yarn theme={"system"}
  yarn create cloudflare@latest
  ```
</CodeGroup>

This will install the `create-cloudflare` package, and lead you through setup. C3 will also install Wrangler in projects by default, which helps us testing and deploying the projects.

```text  theme={"system"}
‚ûú  npm create cloudflare@latest
Need to install the following packages:
  create-cloudflare@2.52.3
Ok to proceed? (y) y

using create-cloudflare version 2.52.3

‚ï≠ Create an application with Cloudflare Step 1 of 3
‚îÇ
‚îú In which directory do you want to create your application?
‚îÇ dir ./cloudflare_starter
‚îÇ
‚îú What would you like to start with?
‚îÇ category Hello World example
‚îÇ
‚îú Which template would you like to use?
‚îÇ type Worker only
‚îÇ
‚îú Which language do you want to use?
‚îÇ lang TypeScript
‚îÇ
‚îú Do you want to use git for version control?
‚îÇ yes git
‚îÇ
‚ï∞ Application created
```

We will also install the **Upstash QStash library**.

```bash  theme={"system"}
npm install @upstash/qstash
```

### 3. Use QStash in your handler

First we import the library:

```ts src/index.ts theme={"system"}
import { Receiver } from "@upstash/qstash";
```

Then we adjust the `Env` interface to include the `QSTASH_CURRENT_SIGNING_KEY`
and `QSTASH_NEXT_SIGNING_KEY` environment variables.

```ts src/index.ts theme={"system"}
export interface Env {
  QSTASH_CURRENT_SIGNING_KEY: string;
  QSTASH_NEXT_SIGNING_KEY: string;
}
```

And then we validate the signature in the `handler` function.

First we create a new receiver and provide it with the signing keys.

```ts src/index.ts theme={"system"}
const receiver = new Receiver({
  currentSigningKey: env.QSTASH_CURRENT_SIGNING_KEY,
  nextSigningKey: env.QSTASH_NEXT_SIGNING_KEY,
});
```

Then we verify the signature.

```ts src/index.ts theme={"system"}
const body = await request.text();

const isValid = await receiver.verify({
  signature: request.headers.get("Upstash-Signature")!,
  body,
});
```

The entire file looks like this now:

```ts src/index.ts theme={"system"}
import { Receiver } from "@upstash/qstash";

export interface Env {
  QSTASH_CURRENT_SIGNING_KEY: string;
  QSTASH_NEXT_SIGNING_KEY: string;
}

export default {
  async fetch(request, env, ctx): Promise<Response> {
    const receiver = new Receiver({
      currentSigningKey: env.QSTASH_CURRENT_SIGNING_KEY,
      nextSigningKey: env.QSTASH_NEXT_SIGNING_KEY,
    });

    const body = await request.text();

    const isValid = await receiver.verify({
      signature: request.headers.get("Upstash-Signature")!,
      body,
    });

    if (!isValid) {
      return new Response("Invalid signature", { status: 401 });
    }

    // signature is valid

    return new Response("Hello World!");
  },
} satisfies ExportedHandler<Env>;
```

### Configure Credentials

There are two methods for setting up the credentials for QStash. One for worker level, the other for account level.

#### Using Cloudflare Secrets (Worker Level Secrets)

This is the common way of creating secrets for your worker, see [Workflow Secrets](https://developers.cloudflare.com/workers/configuration/secrets/)

* Navigate to [Upstash Console](https://console.upstash.com) and get your QStash credentials.

* In [Cloudflare Dashboard](https://dash.cloudflare.com/), Go to **Compute (Workers)** > **Workers & Pages**.

* Select your worker and go to **Settings** > **Variables and Secrets**.

* Add your QStash credentials as secrets here:

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=0fdc5a1123d5c3c3eaa083821712e887" data-og-width="1718" width="1718" data-og-height="624" height="624" data-path="img/cloudflare-integration/secrets.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=50845185131054d4d6a5a5297494386a 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=8ed427e7462fcf0f234f39de7f51c39b 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=edf1bdf371db5acbb1fa785d93c89347 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=e1e318665638791c5628f810b1048a2d 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=86ede44dae15be8f5019028458507fca 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=3dc232893357fcb259639d2b7e648b91 2500w" />
</Frame>

#### Using Cloudflare Secrets Store (Account Level Secrets)

This method requires a few modifications in the worker code, see [Access to Secret on Env Object](https://developers.cloudflare.com/secrets-store/integrations/workers/#3-access-the-secret-on-the-env-object)

```ts src/index.ts theme={"system"}
import { Receiver } from "@upstash/qstash";

export interface Env {
  QSTASH_CURRENT_SIGNING_KEY: SecretsStoreSecret;
  QSTASH_NEXT_SIGNING_KEY: SecretsStoreSecret;
}

export default {
  async fetch(request, env, ctx): Promise<Response> {
    const c = new Receiver({
      currentSigningKey: await env.QSTASH_CURRENT_SIGNING_KEY.get(),
      nextSigningKey: await env.QSTASH_NEXT_SIGNING_KEY.get(),
    });

    // Rest of the code
  },
};
```

After doing these modifications, you can deploy the worker to Cloudflare with `npx wrangler deploy`, and
follow the steps below to define the secrets:

* Navigate to [Upstash Console](https://console.upstash.com) and get your QStash credentials.

* In [Cloudflare Dashboard](https://dash.cloudflare.com/), Go to **Secrets Store** and add QStash credentials as secrets.

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=daefd6a42242541b70452ccd1071e7dd" data-og-width="1940" width="1940" data-og-height="1110" height="1110" data-path="img/cloudflare-integration/secrets-store.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=4dcc1246d56ffba5f01961b68774af90 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=8a288410ed7f8913c97e610d41ebd7c6 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=a180068645d1f866f6ca5c6f302f7e16 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=8c371c37e0b4809493768fd8734c1337 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=b0e40ebfe03c24b833311fb3806bb09a 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/secrets-store.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=a420fa6ad32aa11a9198f73e5ae7b6b1 2500w" />
</Frame>

* Under **Compute (Workers)** > **Workers & Pages**, find your worker and add these secrets as bindings.

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=3959adcb8a96153fbc001d35609182ad" data-og-width="1940" width="1940" data-og-height="1368" height="1368" data-path="img/cloudflare-integration/add-binding.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=8ac52ecfe1badade3aa079ab5be91840 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=8a824b1590cddb28be8ae046008d6daa 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=f7ca746df30c5b0e4c9ba39c99def7d5 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=b689b92485b9c5f538ba6b7f340d84e2 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=43d991ebc0be959c42efb31a95bac614 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/add-binding.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=ffb326c5cadb3044db014762bddbeddf 2500w" />
</Frame>

### Deployment

<Note>
  Newer deployments may revert the configurations you did in the dashboard.
  While worker level secrets persist, the bindings will be gone!
</Note>

Deploy your function to Cloudflare with `npx wrangler deploy`

The endpoint of the function will be provided to you, once the deployment is done.

### Publish a message

Open a different terminal and publish a message to QStash. Note the destination
url is the same that was printed in the previous deploy step.

```bash  theme={"system"}
curl --request POST "https://qstash.upstash.io/v2/publish/https://<your-worker-name>.<account-name>.workers.dev" \
     -H "Authorization: Bearer <QSTASH_TOKEN>" \
     -H "Content-Type: application/json" \
     -d "{ \"hello\": \"world\"}"
```

In the logs you should see something like this:

```bash  theme={"system"}
$ npx wrangler tail

‚õÖÔ∏è wrangler 4.43.0
--------------------

Successfully created tail, expires at 2025-10-16T00:25:17Z
Connected to <your-worker-name>, waiting for logs...
POST https://<your-worker-name>.<account-name>.workers.dev/ - Ok @ 10/15/2025, 10:34:55 PM
```

## Next Steps

That's it, you have successfully created a secure Cloudflare Worker, that
receives and verifies incoming webhooks from qstash.

Learn more about publishing a message to qstash [here](/qstash/howto/publishing).

You can find the source code [here](https://github.com/upstash/qstash-examples/tree/main/cloudflare-workers).


# Deno Deploy
Source: https://upstash.com/docs/qstash/quickstarts/deno-deploy



[Source Code](https://github.com/upstash/qstash-examples/tree/main/deno-deploy)

This is a step by step guide on how to receive webhooks from QStash in your Deno
deploy project.

### 1. Create a new project

Go to [https://dash.deno.com/projects](https://dash.deno.com/projects) and
create a new playground project.

### 2. Edit the handler function

Then paste the following code into the browser editor:

```ts  theme={"system"}
import { serve } from "https://deno.land/std@0.142.0/http/server.ts";
import { Receiver } from "https://deno.land/x/upstash_qstash@v0.1.4/mod.ts";

serve(async (req: Request) => {
  const r = new Receiver({
    currentSigningKey: Deno.env.get("QSTASH_CURRENT_SIGNING_KEY")!,
    nextSigningKey: Deno.env.get("QSTASH_NEXT_SIGNING_KEY")!,
  });

  const isValid = await r
    .verify({
      signature: req.headers.get("Upstash-Signature")!,
      body: await req.text(),
    })
    .catch((err: Error) => {
      console.error(err);
      return false;
    });

  if (!isValid) {
    return new Response("Invalid signature", { status: 401 });
  }

  console.log("The signature was valid");

  // do work

  return new Response("OK", { status: 200 });
});
```

### 3. Add your signing keys

Click on the `settings` button at the top of the screen and then click
`+ Add Variable`

Get your current and next signing key from
[Upstash](https://console.upstash.com/qstash) and then set them in deno deploy.

<img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fcd35bafc9752ac36a93de5ff8142c18" alt="" data-og-width="3016" width="3016" data-og-height="1666" height="1666" data-path="img/qstash/deno_deploy_env.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d489d42d7b134d28b4863cde8544efac 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=44d5b15af4e1a47614ac4b583c79270e 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=36e34a30f657a0809203e6e6bfdc87f3 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3b6fb4bc9c79c2461d822890da31f2bf 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ff3513e131ffdb82378f2c53abf7ba20 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/deno_deploy_env.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=65cb2066cc2ab3ee9ceda1620c354751 2500w" />

### 4. Deploy

Simply click on `Save & Deploy` at the top of the screen.

### 5. Publish a message

Make note of the url displayed in the top right. This is the public url of your
project.

```bash  theme={"system"}
curl --request POST "https://qstash.upstash.io/v2/publish/https://early-frog-33.deno.dev" \
     -H "Authorization: Bearer <QSTASH_TOKEN>" \
     -H "Content-Type: application/json" \
     -d "{ \"hello\": \"world\"}"
```

In the logs you should see something like this:

```basheurope-west3isolate start time: 2.21 ms theme={"system"}
Listening on http://localhost:8000/
The signature was valid
```

## Next Steps

That's it, you have successfully created a secure deno API, that receives and
verifies incoming webhooks from qstash.

Learn more about publishing a message to qstash [here](/qstash/howto/publishing)


# Golang
Source: https://upstash.com/docs/qstash/quickstarts/fly-io/go



[Source Code](https://github.com/upstash/qstash-examples/tree/main/fly.io/go)

This is a step by step guide on how to receive webhooks from QStash in your
Golang application running on [fly.io](https://fly.io).

## 0. Prerequisites

* [flyctl](https://fly.io/docs/getting-started/installing-flyctl/) - The fly.io
  CLI

## 1. Create a new project

Let's create a new folder called `flyio-go` and initialize a new project.

```bash  theme={"system"}
mkdir flyio-go
cd flyio-go
go mod init flyio-go
```

## 2. Creating the main function

In this example we will show how to receive a webhook from QStash and verify the
signature using the popular [golang-jwt/jwt](https://github.com/golang-jwt/jwt)
library.

First, let's import everything we need:

```go  theme={"system"}
package main

import (
	"crypto/sha256"
	"encoding/base64"
	"fmt"
	"github.com/golang-jwt/jwt/v4"
	"io"
	"net/http"
	"os"
	"time"
)
```

Next we create `main.go`. Ignore the `verify` function for now. We will add that
next. In the handler we will prepare all necessary variables that we need for
verification. This includes the signature and the signing keys. Then we try to
verify the request using the current signing key and if that fails we will try
the next one. If the signature could be verified, we can start processing the
request.

```go  theme={"system"}
func main() {
	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}

	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		defer r.Body.Close()

		currentSigningKey := os.Getenv("QSTASH_CURRENT_SIGNING_KEY")
		nextSigningKey := os.Getenv("QSTASH_NEXT_SIGNING_KEY")
		tokenString := r.Header.Get("Upstash-Signature")

		body, err := io.ReadAll(r.Body)
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}

		err = verify(body, tokenString, currentSigningKey)
		if err != nil {
			fmt.Printf("Unable to verify signature with current signing key: %v", err)
			err = verify(body, tokenString, nextSigningKey)
		}

		if err != nil {
			http.Error(w, err.Error(), http.StatusUnauthorized)
			return
		}

		// handle your business logic here

		w.WriteHeader(http.StatusOK)

	})

	fmt.Println("listening on", port)
	err := http.ListenAndServe(":"+port, nil)
	if err != nil {
		panic(err)
	}
}
```

The `verify` function will handle verification of the [JWT](https://jwt.io),
that includes claims about the request. See
[here](/qstash/features/security#claims).

```go  theme={"system"}
func verify(body []byte, tokenString, signingKey string) error {
	token, err := jwt.Parse(
		tokenString,
		func(token *jwt.Token) (interface{}, error) {
			if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
				return nil, fmt.Errorf("Unexpected signing method: %v", token.Header["alg"])
			}
			return []byte(signingKey), nil
		})

	if err != nil {
		return err
	}

	claims, ok := token.Claims.(jwt.MapClaims)
	if !ok || !token.Valid {
		return fmt.Errorf("Invalid token")
	}

	if !claims.VerifyIssuer("Upstash", true) {
		return fmt.Errorf("invalid issuer")
	}
	if !claims.VerifyExpiresAt(time.Now().Unix(), true) {
		return fmt.Errorf("token has expired")
	}
	if !claims.VerifyNotBefore(time.Now().Unix(), true) {
		return fmt.Errorf("token is not valid yet")
	}

	bodyHash := sha256.Sum256(body)
	if claims["body"] != base64.URLEncoding.EncodeToString(bodyHash[:]) {
		return fmt.Errorf("body hash does not match")
	}

	return nil
}
```

You can find the complete file
[here](https://github.com/upstash/qstash-examples/blob/main/fly.io/go/main.go).

That's it, now we can deploy our API and test it.

## 3. Create app on fly.io

[Login](https://fly.io/docs/getting-started/log-in-to-fly/) with `flyctl` and
then `flyctl launch` the new app. This will create the necessary `fly.toml` for
us. It will ask you a bunch of questions. I chose all defaults here except for
the last question. We do not want to deploy just yet.

```bash  theme={"system"}
$ flyctl launch
Creating app in /Users/andreasthomas/github/upstash/qstash-examples/fly.io/go
Scanning source code
Detected a Go app
Using the following build configuration:
        Builder: paketobuildpacks/builder:base
        Buildpacks: gcr.io/paketo-buildpacks/go
? App Name (leave blank to use an auto-generated name):
Automatically selected personal organization: Andreas Thomas
? Select region: fra (Frankfurt, Germany)
Created app winer-cherry-9545 in organization personal
Wrote config file fly.toml
? Would you like to setup a Postgresql database now? No
? Would you like to deploy now? No
Your app is ready. Deploy with `flyctl deploy`
```

## 4. Set Environment Variables

Get your current and next signing key from the
[Upstash Console](https://console.upstash.com/qstash)

Then set them using `flyctl secrets set ...`

```bash  theme={"system"}
flyctl secrets set QSTASH_CURRENT_SIGNING_KEY=...
flyctl secrets set QSTASH_NEXT_SIGNING_KEY=...
```

## 5. Deploy the app

Fly.io made this step really simple. Just `flyctl deploy` and enjoy.

```bash  theme={"system"}
flyctl deploy
```

## 6. Publish a message

Now you can publish a message to QStash. Note the destination url is basically
your app name, if you are not sure what it is, you can go to
[fly.io/dashboard](https://fly.io/dashboard) and find out. In my case the app is
named "winter-cherry-9545" and the public url is
"[https://winter-cherry-9545.fly.dev](https://winter-cherry-9545.fly.dev)".

```bash  theme={"system"}
curl --request POST "https://qstash.upstash.io/v2/publish/https://winter-cherry-9545.fly.dev" \
     -H "Authorization: Bearer <QSTASH_TOKEN>" \
     -H "Content-Type: application/json" \
     -d "{ \"hello\": \"world\"}"
```

## Next Steps

That's it, you have successfully created a Go API hosted on fly.io, that
receives and verifies incoming webhooks from qstash.

Learn more about publishing a message to qstash [here](/qstash/howto/publishing)


# Python on Vercel
Source: https://upstash.com/docs/qstash/quickstarts/python-vercel



## Introduction

This quickstart will guide you through setting up QStash to run a daily script
to clean up your database. This is useful for testing and development environments
where you want to reset the database every day.

## Prerequisites

* Create an Upstash account and get your [QStash token](https://console.upstash.com/qstash)

<Steps>
  <Step titleSize="h3" title="Create Python app">
    First, we'll create a new directory for our Python app. We'll call it `clean-db-cron`.

    The database we'll be using is Redis, so we'll need to install the `upstash_redis` package.

    ```bash  theme={"system"}
    mkdir clean-db-cron
    ```

    ```bash  theme={"system"}
    cd clean-db-cron
    ```

    ```bash  theme={"system"}
    pip install upstash-redis
    ```
  </Step>

  <Step titleSize="h3" title="Cleanup logic">
    Let's write the Python code to clean up the database. We'll use the `upstash_redis`
    package to connect to the database and delete all keys.

    ```python index.py theme={"system"}
    from upstash_redis import Redis

    redis = Redis(url="https://YOUR_REDIS_URL", token="YOUR_TOKEN")

    def delete_all_entries():
      keys = redis.keys("*") # Match all keys
      redis.delete(*keys)


    delete_all_entries()
    ```

    Try running the code to see if it works. Your database keys should be deleted!
  </Step>

  <Step titleSize="h3" title="Make the Python code into a public endpoint">
    In order to use QStash, we need to make the Python code into a public endpoint. There
    are many ways to do this such as using Flask, FastAPI, or Django. In this example, we'll
    use the Python `http.server` module to create a simple HTTP server.

    ```python api/index.py theme={"system"}
    from http.server import BaseHTTPRequestHandler
    from upstash_redis import Redis

    redis = Redis(url="https://YOUR_REDIS_URL", token="YOUR_TOKEN")

    def delete_all_entries():
      keys = redis.keys("*") # Match all keys
      redis.delete(*keys)


    class handler(BaseHTTPRequestHandler):
      def do_POST(self):
        delete_all_entries()
        self.send_response(200)
        self.end_headers()
    ```

    For the purpose of this tutorial, I'll deploy the application to Vercel using the
    [Python Runtime](https://vercel.com/docs/functions/runtimes/python), but feel free to
    use any other hosting provider.

    <Accordion title="Deploying to Vercel">
      There are many ways to [deploy to Vercel](https://vercel.com/docs/deployments/overview), but
      I'm going to use the Vercel CLI.

      ```bash  theme={"system"}
      npm install -g vercel
      ```

      ```bash  theme={"system"}
      vercel
      ```
    </Accordion>

    Once deployed, you can find the public URL in the dashboard.
  </Step>

  <Step titleSize="h3" title="Have QStash invoke the endpoint">
    There are two ways we can go about configuring QStash. We can either use the QStash dashboard
    or the QStash API. In this example, it makes more sense to utilize the dashboard since we
    only need to set up a singular cronjob.

    However, you can imagine a scenario where you have a large number of cronjobs and you'd
    want to automate the process. In that case, you'd want to use the QStash Python SDK.

    To create the schedule, go to the [QStash dashboard](https://console.upstash.com/qstash) and enter
    the URL of the public endpoint you created. Then, set the type to schedule and change the
    `Upstash-Cron` header to run daily at a time of your choosing.

    ```
    URL: https://your-vercel-app.vercel.app/api
    Type: Schedule
    Every: every day at midnight (feel free to customize)
    ```

    <Frame>
      <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8173b32d110478738d2c7f4713b69593" alt="QStash console scheduling" data-og-width="2002" width="2002" data-og-height="1282" height="1282" data-path="img/qstash/python-quickstart-schedule.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=de2601e51052910ae56c321912d0568d 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6c4e7261a126990b151704a03b912929 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b874129a02d901bcf4d4308598a855f0 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=41748daa51aef9cc8e0c02c67562658d 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=87c08f2d42bc1f39d9634b05a7a5ebf1 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/python-quickstart-schedule.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=72343d62d71b8b046ddf6700065489b8 2500w" />
    </Frame>

    Once you start the schedule, QStash will invoke the endpoint at the specified time. You can
    scroll down and verify the job has been created!

    <Accordion title="Using the SDK">
      If you have a use case where you need to automate the creation of jobs, you can use the SDK instead.

      ```python  theme={"system"}
      from qstash import QStash

      client = QStash("<QSTASH_TOKEN>")
      client.schedule.create(
          destination="https://YOUR_URL.vercel.app/api",
          cron="0 12 * * *",
      )
      ```
    </Accordion>
  </Step>
</Steps>

Now, go ahead and try it out for yourself! Try using some of the other features of QStash, such as
[callbacks](/qstash/features/callbacks) and [URL Groups](/qstash/features/url-groups).


# Next.js
Source: https://upstash.com/docs/qstash/quickstarts/vercel-nextjs



QStash is a robust message queue and task-scheduling service that integrates perfectly with Next.js. This guide will show you how to use QStash in your Next.js projects, including a quickstart and a complete example.

## Quickstart

At its core, each QStash message contains two pieces of information:

* URL (which endpoint to call)
* Request body (e.g. IDs of items you want to process)

The following endpoint could be used to upload an image and then asynchronously queue a processing task to optimize the image in the background.

```tsx upload-image/route.ts theme={"system"}
import { Client } from "@upstash/qstash"
import { NextResponse } from "next/server"

const client = new Client({ token: process.env.QSTASH_TOKEN! })

export const POST = async (req: Request) => {
  // Image uploading logic

  // üëá Once uploading is done, queue an image processing task
  const result = await client.publishJSON({
    url: "https://your-api-endpoint.com/process-image",
    body: { imageId: "123" },
  })

  return NextResponse.json({
    message: "Image queued for processing!",
    qstashMessageId: result.messageId,
  })
}
```

Note that the URL needs to be publicly available for QStash to call, either as a deployed project or by [developing with QStash locally](/qstash/howto/local-tunnel).

Because QStash calls our image processing task, we get automatic retries whenever the API throws an error. These retries make our function very reliable. We also let the user know immediately that their image has been successfully queued.

Now, let's **receive the QStash message** in our image processing endpoint:

```tsx process-image/route.ts theme={"system"}
import { verifySignatureAppRouter } from "@upstash/qstash/nextjs"

// üëá Verify that this messages comes from QStash
export const POST = verifySignatureAppRouter(async (req: Request) => {
  const body = await req.json()
  const { imageId } = body as { imageId: string }

  // Image processing logic, i.e. using sharp

  return new Response(`Image with id "${imageId}" processed successfully.`)
})
```

```bash .env theme={"system"}
# Copy all three from your QStash dashboard
QSTASH_TOKEN=
QSTASH_CURRENT_SIGNING_KEY=
QSTASH_NEXT_SIGNING_KEY=
```

Just like that, we set up a reliable and asynchronous image processing system in Next.js. The same logic works for email queues, reliable webhook processing, long-running report generations and many more.

## Example project

* Create an Upstash account and get your [QStash token](https://console.upstash.com/qstash)
* Node.js installed

<Steps>
  <Step titleSize="h3" title="Create Next.js app and install QStash">
    ```bash  theme={"system"}
    npx create-next-app@latest qstash-bg-job
    ```

    ```bash  theme={"system"}
    cd qstash-bg-job
    ```

    ```bash  theme={"system"}
    npm install @upstash/qstash
    ```

    ```bash  theme={"system"}
    npm run dev
    ```
  </Step>

  <Step titleSize="h3" title="Create UI">
    After removing the default content in `src/app/page.tsx`, let's create a simple UI to trigger the background job
    using a button.

    ```tsx src/app/page.tsx theme={"system"}
    "use client"

    export default function Home() {
      return (
        <main className="flex h-lvh items-center justify-center">
          <button
            onClick={handleClick}
            className="btn btn-primary w-1/2 h-56 bg-green-500 text-xl sm:text-3xl rounded-lg hover:bg-green-600"
          >
            Start Background Job
          </button>
        </main>
      )
    }
    ```

    <Accordion title="Beautiful">
      <Frame>
        <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=db902e71fc22c50749ebfc8795aa4337" alt="Quickstart UI" data-og-width="1918" width="1918" data-og-height="1126" height="1126" data-path="img/qstash/quickstart-qstash-ui.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6cffcb8f93df2c5b612bdcbcefa176cc 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1566f155c0e7e02185836f266dd6de60 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=895da26a22dc02c86dd9e7cc9816f3e5 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c8f35545af51da14f0abe4b34c6134a7 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d5110f84aed75b824851c3763c0996c4 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-ui.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0b4ab5ed36ba8de483d5ef1753edbc23 2500w" />
      </Frame>
    </Accordion>
  </Step>

  <Step titleSize="h3" title="Start Background Job">
    We can use QStash to start a background job by calling the `publishJSON` method.
    In this example, we're using Next.js server actions, but you can also use route handlers.

    Since we don't have our public API endpoint yet, we can use [Request Catcher](https://requestcatcher.com/) to test the background job.
    This will eventually be replaced with our own API endpoint.

    ```ts src/app/actions.ts theme={"system"}
    "use server"
    import { Client } from "@upstash/qstash"

    const qstashClient = new Client({
      // Add your token to a .env file
      token: process.env.QSTASH_TOKEN!,
    })

    export async function startBackgroundJob() {
      await qstashClient.publishJSON({
        url: "https://firstqstashmessage.requestcatcher.com/test",
        body: {
          hello: "world",
        },
      })
    }
    ```

    Now let's invoke the `startBackgroundJob` function when the button is clicked.

    ```tsx src/app/page.tsx theme={"system"}
    "use client"
    import { startBackgroundJob } from "@/app/actions"

    export default function Home() {
      async function handleClick() {
        await startBackgroundJob()
      }

      return (
        <main className="flex h-lvh items-center justify-center">
          <button
            onClick={handleClick}
            className="btn btn-primary w-1/2 h-56 bg-green-500 text-xl sm:text-3xl rounded-lg hover:bg-green-600"
          >
            Start Background Job
          </button>
        </main>
      )
    }
    ```

    To test the background job, click the button and check the Request Catcher for the incoming request.

    <Accordion title="Verification screenshots">
      <Frame>
        <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f68c3043856bf77c5e55786a54d57cd7" data-og-width="1456" width="1456" data-og-height="580" height="580" data-path="img/qstash/reqcatcher.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=84c76a371ea1a6af224a61c7897176e4 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=337d1aa2277b60b314a69122ba24bfa0 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f8d5a20e4e1a735bb579791f474d891b 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2fcbc86f518555b08b306ff0d4c64045 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f5f8791bc3df089e26bac1e742505b9c 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/reqcatcher.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=26a972e97932d8f03f8183da39996063 2500w" />
      </Frame>

      You can also head over to [Upstash Console](https://console.upstash.com/qstash) and go to the
      `Logs` tab where you can see your message activities.

      <Frame>
        <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=beb5fcdfa587a89b438d2db22938f6df" data-og-width="2026" width="2026" data-og-height="660" height="660" data-path="img/qstash/log.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=acfc44f8f71fec5480334c50076ba5f6 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=46be420ad548bc8d1549ac4eb572ad46 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=506308270b92f95e63fb412cb14835ca 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b51df20dcd9047a2f1c8043db306e1b1 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5482ee85fa85b78af2d8eab873024a00 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/log.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3800e49a97e6c19fcdadef691c25dcd9 2500w" />
      </Frame>
    </Accordion>
  </Step>

  <Step titleSize="h3" title="Create your own endpoint">
    Now that we know QStash is working, let's create our own endpoint to handle a background job. This
    is the endpoint that will be invoked by QStash.

    This job will be responsible for sending 10 requests, each with a 500ms delay. Since we're deploying
    to Vercel, we have to be cautious of the [time limit for serverless functions](https://vercel.com/docs/functions/runtimes#max-duration).

    ```ts src/app/api/long-task/route.ts theme={"system"}
    export async function POST(request: Request) {
      const data = await request.json()

      for (let i = 0; i < 10; i++) {
        await fetch("https://firstqstashmessage.requestcatcher.com/test", {
          method: "POST",
          body: JSON.stringify(data),
          headers: { "Content-Type": "application/json" },
        })
        await new Promise((resolve) => setTimeout(resolve, 500))
      }

      return Response.json({ success: true })
    }
    ```

    Now let's update our `startBackgroundJob` function to use our new endpoint.

    There's 1 problem: our endpoint is not public. We need to make it public so that QStash can call it.
    We have 2 options:

    1. Deploy our application to a platform like Vercel and use the public URL.
    2. Create a [local tunnel](/qstash/howto/local-tunnel) to test the endpoint locally.

    For the purpose, of this tutorial, I'll deploy the application to Vercel, but
    feel free to use a local tunnel if you prefer.

    <Accordion title="Deploying to Vercel">
      There are many ways to [deploy to Vercel](https://vercel.com/docs/deployments/overview), but
      I'm going to use the Vercel CLI.

      ```bash  theme={"system"}
      npm install -g vercel
      ```

      ```bash  theme={"system"}
      vercel
      ```

      Once deployed, you can find the public URL in the Vercel dashboard.
    </Accordion>

    Now that we have a public URL, we can update the URL.

    ```ts src/app/actions.ts theme={"system"}
    "use server"
    import { Client } from "@upstash/qstash"

    const qstashClient = new Client({
      token: process.env.QSTASH_TOKEN!,
    })

    export async function startBackgroundJob() {
      await qstashClient.publishJSON({
        // Replace with your public URL
        url: "https://qstash-bg-job.vercel.app/api/long-task",
        body: {
          hello: "world",
        },
      })
    }
    ```

    And voila! You've created a Next.js app that calls a long-running background job using QStash.
  </Step>

  <Step title="Error catching and security">
    QStash is a great way to handle background jobs, but it's important to remember that it's a public
    API. This means that anyone can call your endpoint. Make sure to add security measures to your endpoint
    to ensure that QStash is the sender of the request.

    Luckily, our SDK provides a way to verify the sender of the request. Make sure to get your signing keys
    from the QStash console and add them to your environment variables. The `verifySignatureAppRouter` will try to
    load `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` from the environment. If one of them is missing,
    an error is thrown.

    ```ts src/app/api/long-task/route.ts theme={"system"}
    import { verifySignatureAppRouter } from "@upstash/qstash/nextjs"

    async function handler(request: Request) {
      const data = await request.json()

      for (let i = 0; i < 10; i++) {
        await fetch("https://firstqstashmessage.requestcatcher.com/test", {
          method: "POST",
          body: JSON.stringify(data),
          headers: { "Content-Type": "application/json" },
        })
        await new Promise((resolve) => setTimeout(resolve, 500))
      }

      return Response.json({ success: true })
    }

    export const POST = verifySignatureAppRouter(handler)
    ```

    Let's also add error catching to our action and a loading state to our UI.

    <CodeGroup>
      ```ts src/app/actions.ts theme={"system"}
      "use server"
      import { Client } from "@upstash/qstash";

      const qstashClient = new Client({
        token: process.env.QSTASH_TOKEN!,
      });

      export async function startBackgroundJob() {
        try {
          const response = await qstashClient.publishJSON({
            "url": "https://qstash-bg-job.vercel.app/api/long-task",
            body: {
              "hello": "world"
            }
          });
          return response.messageId;
        } catch (error) {
          console.error(error);
          return null;
        }
      }
      ```

      ```tsx src/app/page.tsx theme={"system"}
      "use client"
      import { startBackgroundJob } from "@/app/actions";
      import { useState } from "react";

      export default function Home() {
        const [loading, setLoading] = useState(false);
        const [msg, setMsg] = useState("");

        async function handleClick() {
          setLoading(true);
          const messageId = await startBackgroundJob();
          if (messageId) {
            setMsg(`Started job with ID ${messageId}`);
          } else {
            setMsg("Failed to start background job");
          }
          setLoading(false);
        }

        return (
          <main className="flex flex-col h-lvh items-center justify-center">
            <button onClick={handleClick} disabled={loading} className="btn btn-primary w-1/2 h-56 bg-green-500 text-xl sm:text-3xl rounded-lg hover:bg-green-600 disabled:bg-gray-500">
              Start Background Job
            </button>

            {loading && <div className="text-2xl mt-8">Loading...</div>}
            {msg && <p className="text-center text-lg">{msg}</p>}
          </main>
        );
      }
      ```
    </CodeGroup>
  </Step>
</Steps>

## Result

We have now created a Next.js app that calls a long-running background job using QStash!
Here's the app in action:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/nextjs-quickstart-result-gif.gif?s=a49ea8f2c7d3ffdf062005939591030b" alt="Quickstart Result Gif" data-og-width="1000" width="1000" data-og-height="550" height="550" data-path="img/qstash/nextjs-quickstart-result-gif.gif" data-optimize="true" data-opv="3" />
</Frame>

We can also view the logs on Vercel and QStash

<Accordion title="Logs">
  Vercel

  <Frame>
    <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6bebdd8a99667f5859444d537ccb1a1e" alt="Vercel Logs" data-og-width="503" width="503" data-og-height="747" height="747" data-path="img/qstash/vercel-log-quickstart.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=eef02e2b49c43aee744b06431900d37d 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3d27f2f8f59089ef66aefe0fc4aea1de 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=aa64ae73ab4daaa1532d1f0ec4b0f6f1 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d77bcfae328148308a73fb5651d53349 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=51de3010830efa5558a6a0018c0532bc 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel-log-quickstart.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=38c17b368f928e4e84a0266b52c9edb8 2500w" />
  </Frame>

  QStash

  <Frame>
    <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6c91cb9d180d8a4e3d6e7420e8d5f815" alt="Vercel Logs" data-og-width="2034" width="2034" data-og-height="650" height="650" data-path="img/qstash/quickstart-qstash-result.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5197cff2e8c3726ed4e0f7a8df50ca6e 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8cd1d3456f09b96489013d93086bf552 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3dd0bf0918c3cb8f6d9999943785454b 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6942e47bcacbdd8c59c745c92eba9d47 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=649dd318670c87d30f5138616cac7350 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/quickstart-qstash-result.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0f4a0564876d76c63c51b6b0e4cbd6b3 2500w" />
  </Frame>
</Accordion>

And the code for the 3 files we created:

<CodeGroup>
  ```tsx src/app/page.tsx theme={"system"}
  "use client"
  import { startBackgroundJob } from "@/app/actions";
  import { useState } from "react";

  export default function Home() {
  const [loading, setLoading] = useState(false);
  const [msg, setMsg] = useState("");

    async function handleClick() {
      setLoading(true);
      const messageId = await startBackgroundJob();
      if (messageId) {
        setMsg(`Started job with ID ${messageId}`);
      } else {
        setMsg("Failed to start background job");
      }
      setLoading(false);
    }

    return (
      <main className="flex flex-col h-lvh items-center justify-center">
        <button onClick={handleClick} disabled={loading} className="btn btn-primary w-1/2 h-56 bg-green-500 text-xl sm:text-3xl rounded-lg hover:bg-green-600 disabled:bg-gray-500">
          Start Background Job
        </button>

        {loading && <div className="text-2xl mt-8">Loading...</div>}
        {msg && <p className="text-center text-lg">{msg}</p>}
      </main>
    );

  }

  ```

  ```ts src/app/actions.ts theme={"system"}
  "use server"
  import { Client } from "@upstash/qstash";

  const qstashClient = new Client({
    token: process.env.QSTASH_TOKEN!,
  });

  export async function startBackgroundJob() {
    try {
      const response = await qstashClient.publishJSON({
        "url": "https://qstash-bg-job.vercel.app/api/long-task",
        body: {
          "hello": "world"
        }
      });
      return response.messageId;
    } catch (error) {
      console.error(error);
      return null;
    }
  }
  ```

  ```ts src/app/api/long-task/route.ts theme={"system"}
  import { verifySignatureAppRouter } from "@upstash/qstash/nextjs"

  async function handler(request: Request) {
    const data = await request.json()

    for (let i = 0; i < 10; i++) {
      await fetch("https://firstqstashmessage.requestcatcher.com/test", {
        method: "POST",
        body: JSON.stringify(data),
        headers: { "Content-Type": "application/json" },
      })
      await new Promise((resolve) => setTimeout(resolve, 500))
    }

    return Response.json({ success: true })
  }

  export const POST = verifySignatureAppRouter(handler)
  ```
</CodeGroup>

Now, go ahead and try it out for yourself! Try using some of the other features of QStash, like
[schedules](/qstash/features/schedules), [callbacks](/qstash/features/callbacks), and [URL Groups](/qstash/features/url-groups).


# Periodic Data Updates
Source: https://upstash.com/docs/qstash/recipes/periodic-data-updates



<Note>
  * Code:
    [Repository](https://github.com/upstash/qstash-examples/tree/main/periodic-data-updates)
  * App:
    [qstash-examples-periodic-data-updates.vercel.app](https://qstash-examples-periodic-data-updates.vercel.app)
</Note>

This recipe shows how to use QStash as a trigger for a Next.js api route, that
fetches data from somewhere and stores it in your database.

For the database we will use Redis because it's very simple to setup and is not
really the main focus of this recipe.

## What will be build?

Let's assume there is a 3rd party API that provides some data. One approach
would be to just query the API whenever you or your users need it, however that
might not work well if the API is slow, unavailable or rate limited.

A better approach would be to continuously fetch fresh data from the API and
store it in your database.

Traditionally this would require a long running process, that would continuously
call the API. With QStash you can do this inside your Next.js app and you don't
need to worry about maintaining anything.

For the purpose of this recipe we will build a simple app, that scrapes the
current Bitcoin price from a public API, stores it in redis and then displays a
chart in the browser.

## Setup

If you don't have one already, create a new Next.js project with
`npx create-next-app@latest --ts`.

Then install the required packages

```bash  theme={"system"}
npm install @upstash/qstash @upstash/redis
```

You can replace `@upstash/redis` with any kind of database client you want.

## Scraping the API

Create a new serverless function in `/pages/api/cron.ts`

````ts  theme={"system"}
import { NextApiRequest, NextApiResponse } from "next";
import { Redis } from "@upstash/redis";

import { verifySignature } from "@upstash/qstash/nextjs";

/**
 * You can use any database you want, in this case we use Redis
 */
const redis = Redis.fromEnv();

/**
 * Load the current bitcoin price in USD and store it in our database at the
 * current timestamp
 */
async function handler(_req: NextApiRequest, res: NextApiResponse) {
  try {
    /**
     * The API returns something like this:
     * ```json
     * {
     *   "USD": {
     *     "last": 123
     *   },
     *   ...
     * }
     * ```
     */
    const raw = await fetch("https://blockchain.info/ticker");
    const prices = await raw.json();
    const bitcoinPrice = prices["USD"]["last"] as number;

    /**
     * After we have loaded the current bitcoin price, we can store it in the
     * database together with the current time
     */
    await redis.zadd("bitcoin-prices", {
      score: Date.now(),
      member: bitcoinPrice,
    });

    res.send("OK");
  } catch (err) {
    res.status(500).send(err);
  } finally {
    res.end();
  }
}

/**
 * Wrap your handler with `verifySignature` to automatically reject all
 * requests that are not coming from Upstash.
 */
export default verifySignature(handler);

/**
 * To verify the authenticity of the incoming request in the `verifySignature`
 * function, we need access to the raw request body.
 */
export const config = {
  api: {
    bodyParser: false,
  },
};
````

## Deploy to Vercel

That's all we need to fetch fresh data. Let's deploy our app to Vercel.

You can either push your code to a git repository and deploy it to Vercel, or
you can deploy it directly from your local machine using the
[vercel cli](https://vercel.com/docs/cli).

For a more indepth tutorial on how to deploy to Vercel, check out this
[quickstart](/qstash/quickstarts/vercel-nextjs#4-deploy-to-vercel).

After you have deployed your app, it is time to add your secrets to your
environment variables.

## Secrets

Head over to [QStash](https://console.upstash.com/qstash) and copy the
`QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` to vercel's
environment variables. <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4a6b0a2d6462ad1263ca5a818d51f0c4" alt="" data-og-width="1936" width="1936" data-og-height="558" height="558" data-path="img/qstash/vercel_env.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=0a70241ecf06008c91890e8006bb112d 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8bb5ed05bd390dc9b65c90440a2af1eb 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=44d6710922737223fcbea2353e0ef3a7 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=781e9a6c1db30e1a8516eb57ab978d1d 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8415b3480935383e86ae88f9641e1be3 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/vercel_env.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=9c1bed9b4627fa7e247d5ed3a82022f7 2500w" />

If you are not using a custom database, you can quickly create a new
[Redis database](https://console.upstash.com/redis). Afterwards copy the
`UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to vercel.

In the near future we will update our
[Vercel integration](https://vercel.com/integrations/upstash) to do this for
you.

## Redeploy

To use the environment variables, you need to redeploy your app. Either with
`npx vercel --prod` or in the UI.

## Create cron trigger in QStash

The last part is to add the trigger in QStash. Go to
[QStash](https://console.upstash.com/qstash) and create a new schedule.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d2c7fdc9aa6649d1eabc215a22b2c5d8" alt="" data-og-width="1978" width="1978" data-og-height="1268" height="1268" data-path="img/qstash/schedule.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2b98f99aa0996910a67722f13fc7a5cc 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=f346055eb0a179a785dc4e7ad53893c1 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2a84cda9465fecd911bd05ecde8a65c4 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=311e881865a6b41e818f692e5cdab32d 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=932005b810d98335d0d956dc590caa06 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/qstash/schedule.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=10272ef5c53da0a67c2bc5fca78e310e 2500w" />

Now we will call your api function whenever you schedule is triggered.

## Adding frontend UI

This part is probably the least interesting and would require more dependencies
for styling etc. Check out the
[index.tsx](https://github.com/upstash/qstash-examples/blob/main/periodic-data-updates/pages/index.tsx)
file, where we load the data from the database and display it in a chart.

## Hosted example

You can find a running example of this recipe
[here](https://qstash-examples-periodic-data-updates.vercel.app/).


# DLQ
Source: https://upstash.com/docs/qstash/sdks/py/examples/dlq



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Get all messages with pagination using cursor

Since the DLQ can have a large number of messages, they are paginated.
You can go through the results using the `cursor`.

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

all_messages = []
cursor = None
while True:
    res = client.dlq.list(cursor=cursor)
    all_messages.extend(res.messages)
    cursor = res.cursor
    if cursor is None:
        break
```

#### Get a message from the DLQ

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
msg = client.dlq.get("<dlq-id>")
```

#### Delete a message from the DLQ

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.dlq.delete("<dlq-id>")
```


# Events
Source: https://upstash.com/docs/qstash/sdks/py/examples/events



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Get all events with pagination using cursor

Since there can be a large number of events, they are paginated.
You can go through the results using the `cursor`.

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

all_events = []
cursor = None
while True:
    res = client.event.list(cursor=cursor)
    all_events.extend(res.events)
    cursor = res.cursor
    if cursor is None:
        break
```


# Keys
Source: https://upstash.com/docs/qstash/sdks/py/examples/keys



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Retrieve your signing Keys

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
signing_key = client.signing_key.get()

print(signing_key.current, signing_key.next)
```

#### Rotate your signing Keys

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
new_signing_key = client.signing_key.rotate()

print(new_signing_key.current, new_signing_key.next)
```


# Messages
Source: https://upstash.com/docs/qstash/sdks/py/examples/messages



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

Messages are removed from the database shortly after they're delivered, so you
will not be able to retrieve a message after. This endpoint is intended to be used
for accessing messages that are in the process of being delivered/retried.

#### Retrieve a message

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
msg = client.message.get("<msg-id>")
```

#### Cancel/delete a message

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.cancel("<msg-id>")
```

#### Cancel messages in bulk

Cancel many messages at once or cancel all messages

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

# cancel more than one message
client.message.cancel_many(["<msg-id-0>", "<msg-id-1>"])

# cancel all messages
client.message.cancel_all()
```


# Overview
Source: https://upstash.com/docs/qstash/sdks/py/examples/overview



These are example usages of each method in the QStash SDK. You can also reference the
[examples repo](https://github.com/upstash/qstash-py/tree/main/examples) and [API examples](/qstash/overall/apiexamples) for more.


# Publish
Source: https://upstash.com/docs/qstash/sdks/py/examples/publish



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Publish to a URL with a 3 second delay and headers/body

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
res = client.message.publish_json(
    url="https://my-api...",
    body={
        "hello": "world",
    },
    headers={
        "test-header": "test-value",
    },
    delay="3s",
)

print(res.message_id)
```

#### Publish to a URL group with a 3 second delay and headers/body

You can make a URL group on the QStash console or using the [URL group API](/qstash/sdks/py/examples/url-groups)

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
res = client.message.publish_json(
    url_group="my-url-group",
    body={
        "hello": "world",
    },
    headers={
        "test-header": "test-value",
    },
    delay="3s",
)

# When publishing to a URL group, the response is an array of messages for each URL in the group
print(res[0].message_id)
```

#### Publish a method with a callback URL

[Callbacks](/qstash/features/callbacks) are useful for long running functions. Here, QStash will return the response
of the publish request to the callback URL.

We also change the `method` to `GET` in this use case so QStash will make a `GET` request to the `url`. The default
is `POST`.

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.publish_json(
    url="https://my-api...",
    body={
        "hello": "world",
    },
    callback="https://my-callback...",
    failure_callback="https://my-failure-callback...",
    method="GET",
)
```

#### Configure the number of retries

The max number of retries is based on your [QStash plan](https://upstash.com/pricing/qstash)

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.publish_json(
    url="https://my-api...",
    body={
        "hello": "world",
    },
    retries=1,
)
```

By default, the delay between retries is calculated using an exponential backoff algorithm. You can customize this using the `retryDelay` parameter. Check out [the retries page to learn more about custom retry delay values](/qstash/features/retry#custom-retry-delay).

#### Publish HTML content instead of JSON

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.publish(
    url="https://my-api...",
    body="<html><body><h1>Hello World</h1></body></html>",
    content_type="text/html",
)
```

#### Publish a message with [content-based-deduplication](/qstash/features/deduplication)

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.publish_json(
    url="https://my-api...",
    body={
        "hello": "world",
    },
    content_based_deduplication=True,
)
```

#### Publish a message with timeout

Timeout value to use when calling a url ([See `Upstash-Timeout` in Publish Message page](/qstash/api/publish#request))

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.message.publish_json(
    url="https://my-api...",
    body={
        "hello": "world",
    },
    timeout="30s",
)
```


# Queues
Source: https://upstash.com/docs/qstash/sdks/py/examples/queues



#### Create a queue with parallelism

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

queue_name = "upstash-queue"
client.queue.upsert(queue_name, parallelism=2)

print(client.queue.get(queue_name))
```

#### Delete a queue

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

queue_name = "upstash-queue"
client.queue.delete(queue_name)
```

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>

#### Pause/Resume a queue

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")

queue_name = "upstash-queue"
client.queue.upsert(queue_name, parallelism=1)

client.queue.pause(queue_name)

queue = client.queue.get(queue_name)
print(queue.paused) # prints True

client.queue.resume(queue_name)
```

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>


# Receiver
Source: https://upstash.com/docs/qstash/sdks/py/examples/receiver



When receiving a message from QStash, you should [verify the signature](/qstash/howto/signature).
The QStash Python SDK provides a helper function for this.

```python  theme={"system"}
from qstash import Receiver

receiver = Receiver(
    current_signing_key="YOUR_CURRENT_SIGNING_KEY",
    next_signing_key="YOUR_NEXT_SIGNING_KEY",
)

# ... in your request handler

signature, body = req.headers["Upstash-Signature"], req.body

receiver.verify(
    body=body,
    signature=signature,
    url="YOUR-SITE-URL",
)
```


# Schedules
Source: https://upstash.com/docs/qstash/sdks/py/examples/schedules



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Create a schedule that runs every 5 minutes

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
schedule_id = client.schedule.create(
    destination="https://my-api...",
    cron="*/5 * * * *",
)

print(schedule_id)
```

#### Create a schedule that runs every hour and sends the result to a [callback URL](/qstash/features/callbacks)

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.schedule.create(
    destination="https://my-api...",
    cron="0 * * * *",
    callback="https://my-callback...",
    failure_callback="https://my-failure-callback...",
)
```

#### Create a schedule to a URL group that runs every minute

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.schedule.create(
    destination="my-url-group",
    cron="0 * * * *",
)
```

#### Get a schedule by schedule id

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
schedule = client.schedule.get("<schedule-id>")

print(schedule.cron)
```

#### List all schedules

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
all_schedules = client.schedule.list()

print(all_schedules)
```

#### Delete a schedule

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.schedule.delete("<schedule-id>")
```

#### Create a schedule with timeout

Timeout value to use when calling a schedule URL ([See `Upstash-Timeout` in Create Schedule page](/qstash/api/schedules/create)).

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
schedule_id = client.schedule.create(
    destination="https://my-api...",
    cron="*/5 * * * *",
    timeout="30s",
)

print(schedule_id)
```

#### Pause/Resume a schedule

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
schedule_id = "scd_1234"

client.schedule.pause(schedule_id)

schedule = client.schedule.get(schedule_id)
print(schedule.paused) # prints True

client.schedule.resume(schedule_id)
```


# URL Groups
Source: https://upstash.com/docs/qstash/sdks/py/examples/url-groups



<Info>
  You can run the async code by importing `AsyncQStash` from `qstash`
  and awaiting the methods.
</Info>

#### Create a URL group and add 2 endpoints

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.url_group.upsert_endpoints(
    url_group="my-url-group",
    endpoints=[
        {"url": "https://my-endpoint-1"},
        {"url": "https://my-endpoint-2"},
    ],
)
```

#### Get URL group by name

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
url_group = client.url_group.get("my-url-group")

print(url_group.name, url_group.endpoints)
```

#### List URL groups

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
all_url_groups = client.url_group.list()

for url_group in all_url_groups:
    print(url_group.name, url_group.endpoints)
```

#### Remove an endpoint from a URL group

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.url_group.remove_endpoints(
    url_group="my-url-group",
    endpoints=[
        {"url": "https://my-endpoint-1"},
    ],
)
```

#### Delete a URL group

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH-TOKEN>")
client.url_group.delete("my-url-group")
```


# Getting Started
Source: https://upstash.com/docs/qstash/sdks/py/gettingstarted



## Install

### PyPI

```bash  theme={"system"}
pip install qstash
```

## Get QStash token

Follow the instructions [here](/qstash/overall/getstarted) to get your QStash token and signing keys.

## Usage

#### Synchronous Client

```python  theme={"system"}
from qstash import QStash

client = QStash("<QSTASH_TOKEN>")
client.message.publish_json(...)
```

#### Asynchronous Client

```python  theme={"system"}
import asyncio

from qstash import AsyncQStash


async def main():
    client = AsyncQStash("<QSTASH_TOKEN>")
    await client.message.publish_json(...)


asyncio.run(main())
```

#### RetryConfig

You can configure the retry policy of the client by passing the configuration to the client constructor.

Note: This isn for sending the request to QStash, not for the retry policy of QStash.

The default number of retries is **5** and the default backoff function is `lambda retry_count: math.exp(retry_count) * 50`.

You can also pass in `False` to disable retrying.

```python  theme={"system"}
from qstash import QStash

client = QStash(
    "<QSTASH_TOKEN>",
    retry={
        "retries": 3,
        "backoff": lambda retry_count: (2**retry_count) * 20,
    },
)
```


# Overview
Source: https://upstash.com/docs/qstash/sdks/py/overview



`qstash` is an Python SDK for QStash, allowing for easy access to the QStash API.

Using `qstash` you can:

* Publish a message to a URL/URL group/API
* Publish a message with a delay
* Schedule a message to be published
* Access logs for the messages that have been published
* Create, read, update, or delete URL groups.
* Read or remove messages from the [DLQ](/qstash/features/dlq)
* Read or cancel messages
* Verify the signature of a message

You can find the Github Repository [here](https://github.com/upstash/qstash-py).


# DLQ
Source: https://upstash.com/docs/qstash/sdks/ts/examples/dlq



#### Get all messages with pagination using cursor

Since the DLQ can have a large number of messages, they are paginated.
You can go through the results using the `cursor`.

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client("<QSTASH_TOKEN>");
const dlq = client.dlq;
const all_messages = [];
let cursor = null;
while (true) {
  const res = await dlq.listMessages({ cursor });
  all_messages.push(...res.messages);
  cursor = res.cursor;
  if (!cursor) {
    break;
  }
}
```

#### Delete a message from the DLQ

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const dlq = client.dlq;
await dlq.delete("dlqId");
```


# Logs
Source: https://upstash.com/docs/qstash/sdks/ts/examples/logs



#### Get all logs with pagination using cursor

Since there can be a large number of logs, they are paginated.
You can go through the results using the `cursor`.

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const logs = [];
let cursor = null;
while (true) {
  const res = await client.logs({ cursor });
  logs.push(...res.logs);
  cursor = res.cursor;
  if (!cursor) {
    break;
  }
}
```

#### Filter logs by state and only return the first 50.

<Info>
  More filters can be found in the [API Reference](/qstash/api/events/list).
</Info>

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.logs({ 
  filter: {
    state: "DELIVERED",
    count: 50
  }
});
```


# Messages
Source: https://upstash.com/docs/qstash/sdks/ts/examples/messages



Messages are removed from the database shortly after they're delivered, so you
will not be able to retrieve a message after. This endpoint is intended to be used
for accessing messages that are in the process of being delivered/retried.

#### Retrieve a message

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const messages = client.messages
const msg = await messages.get("msgId");
```

#### Cancel/delete a message

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const messages = client.messages
const msg = await messages.delete("msgId");
```

#### Cancel messages in bulk

Cancel many messages at once or cancel all messages

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });

// deleting two messages at once
await client.messages.deleteMany([
  "message-id-1",
  "message-id-2",
])


// deleting all messages
await client.messages.deleteAll()
```


# Overview
Source: https://upstash.com/docs/qstash/sdks/ts/examples/overview



These are example usages of each method in the QStash SDK. You can also reference the
[examples repo](https://github.com/upstash/sdk-qstash-ts/tree/main/examples) and [API examples](/qstash/overall/apiexamples) for more.


# Publish
Source: https://upstash.com/docs/qstash/sdks/ts/examples/publish



#### Publish to a URL with a 3 second delay and headers/body

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  url: "https://my-api...",
  body: { hello: "world" },
  headers: { "test-header": "test-value" },
  delay: "3s",
});
```

#### Publish to a URL group with a 3 second delay and headers/body

You create URL group on the QStash console or using the [URL Group API](/qstash/sdks/ts/examples/url-groups#create-a-url-group-and-add-2-endpoints)

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  urlGroup: "my-url-group",
  body: { hello: "world" },
  headers: { "test-header": "test-value" },
  delay: "3s",
});

// When publishing to a URL Group, the response is an array of messages for each URL in the URL Group
console.log(res[0].messageId);
```

#### Publish a method with a callback URL

[Callbacks](/qstash/features/callbacks) are useful for long running functions. Here, QStash will return the response
of the publish request to the callback URL.

We also change the `method` to `GET` in this use case so QStash will make a `GET` request to the `url`. The default
is `POST`.

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  url: "https://my-api...",
  body: { hello: "world" },
  callback: "https://my-callback...",
  failureCallback: "https://my-failure-callback...",
  method: "GET",
});
```

#### Configure the number of retries

The max number of retries is based on your [QStash plan](https://upstash.com/pricing/qstash)

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  url: "https://my-api...",
  body: { hello: "world" },
  retries: 1,
});
```

By default, the delay between retries is calculated using an exponential backoff algorithm. You can customize this using the `retry_delay` parameter. Check out [the retries documentation to learn more about custom retry delay values](/qstash/features/retry#custom-retry-delay).

#### Publish HTML content instead of JSON

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publish({
  url: "https://my-api...",
  body: "<html><body><h1>Hello World</h1></body></html>",
  headers: {
    "Content-Type": "text/html",
  },
});
```

#### Publish a message with [content-based-deduplication](/qstash/features/deduplication)

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  url: "https://my-api...",
  body: { hello: "world" },
  contentBasedDeduplication: true,
});
```

#### Publish a message with timeout

Timeout value in seconds to use when calling a url ([See `Upstash-Timeout` in Publish Message page](/qstash/api/publish#request))

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const res = await client.publishJSON({
  url: "https://my-api...",
  body: { hello: "world" },
  timeout: "30s" // 30 seconds timeout
});
```


# Queues
Source: https://upstash.com/docs/qstash/sdks/ts/examples/queues



#### Create a queue with parallelism 2

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";
const client = new Client({ token: "<QSTASH_TOKEN>" });

const queueName = "upstash-queue";
await client.queue({ queueName }).upsert({ parallelism: 2 });

const queueDetails = await client.queue({ queueName }).get();
```

#### Delete Queue

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";
const client = new Client({ token: "<QSTASH_TOKEN>" });

const queueName = "upstash-queue";
await client.queue({ queueName: queueName }).delete();
```

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>

#### Pause/Resume a queue

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";
const client = new Client({ token: "<QSTASH_TOKEN>" });

const name = "upstash-pause-resume-queue";
const queue = client.queue({ queueName: name });
await queue.upsert({ parallelism: 1 });

// pause queue
await queue.pause();

const queueInfo = await queue.get();
console.log(queueInfo.paused); // prints true

// resume queue
await queue.resume();
```

<Warning>
  Resuming or creating a queue may take up to a minute.
  Therefore, it is not recommended to pause or delete a queue during critical operations.
</Warning>


# Receiver
Source: https://upstash.com/docs/qstash/sdks/ts/examples/receiver



When receiving a message from QStash, you should [verify the signature](/qstash/howto/signature).
The QStash Typescript SDK provides a helper function for this.

```typescript  theme={"system"}
import { Receiver } from "@upstash/qstash";

const receiver = new Receiver({
  currentSigningKey: "YOUR_CURRENT_SIGNING_KEY",
  nextSigningKey: "YOUR_NEXT_SIGNING_KEY",
});

// ... in your request handler

const signature = req.headers["Upstash-Signature"];
const body = req.body;

const isValid = await receiver.verify({
  body,
  signature,
  url: "YOUR-SITE-URL",
});
```


# Schedules
Source: https://upstash.com/docs/qstash/sdks/ts/examples/schedules



#### Create a schedule that runs every 5 minutes

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.create({
  destination: "https://my-api...",
  cron: "*/5 * * * *",
});
```

#### Create a schedule that runs every hour and sends the result to a [callback URL](/qstash/features/callbacks)

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.create({
  destination: "https://my-api...",
  cron: "0 * * * *",
  callback: "https://my-callback...",
  failureCallback: "https://my-failure-callback...",
});
```

#### Create a schedule to a URL Group that runs every minute

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.create({
  destination: "my-url-group",
  cron: "* * * * *",
});
```

#### Get a schedule by schedule id

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });

const res = await client.schedules.get("scheduleId");
console.log(res.cron);
```

#### List all schedules

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const allSchedules = await client.schedules.list();
console.log(allSchedules);
```

#### Create/overwrite a schedule with a user chosen schedule id

Note that if a schedule exists with the same id, the old one will be discarded
and new schedule will be used.

```typescript Typescript theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.create({
  destination: "https://example.com",
  scheduleId: "USER_PROVIDED_SCHEDULE_ID",
  cron: "* * * * *",
});
```

#### Delete a schedule

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.delete("scheduleId");
```

#### Create a schedule with timeout

Timeout value in seconds to use when calling a schedule URL ([See `Upstash-Timeout` in Create Schedule page](/qstash/api/schedules/create)).

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.schedules.create({
  url: "https://my-api...",
  cron: "* * * * *",
  timeout: "30" // 30 seconds timeout
});
```

#### Pause/Resume a schedule

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";
const client = new Client({ token: "<QSTASH_TOKEN>" });
const scheduleId = "my-schedule"

// pause schedule
await client.schedules.pause({ schedule: scheduleId });

// check if paused
const result = await client.schedules.get(scheduleId);
console.log(getResult.isPaused) // prints true

// resume schedule
await client.schedules.resume({ schedule: scheduleId });
```


# URL Groups
Source: https://upstash.com/docs/qstash/sdks/ts/examples/url-groups



#### Create a URL Group and add 2 endpoints

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const urlGroups = client.urlGroups;
await urlGroups.addEndpoints({
  name: "url_group_name",
  endpoints: [
    { url: "https://my-endpoint-1" },
    { url: "https://my-endpoint-2" },
  ],
});
```

#### Get URL Group by name

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const urlGroups = client.urlGroups;
const urlGroup = await urlGroups.get("urlGroupName");
console.log(urlGroup.name, urlGroup.endpoints);
```

#### List URL Groups

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const allUrlGroups = await client.urlGroups.list();
for (const urlGroup of allUrlGroups) {
  console.log(urlGroup.name, urlGroup.endpoints);
}
```

#### Remove an endpoint from a URL Group

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const urlGroups = client.urlGroups;
await urlGroups.removeEndpoints({
  name: "urlGroupName",
  endpoints: [{ url: "https://my-endpoint-1" }],
});
```

#### Delete a URL Group

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const urlGroups = client.urlGroups;
await urlGroups.delete("urlGroupName");
```


# Getting Started
Source: https://upstash.com/docs/qstash/sdks/ts/gettingstarted



## Install

### NPM

```bash  theme={"system"}
npm install @upstash/qstash
```

## Get QStash token

Follow the instructions [here](/qstash/overall/getstarted) to get your QStash token and signing keys.

## Usage

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({
  token: "<QSTASH_TOKEN>",
});
```

#### RetryConfig

You can configure the retry policy of the client by passing the configuration to the client constructor.

Note: This is for sending the request to QStash, not for the retry policy of QStash.

The default number of attempts is **6** and the default backoff function is `(retry_count) => (Math.exp(retry_count) * 50)`.

You can also pass in `false` to disable retrying.

```typescript  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({
  token: "<QSTASH_TOKEN>",
  retry: {
    retries: 3,
    backoff: retry_count => 2 ** retry_count * 20,
  },
});
```

## Telemetry

This sdk sends anonymous telemetry headers to help us improve your experience.
We collect the following:

* SDK version
* Platform (Cloudflare, AWS or Vercel)
* Runtime version ([node@18.x](mailto:node@18.x))

You can opt out by setting the `UPSTASH_DISABLE_TELEMETRY` environment variable
to any truthy value. Or setting `enableTelemetry: false` in the client options.

```ts  theme={"system"}
const client = new Client({
  token: "<QSTASH_TOKEN>",
  enableTelemetry: false,
});
```


# Overview
Source: https://upstash.com/docs/qstash/sdks/ts/overview



`@upstash/qstash` is a Typescript SDK for QStash, allowing for easy access to the QStash API.

Using `@upstash/qstash` you can:

* Publish a message to a URL/URL Group
* Publish a message with a delay
* Schedule a message to be published
* Access logs for the messages that have been published
* Create, read, update, or delete URL groups.
* Read or remove messages from the [DLQ](/qstash/features/dlq)
* Read or cancel messages
* Verify the signature of a message

You can find the Github Repository [here](https://github.com/upstash/sdk-qstash-ts).


# Channels
Source: https://upstash.com/docs/realtime/features/channels



Channels allow you to scope events to specific people or rooms. For example:

* Chat rooms
* Emitting events to a specific user

## Default Channel

By default, events are sent to the `default` channel. If we emit an event without specifying a channel like so:

```typescript  theme={"system"}
await realtime.emit("notification.alert", "hello world!")
```

it can automatically be read using the default channel:

```typescript  theme={"system"}
useRealtime<RealtimeEvents>({
  event: "notification.alert",
  onData(data, channel) {
    // 100% type-safe data handling
  },
})
```

***

## Custom Channels

Emit events to a specific channel:

```typescript route.ts theme={"system"}
const channel = realtime.channel("user-123")

await channel.emit("notification.alert", "hello world!")
```

Subscribe to one or more channels:

```tsx page.tsx  highlight={8} theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  useRealtime<RealtimeEvents>({
    channels: ["user-123"],
    event: "notification.alert",
    onData(data, channel) {
      // 100% type-safe data handling
    },
  })

  return <>...</>
}
```

## Channel Patterns

<AccordionGroup>
  <Accordion title="User-Specific Channels">
    Send notifications to individual users:

    ```typescript route.ts theme={"system"}
    const channel = realtime.channel(`user-${userId}`)

    await channel.emit("notification.alert", "hello world!")
    ```

    ```typescript page.tsx theme={"system"}
    useRealtime<RealtimeEvents>({
      channels: [`user-${user.id}`],
      event: "notification.alert",
      onData: (data, channel) => {}
    })
    ```
  </Accordion>

  <Accordion title="Room-Based Channels">
    Broadcast to all users in a room:

    ```typescript route.ts theme={"system"}
    await realtime.channel(`room-${roomId}`).emit("room.message", {
      text: "Hello everyone!",
      sender: "Alice"
    })
    ```
  </Accordion>

  <Accordion title="Team Workspaces">
    Scope events to team workspaces:

    ```typescript route.ts theme={"system"}
    await realtime.channel(`team-${teamId}`).emit("project.update", {
      project: "Website Redesign",
      status: "In Progress"
    })
    ```
  </Accordion>
</AccordionGroup>

## Dynamic Channels

Subscribe to multiple channels at the same time:

```tsx page.tsx theme={"system"}
"use client"

import { useState } from "react"
import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  const [channels, setChannels] = useState<string[]>(["lobby"])

  useRealtime<RealtimeEvents>({
    channels,
    event: "chat.message",
    onData(data, channel) {
      console.log(`Message from ${channel}:`, data)
    },
  })

  const joinRoom = (roomId: string) => {
    setChannels((prev) => [...prev, roomId])
  }

  const leaveRoom = (roomId: string) => {
    setChannels((prev) => prev.filter((c) => c !== roomId))
  }

  return (
    <div>
      <p>Active channels: {channels.join(", ")}</p>
      <button onClick={() => joinRoom("room-1")}>Join Room 1</button>
      <button onClick={() => joinRoom("room-2")}>Join Room 2</button>
      <button onClick={() => leaveRoom("lobby")}>Leave Lobby</button>
    </div>
  )
}
```

## Broadcasting to Multiple Channels

Emit to multiple channels at the same time:

```typescript route.ts theme={"system"}
const rooms = ["lobby", "room-1", "room-2"]

await Promise.all(
  rooms.map((room) => {
    const channel = realtime.channel(room)
    return channel.emit("chat.message", `Hi channel ${room}!`)
  })
)
```

## Channel Security

Combine channels with [middleware](/realtime/features/middleware) for secure access control:

```typescript title="app/api/realtime/route.ts" theme={"system"}
import { handle } from "@upstash/realtime"
import { realtime } from "@/lib/realtime"
import { currentUser } from "@/auth"

export const GET = handle({
  realtime,
  middleware: async ({ request, channels }) => {
    const user = await currentUser(request)

    for (const channel of channels) {
      if (!user.canAccessChannel(channel)) {
        return new Response("Unauthorized", { status: 401 })
      }
    }
  },
})
```

<Card title="Authenticate Realtime Requests" icon="shield" href="/realtime/features/middleware">
  See the middleware documentation for authentication examples
</Card>


# Client-Side Usage
Source: https://upstash.com/docs/realtime/features/client-side



The `useRealtime` hook connects your React components to realtime events with full type safety.

## Basic Usage

Subscribe to events in any client component:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  useRealtime<RealtimeEvents>({
    event: "notification.alert",
    onData(data, channel) {
      console.log("Received:", data)
    },
  })

  return <p>Listening for events...</p>
}
```

## Hook Options

<ParamField path="event" type="string" required>
  The event to subscribe to (e.g. `"notification.alert"`)
</ParamField>

<ParamField path="onData" type="function" required>
  Callback when an event is received. Receives `data` and `channel` as arguments.
</ParamField>

<ParamField path="channels" type="string[]" default="[&#x22;default&#x22;]">
  Array of channel names to subscribe to
</ParamField>

<ParamField path="history" type="boolean | object" default="false">
  * `true`: Fetch all available history
  * `{ length: number }`: Fetch the last N messages
  * `{ since: number }`: Fetch messages after a Unix timestamp (in milliseconds)
</ParamField>

<ParamField path="enabled" type="boolean" default="true">
  Whether the connection is active. Set to `false` to disconnect.
</ParamField>

<ParamField path="maxReconnectAttempts" type="number" default="3">
  Maximum number of reconnection attempts before giving up
</ParamField>

<ParamField path="api" type="object" default="{ url: &#x22;/api/realtime&#x22;, withCredentials: false }">
  API configuration: - `url`: The realtime endpoint URL, defaults to `/api/realtime` -
  `withCredentials`: Whether to send cookies with requests (useful for external backends)
</ParamField>

## Return Value

The hook returns an object with:

<ResponseField name="status" type="ConnectionStatus">
  Current connection state: `"connecting"`, `"connected"`, `"reconnecting"`,
  `"disconnected"`, or `"error"`
</ResponseField>

```tsx page.tsx theme={"system"}
const { status } = useRealtime<RealtimeEvents>({
  event: "notification.alert",
  onData: (data, channel) => {},
})

console.log(status)
```

## Connection Control

Enable or disable connections dynamically:

```tsx page.tsx theme={"system"}
"use client"

import { useState } from "react"
import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  const [enabled, setEnabled] = useState(true)

  const { status } = useRealtime<RealtimeEvents>({
    enabled,
    event: "notification.alert",
    onData: (data, channel) => {
      console.log(data, channel)
    },
  })

  return (
    <div>
      <button onClick={() => setEnabled((prev) => !prev)}>
        {enabled ? "Disconnect" : "Connect"}
      </button>

      <p>Status: {status}</p>
    </div>
  )
}
```

### Conditional Connections

Connect only when certain conditions are met:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"
import { useUser } from "@/hooks/auth"

export default function Page() {
  const { user } = useUser()

  useRealtime<RealtimeEvents>({
    enabled: Boolean(user),
    channels: [`user-${user.id}`],
    event: "notification.alert",
    onData: (data, channel) => {
      console.log(data)
    },
  })

  return <p>Notifications {user ? "enabled" : "disabled"}</p>
}
```

## Multiple Channels

Subscribe to multiple channels at once:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  useRealtime<RealtimeEvents>({
    channels: ["global", "announcements", "user-123"],
    event: "notification.alert",
    onData(data, channel) {
      console.log(`Message from ${channel}:`, data)
    },
  })

  return <p>Listening to multiple channels</p>
}
```

### Dynamic Channel Management

Add and remove channels dynamically:

```tsx page.tsx theme={"system"}
"use client"

import { useState } from "react"
import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  const [channels, setChannels] = useState<string[]>(["lobby"])

  useRealtime<RealtimeEvents>({
    channels,
    event: "chat.message",
    onData(data, channel) {
      console.log(`Message from ${channel}:`, data)
    },
  })

  const joinRoom = (roomId: string) => {
    setChannels((prev) => [...prev, roomId])
  }

  const leaveRoom = (roomId: string) => {
    setChannels((prev) => prev.filter((c) => c !== roomId))
  }

  return (
    <div>
      <p>Active channels: {channels.join(", ")}</p>
      <button onClick={() => joinRoom("room-1")}>Join Room 1</button>
      <button onClick={() => joinRoom("room-2")}>Join Room 2</button>
      <button onClick={() => leaveRoom("lobby")}>Leave Lobby</button>
    </div>
  )
}
```

## Fetch History on Connection

Replay past messages when connecting:

```tsx page.tsx theme={"system"}
"use client"

import { useState } from "react"
import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function ChatRoom() {
  const [messages, setMessages] = useState<string[]>([])

  useRealtime<RealtimeEvents>({
    event: "chat.message",
    history: { length: 50 },
    onData(data, channel) {
      // each history item is automatically passed to this handler
      // so you can replay with any logic you like
      setMessages((prev) => [...prev, data])
    },
  })

  return (
    <div>
      {messages.map((msg, i) => (
        <p key={i}>{msg}</p>
      ))}
    </div>
  )
}
```

## Custom API Endpoint

Configure a custom realtime endpoint:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  useRealtime<RealtimeEvents>({
    event: "notification.alert",
    api: {
      url: "/api/custom-realtime",
      withCredentials: true,
    },
    onData: (data, channel) => {
      console.log(data)
    },
  })

  return <p>Connected to custom endpoint</p>
}
```

## Use Cases

<AccordionGroup>
  <Accordion title="Live Notifications">
    Show real-time notifications to users:

    ```tsx notifications.tsx theme={"system"}
    "use client"

    import { useState } from "react"
    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"
    import { toast } from "react-hot-toast"
    import { useUser } from "@/hooks/auth"

    export default function Notifications() {
      const { user } = useUser()

      useRealtime<RealtimeEvents>({
        channels: [`user-${user.id}`],
        event: "notification.alert",
        onData(content, channel) {
          toast(content)
        },
      })

      return <p>Listening for notifications...</p>
    }
    ```
  </Accordion>

  <Accordion title="Realtime Chat">
    Build a real-time chat:

    ```tsx chat.tsx theme={"system"}
    "use client"

    import { useState } from "react"
    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"
    import z from "zod/v4"

    type Message = z.infer<RealtimeEvents["chat"]["message"]>

    export default function Chat() {
      const [messages, setMessages] = useState<Message[]>([])

      useRealtime<RealtimeEvents>({
        channels: ["room-123"],
        event: "chat.message",
        history: true,
        onData(message, channel) {
          setMessages((prev) => [...prev, message])
        },
      })

      return (
        <div>
          {messages.map((msg, i) => (
            <p key={i}>
              <span className="font-bold">{msg.sender}:</span> {msg.text}
            </p>
          ))}
        </div>
      )
    }
    ```
  </Accordion>

  <Accordion title="Live Dashboard">
    Update metrics in real-time:

    ```tsx dashboard.tsx theme={"system"}
    "use client"

    import { useQuery, useQueryClient } from "@tanstack/react-query"
    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"

    export default function Dashboard() {
      const queryClient = useQueryClient()
      
      const { data: metrics } = useQuery({
        queryKey: ["metrics"],
        queryFn: async () => {
          const res = await fetch("/api/metrics?user=user-123")
          return res.json()
        },
      })

      useRealtime<RealtimeEvents>({
        channels: ["user-123"],
        event: "metrics.update",
        onData() {
          // üëá invalidate, so react-query refetches
          queryClient.invalidateQueries({ queryKey: ["metrics"] })
        },
      })

      return (
        <div>
          <p>Active Users: {metrics.users}</p>
          <p>Revenue: ${metrics.revenue}</p>
        </div>
      )
    }
    ```
  </Accordion>

  <Accordion title="Collaborative Editing">
    Sync changes across users:

    ```tsx editor.tsx theme={"system"}
    "use client"

    import { useState } from "react"
    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"

    export default function Editor({ documentId }: { documentId: string }) {
      const [content, setContent] = useState("")

      useRealtime<RealtimeEvents>({
        channels: [`doc-${documentId}`],
        event: "document.update",
        history: { length: 1 },
        onData(data, channel) {
          setContent(data.content)
        },
      })

      return <textarea value={content} onChange={(e) => setContent(e.target.value)} />
    }
    ```
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Channels" icon="tower-broadcast" href="/realtime/features/channels">
    Scope events to specific rooms or users
  </Card>

  <Card title="History" icon="clock-rotate-left" href="/realtime/features/history">
    Configure message retention and replay
  </Card>
</CardGroup>


# History
Source: https://upstash.com/docs/realtime/features/history



Message history allows you to retrieve past events and replay them to clients on connection. This is useful for making sure clients always have the latest state.

## Overview

All Upstash Realtime messages are automatically stored in Redis Streams. This way, messages are always delivered correctly, even after reconnects or network interruptions.

Clients can fetch past events and optionally subscribe to new events.

## Configuration

```typescript lib/realtime.ts theme={"system"}
import { Realtime } from "@upstash/realtime"
import { redis } from "./redis"
import z from "zod/v4"

const schema = {
  chat: {
    message: z.object({
      text: z.string(),
      sender: z.string(),
    }),
  },
}

export const realtime = new Realtime({
  schema,
  redis,
  // üëá (optional) per-channel history settings.
  history: {
    maxLength: 100,
    expireAfterSecs: 86400,
  },
})
```

<ParamField path="maxLength" type="number" default="Infinite">
  Maximum number of messages to retain per channel. Example: `maxLength: 100` will keep
  the last 100 messages in the stream and automatically remove older messages as new ones
  are added.
</ParamField>

<ParamField path="expireAfterSecs" type="number" default="Infinite">
  How long to keep messages per channel before deleting them (in seconds). Resets every
  time a message is emitted to this channel.
</ParamField>

## Client Usage

Get history on connection:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Page() {
  useRealtime<RealtimeEvents>({
    event: "chat.message",
    history: true,
    onData(data, channel) {
      console.log("Historical or new message:", data)
    },
  })

  return <>...</>
}
```

### History Options

<ParamField path="history" type="boolean | object">
  * `true`: Fetch all available history
  * `{ length: number }`: Fetch the last N messages
  * `{ since: number }`: Fetch messages after a Unix timestamp (in milliseconds)
</ParamField>

```tsx page.tsx theme={"system"}
useRealtime<RealtimeEvents>({
  event: "chat.message",
  history: {
    length: 50,
  },
  onData(data, channel) {},
})
```

```tsx page.tsx theme={"system"}
const ONE_DAY_IN_MS = 60 * 60 * 24 * 1000
const oneDayAgo = Date.now() - ONE_DAY_IN_MS

useRealtime<RealtimeEvents>({
  event: "chat.message",
  history: {
    since: oneDayAgo,
  },
  onData(data, channel) {},
})
```

You can also use both `length` and `since` together.

## Server-Side History

Retrieve and process history on the server:

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

export const GET = async () => {
  const channel = realtime.channel("room-123")
  const messages = await channel.history({ length: 50 })

  return new Response(JSON.stringify(messages))
}
```

### Subscribe to new messages with history

You can automatically replay past messages when subscribing to a channel. See the [Server-Side Usage](/realtime/features/server-side) documentation for more details.

```typescript route.ts theme={"system"}
await realtime
  .channel("room-123")
  .history({ length: 50 })
  .on("chat.message", (data) => {
    console.log("Message from room-123:", data)
  })
```

## Use Cases

<AccordionGroup>
  <Accordion title="Chat Application">
    Load recent messages when a user joins a room:

    <Info>We recommend keeping long chat histories in a database (e.g. Redis) and only fetching the latest messages from Upstash Realtime.</Info>

    ```tsx page.tsx theme={"system"}
    "use client"

    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"
    import { useState } from "react"
    import z from "zod/v4"

    type Message = z.infer<RealtimeEvents["chat"]["message"]>

    export default function ChatRoom({ roomId }: { roomId: string }) {
      const [messages, setMessages] = useState<Message[]>([])

      useRealtime<RealtimeEvents>({
        channels: [roomId],
        event: "chat.message",
        history: true,
        onData(data, channel) {
          setMessages((prev) => [...prev, data])
        },
      })

      return (
        <div>
          {messages.map((msg, i) => (
            <div key={i}>
              <strong>{msg.sender}:</strong> {msg.text}
            </div>
          ))}
        </div>
      )
    }
    ```
  </Accordion>

  <Accordion title="Notification Center">
    Show unread notifications with history:

    ```tsx notifications.tsx theme={"system"}
    "use client"

    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"
    import { useUser } from "@/hooks/auth"
    import { useState } from "react"

    type Notification = z.infer<RealtimeEvents["notification"]["alert"]>

    export default function Notifications() {
      const user = useUser()
      const [notifications, setNotifications] = useState<Notification[]>([])

      useRealtime<RealtimeEvents>({
        channels: [`user-${user.id}`],
        event: "notification.alert",
        history: true,
        onData(notification, channel) {
         if(notification.status === "unread") {
           setNotifications((prev) => [...prev, notification])
         }
        },
      })

      return (
        <div>
          {notifications.map((notif, i) => (
            <div key={i}>{notif}</div>
          ))}
        </div>
      )
    }
    ```
  </Accordion>

  <Accordion title="Live Activity Feed">
    Replay recent activity when users visit:

    ```tsx activity-feed.tsx theme={"system"}
    "use client"

    import { useRealtime } from "@upstash/realtime/client"
    import type { RealtimeEvents } from "@/lib/realtime"
    import { useTeam } from "@/hooks/team"
    import { useState } from "react"
    import z from "zod/v4"

    type Activity = z.infer<RealtimeEvents["activity"]["update"]>

    export default function ActivityFeed() {
      const team = useTeam()
      const [activities, setActivities] = useState<Activity[]>([])

      useRealtime<RealtimeEvents>({
        channels: [`team-${team.id}`],
        event: "activity.update",
        history: { length: 100 },
        onData(data, channel) {
          setActivities((prev) => [data, ...prev])
        },
      })

      return (
        <div>
          {activities.map((activity, i) => (
            <div key={i}>{activity.message}</div>
          ))}
        </div>
      )
    }
    ```
  </Accordion>
</AccordionGroup>

## How It Works

1. When you emit an event, it's stored in a Redis Stream with a unique stream ID
2. The stream is trimmed to `maxLength` if configured
3. The stream expires after `expireAfterSecs` if configured
4. On connection, clients request history via query parameters
5. History is replayed in chronological order (oldest to newest)
6. New events continue streaming right after history replay, no messages lost

## Performance Considerations

Upstash Realtime can handle extremely large histories without problems. The bottleneck is the client who needs to handle all replayed events.

At that point you should probably consider using a database like Redis or Postgres to fetch the history once, then stream new events to the client with Upstash Realtime.

<AccordionGroup>
  <Accordion title="Limit History Length">
    For high-volume channels, limit history to prevent large initial payloads.

    ```typescript lib/realtime.ts theme={"system"}
    export const realtime = new Realtime({
      schema,
      redis,
      history: {
        maxLength: 1000,
      },
    })
    ```
  </Accordion>

  <Accordion title="Set Expiration">
    Expire old messages to reduce storage:

    ```typescript lib/realtime.ts theme={"system"}
    export const realtime = new Realtime({
      schema,
      redis,
      history: {
        expireAfterSecs: 3600,
      },
    })
    ```
  </Accordion>

  <Accordion title="Fetch on Demand">
    For less critical features, fetch history only when needed:

    ```tsx page.tsx theme={"system"}
    const [showHistory, setShowHistory] = useState(false)

    useRealtime<RealtimeEvents>({
      event: "chat.message",
      history: showHistory ? { length: 50 } : false,
      onData(data, channel) {},
    })
    ```
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Server-Side Usage" icon="server" href="/realtime/features/server-side">
    Stream history and subscribe to events on the server
  </Card>

  <Card title="Channels" icon="tower-broadcast" href="/realtime/features/channels">
    Scope history to specific rooms or users
  </Card>
</CardGroup>


# Authentication
Source: https://upstash.com/docs/realtime/features/middleware



Protect your realtime endpoints with custom auth logic.

## Basic Middleware

```typescript api/realtime/route.ts theme={"system"}
import { handle } from "@upstash/realtime"
import { realtime } from "@/lib/realtime"
import { currentUser } from "@/auth"

export const GET = handle({
  realtime,
  middleware: async ({ request, channels }) => {
    // channels: the channels a user is attempting to connect to
    // default: ["default"]

    const user = await currentUser(request)

    if (!user) {
      return new Response("Unauthorized", { status: 401 })
    }
  },
})
```

## Middleware API

The middleware function receives:

<ParamField path="request" type="Request">
  The incoming HTTP Request object
</ParamField>

<ParamField path="channels" type="string[]" default="['default']">
  The channels a user is attempting to connect to
</ParamField>

<ResponseField name="return">
  * Return `undefined` or nothing to allow the connection - Return a `Response` object to
    block the connection with a custom error
</ResponseField>

## Authentication Patterns

<AccordionGroup>
  <Accordion title="User-Based Auth">
    Verify users can access specific channels:

    ```typescript api/realtime/route.ts theme={"system"}
    export const GET = handle({
      realtime,
      middleware: async ({ request, channels }) => {
        const user = await currentUser(request)

        for (const channel of channels) {
          // üëá optional: allow access to the default channel
          if(channel === "default") {
            continue
          }

          if (!channel.startsWith(user.id)) {
            return new Response("You can only access your own channels", { status: 403 })
          }
        }
      },
    })
    ```
  </Accordion>

  <Accordion title="Session-Based Auth">
    Verify user sessions before allowing connections:

    ```typescript api/realtime/route.ts theme={"system"}
    import { getSession } from "@/auth"

    export const GET = handle({
      realtime,
      middleware: async ({ request }) => {
        const session = await getSession(request)

        if (!session?.user) {
          return new Response("Please sign in", { status: 401 })
        }
      },
    })
    ```
  </Accordion>

  <Accordion title="Role-Based Access">
    Control access based on user roles:

    ```typescript api/realtime/route.ts theme={"system"}
    export const GET = handle({
      realtime,
      middleware: async ({ request, channels }) => {
        const user = await currentUser(request)

        for (const channel of channels) {
          // üëá optional: allow access to the default channel
          if(channel === "default") {
            continue
          }

          if (channel.startsWith("admin-") && user.role !== "admin") {
            return new Response("Admin access required", { status: 403 })
          }

          if (channel.startsWith("team-")) {
            const teamId = channel.replace("team-", "")
            const isMember = await checkTeamMembership(user.id, teamId)

            if (!isMember) {
              return new Response("Not a team member", { status: 403 })
            }
          }
        }
      },
    })
    ```
  </Accordion>
</AccordionGroup>


# Server-Side Usage
Source: https://upstash.com/docs/realtime/features/server-side



Use Upstash Realtime on the server to subscribe to events, retrieve message history, and stream updates to clients.

## Subscribe to Events

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

const channel = realtime.channel("notifications")

await channel.on("notification.alert", (data) => {
  console.log("New notification:", data)
})
```

Subscribe to multiple events:

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

const channel = realtime.channel("room-123")

await Promise.all([
  channel.on("chat.message", (data) => {
    console.log("New message:", data)
  }),
  channel.on("user.joined", (data) => {
    console.log("User joined:", data)
  }),
])
```

## Retrieve History

Fetch past messages from a channel:

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

export const GET = async () => {
  const channel = realtime.channel("room-123")
  const messages = await channel.history({ length: 50 })

  return new Response(JSON.stringify(messages))
}
```

### History Options

<ParamField path="length" type="number">
  Number of messages to retrieve (starting from most recent)
</ParamField>

<ParamField path="since" type="number">
  Fetch messages by Unix timestamp (inclusive, in milliseconds)
</ParamField>

```typescript route.ts theme={"system"}
const messages = await channel.history({
  length: 100,
  since: Date.now() - 86400000,
})
```

## Subscribe with History

Replay past messages and continue subscribing to new ones:

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

const channel = realtime.channel("room-123")

await channel
  .history({ length: 50 })
  .on("chat.message", (data) => {
    console.log("Message:", data)
  })
```

This pattern:

1. Fetches the last 50 messages
2. Replays them in chronological order
3. Continues to listen for new messages

## Stream to Clients

Stream historical and new messages to clients using Server-Sent Events:

```typescript app/api/stream/route.ts highlight={13-19} theme={"system"}
import { realtime } from "@/lib/realtime"

export const GET = async (req: Request) => {
  const { searchParams } = new URL(req.url)
  const channelId = searchParams.get("channel")

  if (!channelId) {
    return new Response("Channel ID required", { status: 400 })
  }

  const channel = realtime.channel(channelId)

  const stream = new ReadableStream({
    async start(controller) {
      await channel.history().on("notification.alert", (data) => {
        controller.enqueue(`data: ${JSON.stringify(data)}\n\n`)
      })
    },
  })

  return new Response(stream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
    },
  })
}
```

### Handle Disconnections

Clean up subscriptions when a client disconnects:

```typescript app/api/stream/route.ts highlight={18-20,23-25} theme={"system"}
import { realtime } from "@/lib/realtime"

export const GET = async (req: Request) => {
  const { searchParams } = new URL(req.url)
  const channelId = searchParams.get("channel")

  if (!channelId) {
    return new Response("Channel ID required", { status: 400 })
  }

  const channel = realtime.channel(channelId)

  const stream = new ReadableStream({
    async start(controller) {
      await channel.history().on("task.update", (data) => {
        controller.enqueue(`data: ${JSON.stringify(data)}\n\n`)

        if (data.status === "completed" || data.status === "failed") {
          controller.close()
        }
      })

      req.signal.addEventListener("abort", () => {
        controller.close()
      })
    },
  })

  return new Response(stream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
    },
  })
}
```

## Use Cases

<AccordionGroup>
  <Accordion title="Background Jobs">
    Stream progress updates from long-running tasks:

    ```typescript app/api/job/route.ts theme={"system"}
    import { realtime } from "@/lib/realtime"

    export const POST = async (req: Request) => {
      const { jobId } = await req.json()
      const channel = realtime.channel(jobId)

      await channel.emit("job.started", { progress: 0 })

      for (let i = 0; i <= 100; i += 10) {
        await processChunk()
        await channel.emit("job.progress", { progress: i })
      }

      await channel.emit("job.completed", { progress: 100 })

      return new Response("OK")
    }
    ```

    Stream updates to the client:

    ```typescript app/api/job/stream/route.ts theme={"system"}
    import { realtime } from "@/lib/realtime"

    export const GET = async (req: Request) => {
      const { searchParams } = new URL(req.url)
      const jobId = searchParams.get("id")

      const channel = realtime.channel(jobId)

      const stream = new ReadableStream({
        async start(controller) {
          await channel.history().on("job.progress", (data) => {
            controller.enqueue(`data: ${JSON.stringify(data)}\n\n`)

            if (data.progress === 100) {
              controller.close()
            }
          })
        },
      })

      return new Response(stream, {
        headers: { "Content-Type": "text/event-stream" },
      })
    }
    ```
  </Accordion>

  <Accordion title="Event Processing">
    Process events with server-side logic:

    ```typescript route.ts theme={"system"}
    import { realtime } from "@/lib/realtime"
    import { sendEmail } from "@/lib/email"

    const channel = realtime.channel("notifications")

    await channel.on("notification.alert", async (data) => {
      if (data.priority === "high") {
        await sendEmail({
          to: data.userId,
          subject: "Urgent Notification",
          body: data.message,
        })
      }
    })
    ```
  </Accordion>

  <Accordion title="Multi-Channel Broadcasting">
    Emit events to multiple channels:

    ```typescript route.ts theme={"system"}
    import { realtime } from "@/lib/realtime"

    export const POST = async (req: Request) => {
      const { teamIds, message } = await req.json()

      await Promise.all(
        teamIds.map((teamId: string) =>
          realtime.channel(`team-${teamId}`).emit("announcement", message)
        )
      )

      return new Response("Broadcast sent")
    }
    ```
  </Accordion>

  <Accordion title="Webhook Processing">
    Forward webhook events to realtime channels:

    ```typescript app/api/webhook/route.ts theme={"system"}
    import { realtime } from "@/lib/realtime"

    export const POST = async (req: Request) => {
      const payload = await req.json()

      const channel = realtime.channel(`user-${payload.userId}`)
      await channel.emit("webhook.received", payload)

      return new Response("OK")
    }
    ```
  </Accordion>
</AccordionGroup>

## Emit Events

Emit events from any server context:

```typescript route.ts theme={"system"}
import { realtime } from "@/lib/realtime"

export const POST = async () => {
  await realtime.emit("notification.alert", "hello world!")

  return new Response("OK")
}
```

Emit to specific channels:

```typescript route.ts highlight={4-5} theme={"system"}
import { realtime } from "@/lib/realtime"

export const POST = async () => {
  const channel = realtime.channel("user-123")
  await channel.emit("notification.alert", "hello world!")

  return new Response("OK")
}
```

## Next Steps

<CardGroup cols={2}>
  <Card title="History" icon="clock-rotate-left" href="/realtime/features/history">
    Configure message retention and expiration
  </Card>

  <Card title="Channels" icon="tower-broadcast" href="/realtime/features/channels">
    Scope events to specific rooms or users
  </Card>
</CardGroup>


# Deployment
Source: https://upstash.com/docs/realtime/features/serverless



<Note>
  Deploy Upstash Realtime to providers that bill **based on active CPU time**. Great places to
  deploy are

  * Vercel with Fluid Compute enabled
  * Cloudflare
  * Railway
  * A personal VPS
  * any other service that does not bill based on connection duration.
</Note>

## Deploying to Vercel

To deploy Upstash Realtime to Vercel, [enable Fluid Compute](https://vercel.com/docs/fluid-compute#enable-for-entire-project) for your project. For new projects, this is enabled by default.

Fluid Compute allows for less cold-starts, has much higher function timeouts compared to serverless functions, and most importantly **only bills for active CPU time**.

That way, you're only billed for actual message processing time, not connection duration.

<Frame>
  <img src="https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=8e435be20d9e2df4a8614a298e1d9045" data-og-width="1585" width="1585" data-og-height="876" height="876" data-path="img/realtime/vercel-fluid-enabled.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=280&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=ed2ded1fa339a85100951f28e538c954 280w, https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=560&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=74a48de000159e68adf24dcc73845ec5 560w, https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=840&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=4a3dd60fc3da2ca6f9dad002a08ce8b7 840w, https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=1100&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=5a7c25e835f3b1476cdf8c96ac6ca059 1100w, https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=1650&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=35a68e28e8417005b96dcbaff89ce952 1650w, https://mintcdn.com/upstash/IhGKcftpCFCMbFa7/img/realtime/vercel-fluid-enabled.png?w=2500&fit=max&auto=format&n=IhGKcftpCFCMbFa7&q=85&s=23e2da2c9842686b61dc50879ac4cd9b 2500w" />
</Frame>

## Billing Example

Traditional serverless connection billing:

```plaintext Serverless Billing theme={"system"}
Connection duration: 5 minutes
Billing: 5 minutes = $$$
```

Upstash Realtime with fluid compute:

```plaintext Fluid Compute Billing theme={"system"}
Connection duration: 5 minutes
Active processing: 2 seconds
Billing: 2 seconds x CPU cost = $
```

## Automatic Reconnection

The client automatically reconnects before your function timeout:

```tsx page.tsx theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import { RealtimeEvents } from "@/lib/realtime"

export default function Component() {
  // üëá 'connecting' | 'connected' | 'reconnecting' | 'disconnected'
  const { status } = useRealtime<RealtimeEvents>({
    event: "notification.alert",
    onData: (data, channel) => {}
  })

  return <p>Status: {status}</p>
}
```

## Message Delivery Guarantee

Upstash Realtime is powered by Redis Streams, so no message is ever delivered twice or gets lost. Every message is guaranteed to be delivered exactly once.

1. Client establishes connection and subscribes to stream
2. Client initiates reconnection before function timeout (default every 5 mins)
3. Redis auto-replays all messages sent during reconnect


# Quickstart
Source: https://upstash.com/docs/realtime/overall/quickstart



Upstash Realtime is the easiest way to add realtime features to any Next.js project.

<Frame>
  <img src="https://raw.githubusercontent.com/upstash/realtime/refs/heads/main/public/thumbnail.png" alt="Upstash Realtime" />
</Frame>

## Why Upstash Realtime?

* ‚è∞ Setup takes 60 seconds
* üß® Clean APIs & first-class TypeScript support
* ‚ö° Extremely fast, zero dependencies, 1.9kB gzipped
* üíª Deploy anywhere: Vercel, Netlify, etc.
* üíé 100% type-safe with zod 4 or zod mini
* ‚è±Ô∏è Built-in message histories
* üîå Automatic connection management w/ delivery guarantee
* üîã Built-in middleware and authentication helpers
* üì∂ 100% HTTP-based: Redis streams & SSE

***

## Quickstart

Get Upstash Realtime running in your Next.js app in under 60 seconds.

### 1. Installation

<CodeGroup>
  ```bash npm theme={"system"}
  npm install @upstash/realtime
  ```

  ```bash yarn theme={"system"}
  yarn add @upstash/realtime
  ```

  ```bash pnpm theme={"system"}
  pnpm add @upstash/realtime
  ```

  ```bash bun theme={"system"}
  bun install @upstash/realtime
  ```
</CodeGroup>

### 2. Configure Upstash Redis

Upstash Realtime is powered by Redis Streams. Grab your credentials from the [Upstash Console](https://console.upstash.com).

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4530264625c10bdf334129ec8b367511" width="100%" data-og-width="1590" data-og-height="1080" data-path="img/getting_started/database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=729b8c0843969c86866b06e22747c785 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d44be677d29134227ff6839fbfc10674 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=414a590eb3c8ed98001a5a781a6268bf 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eca30f6532a78f7f25952b41beac50d5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e60ccc845ab5a2a2b4fb9d66ac0fe948 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b999e96686847b5aeeebc960cf2d5a30 2500w" />
</Frame>

Add them to your environment variables:

```bash title=".env" theme={"system"}
UPSTASH_REDIS_REST_URL=https://striking-osprey-20681.upstash.io
UPSTASH_REDIS_REST_TOKEN=AVDJAAIjcDEyZ...
```

And lastly, create a Redis instance:

```typescript title="lib/redis.ts" theme={"system"}
import { Redis } from "@upstash/redis"

export const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN,
})
```

### 3. Define Event Schema

Define the structure of realtime events in your app:

```typescript title="lib/realtime.ts" theme={"system"}
import { Realtime, InferRealtimeEvents } from "@upstash/realtime"
import { redis } from "./redis"
import z from "zod/v4"

const schema = {
  notification: {
    alert: z.string(),
  },
}

export const realtime = new Realtime({ schema, redis })
export type RealtimeEvents = InferRealtimeEvents<typeof realtime>
```

### 4. Create Realtime Route Handler

Create a route handler at `api/realtime/route.ts`:

```typescript title="app/api/realtime/route.ts" theme={"system"}
import { handle } from "@upstash/realtime"
import { realtime } from "@/lib/realtime"

export const GET = handle({ realtime })
```

### 5. Emit Events

From any server component, server action, API route:

```typescript title="app/api/notify/route.ts" theme={"system"}
import { realtime } from "@/lib/realtime"

export const POST = async () => {
  // üëá event name and data are 100% type-safe
  await realtime.emit("notification.alert", "hello world!")

  return new Response("OK")
}
```

### 6. Subscribe to Events

In any client component:

```tsx title="app/components/notifications.tsx" theme={"system"}
"use client"

import { useRealtime } from "@upstash/realtime/client"
import type { RealtimeEvents } from "@/lib/realtime"

export default function Notifications() {
  useRealtime<RealtimeEvents>({
    event: "notification.alert",
    onData(data, channel) {
      // 100% type-safe
    },
  })

  return <p>Listening for events...</p>
}
```

That's it! Your app is now listening for realtime events with full type safety. üéâ

## Next Steps

<CardGroup cols={2}>
  <Card title="Client-Side Usage" icon="react" href="/realtime/features/client-side">
    Complete guide to the useRealtime hook
  </Card>

  <Card title="Server-Side Usage" icon="server" href="/realtime/features/server-side">
    Subscribe to events and stream updates on the server
  </Card>

  <Card title="Channels" icon="tower-broadcast" href="/realtime/features/channels">
    Scope events to specific rooms or channels
  </Card>

  <Card title="History" icon="clock-rotate-left" href="/realtime/features/history">
    Fetch and replay past messages
  </Card>
</CardGroup>


# Examples Index
Source: https://upstash.com/docs/redis/examples

List of all Upstash Examples

TODO: fahreddin
import TagFilters from "../../src/components/Filter.js"

<TagFilters>
  <TagFilters.Item externalLink type="Article" tags={["Svelte"]} url="https://blog.upstash.com/sveltekit-todo-redis">
    SvelteKit TODO App with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Strapi"]} url="https://blog.upstash.com/redis-strapi">
    Serverless Redis Caching for Strapi
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Blitz.js"]} url="https://blog.upstash.com/blitzjs-todo-redis">
    To-Do List with Blitz.js & Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Chalice", "Slackbot"]} url="https://blog.upstash.com/chalice-event-reminder-slackbot">
    Slackbot with AWS Chalice and Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Render"]} url="https://blog.upstash.com/render-serverless-redis">
    Using Render with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Slackbot", "Vercel"]} url="https://blog.upstash.com/vercel-note-taker-slackbot">
    Slackbot with Vercel and Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Slackbot", "Vercel"]} url="https://blog.upstash.com/vercel-note-taker-slackbot">
    Slackbot with Vercel and Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Remix", "Cloudflare Workers"]} url="https://blog.upstash.com/fast_websites_with_Remix_on_Cloudflare_and_Upstash_Redis">
    Remix on Cloudflare with Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Remix"]} url="https://blog.upstash.com/remix-todo-redis">
    Remix TODO App with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["GraphQL", "Netlify"]} url="https://blog.upstash.com/netlify-graph-upstash">
    Global Cache for Netlify Graph with Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js", "NextAuth"]} url="https://blog.upstash.com/next-auth-serverless-redis">
    Next.js Authentication with NextAuth and Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js"]} url="https://blog.upstash.com/survey-serverless-redis">
    Building a Survey App with Upstash Redis and Next.js
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["React Native", "Mobile"]} url="https://blog.upstash.com/serverless-react-native">
    Building React Native Apps Backed by AWS Lambda and Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Remix", "Node.js"]} url="https://blog.upstash.com/redis-with-remix">
    Using Upstash Redis with Remix
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Remix", "Node.js"]} url="https://blog.upstash.com/redis-session-remix">
    Using Upstash Redis as a Session Store for Remix
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["REST-API", "Backendless"]} url="https://docs.upstash.com/redis/tutorials/notification">
    Building a Serverless Notification API for Your Web Application with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS App Runner", "Node.js"]} url="https://docs.upstash.com/redis/tutorials/aws_app_runner_with_redis">
    Build Stateful Applications with AWS App Runner and Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Google Cloud"]} url="https://docs.upstash.com/redis/tutorials/cloud_run_sessions">
    Session Management on Google Cloud Run with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Cloudflare Workers", "upstash-redis", "REST-API"]} url="https://docs.upstash.com/redis/tutorials/cloudflare_workers_with_redis">
    Use Redis in Cloudflare Workers
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Fastly Compute", "upstash-redis", "REST-API"]} url="https://blog.upstash.com/fastly-compute-edge-with-redis">
    Use Redis in Fastly Compute
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Cloudflare Workers"]} url="https://docs.upstash.com/redis/tutorials/edge_leaderboard">
    Build a Leaderboard API at Edge Using Cloudflare Workers and Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "Node.js"]} url="https://docs.upstash.com/redis/tutorials/job_processing">
    Job Processing and Event Queue with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "Node.js"]} url="https://docs.upstash.com/redis/tutorials/rate-limiting">
    AWS Lambda Rate Limiting with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "Node.js"]} url="https://docs.upstash.com/redis/tutorials/histogram">
    Build a Serverless Histogram API with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "Node.js"]} url="https://docs.upstash.com/redis/tutorials/auto_complete_with_serverless_redis">
    Autocomplete API with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js", "Vercel"]} url="https://docs.upstash.com/redis/tutorials/roadmapvotingapp">
    Roadmap Voting App with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js"]} url="https://blog.upstash.com/survey-serverless-redis">
    Building a Survey App with Upstash Redis only
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Google Cloud"]} url="https://docs.upstash.com/redis/tutorials/using_google_cloud_functions">
    Serverless Redis on Google Cloud Functions
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/using_serverless_framework">
    Using Serverless Framework
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/using_aws_sam">
    Using AWS SAM
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/api_with_cdk">
    Deploy a Serverless API with AWS CDK and AWS Lambda
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Node.js"]} url="https://docs.upstash.com/redis/tutorials/express_session">
    Express Session with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js"]} url="https://docs.upstash.com/redis/tutorials/nextjs_with_redis">
    Next.js with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Nuxt.js"]} url="https://docs.upstash.com/redis/tutorials/nuxtjs_with_redis">
    Nuxt.js with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Java", "AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/serverless_java_redis">
    Serverless API with Java and Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Go", "AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/goapi">
    Serverless Golang API with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Python", "AWS Lambda"]} url="https://docs.upstash.com/redis/tutorials/pythonapi">
    Serverless Python API with Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Java"]} url="https://docs.upstash.com/redis/tutorials/redisson">
    Serverless Redisson
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Svelte", "Netlify"]} url="https://blog.upstash.com/svelte-with-serverless-redis">
    Building SvelteKit Applications with Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Cloudflare Workers", "upstash-redis", "REST-API"]} url="https://blog.upstash.com/cloudflare-workers-waiting-room">
    Build Your Own Waiting Room for Your Website with Cloudflare Workers and
    Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "Mobile", "Flutter"]} url="https://blog.upstash.com/serverless-with-flutter">
    Fullstack Serverless App with Flutter, Serverless Framework and
    Upstash(REDIS) - PART 1
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js Edge", "Next.js", "Vercel"]} url="https://blog.upstash.com/getstarted-nextjs-edge-with-redis">
    Getting Started with Next.js Edge Functions
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js Edge", "Next.js", "Vercel"]} url="https://blog.upstash.com/nextjs-edge-waiting-room">
    Waiting Room for Your Next.js App Using Edge Functions
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Benchmark"]} url="https://blog.upstash.com/serverless-database-benchmark">
    Serverless Battleground - DynamoDB vs Firestore vs MongoDB vs Cassandra vs
    Redis vs FaunaDB
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["AWS Lambda", "REST-API"]} url="https://blog.upstash.com/aws-lambda-redis-rest">
    Stateful AWS Lambda with Redis REST
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["REST-API"]} url="https://blog.upstash.com/pipeline">
    Pipeline REST API on Serverless Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Next.js", "Vercel", "REST-API"]} url="https://blog.upstash.com/nextjs-todo">
    The Most Minimalist Next.js TODO App
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Cloudflare Workers", "REST-API"]} url="https://blog.upstash.com/edge-guard">
    Implement IP Allow/Deny List at Edge with Cloudflare Workers and Upstash
    Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Cloudflare Workers"]} url="https://blog.upstash.com/redis-cloudflare-workers">
    Redis @ Edge with Cloudflare Workers
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js", "Vercel"]} url="https://www.youtube.com/watch?v=FytxaSVQROc">
    Using Serverless Redis with Next.js
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js"]} url="https://www.youtube.com/watch?v=sBiUqozxY4o">
    Building a Cache with Upstash Redis in Next.js
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js Edge", "Next.js", "Vercel"]} url="https://www.youtube.com/watch?v=hu2SrILiEgE">
    Vercel Edge Function URL Shortener with Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js"]} url="https://www.youtube.com/watch?v=S1oOlKQo8CY">
    Adding Feature Flags to Next.js (Upstash Redis, SWR, Hooks)
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js"]} url="https://www.youtube.com/watch?v=_opoQpUMqF4">
    Rate Limiting Your Serverless Functions with Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Next.js"]} url="https://www.youtube.com/watch?v=1Dotv9T7nIs">
    Create a React Scoreboard with Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Go", "AWS Lambda"]} url="https://www.youtube.com/watch?v=EJ6CJ0GC9lk">
    Upstash on AWS Lambda Using Golang
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Cloudflare Workers"]} url="https://www.youtube.com/watch?v=g6hGJcuscoM">
    IP Address Allow/Deny with Cloudflare Workers and Upstash Redis
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Video" tags={["Vercel", "Next.js Edge"]} url="https://www.youtube.com/watch?v=yuxd2kurpzk&t=968s">
    Edge Functions Explained with Kelsey Hightower and Lee Robinson - (Next.js
    Conf 2021)
  </TagFilters.Item>

  <TagFilters.Item externalLink type="Article" tags={["Elixir"]} url="https://docs.upstash.com/redis/tutorials/elixir_with_redis">
    Elixir with Redis
  </TagFilters.Item>
</TagFilters>


# Auto Upgrade
Source: https://upstash.com/docs/redis/features/auto-upgrade



By default, Upstash will apply usage limits based on your current plan. When you reach these limits, behavior depends on the specific limit type - bandwidth limits will throttle your traffic, while storage limits will reject new write operations. However, Upstash offers an Auto Upgrade feature that automatically upgrades your database to the next higher plan when you reach your usage limits, ensuring uninterrupted service.

Auto Upgrade is particularly useful for applications with fluctuating or growing workloads, as it prevents service disruptions during high-traffic periods or when your data storage needs expand beyond your current plan. This feature allows your database to automatically scale with your application's demands without requiring manual intervention.

## How Auto Upgrade Works

When enabled:

* For **bandwidth limits**: Instead of throttling your traffic when you reach the bandwidth limit, your database will automatically upgrade to the next plan to accommodate the increased traffic.
* For **storage limits**: Instead of rejecting write operations when you reach maximum data size, your database will upgrade to a plan with larger storage capacity.

## Managing Auto Upgrade

* You can enable Auto Upgrade by checking the Auto Upgrade checkbox while creating a new database:

  <Frame>
    <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=77910a547dc9bbabe9ee23fde1a6e54a" width="%50" data-og-width="908" data-og-height="1282" data-path="img/auto-upgrade/create-database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3129a3e3490d16840c059f4b12844d7e 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=dc9f6faa2689de66edcd4ac6f87ed482 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c070e76e2a574304a1938d6934989bc5 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=98c8df116e6d16ea6b594269a435546e 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4b4478c5dbbd1411028a2d1553cd86dc 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/create-database.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0cf052d33b65104a7399b5321e5cdf06 2500w" />
  </Frame>

* Or for an existing database by clicking Enable in the Configuration/Auto Upgrade box in the database details page:
  <Frame>
    <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=dc1a10f8e4285f3a326852ab2f7e2c35" width="600" height="300" data-og-width="1598" data-og-height="916" data-path="img/auto-upgrade/configuration.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=7c1a4f8a08eb4fb8ff726262df3daf99 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5a8ff8da59fccf5dba745bde9f670590 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3b5c10c4282cbb4008119d74666299a9 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e22ff5287b7ffc7ee7dc84157bb0e7ea 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=ebb37808da50f640d5d3d43f049cfde6 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/auto-upgrade/configuration.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=cf7a1c28cfade1a05c162b926fcaa4d2 2500w" />
  </Frame>


# Backup/Restore
Source: https://upstash.com/docs/redis/features/backup



You can create a manual backup of your database and restore that backup to any of your databases. Both backup and restore operations require that your database is in one of the AWS regions.

Additionally, you can utilize the daily backup feature to automatically create backups of your database on a daily basis.

### Create A Manual Backup

To create a manual backup of your database:

* Go to the database details page and navigate to the `Backups` tab

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0fc546f743bdb77b3e003f9cf1cbacf1" width="800" data-og-width="885" data-og-height="473" data-path="img/backuprestore/backuptab.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=40895bfb6190be782e5c37724f5b4bf7 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5e6fc8771720267e891aabdb02ec3232 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a313cb647ee9a94d4a8467ab04f7f4b2 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=87d10052079d834e213f7e3d8c131de6 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=dc5f3677bbaa816928eeb54ef8a90c1d 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptab.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=99cd36e9bc57f918800f2fcafda7a5cb 2500w" />
</Frame>

* Click on the `Backup` button and fill in a name for your backup. **Your backup name must be unique.**
* Then click on the `Create` button.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bb329420779fd6700e45ca1733be4360" width="600" data-og-width="544" data-og-height="263" data-path="img/backuprestore/backupmodal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4719feb0fa4951f76798c3642af825dc 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=457c88dd4e57f1d49fac8a5e4abf9eb6 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0fdd04b60d618a0957b80dae6dfb18e3 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9e3d6db3afbdd708f35baf784797a876 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e08fc748f34f93ad5ddff1b930aa07c3 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupmodal.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4bf13ed7341fbc39dd697318a4b01f56 2500w" />
</Frame>

During the process of creating a backup for your database, it is important to note that your database will be temporarily locked, which means these operations will be unavailable during this time:

* Create Database Backup
* Enable TLS
* Move Database to Team
* Restore Database Backup
* Update Eviction
* Update Password
* Delete Database

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6d6c07d95ee5a7454e0c8e211c3476f6" width="800" data-og-width="1035" data-og-height="492" data-path="img/backuprestore/backupinprogressscreen.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=8718d6ddb01ae1f16244a96a826635be 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=afb5b7fa562d7e68a77c24c5dc987a3b 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=058397de1c75bd0ecf3114ca3158f4d6 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=00b83b578bb7e14455cf922f74677e73 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=aa755c478c391a361dae3f622cd91227 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backupinprogressscreen.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b802850bbf2152fde81d81c238a3b70b 2500w" />
</Frame>

### Restore A Backup

To restore a backup that was created from your current database, follow the steps below:

* Go to the database details page and navigate to the `Backups` tab
* Click on the `Restore` button next to the backup record listed.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=40d627e5cd687455b0becbfae97eb3d3" width="800" data-og-width="1020" data-og-height="415" data-path="img/backuprestore/backuptabdailyenabled.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fd2de7c4f9b2f24473f74c9ac3cbe2f6 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=710f6de85d63d7961ff1dab81ea2ad59 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=2a7d5252b75242813deee6ee7a498bf6 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=01fd05412906015fc7aa5e67d33ddb1c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=11368f5f74aa1893e5979b4efec6ced1 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e43725ecf184c2c75dd0c67637ff27b5 2500w" />
</Frame>

* Click on `Restore`. **Be aware of the fact that your target database will be flushed with this operation.**

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1965caef45339b88c3e0a208abce4366" width="700" data-og-width="724" data-og-height="523" data-path="img/backuprestore/restorebackupfromcurrentdatabase.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bf7fec0c2a3051ab22af1f9e1e6800ea 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c3706c3b3d7e83be685a29724bc250dc 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bf0087e49e0347ffeea8d4921615f509 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=dd663f032b742a3003729670bb2e0d94 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1c57fd10f2dd39248e388d943e7a95ea 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupfromcurrentdatabase.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d50832d92cfc592e40d26d267eb0cc78 2500w" />
</Frame>

### Restore A Backup From Another Database

To restore a backup that was created from one of your databases other than the current one, follow the steps below:

* Go to the database details page and navigate to the `Backups` tab
* Click on the `Restore...` button

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=40d627e5cd687455b0becbfae97eb3d3" width="800" data-og-width="1020" data-og-height="415" data-path="img/backuprestore/backuptabdailyenabled.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fd2de7c4f9b2f24473f74c9ac3cbe2f6 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=710f6de85d63d7961ff1dab81ea2ad59 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=2a7d5252b75242813deee6ee7a498bf6 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=01fd05412906015fc7aa5e67d33ddb1c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=11368f5f74aa1893e5979b4efec6ced1 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e43725ecf184c2c75dd0c67637ff27b5 2500w" />
</Frame>

* Select the source database, referring to the database from which the backup was generated.
* Select the backup record that you want to restore to the current database.
* Click on `Start Restore`. **Be aware of the fact that your target database will be flushed with this operation.**

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4fb9163488e04b207de89d4d0d4870e4" width="700" data-og-width="749" data-og-height="525" data-path="img/backuprestore/restorebackupmodal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f52cc22791ec090798708d13465ad16c 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c50177d4ae0a3c53a39c7c45738585c3 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=cf57a498a3e4d17f3e6779b86944fdf4 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=706017a05bb4a68cd0fc73f153140135 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6548fa295b5a642ba81da2b0369cf229 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/restorebackupmodal.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=17132459f602a815c2e84287d2bccf5c 2500w" />
</Frame>

### Enable Daily Automated Backup

To enable daily automated backup for your database:

* Go to the database details page and navigate to the `Backups` tab

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b2fe0e0e7f8b9b23b1ec5fd4c9df1807" width="800" data-og-width="1027" data-og-height="404" data-path="img/backuprestore/backuptabwide.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b6358222859407014b3931a248a9fc25 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=254173a5df25bbc628486c3277a4280a 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f339443376b328e48b91df63e2471da0 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=11518960f63853e01c45fdec391951af 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=af4eb4ebaf53473026d24f6834a3fd0a 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabwide.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=24b3eeb6b2094a781be1087bf6a82d4d 2500w" />
</Frame>

* Enable the switch next to the `Daily Backup`
* Click on `Enable`

### Disable Daily Automated Backup

To disable the daily automated backup for your database, please follow the steps below:

* Go to the database details page and navigate to the `Backups` tab

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=40d627e5cd687455b0becbfae97eb3d3" width="800" data-og-width="1020" data-og-height="415" data-path="img/backuprestore/backuptabdailyenabled.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fd2de7c4f9b2f24473f74c9ac3cbe2f6 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=710f6de85d63d7961ff1dab81ea2ad59 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=2a7d5252b75242813deee6ee7a498bf6 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=01fd05412906015fc7aa5e67d33ddb1c 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=11368f5f74aa1893e5979b4efec6ced1 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/backuptabdailyenabled.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e43725ecf184c2c75dd0c67637ff27b5 2500w" />
</Frame>

* Disable the switch next to the `Daily Backup`
* Click on `Disable`

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c0246bd6bb8a3c5e9f383040f7159586" width="700" data-og-width="732" data-og-height="523" data-path="img/backuprestore/dailybackupdisablemodal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=28e5517e8292179ae735e2cf8afc7c50 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5be3d9a160c2948f115c26943888ea27 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1f321710a754b10b81d6e358ae3f3bf3 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e314a836e10bbbd1d3589e263ba97754 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=fc66da756cff1b257542eb9232c8a7e3 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/backuprestore/dailybackupdisablemodal.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9b96d510c5249fa2c392641d2964dc20 2500w" />
</Frame>


# Consistency
Source: https://upstash.com/docs/redis/features/consistency



Upstash utilizes a leader-based replication mechanism. Under this mechanism,
each key is assigned to a leader replica, which is responsible for handling
write operations on that key. The remaining replicas serve as backups to the
leader. When a write operation is performed on a key, it is initially processed
by the leader replica and then asynchronously propagated to the backup replicas.
This ensures that data consistency is maintained across the replicas. Reads can
be performed from any replica.

Each replica employs a failure detector to track liveness of the leader replica.
When the leader replica fails for a reason, remaining replicas start a new
leader election round and elect a new leader. This is the only unavailability
window for the cluster where *write* your requests can be blocked for a short
period of time. Also in case of cluster wide failures like network partitioning
(split brain); periodically running anti entropy jobs resolve the conflicts
using `Last-Writer-Wins` algorithm and converge the replicas to the same state.

This model gives a better write consistency and read scalability but can provide
only **Eventual Consistency**. Additionally you can achieve **Causal
Consistency** (`Read-Your-Writes`, `Monotonic-Reads`, `Monotonic-Writes` and
`Writes-Follow-Reads` guarantees) for a single Redis connection. (A TCP
connection forms a session between client and server).

Checkout [Read Your Writes](/redis/howto/readyourwrites) for more details on how to achieve RYW consistency.

Checkout [Replication](/redis/features/replication) for more details on Replication mechanism.

<Note>
  Previously, Upstash supported `Strong Consistency` mode for the single region
  databases. We decided to deprecate this feature because its effect on latency
  started to conflict with the performance expectations of Redis use cases. Also
  we are gradually moving to **CRDT** based Redis data structures, which will
  provide `Strong Eventual Consistency`.
</Note>


# Credential Protection
Source: https://upstash.com/docs/redis/features/credential-protection



Enabling Credential Protection ensures your database credentials are never stored within Upstash infrastructure. This enhances security by making credentials accessible only once‚Äîat the moment they are generated.

<Note>
  Credential Protection is a [Production
  Pack](/redis/overall/enterprise#prod-pack-features)
  feature.
</Note>

## How It Works

When enabled:

* Redis database credentials are no longer stored in Upstash infrastructure
* Credentials are displayed only once during enablement - save them immediately
* Console features requiring database access are disabled (CLI, Data Browser, Monitor, RBAC)

## Managing Credential Protection

1. Go to database details page ‚Üí Configuration section
2. Toggle **Protect Credentials** switch:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5b7d7f7ee9afb5756a3b4471de204e3b" data-og-width="1940" width="1940" data-og-height="1186" height="1186" data-path="img/credential-protection/activate-protect-credentials.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=aefd3ada4a92b2c7f61ce058d8f02ffe 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0676d401afb66615688c34b00b95cf11 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=82e2bd601d002a40cc228e61e8cff64b 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=350b009a0f235561a030dbda20fae342 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6f84c61bd72f0e226c586d816eb1f141 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/activate-protect-credentials.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=00306233061516ee98be27b5ecdfce29 2500w" />
</Frame>

3. Save the credentials shown in the modal:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=eadb65e7235715d1c5a0936f361e9891" data-og-width="1940" width="1940" data-og-height="1186" height="1186" data-path="img/credential-protection/save-credentials.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1c9605add0b9c26038a6f866229320a0 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d05000ee37970d2d1bd1f359ae899d24 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a6816d547836044aba1e359b3473782b 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=8c15437ace32b7c39f1ffe75cec8f730 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5364abfc3c5851966002b24de873b7e6 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/save-credentials.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=81ca238de02e2dd4f4c9e23b6e1a2ddc 2500w" />
</Frame>

<Warning>
  Disabling this feature will permanently revoke current credentials and
  generate new ones, potentially breaking applications using those credentials.
</Warning>

## What If You Lose Your Credentials

**Reset Credentials**: This function remains available and, when credential protection is enabled, will generate new protected credentials.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4ffe1d18790c44011d0071762aa29dbf" data-og-width="1940" width="1940" data-og-height="1186" height="1186" data-path="img/credential-protection/reset-credentials.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=8fa7381ae952be89f6467d6dd68baf5c 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b1b96c0d34d8d31d18e8b531574615fb 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=dc1650393305631314ad49d6fb4f6154 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bc187b7230cf775b4210fbb855d7a2ad 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0298210a8a6fb696b3387f1524fa4fc4 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/credential-protection/reset-credentials.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3016bbd6fc57290e0c93ee78feb38525 2500w" />
</Frame>


# Durable Storage
Source: https://upstash.com/docs/redis/features/durability

This article explains the persistence provided by Upstash databases.

In Upstash, persistence is always enabled, setting it apart from other Redis
offerings. Every write operation is consistently stored in both memory and the
block storage provided by cloud providers, such as AWS's EBS. This dual storage
approach ensures data durability. Read operations are optimized to first check
if the data exists in memory, facilitating faster access. If the data is not in
memory, it is retrieved from disk. This combination of memory and disk storage
in Upstash guarantees reliable data access and maintains data integrity, even
during system restarts or failures.

### Multi Tier Storage

Upstash keeps your data both in memory and disk. This design provides:

* Data safety with persistent storage
* Low latency with in memory access
* Price flexibility by using memory only for active data

In Upstash, an entry in memory is evicted if it remains idle, meaning it has not
been accessed for an extended period. It's important to note that eviction does
not result in data loss since the entry is still stored in the block storage.
When a read operation occurs for an evicted entry, it is efficiently reloaded
from the block storage back into memory, ensuring fast access to the data. This
eviction mechanism in Upstash optimizes memory usage by prioritizing frequently
accessed data while maintaining the ability to retrieve less frequently accessed
data when needed.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c0eeb259e96ff7af442e7448881b59c8" width="600" data-og-width="1201" data-og-height="480" data-path="img/durability/storage.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=10610e8264156a1c5de14a81c39012b7 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e2d42bfc5b97d7ce53627bdf209358bb 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eb172e2fc37ee66a9d0350fafccd4a63 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f39bb49c093c837cd063f185dc79a698 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2782e0a2cf455b1b9e1f107081d27803 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/durability/storage.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5ebefcfbefa685aec3b3d426f7de17a3 2500w" />
</Frame>

<Card title="Can I use Upstash as a database?" icon="lightbulb" iconType="duotone" color="#34D399">
  Definitely, yes. Some users are worried that Redis data will be lost when a
  server crashes. This is not the case for Upstash thanks to Durable Storage.
  Data is reloaded to memory from block storage in case of a server crash.
  Moreover, except for the free tier, all paid tier databases provide extra redundancy by replicating data to multiple instances.
</Card>


# Eviction
Source: https://upstash.com/docs/redis/features/eviction



By default eviction is disabled, and Upstash Redis will reject write operations once the maximum data size
limit has been reached. However, if you are utilizing Upstash Redis as a cache, you
have the option to enable eviction. Enabling eviction allows older data to be
automatically removed from the cache (including Durable Storage) when the maximum size limit is reached.
This ensures that the cache remains within the allocated size and can make room
for new data to be stored. Enabling eviction is particularly useful when the
cache is intended to store frequently changing or temporary data, allowing the
cache to adapt to evolving data needs while maintaining optimal performance.

* You can enable eviction by checking **Eviction** checkbox while creating a new
  database:

  <Frame>
    <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2b8dfc85b0ffbed7aa2e1fa3f50602ab" data-og-width="973" width="973" data-og-height="1062" height="1062" data-path="img/eviction/create-database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=130c831abf4194aee46803c1f2183501 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=527c06fce84b35d51c53aeea76e939e3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=08624f615cf33f68a08b582adf53099f 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=cca6bf52778637582b3b19a4b9a12db7 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b26a53edf4b452b782fd573cfaedcf3 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/create-database.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=45c723eaac4f6d4c629b4073b2aa0576 2500w" />
  </Frame>

* Or for an existing database by clicking **Enable** in Configuration/Eviction
  box in the database details page:
  <Frame>
    <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7239372ec2b89584bc472cb0ea8d8bd0" data-og-width="1984" width="1984" data-og-height="548" height="548" data-path="img/eviction/configuration.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=03c8de205dc380b5301a6b4b6f97b5af 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6c61b08ae71acf223bde3b9184f3a891 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=610daaef4953abd382236fe08cbd03ae 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=db7b98ee0a30569561699a99c0d224b5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=cc78e89b1e11e13b6fa177435bfc96a2 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/eviction/configuration.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7b01cad1e942cc3ff04bfd59814e4af9 2500w" />
  </Frame>

Upstash currently uses a single eviction algorithm, called
**optimistic-volatile**, which is a combination of *volatile-random* and
*allkeys-random* eviction policies available in
[the original Redis](https://redis.io/docs/manual/eviction/#eviction-policies).

Initially, Upstash employs random sampling to select keys for eviction, giving
priority to keys marked with a TTL (expire field). If there is a shortage of
volatile keys or they are insufficient to create space, additional non-volatile
keys are randomly chosen for eviction. In future releases, Upstash plans to
introduce more eviction policies, offering users a wider range of options to
customize the eviction behavior according to their specific needs.


# Global Database
Source: https://upstash.com/docs/redis/features/globaldatabase



In the global database, the replicas are distributed across multiple regions
around the world. The clients are routed to the nearest region. This helps with
minimizing latency for use cases where users can be anywhere in the world.

### Primary Region and Read Regions

The Upstash Global database is structured with a Primary Region and multiple
Read Regions. When a write command is issued, which can be initiated from any region, it is initially sent and processed
at the Primary Region. The write operation is then replicated to all the Read
Regions, ensuring data consistency across the database.

On the other hand, when a read command is executed, it is directed to the
nearest Read Region to optimize response time. By leveraging the Global
database's distributed architecture, read operations can be performed with
reduced latency, as data retrieval occurs from the closest available Read
Region.

The Global database's design thus aids in minimizing read operation latency by
efficiently distributing data across multiple regions and enabling requests to
be processed from the nearest Read Region.

User selects a single primary region and multiple read regions. For the best
performance, you should select the primary region in the same location where
your writes happen. Select the read regions where your clients that read the
Redis located. You may have your database with a single primary region but no
read regions which would be practically same with a single region (regional)
database. You can add or remove regions on a running Redis database.

Here the list of regions currently supported:

* AWS US-East-1 North Virginia
* AWS US-East-2 Ohio
* AWS US-West-1 North California
* AWS US-West-2 Oregon
* AWS EU-West-1 Ireland
* AWS EU-West-2 London
* AWS EU-Central-1 Frankfurt
* AWS AP-South-1 Mumbai
* AWS AP-SouthEast-1 Singapore
* AWS AP-SouthEast-2 Sydney
* AWS AP-NorthEast-1 Japan
* AWS SA-East-1 S√£o Paulo

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c177261b7443aad5aab557f7ab312d8d" width="520" data-og-width="974" data-og-height="1603" data-path="img/globaldb/regionselect.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8dc3ffc3f04cb5aac64fb1d284467a92 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b413c448ee87a3578e0a70ef409dfe1d 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1b42b024e74fafd89a13e50c98e34fb3 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=55a74b38c825de58ed043a063d226ebc 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=cba8e82fee977b3c70e605be921a13ed 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/regionselect.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6b6406fdcea9e681b23b2a81a0e19919 2500w" />
</Frame>

In our internal tests, we see the following latencies (99th percentile):

* Read latency from the same region \<1ms
* Write latency from the same region \<5ms
* Read/write latency from the same continent \<50ms

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6e744968e9185a825f52ee2986a23f7e" width="1000" data-og-width="1680" data-og-height="874" data-path="img/globaldb/map2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3f9b8524ff479b37266efe47da799185 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a47f9e8c867f53df998e390d09866fa9 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e5ea157ad2d54c6ce0ac0a2636861eae 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=da93e8b5bdf527ee2e54ea6fcc32f8e5 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0218a1971423ae33cfc9500ae0aaa1dc 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/globaldb/map2.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=966b9f9e1835f38321b8c1c879b50df3 2500w" />
</Frame>

### Architecture

In the multi region architecture, each key is owned by a primary replica which
is located at the region that you choose as primary region. Read replicas become
the backups of the primary for the related keys. The primary replica processes
the writes, then propagates them to the read replicas. Read requests are
processed by all replicas, this means you can read a value from any of the
replicas. This model gives a better write consistency and read scalability.

Each replica employs a failure detector to track the liveness of the primary
replica. When the primary replica fails for a reason, read replicas start a new
leader election round and elect a new leader (primary). This is the only
unavailability window for the cluster where your requests can be blocked for a
short period of time.

<Note>
  Global Database is designed to optimize the latency of READ operations. It may
  not be a good choice if your use case is WRITE heavy.
</Note>

### Use Cases

* **Edge functions:** Edge computing (Cloudflare workers, Fastly Compute) is
  becoming a popular way of building globally fast applications. But there are
  limited data solutions accessible from edge functions. Upstash Global Database
  is accessible from Edge functions with the REST API. Low latency from all edge
  locations makes it a perfect solution for Edge functions

* Multi region serverless architectures: You can run your AWS Lambda function in
  multiple regions to lower global latency. Vercel/Netlify functions can be run
  in different regions. Upstash Global database provides low latency data
  wherever your serverless functions are.

* Web/mobile use cases where you need low latency globally. Thanks to the read
  only REST API, you can access Redis from your web/mobile application directly.
  In such a case, Global Database will help to lower the latency as you can
  expect the clients from anywhere.

### High Availability and Disaster Recovery

Although the main motivation behind the Global Database is to provide low
latency; it also makes your database resilient to region wide failures. When a
region is not available, your requests are routed to another region; so your
database remains available.

### Consistency

Global Database is an eventually consistent database. The write request returns
after the primary replica processes the operation. Write operation is replicated
to read replicas asynchronously. Read requests can be served by any replica,
which gives better horizontal scalability but also means a read request may
return a stale value while a write operation for the same key is being
propagated to read replicas.

In case of cluster wide failures like network partitioning (split brain);
periodically running anti entropy jobs resolve the conflicts using LWW
algorithms and converge the replicas to the same state.

### Upgrade from Regional to Global

Currently, we do not support auto-upgrade from regional to global database. You
can export data from your old database and import into the global database.

### Pricing

Global Database charges \$0.2 per 100K commands. The write commands are replicated to all read regions in addition to primary region so the replications are counted as commands. For example, if you have 1 primary 1 read region, 100K writes will cost \$0.4 (\$0.2 x 2). You can use Global Database in the free tier too. Free usage is limited with max one read region.


# Replication
Source: https://upstash.com/docs/redis/features/replication



Replication is enabled for all paid Upstash databases. The data is replicated to
multiple instances. Replication provides you high availability and better
scalability.

### High Availability

Replication makes your database resilient to failures because even one of the
replicas is not available, your database continues to work.

There are two types of replicas in Upstash Redis: primary replicas and read replicas. Primary replicas handle both reads and writes, while read replicas are used only for reads.

In all subscription plans, primary replicas are highly available with multiple replicas to ensure that even if one fails, your database continues to function.

If a read replica fails, your database remains operational, and you can still read from the primary replicas, though with higher latency.
When [Prod Pack](/redis/overall/enterprise#prod-pack-features) is enabled, read replicas are also highly available. This ensures that if one read replica fails, you can read from another read replica in the same region without any additional latency.

### Better Scalability

In a replicated database, your requests are evenly distributed among the
replicas using a round-robin approach. As your throughput requirements grow,
additional replicas can be added to the cluster to handle the increased workload
and maintain high performance. This scalability feature ensures that your
database can effectively meet the demands of high throughput scenarios.

### Architecture

We use the single leader replication model. Each key is owned by a leader
replica and other replicas become the backups of the leader. Writes on a key are
processed by the leader replica first then propagated to backup replicas. Reads
can be performed from any replica. This model gives a better write consistency
and read scalability.

### Consistency

Each replica in the cluster utilizes a failure detector to monitor the status of
the leader replica. In the event that the leader replica fails, the remaining
replicas initiate a new leader election process to select a new leader. During
this leader election round, which is the only unavailability window for the
cluster, there may be a short period of time where your requests can be
temporarily blocked.

However, once a new leader is elected, normal operations resume, ensuring the
continued availability of the cluster. This mechanism ensures that any potential
unavailability caused by leader failure is minimized, and the cluster can
quickly recover and resume processing requests.

Checkout [Read Your Writes](/redis/howto/readyourwrites) for more details on how to achieve RYW consistency.


# REST API
Source: https://upstash.com/docs/redis/features/restapi



REST API enables you to access your Upstash database using REST.

## Get Started

If you do not have a database already, follow
[these steps](../overall/getstarted) to create one.

In the [Upstash Console](https://console.upstash.com/redis), select your database. Then, in the database page, you will see the section that includes the endpoint URL and token details. When you hover over the `Endpoint` or `Token / Readonly Token` fields, copy button will appear for each. You can click it to easily copy the values you need for your connection.

Copy the `HTTPS` for REST URL and the `Token` for authorization. Send an HTTP SET request to the
provided URL by adding an `Authorization: Bearer $TOKEN` header like below: (See the sample command with your credentials in the `cURL` tab of Connection section)

```shell  theme={"system"}
curl https://us1-merry-cat-32748.upstash.io/set/foo/bar \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

The above script executes a `SET foo bar` command. It will return a JSON
response:

```json  theme={"system"}
{ "result": "OK" }
```

You can also set the token as `_token` request parameter as below:

```shell  theme={"system"}
curl https://us1-merry-cat-32748.upstash.io/set/foo/bar?_token=2553feg6a2d9842h2a0gcdb5f8efe9934
```

## API Semantics

Upstash REST API follows the same convention with
[Redis Protocol](https://redis.io/commands). Give the command name and
parameters in the same order as Redis protocol by separating them with a `/`.

```shell  theme={"system"}
curl REST_URL/COMMAND/arg1/arg2/../argN
```

Here are some examples:

* `SET foo bar` -> `REST_URL/set/foo/bar`

* `SET foo bar EX 100` -> `REST_URL/set/foo/bar/EX/100`

* `GET foo` -> `REST_URL/get/foo`

* `MGET foo1 foo2 foo3` -> `REST_URL/mget/foo1/foo2/foo3`

* `HGET employee:23381 salary` -> `REST_URL/hget/employee:23381/salary`

* `ZADD teams 100 team-x 90 team-y` ->
  `REST_URL/zadd/teams/100/team-x/90/team-y`

#### JSON or Binary Value

To post a JSON or a binary value, you can use an HTTP POST request and set value
as the request body:

```shell  theme={"system"}
curl -X POST -d '$VALUE' https://us1-merry-cat-32748.upstash.io/set/foo \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

In the example above, `$VALUE` sent in request body is appended to the command
as `REST_URL/set/foo/$VALUE`.

Please note that when making a POST request to the Upstash REST API, the request
body is appended as the last parameter of the Redis command. If there are
additional parameters in the Redis command after the value, you should include
them as query parameters in the request:

```shell  theme={"system"}
curl -X POST -d '$VALUE' https://us1-merry-cat-32748.upstash.io/set/foo?EX=100 \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

Above command is equivalent to `REST_URL/set/foo/$VALUE/EX/100`.

#### POST Command in Body

Alternatively, you can send the whole command in the request body as a single
JSON array. Array's first element must be the command name and command
parameters should be appended next to each other in the same order as Redis
protocol.

```shell  theme={"system"}
curl -X POST -d '[COMMAND, ARG1, ARG2,.., ARGN]' REST_URL
```

For example, Redis command `SET foo bar EX 100` can be sent inside the request
body as:

```shell  theme={"system"}
curl -X POST -d '["SET", "foo", "bar", "EX", 100]' https://us1-merry-cat-32748.upstash.io \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

## HTTP Codes

* `200 OK`: When request is accepted and successfully executed.

* `400 Bad Request`: When there's a syntax error, an invalid/unsupported command
  is sent or command execution fails.

* `401 Unauthorized`: When authentication fails; auth token is missing or
  invalid.

* `405 Method Not Allowed`: When an unsupported HTTP method is used. Only
  `HEAD`, `GET`, `POST` and `PUT` methods are allowed.

## Response

REST API returns a JSON response by default. When command execution is successful, response
JSON will have a single `result` field and its value will contain the Redis
response. It can be either;

* a `null` value

```json  theme={"system"}
{ "result": null }
```

* an integer

```json  theme={"system"}
{ "result": 137 }
```

* a string

```json  theme={"system"}
{ "result": "value" }
```

* an array value:

```json  theme={"system"}
{ "result": ["value1", null, "value2"] }
```

If command is rejected or fails, response JSON will have a single `error` field
with a string value explaining the failure:

```json  theme={"system"}
{"error":"WRONGPASS invalid password"}

{"error":"ERR wrong number of arguments for 'get' command"}
```

### Base64 Encoded Responses

If the response contains an invalid utf-8 character, it will be replaced with
a ÔøΩ (Replacement character U+FFFD). This can happen when you are using binary
operations like `BITOP NOT` etc.

If you prefer the raw response in base64 format, you can achieve this by setting
the `Upstash-Encoding` header to `base64`. In this case, all strings in the response
will be base64 encoded, except for the "OK" response.

```shell  theme={"system"}
curl https://us1-merry-cat-32748.upstash.io/SET/foo/bar \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -H "Upstash-Encoding: base64"

# {"result":"OK"}

curl https://us1-merry-cat-32748.upstash.io/GET/foo \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -H "Upstash-Encoding: base64"

# {"result":"YmFy"}
```

### RESP2 Format Responses

REST API returns a JSON response by default and the response content type is set to `application/json`.

If you prefer the binary response in RESP2 format, you can achieve this by setting
the `Upstash-Response-Format` header to `resp2`. In this case, the response content type
is set to `application/octet-stream` and the raw response is returned as binary similar to a TCP-based Redis client.

The default value for this option is `json`.
Any format other than `json` and `resp2` is not allowed and will result in a HTTP 400 Bad Request.

This option is not applicable to `/multi-exec` transactions endpoint, as it only returns response in JSON format.
Additionally, setting the `Upstash-Encoding` header to `base64` is not permitted when the `Upstash-Response-Format` is set to `resp2`
and will result in a HTTP 400 Bad Request.

```shell  theme={"system"}
curl https://us1-merry-cat-32748.upstash.io/SET/foo/bar \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -H "Upstash-Reponse-Format: resp2"

# +OK\r\n

curl https://us1-merry-cat-32748.upstash.io/GET/foo \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -H "Upstash-Reponse-Format: resp2"

# $3\r\nbar\r\n
```

## Pipelining

Upstash REST API provides support for command pipelining, allowing you to send
multiple commands as a batch instead of sending them individually and waiting
for responses. With the pipeline API, you can include several commands in a
single HTTP request, and the response will be a JSON array. Each item in the
response array corresponds to the result of a command in the same order as they
were included in the pipeline.

API endpoint for command pipelining is `/pipeline`. Pipelined commands should be
send as a two dimensional JSON array in the request body, each row containing
name of the command and its arguments.

**Request syntax**:

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/pipeline \
 -H "Authorization: Bearer $TOKEN" \
 -d '
    [
      ["CMD_A", "arg0", "arg1", ..., "argN"],
      ["CMD_B", "arg0", "arg1", ..., "argM"],
      ...
    ]
    '
```

**Response syntax**:

```json  theme={"system"}
[{"result":"RESPONSE_A"},{"result":"RESPONSE_B"},{"error":"ERR ..."}, ...]
```

<Note>
  Execution of the pipeline is *not atomic*. Even though each command in the
  pipeline will be executed in order, commands sent by other clients can
  interleave with the pipeline. Use [transactions](#transactions) API instead if
  you need atomicity.
</Note>

For example you can write the `curl` command below to send following Redis
commands using pipeline:

```redis  theme={"system"}
SET key1 valuex
SETEX key2 13 valuez
INCR key1
ZADD myset 11 item1 22 item2
```

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/pipeline \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -d '
    [
      ["SET", "key1", "valuex"],
      ["SETEX", "key2", 13, "valuez"],
      ["INCR", "key1"],
      ["ZADD", "myset", 11, "item1", 22, "item2"]
    ]
    '
```

And pipeline response will be:

```json  theme={"system"}
[
  { "result": "OK" },
  { "result": "OK" },
  { "error": "ERR value is not an int or out of range" },
  { "result": 2 }
]
```

You can use pipelining when;

* You need more throughput, since pipelining saves from multiple round-trip
  times. (*But beware that latency of each command in the pipeline will be equal
  to the total latency of the whole pipeline.*)
* Your commands are independent of each other, response of a former command is
  not needed to submit a subsequent command.

## Transactions

Upstash REST API supports transactions to execute multiple commands atomically.
With transactions API, several commands are sent using a single HTTP request,
and a single JSON array response is returned. Each item in the response array
corresponds to the command in the same order within the transaction.

API endpoint for transaction is `/multi-exec`. Transaction commands should be
send as a two dimensional JSON array in the request body, each row containing
name of the command and its arguments.

**Request syntax**:

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/multi-exec \
 -H "Authorization: Bearer $TOKEN" \
 -d '
    [
      ["CMD_A", "arg0", "arg1", ..., "argN"],
      ["CMD_B", "arg0", "arg1", ..., "argM"],
      ...
    ]
    '
```

**Response syntax**:

In case when transaction is successful, multiple responses corresponding to each
command is returned in json as follows:

```json  theme={"system"}
[{"result":"RESPONSE_A"},{"result":"RESPONSE_B"},{"error":"ERR ..."}, ...]
```

If transaction is discarded as a whole, a single error is returned in json as
follows:

```json  theme={"system"}
{ "error": "ERR ..." }
```

A transaction might be discarded in following cases:

* There is a syntax error on the transaction request.
* At least one of the commands is unsupported.
* At least one of the commands exceeds the
  [max request size](../troubleshooting/max_request_size_exceeded).
* At least one of the commands exceeds the
  [daily request limit](../troubleshooting/max_daily_request_limit).

Note that a command may still fail even if it is a supported and valid command.
In that case, all commands will be executed. Upstash Redis will not stop the
processing of commands. This is to provide same semantics with Redis when there
are
[errors inside a transaction](https://redis.io/docs/manual/transactions/#errors-inside-a-transaction).

**Example**:

You can write the `curl` command below to send following Redis commands using
REST transaction API:

```
MULTI
SET key1 valuex
SETEX key2 13 valuez
INCR key1
ZADD myset 11 item1 22 item2
EXEC
```

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/multi-exec \
 -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
 -d '
    [
      ["SET", "key1", "valuex"],
      ["SETEX", "key2", 13, "valuez"],
      ["INCR", "key1"],
      ["ZADD", "myset", 11, "item1", 22, "item2"]
    ]
    '
```

And transaction response will be:

```json  theme={"system"}
[
  { "result": "OK" },
  { "result": "OK" },
  { "error": "ERR value is not an int or out of range" },
  { "result": 2 }
]
```

## Monitor Command

Upstash REST API provides Redis [`MONITOR`](https://redis.io/docs/latest/commands/monitor/) command using
[Server Send Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) mechanism. API endpoint is `/monitor`.

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/monitor \
  -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
  -H "Accept:text/event-stream"
```

This request will listen for Redis monitor events and incoming data will be received as:

```
data: "OK"
data: 1721284005.242090 [0 0.0.0.0:0] "GET" "k"
data: 1721284008.663811 [0 0.0.0.0:0] "SET" "k" "v"
data: 1721284025.561585 [0 0.0.0.0:0] "DBSIZE"
data: 1721284030.601034 [0 0.0.0.0:0] "KEYS" "*"
```

## Subscribe & Publish Commands

Simiar to `MONITOR` command, Upstash REST API provides Redis [`SUBSCRIBE`](https://redis.io/docs/latest/commands/subscribe/) and
[`PUBLISH`](https://redis.io/docs/latest/commands/publish/) commands. The `SUBSCRIBE` endpoint works using\
[Server Send Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) mechanism.
API endpoints are `/subscribe` and `/publish`

Following request will subscribe to a channel named `chat`:

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/subscribe/chat \
  -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934" \
  -H "Accept:text/event-stream"
```

Following request will publish to a channel named `chat`:

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/publish/chat/hello \
  -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

The subscriber will receive incoming messages as:

```
data: subscribe,chat,1
data: message,chat,hello
data: message,chat,how are you today?
```

## Security and Authentication

You need to add a header to your API requests as `Authorization: Bearer $TOKEN`
or set the token as a url parameter `_token=$TOKEN`.

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/info \
  -H "Authorization: Bearer 2553feg6a2d9842h2a0gcdb5f8efe9934"
```

OR

```shell  theme={"system"}
curl -X POST https://us1-merry-cat-32748.upstash.io/info?_token=2553feg6a2d9842h2a0gcdb5f8efe9934
```

Upstash by default provides two separate access tokens per database: "Standard"
and "Read Only".

* **Standard** token has full privilege over the database, can execute any
  command.

* **Read Only** token permits access to the read commands only. Some powerful
  read commands (e.g. SCAN, KEYS) are also restricted with read only token. It
  makes sense to use *Read Only* token when you access Upstash Redis from web
  and mobile clients where the token is exposed to public.

You can get/copy the tokens by clicking copy button next to
`UPSTASH_REDIS_REST_TOKEN` in REST API section of the console. For the *Read
Only* token, just enable the "Read-Only Token" switch.

<Frame>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6a1d70558755a14b393174a193242d6e" data-og-width="1915" width="1915" data-og-height="715" height="715" data-path="img/restapi/tokens.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e2202a9fc20769a1b588b1f90f9000dd 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=cb353bcd79b0d5dc136a43971c046f88 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e1df91ef201d5f31e4f0de6587a962ae 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=5b0222a25b503cdcd9e7d4ad4b6a57cb 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=314064699fa2a48f544737e53b69991f 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/tokens.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e255c1b97fdce8f39c8a50064550e815 2500w" />
</Frame>

<Warning>
  Do not expose your *Standard* token publicly. *Standard* token has full
  privilege over the database. You can expose the *Read Only* token as it has
  access to read commands only. You can revoke both *Standard* and *Read Only*
  tokens by resetting password of your database.
</Warning>

### REST Token for ACL Users

In addition to the tokens provided by default, you can create REST tokens for
the users created via [`ACL SETUSER`](https://redis.io/commands/acl-setuser/)
command. Upstash provides a custom `ACL` subcommand to generate REST tokens:
`ACL RESTTOKEN`. It expects two arguments; username and user's password. And
returns the REST token for the user as a string response.

```
ACL RESTTOKEN <username> <password>
    Generate a REST token for the specified username & password.
    Token will have the same permissions with the user.
```

You can execute `ACL RESTTOKEN` command via `redis-cli`:

```shell  theme={"system"}
redis-cli> ACL RESTTOKEN default 35fedg8xyu907d84af29222ert
"AYNgAS2553feg6a2d9842h2a0gcdb5f8efe9934DQ="
```

Or via CLI on the Upstash console:

<Frame>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=42512a275e39be075e4b8cb2a7969d60" data-og-width="1954" width="1954" data-og-height="410" height="410" data-path="img/restapi/acl-resttoken.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d44ba413edab40499eb6f71792d7a424 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=1d068f67df2232ccf9ec3a3a66868e25 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=bf2370a4c68f43a0a4ba069ffde9240f 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6200957ce7ba28860be4988381d491e8 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=b630f3ce3cd85173d627c67d6cffadc1 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/restapi/acl-resttoken.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=16d5366c643aa99f1ded25a0abe215b3 2500w" />
</Frame>

If the user doesn't exist or password doesn't match then an error will be
returned.

```shell  theme={"system"}
redis-cli> ACL RESTTOKEN upstash fakepass
(error) ERR Wrong password or user "upstash" does not exist
```

## Redis Protocol vs REST API

### REST API Pros

* If you want to access to Upstash database from an environment like CloudFlare
  Workers, WebAssembly, Fastly Compute\@Edge then you can not use Redis protocol
  as it is based on TCP. You can use REST API in those environments.

* REST API is request (HTTP) based where Redis protocol is connection based. If
  you are running serverless functions (AWS Lambda etc), you may need to manage
  the Redis client's connections. REST API does not have such an issue.

* Redis protocol requires Redis clients. On the other hand, REST API is
  accessible with any HTTP client.

### Redis Protocol Pros

* If you have legacy code that relies on Redis clients, the Redis protocol
  allows you to utilize Upstash without requiring any modifications to your
  code.

* By leveraging the Redis protocol, you can take advantage of the extensive
  Redis ecosystem. For instance, you can seamlessly integrate your Upstash
  database as a session cache for your Express application.

## Cost and Pricing

Upstash pricing is based on per command/request. So the same pricing listed in
our [pricing](https://upstash.com/pricing/redis) applies to your REST calls too.

## Metrics and Monitoring

In the current version, we do not expose any metrics specific to API calls in
the console. But the metrics of the database backing the API should give a good
summary about the performance of your APIs.

## REST - Redis API Compatibility

| Feature                                                       | REST Support? |                               Notes                               |
| ------------------------------------------------------------- | :-----------: | :---------------------------------------------------------------: |
| [String](https://redis.io/commands/?group=string)             |       ‚úÖ       |                                                                   |
| [Bitmap](https://redis.io/commands/?group=bitmap)             |       ‚úÖ       |                                                                   |
| [Hash](https://redis.io/commands/?group=hash)                 |       ‚úÖ       |                                                                   |
| [List](https://redis.io/commands/?group=list)                 |       ‚úÖ       | Blocking commands (BLPOP - BRPOP - BRPOPLPUSH) are not supported. |
| [Set](https://redis.io/commands/?group=set)                   |       ‚úÖ       |                                                                   |
| [SortedSet](https://redis.io/commands/?group=sorted_set)      |       ‚úÖ       |     Blocking commands (BZPOPMAX - BZPOPMIN) are not supported.    |
| [Geo](https://redis.io/commands/?group=geo)                   |       ‚úÖ       |                                                                   |
| [HyperLogLog](https://redis.io/commands/?group=hyperloglog)   |       ‚úÖ       |                                                                   |
| [Transactions](https://redis.io/commands/?group=transactions) |       ‚úÖ       |              WATCH/UNWATCH/DISCARD are not supported              |
| [Generic](https://redis.io/commands/?group=generic)           |       ‚úÖ       |                                                                   |
| [Server](https://redis.io/commands/?group=server)             |       ‚úÖ       |                                                                   |
| [Scripting](https://redis.io/commands/?group=scripting)       |       ‚úÖ       |                                                                   |
| [Pub/Sub](https://redis.io/commands/?group=pubsub)            |       ‚úÖ       |                                                                   |
| [Connection](https://redis.io/commands/?group=connection)     |       ‚ö†Ô∏è      |                 Only PING and ECHO are supported.                 |
| [JSON](https://redis.io/commands/?group=json)                 |       ‚úÖ       |                                                                   |
| [Streams](https://redis.io/commands/?group=stream)            |       ‚úÖ       |    Supported, except blocking versions of XREAD and XREADGROUP.   |
| [Cluster](https://redis.io/commands#cluster)                  |       ‚ùå       |                                                                   |


# Security
Source: https://upstash.com/docs/redis/features/security



Upstash has a set of features to help you secure your data. We will list them
and at the end of the section we will list the best practices to improve
security of database.

## TLS

TLS is always enabled on Upstash Redis databases. The data transfer between the client and database is
encrypted.

## Redis ACL

With Redis ACL, you can improve security by restricting a user's access to
commands and keys, so that untrusted clients have no access and trusted clients
have just the minimum required access level to the database. Moreover it
improves operational safety, so that clients or users accessing Redis are not
allowed to damage the data or the configuration due to errors or mistakes. Check
[Redis ACL documentation](https://redis.io/docs/manual/security/acl/). If you
are using the REST API, you can still benefit from ACLs as explained
[here](/redis/features/restapi#rest-token-for-acl-users)

## Database Credentials

When you create a database, a secure password is generated. Upstash keeps the
password encrypted. Use environment variables or your provider's secret
management system (e.g. AWS Secrets Manager, Vercel Secrets) to keep them. Do
not use them hardcoded in your code. If your password is leaked, reset the
password using Upstash console.

## Encryption at Rest

Encryption at REST encrypts the block storage where your data is persisted and
stored. It is available with [Prod Pack](redis/overall/enterprise#prod-pack-features) add-on.

## Application Level Encryption

Client side encryption can be used to encrypt data through application
lifecycle. Client-side encryption is used to help protect data in use. This
comes with some limitations. Operations that must operate on the data, such as
increments, comparisons, and searches will not function properly. You can write
client-side encryption logic directly in your own application or use functions
built into clients such as the Java Lettuce cipher codec. We have plans to
support encryption in our SDKs.

## IP Allowlisting

We can restrict the access to your database to a set of IP addresses which will
have access to your database. This is quite a strong way to secure your
database, but it has some limitations. For example you can not know the IP
addresses in serverless platforms such AWS Lambda and Vercel functions.

## VPC Peering

VPC Peering enables you to connect to Upstash from your own VPC using private
IP. Database will not be accessible from the public network. Database and your
application can run in the same subnet which also minimizes data transfer costs.
VPC Peering is only available for Pro databases.

## Private Link

AWS Private link provides private connectivity between Upstash Database and your
Redis client inside AWS infrastructure. Private link is only available for
Pro databases.


# Compliance
Source: https://upstash.com/docs/redis/help/compliance



## Upstash Legal & Security Documents

* [Upstash Terms of Service](https://upstash.com/static/trust/terms.pdf)
* [Upstash Privacy Policy](https://upstash.com/static/trust/privacy.pdf)
* [Upstash Data Processing Agreement](https://upstash.com/static/trust/dpa.pdf)
* [Upstash Technical and Organizational Security Measures](https://upstash.com/static/trust/security-measures.pdf)
* [Upstash Subcontractors](https://upstash.com/static/trust/subprocessors.pdf)

## Is Upstash SOC2 Compliant?

As of July 2023, Upstash Redis is SOC2 compliant. Check our [trust page](https://trust.upstash.com/) for details.

## Is Upstash ISO-27001 Compliant?

We are in process of getting this certification. Contact us
([support@upstash.com](mailto:support@upstash.com)) to learn about the expected
date.

## Is Upstash GDPR Compliant?

Yes. For more information, see our
[Privacy Policy](https://upstash.com/static/trust/privacy.pdf). We acquire DPAs
from each [subcontractor](https://upstash.com/static/trust/subprocessors.pdf)
that we work with.

## Is Upstash HIPAA Compliant?

Upstash is currently not HIPAA compliant. Contact us
([support@upstash.com](mailto:support@upstash.com)) if HIPAA is important for
you and we can share more details.

## Is Upstash PCI Compliant?

Upstash does not store personal credit card information. We use Stripe for
payment processing. Stripe is a certified PCI Service Provider Level 1, which is
the highest level of certification in the payments industry.

## Does Upstash conduct vulnerability scanning and penetration tests?

Yes, we use third party tools and work with pen testers. We share the results
with Enterprise customers. Contact us
([support@upstash.com](mailto:support@upstash.com)) for more information.

## Does Upstash take backups?

Yes, we take regular snapshots of the data cluster to the AWS S3 platform.

## Does Upstash encrypt data?

Customers can enable TLS while creating database/cluster, and we recommend it
for production databases/clusters. Also we encrypt data at rest at request of
customers.


# Frequently Asked Questions
Source: https://upstash.com/docs/redis/help/faq



## What is Upstash Redis?

Upstash is a serverless database service compatible with Redis¬Æ API.

## What is a Serverless Database?

* You do not have to manage and provision servers.
* You do not deal with configuring or maintaining any server.
* You just use the service and pay what you use. If you are not using it, you should not be paying.

## What are the use cases?

Upstash works for all the common usecases for Redis¬Æ. You can use Upstash in your serverless stack. In addition, you can use Upstash as storage (or caching) for your serverless functions. See [Use Cases](/redis/overall/usecases) for more.

## Do you support all Redis¬Æ API?

Most of them. See [Redis¬Æ API Compatibility](/redis/overall/rediscompatibility) for the list of supported commands.

## Can I use any Redis client?

Yes, Upstash is compatible Redis client protocol.

## Which cloud providers do you support?

Initially we have AWS and GCP. Digital Ocean is planned.

## Which regions do you support in AWS?

We start with AWS-US-EAST-1 (Virginia), GCP-US-CENTRAL-1 (IOWA), AWS-US-WEST-1 (N. California), AWS-EU-WEST-1 (Ireland), AWS-APN-NE-1 (Japan). We will add new regions soon. You can expedite this by telling us your use case and the region you need by emailing to [support@upstash.com](mailto:support@upstash.com)

## Should my client be hosted in the AWS to use Upstash?

No. Your client can be anywhere but the clients in AWS regions will give you better performance.

## How do you compare Upstash with ElastiCache?

Upstash is serverless. With ElastiCache, you pay even you do not use the database. See [Compare](/redis/overall/compare) for more info.

## How do you compare Upstash with Redis Labs or Compose.io?

Upstash is serverless. With Redis Labs or Compose.io, you always pay a lot when your data size is big but your traffic is low. In Upstash, the pricing is based on per request. See [Compare](/redis/overall/compare) for more info.

## Do you persist data?

Yes, by default we write data to the disk. So in case of a failure you should not lose any data.

## Do you support Redis Cluster?

We support replication in Premium type database. We do not support sharding yet.

## I have database with 10GB data, I pay nothing if I do not use it. Is that correct?

You only pay for the disk storage cost that is \$0.25 per GB. For your case, you will pay \$2.5 monthly.

## What happens when I exceed the request limit on Free Database (10.000 requests per day)?

The exceeding commands return exception.

## When I upgrade my free database, do I lose data?

You do not lose data but clients may disconnect and reconnect.

## Upstash is much cheaper than Elasticache and Redis Labs for big data sizes (> 10GB). How is that possible?

Upstash storage layer is multi tiered. We keep your data in both memory and block storage (disk). The entries that are not accessed frequently are removed from the memory but stored in disk. Latency overhead of idle entries is limited thanks to the SSD based storage. Multi tiered storage allows us to provide more flexible pricing.

## Will my data be safe?

Upstash is a GDPR compliant company. We do not share any user data with third parties. See our [Legal Documents](/common/help/legal) for more information.

## What happens if my database is not used?

Free databases are archived after a minimum of 14 days of inactivity. Pay As You Go databases are archived after a minimum of 3 months of inactivity. Users get several warning emails prior to this operation.

If you wish to keep your database endpoint active for a longer period of inactivity, consider switching to a Fixed plan.

<Note>
  No data is lost due to this process. When a database is archived due to inactivity, we take a backup of the data so users can create a new database and restore their data from the Upstash Console.
</Note>

## How do you handle the noisy neighbour problem? Do other tenants affect my database?

Databases are isolated on some aspects but still share some hardware resources such as CPU or network. To avoid noisy neighbor influence on these resources, there are specific quotas for each database. When they reach any of these quotas they are throttled using a backoff strategy. When multiple databases sharing the same hardware are close to the limits, our system can add new resources to the pool and/or migrate some of the databases to distribute the load.

Also if a database exceeds its quotas very frequently, we notify users whether they want to upgrade to an upper plan. Databases in enterprise plans are placed either on dedicated or more isolated hardware due to higher resource needs.


# Integration with Third Parties & Partnerships
Source: https://upstash.com/docs/redis/help/integration



<Frame>
  <img height="100" src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=12b02067fd6101b2b40df79848f845f4" data-og-width="1912" data-og-height="1570" data-path="img/integration/upstash-integration-diagram.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1a1eaa2be7331d3ccb3fec182c7d85c7 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ce655b76b595e01c3639ceb3ceaeab34 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3ead270c9c90e142fa00987dab2efb83 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5821438d41e99e22447a29ec6d891889 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1fe4a7a092250af25b26086c22a888fa 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/upstash-integration-diagram.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bdf82bf103f38088843b890fb776a5e5 2500w" />
</Frame>

## Introduction

In this guideline we will outline the steps to integrate Upstash into your platform (GUI or Web App) and allow your users to create and manage Upstash databases without leaving your interfaces. We will explain how to use OAuth2.0 as the underlying foundation to enable this access seamlessly.

If your product or service offering utilizes Redis, Vector or QStash or if there is a common use case that your end users enable by leveraging these database resources, we invite you to be a partner with us. By integrating Upstash into your platform, you can offer a more complete package for your customers and become a one stop shop. This will also position yourself at the forefront of innovative cloud computing trends such as serverless and expand your customer base.

This is the most commonly used partnership integration model that can be easily implemented by following this guideline. Recently [Cloudflare workers integration](https://blog.cloudflare.com/cloudflare-workers-database-integration-with-upstash/) is implemented through this methodology. For any further questions or partnership discussions please send us an email at [partnerships@upstash.com](mailto:partnerships@upstash.com)

<Info>
  Before starting development to integrate Upstash into your product, please
  send an email to [partnerships@upstash.com](mailto:partnerships@upstash.com) for further assistance and guidance.
</Info>

**General Flow (High level user flow)**

1. User clicks **`Connect Upstash`**¬†button on your platform‚Äôs surface (GUI, Web App)
2. This initiates the OAuth 2.0 flow, which opens a new browser page displaying the¬†**`Upstash Login Page`**.
3. If this is an existing user, user logins with their Upstash credentials otherwise they can directly sign up for a new Upstash account.
4. Browser window redirects to¬†**`Your account has been connected`**¬†page and authentication window automatically closes.
5. After the user returns to your interface, they see their Upstash Account is now connected.

## Technical Design (SPA - Regular Web Application)

1. Users click `Connect Upstash` button from Web App.
2. Web App initiate Upstash OAuth 2.0 flow. Web App can use
   [Auth0 native libraries](https://auth0.com/docs/libraries).

<Note>
  Please reach [partnerships@upstash.com](mailto:partnerships@upstash.com) to receive client id and callback url.
</Note>

3. After user returns from OAuth 2.0 flow then web app will have JWT token. Web
   App can generate Developer Api key:

```bash  theme={"system"}
curl -XPOST https://api.upstash.com/apikey \
    -H "Authorization: Bearer JWT_KEY" \
    -H "Content-Type: application/json" \
    -d '{ "name": "APPNAME_API_KEY_TIMESTAMP" }'
```

4. Web App need to save Developer Api Key to the backend.

## Technical Design ( GUI Apps )

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bcef33147cd866b6e5491aae3b051b3f" data-og-width="2226" width="2226" data-og-height="1692" height="1692" data-path="img/integration/oauth2-integration.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e006a10cd79f12d80e3e13dd0f22a7fe 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0868fc8d69400942bcccb568131be41b 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=fd2fa7c5719b0949f13f2fa972f1d5fb 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=32f6c33468107be0126cb5e92d0b9f34 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2be1b63bccc956937c20d79bb5eee6d1 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/integration/oauth2-integration.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=331dbabdd4c875ecfbddc94eebba1152 2500w" />
</Frame>

1. User clicks¬†**`Connect Upstash`**¬†button from web app.
2. Web app initiates Upstash OAuth 2.0 flow and it can use¬†**[Auth0 native libraries](https://auth0.com/docs/libraries)**.
3. App will open new browser:

```
https://auth.upstash.com/authorize?response_type=code&audience=upstash-api&scope=offline_access&client_id=XXXXXXXXXX&redirect_uri=http%3A%2F%2Flocalhost:3000
```

<Note>Please reach [partnerships@upstash.com](mailto:partnerships@upstash.com) to receive client id.</Note>

4. After user authenticated Auth0 will redirect user to
   `localhost:3000/?code=XXXXXX`

5. APP can return some nice html response when Auth0 returns to `localhost:3000`

6. After getting `code` parameter from the URL query, GUI App will make http
   call to the Auth0 code exchange api. Example CURL request

```bash  theme={"system"}
curl -XPOST 'https://auth.upstash.com/oauth/token' \
  --header 'content-type: application/x-www-form-urlencoded' \
  --data 'grant_type=authorization_code --data audience=upstash-api' \
  --data 'client_id=XXXXXXXXXXX' \
  --data 'code=XXXXXXXXXXXX' \
  --data 'redirect_uri=localhost:3000'
```

Response:

```json  theme={"system"}
{
  "access_token": "XXXXXXXXXX",
  "refresh_token": "XXXXXXXXXXX",
  "scope": "offline_access",
  "expires_in": 172800,
  "token_type": "Bearer"
}
```

7. After 6th Step the response will include `access_token`, it has 3 days TTL.
   GUI App will call Upstash API to get a developer api key:

```bash  theme={"system"}
curl https://api.upstash.com/apikey -H "Authorization: Bearer JWT_KEY" -d '{ "name" : "APPNAME_API_KEY_TIMESTAMP" }'
```

8. GUI App will save Developer Api key locally. Then GUI App can call any
   Upstash Developer API [developer.upstash.com/](https://developer.upstash.com/)

## Managing Resources

After obtaining Upstash Developer Api key, your platform surface (web or GUI) can call Upstash API. For example¬†**[Create Database](https://developer.upstash.com/#create-database-global)**,¬†**[List Database](https://developer.upstash.com/#list-databases)**

In this flow, you can ask users for region information and name of the database then can call Create Database API to complete the task

Example CURL request:

```bash  theme={"system"}
curl -X POST \
  https://api.upstash.com/v2/redis/database \
  -u 'EMAIL:API_KEY' \
  -d '{"name":"myredis", "region":"global", "primary_region":"us-east-1", "read_regions":["us-west-1","us-west-2"], "tls": true}'
```


# Legal
Source: https://upstash.com/docs/redis/help/legal



## Upstash Legal Documents

* [Upstash Terms of Service](https://upstash.com/trust/terms.pdf)
* [Upstash Privacy Policy](https://upstash.com/trust/privacy.pdf)
* [Upstash Subcontractors](https://upstash.com/trust/subprocessors.pdf)


# Managing Healthcare Data
Source: https://upstash.com/docs/redis/help/managing-healthcare-data



You can use Upstash Redis to store and process Protected Health Information (PHI). You are responsible for the following:

* **Signing a Business Associate Agreement (BAA)** with Upstash. Email [support@upstash.com](mailto:support@upstash.com) to get started.
* **Marking specific databases as HIPAA databases** and addressing security issues raised by the Upstash team.
* **Ensuring MFA is enabled** on all Upstash Console accounts.
  * Enforce MFA as a requirement to access the organization
* **Enabling Prod Pack** which provides encryption at rest and advanced security features (already included in the Enterprise plan).
* **Enabling Credential Protection** to prevent storing credentials in Upstash infrastructure and limit console access requiring database credentials.
* **Configuring IP allowlist** to restrict database access to authorized networks.
* **Enabling daily backups** to validate recoverability and meet retention requirements.
* **Complying with encryption requirements** in the HIPAA Security Rule. Data is encrypted at rest and in transit by Upstash. You can consider encrypting the data at your application layer.
* **Ensuring that PHI is stored only within your database**. Storing PHI in resource names or other locations is strictly prohibited.
* **Ensuring that PHI is stored only in values of data structures, not in identifiers or keys**. Avoid logging keys anywhere.
* **Not using public endpoints** to process PHI.
* **Not transferring databases** to a non-HIPAA organization.

<Note>
  For a comprehensive guide on implementing these responsibilities in production, see our [Production Checklist](/redis/help/production-checklist). For questions about managing healthcare data, contact our support team at [support@upstash.com](mailto:support@upstash.com).
</Note>


# Production Checklist
Source: https://upstash.com/docs/redis/help/production-checklist



This checklist provides essential recommendations for securing and optimizing your Upstash databases for production workloads.

## Security Features

### Enable Prod Pack

Prod Pack provides enterprise-grade security and monitoring features:

* 99.99% uptime SLA
* SOC-2 Type 2 report available
* Role-Based Access Control (RBAC)
* Encryption at Rest
* Advanced monitoring (Prometheus, Datadog)
* High availability for read regions

<Note>
  Prod Pack is available as a \$200/month add-on per database for all paid plans except Free tier.
</Note>

### Enable Credential Protection

Protect your database credentials (Prod Pack feature):

* Credentials are never stored in Upstash infrastructure
* Credentials are displayed only once during enablement
* Console features requiring database access are disabled

<Warning>
  Disabling this feature will permanently revoke current credentials and generate new ones.
</Warning>

### Configure IP Allowlist

Restrict database access to specific IP addresses:

* Available on all plans except Free tier
* Supports IPv4 addresses and CIDR blocks
* Multiple IP ranges can be configured

### Implement Redis ACL

Use Redis Access Control Lists to restrict user access:

* Create users with minimal required permissions
* Available for both TCP connections and REST API
* Use `ACL RESTTOKEN` command to generate REST tokens

### Enable Multi-Factor Authentication

Enable MFA on your Upstash account for enhanced security:

* Use your existing authentication provider (Google, GitHub, Amazon)
* Consider using a dedicated email/password account for production
* Force MFA for all team members to ensure consistent security
* Regularly review account access and team member permissions

### Secure Credential Management

Follow these best practices:

* Never hardcode credentials in your application code
* Use environment variables or secret management systems
* Reset passwords immediately if credentials are compromised
* Use Read-Only tokens for public-facing applications

## Network Security

### TLS Encryption

TLS is always enabled on Upstash Redis databases.

### VPC Peering (Enterprise)

Connect databases to your VPCs using private IP:

* Database becomes inaccessible from public networks
* Minimizes data transfer costs
* Available for Enterprise customers

## Monitoring & Observability

### Enable Advanced Monitoring

Prod Pack includes comprehensive monitoring:

* Prometheus integration
* Datadog integration
* Extended console metrics (up to one month)

## High Availability & Backup

### Enable Daily Backups

Configure automated daily backups for data protection:

* Available on all paid plans
* Backup retention up to 3 days with Prod Pack
* Hourly backups with customizable retention (Enterprise)

### Global Replication

For global applications, consider using Global Database:

* Distribute data across multiple regions
* Minimize latency for users worldwide
* Enhanced disaster recovery capabilities

## Compliance & Governance

### SOC-2 Compliance

Prod Pack and Enterprise plans include SOC-2 Type 2 compliance:

* Request SOC-2 report from [trust.upstash.com](https://trust.upstash.com/)
* Available for production workloads

### Enterprise Features

For enterprise customers:

* HIPAA compliance available
* SAML SSO integration
* Access logs available
* Custom resource allocation

## Pre-Production Checklist

Before going live, ensure you have:

* [ ] Prod Pack enabled (recommended)
* [ ] Credential Protection enabled
* [ ] IP Allowlist configured
* [ ] MFA enabled on your account
* [ ] Daily backups enabled
* [ ] Monitoring and alerts configured
* [ ] Environment variables secured
* [ ] Error handling tested

## Additional Resources

* [Security Features](/redis/features/security)
* [Prod Pack & Enterprise](/redis/overall/enterprise)
* [Backup & Restore](/redis/features/backup)
* [Global Database](/redis/features/globaldatabase)
* [Monitoring & Metrics](/redis/howto/metricsandcharts)
* [Compliance Information](/common/help/compliance)
* [Professional Support](/common/help/prosupport)

For additional assistance with production deployment, contact our support team at [support@upstash.com](mailto:support@upstash.com).


# Shared Responsibility Model
Source: https://upstash.com/docs/redis/help/shared-responsibility-model



The Shared Responsibility Model defines the security and operational responsibilities between Upstash and our customers when using Upstash Redis. This model ensures clarity in who is responsible for what aspects of security, compliance, and operations.

## Overview

Upstash Redis is a serverless database service that provides Redis¬Æ API compatibility with automatic scaling, high availability, and enterprise-grade security features. The shared responsibility model divides responsibilities into three main categories:

* **Upstash Responsibilities**: Infrastructure, platform, and service-level security
* **Customer Responsibilities**: Data, application, and access management
* **Shared Responsibilities**: Configuration, monitoring, and incident response

## Responsibility Matrix

| Category                    | Upstash                                                                             | Customer                                                                       | Shared                                        |
| --------------------------- | ----------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ | --------------------------------------------- |
| **Infrastructure Security** | ‚úÖ Physical security, network infrastructure, DDoS protection, hardware maintenance  | ‚ùå                                                                              | ‚ùå                                             |
| **Platform Security**       | ‚úÖ OS security, Redis updates, container security, infrastructure monitoring         | ‚ùå                                                                              | ‚ùå                                             |
| **Service Availability**    | ‚úÖ 99.99% SLA (Prod Pack), multi-region replication, auto-scaling, disaster recovery | ‚ùå                                                                              | ‚ùå                                             |
| **Data Encryption**         | ‚úÖ TLS in transit, encryption at rest (Prod Pack), key management                    | ‚ùå                                                                              | ‚ùå                                             |
| **Compliance**              | ‚úÖ SOC 2 (Prod Pack), GDPR, HIPAA (Enterprise)                                       | ‚ùå                                                                              | ‚ùå                                             |
| **Data Management**         | ‚ùå                                                                                   | ‚úÖ Data classification, retention policies, quality controls                    | ‚ùå                                             |
| **Application Security**    | ‚ùå                                                                                   | ‚úÖ Secure development, input validation, authentication, client-side encryption | ‚ùå                                             |
| **Access Control**          | ‚ùå                                                                                   | ‚úÖ Redis ACL, user permissions, credential management, MFA                      | ‚ùå                                             |
| **Network Security**        | ‚ùå                                                                                   | ‚úÖ IP allowlist, network segmentation, client security                          | ‚ùå                                             |
| **Security Configuration**  | ‚ùå                                                                                   | ‚ùå                                                                              | ‚úÖ ACL setup, security policies                |
| **Monitoring**              | ‚úÖ Infrastructure monitoring, incident response                                      | ‚úÖ Application monitoring, custom metrics                                       | ‚úÖ Performance monitoring, security monitoring |
| **Incident Response**       | ‚úÖ Infrastructure incidents, service restoration                                     | ‚úÖ Application incidents, data incidents                                        | ‚úÖ Incident coordination, root cause analysis  |

## Key Responsibilities

<AccordionGroup>
  <Accordion title="Upstash Responsibilities">
    **Infrastructure & Platform:**

    * Physical security, network infrastructure, DDoS protection
    * OS security, Redis updates, container security
    * 99.99% uptime SLA (Prod Pack), multi-region replication, auto-scaling
    * TLS encryption, encryption at rest (Prod Pack), key management
    * SOC 2 (Prod Pack), GDPR, HIPAA (Enterprise)
    * 24/7 infrastructure monitoring and incident response
  </Accordion>

  <Accordion title="Customer Responsibilities">
    **Data & Application Security:**

    * Architecture: retries/backoff, idempotency, timeouts; region/topology choices
    * Data governance: classification, retention, integrity
    * App security: secure coding, input validation, authN/authZ
    * Access: Redis ACL (least privilege), credential hygiene and rotation
    * Network: IP allowlist and client hardening
    * Ops: monitoring/alerts, error handling, budgets/limits
  </Accordion>

  <Accordion title="Shared Responsibilities">
    **Configuration & Operations:**

    * ACL, IP allowlist, and Prod Pack configuration
    * Compliance requirements understanding and implementation
    * Performance monitoring setup and alerting
    * Incident coordination and root cause analysis
  </Accordion>
</AccordionGroup>


# Support & Contact Us
Source: https://upstash.com/docs/redis/help/support



## Community

[Upstash Discord Channel](https://upstash.com/discord) is the best way to
interact with the community.

## Team

You can contact the team
via [support@upstash.com](mailto:support@upstash.com) for technical support as
well as questions and feedback.

## Follow Us

Follow us at [X](https://x.com/upstash).

## Professional Support

Get [Professional Support](/common/help/prosupport) from the Upstash team.


# Uptime Monitor
Source: https://upstash.com/docs/redis/help/uptime



## Status Page

You can track the uptime status of Upstash databases in
[Upstash Status Page](https://status.upstash.com)

## Latency Monitor

You can see the average latencies for different regions in
[Upstash Latency Monitoring](https://latency.upstash.com) page


# Connect Your Client
Source: https://upstash.com/docs/redis/howto/connectclient



Upstash works with Redis¬Æ API, that means you can use any Redis client with
Upstash. At the [Redis Clients](https://redis.io/clients) page you can find the
list of Redis clients in different languages.

Probably, the easiest way to connect to your database is to use `redis-cli`.
Because it is already covered in [Getting Started](../overall/getstarted), we
will skip it here.

## Database

After completing the [getting started](../overall/getstarted) guide, you will
see the database page as below:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4530264625c10bdf334129ec8b367511" data-og-width="1590" width="1590" data-og-height="1080" height="1080" data-path="img/getting_started/database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=729b8c0843969c86866b06e22747c785 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d44be677d29134227ff6839fbfc10674 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=414a590eb3c8ed98001a5a781a6268bf 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eca30f6532a78f7f25952b41beac50d5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e60ccc845ab5a2a2b4fb9d66ac0fe948 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b999e96686847b5aeeebc960cf2d5a30 2500w" />
</Frame>

The information required for Redis clients is displayed here as **Endpoint**,
**Port** and **Password**. Also when you click on `Clipboard` button on **Connect to your database** section, you can copy
the code that is required for your client.

Below, we will provide examples from popular Redis clients, but the information above should help you configure all Redis clients similarly.

<Note>
  TLS is enabled by default for all Upstash Redis databases. It's not possible
  to disable it.
</Note>

## upstash-redis

<Info>
  Because upstash-redis is HTTP based, we recommend it for Serverless functions.
  Other TCP based clients can cause connection problems in highly concurrent use
  cases.
</Info>

**Library**: [upstash-redis](https://github.com/upstash/upstash-redis)

**Example**:

```typescript  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = new Redis({
  url: "UPSTASH_REDIS_REST_URL",
  token: "UPSTASH_REDIS_REST_TOKEN",
});

(async () => {
  try {
    const data = await redis.get("key");
    console.log(data);
  } catch (error) {
    console.error(error);
  }
})();
```

## Node.js

**Library**: [ioredis](https://github.com/luin/ioredis)

**Example**:

```javascript  theme={"system"}
const Redis = require("ioredis");

let client = new Redis("rediss://:YOUR_PASSWORD@YOUR_ENDPOINT:YOUR_PORT");
await client.set("foo", "bar");
let x = await client.get("foo");
console.log(x);
```

## Python

**Library**: [redis-py](https://github.com/andymccurdy/redis-py)

**Example**:

```python  theme={"system"}
import redis
r = redis.Redis(
host= 'YOUR_ENDPOINT',
port= 'YOUR_PORT',
password= 'YOUR_PASSWORD',
ssl=True)
r.set('foo','bar')
print(r.get('foo'))
```

## Java

**Library**: [jedis](https://github.com/xetorthio/jedis)

**Example**:

```java  theme={"system"}
Jedis jedis = new Jedis("YOUR_ENDPOINT", "YOUR_PORT", true);
jedis.auth("YOUR_PASSWORD");
jedis.set("foo", "bar");
String value = jedis.get("foo");
System.out.println(value);
```

<Info>
  Jedis does not offer command level retry config by default, but you can handle
  retries using connection pool. Check [Retrying a command after a connection
  failure](https://redis.io/docs/latest/develop/clients/jedis/connect/#retrying-a-command-after-a-connection-failure)
</Info>

## PHP

**Library**: [phpredis](https://github.com/phpredis/phpredis)

**Example**:

```php  theme={"system"}
<?php

$redis = new Redis();

$redis->connect("YOUR_ENDPOINT", "YOUR_PORT");
$redis->auth("YOUR_PASSWORD");

$redis->set("foo", "bar");

print_r($redis->get("foo"));
```

<Info>
  Phpredis supports connection level retries through `OPT_MAX_RETRIES`. However,
  for command level retries, it only supports [SCAN
  command](https://github.com/phpredis/phpredis?tab=readme-ov-file#example-29).
</Info>

## Go

**Library**: [redigo](https://github.com/gomodule/redigo)

**Example**:

```go  theme={"system"}
func main() {
  c, err := redis.Dial("tcp", "YOUR_ENDPOINT:YOUR_PORT", redis.DialUseTLS(true))
  if err != nil {
      panic(err)
  }

  _, err = c.Do("AUTH", "YOUR_PASSWORD")
  if err != nil {
      panic(err)
  }

  _, err = c.Do("SET", "foo", "bar")
  if err != nil {
      panic(err)
  }

  value, err := redis.String(c.Do("GET", "foo"))
  if err != nil {
      panic(err)
  }

  println(value)
}
```


# Connect with upstash-redis
Source: https://upstash.com/docs/redis/howto/connectwithupstashredis



[upstash-redis](https://github.com/upstash/redis-js)
is an HTTP/REST based Redis client built on top of
[Upstash REST API](/redis/features/restapi). For more information,
refer to the documentation of Upstash redis client ([TypeScript](/redis/sdks/ts/overview) & [Python](/redis/sdks/py/overview)).

It is the only connectionless (HTTP based) Redis client and designed for:

* Serverless functions (AWS Lambda ...)
* Cloudflare Workers (see
  [the example](https://github.com/upstash/redis-js/tree/main/examples/cloudflare-workers-with-typescript))
* Fastly Compute\@Edge
* Next.js, Jamstack ...
* Client side web/mobile applications
* WebAssembly
* and other environments where HTTP is preferred over TCP.

See
[the list of APIs](https://docs.upstash.com/features/restapi#rest---redis-api-compatibility)
supported.

## Quick Start

### Install

```bash  theme={"system"}
npm install @upstash/redis
```

### Usage

```typescript  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = new Redis({
  url: "UPSTASH_REDIS_REST_URL",
  token: "UPSTASH_REDIS_REST_TOKEN",
});

(async () => {
  try {
    const data = await redis.get("key");
    console.log(data);
  } catch (error) {
    console.error(error);
  }
})();
```

If you define `UPSTASH_REDIS_REST_URL` and`UPSTASH_REDIS_REST_TOKEN` environment
variables, you can load them automatically.

```typescript  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = Redis.fromEnv()(async () => {
  try {
    const data = await redis.get("key");
    console.log(data);
  } catch (error) {
    console.error(error);
  }
})();
```


# Datadog - Upstash Redis Integration
Source: https://upstash.com/docs/redis/howto/datadog



This guide will walk you through the steps to seamlessly connect your Datadog account with Upstash for enhanced monitoring and analytics.

<Check>
  **Integration Scope**

  Upstash Datadog Integration only covers Pro databases or those included in the Enterprise Plan.
</Check>

## **Step 1: Log in to Your Datadog Account**

1. Open your web browser and navigate to [Datadog](https://www.datadoghq.com/).
2. Log in to your Datadog account.

## **Step 2: Install Upstash Application**

1. Once logged in, navigate to the "Integrations" page in Datadog.
2. Search for "Upstash" in the integrations list and click on it.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1d4018e79c0fedb23a2c8d21bc3b6a43" alt="integration-tab.png" data-og-width="2880" width="2880" data-og-height="1028" height="1028" data-path="img/datadog/integration-tab.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e20319650673fc0c2ddb267c8c521d59 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5eceb4e5af82406788781e8098229cf3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1e0ba16abd0046c3e8a65815eaa3fc19 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5ade8ad371aaf59d811824c6310887a2 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80c8644a9d8d417d9138d13143afaba0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eda063436df126a626dd96a87f22a050 2500w" />

Let‚Äôs click on the "Install" button to add Upstash to your Datadog account.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=add4288783757921f62353223fbf39b5" alt="installation.png" data-og-width="2802" width="2802" data-og-height="1384" height="1384" data-path="img/datadog/installation.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=142c3fcc921b90a0abc94bbeb8a7bae3 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b7a6aae307da8f8b9757e84cff0db8d3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=413d45cfe27a64e38c4e422c97984c8e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=ba35ec57c2be78e999358a701e533812 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=52b29977b08a6500f380adea36c6881c 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=811d297b670fc274b74322f932c80475 2500w" />

## **Step 3: Connect Accounts**

After installing Upstash, click on the "Connect Accounts" button and Datadog will redirect you to the Upstash site for account integration.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=64d0abd76d3037f01a3811cd531c46d4" alt="connect-acc.png" data-og-width="1756" width="1756" data-og-height="936" height="936" data-path="img/datadog/connect-acc.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=085212af402a08e0f7e89ba644529d48 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f379315b18a9f213fa92aa119ca32f81 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3a7dadd01cdd15abded31929223a534e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6b2fa6785253ca09d38a1c24cc081e4e 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f6630bbfe1b49efa9f4b6fc4f4cc3a22 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80054d3b9fa019a5bf1c1ee60334b116 2500w" />

## **Step 4: Select Account to Integrate**

1. On the Upstash site, you will be prompted to select the Datadog account you want to integrate.
2. Choose the appropriate Datadog account from the list.

Upstash Datadog Integration allows you to integrate personal and team based accounts.

**Caveats;**

* This integration can only be executed only one time.If you would like to extend list of the team in integration please re-establish the integration from scratch.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7d332ed4228eaba275329f458d1dbd2f" alt="personal.png" data-og-width="886" width="886" data-og-height="1026" height="1026" data-path="img/datadog/personal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f665cc6a4bbcf6d9d639c0b2b953fa0d 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a1f4954abf4877df690e05633d0e0142 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=be4a2b8f7e038b224d48dada4132866c 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b18d7807fa6df65216f98ed0d3526f5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4791a82eeec9a917746a8684751e99f0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d5cc8d1e39f3ab8058127a7bfc5a4f84 2500w" />

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=91af03309be7ba54f5c1e605052fe3cd" alt="team.png" data-og-width="950" width="950" data-og-height="1104" height="1104" data-path="img/datadog/team.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e0bcf3f87626d2f35dad5e349d8d530a 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e5a7d1921331a83c3b2b6d0485b418df 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=575a5ad465eaa4e5ff17a202f0dce775 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=67232bca77ab58e0be7a9ea6788caab9 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=71654ac0f72319d20778dacd0c9c2c3d 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6326dfc48f62069c3cb19a0f6b96a7ed 2500w" />

## **Step 5: Wait for Metrics Availability**

Once you've selected your Datadog account, Upstash will begin the integration process and please be patient while the metrics are being retrieved. This may take a few moments.

And here we go, metrics will be available in Upstash Overview Dashboard !

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=51602659ff8b8397d697275666548800" alt="upstash-dashboard.png" data-og-width="2560" width="2560" data-og-height="1446" height="1446" data-path="img/datadog/upstash-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1e0338139343dcd9c62da9bc00c2a938 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1d1770c140db5c4cc9f236dec7ca56bc 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=73066cef51f7d09a522fea104a927ecb 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=96acd006766b83ce668cd54caff36cc2 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eb025ce3c6349b3ec4d1a2c3ab868c20 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/upstash-dashboard.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=767658484b86f7e480fb5dc920fed64c 2500w" />

## **Step 6: Datadog Integration Removal Process**

Navigate to Integration Tab on your Datadog account,

Once logged in, navigate to the "Integration" tab and continue with Datadog part. If you would like to remove your integration between Upstash and Datadog account press "Remove".

### Confirm Removal:

Upstash will suspend all metric publishing process after the you remove Datadog Integration.

After removing the integration on the Upstash side, it's crucial to go to your Datadog account and remove any related API keys or configurations associated with the integration.

## Pricing

If you choose to integrate Datadog via Upstash, there will be an additional cost of \$5 per month.
This charge will be reflected in your monthly invoice accordingly.

## **Conclusion**

Congratulations! You have successfully integrated your Datadog account with Upstash. You will now have access to enhanced monitoring and analytics for your Datadog metrics.

Feel free to explore Upstash's features and dashboards to gain deeper insights into your system's performance.

If you encounter any issues or have questions, please refer to the Upstash support documentation or contact our support team for assistance.


# EMQX - Upstash Redis Integration
Source: https://upstash.com/docs/redis/howto/emqxintegration



EMQX, a robust open-source MQTT message broker, is engineered for scalable, distributed environments, prioritizing high
availability, throughput, and minimal latency. As a preferred protocol in the IoT landscape, MQTT (Message Queuing
Telemetry Transport) excels in enabling devices to effectively publish and subscribe to messages.

Offered by EMQ, EMQX Cloud is a comprehensively managed MQTT service in the cloud, inherently scalable and secure. Its
design is particularly advantageous for IoT applications, providing dependable MQTT messaging services.

This tutorial guides you on streaming MQTT data to Upstash via data integration. It allows clients to send temperature
and humidity data to EMQX Cloud using MQTT and channel it into Upstash for Redis storage.

## Setting Up Redis Database with Upstash

1. Log in and create a Redis Database by clicking the **Create Database** button on [Upstash Console](https://console.upstash.com).

2. Name your database and select a region close to your EMQX Cloud for optimal performance.

3. Click **Create** to have your serverless Redis Database ready.

![upstash](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_01.png)

### Database Details

Access the database console for the necessary information for further steps.

![upstash](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_02.png)

The above steps, conclude the initial setup for Upstash.

## Establishing Data Integration with Upstash

### Activating EMQX Cloud's NAT Gateway

1. Log into the EMQX Cloud console and go to the deployment Overview.

2. Select **NAT Gateway** at the bottom and click **Subscribe Now**.

![NAT](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/public_nat.png)

### Configuring Data Integration

1. In the EMQX Cloud console, choose **Data Integrations** and select **Upstash for Redis**.

   ![create resource](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_03.png)

2. Input **Endpoints** info from the Redis detail page into the **Redis Server** field, including the port. Enter the
   password in **Password** and click **Test** to ensure connectivity.
   ![create resource](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_04.png)

3. Click **New** to add a Redis resource. A new Upstash for Redis will appear under **Configured Resources**.

4. Formulate a new SQL rule in the **SQL** field. This rule will read from `temp_hum/emqx` and append client\_id, topic,
   timestamp.

   * `up_timestamp`: Message report time
   * `client_id`: Publishing client's ID
   * `temp`: Temperature data
   * `Hum`: Humidity data

```sql  theme={"system"}
SELECT
timestamp as up_timestamp,
clientid as client_id,
payload.temp as temp,
payload.hum as hum
FROM
"temp_hum/emqx"
```

![rule sql](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/kafka_create_sql.png)

5. Execute an SQL test with payload, topic, client info. Successful results confirm the rule's effectiveness.

   ![rule sql](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/kafka_create_sql_test.png)

6. Proceed to **Next** to link an action. The rule will store the timestamp, client ID, temperature, and humidity in
   Redis. Click **Confirm**.

   ```bash  theme={"system"}
   HMSET ${client_id} ${up_timestamp} ${temp}
   ```

   ![rule sql](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_05.png)

7. Post-binding, click **View Details** for the rule SQL and bound actions.

8. To review rules, select **View Created Rules** in Data Integrations. Check detailed metrics in the **Monitor**
   column.

## Testing the Data Bridge

1. Simulate temperature and humidity data with [MQTTX](https://mqttx.app/). Add connection address and client
   authentication for the EMQX Dashboard.
   ![MQTTX](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_kafka_06.png)

2. In Upstash Console, under Data Browser, select a client entry to review messages.

   ![monitor](https://raw.githubusercontent.com/emqx/cloud-docs/master/en_US/rule_engine/_assets/upstash_redis_07.png)


# Get Started with AWS Lambda
Source: https://upstash.com/docs/redis/howto/getstartedawslambda



You can connect to Upstash database from your Lambda functions using your
favorite Redis client. You do not need any extra configuration. The only thing
to note is you should use the same region for your Lambda function and database
to minimize latency.

If you do not have any experience with AWS Lambda functions, you can follow the
following tutorial. The tutorial explains the required steps to implement an AWS
Lambda function that takes the key/value as parameters from APIGateway then
inserts an entry (key/value) to the database which is on Upstash. We have
implemented the function in Node.js, but the steps and the logic are quite
similar in other languages.

<Note>
  This example uses Redis clients. If you expect many concurrent AWS Lambda
  invocation then we recommend using
  **[upstash-redis](/redis/howto/connectwithupstashredis)** which is HTTP/REST
  based.
</Note>

**Step 1: Create database on Upstash**

If you do not have one, create a database following this
[guide](../overall/getstarted).

**Step 2: Create a Node project**

Create an empty folder for your project and inside the folder create a node
project with the command:

```
npm init
```

Then install the redis client with:

```
npm install ioredis
```

Now create index.js file. Replace the Redis URL in the below code.

<Snippet file="redis/ioredisnote.mdx" />

```javascript  theme={"system"}
var Redis = require("ioredis");

if (typeof client === "undefined") {
  var client = new Redis("rediss://:YOUR_PASSWORD@YOUR_ENDPOINT:YOUR_PORT");
}
exports.handler = async (event) => {
  await client.set("foo", "bar");
  let result = await client.get("foo");
  let response = {
    statusCode: 200,
    body: JSON.stringify({
      result: result,
    }),
  };
  return response;
};
```

**Step 3: Deploy Your Function**

Our function is ready to deploy. Normally you could copy-paste your function
code to AWS Lambda editor. But here it is not possible because we have an extra
dependency (redis-client). So we will zip and upload our function.

When you are in your project folder, create a zip with this command:

```
zip -r app.zip .
```

Now open your AWS console, from the top-right menu, select the region that you
created your database in Upstash. Then find or search the lambda service, click
on `Create Function` button.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=41a2318c6d70be9672dc2723a98fb594" width="100%" data-og-width="2610" data-og-height="1460" data-path="img/awslambda/createfunction.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a2b35239fbd7e114999b7db335f964cf 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b3db2b6794c47d93a5eddcdd233e1005 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=a7d4afb3039459c4adc9961135b697e0 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=2cf57b76ccaecae1e6c9f8b644738a02 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=bfeab75ee6b738536bff6baf139206ad 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/createfunction.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=92790c5c7670d5f8180a4c180de339af 2500w" />
</Frame>

Enter a name for your function and select `Node.js 14.x` as runtime. Click
`Create Function`.

Now you are on the function screen, scroll below to `Function Code` section. On
`Code entry type` selection, select `Upload a .zip file`. Upload the `app.zip`
file you have just created and click on the `Save` button on the top-right. You
need to see your code as below:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=592b191224ba6ee04d13f67cdf130f3e" width="100%" data-og-width="2556" data-og-height="1250" data-path="img/awslambda/functioncode.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=38b094a1768c9545f3fc42e2646a83c0 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=3ac03f629bc106b193abea0d6845bb95 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=b68484c37611965f654ac08b9b63ca10 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=e414f38dd6363f42cada7235a41ec733 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=44e457af19727ac7aacef929ef914571 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/functioncode.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1ae2f984255e4ce6c11f862783311e8d 2500w" />
</Frame>

Now you can test your code. Click on the `Test` button on the top right. Create
an event like the below:

```
{
  "key": "foo",
  "value": "bar"
}
```

Now, click on Test. You will see something like this:

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d7b295ca30abb4c9925ea3c6de34176c" width="100%" data-og-width="1884" data-og-height="832" data-path="img/awslambda/success.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=79680feab46a3a3d391388b5e8e14a3b 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=c39790f9d2853d3d50e2af791927f6bc 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=59a3ac6431fedf667ecc3984f2dc7b33 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d24ddbd3a73dce1e513039eb1934161d 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0f33665fc23e464f5440e1f77567e5a3 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/awslambda/success.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=7261209a27b3c2497bf216fceb1c4cee 2500w" />
</Frame>

Congratulations, now your lambda function inserts entry to your Upstash
database.

**What can be the next?**

* You can write and deploy another function to just get values from the
  database.
* You can learn better ways to deploy your functions such as
  [serverless framework](https://serverless.com/) and
  [AWS SAM](https://aws.amazon.com/serverless/sam/)
* You can integrate
  [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-create-api-as-simple-proxy-for-lambda.html)
  so you can call your function via http.
* You can learn about how to monitor your functions from CloudWatch as described
  [here](https://docs.aws.amazon.com/lambda/latest/dg//monitoring-functions-logs.html)
  .

#### Redis Connections in AWS Lambda

Although Redis connections are very lightweight, a new connection inside each
Lambda function can cause a notable latency. On the other hand, reusing Redis
connections inside the AWS Lambda functions has its own drawbacks. When AWS
scales out Lambda functions, the number of open connections can rapidly
increase. Fortunately, Upstash detects and terminates the idle and zombie
connections thanks to its smart connection handling algorithm. Since this
algorithm is used; we have been recommending caching your Redis connection in
serverless functions.

<Info>
  See [the blog post](https://blog.upstash.com/serverless-database-connections)
  about the database connections in serverless functions.
</Info>

Below is our findings about various Redis clients' behaviours when connection is
created, a single command is submitted and then connection is closed. **Note
that these commands (AUTH, INFO, PING, QUIT, COMMAND) are not billed.**

| Client                                                | #Commands |   Issued Commands  |
| ----------------------------------------------------- | :-------: | :----------------: |
| [redis-cli](https://redis.io/topics/rediscli)         |     2     |   AUTH - COMMAND   |
| [node-redis](https://github.com/NodeRedis/node-redis) |     3     | AUTH - INFO - QUIT |
| [ioredis](https://github.com/luin/ioredis)            |     3     | AUTH - INFO - QUIT |
| [redis-py](https://github.com/andymccurdy/redis-py)   |     1     |        AUTH        |
| [jedis](https://github.com/xetorthio/jedis)           |     2     |     AUTH - QUIT    |
| [lettuce](https://github.com/lettuce-io/lettuce-core) |     2     |     AUTH - QUIT    |
| [go-redis](https://github.com/go-redis/redis)         |     1     |        AUTH        |


# Get Started with Cloudflare Workers
Source: https://upstash.com/docs/redis/howto/getstartedcloudflareworkers



This tutorial showcases using Redis with REST API in Cloudflare Workers. We will
write a sample edge function (Cloudflare Workers) which will show a custom
greeting depending on the location of the client. We will load the greeting
message from Redis so you can update it without touching the code.

See
[the code](https://github.com/upstash/examples/tree/master/examples/using-cloudflare-workers).

### Why Upstash?

* Cloudflare Workers does not allow TCP connections. Upstash provides REST API
  on top of the Redis database.
* Upstash is a serverless offering with per-request pricing which fits for edge
  and serverless functions.
* Upstash Global database provides low latency all over the world.

### Step-1: Create Redis Database

Create a free Global database from
[Upstash Console](https://console.upstash.com). Find your REST URL and token in
the database details page in the console. Copy them.

Connect your database with redis-cli and add some greetings

```shell  theme={"system"}
usw1-selected-termite-30690.upstash.io:30690> set GB "Ey up?"
OK
usw1-selected-termite-30690.upstash.io:30690> set US "Yo, what‚Äôs up?"
OK
usw1-selected-termite-30690.upstash.io:30690> set TR "Naber dostum?"
OK
usw1-selected-termite-30690.upstash.io:30690> set DE "Was ist los?"
```

### Step-2: Edge Function

The best way to work with Cloudflare Workers is to use
[Wrangler](https://developers.cloudflare.com/workers/get-started/guide). After
installing and configuring wrangler, create a folder for your project inside the
folder run: `wrangler init`

Choose `yes` to create package.json, `no` to typescript and `yes` to create a
worker in src/index.js.

It will create `wrangler.toml`, `package.json` and `src/index.js`.

Append the Upstash REST URL and token to the toml as below:

```toml  theme={"system"}
# wrangler.toml

# existing config

[vars]
UPSTASH_REDIS_REST_TOKEN = "AX_sASQgODM5ZjExZGEtMmI3Mi00Mjcwk3NDIxMmEwNmNkYjVmOGVmZTk5MzQ="
UPSTASH_REDIS_REST_URL = "https://us1-merry-macaque-31458.upstash.io/"
```

Install upstash-redis: `npm install @upstash/redis`

Replace `src/index.js` with the following:

```javascript  theme={"system"}
// src/index.js

import { Redis } from "@upstash/redis/cloudflare";

export default {
  async fetch(request, env) {
    const redis = Redis.fromEnv(env);

    const country = request.headers.get("cf-ipcountry");
    if (country) {
      const greeting = await redis.get(country);
      if (greeting) {
        return new Response(greeting);
      }
    }

    return new Response("Hello!");
  },
};
```

The code tries to find out the user's location checking the "cf-ipcountry"
header. Then it loads the correct greeting for that location using the Redis
REST API.

## Run locally

Run `wrangler dev` and open your browser at
[localhost:8787](http://localhost:8787).

## Build and Deploy

Build and deploy your app to Cloudflare by running: `wrangler publish`

The url of your app will be logged:
[https://using-cloudflare-workers.upstash.workers.dev/](https://using-cloudflare-workers.upstash.workers.dev/)

## Typescript example

We also have a typescript example, available
[here](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers-with-typescript).


# Get Started with Google Cloud Functions
Source: https://upstash.com/docs/redis/howto/getstartedgooglecloudfunctions



### Prerequisites:

* A GCP account for Google Cloud functions.
* Install [Google Cloud SDK](https://cloud.google.com/sdk/docs/install).
* An Upstash account for Serverless Redis.

### Step 1: Init the Project

* Create a folder, then run `npm init` inside the folder.

### Step 2: Install a Redis Client

Our only dependency is redis client. Install go-redis via `npm install ioredis`

### Step 3: Create a Redis Database

Create a Redis database from Upstash console. **Select the GCP US-Central-1 as
the region.** Free tier should be enough. It is pretty straight forward but if
you need help, check [getting started](../overall/getstarted) guide. In the
database details page, click the Connect button. You will need the endpoint and
password in the next step.

### Step 4: The function Code

Create index.js as below:

```javascript  theme={"system"}
var Redis = require("ioredis");

if (typeof client === "undefined") {
  var client = new Redis("rediss://:YOUR_PASSWORD@YOUR_ENDPOINT:YOUR_PORT");
}

exports.helloGET = async (req, res) => {
  let count = await client.incr("counter");
  res.send("Page view:" + count);
};
```

<Snippet file="redis/ioredisnote.mdx" />

The code simply increments a counter in Redis database and returns its value in
json format.

### Step 5: Deployment

Now we are ready to deploy our API. Deploy via:

```shell  theme={"system"}
gcloud functions deploy helloGET \
--runtime nodejs14 --trigger-http --allow-unauthenticated
```

You will see the URL of your Cloud Function. Click to the URL to check if it is
working properly.

```shell  theme={"system"}
httpsTrigger:
securityLevel: SECURE_OPTIONAL
url: https://us-central1-functions-317005.cloudfunctions.net/helloGET
```

In case of an issue, you can check the logs of your Cloud Function in the GCP
console as below.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=99ee8359e129827922ee7a215981bfcf" width="100%" data-og-width="2258" data-og-height="1000" data-path="img/examples/gcp-error.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0af6b90b27aca7cf2899180a35ec1a46 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b85aaef2412606c426858201ae8923f2 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=61b87875712681d9ab30f3f0d40d6ad6 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=358eb01f1d5da37a4d23e699d12ae834 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d1edbe5cea04238b861bc5e2368a4e6b 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/gcp-error.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2ec6728a891c7e76179c67a4a4299a24 2500w" />
</Frame>


# Import/Export Data
Source: https://upstash.com/docs/redis/howto/importexport



## Using Upstash Console

You can use the migration wizard in the
[Upstash console](https://console.upstash.com) to import your Redis to Upstash.
In the database list page, click on the `Import` button, you will see the dialog
like below:

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=99d17377bf60bf21d22b9aa5dd1c9d7e" width="60%" data-og-width="1058" data-og-height="1126" data-path="img/import/import.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=102a8daa70a8585410f3efebe2848175 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a8650496bf4d54db8a1121b5c1027315 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=814e8cd74042ec5e156f3d6183be8f9b 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f0e55279dcd2aff227cb96dcd87ba536 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d97cabd9ac40ef4110b991dbb8025f93 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/import/import.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=794c822ee814f035602b468d460eec35 2500w" />
</Frame>

You can move your data from either an Upstash database or a database in another
provider (or on premise).

<Info>
  All the data will be deleted (flushed) in the destination database before the
  migration process starts.
</Info>

## Using upstash-redis-dump

You can also use the
[upstash-redis-dump](https://github.com/upstash/upstash-redis-dump) tool
import/export data from another Redis.

The below is an example how to dump and import data:

```shell  theme={"system"}
$ upstash-redis-dump -db 0 -host eu1-moving-loon-6379.upstash.io -port 6379 -pass PASSWORD -tls > redis.dump
Database 0: 9 keys dumped
```

See [upstash-redis-dump repo](https://github.com/upstash/upstash-redis-dump) for
more information.


# ioredis note
Source: https://upstash.com/docs/redis/howto/ioredisnote



<Note>
  This example uses ioredis, you can copy the connection string from the `Node`
  tab in the console.
</Note>


# Use IP Allowlist
Source: https://upstash.com/docs/redis/howto/ipallowlist



<Info>
  IP Allowlist is available on all plans except for the free plan.
</Info>

IP Allowlist can be used to restrict which IP addresses are permitted to access your database by comparing a connection's address with predefined CIDR blocks. This feature enhances database security by allowing connections only from specified IP addresses. For example if you have dedicated production servers with static IP addresses, enabling IP allowlist blocks connections from other addresses.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=fe7461f8b0bed3087379e89050101dbe" alt="allowlist" data-og-width="1930" width="1930" data-og-height="264" height="264" data-path="img/ipallowlist/ipallowlist.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eba035250fb240a609d516152ed6e618 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c175125f56e9399ee399e560984bb911 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=690f622144438db97854fb053977b106 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ddf7573ae788a4816cf6a9a699d46819 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=48156fae282cf2bcdf4d2a974d25ad96 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/ipallowlist/ipallowlist.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a56d6cd2b3ee29c04ea39eaf01c90b7e 2500w" />

## Enabling IP Allowlist

By default, any IP address can be used to connect to your database. You must add at least one IP range to enable the allowlist. You can manage added IP ranges in the `Configuration` section on the database details page. You can either provide

* IPv4 address, e.g. `37.237.15.43`
* CIDR block, e.g. `181.49.172.0/24`

<Info>
  Currently, IP Allowlist only supports IPv4 addresses.
</Info>

You can use more than one range to allow multiple clients. Meeting the criteria of just one is enough to establish a connection.

<Note>
  It may take a few minutes for changes to propagate.
</Note>


# Listen Keyspace Notifications
Source: https://upstash.com/docs/redis/howto/keyspacenotifications



Upstash allows you to listen for keyspace notifications over pubsub channels to
receive events for changes over the keys.

For each event that occurs, two kinds of events are fired over the corresponding
pubsub channels:

* A keyspace event that will use the pubsub channel for the key, possibly containing
  other events for the same key
* A keyevent event that will use the pubsub channel for the event, possibly containing
  other events for the different keys

The channel names and their content are of the form:

* `__keyspace@0__:keyname` channel with the values of the event names for the keyspace
  notifications
* `__keyevent@0__:eventname` channel with the values of the key names for the keyevent
  notifications

## Enabling Notifications

By default, all keyspace and keyevent notifications are off. To enable it, you can use
the `CONFIG SET` command, and set the `notify-keyspace-events` options to one of the
appropriate flags described below.

<Warning>
  Each keyspace and keyevent notification fired might have an effect on the latency of the
  commands as the events are delivered to the listening clients and cluster members for
  multi-replica deployments. Therefore, it is advised to only enable the minimal subset of the
  notifications that are needed.
</Warning>

| Flag | Description                 |
| ---- | --------------------------- |
| K    | Keyspace events             |
| E    | Keyevent events             |
| g    | Generic command events      |
| \$   | String command events       |
| l    | List command events         |
| s    | Set command events          |
| h    | Hash command events         |
| z    | Sorted set command events   |
| t    | Stream command events       |
| d    | Module(JSON) command events |
| x    | Expiration events           |
| e    | Eviction events             |
| m    | Key miss events             |
| n    | New key events              |
| A    | Alias for g\$lshztxed       |

At least one of the `K` or `E` flags must be present in the option value.

For example, you can use the following command to receive keyspace notifications
only for the hash commands:

<Tabs>
  <Tab title="cURL">
    ```bash  theme={"system"}
    curl -X POST \
        -d '["CONFIG", "SET", "notify-keyspace-events", "Kh"]' \
        -H "Authorization: Bearer $UPSTASH_REDIS_REST_TOKEN" \
        $UPSTASH_REDIS_REST_URL
    ```
  </Tab>

  <Tab title="redis-cli">
    ```bash  theme={"system"}
    redis-cli --tls -u $UPSTASH_REDIS_CLI_URL config set notify-keyspace-events Kh
    ```
  </Tab>
</Tabs>

You can listen for all the channels using redis-cli to test the effect of the
above command:

```bash  theme={"system"}
redis-cli --tls -u $UPSTASH_REDIS_CLI_URL --csv psubscribe '__key*__:*'
```

### Disabling Notifications

You can reuse the `CONFIG SET` command and set `notify-keyspace-events` option to empty string
to disable all keyspace and keyevent notifications.

<Tabs>
  <Tab title="cURL">
    ```bash  theme={"system"}
    curl -X POST \
        -d '["CONFIG", "SET", "notify-keyspace-events", ""]' \
        -H "Authorization: Bearer $UPSTASH_REDIS_REST_TOKEN" \
        $UPSTASH_REDIS_REST_URL
    ```
  </Tab>

  <Tab title="redis-cli">
    ```bash  theme={"system"}
    redis-cli --tls -u $UPSTASH_REDIS_CLI_URL config set notify-keyspace-events ""
    ```
  </Tab>
</Tabs>

### Checking Notification Configuration

`CONFIG GET` command can be used the get the current value of the `notify-keyspace-events` option
to see the active keyspace and keyevent notifications configuration.

<Tabs>
  <Tab title="cURL">
    ```bash  theme={"system"}
    curl -X POST \
        -d '["CONFIG", "GET", "notify-keyspace-events"]' \
        -H "Authorization: Bearer $UPSTASH_REDIS_REST_TOKEN" \
        $UPSTASH_REDIS_REST_URL
    ```
  </Tab>

  <Tab title="redis-cli">
    ```bash  theme={"system"}
    redis-cli --tls -u $UPSTASH_REDIS_CLI_URL config get notify-keyspace-events
    ```
  </Tab>
</Tabs>


# Metrics and Charts
Source: https://upstash.com/docs/redis/howto/metricsandcharts



There are many metrics and charts in Upstash console. In this document, we will
explain what each of these charts refers to. There are two pages where you can
see charts and metrics:

## Database List

The charts on this page give aggregated and total information about the database
and your usage.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1bfeedaf3da962ac728ade0f96e4ec1b" width="100%" data-og-width="2090" data-og-height="1540" data-path="img/metrics/databaselist.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9f5e23291c80c5a3aa02d9024abbad38 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d60c81fe171fef9b3257815259d387f4 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=56538cecb9050942f9500d0728eb9478 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c7b121ccd46c58a6a919fec5aea3f843 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e9369de2b64d74d5de2cfeb6d554b780 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/databaselist.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e7bb54a2b09aca76f85b549716ed8ed2 2500w" />
</Frame>

In this chart, all your databases are listed. You can click on the name of the
database that you want to see detailed information. Also, the following
information is listed for each database:

* The region of the database
* The current size of the data
* The current count of active connections: Not that if your connections are
  short-lived then you may see 0 here most of the time.

## Database Detail

The charts on this page show metrics that are specific to the selected database.

### Current Month

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5877d4bebd845c27810cc8cc4ec3195f" width="100%" data-og-width="1944" data-og-height="350" data-path="img/metrics/current-month.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=58348a8cba19fe8d071f0e746e7e1534 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=96c5c3d4b43ebdd147285aa1a312a2fc 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c72087364242529c59ce0fcaa14aa493 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=48098af5c4446f6d5b36d11f58341b93 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9731d6481856da4118f6f13a8a153033 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/current-month.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=04c79d32f5c4f30e5301949b7919b370 2500w" />
</Frame>

* This chart shows the daily cost of the database. The chart covers the last 5
  days.

### Daily Request

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bb47018dbc1f7c992f1f638b7a640bee" width="100%" data-og-width="1900" data-og-height="558" data-path="img/metrics/requests5days.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9d1e00317449c35e1d6d8ee96ddcb9af 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=01ef6c41e745418cc659d656b9b1219b 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a90be9fbcd4bd7c1cd8baecfc5e51158 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c03f38a80a6bb1a9d8520ce17de6b935 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bf2fd7816efce742343be6f77bc25475 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/requests5days.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f12cbc08d87c4d2ca228b6d727d42702 2500w" />
</Frame>

This chart shows the daily total number of requests to the database. The chart
covers the last 5 days.

### Throughput

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bd9b68c5f978fc6528688d77ec5ef2c1" width="100%" data-og-width="1896" data-og-height="558" data-path="img/metrics/throughput.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=52242b6b52e92a8f947474cba552d9f5 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ccb5e6a53292600a6a1069ab680d8eb3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d54cf5cbd42f9a1bb60a5c2ec3e7b263 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f8854430aa52f6c60e89dc271bf994de 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9344006f469f3a4007940822d4ac45a8 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/throughput.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=69cf08913c6073d20d184feb5c1954bb 2500w" />
</Frame>

Throughput chart shows throughput values for reads, writes and commands (all
commands including reads and writes) per second. The chart covers the last 1
hour and it is updated every 10 seconds.

### Service Time Latency

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=93e539c79251a2a6b6f53418338df464" width="100%" data-og-width="1898" data-og-height="560" data-path="img/metrics/latency.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0a978605819cfd4cb753814c4c9f1f9c 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e549244ce396e45917257f270de2b5f6 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=314d3ac153d0b4d1201d5f06714e8ba9 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=cd44387ee7b07d3352aa42f12e4b11e6 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=7aa4ee3abda11ccbceaf8d9c689056cc 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/latency.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b64cb97ad59a2d33eba928c583f66b87 2500w" />
</Frame>

This chart shows the processing time of the request between it is received by
the server and the response is sent to the caller. It shows the times in max,
mean, min, 99.9 percentile and 99.99 percentile. The chart covers the last 1
hour and it is updated every 10 seconds.

### Data Size

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5566d7e0af3738a35fb29ce6b408d614" width="100%" data-og-width="1900" data-og-height="562" data-path="img/metrics/datasize.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8f64b1c8c788ec17b2d0fc3a4c51449b 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eab3501e9378bca8ede19195a78a0902 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1b3ec53524aff55722b13d9f15b18e68 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=18de16f7a97e6f694deec7fa4db5ead8 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9d0ff28a7c91c6dfba40f05234f5ed29 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/datasize.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=36c49d0bcf3b1c69fd8df1c3fb60a9d3 2500w" />
</Frame>

This chart shows the data size of your database. The chart covers the last 24
hours and it is updated every 10 seconds.

### Connections

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0e16374f40c7f79a5470ed23eb46e22a" width="100%" data-og-width="1904" data-og-height="560" data-path="img/metrics/connections.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=51ba2885311118b033a79feda598c88d 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=04fefef10b913c04008e3c8d6027091f 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b80eb884269755331d1aee639c863b56 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1f5e2cf09c5e0df00f3d9cac809fe75a 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f448256042bc5b2eca3c5de2f0bc62e3 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/connections.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f02a61abe45dd218efd05068eb73d01a 2500w" />
</Frame>

This chart shows the number of active client connections. It shows the number of
open connections plus the number of short-lived connections that started and
terminated in 10 seconds period. The chart covers the last 1 hour and it is
updated every 10 seconds.

### Key Space

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0064c3169cfef118f2758e6987243612" width="100%" data-og-width="1900" data-og-height="558" data-path="img/metrics/keyspace.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a908f4c0d9d549a2b3c063c45f3bc8ef 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=93da2da5edffa7c1701c85f320af43fe 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=cfecd002edbc698df1ced5485ee85a8a 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f55968ac469439e799216b56e4b8cb7b 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=94e9ebcec313fb1c0e3265999529940e 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/keyspace.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8312a62fa59e7b2d7ff06b0993d1b81d 2500w" />
</Frame>

This chart shows the number of keys. The chart covers the last 24 hours and it
is updated every 10 seconds.

### Hits / Misses

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2490381beaa6cb089397c8be234c1cb1" width="100%" data-og-width="1900" data-og-height="558" data-path="img/metrics/hitsmisses.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c9cfa43877934baffbd9b80e0941b011 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5dfa74f96d6e342944a8e4887d6aa535 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=805c93b859f1dc0851b230755b35d13f 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b91650317c60b586989634875eb0ff8a 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bf4e2af8f599800029eaf6a984054891 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/metrics/hitsmisses.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=08abe836b0b9df56b073cfb451453406 2500w" />
</Frame>

This chart shows the number of hits per second and misses per second. The chart
covers the last 1 hour and it is updated every 10 seconds.


# Migrate Regional to Global Database
Source: https://upstash.com/docs/redis/howto/migratefromregionaltoglobal



This guide will help you migrate your data from a regional Upstash Redis database to a global database.
If your database is Upstash Regional, we strongly recommend you to migrate to [Upstash Redis Global](/common/concepts/global-replication).
Our Regional Redis databases are legacy and deprecated.

## Why Migrate?

* New infrastructure, more modern and more secure
* Upstash Global is SOC-2 (included with Prod pack) and HIPAA (included with Enterprise) compatible
* Enhanced feature set: New features are only made available on Upstash Global
* Ability to add/remove read regions on the go
* Better performance as per our benchmarks

## Prerequisites

Before starting the migration, make sure you have:

1. An existing regional Upstash Redis database (source)
2. A new global Upstash Redis database (destination)
3. Access to both databases' credentials (connection strings, passwords)

## Migration Process

There are several official ways to migrate your data:

<Warning>
  If you are using RBAC, please note that they are not migrated automatically. You need to redefine ACL users for new the global database after migration.
</Warning>

### 1. Using Backup/Restore (Recommended for AWS Regional Databases)

If your regional database is hosted in AWS, you can use Upstash's backup/restore feature:

1. Create a backup of your regional database:

   * Go to your regional database details page
   * Navigate to the `Backups` tab
   * Click the `Backup` button
   * Provide a unique name for your backup
   * Wait for the backup process to complete

   <Info>
     During backup creation, some database operations will be temporarily unavailable.
   </Info>

2. Restore the backup to your global database:

   * Go to your global database details page
   * Navigate to the `Backups` tab
   * Click `Restore...`
   * Select your regional database as the source
   * Select the backup you created
   * Click `Start Restore`

   <Warning>
     The restore operation will flush (delete) all existing data in your (destination) global database before restoring the backup.
   </Warning>

### 2. Using Upstash Console Migration Wizard

The easiest way to migrate your data is using the Upstash Console's built-in migration wizard:

1. Go to [Upstash Console](https://console.upstash.com)
2. In the database list page, click the `Import` button
3. Select your source (regional) database
4. Select your destination (global) database
5. Follow the wizard instructions to complete the migration

<Info>
  Note: The destination database will be flushed before migration starts.
</Info>

### 3. Using upstash-redis-dump

Another reliable method is using the official [upstash-redis-dump](https://github.com/upstash/upstash-redis-dump) tool:

1. Install upstash-redis-dump:
   ```bash  theme={"system"}
   go install github.com/upstash/upstash-redis-dump@latest
   ```

2. Export data from regional database:
   ```bash  theme={"system"}
   upstash-redis-dump -db 0 -host YOUR_REGIONAL_HOST -port YOUR_DATABASE_PORT -pass YOUR_PASSWORD -tls > redis.dump
   ```

3. Import data to global database:
   ```bash  theme={"system"}
   redis-cli --tls -u redis://YOUR_PASSWORD@YOUR_REGIONAL_HOST:6379 --pipe < redis.dump
   ```

## Verification

After migration, verify your data:

1. Compare key counts in both databases
2. Sample test some keys to ensure data integrity

## Post-Migration Steps

1. Update your application configuration to use the new Global database URL
2. Test your application thoroughly with the new database
3. Monitor performance and consistency across regions
4. Keep the regional database as backup for a few days
5. Once verified, you can safely delete the regional database

## Need Help?

If you encounter any issues during migration, please contact Upstash support via chat, [support@upstash.com](mailto:support@upstash.com) or visit our Discord community for assistance.


# Monitor your usage
Source: https://upstash.com/docs/redis/howto/monitoryourusage



We support the Redis `MONITOR` command, a debugging command that allows you to see all requests processed by your Redis instance in real-time.

## Monitoring Your Usage - Video Guide

In this video, we'll walk through setting up a monitor instance step-by-step.

<Frame>
  <iframe id="intro-video" width="560" height="315" src="https://www.youtube.com/embed/tWIm396WAkI?rel=0&disablekb=1" title="YouTube video player" frameborder="0" allow="accelerometer; fullscreen; clipboard-write; encrypted-media; gyroscope" allowfullscreen />
</Frame>

<Note>
  The `MONITOR`command expects a persistent connection and, therefore, does not work over HTTP.
</Note>

In this video, we use `ioredis` to connect to our Upstash Redis database. Using an event handler, we can define what should happen for each executed command against on Redis instance. For example, logging all data to the console.

<RequestExample>
  ```ts Example theme={"system"}
  const monitor = await redis.monitor()

  monitor.on("monitor", (time, args, source, database) => {
    console.log(time, args, source, database)
  })
  ```
</RequestExample>


# Read Your Writes
Source: https://upstash.com/docs/redis/howto/readyourwrites



The "Read Your Writes" feature in Upstash Redis ensures that write operations are completed before subsequent read operations occur, maintaining data consistency in your application.

### How It Works

All write operations happen on the primary member and take time to propagate to the read replicas. Imagine that a client attempts to read an item immediately after it‚Äôs written. The read may go to a replica that hasn‚Äôt synced with the primary yet, resulting in stale data being returned.

RYW consistency solves this by returning a **sync token** after each request, which indicates the primary member‚Äôs state. In the next request, this sync token ensures the read replica syncs up to that token before serving the read.

So, the sync token acts as a checkpoint, ensuring that any read operations following a write reflect the most recent changes, even if they are served by a read replica.

Management of the sync token is handled automatically by the official [Typescript (version 1.34.0 and later)](/redis/sdks/ts/overview) and [Python (version 1.2.0 and later)](/redis/sdks/py/overview) SDKs of Upstash. When you initialize a Redis client with these SDKs, the writes made by that client will be respected during subsequent reads from the same client.

For REST users, you can achieve similar behavior by using the `upstash-sync-token` header. Each time you make a request, save the value of the `upstash-sync-token` header from the response and pass it in the `upstash-sync-token` header of your next request. This ensures that subsequent reads reflect the writes.

### Cross-Client Synchronization

Imagine that you are writing some key to Redis and then you read the same key from a different Redis client instance. In this case, the second client‚Äôs read request may not reflect the write made by the first client, as the sync tokens are updated independently in the two clients.

Consider these two example functions, each representing separate API endpoints:

```ts  theme={"system"}
export const writeRequest = async () => {
  const redis = Redis.fromEnv();
  const randomKey = nanoid();
  await redis.set(randomKey, "value");
  return randomKey;
};

export const readRequest = async (randomKey: string) => {
  const redis = Redis.fromEnv();
  const value = await redis.get(randomKey);
  return value;
};
```

If these functions are called in sequence, they will create two separate clients:

```ts  theme={"system"}
const randomKey = await writeRequest();
await readRequest(randomKey);
```

As explained above, in rare cases, one of your [read replicas](/redis/features/globaldatabase#primary-region-and-read-regions) can serve the `read` request before it receives the `write` update from the primary replica. To avoid this, if you are using `@upstash/redis` version 1.34.1 or later, you can pass the `readYourWritesSyncToken` from the first client to the second:

```ts  theme={"system"}
export const writeRequest = async () => {
  const redis = Redis.fromEnv();
  const randomKey = nanoid();
  await redis.set(randomKey, "value");

  // Get the token **after** making the write
  const token = redis.readYourWritesSyncToken;
  return { randomKey, token };
};

export const readRequest = async (
  randomKey: string,
  token: string | undefined
) => {
  const redis = Redis.fromEnv();

  // Set the token **before** making the read
  redis.readYourWritesSyncToken = token;

  const value = await redis.get(randomKey);
  return value;
};

const { randomKey, token } = await writeRequest();
await readRequest(randomKey, token);
```

Remember to get the sync token after the write request is completed, as the session token changes with each request.

For REST users or the Upstash Python SDK, a similar approach can be used. In Python, use `Redis._sync_token` instead of `readYourWritesSyncToken`.


# Terraform Provider
Source: https://upstash.com/docs/redis/howto/terraformprovider



You can use Upstash terraform provider to create your resources. API key is
required in order to create resources.

### Configure Provider

Provider requires your email address and api key which can be created in
console.

```
provider "upstash" {
  email = ""
  api_key = ""
}
```

### Create Database

As input you need to give database name, region and type.

```
resource "upstash_database" "mydb" {
  database_name = "testdblstr"
  region = "eu-west-1"
  type = "free"
}
```

You can output database credentials as following

```
output "endpoint" {
  value = "${upstash_database.mydb.endpoint}"
}

output "port" {
  value = "${upstash_database.mydb.port}"
}
output "password" {
  value = "${upstash_database.mydb.password}"
}
```

See our
[Terraform Provider Github Repository](https://github.com/upstash/terraform-provider-upstash)
for details and examples about Upstash Terraform Provider.


# Upgrade Your Database
Source: https://upstash.com/docs/redis/howto/upgradedatabase



Free tier has followings restrictions:

* Max 500K commands per month
* Max 256MB data size
* One free database per account

If you think your database is close to reaching any of these limits, we
recommend you to upgrade to pay-as-you-go plan which includes:

* No limit on requests per day
* Data size up to 100 GB

To upgrade your database, you need to have a payment method. You can add a
payment method as described [here](/common/account/addapaymentmethod). After you add
a payment method, Upstash restarts your database and your new database starts
with the pay-as-you-go plan.

See the [Pricing & Limits](../overall/pricing) for limits of the
pay-as-you-go and fixed plans. If you think, your use case will exceed those quotas,
contact us ([support@upstash.com](mailto:support@upstash.com)) for our [Enterprise Plan](../overall/enterprise)
where you can customize the limits.

<Note>
  During the upgrade process, you will not lose any data but your database will
  experience a downtime about 1-2 seconds. Your existing clients will be
  disconnected. So it is recommended to upgrade your database when there is the
  least activity.
</Note>


# Vercel - Upstash Redis Integration
Source: https://upstash.com/docs/redis/howto/vercelintegration



If you are using [Vercel](https://vercel.com/) then you can integrate Upstash
Redis, Vector, Search or QStash to your project easily. Upstash is the perfect serverless
solution for your applications thanks to its:

* Low latency data
* Per request pricing
* Durable storage
* Ease of use

Below are the steps of the integration.

## Add Integration to Your Vercel Account

Visit the [Upstash Integration](https://vercel.com/integrations/upstash) on
Vercel and click the `Install` button. If you are installing an Upstash integration
for the first time, you will be prompted to choosing between connecting an existing Upstash
account or letting Vercel manage an Upstash account for you.

<img src="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=7ddb17b7704d1783fd33fbec684d382f" width="520" data-og-width="1210" data-og-height="657" data-path="img/vercel/vercel_integration_create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=280&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=e2ab149cff9d2bfbac828e5fb65ffd27 280w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=560&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=f4fb69577ae86807900e89d5ee29e103 560w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=840&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=0d142acab3fdc121b8c6314229122638 840w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=1100&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=213c9ecd06073b85ed7de8bc4c84a395 1100w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=1650&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=aa0791adaa501f32d932d12848769456 1650w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_integration_create.png?w=2500&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=217ea8a4bfeb010faa10bfc926f03a58 2500w" />

In both cases, you will be able to create and use a redis database as usual. If you let Vercel
manage your Upstash account, you can handle payments, database creation and deletion directly from the Vercel dashboard.

If you choose to connect an existing Upstash account, you will be able to utilize features on Upstash Console
such as teams and audit logs.

### Option 1: "Create New Upstash Account"

If you choose this option, Vercel will prompt you to choose one of the products available on Upstash,
configure the database (by choosing database name, regions, plan). After you finish the configuration,
Vercel will create the Upstash account and the selected resources for you and redirect you to the
page of the created resource on Vercel dashboard.

On the Vercel dashboard, you will be able to find the credentials of the database, change the database
name, update the regions or plan.

<img src="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=146cab752ab283c660ca333bdc18ca14" width="520" data-og-width="1210" data-og-height="665" data-path="img/vercel/vercel_dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=280&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=4429f37ff266f8826dda35e2506d8d4e 280w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=560&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=39ff2bdf5c087b418ed4065dfced07d6 560w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=840&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=bebcb6ee873323e16796088a0dd6fb69 840w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=1100&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=6d18e6ca0fd8221d001bd266d1b1c3f1 1100w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=1650&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=fb00f1f4bf1a100578f3f291619b4a3e 1650w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/vercel_dashboard.png?w=2500&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=b78a544f6c7054240b612bd484675c45 2500w" />

You can also go to the `Settings` tab and connect your apps on Vercel to the database, making the credentials
of the database available to the app as environment variables.

### Option 2: "Link Existing Upstash Account"

Vercel will redirect you to Upstash, where you can select your Vercel project
and Upstash resources that you want to integrate.

<Tip>
  You should login to [the Upstash Console](https://console.upstash.com/) with your account if you
  are not logged in before clicking continue.
</Tip>

<Frame>
  <img src="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=3ba54cc2387ad309508e0ce02609a2f5" width="520" data-og-width="732" data-og-height="607" data-path="img/vercel/integration_init.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=280&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=8f9cdd777c0cf0045344552951d2046e 280w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=560&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=70a7d04d31aaea1d00c36b59a46e17ff 560w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=840&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=66f324ba3bc8291fc00e915d8610913e 840w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=1100&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=7083c6ebd83b23e3489431dce34c9ecc 1100w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=1650&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=518c13808bf283fb5babe404d4c107a4 1650w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_init.png?w=2500&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=167383774a2bcae7444818fe8cab5144 2500w" />
</Frame>

If you do not have a Redis database yet, you can create one
from the dropdown menu.

<Frame>
  <img src="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=4ed4dde36532aa6dafdf6e73a920617e" width="520" data-og-width="732" data-og-height="627" data-path="img/vercel/integration_redis_create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=280&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=99e105f480bbdf2504fae32d0665c945 280w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=560&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=2c9e066e78f912ef8c349474372e6e24 560w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=840&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=273b3a8ea22b3fb794fb6ff6b4500251 840w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=1100&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=d3cd2ae4d253e56a452ba41deefb03bb 1100w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=1650&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=d3df90bfad7c6877c8e67a4622498741 1650w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_redis_create.png?w=2500&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=4da2d68f1913703c0fcef731aaab24d9 2500w" />
</Frame>

Once you have selected all resources, click the `Save` button at the bottom of
the page.

After all environment variables are created, you will be forwarded to Vercel. Go
to your project settings where you can see all added environment variables.

<Tip>
  You need to redeploy your app for the environment variable to be used.
</Tip>

The [Integration Dashboard](https://console.upstash.com/integration/vercel)
allows you to see all your integrations, link new projects or manage existing
ones.

<Frame>
  <img src="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=9d0f827ee454d30d24636740f83dd30b" data-og-width="1199" width="1199" data-og-height="618" height="618" data-path="img/vercel/integration_dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=280&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=1743bcd4c549a4a3909273b3f9c95145 280w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=560&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=01e67d7ed31aa99999444d7a9c90c363 560w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=840&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=a9321fd78b137b5b17db53b690837d07 840w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=1100&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=cfcd45cf4a0ef149edabb801bc19c83f 1100w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=1650&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=37d2592873d4ca91531faedf7ebc47d3 1650w, https://mintcdn.com/upstash/jORuCV5FkbdVFZ31/img/vercel/integration_dashboard.png?w=2500&fit=max&auto=format&n=jORuCV5FkbdVFZ31&q=85&s=0842fcb83d911aac2e156275fe8fdc39 2500w" />
</Frame>

## Use Upstash in Your App

If you completed the integration steps above and redeploy your app, the added
environment variables will be accessible inside your Vercel application. You can
now use them in your clients to connect

### Redis

```ts  theme={"system"}
import { Redis } from "@upstash/redis";
import { type NextRequest, NextResponse } from "next/server";

const redis = Redis.fromEnv();

export const POST = async (request: NextRequest) => {
  await redis.set("foo", "bar");
  const bar = await redis.get("foo");
  return NextResponse.json({
    body: `foo: ${bar}`,
  });
}
```

### QStash

**Client**

```ts  theme={"system"}
import { Client } from "@upstash/qstash";

const client = new Client({
  token: process.env.QSTASH_TOKEN,
});

const res = await client.publishJSON({
  url: "https://my-api...",
  body: {
    hello: "world",
  },
});
```

**Receiver**

```ts  theme={"system"}
import { Receiver } from "@upstash/qstash";

const receiver = new Receiver({
  currentSigningKey: process.env.QSTASH_CURRENT_SIGNING_KEY,
  nextSigningKey: process.env.QSTASH_NEXT_SIGNING_KEY,
});

const isValid = await receiver.verify({
  signature: "..."
  body: "..."
})
```

### Vector

```ts  theme={"system"}
import { Index } from "@upstash/vector";

const index = new Index({
  url: process.env.UPSTASH_VECTOR_REST_URL,
  token: process.env.UPSTASH_VECTOR_REST_TOKEN,
});

await index.upsert({
  id: "1",
  data: "Hello world!",
  metadata: { "category": "greeting" }
})
```

### Search

```ts  theme={"system"}
import { Search } from "@upstash/search";

const client = new Search({
  url: process.env.UPSTASH_SEARCH_REST_URL,
  token: process.env.UPSTASH_SEARCH_REST_TOKEN,
});

const index = client.index("my-index");
await index.upsert({
  id: "1",
  content: { text: "Hello world!" },
  metadata: { category: "greeting" }
});
```

## Support

If you have any issue you can ask in our
[Discord server](https://discord.gg/w9SenAtbme) or send email at
[support@upstash.com](mailto:support@upstash.com)


# BullMQ with Upstash Redis
Source: https://upstash.com/docs/redis/integrations/bullmq



You can use BullMQ and Bull with Upstash Redis. BullMQ is a Node.js queue library that is built on top of Bull. It is a Redis-based queue library so you can use Upstash Redis as its storage.

## Install

```bash  theme={"system"}
npm install bullmq upstash-redis
```

## Usage

```javascript  theme={"system"}
import { Queue } from 'bullmq';

const myQueue = new Queue('foo', { connection: {
        host: "UPSTASH_REDIS_ENDPOINT",
        port: 6379,
        password: "UPSTASH_REDIS_PASSWORD",
        tls: {}
    }});

async function addJobs() {
    await myQueue.add('myJobName', { foo: 'bar' });
    await myQueue.add('myJobName', { qux: 'baz' });
}

await addJobs();
```

## Billing Optimization

BullMQ accesses Redis regularly, even when there is no queue activity. This can incur extra costs because Upstash charges per request on the Pay-As-You-Go plan. With the introduction of [our Fixed plans](/redis/overall/pricing#all-plans-and-limits), **we recommend switching to a Fixed plan to avoid increased command count and high costs in BullMQ use cases.**


# Celery with Upstash Redis
Source: https://upstash.com/docs/redis/integrations/celery



You can use **Celery** with Upstash Redis to build scalable and serverless task queues. Celery is a Python library that manages asynchronous task execution, while Upstash Redis acts as both the broker (queue) and the result backend.

## Setup

### Install Celery

To get started, install the necessary libraries using `pip`:

```bash  theme={"system"}
pip install "celery[redis]"
```

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com). Export the `UPSTASH_REDIS_HOST`, `UPSTASH_REDIS_PORT`, and `UPSTASH_REDIS_PASSWORD` to your environment:

```bash  theme={"system"}
export UPSTASH_REDIS_HOST=<YOUR_HOST>
export UPSTASH_REDIS_PORT=<YOUR_PORT>
export UPSTASH_REDIS_PASSWORD=<YOUR_PASSWORD>
```

You can also use `python-dotenv` to load environment variables from a `.env` file:

```text .env theme={"system"}
UPSTASH_REDIS_HOST=<YOUR_HOST>
UPSTASH_REDIS_PORT=<YOUR_PORT>
UPSTASH_REDIS_PASSWORD=<YOUR_PASSWORD
```

## Example Application

### Setting up Celery with Upstash Redis

```python tasks.py theme={"system"}
import os
from celery import Celery
from dotenv import load_dotenv

load_dotenv()

# Configure Celery with Upstash Redis
UPSTASH_REDIS_HOST = os.getenv("UPSTASH_REDIS_HOST")
UPSTASH_REDIS_PORT = os.getenv("UPSTASH_REDIS_PORT")
UPSTASH_REDIS_PASSWORD = os.getenv("UPSTASH_REDIS_PASSWORD")

connection_link = f"rediss://:{UPSTASH_REDIS_PASSWORD}@{UPSTASH_REDIS_HOST}:{UPSTASH_REDIS_PORT}?ssl_cert_reqs=required"

celery_app = Celery("tasks", broker=connection_link, backend=connection_link)

@celery_app.task
def add(x, y):
    return x + y
```

Note that we should use the `rediss://` protocol to connect to redis over TLS and set `ssl_cert_reqs=required` to enforce certificate validation.

### Running the Worker

Start the Celery worker to execute tasks:

```bash  theme={"system"}
celery -A tasks worker --loglevel=info
```

### Using the Task

You can now use the `add` task to perform background computations:

```python main.py theme={"system"}
from tasks import add

result = add.delay(4, 6)
print(f"Task state: {result.state}")  # Outputs 'PENDING' initially

# Wait for the result
output = result.get(timeout=10)
print(f"Task result: {output}")  # Outputs '10'
```

## Conclusion

To see a more detailed example of using Celery with Upstash Redis, check out the [Job Processor with Celery example](https://upstash.com/examples/jobprocessorwithcelery) on our website.

For more details on Celery, visit the [Celery Documentation](https://docs.celeryproject.org). For Upstash Redis, check out the [Upstash Redis Documentation](/redis).


# DrizzleORM with Upstash Redis
Source: https://upstash.com/docs/redis/integrations/drizzle



### Quickstart

DrizzleORM provides an `upstashCache()` helper to easily connect with Upstash Redis. To prevent surprises, the cache is always opt-in by default. Nothing is cached until you opt-in for a specific query or enable global caching.

1. **Install the package:**

```bash  theme={"system"}
npm install drizzle-orm@cache
```

2. **Configure your Drizzle instance:**

```ts  theme={"system"}
import { upstashCache } from "drizzle-orm/cache/upstash"
import { drizzle } from "drizzle-orm/..."

const db = drizzle(process.env.DB_URL!, {
  cache: upstashCache(),
})
```

You can also explicitly define your Upstash credentials, enable global caching for all queries by default (opt-out) or pass custom caching options:

```ts  theme={"system"}
import { upstashCache } from "drizzle-orm/cache/upstash"
import { drizzle } from "drizzle-orm/..."

const db = drizzle(process.env.DB_URL!, {
  cache: upstashCache({
    // üëá Redis credentials (optional ‚Äî can also be pulled from env vars)
    url: "<UPSTASH_URL>",
    token: "<UPSTASH_TOKEN>",
    // üëá Enable caching for all queries (optional, default false)
    global: true,
    // üëá Default cache behavior (optional)
    config: { ex: 60 },
  }),
})
```

***

### Cache Behavior

* **Per-query caching (opt-in, default):**\
  No queries are cached unless you explicitly call `.$withCache()`.

  ```ts  theme={"system"}
  await db.insert(users).value({ email: "cacheman@upstash.com" });

  // üëá reads from cache
  await db.select().from(users).$withCache()
  ```

* **Global caching:**\
  When setting `global: true`, all queries will read from cache by default.

  ```ts  theme={"system"}
  const db = drizzle(process.env.DB_URL!, {
    cache: upstashCache({ global: true }),
  })

  // üëá reads from cache (no more explicit `$withCache()`)
  await db.select().from(users)
  ```

  You can always turn off caching for a specific query:

  ```ts  theme={"system"}
  await db.select().from(users).$withCache(false)
  ```

***

### Manual Cache Invalidation

Cache invalidation is fully automatic by default. If you ever need to, you can manually invalidate cached queries by table name or custom tags:

```ts  theme={"system"}
// üëá invalidate all queries that use the `users` table
await db.$cache?.invalidate({ tables: ["usersTable"] })

// üëá invalidate all queries by custom tag (defined in previous queries)
await db.$cache?.invalidate({ tags: ["custom_key"] })
```

***

For more details on this integration, refer to the [Drizzle ORM caching documentation](https://cache.drizzle-orm-fe.pages.dev/docs/cache).


# Upstash MCP
Source: https://upstash.com/docs/redis/integrations/mcp



We provide an open source Upstash MCP to use natural language to interact with your Upstash account, e.g.:

* "Create a new Redis database in us-east-1"
* "List my databases"
* "Show all keys starting with "user:" in my users-db"
* "Create a backup"
* "Show me the throughput spikes for the last 7 days"

***

## Quickstart

### Step 1: Get your API Key

1. Go to `Account > Management API > Create API key` and create an API key.
   <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6f836a85ae3c72966f48885c3d450831" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/mcp/create-upstash-api-key.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a6a4f5b04f9ddaf4c95b8a2c541093bd 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5e82b612cffa5b4224be9ba12bd25798 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=409adc475e28bdbc45b1a357531bb08a 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=47cdc98dfc7f4c47128dcdc29e30cd51 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=30e541dfa7bd93358c5fe48b0de53451 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/create-upstash-api-key.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2d6163be507df6c7a430d143c6f4a7d 2500w" />
2. Note down your `<UPSTASH_EMAIL>` and `<UPSTASH_API_KEY>`.

***

### Step 2: Locate `mcp.json`

* **Cursor**: Navigate to `Cursor Settings > Features > MCP` and click `+ Add new global MCP server`. This will open the `mcp.json` file.
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=397c0ef714c08e365b83721b1e383f2f" data-og-width="1919" width="1919" data-og-height="1080" height="1080" data-path="img/mcp/cursor-mcp-settings.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2e42d06225b9b189b9be686e72752c05 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a8e5939c5760be8edbab1cedf2770f09 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=068b5ddc6f021a55158ca03bc913d357 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c138d351742e6cb2ac3607d70b1c6320 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3c00c5fcb0c671d727b36084b2200490 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/mcp/cursor-mcp-settings.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=197f47de70b9ee3336962b0758178606 2500w" />
* **Claude**: Navigate to `Settings > Developer` and click `Edit Config`. This will open the `claude_desktop_config.json` file. [Refer to the MCP documentation for more details](https://modelcontextprotocol.io/quickstart/user).
* **Copilot**: Create a `.vscode/mcp.json` file in your workspace directory. For Copilot, first update the `mcp.json` file as described in the next step on this page, then follow the [Copilot documentation (starting from step 2)](https://docs.github.com/en/copilot/customizing-copilot/extending-copilot-chat-with-mcp#configuring-mcp-servers-in-visual-studio-code) to configure MCP servers in VS Code Chat.

***

### Step 3: Configure the MCP File

There are two transport modes for MCP servers: `stdio` and `sse`.

* **Stdio**: Best for local development. The server runs locally, and the client connects directly to it.
* **SSE**: Designed for server deployments. However, since clients don't yet support SSE connections with all the features we need, you need a proxy server. The proxy acts as a `stdio` server for the client and communicates with the SSE server in the background.

#### Option 1: Stdio Server

Add the following configuration to your MCP file:

<CodeGroup>
  ```json Claude & Cursor theme={"system"}
  {
    "mcpServers": {
      "upstash": {
        "command": "npx",
        "args": [
          "-y",
          "@upstash/mcp-server",
          "run",
          "<UPSTASH_EMAIL>",
          "<UPSTASH_API_KEY>"
        ]
      }
    }
  }
  ```

  ```json Copilot theme={"system"}
  {
    "servers": {
      "upstash": {
        "type": "stdio",
        "command": "npx",
        "args": [
          "-y",
          "@upstash/mcp-server",
          "run",
          "<UPSTASH_EMAIL>",
          "<UPSTASH_API_KEY>"
        ]
      }
    }
  }
  ```
</CodeGroup>

#### Option 2: SSE Server with Proxy

SSE (Server-Sent Events) is the next stage in MCP transport modes after `stdio`. It is designed for server deployments and will eventually be followed by an HTTP-based transport mode. However, since clients currently do not support direct connections to SSE servers, we use a proxy to bridge the gap.

The proxy, powered by `supergateway`, acts as a `stdio` server locally while communicating with the SSE server in the background. This allows you to use the SSE server seamlessly with your client.

Add the following configuration to your `mcp.json` file:

<CodeGroup>
  ```json Claude & Cursor theme={"system"}
  {
    "mcpServers": {
      "upstash": {
        "command": "npx",
        "args": [
          "-y",
          "supergateway",
          "--sse",
          "https://mcp.upstash.io/sse",
          "--oauth2Bearer",
          "<UPSTASH_EMAIL>:<UPSTASH_API_KEY>"
        ]
      }
    }
  }
  ```

  ```json Copilot theme={"system"}
  {
    "servers": {
      "upstash": {
        "type": "stdio",
        "command": "npx",
        "args": [
          "-y",
          "supergateway",
          "--sse",
          "https://mcp.upstash.io/sse",
          "--oauth2Bearer",
          "<UPSTASH_EMAIL>:<UPSTASH_API_KEY>"
        ]
      }
    }
  }
  ```
</CodeGroup>

***

### Step 4: Use MCP with Your Client

Once your MCP is configured, your client can now interact with the MCP server for tasks like:

* Seeding data
* Querying databases
* Creating new databases
* Managing backups
* Analyzing performance metrics

For example, you can ask your client to "add ten users to my Redis database" or "show me the throughput spikes for the last 7 days."


# n8n with Upstash Redis
Source: https://upstash.com/docs/redis/integrations/n8n



## Quickstart

In this quickstart we're going to set up an Redis node in n8n using Upstash Redis, and go over an example use case step by step.

***

### Step 1: Get Your Upstash Redis Credentials

1. Go to Upstash Console and create a Redis database if you don't have any
2. Note down your credentials in the details page, we will be using those to connect Redis
   Node in n8n to our Upstash Redis instance.
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=293c28caa72112f9bc65bd47286fb998" data-og-width="1296" width="1296" data-og-height="1002" height="1002" data-path="img/n8n/redis-credentials.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=558de513f4db32937abd719b2d97c702 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=a8109e271366d915e72906b7a836b19f 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=1097bc6589a8b04515896108836ae6f2 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=f98c42f3d7f6206f3c0f9342d87a2f19 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=18a59c02bedc67e50ca243ec0dc2d058 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-credentials.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=935e03368d2cd43c6d4a7cd84b6c38c0 2500w" />

***

### Step 2: Set Up an n8n Project

1. Go to [https://n8n.io](https://n8n.io) and create a new project
2. Create a Trigger as Webhook with default settings, this will be our entry point. Our Redis instances gonna watch the visits to this url.
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=46fccbccd381de6cb7a4e7a6238a2395" data-og-width="1940" width="1940" data-og-height="1044" height="1044" data-path="img/n8n/webhook.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=2840fcb0514aa9fd29904c3b86b02787 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=ee46e8d40b539cdd0f8628d313f54e9f 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=aa5a727dc846da79fa3b05d66c6eb735 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=2fad07185afd20ec5f627fdc73d79f0d 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=d1e6aef67c2c704d11eba58c510b3f34 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/webhook.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=693cd81b6f8a6cec7effdf0656e55a69 2500w" />

***

### Step 3: Create a Redis Node

Now, Let's create a redis node and connect it to our Upstash Redis instance

1. Search for redis in nodes, and select increment action.
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=17210dc691c9727719aa8b2e7c13b4b7" data-og-width="1940" width="1940" data-og-height="1108" height="1108" data-path="img/n8n/redis-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=21305ab4e1b3692fefb541a0604495d9 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=f57b6f819de738965a8fdb742050df1b 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=a253417c3efe88098458545bc68aa585 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=623227d90c713d2d9d9a75150055fb9b 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=50114b2ab0c1525d8b48bcefdd179169 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-1.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=fa1517308989617be05d84342627372a 2500w" />

2. In the opening window, click select credentials, and create new credentials.
   Later, for other redis nodes, this will be saved and used automatically.
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=5886973b53daaa61f2ce68d22ed582ce" data-og-width="1940" width="1940" data-og-height="1184" height="1184" data-path="img/n8n/redis-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=05e58e83a42231e959ef4547e3cc428d 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=59890df027b5f472179be691f73f5b8e 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=ad7e1a1730fb4c61ca6de0ce8c8dba51 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=54b8704f321571db05ee7156f8c89151 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=71955838f50775c68c6eb2148fe521f0 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-2.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=914f51b4f4fe8b3721be51db7dbfd855 2500w" />

3. Fill the credentials.

   * Pass your Upstash Token to the password field.
   * Leave the user field blank
   * Pass your Upstash Redis endpoint to the host field. (Leave the https\:// part out)
   * If your Upstash Database has a port other than the default 6379, change it here.

   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=b70059ad2814d8247382d5b7c85771ff" data-og-width="1940" width="1940" data-og-height="1182" height="1182" data-path="img/n8n/redis-3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=bb5523fa801bdfda785eebf717d3f606 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=93c9b80e7157395d87a7c960e636df83 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=55f4036c037979c91000bc0cbae329fd 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=14cd77f09755336c19a2c09b3fb958e1 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=cec94da1a6bc7c5df368fad08fa9c086 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-3.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=56eeaab28cfcb05d27891dee4cb65fa2 2500w" />

4. Enable SSL (Upstash Redis requires SSL) and hit the save button.
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=4fa61b1766a9660896b4cd006bee3998" data-og-width="1940" width="1940" data-og-height="1182" height="1182" data-path="img/n8n/redis-4.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=939c1ef664e333602e1764bcdb81f6c4 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=04bc388586ad1e1e0080b44b54355c25 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=8468e6d6949182c03a4fd294c399c0b3 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=718757ed3bc098a8287370a6de3d0177 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=2fd733d5ee8eb57a607a565f0b54c836 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-4.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=92909303daedb6d2f78e196be3ae4dcb 2500w" />

***

### Redis Example: Store the Visit Count per Visitor

1. Track the users with `x-real-ip`
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=9eee362c716758f14a5708525ab7f67f" data-og-width="1162" width="1162" data-og-height="716" height="716" data-path="img/n8n/redis-increment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=85e7d6d505fbe16a0b78a0fcf7ec4285 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=1e21288675aa6dab3a067471ad8732fc 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=3134cd19f6b5a6e5728152a029f8c4c2 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=db3efceea20d032531f7c17ddc45f2b4 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=9cc48d9c586b374163085a75611429c2 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-increment.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=5a777218e790e7c15b5efa31298d7a58 2500w" />
2. Add another redis node with get action to see the visit counts
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=42249a3617a1789a5b42cdf83f585473" data-og-width="1940" width="1940" data-og-height="1108" height="1108" data-path="img/n8n/redis-get.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=8cdf12062830a80ac6dc665d4118d94b 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=04d246258e3c28eff823ca4faf9b21b2 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=8b9a184ea20f41b9d5c021cddcc134d5 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=ed89e1917c8f8446998b1a36ff0b6255 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=d3723e58a01a7ac24dc6af8308c937cc 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=c56ef7f7cb15950c7d5cec6e48d54afb 2500w" />
3. Read the set visit count with redis get
   <img src="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=adae35c65316e902112286724d772b89" data-og-width="1940" width="1940" data-og-height="1572" height="1572" data-path="img/n8n/redis-get-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=280&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=5a61abf209a3346e5e48cf3c5e8b1d3c 280w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=560&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=9947b2f77fdab58cb6122fb74acaf840 560w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=840&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=f444307a7ac571c1571ea28605713d7f 840w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=1100&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=2ed4d47c1a155f4e1da4878c734ae96e 1100w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=1650&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=7967dd19ed0eb118119256149b0a89d9 1650w, https://mintcdn.com/upstash/H3SBHpRUOHZbOxSA/img/n8n/redis-get-2.png?w=2500&fit=max&auto=format&n=H3SBHpRUOHZbOxSA&q=85&s=42c0266758d3ce668174507bf0ae7683 2500w" />

***

### Test Redis Example

Run the workflow and visit the webhook URL, This will send a get request and trigger the workflow run.
Then from the headers your ip will be fetched and in the redis instance you will see `user:user-ip` set to `1`.
As you visit the page it will be incremented and at the end of the workflow you can track and confirm this setup with
the get request.

***


# Prometheus - Upstash Redis Integration
Source: https://upstash.com/docs/redis/integrations/prometheus



To monitor your Upstash database in Prometheus and visualize metrics in Grafana, follow these steps:

<Check>
  **Integration Scope**

  Upstash Prometheus Integration only covers Pro databases or those included in the Enterprise Plan.
</Check>

## **Step 1: Log in to Your Upstash Account**

1. Open your web browser and navigate to [Upstash](https://console.upstash.com/).
2. Navigate to the main dashboard, where you‚Äôll see a list of your databases.

## **Step 2: Select your Database**

1. Select the database you want to integrate with Prometheus.
2. This will open the database settings, where you can manage various configuration options for your selected database.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=40fe38535d9e2fbdb7d59428c6a94f6d" alt="configuration.png" data-og-width="1938" width="1938" data-og-height="610" height="610" data-path="img/prometheus/configuration.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c92a8f1602b50cde5ec240868f45e0d2 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d07d75368b10aa356a11c185a3cd4f99 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e0fe31a301dbfaaf6371636cf1ea3830 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6854568834b20b13ae8b9fff9c2ec58e 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b159937d273d58bf69326cea3a0d6e53 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/configuration.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=76e60d4cc2474fbfe5841a1ae5d7f86e 2500w" />

3. Enable Prometheus by toggling the switch. This allows you to monitor metrics related to your Upstash database performance, usage, and other key metrics.

## **Step 3: Connect Accounts**

1. After enabling Prometheus, a monitoring token is generated and displayed.

2. Copy this token. This token is unique to your database and is required to authenticate Prometheus with the Upstash metrics endpoint.

<Check>
  **Header Format**

  You should add monitoring token according to this format `Bearer <MONITORING_TOKEN>`
</Check>

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2618f754b9209f28f30d27b16a652786" alt="monitoring-token.png" data-og-width="950" width="950" data-og-height="520" height="520" data-path="img/prometheus/monitoring-token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bd809c06e4421719c1195a3542a16cfb 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2721266c30939e15e371087ba8d8531 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=dbf58ef63addcf094f3cd2ea1e4ddd2b 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=65e3183a923ab6bfcb7c1e55cbce5a27 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0d9ad474b754c5a3ac37fff5155f22c0 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bb17a652adc3478d3b68704d29886aa4 2500w" />

## **Step 4: Set Up Prometheus Connection**

### **Grafana Dashboard Setup**

1. Open your Grafana instance, navigate to the Data Sources section, and select Prometheus as the data source.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3dce2b10059a2eb96d8d560bdabb7303" alt="datasource.png" data-og-width="1848" width="1848" data-og-height="464" height="464" data-path="img/prometheus/datasource.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=325217df537ca2f7269c4d38803b952f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9264339789011443e61167e443c0ae8a 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c1a7c769e5b857d21a733aec149233a8 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1e156eabf6c5c92c9ab2aa54d175667a 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eb464cb41c5bc5d8906f09c6a70f5c2b 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9a0c6ef2b3f5989c557a6b9d054dc0b7 2500w" />

2. Enter the data source name, set `https://api.upstash.com/monitoring/prometheus` as the data source address, and then add your monitoring token in the HTTP Headers section.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f32611d6c8cedb2b6a73d21e9b8a1cd5" alt="headers.png" data-og-width="1322" width="1322" data-og-height="346" height="346" data-path="img/prometheus/headers.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=613ce8cdff83bfadfbd95e40fac9548f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3edb89b53a21ffc79173c03e0c0bd7b 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d624ffcce430e3014319386a7de649d5 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4fb91d8f22449f95fc91704839fb1eb5 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6a5a66bed411dde641fbcf8a6111de7d 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1f60d9ffdf856ad140c8f470e1e9028e 2500w" />

3. Then, click <b>Test and Save</b> to verify that the data source is working properly.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6e3f9cc214486c59085fe036a0dd6a28" alt="datasource-final.png" data-og-width="1560" width="1560" data-og-height="412" height="412" data-path="img/prometheus/datasource-final.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a97d2c20d4cae7002e57524de561937b 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e93e44229ab80a44a9115225b65c8742 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2d542697335e6b8e3ca346cd5371292d 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bde3d4b76f3d4f0f4712a307d1d90f12 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a15201c139e232a3ca6a6599e35a119a 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2950933a8fb225e5ddfc04143a36a111 2500w" />

### **Prometheus Federation Setup**

Federation lets your Prometheus pull metrics from Upstash‚Äôs API and store them in **your own** Prometheus instance, so Grafana can query your Prometheus instead of hitting the Upstash endpoint directly.

#### When to use federation

* You already run Prometheus and want to persist Upstash metrics locally.
* You want to control retention, recording rules, or alerts on Upstash metrics

1. Set up a new scrape job in your Prometheus configuration file (`prometheus.yml`):

```yaml  theme={"system"}
scrape_configs:
  # Federation job: pull from Upstash API
  - job_name: "federate_upstash"
    honor_labels: true
    metrics_path: "/monitoring/prometheus/federate"
    scheme: https
    params:
      match[]:
        - 'upstash_db_metrics{}'
    static_configs:
      - targets:
          - "api.upstash.com"
    authorization:
      type: Bearer
      credentials: "<MONITORING_TOKEN>"
```

<Check>
  This configuration assumes you want to pull all metrics. You can adjust the `match[]` parameter to filter specific metrics if needed.

  * `upstash_db_metrics{database_id="your_database_id"}` can be used to pull metrics for a specific database
  * `upstash_db_metrics{replica_id=~"us-east-1.*"}` can be used to pull metrics for replicas in a specific region
</Check>

2. Verify the Federation Target

* Reload (or restart) your Prometheus server to apply the new configuration.
* Visit **Prometheus ‚Üí Status ‚Üí Targets** and confirm `federate_upstash` is **UP**

## **Step 5: Wait for Metrics Availability**

To visualize your Upstash metrics, you can use a pre-built Grafana dashboard.

Select your Prometheus data source when prompted, and complete the import.

Please check this address to access Upstash Grafana Dashboard <a href="https://grafana.com/grafana/dashboards/22257-upstash-redis-dashboard/"> Dashboard </a>

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=372dafae3c34f39565a23447bbc4446f" alt="grafana-dashboard.png" data-og-width="1800" width="1800" data-og-height="1118" height="1118" data-path="img/prometheus/grafana-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=078efa29ccdeff007763151e040738eb 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e30a8d619a54ee3c237fd81a47b7f8a0 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eb6ded213e28397f031a313a7f6db6e8 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3d1f54b522869dbfb12106f76f066149 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=23b8d80dfec0485b0e581964d764a230 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/grafana-dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=05144eda40660dd53e0465cee0aad5e5 2500w" />

## **Conclusion**

You've now integrated your database with Upstash Prometheus, providing access to improved monitoring and analytics.

Feel free to explore Upstash's features and dashboards to gain deeper insights into your system's performance.

If you encounter any issues or have questions, please refer to the Upstash support documentation or contact our support team for assistance.


# Configure Upstash Ratelimit Strapi Plugin
Source: https://upstash.com/docs/redis/integrations/ratelimit/strapi/configurations



After setting up the plugin, it's possible to customize the ratelimiter algorithm and rates. You can also define different rate limits and rate limit algorithms for different routes.

## General Configurations

<ParamField path="enabled" type="boolean" default="true">
  Enable or disable the plugin.
</ParamField>

## Database Configurations

<ParamField path="token" type="string" required>
  The token to authenticate with the Upstash Redis REST API. You can find this
  credential on Upstash Console with the name `UPSTASH_REDIS_REST_TOKEN`
</ParamField>

<ParamField path="url" type="string" required>
  The URL for the Upstash Redis REST API. You can find this credential on
  Upstash Console with the name `UPSTASH_REDIS_REST_URL`
</ParamField>

<ParamField path="prefix" type="string" default="@strapi">
  The prefix for the rate limit keys. The plugin uses this prefix to store the
  rate limit data in Redis. <br />
  For example, if the prefix is `@strapi`, the key will be
  `@strapi:<method>:<route>:<identifier>`.
</ParamField>

<ParamField path="analytics" type="boolean" default="false">
  Enable analytics for the rate limit. When enabled, the plugin extra insights
  related to your ratelimits. You can use this data to analyze the rate limit
  usage on [Upstash Console](https://console.upstash.com/ratelimit).
</ParamField>

## Strategy

The plugin uses a strategy array to define the rate limits per route. Each strategy object has the following properties:

<ParamField path="methods" type="('GET' | 'POST' | 'DELETE' | 'PUT' | 'PATCH' |'ALL')[]" required>
  An array of HTTP methods to apply the rate limit. <br />
  For example, `["GET", "POST"]`
</ParamField>

<ParamField path="path" type="string" required>
  The path to apply the rate limit. You can use wildcards to match multiple
  routes. For example, `*` matches all routes. <br />
  Some examples: <br />

  * `path: "/api/restaurants/:id"` <br />
  * `path: "/api/restaurants"` <br />
</ParamField>

<ParamField path="identifierSource" type="string" required>
  The source to identifiy the user. Requests with the same identifier will be
  rate limited under the same limit. <br />
  Available sources are: <br />

  * `ip`: The IP address of the user. <br />
  * `header`: The value of a header key. You should pass the source in the `header.<HEADER_KEY>` format. <br />
    For example, `header.Authorization` will use the value of the `Authorization`
</ParamField>

<ParamField path="debug" type="string">
  Enable debug mode for the route. When enabled, the plugin logs the remaining
  limits and the block status for each request. <br />
</ParamField>

<ParamField path="limiter" type="object" required>
  The limiter configuration for the route. The limiter object has the following
  properties:

  <Card>
    <ParamField path="algorithm" type="'fixed-window' | 'sliding-window' | 'token-bucket'" required>
      The rate limit algorithm to use. For more information related to algorithms, see docs [**here**](/redis/sdks/ratelimit-ts/algorithms). <br />

      * `fixed-window`: The fixed-window algorithm divides time into fixed intervals. Each interval has a set limit of allowed requests. When a new interval starts, the count resets. <br />
      * `sliding-window`:
        The sliding-window algorithm uses a rolling time frame. It considers requests from the past X time units, continuously moving forward. This provides a smoother distribution of requests over time. <br />
      * `token-bucket`: The token-bucket algorithm uses a bucket that fills with tokens at a steady rate. Each request consumes a token. If the bucket is empty, requests are denied. This allows for bursts of traffic while maintaining a long-term rate limit.<br />
    </ParamField>

    <ParamField path="tokens" type="number" required>
      The number of tokens allowed in the time window. <br />
    </ParamField>

    <ParamField path="window" type="string" required>
      The time window for the rate limit. Available units are `"ms" | "s" | "m" | "h" | "d"` <br />
      For example, `20s` means 20 seconds.
    </ParamField>

    <ParamField path="refillRate" type="number">
      The rate at which the bucket refills. **This property is only used for the token-bucket algorithm.** <br />
    </ParamField>
  </Card>
</ParamField>

## Examples

<CodeGroup>
  ```json Apply rate limit for all routes theme={"system"}
  {
     "strapi-plugin-upstash-ratelimit":{
        "enabled":true,
        "resolve":"./src/plugins/strapi-plugin-upstash-ratelimit",
        "config":{
           "enabled":true,
           "token":"process.env.UPSTASH_REDIS_REST_TOKEN",
           "url":"process.env.UPSTASH_REDIS_REST_URL",
           "strategy":[
              {
                 "methods":[
                    "GET",
                    "POST"
                 ],
                 "path":"*",
                 "identifierSource":"header.Authorization",
                 "limiter":{
                    "algorithm":"fixed-window",
                    "tokens":10,
                    "window":"20s"
                 }
              }
           ],
           "prefix":"@strapi"
        }
     }
  }
  ```

  ```json Apply rate limit with IP theme={"system"}
  {
    "strapi-plugin-upstash-ratelimit": {
      "enabled": true,
      "resolve": "./src/plugins/strapi-plugin-upstash-ratelimit",
      "config": {
        "enabled": true,
        "token": "process.env.UPSTASH_REDIS_REST_TOKEN",
        "url": "process.env.UPSTASH_REDIS_REST_URL",
        "strategy": [
          {
            "methods": ["GET", "POST"],
            "path": "*",
            "identifierSource": "ip",
            "limiter": {
              "algorithm": "fixed-window",
              "tokens": 10,
              "window": "20s"
            }
          }
        ],
        "prefix": "@strapi"
      }
    }
  }
  ```

  ```json Routes with different rate limit algorithms theme={"system"}
  {
    "strapi-plugin-upstash-ratelimit": {
      "enabled": true,
      "resolve": "./src/plugins/strapi-plugin-upstash-ratelimit",
      "config": {
        "enabled": true,
        "token": "process.env.UPSTASH_REDIS_REST_TOKEN",
        "url": "process.env.UPSTASH_REDIS_REST_URL",
        "strategy": [
          {
            "methods": ["GET", "POST"],
            "path": "/api/restaurants/:id",
            "identifierSource": "header.x-author",
            "limiter": {
              "algorithm": "fixed-window",
              "tokens": 10,
              "window": "20s"
            }
          },
          {
            "methods": ["GET"],
            "path": "/api/restaurants",
            "identifierSource": "header.x-author",
            "limiter": {
              "algorithm": "tokenBucket",
              "tokens": 10,
              "window": "20s",
              "refillRate": 1
            }
          }
        ],
        "prefix": "@strapi"
      }
    }
  }
  ```
</CodeGroup>


# Upstash Ratelimit Strapi Integration
Source: https://upstash.com/docs/redis/integrations/ratelimit/strapi/getting-started



Strapi is an open-source, Node.js based, Headless CMS that saves developers a lot of development time, enabling them to build their application backends quickly by decreasing the lines of code necessary.

You can use Upstash's HTTP and Redis based [Ratelimit package](https://github.com/upstash/ratelimit-js) integration with Strapi to protect your APIs from abuse.

## Getting started

### Installation

<CodeGroup>
  ```bash npm theme={"system"}
  npm install --save @upstash/strapi-plugin-upstash-ratelimit
  ```

  ```bash yarn theme={"system"}
  yarn add @upstash/strapi-plugin-upstash-ratelimit
  ```
</CodeGroup>

### Create database

Create a new redis database on [Upstash Console](https://console.upstash.com/). See [related docs](/redis/overall/getstarted) for further info related to creating a database.

### Set up environment variables

Get the environment variables from [Upstash Console](https://console.upstash.com/), and set it to `.env` file as below:

```shell .env theme={"system"}
UPSTASH_REDIS_REST_TOKEN="<YOUR_TOKEN>"
UPSTASH_REDIS_REST_URL="<YOUR_URL>"
```

### Configure the plugin

You can use

<CodeGroup>
  ```typescript /config/plugins.ts theme={"system"}
  export default () => ({
    "strapi-plugin-upstash-ratelimit": {
      enabled: true,
      resolve: "./src/plugins/strapi-plugin-upstash-ratelimit",
      config: {
        enabled: true,
        token: process.env.UPSTASH_REDIS_REST_TOKEN,
        url: process.env.UPSTASH_REDIS_REST_URL,
        strategy: [
          {
            methods: ["GET", "POST"],
            path: "*",
            limiter: {
              algorithm: "fixed-window",
              tokens: 10,
              window: "20s",
            },
          },
        ],
        prefix: "@strapi",
      },
    },
  });
  ```

  ```javascript /config/plugins.js theme={"system"}
  module.exports = () => ({
    "strapi-plugin-upstash-ratelimit": {
      enabled: true,
      resolve: "./src/plugins/strapi-plugin-upstash-ratelimit",
      config: {
        enabled: true,
        token: process.env.UPSTASH_REDIS_REST_TOKEN,
        url: process.env.UPSTASH_REDIS_REST_URL,
        strategy: [
          {
            methods: ["GET", "POST"],
            path: "*",
            limiter: {
              algorithm: "fixed-window",
              tokens: 10,
              window: "20s",
            },
          },
        ],
        prefix: "@strapi",
      },
    },
  });
  ```
</CodeGroup>


# Replit Templates
Source: https://upstash.com/docs/redis/integrations/replit-templates



## Overview

Explore our collection of example templates showcasing Upstash's capabilities with different frameworks and use cases. Each template comes with a live demo and source code on Replit.

<CardGroup cols={2}>
  <Card title="Redis Web Caching" icon="database" href="https://upstash-web-caching.replit.app">
    Cache SQL queries using Upstash Redis to speed up read requests
  </Card>

  <Card title="Rate Limiting Dashboard" icon="gauge-high" href="https://rate-limit-dashboard.replit.app">
    Implement robust rate limiting using Upstash Redis in a web application
  </Card>

  <Card title="Real-time Chat" icon="messages" href="https://real-time-chat.replit.app">
    Build a real-time chat application using Upstash Redis Pub/Sub with Python
  </Card>

  <Card title="RAG Chat Application" icon="robot" href="https://upstash-rag-chat.replit.app">
    Create an AI chat app with context retrieval using Upstash Vector and Redis
  </Card>

  <Card title="Vector Search" icon="magnifying-glass" href="https://upstash-vector-search.replit.app">
    Implement powerful web search using Upstash Vector Hybrid Search
  </Card>
</CardGroup>


# Sidekiq with Upstash Redis
Source: https://upstash.com/docs/redis/integrations/sidekiq



You can use Sidekiq with Upstash Redis. Sidekiq is a Ruby based queue library with a Redis-based queue storage so you can use with Upstash Redis.

## Example Application

```bash  theme={"system"}
bundle init 
bundle add sidekiq
```

```python  theme={"system"}
require "sidekiq"
require "sidekiq/api"
 
connection_url = ENV['UPSTASH_REDIS_LINK']
 
Sidekiq.configure_client do |config|
    config.redis = {url: connection_url}
end
 
Sidekiq.configure_server do |config|
    config.redis = {url: connection_url}
end
 
class EmailService
    include Sidekiq::Worker
    def perform(id, type)
        # Logic goes here. Let's assume sending email by printing to console.
        puts "Emailed to: " +  id + ": " + "'Congrats on " + type + " plan.'"
    end
end
 
def updateEmail(id, newType)
    jobFound = false
 
    a = Sidekiq::ScheduledSet.new
    a.each do |job|
        if job.args[0] == id
            job.delete
            jobFound = true
        end
    end
 
    if jobFound
        EmailService.perform_async(id, ("starting using our service and upgrading it to " + newType))
    else
        EmailService.perform_async(id, ("upgrading to " + newType))
    end
end
 
def sendEmail(id, type)
    case type
    when "free"
        # if free, delay for 10 seconds.
        EmailService.perform_in("10", id, "free")
    when "paid"
        # if paid, delay for 5 seconds.
        EmailService.perform_in("5", id, "paid")
    when "enterprise"
        # if enterprise, immediately queue.
        EmailService.perform_async(id, "enterprise")
    when "enterprise10k"
        EmailService.perform_async(id, "enterprise10k")
    else
        puts "Only plans are: `free`, `paid` and `enterprise`"
    end
end
 
def clearSchedules()
    Sidekiq::ScheduledSet.new.clear
    Sidekiq::Queue.new.clear
end
```

## Billing Optimization

Sidekiq accesses Redis regularly, even when there is no queue activity. This can incur extra costs because Upstash charges per request on the Pay-As-You-Go plan. With the introduction of [our Fixed plans](/redis/overall/pricing#all-plans-and-limits), **we recommend switching to a Fixed plan to avoid increased command count and high costs in Sidekiq use cases.**


# Changelog
Source: https://upstash.com/docs/redis/overall/changelog



<Update label="Feb 2025">
  Added [`EVAL_RO`](https://redis.io/docs/latest/commands/eval_ro/) and [`EVALSHA_RO`](https://redis.io/docs/latest/commands/evalsha_ro/)
  commands introduced in Redis 7.
</Update>

<Update label="July 2024">
  * Added REST API support for [`MONITOR`](https://redis.io/docs/latest/commands/monitor/) and [`SUBSCRIBE`](https://redis.io/docs/latest/commands/subscribe/)
    commands using [SSE](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events).
    See [Monitor](../features/restapi#monitor-command) and [Subscribe](../features/restapi#subscribe-command) docs.
  * Added [`JSON.MSET`](https://redis.io/docs/latest/commands/json.mset/) and [`JSON.MERGE`](https://redis.io/docs/latest/commands/json.merge/) commands.
  * Introduced the `IP Allowlist` feature for enhanced security on newly created databases. By default, all IP addresses will be allowed.
    However, access can be restricted by specifying permitted IP addresses or CIDR ranges.
</Update>

<Update label="June 2024">
  * Added AWS AP-NorthEast-1 Japan region.
  * Added an option to return REST response in [`RESP2`](https://redis.io/docs/latest/develop/reference/protocol-spec/) format instead of `JSON`.
    See [REST API docs](/redis/features/restapi#resp2-format-responses) for more information.
</Update>

<Update label="April 2024">
  * Implemented [`MONITOR`](https://redis.io/docs/latest/commands/monitor/) command
  * Implemented Redis [keyspace notifications](/redis/howto/keyspacenotifications)
  * Implemented [`WAIT`](https://redis.io/docs/latest/commands/wait/) and [`WAITAOF`](https://redis.io/docs/latest/commands/waitaof/) commands
  * Added `lag` field to [`XINFO GROUPS`](https://redis.io/docs/latest/commands/xinfo-groups/)
  * Added [`CLIENT ID`](https://redis.io/docs/latest/commands/client-id/) subcommand
  * Added password strength check to [`ACL SETUSER`](https://redis.io/docs/latest/commands/acl-setuser/) command
</Update>

<Update label="February 2024">
  * Fixed JSON commands with empty keys
  * Fixed a panic on `XTRIM` and `XDEL`
  * Added `CLIENT SETNAME/NAME/LIST` subcommands
  * Implemented near exact trim for streams
</Update>

<Update label="September 2023">
  * Implemented some missing Redis commands:
    * `DUMP`
    * `RESTORE`
    * `ZMPOP`
    * `BZMPOP`
    * `LMPOP`
    * `BLMPOP`
    * `SINTERCARD`
  * Added support for `BIT/BYTE` flag to `BITPOS` and `BITCOUNT` commands
  * Added support for `XX`, `NX`, `GT`, and `LT` arguments to `EXPIRE` commands
  * Allowed `NX` and `GET` args to be used together in `SET` command
</Update>


# Compare
Source: https://upstash.com/docs/redis/overall/compare



In this section, we will compare Upstash with alternative cloud based solutions.

## AWS ElastiCache

* **Serverless Pricing:** Elasticache does not have a serverless pricing model.
  The price does not scale to zero. You need to pay for the instances even when
  you do not use them. Upstash charges per request.
* **REST API:** Unlike ElastiCache, Upstash has a built-in REST API, so you can
  access from environments where TCP connections are not allowed such as edge
  functions at Cloudflare Workers.
* **Access:** Elasticache is designed to be used inside AWS VPC. You can access
  Upstash from anywhere.
* **Durability:** Upstash persists your data to the block storage in addition to
  memory so you can use it as your primary database.

## AWS MemoryDB

* **Serverless Pricing:** Similar to Elasticache, MemoryDB does not offer a
  serverless pricing model. The pricing does not scale down to zero, and even
  the most affordable instance costs over \$200 per month. This means you are
  required to pay for the instances regardless of usage. In contrast, Upstash
  follows a different approach by charging per request. With Upstash, you only
  incur charges when actively using your Redis database, ensuring that you do
  not have to pay when it's not in use.

* **REST API:** Unlike MemoryDB, Upstash has a built-in REST API, so you can
  access from environments where TCP connections are not allowed such as edge
  functions at Cloudflare Workers.

* **Access:** MemoryDB is designed to be used inside AWS VPC. You can access
  Upstash from anywhere.

## Redis Labs

* **Serverless Pricing:** Redis Labs does not have a serverless pricing model
  either. The price does not scale to zero. You need to pay for the instances
  even when you do not use them. Upstash charges per request, so you only pay
  for your real usage.
* **REST API:** Unlike Redis Labs, Upstash has a built-in REST API, so you can
  access from environments where TCP connections are not allowed such as edge
  functions at Cloudflare Workers.
* **Durability:** Upstash persists your data to the block storage instantly in
  addition to the memory, so you can use it as your primary database.

## AWS DynamoDB

* **Latency:** DynamoDB is a disk based data storage. Both write and read
  latency are much higher than Redis. Check our
  [benchmark app](https://serverless-battleground.vercel.app/) to get an idea.

* **Complex Pricing:** Initially, DynamoDB may appear cost-effective, but if you
  begin utilizing advanced features such as DAX or Global Tables, you might
  encounter unexpected expenses on your AWS bill. In contrast, Upstash offers a
  more transparent pricing policy, ensuring that you are not taken by surprise.
  With Upstash, there are limits in place to cap your maximum costs, providing
  clarity and preventing any unwelcome surprises in your billing.

* **Portability:** DynamoDB is exclusive to AWS and cannot be used outside of
  the AWS platform. However, Redis is supported by numerous cloud providers and
  can also be self-hosted. Upstash provides compatibility with Redis, ensuring
  vendor neutrality.

* **Testability:** Running a local Redis for testing purposes is much easier
  than running a local DynamoDB. Check
  [this](https://stackoverflow.com/questions/26901613/easier-dynamodb-local-testing).

## FaunaDB

* **Latency:** FaunaDB is a globally consistent database. Consistency at global
  level comes with performance cost. Check our
  [benchmark app](https://serverless-battleground.vercel.app/) to get an idea.

* **Complex Pricing:** FaunaDB has a complicated pricing. It has 6 different
  dimensions to calculate the price. Check
  [this article](https://docs.fauna.com/fauna/current/manage/plans-billing/billing/)
  where the pricing is explained. If your use case is write heavy and
  if your requests have bigger payloads, then it can become expensive very easily.
  On the other hand, Upstash has different options for different needs and
  pricing is simple for all options. You pay per request in addition to
  storage cost which is generally much smaller amount.

* **Portability:** FaunaDB is only supported by Fauna Inc. On the other hand,
  you can use Redis almost in all cloud providers as well as you can host Redis
  yourself. Upstash does not lock you to any vendor.

* **Testability:** Running a local Redis for testing purposes is much easier
  than running a local FaunaDB. Check
  [this](https://dev.to/englishcraig/how-to-set-up-faunadb-for-local-development-5ha7).

## What makes Upstash different?

You have a new project and you do not know how many requests will it receive?
You love the performance and simplicity of Redis. But all Redis Cloud services
charge you per instance or per GB of memory. But maybe your application will not
receive big traffic at first, then why will you pay the full amount?
Unfortunately none of the current Redis cloud products provides a real
`pay-per-use` pricing model.

Let's do a simple calculation. Say I have a 1GB Redis database and I receive 1
million requests per month. For ElastiCache (cache.t3.small, \$0.034 hourly) this
costs at least \$24 not including data transfer and storage cost. For RedisLabs,
the 1GB plan costs \$22 per month. For Upstash the price is \$0.2 per 100k
requests. For 1 million, it is \$2 plus the storage cost that is \$0.25. So for
1GB, 1M request per months, ElastiCache is \$24, RedisLabs is \$22, Upstash is
\$2.25.

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=7ad12f477f220c1e42ba896f8577ad72" data-og-width="848" width="848" data-og-height="278" height="278" data-path="img/compare/comparecosts.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=6e160ae49538223a3cae34a2ec34f918 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=9148a2ed380e52959ac0ae2831bbb7b1 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5a4881c139987b280ce3150d3c616f17 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=273e96942a774918c60eb179ebafdd6a 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=be4331883539fe16de82087e3b643c6f 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/compare/comparecosts.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=0f16d19f8abf4829f9158fb760914323 2500w" />
</Frame>

**What if your product becomes popular and starts to gain high and steady
traffic?**

Most of the serverless products start to lose their spell if the service
receives steady and high traffic as it starts to cost higher than
server/instance based pricing models. To overcome this situation we give you
option to purchase Pro Plan. In Pro plan you can set fixed
price per month with a restriction on max throughput and data size. For high and
steady throughput use cases, enterprise databases cost less than serverless one.
The good thing is you can start your database with pay-as-you-go pricing and
move it enterprise when you want. See [enterprise plans](/redis/overall/enterprise) for more
information.

Even if you choose not to upgrade to the Pro plan, Upstash guarantees
transparent billing without any unexpected surprises. Each Upstash database has
a predefined monthly maximum price, known as the "Ceiling Price." For
pay-as-you-go (PAYG) databases, this ceiling price is set at \$360 per month.
Therefore, even if your application experiences a significant surge in traffic,
such as reaching the front page of HackerNews, your Upstash database will not
exceed a maximum cost of \$360 per month.


# Prod Pack & Enterprise
Source: https://upstash.com/docs/redis/overall/enterprise



Upstash has Prod Pack and Enterprise plans for customers with critical production workloads. Prod Pack and Enterprise plans include additional monitoring and security features in addition to higher capacity limits and more powerful resources

Prod Pack -> Per database

Enterprise contract -> Per account

Prod Pack are an add-on per database available to both pay-as-you-go and fixed-price plans, not per account. You can have databases on different plans in the same account and each is charged separately. Meanwhile, Enterprise plans are per account, not per database. All of your databases can be included in the same Enterprise plan covering all of your databases.

# Prod Pack Features

These features are available on Prod Pack databases.

### Uptime SLA

All Prod Pack databases come with an SLA guaranteeing 99.99% uptime. For mission-critical data where uptime is crucial, we recommend Prod Pack plans.

### RBAC

Role-Based Access Control (RBAC) is a security model that manages database access. You can create multiple users with different roles to control their actions on your databases.

We recommend using RBAC if your database is accessible to multiple developers.

### SOC-2 Type 2 Report

We have a SOC 2 Type 2 report available for our Prod Pack and Enterprise plans. You can request access to the report by contacting [support@upstash.com](mailto:support@upstash.com).

### Prometheus Metrics

Prometheus is an open-source monitoring system widely used for monitoring and alerting in cloud-native and containerized environments.

Upstash Prod Pack and Enterprise plans offer Prometheus metrics collection, enabling you to monitor your Redis databases with Prometheus in addition to console metrics.

### Datadog Integration

Upstash Prod Pack and Enterprise plans include integration with Datadog, allowing you to monitor your Redis databases with Datadog in addition to console metrics.

### More metrics on the Console

Max interval of the metrics that are available on the Upstash Console increases from one week to one month for databases with Prod Pack.

### High Availability for Read Regions

With Prod Pack add-on, read regions of your database are [highly available](/redis/features/replication#high-availability). This ensures that if one read replica fails, you can read from another read replica in the same region without any additional latency.

### More Backup Capability

Backups up to 3 days are possible with the Prod Pack add-on.

### Encryption at Rest

Encrypts the block storage where your data is persisted and stored.

# Enterprise Features

All Prod Pack features are included in the Enterprise plan. Additionally, Enterprise plans include:

### Custom Limits

Get a custom-tailored plan for your Upstash Redis databases to handle the growing demands of your business at any scale.

### Professional Support

All of the databases in the Enterprise plan get access to our professional support. The plan includes response time SLAs and priority access to our support team. Check out the [support page](/common/help/prosupport) for more details.

The below features are available upon request for Enterprise customers.

### SAML SSO

Single Sign-On (SSO) allows you to use your existing identity provider to authenticate users for your Upstash account. This feature is available upon request for Enterprise customers.

### VPC Peering and Private Links

VPC Peering and Private Links enable you to connect your databases to your VPCs and other private networks, enhancing isolation and security while reducing data transfer costs. This feature is available upon request for Enterprise customers.

### Configurable Backups

Hourly backups with customizable retention are available upon request for Enterprise customers.

### Access Logs

Enterprise customers can request access logs to the databases.

### More Resources

A non-Enterprise Upstash account can create up to 100 databases and 10 teams. Enterprise customers can have more resources.

### HIPAA Compliance

HIPAA compliance and a BAA agreement is available with our Enterprise plan. To request access, please contact [support@upstash.com](mailto:support@upstash.com).

## How to Upgrade

You can activate Prod Pack on the database details page in the console. For the Enterprise plan, contact [support@upstash.com](mailto:support@upstash.com).


# Getting Started
Source: https://upstash.com/docs/redis/overall/getstarted

Create an Upstash Redis database in seconds

Upstash Redis is a **highly available, infinitely scalable** Redis-compatible database:

* 99.99% uptime guarantee with auto-scaling ([Prod Pack](/redis/overall/enterprise#prod-pack-features))
* Ultra-low latency worldwide
* Multi-region replication
* Durable, persistent storage without sacrificing performance
* Automatic backups
* Optional SOC-2 compliance, encryption at rest and much more

***

## 1. Create an Upstash Redis Database

Once you're logged in, create a database by clicking `+ Create Database` in the upper right corner. A dialog opens up:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=09013e74602d754565d828cc90c26aa6" data-og-width="1518" width="1518" data-og-height="977" height="977" data-path="img/getting_started/create-global.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f1637d9a7924028f57086f27046ec034 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1b215849edb3da0470f4b293164cfbe7 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7167b0f17fd1fb4dbecd1da4ef082313 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=94fccda941b66418a310a4332816e5e3 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d730a3da055cd05a25c8cf8daf699610 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/create-global.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c9c3886ad67145b0bce8a9cdb167a328 2500w" />
</Frame>

**Database Name:** Enter a name for your database.

**Primary Region and Read Regions:** For optimal performance, select the Primary Region closest to where most of your writes will occur. Select the read region(s) where most of your reads will occur.

Once you click `Next` and select a plan, your database is running and ready to connect:

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4530264625c10bdf334129ec8b367511" width="100%" data-og-width="1590" data-og-height="1080" data-path="img/getting_started/database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=729b8c0843969c86866b06e22747c785 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d44be677d29134227ff6839fbfc10674 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=414a590eb3c8ed98001a5a781a6268bf 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eca30f6532a78f7f25952b41beac50d5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e60ccc845ab5a2a2b4fb9d66ac0fe948 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/database.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b999e96686847b5aeeebc960cf2d5a30 2500w" />
</Frame>

***

## 2. Connect to Your Database

You can connect to Upstash Redis with any Redis client. For simplicity, we'll use `redis-cli`. See the [Connect Your Client](../howto/connectclient) section for connecting via our TypeScript or Python SDKs and other clients.

The Redis CLI is included in the official Redis distribution. If you don't
have Redis installed, you can get it [here](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/).

Connect to your database and execute commands on it:

```bash  theme={"system"}
> redis-cli --tls -a PASSWORD -h ENDPOINT -p PORT
ENDPOINT:PORT> set counter 0
OK
ENDPOINT:PORT> get counter
"0"
ENDPOINT:PORT> incr counter
(int) 1
ENDPOINT:PORT> incr counter
(int) 2
```

As you run commands, you'll see updates to your database metrics in (almost) real-time. These database metrics are refreshed every 10 seconds.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0a226cc212d85606ab415a6a90c66beb" width="100%" data-og-width="1271" data-og-height="279" data-path="img/getting_started/charts.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=dc0e463aa9c36746a1694664b239bc45 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a61aab0a54b97118d4bc954ea965c522 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=bb030d544341fdf3081900165d97b10f 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=11e42d05b3266a9873b7754ef3727cd0 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7a571f7865a8effb308e3bab2eeb3875 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/getting_started/charts.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=79e0053753bf2e716ce274b8a20eb79c 2500w" />
</Frame>

Congratulations! You have created an ultra-fast Upstash Redis database! üéâ

<Check>
  **New: Manage Upstash Redis From Cursor (optional)**

  Manage Upstash Redis databases from Cursor and other AI tools by using our [MCP server](/redis/integrations/mcp).
</Check>


# llms.txt
Source: https://upstash.com/docs/redis/overall/llms-txt





# Pricing & Limits
Source: https://upstash.com/docs/redis/overall/pricing



## Free Tier

* 256MB data size
* 500K commands per month
* One free database per account

## Pay-as-you-go Pricing

* Request Price: \$0.20 per 100K requests
* Bandwidth Price: First 200GB free, then \$0.03/GB
* Storage Price: \$0.25/GB

## All Plans and Limits

|          Plan |  Price | Read Region Price | Max Data Size | Max Bw GB Monthly | Max Req Per Sec | Max Request Size | Max Record | Max Connections |
| ------------: | -----: | ----------------: | ------------: | ----------------: | --------------: | ---------------: | ---------: | --------------: |
|          Free |    \$0 |               \$0 |         256MB |               10G |           10000 |             10MB |      100MB |           10000 |
| Pay-as-you-go |    \$0 |               \$0 |         100GB |         Unlimited |           10000 |             10MB |      100MB |           10000 |
|   Fixed 250MB |   \$10 |               \$5 |         250MB |              50GB |           10000 |             10MB |      100MB |           10000 |
|     Fixed 1GB |   \$20 |              \$10 |           1GB |             100GB |           10000 |             10MB |      200MB |           10000 |
|     Fixed 5GB |  \$100 |              \$50 |           5GB |             500GB |           10000 |             20MB |      300MB |           10000 |
|    Fixed 10GB |  \$200 |             \$100 |          10GB |               1TB |           10000 |             30MB |      400MB |           10000 |
|    Fixed 50GB |  \$400 |             \$200 |          50GB |               5TB |           10000 |             50MB |      500MB |           10000 |
|   Fixed 100GB |  \$800 |             \$400 |         100GB |              10TB |           16000 |             75MB |        1GB |           10000 |
|   Fixed 500GB | \$1500 |             \$750 |         500GB |              20TB |           16000 |            100MB |        5GB |          100000 |
|    Enterprise | Custom |            Custom |          10TB |         Unlimited |          Custom |            500MB |        5GB |          100000 |

## Prod Pack

* \$200/month per database
* Uptime SLA
* SOC 2 Type 2 report
* Advanced monitoring (Prometheus, Grafana, Datadog)
* High Availability for Read Regions
* Role-based access control (RBAC)
* Encryption at Rest

## Enterprise subscription

* All features of Prod pack for all your databases
* Dedicated professional support
* Dedicated technical account manager
* Unlimited databases
* HIPAA compliance
* VPC peering
* SSO integration
* Custom pricing with monthly or annual contract options

## Custom Quota Pricing (Pay-as-you-go)

### Request Size Limits

| Max Request Size | Value \$ per month |
| ---------------: | -----------------: |
|             50MB |               \$80 |
|            100MB |              \$120 |
|             more |         contact us |

### Collection Size Limits

| Max Record Size | Value \$ per month |
| --------------: | -----------------: |
|           250MB |               \$60 |
|           500MB |              \$100 |
|             1GB |              \$180 |
|            more |         contact us |

### Number of Databases

| Number of Databases |                           Price per month |
| ------------------: | ----------------------------------------: |
|            First 10 |                                      Free |
|              10-100 |                              \$0.5 per DB |
|                more | [contact us](https://upstash.com/contact) |

## FAQs

### How can I upgrade to pay as you go from free tier?

Once you enter your credit card, your database will be upgraded to the pay-as-you-go plan and limits will be updated.

### What is included in free tier?

In free tier includes 256MB data size and 500K commands per month.

### Are paid database's first 256MB data and 500K commands free?

No. Once you upgrade to paid tier, you will be charged for the data size and commands.

### How does the budget work?

Budget is only available for pay-as-you-go plan.

With the Pay-as-you-go plan, you can set a maximum monthly budget for your database so that you won't be charged beyond this chosen limit. We'll keep you informed by sending email notifications once you reach 70% and 90% of your monthly budget. This notifications will let you either adjust your budget limit or upgrade to a Fixed plan. Note that if your usage exceeds your monthly budget cap, your database will be rate limited and your cost will not exceed your chosen budget limit.

Please set your budget limit high enough to avoid service disruption.

<Note>
  If you change from a Fixed plan to Pay-as-you-go mid-month, your budget will only track your Pay-as-you-go spending.
</Note>

### Are all Redis commands counted in billing?

Operational commands like AUTH, HELLO, SELECT, COMMAND, CONFIG, INFO, PING, RESET, QUIT will not be charged.

### Are databases faster in higher plans?

Ops/sec limit is same in most initial plans, while our higher plans provide higher throughput as well as increasing other limits. There is no performance difference between plans within the limits.

### Are read and write commands same price?

Yes. But for Global databases, the write commands are replicated to all read regions in addition to primary region. Replications (write operations) are also counted as commands. For example, if you have 1 primary 1 read region, 100K writes will cost $0.4 ($0.2 x 2)

### How is the storage cost calculated for pay-as-you-go plan?

For each database the first 1GB is free. Beyond that, the storage cost is charged at a rate of \$0.25 per GB total storage. Total storage is determined by adding up the storage at all replicas and regions. Even if you do not access your data, we have to keep it persistent in Cloud Provider's block storage (eg AWS EBS) in multiple replicas for durability and high availability. To calculate the total storage cost, we take daily average of your total data size in all replicas and multiply with the rate at the end of the month. If you are using your database as a cache; then it is a good practice to set a timeout (EXPIRE) for your keys to minimize the cost.

### What happens when I hit limits on pay-as-you-go plan?

For each limit exceeded, you will be notified via email. We will do our best to keep your database running but we may rate limit depending on the case.

For concurrent connections, if you hit the limit, your database will start rejecting new connections. This can cause extra latency on your clients.

For max request size, the requests exceeding the limit will be rejected with an exception.

For max record size, the collection that exceeds the limit will stop accepting new records.

For bandwidth and storage, there are no limits but you can set a budget limit to avoid unexpected charges.

### What happens when I hit limits on fixed plans?

For each limit exceeded, you will be notified via email.

When your database hits the bandwidth and storage limits and if you have enabled auto-upgrade, your database will be upgraded to the one upper tier. When auto-upgrade is not enabled, your database will be rate limited which means your traffic will be blocked for bandwidth case, your write operations will be blocked for storage case.

For concurrent connections, if you hit the limit, your database will start rejecting new connections. This can cause extra latency on your clients.

For max request size, the requests exceeding the limit will be rejected with an exception.

For max record size, the collection that exceeds the limit will stop accepting new records.

### Are there free trials?

Yes, we can provide free trials for testing and PoC purposes. Email us at [support@upstash.com](mailto:support@upstash.com)

### How many databases can I create?

You can create up to 10 databases for free and beyond this you will be charged \$0.5 per database up to 100 databases. For more than 100 databases, please contact us at [support@upstash.com](mailto:support@upstash.com)
The charge is calculated based on the number of active databases at the end of the month.

### What happens if I delete my database after 2-3 days?

For fixed plans, you'll be charged pro-rata for the days the database was active (in this case, 2-3 days), regardless of whether you actively used the database or not. For pay-as-you-go plans, you'll only be charged for your actual usage during those 2-3 days.

### How much is the price for bandwidth?

For pay is you go plan, it is free up to monthly bandwidth limit of 200GB. Beyond that, we charge \$0.03 for each additional GB data transfer.

For fixed plans, bandwidth is included in the price, so you will not be charged for it.

For use cases with high volume, you may consider VPC Peering which minimizes the data transfer cost. VPC Peering requires Enterprise contract. Contact us at [support@upstash.com](mailto:support@upstash.com) for details.

Bandwidth price depends on cloud provider's fee for the traffic so it is subject to change. In case of any changes, we will notify you via email.

### Can I purchase Prod Pack for any plan?

Yes, you can purchase Prod Pack for any plan except Free tier. You can enable it in your [Upstash Dashboard](https://upstash.com/dashboard/redis) database details page.

### What is included in Prod Pack?

It includes uptime SLA, SOC 2 Type 2 report, advanced monitoring (Prometheus, Grafana, Datadog), and role-based access control (RBAC).

### What is included in Enterprise subscription?

All the features of Prod pack will be available for all your databases. Moreover, dedicated professional support, HIPAA compliance, VPC peering, Private link and SSO integration will be available at request.

### How is the Enterprise subscription priced?

For Enterprise subscription, a custom price is set based on specific requirements of the customer. For more information email us at [sales@upstash.com](mailto:sales@upstash.com)

### Do you have the Professional Support plan?

Professional support includes a dedicated service desk along and a Slack/Discord channel with a committed response time SLA. Check [Professional Support](/common/help/prosupport) for details.


# Pricing & Limits
Source: https://upstash.com/docs/redis/overall/pricingold





# Python SDK
Source: https://upstash.com/docs/redis/overall/pythonredis





# Rate Limit SDK
Source: https://upstash.com/docs/redis/overall/ratelimit





# Typescript SDK
Source: https://upstash.com/docs/redis/overall/redis





# Redis¬Æ API Compatibility
Source: https://upstash.com/docs/redis/overall/rediscompatibility



Upstash supports Redis client protocol up to version `6.2`.  We are also gradually adding changes introduced in versions `7.0` and `7.2`,
such as `EXPIRETIME`, `LMPOP`, `ZINTERCARD` and `EVAL_RO`.

The following table shows the most recent list of the supported Redis commands:

| Feature                                                       | Supported? |                                                                                                                                                                                                  Supported Commands                                                                                                                                                                                                  |
| ------------------------------------------------------------- | :--------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| [String](https://redis.io/commands/?group=string)             |      ‚úÖ     |                                                                                                                       APPEND - DECR - DECRBY - GET - GETDEL - GETEX - GETRANGE - GETSET - INCR - INCRBY - INCRBYFLOAT - MGET - MSET - MSETNX - PSETEX - SET - SETEX - SETNX - SETRANGE - STRLEN                                                                                                                      |
| [Bitmap](https://redis.io/commands/?group=bitmap)             |      ‚úÖ     |                                                                                                                                                                         BITCOUNT - BITFIELD - BITFIELD\_RO - BITOP - BITPOS - GETBIT - SETBIT                                                                                                                                                                        |
| [Hash](https://redis.io/commands/?group=hash)                 |      ‚úÖ     |                                                                                                                                    HDEL - HEXISTS - HGET - HGETALL - HINCRBY - HINCRBYFLOAT - HKEYS - HLEN - HMGET - HMSET - HSCAN - HSET - HSETNX - HSTRLEN - HRANDFIELD - HVALS                                                                                                                                    |
| [List](https://redis.io/commands/?group=list)                 |      ‚úÖ     |                                                                                                               BLMOVE - BLMPOP - BLPOP - BRPOP - BRPOPLPUSH - LINDEX - LINSERT - LLEN - LMOVE - LMPOP - LPOP - LPOS - LPUSH - LPUSHX - LRANGE - LREM - LSET - LTRIM - RPOP - RPOPLPUSH - RPUSH - RPUSHX                                                                                                               |
| [Set](https://redis.io/commands/?group=set)                   |      ‚úÖ     |                                                                                                                     SADD - SCARD - SDIFF - SDIFFSTORE - SINTER - SINTERCARD - SINTERSTORE - SISMEMBER - SMEMBERS - SMISMEMBER - SMOVE - SPOP - SRANDMEMBER - SREM - SSCAN - SUNION - SUNIONSTORE                                                                                                                     |
| [SortedSet](https://redis.io/commands/?group=sorted_set)      |      ‚úÖ     | BZMPOP - BZPOPMAX - BZPOPMIN - ZADD - ZCARD - ZCOUNT - ZDIFF - ZDIFFSTORE - ZINCRBY - ZINTER - ZINTERCARD - ZINTERSTORE - ZLEXCOUNT - ZMPOP - ZMSCORE - ZPOPMAX - ZPOPMIN - ZRANDMEMBER - ZRANGE - ZRANGESTORE - ZRANGEBYLEX - ZRANGEBYSCORE - ZRANK - ZREM - ZREMRANGEBYLEX - ZREMRANGEBYRANK - ZREMRANGEBYSCORE - ZREVRANGE - ZREVRANGEBYLEX - ZREVRANGEBYSCORE - ZREVRANK - ZSCAN - ZSCORE - ZUNION - ZUNIONSTORE |
| [Geo](https://redis.io/commands/?group=geo)                   |      ‚úÖ     |                                                                                                                                       GEOADD - GEODIST - GEOHASH - GEOPOS - GEORADIUS - GEORADIUS\_RO - GEORADIUSBYMEMBER - GEORADIUSBYMEMBER\_RO - GEOSEARCH - GEOSEARCHSTORE                                                                                                                                       |
| [HyperLogLog](https://redis.io/commands/?group=hyperloglog)   |      ‚úÖ     |                                                                                                                                                                                               PFADD - PFCOUNT - PFMERGE                                                                                                                                                                                              |
| [Scripting](https://redis.io/commands/?group=scripting)       |      ‚úÖ     |                                                                                                                                                                 EVAL - EVALSHA - EVAL\_RO - EVALSHA\_RO - SCRIPT EXISTS - SCRIPT LOAD - SCRIPT FLUSH                                                                                                                                                                 |
| [Pub/Sub](https://redis.io/commands/?group=pubsub)            |      ‚úÖ     |                                                                                                                                                                        SUBSCRIBE - PSUBSCRIBE - UNSUBSCRIBE - PUNSUBSCRIBE - PUBLISH - PUBSUB                                                                                                                                                                        |
| [Transactions](https://redis.io/commands/?group=transactions) |      ‚úÖ     |                                                                                                                                                                                       DISCARD - EXEC - MULTI - UNWATCH - WATCH                                                                                                                                                                                       |
| [Generic](https://redis.io/commands/?group=generic)           |      ‚úÖ     |                                                                                                        COPY - DEL - DUMP - EXISTS - EXPIRE - EXPIREAT - EXPIRETIME - KEYS - PERSIST - PEXPIRE - PEXPIREAT - PEXPIRETIME - PTTL - RANDOMKEY - RENAME - RENAMENX - RESTORE - SCAN - TOUCH - TTL - TYPE - UNLINK                                                                                                        |
| [Connection](https://redis.io/commands/?group=connection)     |      ‚úÖ     |                                                                                                                                                                                  AUTH - HELLO - ECHO - PING - QUIT - RESET - SELECT                                                                                                                                                                                  |
| [Server](https://redis.io/commands/?group=server)             |      ‚úÖ     |                                                                                                                                                                                ACL(\*) - DBSIZE - FLUSHALL - FLUSHDB - MONITOR - TIME                                                                                                                                                                                |
| [JSON](https://redis.io/commands/?group=json)                 |      ‚úÖ     |                                            JSON.ARRAPPEND - JSON.ARRINSERT - JSON.ARRINDEX - JSON.ARRLEN - JSON.ARRPOP - JSON.ARRTRIM - JSON.CLEAR - JSON.DEL - JSON.FORGET - JSON.GET - JSON.MERGE - JSON.MGET - JSON.MSET - JSON.NUMINCRBY - JSON.NUMMULTBY - JSON.OBJKEYS - JSON.OBJLEN - JSON.RESP - JSON.SET - JSON.STRAPPEND - JSON.STRLEN - JSON.TOGGLE - JSON.TYPE                                           |
| [Streams](https://redis.io/commands/?group=stream)            |      ‚úÖ     |                                                                                                                                XACK - XADD - XAUTOCLAIM - XCLAIM - XDEL - XGROUP - XINFO GROUPS - XINFO CONSUMERS - XLEN - XPENDING - XRANGE - XREAD - XREADGROUP - XREVRANGE - XTRIM                                                                                                                                |
| [Cluster](https://redis.io/commands#cluster)                  |      ‚ùå     |                                                                                                                                                                                                                                                                                                                                                                                                                      |

We run command integration tests from following Redis clients after each code
change and also periodically:

* **[Node-Redis](https://github.com/redis/node-redis)**
  [Command Tests](https://github.com/redis/node-redis/tree/v3.1.2/test/commands)
* **[Jedis](https://github.com/redis/jedis)**
  [Command Tests](https://github.com/redis/jedis/tree/v4.1.1/src/test/java/redis/clients/jedis/commands)
* **[Lettuce](https://github.com/lettuce-io/lettuce-core)**
  [Command Tests](https://github.com/lettuce-io/lettuce-core/tree/6.1.6.RELEASE/src/test/java/io/lettuce/core/commands)
* **[Go-Redis](https://github.com/go-redis/redis)**
  [Command Tests](https://github.com/go-redis/redis/blob/master/commands_test.go)
* **[Redis-py](https://github.com/redis/redis-py)**
  [Command Tests](https://github.com/redis/redis-py/tree/v4.4.0/tests)

Most of the unsupported items are in our roadmap. If you need a feature that we
do not support, please drop a note to
[support@upstash.com](mailto:support@upstash.com). So we can inform you when we
are planning to support it.


# Use Cases
Source: https://upstash.com/docs/redis/overall/usecases



The data store behind Upstash is [compatible](../overall/rediscompatibility)
with almost all Redis¬Æ API. So you can use Upstash for the Redis¬Æ' popular use
cases such as:

* General caching
* Session caching
* Leaderboards
* Queues
* Usage metering (counting)
* Content filtering

Check Salvatore's [blog](http://antirez.com/post/take-advantage-of-redis-adding-it-to-your-stack.html) post. You can find lots of similar articles about the common use cases of Redis.

## Key Value Store and Caching for Next.js Application

Next.js is increasingly becoming the preferred method for developing dynamic and fast web applications in an agile manner. It owes its popularity to its server-side rendering capabilities and API routes supported by serverless functions, including Vercel serverless and edge functions. Upstash Redis is a great fit with Next.js applications due to its serverless model and its REST-based APIs. The REST API plays a critical role in enabling access from edge functions while also addressing connection issues in serverless functions.

Check the blog post:
[Speed up your Next.js application with Redis](https://upstash.com/blog/nextjs-caching-with-redis)

## Redis for Vercel Functions

Vercel stands out as one of the most popular cloud platform for web developers, offering continuous integration, deployment, CDN and serverless functions. However, when it comes to databases, you'll need to rely on external data services to support dynamic applications.

That's where Upstash comes into play as one of the most favored data solutions within the Vercel platform. Here are some reasons that contribute to Upstash's popularity in the Vercel ecosystem:

* No connection problems thanks to
  [Upstash SDK](https://github.com/upstash/upstash-redis) built on Upstash REST
  API.
* Edge runtime does not allow TCP based connections. You can not use regular
  Redis clients. [Upstash SDK](https://github.com/upstash/upstash-redis) works
  on edge runtimes without a problem.
* Upstash has a [Vercel add on](https://vercel.com/integrations/upstash) where
  you can easily integrate Upstash to your Vercel projects.

## Storage For Lambda Functions (FaaS)

People use Lambda functions for various reasons, with one of the primary advantages being their cost-effectiveness ‚Äì you only pay for what you actually use, which is great. However, when it comes to needing a storage layer, AWS recommends DynamoDB. DynamoDB does offer a serverless mode, which sounds promising until you encounter its latency when connecting and operating within Lambda Functions. Unfortunately, DynamoDB's latency may not be ideal for Lambda Functions, where every second of latency can have a significant impact on costs. At this point, AWS suggests using ElastiCache for low-latency data storage, which is also a Redis¬Æ cache as a service ‚Äì a positive aspect. However, it's worth noting that ElastiCache is not serverless, and you have to pay based on what you provision, rather than what you use. To be honest, the pricing may not be the most budget-friendly option. This leaves you with two alternatives:

* DynamoDB: Serverless but high latency
* ElastiCache: Low latency but not serverless.

Until you meet the Upstash. Our sole mission is to provide a Redis¬Æ API
compatible database that you love in the serverless model. In Upstash, you pay
per the number of requests you have sent to your database. So if you are not
using the database you pay almost nothing. (Almost, because we charge for the
storage. It is a very low amount but still it is there.)

We believe that Upstash is the best storage for your Lambda Functions because:

* Serverless just like Lambda functions itself
* Designed for low latency data access
* The lovely simple Redis¬Æ API


# AWS Lambda
Source: https://upstash.com/docs/redis/quickstarts/aws-lambda



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/aws-cdk-typescript" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

* Complete all steps in [Getting started with the AWS CDK](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html)

### Project Setup

Create and navigate to a directory named `counter-cdk`. The CDK CLI uses this directory name to name things in your CDK code, so if you decide to use a different name, don't forget to make the appropriate changes when applying this tutorial.

```shell  theme={"system"}
mkdir counter-cdk && cd counter-cdk
```

Initialize a new CDK project.

```shell  theme={"system"}
cdk init app --language typescript
```

Install `@upstash/redis`.

```shell  theme={"system"}
npm install @upstash/redis
```

### Counter Function Setup

Create `/api/counter.ts`.

```ts /api/counter.ts theme={"system"}
import { Redis } from '@upstash/redis';

const redis = Redis.fromEnv();

export const handler = async function() {
    const count = await redis.incr("counter");
    return {
        statusCode: 200,
        body: JSON.stringify('Counter: ' + count),
    };
};
```

### Counter Stack Setup

Update `/lib/counter-cdk-stack.ts`.

```ts /lib/counter-cdk-stack.ts theme={"system"}
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as lambda from 'aws-cdk-lib/aws-lambda';
import * as nodejs from 'aws-cdk-lib/aws-lambda-nodejs';

export class CounterCdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const counterFunction = new nodejs.NodejsFunction(this, 'CounterFunction', {
      entry: 'api/counter.ts',
      handler: 'handler',
      runtime: lambda.Runtime.NODEJS_20_X,
      environment: {
        UPSTASH_REDIS_REST_URL: process.env.UPSTASH_REDIS_REST_URL || '',
        UPSTASH_REDIS_REST_TOKEN: process.env.UPSTASH_REDIS_REST_TOKEN || '',
      },
      bundling: {
        format: nodejs.OutputFormat.ESM,
        target: "node20",
        nodeModules: ['@upstash/redis'],
      },
    });

    const counterFunctionUrl = counterFunction.addFunctionUrl({
      authType: lambda.FunctionUrlAuthType.NONE,
    });

    new cdk.CfnOutput(this, "counterFunctionUrlOutput", {
      value: counterFunctionUrl.url,
    })
  }
}
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Deploy

Run in the top folder:

```shell  theme={"system"}
cdk synth
cdk bootstrap
cdk deploy
```

Visit the output URL.


# Azure Functions
Source: https://upstash.com/docs/redis/quickstarts/azure-functions



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/azure-functions" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

1. [Create an Azure account.](https://azure.microsoft.com/en-us/free/)
2. [Set up Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)
3. [Install the Azure Functions Core Tools](https://learn.microsoft.com/en-us/azure/azure-functions/create-first-function-cli-typescript)

### Project Setup

Initialize the project:

```shell  theme={"system"}
func init --typescript
```

Install `@upstash/redis`

```shell  theme={"system"}
npm install @upstash/redis
```

### Counter Function Setup

Create a new function from template.

```shell  theme={"system"}
func new --name CounterFunction --template "HTTP trigger" --authlevel "anonymous"
```

Update `/src/functions/CounterFunction.ts`

```ts /src/functions/CounterFunction.ts theme={"system"}
import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { Redis } from "@upstash/redis";

const redis = new Redis({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN
});

export async function CounterFunction(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
    const count = await redis.incr("counter");

    return { status: 200, body: `Counter: ${count}` };
};

app.http('CounterFunction', {
    methods: ['GET', 'POST'],
    authLevel: 'anonymous',
    handler: CounterFunction
});
```

### Create Azure Resources

You can use the command below to find the `name` of a region near you.

```shell  theme={"system"}
az account list-locations
```

Create a resource group.

```shell  theme={"system"}
az group create --name AzureFunctionsQuickstart-rg --location <REGION>
```

Create a storage account.

```shell  theme={"system"}
az storage account create --name <STORAGE_NAME> --location <REGION> --resource-group AzureFunctionsQuickstart-rg --sku Standard_LRS --allow-blob-public-access false
```

Create your Function App.

```shell  theme={"system"}
az functionapp create --resource-group AzureFunctionsQuickstart-rg --consumption-plan-location <REGION> --runtime node --runtime-version 18 --functions-version 4 --name <APP_NAME> --storage-account <STORAGE_NAME>
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and set `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` in your Function App's settings.

```shell  theme={"system"}
az functionapp config appsettings set --name <APP_NAME> --resource-group AzureFunctionsQuickstart-rg --settings UPSTASH_REDIS_REST_URL=<YOUR_URL> UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Deploy

Take a build of your application.

```shell  theme={"system"}
npm run build
```

Publish your application.

```shell  theme={"system"}
func azure functionapp publish <APP_NAME>
```

Visit the given Invoke URL.


#  Cloudflare Workers
Source: https://upstash.com/docs/redis/quickstarts/cloudflareworkers



### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or
[Upstash CLI](https://github.com/upstash/cli).

### Project Setup

We will use **C3 (create-cloudflare-cli)** command-line tool to create our application. You can open a new terminal window and run C3 using the prompt below.

<CodeGroup>
  ```shell npm theme={"system"}
  npm create cloudflare@latest -- upstash-redis-worker
  ```

  ```shell yarn theme={"system"}
  yarn create cloudflare upstash-redis-worker
  ```

  ```shell pnpm theme={"system"}
  pnpm create cloudflare upstash-redis-worker
  ```
</CodeGroup>

This will create a new Cloudflare Workers project:

```text  theme={"system"}
‚ûú  npm create cloudflare@latest -- upstash-redis-worker

> npx
> create-cloudflare upstash-redis-worker


‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üëã Welcome to create-cloudflare v2.50.8!
üß° Let's get started.
üìä Cloudflare collects telemetry about your usage of Create-Cloudflare.

Learn more at: https://github.com/cloudflare/workers-sdk/blob/main/packages/create-cloudflare/telemetry.md
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚ï≠ Create an application with Cloudflare Step 1 of 3
‚îÇ
‚îú In which directory do you want to create your application?
‚îÇ dir ./upstash-redis-worker
‚îÇ
‚îú What would you like to start with?
‚îÇ category Hello World example
‚îÇ
‚îú Which template would you like to use?
‚îÇ type Worker only
‚îÇ
‚îú Which language do you want to use?
‚îÇ lang TypeScript
‚îÇ
‚îú Copying template files
‚îÇ files copied to project directory
‚îÇ
‚îú Updating name in `package.json`
‚îÇ updated `package.json`
‚îÇ
‚îú Installing dependencies
‚îÇ installed via `npm install`
‚îÇ
‚ï∞ Application created 

...

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üéâ  SUCCESS  Application created successfully!
```

We will also install the **Upstash Redis SDK** to connect to Redis.

```bash  theme={"system"}
npm install @upstash/redis
```

### The Code

Here is a Worker template to configure and test Upstash Redis connection.

<CodeGroup>
  ```ts src/index.ts theme={"system"}
  import { Redis } from "@upstash/redis/cloudflare";

  export interface Env {
    UPSTASH_REDIS_REST_URL: string;
    UPSTASH_REDIS_REST_TOKEN: string;
  }

  export default {
  	async fetch(request, env, ctx): Promise<Response> {
  		const redis = Redis.fromEnv(env);
  		const count = await redis.incr("counter");
  		return new Response(JSON.stringify({ count }));
  		
  	},
  } satisfies ExportedHandler<Env>;

  ```

  ```js src/index.js theme={"system"}
  import { Redis } from "@upstash/redis/cloudflare";

  export default {
    async fetch(request, env, ctx) {
      const redis = Redis.fromEnv(env);
      const count = await redis.incr("counter");
      return new Response(JSON.stringify({ count }));
    },
  };
  ```
</CodeGroup>

### Configure Credentials

There are two methods for setting up the credentials for Redis. One for worker level, the other for account level.

#### Using Cloudflare Secrets (Worker Level Secrets)

This is the common way of creating secrets for your worker, see [Workflow Secrets](https://developers.cloudflare.com/workers/configuration/secrets/)

* Navigate to [Upstash Console](https://console.upstash.com) and get your Redis credentials.

* In [Cloudflare Dashboard](https://dash.cloudflare.com/), Go to **Compute (Workers)** > **Workers & Pages**.

* Select your worker and go to **Settings** > **Variables and Secrets**.

* Add your Redis credentials as secrets here:

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=890eabf39148b839095a2c12a516345b" data-og-width="1716" width="1716" data-og-height="626" height="626" data-path="img/cloudflare-integration/redis-secrets.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=1a7745e9dbb4f40efb1800ccc93e285c 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=cfdfa08edd78b912a51b0d453b066076 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=afb7d787d4aafae317fd1e541d61d942 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=bb69c86b2e587273b6d679fa7758b93f 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=c9d225dce59a3386eae154a2e9eae85b 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=c694a40ad032e0b41315bfd9b95b82cb 2500w" />
</Frame>

#### Using Cloudflare Secrets Store (Account Level Secrets)

This method requires a few modifications in the worker code, see [Access to Secret on Env Object](https://developers.cloudflare.com/secrets-store/integrations/workers/#3-access-the-secret-on-the-env-object)

```ts src/index.ts theme={"system"}
import { Redis } from "@upstash/redis/cloudflare";

export interface Env {
  UPSTASH_REDIS_REST_URL: SecretsStoreSecret;
  UPSTASH_REDIS_REST_TOKEN: SecretsStoreSecret;
}

export default {
	async fetch(request, env, ctx): Promise<Response> {
		const redis = Redis.fromEnv({
			UPSTASH_REDIS_REST_URL: await env.UPSTASH_REDIS_REST_URL.get(),
			UPSTASH_REDIS_REST_TOKEN: await env.UPSTASH_REDIS_REST_TOKEN.get(),
		});
		const count = await redis.incr("counter");
		return new Response(JSON.stringify({ count }));

	},
} satisfies ExportedHandler<Env>;
```

After doing these modifications, you can deploy the worker to Cloudflare with `npx wrangler deploy`, and
follow the steps below to define the secrets:

* Navigate to [Upstash Console](https://console.upstash.com) and get your Redis credentials.

* In [Cloudflare Dashboard](https://dash.cloudflare.com/), Go to **Secrets Store** and add Redis credentials as secrets.

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=f8cd7072110966eaf77fff1b6a7d8254" data-og-width="1940" width="1940" data-og-height="1110" height="1110" data-path="img/cloudflare-integration/redis-secrets-store.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=0ed4848f21aad699b9a4deddfdc196dc 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=48d16bca52c3f4212a6119906c795384 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=dfa548e4102eb279f5dde6533d12bd3c 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=01725e656a74c38d5457f9af1c75dd49 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=672afadaa6fc60efdc0bec66f7a4a7ed 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-secrets-store.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=4760d6eff8516994b0bc185d3f833335 2500w" />
</Frame>

* Under **Compute (Workers)** > **Workers & Pages**, find your worker and add these secrets as bindings.

<Frame>
  <img src="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=840e39008f8888642accf0dc1c44a641" data-og-width="1940" width="1940" data-og-height="1370" height="1370" data-path="img/cloudflare-integration/redis-add-binding.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=280&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=b0991567a3c4eb6075f26a148b9c9c60 280w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=560&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=337e5484907c1199cc92407c86b4e4b0 560w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=840&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=c66555178015dfa8e395893352458048 840w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=1100&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=55f59d8885adfdbd187db6f4503d1cd0 1100w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=1650&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=688c3420d6b6644e9147c8555a9008b1 1650w, https://mintcdn.com/upstash/DrxIz7v3jaqUZCku/img/cloudflare-integration/redis-add-binding.png?w=2500&fit=max&auto=format&n=DrxIz7v3jaqUZCku&q=85&s=6503005e5fec4dbbaa13246fee4533b9 2500w" />
</Frame>

### Deployment

<Note>
  Newer deployments may revert the configurations you did in the dashboard.
  While worker level secrets persist, the bindings will be gone!
</Note>

Deploy your function to Cloudflare with `npx wrangler deploy`

The endpoint of the function will be provided to you, once the deployment is done.

### Testing

Open a different terminal and test the endpoint. Note the destination
url is the same that was printed in the previous deploy step.

```bash  theme={"system"}
curl -X POST 'https://<your-worker-name>.<account-name>.workers.dev' \
     -H 'Content-Type: application/json' 
```

The response will be in the format of `{"count":20}`

In the logs you should see something like this:

```bash  theme={"system"}
$ npx wrangler tail

‚õÖÔ∏è wrangler 4.43.0
--------------------

Successfully created tail, expires at 2025-10-16T18:59:18Z
Connected to <your-worker-name>, waiting for logs...
POST https://<your-worker-name>.<account-name>.workers.dev/ - Ok @ 10/16/2025, 4:05:30 PM
```

## Repositories

Javascript:
[https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers)

Typescript:
[https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers-with-typescript](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers-with-typescript)


# Deno Deploy
Source: https://upstash.com/docs/redis/quickstarts/deno-deploy



This is a step-by-step guide on how to use Upstash Redis to create a view
counter in your Deno deploy project.

### Create a database

Create a Redis database using [Upstash Console](https://console.upstash.com) or
[Upstash CLI](https://github.com/upstash/cli). Select the global to minimize the
latency from all edge locations. Copy the `UPSTASH_REDIS_REST_URL` and
`UPSTASH_REDIS_REST_TOKEN` for the next steps.

### Create a Deno deploy project

Go to [https://dash.deno.com/projects](https://dash.deno.com/projects) and
create a new playground project.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6cb71bf83b9a0df25b5457e6efe3b500" alt="" data-og-width="2056" width="2056" data-og-height="1308" height="1308" data-path="img/redis-deno/create.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2de9ae1edfca54b35d9eb159e59e38de 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=b5ef2baf9818d05d0480b7db02405566 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=ee6916085e844938a85477e1d470b811 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=439b4d7d78a4300e13fdd43929d8fcaf 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3d0f34898f283b2f5d94e7948effd09d 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/create.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=29fd67668409aa7d02ffe551861a6ff4 2500w" />

### 2. Edit the handler function

Then paste the following code into the browser editor:

```ts  theme={"system"}
import { serve } from "https://deno.land/std@0.142.0/http/server.ts";
import { Redis } from "https://deno.land/x/upstash_redis@v1.14.0/mod.ts";

serve(async (_req: Request) => {
  if (!_req.url.endsWith("favicon.ico")) {
    const redis = new Redis({
      url: "UPSTASH_REDIS_REST_URL",
      token: "UPSTASH_REDIS_REST_TOKEN",
    });

    const counter = await redis.incr("deno-counter");
    return new Response(JSON.stringify({ counter }), { status: 200 });
  }
});
```

### 3. Deploy and Run

Simply click on `Save & Deploy` at the top of the screen.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=9b2c12804600632014a6ca7303a9f72c" alt="" data-og-width="2962" width="2962" data-og-height="1492" height="1492" data-path="img/redis-deno/deploy.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=c9e4dbe9329b0b51b99fa30ad58a424c 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=cb6f0245fe154bc06c1d809f59529eac 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4ac9892f2d8417eeed6a6a506b24c127 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=aab0ddf63ead58d891eec12d37d8a9a7 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3e12f7b42470a62802bc2cd354047cbc 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-deno/deploy.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=547347df1aaece994b978b022e13b038 2500w" />


# DigitalOcean
Source: https://upstash.com/docs/redis/quickstarts/digitalocean



<Info>
  Upstash has native integration with [DigitalOcean Add-On
  Marketplace](https://marketplace.digitalocean.com/add-ons/upstash-redis).
</Info>

This quickstart shows how to create an Upstash for Redis¬Æ Database from
DigitalOcean Add-On Marketplace.

### Database Setup

Creating Upstash for Redis Database requires a DigitalOcean account.

[Login or Sign-up](https://cloud.digitalocean.com/login) for DigitalOcean
account. Then navigate the
[Upstash Redis Marketplace](https://marketplace.digitalocean.com/add-ons/upstash-redis)
page.

Click `Add Upstash Redis` button. Now setup page will open and it will ask
`Database Name / Plan / Region` info.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6af99135ba1ea833f64cb26f1943a4eb" data-og-width="708" width="708" data-og-height="1146" height="1146" data-path="img/digitalocean/img.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6ed4ff26ddaa40b07fda875b2caeb7ac 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a4c7a62eadf060b1ec9cabf04a0b389d 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=42cebdbd5a5eb1f36211a929a709daab 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=47eb6a571658d767986975c338053298 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f5d742fa5939ed1f6b7f96fbaf86845d 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e91e69128c005046f690e6eae534e1cc 2500w" />
</Frame>

After selecting Name, Plan and Region, click `Add Upstash Redis` button.

### Connecting to Database - SSO

After creating database, Overview/Details page will be opened.

Environment variables can be shown in that page.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=847d5cd110c5862b287265e8c01d57b4" data-og-width="1672" width="1672" data-og-height="958" height="958" data-path="img/digitalocean/img2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e425de665cff7bf0fd4c2f029f7c9267 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b57d97b5137a14d69a4cbb550d0f7cb4 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0ca20e434c3517b6b4838e94405c5e32 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f95c2f88abf309beebe6ebd842d849aa 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6e672fc905e7e4571ef41c149cb50c1d 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img2.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9683b0651bc6302143c038096c2ee240 2500w" />
</Frame>

While creating a Droplet, Upstash Addon can be selected and environment
variables are automatically injected to Droplet.

These Steps can be followed: `Create --> Droplets --> Marketplace Add-Ons` then
select the previously created Upstash Redis Addon.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b9dbcc8d1d7e30470669bd4ffc5a012" data-og-width="1638" width="1638" data-og-height="530" height="530" data-path="img/digitalocean/img3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=dd648a113583cff7b9a597a11aea8534 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7489cb6e8832b8a649490e9dbd5fcd53 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=921816a2537bb3d0667478fefa60f2d2 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7c4769fb3ef70cba74f111c3ab2a35f6 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4a2a8ea0a7de17c350ca49fbf3392835 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/digitalocean/img3.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a013c55e1ee2d7174013675a6e51fa1c 2500w" />
</Frame>

Upstash also support Single Sign-On from DigitalOcean to Upstash Console.

So databases created from DigitalOcean can benefit from Upstash Console
features.

In order to access Upstash Console from DigitalOcean just click `Dashboard` link
when you create the Upstash addon.


# Django
Source: https://upstash.com/docs/redis/quickstarts/django



### Introduction

In this quickstart tutorial, we will demonstrate how to use Django with Upstash Redis to build a simple web application that increments a counter every time the homepage is accessed.

### Environment Setup

First, install Django and the Upstash Redis client for Python:

```shell  theme={"system"}
pip install django
pip install upstash-redis
```

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment:

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

You can also use `python-dotenv` to load environment variables from your `.env` file.

### Project Setup

Create a new Django project:

```shell  theme={"system"}
django-admin startproject myproject
cd myproject
python manage.py startapp myapp
```

In `myproject/settings.py`, add your new app (`myapp`) to the `INSTALLED_APPS` list.

### Application Setup

In `myapp/views.py`, add the following:

```python  theme={"system"}
from django.http import HttpResponse
from upstash_redis import Redis

redis = Redis.from_env()

def index(request):
    count = redis.incr('counter')
    return HttpResponse(f'Page visited {count} times.')
```

In `myproject/urls.py`, connect the view to a URL pattern:

```python  theme={"system"}
from django.urls import path
from myapp import views

urlpatterns = [
    path('', views.index),
]
```

### Running the Application

Run the development server:

```shell  theme={"system"}
python manage.py runserver
```

Visit `http://127.0.0.1:8000/` in your browser, and the counter will increment with each page refresh.

### Code Breakdown

1. **Redis Setup**: We use the Upstash Redis client to connect to our Redis database using the environment variables `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN`. The `Redis.from_env()` method initializes this connection.

2. **Increment Counter**: In the `index` view, we increment the `counter` key each time the homepage is accessed. If the key doesn't exist, Redis creates it and starts counting from 1.

3. **Display the Count**: The updated count is returned as an HTTP response each time the page is loaded.


# Elixir
Source: https://upstash.com/docs/redis/quickstarts/elixir

Tutorial on Using Upstash Redis In Your Phoenix App and Deploying it on Fly.

This tutorial showcases how one can use [fly.io](https://fly.io) to deploy a Phoenix
app using Upstash Redis to store results of external API calls.

See [code](https://github.com/upstash/examples/tree/master/examples/elixir-with-redis) and
[demo](https://elixir-redis.fly.dev/).

### `1` Create a Elixir app with Phoenix

To create an app, run the following command:

```
mix phx.new redix_demo --no-ecto 
```

Phoenix apps are initialized with a datastore. We pass `--no-ecto` flag to disable
the datastore since we will only use Redis. See
[Phoenix documentation](https://hexdocs.pm/phoenix/up_and_running.html) for more details.

Navigate to the new directory by running

```
cd redix_demo
```

### `2` Add Redix

To connect to the Upstash Redis, we will use the
[Redix client](https://github.com/whatyouhide/redix.git) written for Elixir.

To add Redix to our project, we will first update the dependencies of our project. Simply
add the following two entries to the dependencies in the `mix.exs` file
(See [Redix documentation](https://github.com/whatyouhide/redix.git)):

```elixir  theme={"system"}
defp deps do
  [
    {:redix, "~> 1.1"},
    {:castore, ">= 0.0.0"}
  ]
end
```

Then, run `mix deps.get` to install the new dependencies.

Next, we will add Redix to our app. In our case, we will add a single global Redix instance.
Open the `application.ex` file and find the `children` list in the `start` function.

First, add a method to read the connection parameters from the `REDIS_URL` environment variable.
We choose this name for the environment variable because Fly will create a secret with this name
when we launch the app with a Redis store. Use regex to extract the password, host and port
information from the Redis URL:

```elixir  theme={"system"}
  def start(_type, _args) do
    [_, password, host, port] = Regex.run(
      ~r{(.+):(.+)@(.+):(\d+)},
      System.get_env("REDIS_URL"),
      capture: :all_but_first
    )
    port = elem(Integer.parse(port), 0)

    # ...
  end
```

Next, add the Redix client to the project by adding it to the `children` array.
([See Redix Documentation for more details](https://hexdocs.pm/redix/real-world-usage.html#single-named-redix-instance))

```elixir  theme={"system"}
children = [
  # ...
  {
    Redix,
    name: :redix,
    host: host,
    port: port,
    password: password,
    socket_opts: [:inet6]
  }
]
```

Here, we would like to draw attention to the `socket_opts` parameter. If you wish to test
your app locally by creating an Upstash Redis yourself without Fly, you must define Redix
client **without the `socket_opts: [:inet6]` field**.

### `3` Testing the Connection

At this point, our app should now be able to communicate with Redix. To test if this
connection works as expected, we will first add a status page to our app.

To add this page, we will change the default landing page of our Phoenix app. Go to the
`lib/redix_demo_web/controllers/page_html/home.html.heex` file. Replace the content of
the file with:

```html  theme={"system"}
<.flash_group flash={@flash} />
<div class="container mx-auto px-4">
  <h1 class="text-3xl font-bold mb-4">Redix Demo</h1>

  <form action="/" method="get" class="w-full flex items-center mb-4">
    <input type="text" name="text" placeholder="Location" class="flex-1 px-4 py-2 border border-gray-300 rounded-lg shadow-sm focus:outline-none focus:border-blue-500">
    <button type="submit" class="ml-4 px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600">Submit</button>
  </form>

  <%= if @text do %>
    <%= @text %>
  <% end %>

  <%= if @weather do %>
    <div class=" text-lg bg-gray-100 rounded-lg p-4">

      <%= if @location do %>
        <strong>
          Location:
        </strong>
        <%= @location %>
      <% end %>

      <p>
        <strong>
          Weather:
        </strong>
        <%= @weather %> ¬∞C
      </p>

    </div>
  <% end %>
</div>
```

This HTML will show different content depending on the parameters we
pass it. It has a form at the top which is where the user will enter
some location. Below, we will show the weather information.

Next, open the `lib/redix_demo_web/router.ex` file. In this file,
URL paths are defined with the `scope` keyword. Update the scope
in the following way:

```
  scope "/", RedixDemoWeb do
    pipe_through :browser

    get "/status", PageController, :status

    get "/", PageController, :home
    get "/:text", PageController, :home
  end
```

Our website will have a `/status` path, which will be rendered with the
`status` method we will define. The website will also render the home
page in `/` and in `/:text`. `/:text` will essentially match any route
and the route will be available to our app as a parameter when rendering.

Finally, we will define the status page in
`lib/redix_demo_web/controllers/page_controller.ex`. We will define a struct
`Payload` and a private method `render_home`. Then, we will define the home
page and the status page:

```elixir  theme={"system"}
defmodule RedixDemoWeb.PageController do
  use RedixDemoWeb, :controller

  defmodule Payload do
    defstruct text: nil, weather: nil, location: nil
  end

  def status(conn, _params) do
    case Redix.command(:redix, ["PING"]) do
      {:ok, response} ->
        render_home(conn, %Payload{text: "Redis Connection Status: Success! Response to 'PING': '#{response}'"})
      {:error, response} ->
        render_home(conn, %Payload{text: "Redis Connection Status: Error. Reason: #{response.reason}"})
      end
  end

  def home(conn, _params) do
    render_home(conn, %Payload{text: "Enter a location above to get the weather info!"})
  end

  defp render_home(conn, %Payload{} = payload) do
    render(conn, "home.html", text: payload.text, weather: payload.weather, location: payload.location)
  end
end
```

The home page simply renders our home page. The status page renders the same page, but
shows the response of a `PING` request to our Redis server.

We are now ready to deploy the app on Fly!

### `4` Deploy on Fly

To deploy the app on Fly, first
[install Fly CLI](https://fly.io/docs/hands-on/install-flyctl/) and authenticate. Then,
launch the app with:

```
fly launch
```

If you haven't set `REDIS_URL` environment variable in your environment, `fly launch` command will show
an error when compiling the app but don't worry. You can still continue with launching the app.
Fly will add this environment variable itself.

Fly will at some point ask if we want to tweak the settings of the app. Choose yes (`y`):

```
>>> fly launch

Detected a Phoenix app
Creating app in /Users/examples/redix_demo
We're about to launch your Phoenix app on Fly.io. Here's what you're getting:

Organization: C. Arda                (fly launch defaults to the personal org)
Name:         redix_demo             (derived from your directory name)
Region:       Bucharest, Romania     (this is the fastest region for you)
App Machines: shared-cpu-1x, 1GB RAM (most apps need about 1GB of RAM)
Postgres:     <none>                 (not requested)
Redis:        <none>                 (not requested)
Sentry:       false                  (not requested)

? Do you want to tweak these settings before proceeding? (y/N)
```

This will open the settings on the browser. Two settings are relevant to this guide:

* Region: Upstash is not available in all regions. Choose Amsterdam.
* Redis: Choose "Redis with Upstash"

If you already have a Redis on Fly you want to use, you may want to not choose the
"Redis with Upstash". Instead, you can get the `REDIS_URL` from [the Upstash Fly console](https://console.upstash.com/flyio/redis)
and add it as a secret with `fly secrets set REDIS_URL=****`. Note that the `REDIS_URL`
will be in `redis://default:****@fly-****.upstash.io:****` format.

Once the app is launched, deploy it with:

```
fly deploy
```

The website will become avaiable after some time. Check the `/status` page to see that
the redis connection is correctly done.

In the rest of our tutorial, we will work on caching the responses from an external api.
If you are only interested in how a Phoenix app with Redis can be deployed on Fly, you
may not need to read the rest of the tutorial.

### `5` Using Redix to Cache External API Responses

Finally, we will now build our website to offer weather information. We will use the API
of [WeatherAPI](https://www.weatherapi.com/) to get the weather information upon user
request. We will cache the results of our calls in Upstash Redis to reduce the number
of calls we make to the external API and to reduce the response time of our app.

In the end, we will have a method `def home(conn, %{"text" => text})` in the
`lib/redix_demo_web/controllers/page_controller.ex` file. To see the final file, find the
[`page_controller.ex` file Upstash examples repository](https://github.com/upstash/examples/blob/main/examples/elixir-with-redis/lib/redix_demo_web/controllers/page_controller.ex).

First, we need to define some private methods to handle the request logic. We start off
with a function to fetch the weather. The method gets the location string and replaces
the empty characters with `%20`. Then it calls `fetch_weather_from_cache` method we will
define. Depending on the result, it either returns the result from cache, or fetches the
result from the api.

```elixir  theme={"system"}
  defp fetch_weather(location) do
    location = String.replace(location, " ", "%20")
    case fetch_weather_from_cache(location) do
      {:ok, cached_weather} ->
        {:ok, cached_weather}
      {:error, :not_found} ->
        fetch_weather_from_api(location)
      {:error, reason} ->
        {:error, reason}
    end
  end
```

Now, we will define the `fetch_weather_from_cache` method. This method will use
Redix to fetch the weather from the location. If it's not found, we will return
`{:error, :not_found}`. If it's found, we will return after decoding it into a
map.

```elixir  theme={"system"}
  defp fetch_weather_from_cache(location) do
    case Redix.command(:redix, ["GET", "weather:#{location}"]) do
      {:ok, nil} ->
        {:error, :not_found}
      {:ok, cached_weather_json} ->
        {:ok, Jason.decode!(cached_weather_json)}
      {:error, _reason} ->
        {:error, "Failed to fetch weather data from cache."}
    end
  end
```

Next, we will define the `fetch_weather_from_api` method. This method
requests the weather information from the external API. If the request
is successfull, it also saves the result in the cache with the
`cache_weather_response` method.

```elixir  theme={"system"}
  defp fetch_weather_from_api(location) do
    weather_api_key = System.get_env("WEATHER_API_KEY")
    url = "http://api.weatherapi.com/v1/current.json?key=#{weather_api_key}&q=#{location}&aqi=no"

    case HTTPoison.get(url) do
      {:ok, %{status_code: 200, body: body}} ->
        weather_info = body
                      |> Jason.decode!()
                      |> get_weather_info()

        # Cache the weather response in Redis for 8 hours
        cache_weather_response(location, Jason.encode!(weather_info))

        {:ok, weather_info}
      {:ok, %{status_code: status_code, body: body}} ->
        {:error, "#{body} (#{status_code})"}
      {:error, _reason} ->
        {:error, "Failed to fetch weather data."}
    end
  end
```

In the `cache_weather_response` method, we simply store the weather
information in our Redis:

```elixir  theme={"system"}
  defp cache_weather_response(location, weather_data) do
    case Redix.command(:redix, ["SET", "weather:#{location}", weather_data, "EX", 8 * 60 * 60]) do
      {:ok, _} ->
        :ok
      {:error, _reason} ->
        {:error, "Failed to cache weather data."}
    end
  end
```

Finally, we define the `get_weather_info` and `home` methods.

```elixir  theme={"system"}
  def home(conn, %{"text" => text}) do
    case fetch_weather(text) do
      {:ok, %{"location" => location, "temp" => temp_c, "condition" => condition_text}} ->
        render_home(conn, %Payload{weather: "#{condition_text}, #{temp_c}", location: location})
      {:error, reason} ->
        render_home(conn, %Payload{text: reason})
    end
  end

  defp get_weather_info(%{
    "location" => %{
      "name" => name,
      "region" => region
    },
    "current" => %{
      "temp_c" => temp_c,
      "condition" => %{
        "text" => condition_text
      }
    }
  }) do
    %{"location" => "#{name}, #{region}", "temp" => temp_c, "condition" => condition_text}
  end
```

### `6` Re-deploying the App

To deploy the app after adding the home page logic, only a few steps remain to deploy the
finished app.

First, add `{:httpoison, "~> 1.5"}` dependency to `mix.exs` file and run `mix deps.get`.

Then, get an API key from [WeatherAPI](https://www.weatherapi.com/) and set it as secret in
fly with:

```
fly secrets set WEATHER_API_KEY=****
```

Now, you can run `fly deploy` in your directory to deploy the completed app!


# FastAPI
Source: https://upstash.com/docs/redis/quickstarts/fastapi



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/fastapi" horizontal>
  You can find the project source code on GitHub.
</Card>

### Environment Setup

Install FastAPI and `upstash-redis`.

```shell  theme={"system"}
pip install fastapi
pip install upstash-redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### API Setup

Create `main.py`:

```py main.py theme={"system"}
from fastapi import FastAPI

from upstash_redis import Redis

app = FastAPI()

redis = Redis.from_env()

@app.get("/")
def read_root():
    count = redis.incr('counter')
    return {"count": count}
```

### Run

Run the app locally with `fastapi dev main.py`, check `http://127.0.0.1:8000/`


# Fastly
Source: https://upstash.com/docs/redis/quickstarts/fastlycompute



### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or
[Upstash CLI](https://github.com/upstash/cli). Select the global to minimize the
latency from all edge locations. Copy the `UPSTASH_REDIS_REST_URL` and
`UPSTASH_REDIS_REST_TOKEN` for the next steps.

### Project Setup

We will use Fastly CLI for deployment, so please install
[Fastly CLI](https://developer.fastly.com/reference/cli/).

Create a folder for your project and run `fastly init`. Select `[2] JavaScript`,
then `[2] Empty starter for JavaScript`

```shell  theme={"system"}
> fastly compute init

Creating a new Compute@Edge project.

Press ^C at any time to quit.

Name: [fastly-upstash]
Description:
Author: [enes@upstash.com]
Language:
[1] Rust
[2] JavaScript
[3] AssemblyScript (beta)
[4] Other ('bring your own' Wasm binary)
Choose option: [1] 2
Starter kit:
[1] Default starter for JavaScript
    A basic starter kit that demonstrates routing, simple synthetic responses and
    overriding caching rules.
    https://github.com/fastly/compute-starter-kit-javascript-default
[2] Empty starter for JavaScript
    An empty application template for the Fastly Compute@Edge environment which simply
    returns a 200 OK response.
    https://github.com/fastly/compute-starter-kit-javascript-empty
Choose option or paste git URL: [1] 2
```

Install @upstash/redis:

```shell  theme={"system"}
npm install @upstash/redis
```

Now, we will create a Fastly Compute service by running,
`fastly compute publish`. You need to add your Upstash database's endpoint as a
backend and select 443 as its port.

```shell  theme={"system"}
> fastly compute publish
‚úì Initializing...
‚úì Verifying package manifest...
‚úì Verifying local javascript toolchain...
‚úì Building package using javascript toolchain...
‚úì Creating package archive...

SUCCESS: Built package 'fastly-upstash' (pkg/fastly-upstash.tar.gz)


There is no Fastly service associated with this package. To connect to an existing service
add the Service ID to the fastly.toml file, otherwise follow the prompts to create a
service now.

Press ^C at any time to quit.

Create new service: [y/N] y

‚úì Initializing...
‚úì Creating service...

Domain: [supposedly-included-corgi.edgecompute.app]

Backend (hostname or IP address, or leave blank to stop adding backends): global-concise-scorpion-30984.upstash.io
Backend port number: [80] 443
Backend name: [backend_1] upstash

Backend (hostname or IP address, or leave blank to stop adding backends):

‚úì Creating domain 'supposedly-smart-corgi.edgecompute.app'...
‚úì Creating backend 'upstash' (host: global-concise-scorpion-30984.upstash.io, port: 443)...
‚úì Uploading package...
‚úì Activating version...
```

### The Code

Update `src/index.js` as below:

```js  theme={"system"}
import { Redis } from "@upstash/redis/fastly";

addEventListener("fetch", (event) => event.respondWith(handleRequest(event)));

async function handleRequest(event) {
  const redis = new Redis({
    url: "UPSTASH_REDIS_REST_URL",
    token: "UPSTASH_REDIS_REST_TOKEN",
    backend: "upstash",
  });
  const data = await redis.incr("count");
  return new Response("View Count:" + data, { status: 200 });
}
```

### Deploy

Deploy: `fastly compute deploy`

After deployment, the CLI logs the endpoint. You can check the logs with:
`fastly log-tail --service-id=<YOUR_FASTLY_SERVICE_ID>`

### Run Locally

To run the function locally add the backend to your `fastly.toml` as below:

```toml  theme={"system"}
[local_server.backends.upstash]
url = "UPSTASH_REDIS_REST_URL"
```

Then run: `fastly compute serve`


# Flask
Source: https://upstash.com/docs/redis/quickstarts/flask



### Introduction

In this quickstart tutorial, we will explore how to use Flask with Upstash Redis to build a simple web application that increments a counter each time a user accesses the homepage.

### Environment Setup

First, install Flask and the Upstash Redis client for Python.

```shell  theme={"system"}
pip install flask
pip install upstash-redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

You can also use `python-dotenv` to load environment variables from your `.env` file.

### Application Setup

Create `app.py`:

```py app.py theme={"system"}
from flask import Flask
from upstash_redis import Redis

app = Flask(__name__)

redis = Redis.from_env()

@app.route('/')
def index():
    count = redis.incr('counter')
    return f'Page visited {count} times.'

if __name__ == '__main__':
    app.run(debug=True)
```

### Running the Application

Run the Flask app locally:

```shell  theme={"system"}
python app.py
```

Visit `http://127.0.0.1:5000/` in your browser, and you will see the `counter` increment with each refresh.

Code Breakdown

1. **Redis Setup:** We first import Flask and the Upstash Redis client. Using `Redis.from_env()`, we initialize the connection to our Redis database using the environment variables exported earlier.
2. **Increment Counter:** Each time the root route (`/`) is accessed, Redis increments the `counter` key. This key-value pair is automatically created in Redis if it does not exist, and its value is incremented on each request.
3. **Display the Count:** The number of visits is returned in the response as plain text.


# Fly.io
Source: https://upstash.com/docs/redis/quickstarts/fly



<Info>
  Fly.io has a native integration with Upstash where the databases are hosted in
  Fly. You can still access a Redis from Fly to Upstash but for the best
  latency, we recommend creating Redis (Upstash) inside Fly platform. Check
  [here](https://fly.io/docs/reference/redis/) for details.
</Info>

In this tutorial, we'll walk you through the process of deploying a Redis by
Upstash and connecting it to an application hosted on Fly.io. We'll be using
Node.js and Express for our example application, but the process can be easily
adapted to other languages and frameworks.

### Redis Setup

Create a Redis database using
[Fly CLI](https://fly.io/docs/hands-on/install-flyctl/)

```shell  theme={"system"}
> flyctl redis create
? Select Organization: upstash (upstash)
? Choose a Redis database name (leave blank to generate one):
? Choose a primary region (can't be changed later) San Jose, California (US) (sjc)

Upstash Redis can evict objects when memory is full. This is useful when caching in Redis. This setting can be changed later.
Learn more at https://fly.io/docs/reference/redis/#memory-limits-and-object-eviction-policies
? Would you like to enable eviction? No
? Optionally, choose one or more replica regions (can be changed later):
? Select an Upstash Redis plan 3G: 3 GB Max Data Size

Your Upstash Redis database silent-tree-6201 is ready.
Apps in the upstash org can connect to at redis://default:978ba2e07tyrt67598acd8ac916a@fly-silent-tree-6201.upstash.io
If you have redis-cli installed, use fly redis connect to connect to your database.
```

### Set up the Node.js application

* Create a new folder for your project and navigate to it in the terminal.
* Run `npm init -y` to create a `package.json` file.
* Install Express and the Redis client: `npm install express redis`
* Create an `index.js` file in the project folder with the following content:

```js  theme={"system"}
const express = require("express");
const redis = require("redis");
const { promisify } = require("util");

const app = express();
const client = redis.createClient(process.env.REDIS_URL);

const getAsync = promisify(client.get).bind(client);
const setAsync = promisify(client.set).bind(client);

app.get("/", async (req, res) => {
  const value = await getAsync("counter");
  await setAsync("counter", parseInt(value || 0) + 1);
  res.send(`Hello, visitor number ${value || 0}!`);
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`Server running on port ${PORT}`));
```

This code creates a simple Express server that increments a counter in Redis and
returns the visitor number.

### Configure the Fly.io application

* Run `fly init "your-app-name"` to initialize a new Fly.io application.
* Choose the "Node.js (14.x)" builder, and accept the defaults for the remaining
  prompts.
* Open the `fly.toml` file that was generated and add the following environment
  variable under the `[[services]]` section:

```toml  theme={"system"}
[env]
  REDIS_URL = "<your-upstash-redis-url>"
```

Replace `your-upstash-redis-url` with the Redis URL from your Upstash instance.

### Deploy the application to Fly.io

* Run fly deploy to build and deploy your application.
* After the deployment is complete, run fly status to check if the application
  is running.
* Visit the URL provided in the output (e.g., [https://your-app-name.fly.dev](https://your-app-name.fly.dev)) to
  test your application.

### Conclusion

You have successfully deployed a Node.js application on Fly.io that uses an
Upstash Redis instance as its data store. You can now build and scale your
application as needed, leveraging the benefits of both Fly.io and Upstash.

### Availability of Redis URL for Local Development and Testing

#### Understanding Fly.io and Redis Setup

* **Redis Instance on Fly.io**: When you create a Redis instance using `fly redis create`, Fly.io establishes a Redis server in its cloud environment, designed specifically for applications running on the Fly.io platform.

* **Connection String**: This command generates a connection string. However, it's important to note that this string is intended primarily for applications deployed within Fly.io's network. Due to security and network configurations, it's not directly accessible from external networks, like your local development environment.

#### Creating a Tunnel for Local Testing

* **Fly Redis Connect**: For local access to your Redis instance, use `fly redis connect`. This command establishes a secure tunnel between your local machine and the Redis instance on Fly.io.

  * **How it Works**:
    * The tunnel maps a local port to the remote Redis port on Fly.io.
    * Once established, you can connect to Redis as if it were running locally, typically at `localhost` with the mapped port.

  * **Setting Up the Tunnel**:
    * Execute `fly redis connect` in your terminal.
    * The command provides a local address (e.g., `localhost:10000`).
    * Use this address as your Redis connection URL in your local development setup.

  * **Considerations**:
    * This tunnel is a temporary solution, ideal for development and testing, not for production.
    * Ensure compatibility with your local firewall and network settings.

#### Additional Notes

* **Security Considerations**: Exercise caution regarding security. Although the tunnel is secure, it exposes your Redis instance to your local network.
* **Alternative Approaches**: Some developers opt to run a local Redis instance for development to bypass these complexities.

#### Summary

To connect to a Redis instance hosted on Fly.io from your local machine, a secure tunnel is necessary. This tunnel effectively simulates a local Redis instance, enabling testing and development activities without exposing your Redis instance over the internet.

#### Example Code for Setting Up and Using the Fly.io Redis Tunnel

##### Step 1: Establish the Tunnel

To establish a tunnel between your local machine and the Redis instance on Fly.io, run the following command in your terminal:

```shell  theme={"system"}
fly redis connect
```

After running this command, you'll receive a local address, such as `localhost:10000`. This address will act as your local Redis endpoint.

##### Step 2: Connect to Redis in Your Application

In your application, you should typically use an environment variable for the Redis URL. When developing locally, set this environment variable to the local address provided by the `fly redis connect` command.

Here's an example in a Node.js application:

```js  theme={"system"}
const redis = require("redis");

// Local Redis URL for development
const LOCAL_REDIS_URL = 'redis://localhost:10000'; // Replace with your actual local address
const REDIS_URL = process.env.NODE_ENV === 'development' ? LOCAL_REDIS_URL : process.env.REDIS_URL;

const client = redis.createClient({
    url: REDIS_URL
});

client.on("error", function(error) {
  console.error(error);
});

// Rest of your Redis-related code
```

##### Step 3: Running Your Application Locally

Ensure that the Fly.io Redis tunnel is active when you run your application locally. Your application will connect to Redis through this tunnel, simulating a local instance.

```shell  theme={"system"}
npm start
```

**Important Notes:**

* The `fly redis connect` tunnel should only be used for development and testing purposes.
* Replace `LOCAL_REDIS_URL` in the sample code with the actual local address provided by `fly redis connect`.
* Set your application's environment to 'development' when running locally to use the local Redis URL.


# Google Cloud Functions
Source: https://upstash.com/docs/redis/quickstarts/google-cloud-functions



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/google-cloud-functions" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

1. [Create a Google Cloud Project.](https://cloud.google.com/resource-manager/docs/creating-managing-projects)
2. [Enable billing for your project.](https://cloud.google.com/billing/docs/how-to/verify-billing-enabled#console)
3. Enable Cloud Functions, Cloud Build, Artifact Registry, Cloud Run, Logging, and Pub/Sub APIs.

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli). Copy `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` for the next steps.

### Counter Function Setup & Deploy

1. Go to [Cloud Functions](https://console.cloud.google.com/functions/list) in Google Cloud Console.
2. Click **Create Function**.
3. Setup **Basics and Trigger** Configuration like below:
   <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=007ed606059c1a85715b71f3cc93f7d8" alt="" data-og-width="1090" width="1090" data-og-height="1082" height="1082" data-path="img/redis-gcloud/basics.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=43b1d3e50933c5dcfa82b66fc851a7a0 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=7004784999274823be6d91f4fada8507 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=f898ec6c37fe88ca6ea160cb5d6c128e 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2871baf9499c25407ad19cf314871b28 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=a3a3397a7490aaa2f81fde3081af7cdd 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3c6c312c51df82b43ae09ff00d414a81 2500w" />
4. Using your `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN`, setup **Runtime environment variables** under **Runtime, build, connections and privacy settings** like below.
   <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e23d98d5b0c2619d971719dac8899931" alt="" data-og-width="1006" width="1006" data-og-height="432" height="432" data-path="img/redis-gcloud/environment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d1d4089e0dab97bd4f9c722792e3f665 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2f0f5f385024764675ac77ca35de41e9 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2ffe0b80e0a93ac3eceb060fa0ae8bb6 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=321957fba3db5bdc17b51bf3af983cef 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d2821b72c40318f56fabb809970bbe62 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=af5fbdb53b54bb2953ec0c56a6454c44 2500w" />
5. Click **Next**.
6. Set **Entry point** to `counter`.
7. Update `index.js`

```js index.js theme={"system"}
const { Redis } = require("@upstash/redis");
const functions = require('@google-cloud/functions-framework');

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN
});

functions.http('counter', async (req, res) => {
  const count = await redis.incr("counter");
  res.send("Counter:" + count);
});
```

8. Update `package.json` to include `@upstash/redis`.

```json package.json theme={"system"}
{
  "dependencies": {
    "@google-cloud/functions-framework": "^3.0.0",
    "@upstash/redis": "^1.31.6"
  }
}
```

9. Click **Deploy**.
10. Visit the given URL.


# Ion
Source: https://upstash.com/docs/redis/quickstarts/ion



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/ion" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

You need to have AWS credentials configured locally and SST CLI installed.

1. [Create an AWS account](https://aws.amazon.com/)
2. [Create an IAM user](https://sst.dev/chapters/create-an-iam-user.html)
3. [Configure the AWS CLI](https://sst.dev/chapters/configure-the-aws-cli.html)
4. [Setup SST CLI](https://ion.sst.dev/docs/reference/cli/)

### Project Setup

Let's create a new Next.js application.

```shell  theme={"system"}
npx create-next-app@latest
cd my-app
```

Let's initialize SST in our app.

```shell  theme={"system"}
sst init
```

Install the `@upstash/redis` package.

```shell  theme={"system"}
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Pass the Environment Variables

```ts /sst.config.ts theme={"system"}
/// <reference path="./.sst/platform/config.d.ts" />

export default $config({
  app(input) {
    return {
      name: "my-app",
      removal: input?.stage === "production" ? "retain" : "remove",
      home: "aws",
    };
  },
  async run() {
    new sst.aws.Nextjs("MyWeb", {
      environment: {
        UPSTASH_REDIS_REST_URL: process.env.UPSTASH_REDIS_REST_URL || "",
        UPSTASH_REDIS_REST_TOKEN: process.env.UPSTASH_REDIS_REST_TOKEN || "",
      },
    });
  },
});
```

### Home Page Setup

Update `/app/page.tsx`:

```tsx /app/page.tsx theme={"system"}
import { Redis } from "@upstash/redis";

const redis = Redis.fromEnv();

export default async function Home() {
  const count = await redis.incr("counter");
  return (
    <div className="flex h-screen w-screen items-center justify-center">
      <h1 className="text-4xl font-bold">Counter: {count}</h1>
    </div>
  )
}
```

### Run

Run the SST app.

```shell  theme={"system"}
npm run dev
```

Check `http://localhost:3000/`

### Deploy

Deploy with SST.

```shell  theme={"system"}
sst deploy
```

Check the output URL.


# ioredis note
Source: https://upstash.com/docs/redis/quickstarts/ioredisnote



<Note>
  This example uses ioredis, you can copy the connection string from the `Node`
  tab in the console.
</Note>


# Koyeb
Source: https://upstash.com/docs/redis/quickstarts/koyeb



Integrate a serverless Upstash Redis database with your Koyeb applications. Combine the serverless features of Koyeb on the application side and Upstash for your key-value storage to deploy and scale applications globally with ease.

This guide explains how to connect an Upstash Redis data store as a database cache with an application running on Koyeb. To successfully follow this documentation, you will need to have:

* A [Koyeb account](https://app.koyeb.com/) to deploy the application. You can optionally install the [Koyeb CLI](https://www.koyeb.com/docs/quickstart/koyeb-cli) to deploy the application from the command line
* An [Upstash account](https://console.upstash.com/) to deploy the database
* [Node.js](https://nodejs.org/en) and `npm` installed on your local machine to create the demo application.

If you already have a freshly created Upstash Redis database running and want to quickly preview how to connect your Upstash database to an application running on Koyeb, use the [Deploy to Koyeb](https://www.koyeb.com/docs/deploy-to-koyeb-button) button below.

[![Deploy to Koyeb](https://www.koyeb.com/static/images/deploy/button.svg)](https://app.koyeb.com/deploy?type=git\&repository=github.com/koyeb/example-koyeb-upstash\&branch=main\&name=example-koyeb-upstash\&env\[UPSTASH_REDIS_REST_URL]=REPLACE_ME\&env\[UPSTASH_REDIS_REST_TOKEN]=REPLACE_ME\&env\[PORT]=8000)

*Make sure to replace the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` environment variables with the values for your Upstash database.*

## Create an Upstash Redis database

To create an Upstash Redis database, sign into your [Upstash account](https://console.upstash.com/).

In the Upstash console, select **Redis** from the top navigation bar. On the Redis page, click **Create database**:

1. In the **Name** field, choose a name for your database. In this example, we'll use `example-koyeb-upstash`.
2. Select the **Type** of deployment you want. Because this is demo does not have global requirements, we will use "Regional" in this guide to limit the choices we have to make.
3. In the **Region** drop-down menu, choose a location that's geographically convenient for your database and users. We use "N. Virginia (us-east-1)".
4. Select your preferred options. In this example, we will select "TLS (SSL) Enabled" so that connections to the database are encrypted and "Eviction" so that older data will be purged when we run out of space.
5. Click **Create** to provision the Redis database.

### Retrieve your Upstash URL and token

On your Upstash Redis page, scroll down to the **REST API** section of the page.

Click on the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` buttons to copy their respective values to your clipboard. Paste the copied values to a safe location so that you can reference them later when testing and deploying your application.

Alternatively, you can click on the `@upstash/redis` tab to view a code snippet:

```javascript  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = new Redis({
  url: "<YOUR_UPSTASH_REDIS_REST_URL>",
  token: "<YOUR_UPSTASH_REDIS_REST_TOKEN>",
});

const data = await redis.set("foo", "bar");
```

When you copy the code block using the provided copy button, the code snippet, along with your database's URL and access token will be copied to your clipboard. While this works well for private or demonstration code, it generally isn't good practice to hard-code sensitive data like tokens within your application. To avoid this, we will configure the application to get these values from the environment instead.

## Create a demo application

Next, you can create a simple Node.js application that uses your Upstash Redis database. The application will use the [Express](https://expressjs.com/) web framework to build and serve a simple page and Upstash's own [`@upstash/redis`](/redis/sdks/ts/overview) package to connect to the database.

### Install the dependencies

Create a new directory for your demo application and navigate to the new location:

```bash  theme={"system"}
mkdir example-koyeb-upstash
cd example-koyeb-upstash
```

Within the new directory, generate a `package.json` file for the new project using the default settings:

```bash  theme={"system"}
npm init -y
```

Next, install the `@upstash/redis` package so that you can connect to your Redis database from within the application and the `express` package so that we can build a basic web application:

```bash  theme={"system"}
npm install @upstash/redis express
```

### Create the application file

Now, create a new file called `index.js` with the following contents:

```javascript  theme={"system"}
// Note: if you are using Node.js version 17 or lower,
//       change the first line to the following:
// const { Redis } = require ("@upstash/redis/with-fetch");
const { Redis } = require("@upstash/redis");
const express = require("express");

const app = express();
const redis = Redis.fromEnv();

app.get("/", async (req, res) => {
  const value = await redis.get("counter");
  await redis.set("counter", parseInt(value || 0) + 1);
  res.send(`Counter: ${value || 0}`);
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});
```

**Note:** If you are running Node.js version 17 or lower, you need to adjust the first line of the app to import from the `@upstash/redis/with-fetch` instead of `@upstash/redis`. Node.js versions prior to 18 did not natively support `fetch` API, so you need to change the import path in order to access that functionality.

This above code will introduce a simple `counter` key to your Redis database. It will use this key to store the number of times the page has been accessed and display that value on the page.

### Add the run scripts

Finally, edit the `package.json` file to define the scripts used to run the application. The `dev` script runs the application in debug mode while the `start` script starts the application normally:

```diff  theme={"system"}
{
  "name": "example-koyeb-upstash",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
+   "dev": "DEBUG=express:* node index.js",
+   "start": "node index.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "@upstash/redis": "^1.20.6",
    "express": "^4.18.2"
  }
}
```

## Run the demo application locally

Now that the project is set up, you can run the application locally verify that it functions correctly.

In your shell, set and export the variables you copied from your Upstash Redis page:

```bash  theme={"system"}
export UPSTASH_REDIS_REST_URL="<YOUR_UPSTASH_REDIS_REST_URL>"
export UPSTASH_REDIS_REST_TOKEN="<YOUR_UPSTASH_REDIS_REST_TOKEN>"
```

In the same terminal, you should now be able to test your application by typing:

```bash  theme={"system"}
npm run dev
```

The application server should start in debug mode, printing information about the process to the display. In your browser, navigate to `127.0.0.1:3000` to see your application. It should show the counter and number of visits you've made: "Counter: 0". The number should increase by one every time you refresh the page.

Press <kbd>CTRL</kbd>-<kbd>c</kbd> to stop the application when you are finished.

## Deploy the application to Koyeb using git-driven deployment

Once you've verified that the project runs locally, create a new Git repository to save your work.

Run the following commands to create a new Git repository within the project's root directory, commit the project files, and push changes to GitHub. Remember to replace the values of `<YOUR_GITHUB_USERNAME>` and `<YOUR_REPOSITORY_NAME>` with your own information:

```bash  theme={"system"}
git init
echo 'node_modules' >> .gitignore
git add .
git commit -m "Initial commit"
git remote add origin git@github.com:<YOUR_GITHUB_USERNAME>/<YOUR_REPOSITORY_NAME>.git
git push -u origin main
```

You can deploy the demo application to Koyeb and connect it to the Upstash Redis database using the [control panel](#via-the-koyeb-control-panel) or via the [Koyeb CLI](#via-the-koyeb-cli).

### Via the Koyeb control panel

To deploy the using the [control panel](https://app.koyeb.com/), follow these steps:

1. Click **Create App** in the Koyeb control panel.
2. Select **GitHub** as the deployment option.
3. Choose the GitHub **repository** and **branch** containing your application code.
4. Name your service, for example `upstash-service`.
5. Click **Advanced** to view additional options. Under **Environment variables**, click **Add Variable** to add two new variables called `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN`. Populate them with the values you copied for your Upstash Redis database.
6. Name the App, for example `upstash-demo`.
7. Click the **Deploy** button.

A Koyeb App and Service will be created. Your application will be built and deployed to Koyeb. Once the build has finished, you will be able to access your application running on Koyeb by clicking the URL ending with `.koyeb.app`.

### Via the Koyeb CLI

To deploy the example application using the [Koyeb CLI](https://www.koyeb.com/docs/cli/installation), run the following command in your terminal:

```bash  theme={"system"}
koyeb app init example-koyeb-upstash \
  --git github.com/<YOUR_GITHUB_USERNAME>/<YOUR_REPOSITORY_NAME> \
  --git-branch main \
  --ports 3000:http \
  --routes /:3000 \
  --env PORT=3000 \
  --env UPSTASH_REDIS_REST_URL="<YOUR_UPSTASH_REDIS_REST_URL>" \
  --env UPSTASH_REDIS_REST_TOKEN="<YOUR_UPSTASH_REDIS_REST_TOKEN>"
```

*Make sure to replace `<YOUR_GITHUB_USERNAME>/<YOUR_REPOSITORY_NAME>` with your GitHub username and repository name and replace `<YOUR_UPSTASH_REDIS_REST_URL>` and `<YOUR_UPSTASH_REDIS_REST_TOKEN>` with the values copied from your Upstash Redis page.*

#### Access deployment logs

To track the app deployment and view the build logs, execute the following command:

```bash  theme={"system"}
koyeb service logs example-koyeb-upstash/example-koyeb-upstash -t build
```

#### Access your app

Once the deployment of your application has finished, you can retrieve the public domain to access your application by running the following command:

```bash  theme={"system"}
$ koyeb app get example-koyeb-upstash
ID      	NAME         	        DOMAINS                          	        CREATED AT
85c78d9a	example-koyeb-upstash	["example-koyeb-upstash-myorg.koyeb.app"]	31 May 23 13:08 UTC
```

#### Access runtime logs

With your app running, you can track the runtime logs by running the following command:

```bash  theme={"system"}
koyeb service logs example-koyeb-upstash/example-koyeb-upstash -t runtime
```

## Deploy the application to Koyeb using a pre-built container

As an alternative to using git-driven deployment, you can deploy a pre-built container from any public or private registry. This can be useful if your application needs specific system dependencies or you need more control over how the build is performed.

To dockerize the application, start by adding a file called `.dockerignore` to the project's root directory. Paste the following contents to limit the files copied to the Docker image:

```
Dockerfile
.dockerignore
.git
node_modules
npm-debug.log
/.cache
.env
README.md
```

Afterwards, create a `Dockerfile` in your project root directory and copy the content below:

```dockerfile  theme={"system"}
FROM node:18-alpine AS base

FROM base AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm ci

FROM base AS runner
WORKDIR /app
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nodejs
COPY --from=deps /app/node_modules ./node_modules
COPY . .
USER node
EXPOSE 3000
ENV PORT 3000
CMD ["npm", "run", "start"]
```

The Dockerfile above provides the minimum requirements to run the sample Node.js application. You can easily extend it depending on your needs.

*Be sure to set the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` environment variables to the values you copied from the Upstash console when you deploy the container in the Koyeb control panel.*

To build and push the Docker image to a registry and deploy it on Koyeb, refer to the [Deploy an app from a Docker image](https://www.koyeb.com/docs/quickstart/deploy-a-docker-application) documentation.

A Koyeb App and Service will be created. Your Docker image will be pulled and deployed to Koyeb. Once the deployment has finished, you will be able to access your application running on Koyeb by clicking the URL ending with `.koyeb.app`.

## Delete the example application and Upstash Redis database

To delete the example application and the Upstash Redis database and avoid incurring any charges, follow these steps:

* From the [Upstash console](https://console.upstash.com/), select your Redis database and scroll to the bottom of the **Details** page. Click **Delete this database** and follow the instructions.
* From the [Koyeb control panel](https://app.koyeb.com/), select your App. Click the **Settings** tab, and click the **Danger Zone**. Click **Delete App** and follow the instructions. Alternatively, from the CLI, you can delete your Koyeb App and service by typing `koyeb app delete example-koyeb-upstash`.


# Laravel
Source: https://upstash.com/docs/redis/quickstarts/laravel



## Project Setup

To get started, let‚Äôs create a new Laravel application. If you don‚Äôt have the Laravel CLI installed globally, install it first using Composer:

```shell  theme={"system"}
composer global require laravel/installer
```

After installation, create your Laravel project:

```shell  theme={"system"}
laravel new example-app
cd example-app
```

Alternatively, if you don‚Äôt want to install the Laravel CLI, you can create a project using Composer:

```shell  theme={"system"}
composer create-project laravel/laravel example-app
cd example-app
```

## Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com). Go to the **Connect to your database** section and click on Laravel. Copy those values into your .env file:

```shell .env theme={"system"}
REDIS_HOST="<YOUR_ENDPOINT>"
REDIS_PORT=6379
REDIS_PASSWORD="<YOUR_PASSWORD>"
```

## Framework Integration

Upstash Redis integrates seamlessly with Laravel, allowing it to be used as a driver for multiple framework components.

### Interact with Redis

The Redis Facade in Laravel provides a convenient way to interact with your Redis database. For example:

```php  theme={"system"}
use Illuminate\Support\Facades\Redis;

// Storing a value in Redis
Redis::set('key', 'value');

// Retrieving a value from Redis
$value = Redis::get('key');
```

This can be particularly useful for simple caching or temporary data storage.

### Cache

To use Upstash Redis as your caching driver, update the CACHE\_STORE in your .env file:

```shell .env theme={"system"}
CACHE_STORE="redis"
REDIS_CACHE_DB="0"
```

With this configuration, you can use Laravel‚Äôs caching functions, such as:

```php  theme={"system"}
Cache::put('key', 'value', now()->addMinutes(10));
$value = Cache::get('key');
```

For more advanced cache configurations, see the [Laravel Cache Documentation](https://laravel.com/docs/cache).

### Session

Laravel can store session data in Upstash Redis. To enable this, set the SESSION\_DRIVER in your .env file:

```shell .env theme={"system"}
SESSION_DRIVER="redis"
```

This ensures that session data is stored in your Upstash Redis database, providing fast and reliable session management.

### Queue

Upstash Redis can also serve as a driver for Laravel‚Äôs queue system, enabling job processing. To configure this, update the QUEUE\_CONNECTION in your .env file:

```shell .env theme={"system"}
QUEUE_CONNECTION="redis"
```

For detailed queue configurations and usage, refer to the [Laravel Queues Documentation](https://laravel.com/docs/queues).


# App Router
Source: https://upstash.com/docs/redis/quickstarts/nextjs-app-router



***

## Quickstart: Upstash Redis in Next 15

<Frame>
  <iframe src="https://player.mux.com/gPYmP1M00800UgLr4fa9O8CeN6M36E2iY6Bww8Ir5Qn4U?thumbnail-time=5&metadata-video-title=Upstash+Redis+x+Next+15+Quickstart&video-title=Upstash+Redis+x+Next+15+Quickstart" allow="accelerometer; gyroscope; autoplay; encrypted-media; fullscreen;" allowfullscreen className="w-full aspect-video" />
</Frame>

***

## 1. Install package

In your Next.js app, install our `@upstash/redis` package:

```bash  theme={"system"}
npm install @upstash/redis
```

***

## 2. Connect to Redis

1. Grab your Redis credentials from the Upstash dashboard

   <Frame>
     <img src="https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=9579b4b5bdffebf8fc826afb27dbade0" data-og-width="1465" width="1465" data-og-height="392" height="392" data-path="img/next-quickstart/credentials.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=280&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=dd43bbd32b2f717411a9e9224d011ecc 280w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=560&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=ad29f55a2af986d3d60f951eeca48ce9 560w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=840&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=fdc958de0ac98113944ea845e21cf6a5 840w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=1100&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=aaf5a153a3c3e820e392596d044e9ab5 1100w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=1650&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=e824c0be82bfa51b7726c54bc672821b 1650w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/credentials.png?w=2500&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=c1c12586cf4fe6fbce09cfd07d893a2c 2500w" />
   </Frame>

2. Paste them into your Next environment variables:

   ```bash title=".env" theme={"system"}
   UPSTASH_REDIS_REST_URL=https://holy-kite-17499.upstash.io
   UPSTASH_REDIS_REST_TOKEN=AURbAAIncDEyYjM4M...
   ```

3. Create a Redis instance, for example in `lib/redis.ts`

   ```typescript title="lib/redis.ts" theme={"system"}
   import { Redis } from "@upstash/redis"

   // üëá we can now import our redis client anywhere we need it
   export const redis = new Redis({
     url: process.env.UPSTASH_REDIS_REST_URL,
     token: process.env.UPSTASH_REDIS_REST_TOKEN,
   })
   ```

***

## 3. Using our Redis Client

We can now connect to Upstash Redis from any server component or API route. For example:

```typescript title="app/page.tsx" theme={"system"}
import { redis } from "@/lib/redis"

// üëá server component
const Page = async () => {
  const count = await redis.get<number>("count")
  return <p>count: {count}</p>
}

export default Page
```

Because this `count` doesn't exist yet, let's create a Next API route to populate it.

***

## 3. Storing data in Redis

Let's create a super simple API that, every time when called, increments an integer value we call `count`. This is the same value we display in our page above:

```typescript title="app/api/counter/route.ts" theme={"system"}
import { redis } from "@/lib/redis"

export const POST = async () => {
  await redis.incr("count")

  return new Response("OK")
}
```

Perfect! Every time we now call this API, we increment the count in our Redis database:

<Frame>
  <img src="https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=76efae06a8805d53c457726204f61c73" data-og-width="953" width="953" data-og-height="108" height="108" data-path="img/next-quickstart/curl.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=280&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=90fab89a9e93352d33f1cb45ead14529 280w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=560&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=3a5fe449bc5ce81186a9de193ad016e3 560w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=840&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=d01de44348f675b6feccb72667cbb0ce 840w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=1100&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=d40e207b189ec138e5fea53818fb9e4c 1100w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=1650&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=6e2b43c93cb4a6fbb0817fc70267072a 1650w, https://mintcdn.com/upstash/jtc3r6kD_firFPfY/img/next-quickstart/curl.png?w=2500&fit=max&auto=format&n=jtc3r6kD_firFPfY&q=85&s=c9b9118267f9de0e28b40e6a2039de47 2500w" />
</Frame>

The server component fetches the most recent count at render-time and displays the up-to-date value automatically. For a video demo, check the video at the top of this article.

***

## Examples

<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/nextjs-app-router" horizontal>
  You can find the project source code on GitHub.
</Card>

<Info>
  If you're already on Vercel, you can create Upstash projects directly through Vercel: [Read more](../howto/vercelintegration).
</Info>


# Pages Router
Source: https://upstash.com/docs/redis/quickstarts/nextjs-pages-router



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/nextjs-pages-router" horizontal>
  You can find the project source code on GitHub.
</Card>

### Project Setup

Let's create a new Next.js application with Pages Router and install `@upstash/redis` package.

```shell  theme={"system"}
npx create-next-app@latest
cd my-app
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Home Page Setup

Update `/pages/index.tsx`:

```tsx /pages/index.tsx theme={"system"}
import type { InferGetServerSidePropsType, GetServerSideProps } from 'next'
import { Redis } from "@upstash/redis";

const redis = Redis.fromEnv();

export const getServerSideProps = (async () => {
  const count = await redis.incr("counter");
  return { props: { count } }
}) satisfies GetServerSideProps<{ count: number }>

export default function Home({
  count,
}: InferGetServerSidePropsType<typeof getServerSideProps>) {
  return (
    <div className="flex h-screen w-screen items-center justify-center">
      <h1 className="text-4xl font-bold">Counter: {count}</h1>
    </div>
  )
}
```

### Run & Deploy

Run the app locally with `npm run dev`, check `http://localhost:3000/`

Deploy your app with `vercel`

<Info>
  You can also integrate your Vercel projects with Upstash using Vercel
  Integration module. Check [this article](../howto/vercelintegration).
</Info>


#  AWS Lambda
Source: https://upstash.com/docs/redis/quickstarts/python-aws-lambda



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/aws-cdk-python" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

* Complete all steps in [Getting started with the AWS CDK](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html)

### Project Setup

Create and navigate to a directory named `counter-cdk`. CDK CLI uses this directory name to name things in your CDK code, so if you decide to use a different name, don't forget to make the appropriate changes when applying this tutorial.

```shell  theme={"system"}
mkdir counter-cdk && cd counter-cdk
```

Initialize a new CDK project.

```shell  theme={"system"}
cdk init app --language typescript
```

### Counter Function Setup

Create a folder named `api` under `lib`

```shell  theme={"system"}
mkdir lib/api
```

Create `/lib/api/requirements.txt`

```txt /lib/api/requirements.txt theme={"system"}
upstash-redis
```

Create `/lib/api/index.py`

```py /lib/api/index.py theme={"system"}
from upstash_redis import Redis

redis = Redis.from_env()

def handler(event, context):
    count = redis.incr('counter')
    return {
        'statusCode': 200,
        'body': f'Counter: {count}'
    }
```

### Counter Stack Setup

Update `/lib/counter-cdk-stack.ts`

```ts /lib/counter-cdk-stack.ts theme={"system"}
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as lambda from 'aws-cdk-lib/aws-lambda';
import * as path from 'path';

export class CounterCdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const counterFunction = new lambda.Function(this, 'CounterFunction', {
      code: lambda.Code.fromAsset(path.join(__dirname, 'api'), {
        bundling: {
          image: lambda.Runtime.PYTHON_3_9.bundlingImage,
          command: [
            'bash', '-c',
            'pip install -r requirements.txt -t /asset-output && cp -au . /asset-output'
          ],
        },
      }),
      runtime: lambda.Runtime.PYTHON_3_9,
      handler: 'index.handler',
      environment: {
        UPSTASH_REDIS_REST_URL: process.env.UPSTASH_REDIS_REST_URL || '',
        UPSTASH_REDIS_REST_TOKEN: process.env.UPSTASH_REDIS_REST_TOKEN || '',
      },
    });

    const counterFunctionUrl = counterFunction.addFunctionUrl({
      authType: lambda.FunctionUrlAuthType.NONE,
    });

    new cdk.CfnOutput(this, "counterFunctionUrlOutput", {
      value: counterFunctionUrl.url,
    })
  }
}
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Deploy

Run in the top folder:

```shell  theme={"system"}
cdk synth
cdk bootstrap
cdk deploy
```

Visit the output url.


# SST v2
Source: https://upstash.com/docs/redis/quickstarts/sst-v2



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/sst-v2" horizontal>
  You can find the project source code on GitHub.
</Card>

### Prerequisites

You need to have AWS credentials configured locally.

1. [Create an AWS account](https://aws.amazon.com/)
2. [Create an IAM user](https://sst.dev/chapters/create-an-iam-user.html)
3. [Configure the AWS CLI](https://sst.dev/chapters/configure-the-aws-cli.html)

### Project Setup

Let's create a new SST + Next.js application.

```shell  theme={"system"}
npx create-sst@latest --template standard/nextjs
cd my-sst-app
npm install
```

Install the `@upstash/redis` package.

```shell  theme={"system"}
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell  theme={"system"}
npx sst secrets set UPSTASH_REDIS_REST_URL <YOUR_URL>
npx sst secrets set UPSTASH_REDIS_REST_TOKEN <YOUR_TOKEN>
```

### Bind the Secrets

```ts /stacks/Default.ts theme={"system"}
import { Config, StackContext, NextjsSite } from "sst/constructs";

export function Default({ stack }: StackContext) {
  const UPSTASH_REDIS_REST_URL = new Config.Secret(stack, "UPSTASH_REDIS_REST_URL");
  const UPSTASH_REDIS_REST_TOKEN = new Config.Secret(stack, "UPSTASH_REDIS_REST_TOKEN");
  const site = new NextjsSite(stack, "site", {
    bind: [UPSTASH_REDIS_REST_URL, UPSTASH_REDIS_REST_TOKEN],
    path: "packages/web",
  });
  stack.addOutputs({
    SiteUrl: site.url,
  });
}
```

### API Setup

```ts /packages/web/pages/api/hello.ts theme={"system"}
import { Redis } from "@upstash/redis";
import type { NextApiRequest, NextApiResponse } from "next";
import { Config } from "sst/node/config";

const redis = new Redis({
  url: Config.UPSTASH_REDIS_REST_URL,
  token: Config.UPSTASH_REDIS_REST_TOKEN,
  });

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse,
) {
  const count = await redis.incr("counter");
  res.status(200).json({ count });
}

```

### Run

Run the SST app.

```shell  theme={"system"}
npm run dev
```

After prompted, run the Next.js app.

```shell  theme={"system"}
cd packages/web
npm run dev
```

Check `http://localhost:3000/api/hello`

### Deploy

Set the secrets for the prod stage.

```shell  theme={"system"}
npx sst secrets set --stage prod UPSTASH_REDIS_REST_URL <YOUR_URL>
npx sst secrets set --stage prod UPSTASH_REDIS_REST_TOKEN <YOUR_TOKEN>
```

Deploy with SST.

```shell  theme={"system"}
npx sst deploy --stage prod
```

Check `<SiteUrl>/api/hello` with the given SiteUrl.


# Supabase Functions
Source: https://upstash.com/docs/redis/quickstarts/supabase



The below is an example for a Redis counter that stores a
[hash](https://redis.io/commands/hincrby/) of Supabase function invocation count
per region.

## Redis database setup

Create a Redis database using the
[Upstash Console](https://console.upstash.com/) or
[Upstash CLI](https://github.com/upstash/cli).

Select the `Global` type to minimize the latency from all edge locations. Copy
the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your .env file.

You'll find them under **Details > REST API > .env**.

```shell  theme={"system"}
cp supabase/functions/upstash-redis-counter/.env.example supabase/functions/upstash-redis-counter/.env
```

## Code

Make sure you have the latest version of the
[Supabase CLI installed](https://supabase.com/docs/guides/cli#installation).

Create a new function in your project:

```shell  theme={"system"}
supabase functions new upstash-redis-counter
```

And add the code to the `index.ts` file:

```ts index.ts theme={"system"}
import { serve } from "https://deno.land/std@0.177.0/http/server.ts";
import { Redis } from "https://deno.land/x/upstash_redis@v1.19.3/mod.ts";
console.log(`Function "upstash-redis-counter" up and running!`);
serve(async (_req) => {
  try {
    const redis = new Redis({
      url: Deno.env.get("UPSTASH_REDIS_REST_URL")!,
      token: Deno.env.get("UPSTASH_REDIS_REST_TOKEN")!,
    });
    const deno_region = Deno.env.get("DENO_REGION");
    if (deno_region) {
      // Increment region counter
      await redis.hincrby("supa-edge-counter", deno_region, 1);
    } else {
      // Increment localhost counter
      await redis.hincrby("supa-edge-counter", "localhost", 1);
    }
    // Get all values
    const counterHash: Record<string, number> | null = await redis.hgetall(
      "supa-edge-counter"
    );
    const counters = Object.entries(counterHash!)
      .sort(([, a], [, b]) => b - a) // sort desc
      .reduce(
        (r, [k, v]) => ({
          total: r.total + v,
          regions: { ...r.regions, [k]: v },
        }),
        {
          total: 0,
          regions: {},
        }
      );
    return new Response(JSON.stringify({ counters }), { status: 200 });
  } catch (error) {
    return new Response(JSON.stringify({ error: error.message }), {
      status: 200,
    });
  }
});
```

## Run locally

```bash  theme={"system"}
supabase start
supabase functions serve upstash-redis-counter --no-verify-jwt --env-file supabase/functions/upstash-redis-counter/.env
```

Navigate to [http://localhost:54321/functions/v1/upstash-redis-counter](http://localhost:54321/functions/v1/upstash-redis-counter).

## Deploy

```bash  theme={"system"}
supabase functions deploy upstash-redis-counter --no-verify-jwt
supabase secrets set --env-file supabase/functions/upstash-redis-counter/.env
```


# App Router
Source: https://upstash.com/docs/redis/quickstarts/vercel-functions-app-router



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/vercel-functions-app-router" horizontal>
  You can find the project source code on GitHub.
</Card>

### Project Setup

Let's create a new Next.js application with App Router and install `@upstash/redis` package.

```shell  theme={"system"}
npx create-next-app@latest
cd my-app
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Function Setup

<Info>
  This is a Vercel Serverless Function. If you want to use Edge Runtime, you can add the `export const runtime = 'edge'` line to this Route Handler.
</Info>

Create `/app/api/hello/route.ts`:

```ts /app/api/hello/route.ts theme={"system"}
import { Redis } from "@upstash/redis";
import { NextResponse } from "next/server";

const redis = Redis.fromEnv();

export async function GET() {
    const count = await redis.incr("counter");
    return NextResponse.json({ count });
}

export const dynamic = 'force-dynamic'
```

### Run & Deploy

Run the app locally with `npm run dev`, check `http://localhost:3000/api/hello`

Deploy your app with `vercel`

<Info>
  You can also integrate your Vercel projects with Upstash using Vercel
  Integration module. Check [this article](../howto/vercelintegration).
</Info>


# Pages Router
Source: https://upstash.com/docs/redis/quickstarts/vercel-functions-pages-router



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/vercel-functions-pages-router" horizontal>
  You can find the project source code on GitHub.
</Card>

<Info>
  This is a quickstart for Vercel Serverless Functions. If you want to use Edge Runtime, Vercel recommends icrementally adopting the App Router.
</Info>

### Project Setup

Let's create a new Next.js application with Pages Router and install `@upstash/redis` package.

```shell  theme={"system"}
npx create-next-app@latest
cd my-app
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Function Setup

Update `/pages/api/hello.ts`:

```ts /pages/api/hello.ts theme={"system"}
import { Redis } from "@upstash/redis";
import type { NextApiRequest, NextApiResponse } from "next";

const redis = Redis.fromEnv();

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse,
) {
  const count = await redis.incr("counter");
  res.status(200).json({ count });
}
```

### Run & Deploy

Run the app locally with `npm run dev`, check `http://localhost:3000/api/hello`

Deploy your app with `vercel`

<Info>
  You can also integrate your Vercel projects with Upstash using Vercel
  Integration module. Check [this article](../howto/vercelintegration).
</Info>


# Vercel Python Runtime
Source: https://upstash.com/docs/redis/quickstarts/vercel-python-runtime



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/vercel-python-runtime-django" horizontal>
  You can find the project source code on GitHub.
</Card>

<Info>
  This quickstart uses django but you can easily adapt it to Flask, FastAPI or plain Python, see [Vercel Python Templates](https://vercel.com/templates?framework=python).
</Info>

### Project Setup

Let's create a new django application from Vercel's template.

```shell  theme={"system"}
npx create-next-app vercel-django --example "https://github.com/vercel/examples/tree/main/python/django"
cd vercel-django
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Environment Setup

Update `requirements.txt` to include `upstash-redis`.

```txt requirements.txt theme={"system"}
Django==4.1.3
upstash-redis
```

We will create a Conda environment with python version `3.12` to match Vercel Python Runtime and avoid conflicts on deployment, you can use any other environment management system.

```shell  theme={"system"}
conda create --name vercel-django python=3.12
conda activate vercel-django
pip install -r requirements.txt
```

### View Setup

Update `/example/views.py`:

```py /example/views.py theme={"system"}
from datetime import datetime

from django.http import HttpResponse

from upstash_redis import Redis

redis = Redis.from_env()

def index(request):
    count = redis.incr('counter')
    html = f'''
    <html>
        <body>
            <h1>Counter: { count }</h1p>
        </body>
    </html>
    '''
    return HttpResponse(html)
```

### Run & Deploy

Run the app locally with `python manage.py runserver`, check `http://localhost:8000/`

Deploy your app with `vercel`

Set `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` in your project's Settings -> Environment Variables. Redeploy from Deployments tab.

<Info>
  You can also integrate your Vercel projects with Upstash using Vercel
  Integration module. Check [this article](../howto/vercelintegration).
</Info>


# ECHO
Source: https://upstash.com/docs/redis/sdks/py/commands/auth/echo



Returns a message back to you. Useful for debugging the connection.

## Arguments

<ParamField body="message" type="str" required>
  A message to send to the server.
</ParamField>

## Response

<ResponseField type="str" required>
  The same message you sent.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  assert redis.echo("hello world") == "hello world"
  ```
</RequestExample>


# PING
Source: https://upstash.com/docs/redis/sdks/py/commands/auth/ping

Send a ping to the server and get a response if the server is alive.

## Arguments

No arguments

## Response

<ResponseField type="str" required>
  `PONG`
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  assert redis.ping() == "PONG"
  ```
</RequestExample>


# BITCOUNT
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/bitcount

Count the number of set bits.

The `BITCOUNT` command in Redis is used to count the number of set bits (bits with a value of 1) in a range of bytes within a key that is stored as a binary string. It is primarily used for bit-level operations on binary data stored in Redis.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="start" type="int">
  Specify the range of bytes within the binary string to count the set bits. If not provided, it counts set bits in the entire string.

  Either specify both `start` and `end` or neither.
</ParamField>

<ParamField body="end" type="int">
  Specify the range of bytes within the binary string to count the set bits. If not provided, it counts set bits in the entire string.

  Either specify both `start` and `end` or neither.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of set bits in the specified range.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.setbit("mykey", 7, 1)
  redis.setbit("mykey", 8, 1)
  redis.setbit("mykey", 9, 1)

  # With range
  assert redis.bitcount("mykey", 0, 10) == 3

  # Without range
  assert redis.bitcount("mykey") == 3
  ```
</RequestExample>


# BITFIELD
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/bitfield

Sets or gets parts of a bitfield

The `bitfield` function returns a `BitFieldCommands` instance that can be used
to execute multiple bitfield operations in a single command.

The encoding can be a signed or unsigned integer, by prefixing the type with
`i` or `u`. For example, `i4` is a signed 4-bit integer, and `u8` is an
unsigned 8-bit integer.

```py  theme={"system"}
redis.set("mykey", "")

# Sets the first 4 bits to 1
# Increments the next 4 bits by 1
result = redis.bitfield("mykey")
        .set("u4", 0, 16)
        .incr("u4", 4, 1)
        .execute()

assert result == [0, 1]
```

## Commands

### `get(type: str, offset: int)`

Returns a value from the bitfield at the given offset.

### `set(type: str, offset: int, value: int)`

Sets a value and returns the old value.

### `incr(type: str, offset: int, increment: int)`

Increments a value and returns the new value.

## Arguments

<ParamField body="key" type="str" required>
  The string key to operate on.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers, one for each operation.
</ResponseField>

<RequestExample>
  ```py Get theme={"system"}
  redis.set("mykey", "\x05\x06\x07")

  result = redis.bitfield("mykey") \
      .get("u8", 0) \
      .get("u8", 8) \
      .get("u8", 16) \
      .execute()

  assert result == [5, 6, 7]
  ```

  ```py Set theme={"system"}
  redis.set("mykey", "")

  result = redis.bitfield("mykey") \
      .set("u4", 0, 16) \
      .set("u4", 4, 1) \
      .execute()
    
  assert result == [0, 1]
  ```

  ```py Incr theme={"system"}
  redis.set("mykey", "")

  # Increment offset 0 by 16, return 
  # Increment offset 4 by 1

  result = redis.bitfield("mykey") \
      .incr("u4", 0, 16) \
      .incr("u4", 4, 1) \
      .execute()

  assert result == [0, 1]
  ```
</RequestExample>


# BITOP
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/bitop

Perform bitwise operations between strings.

The `BITOP` command in Redis is used to perform bitwise operations on multiple keys (or Redis strings) and store the result in a destination key. It is primarily used for performing logical AND, OR, XOR, and NOT operations on binary data stored in Redis.

## Arguments

<ParamField body="operation" type="AND | OR | XOR | NOT" required>
  Specifies the type of bitwise operation to perform, which can be one of the
  following: `AND`, `OR`, `XOR`, or `NOT`.
</ParamField>

<ParamField body="destkey" type="str" required>
  The key to store the result of the operation in.
</ParamField>

<ParamField body="keys" type="*List[str]" required>
  One or more keys to perform the operation on.
</ParamField>

## Response

<ResponseField type="int" required>
  The size of the string stored in the destination key.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # key1 = 00000001
  # key2 = 00000010
  redis.setbit("key1", 0, 1)
  redis.setbit("key2", 0, 0)
  redis.setbit("key2", 1, 1)

  assert redis.bitop("AND", "dest", "key1", "key2") == 1

  # result = 00000000
  assert redis.getbit("dest", 0) == 0
  assert redis.getbit("dest", 1) == 0
  ```
</RequestExample>


# BITPOS
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/bitpos

Find the position of the first set or clear bit (bit with a value of 1 or 0) in a Redis string key.

## Arguments

<ParamField body="key" type="str" required>
  The key to search in.
</ParamField>

<ParamField body="bit" type="0 | 1" required>
  The key to store the result of the operation in.
</ParamField>

<ParamField body="start" type="int">
  The index to start searching at.
</ParamField>

<ParamField body="end" type="int">
  The index to stop searching at.
</ParamField>

## Response

<ResponseField type="int" required>
  The index of the first occurrence of the bit in the string.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.setbit("mykey", 7, 1)
  redis.setbit("mykey", 8, 1)

  assert redis.bitpos("mykey", 1) == 7
  assert redis.bitpos("mykey", 0) == 0

  # With a range
  assert redis.bitpos("mykey", 1, 0, 2) == 0
  assert redis.bitpos("mykey", 1, 2, 3) == -1
  ```

  ```py With Range theme={"system"}
  redis.bitpos("key", 1, 5, 20)
  ```
</RequestExample>


# GETBIT
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/getbit

Retrieve a single bit.

## Arguments

<ParamField body="key" type="str" required>
  The key of the bitset
</ParamField>

<ParamField body="offset" type="int" required>
  Specify the offset at which to get the bit.
</ParamField>

## Response

<ResponseField type="int" required>
  The bit value stored at offset.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  bit = redis.getbit(key, 4)
  ```
</RequestExample>


# SETBIT
Source: https://upstash.com/docs/redis/sdks/py/commands/bitmap/setbit

Set a single bit in a string.

## Arguments

<ParamField body="key" type="str" required>
  The key of the bitset
</ParamField>

<ParamField body="offset" type="int" required>
  Specify the offset at which to set the bit.
</ParamField>

<ParamField body="value" type="0 | 1" required>
  The bit to set
</ParamField>

## Response

<ResponseField type="0 | 1" required>
  The original bit value stored at offset.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  original_bit = redis.setbit(key, 4, 1)
  ```
</RequestExample>


# DEL
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/del

Removes the specified keys. A key is ignored if it does not exist.

## Arguments

<ParamField body="keys" type="*List[str]" required>
  One or more keys to remove.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of keys that were removed.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")
  redis.set("key2", "World")
  redis.delete("key1", "key2")

  assert redis.get("key1") is None
  assert redis.get("key2") is None
  ```
</RequestExample>


# EXISTS
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/exists

Check if a key exists.

## Arguments

<ParamField body="keys" type="*List[str]" required>
  One or more keys to check.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of keys that exist
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")
  redis.set("key2", "World")

  assert redis.exists("key1", "key2") == 2

  redis.delete("key1")

  assert redis.exists("key1", "key2") == 1
  ```
</RequestExample>


# EXPIRE
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/expire

Sets a timeout on key. The key will automatically be deleted.

## Arguments

<ParamField body="key" type="str" required>
  The key to set the timeout on.
</ParamField>

<ParamField body="seconds" type="int | datetime.timedelta" required>
  The timeout in seconds as int or datetime.timedelta object
</ParamField>

<ParamField body="nx" type="bool">
  Set expiry only when the key has no expiry
</ParamField>

<ParamField body="xx" type="bool">
  Set expiry only when the key has an existing expiry
</ParamField>

<ParamField body="gt" type="bool">
  Set expiry only when the new expiry is greater than current one
</ParamField>

<ParamField body="lt" type="bool">
  Set expiry only when the new expiry is less than current one
</ParamField>

## Response

<ResponseField type="bool">
  `True` if the timeout was set
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # With seconds
  redis.set("mykey", "Hello")
  redis.expire("mykey", 5)

  assert redis.get("mykey") == "Hello"

  time.sleep(5)

  assert redis.get("mykey") is None

  # With a timedelta
  redis.set("mykey", "Hello")
  redis.expire("mykey", datetime.timedelta(seconds=5))
  ```
</RequestExample>


# EXPIREAT
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/expireat

Sets a timeout on key. The key will automatically be deleted.

## Arguments

<ParamField body="key" type="str" required>
  The key to set the timeout on.
</ParamField>

<ParamField body="unix_time_seconds" type="int | datetime.datetime" required>
  The timeout in unix seconds timestamp as int or a datetime.datetime object.
</ParamField>

<ParamField body="nx" type="bool">
  Set expiry only when the key has no expiry
</ParamField>

<ParamField body="xx" type="bool">
  Set expiry only when the key has an existing expiry
</ParamField>

<ParamField body="gt" type="bool">
  Set expiry only when the new expiry is greater than current one
</ParamField>

<ParamField body="lt" type="bool">
  Set expiry only when the new expiry is less than current one
</ParamField>

## Response

<ResponseField type="bool">
  `True` if the timeout was set
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # With a datetime object
  redis.set("mykey", "Hello")
  redis.expireat("mykey", datetime.datetime.now() + datetime.timedelta(seconds=5))

  # With a unix timestamp
  redis.set("mykey", "Hello")
  redis.expireat("mykey", int(time.time()) + 5)
  ```
</RequestExample>


# KEYS
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/keys

Returns all keys matching pattern.

<Warning>
  This command may block the DB for a long time, depending on its size. We advice against using it in production. Use [SCAN](/redis/sdks/py/commands/generic/scan) instead.
</Warning>

## Arguments

<ParamField body="match" type="str" required>
  A glob-style pattern. Use `*` to match all keys.
</ParamField>

## Response

<ResponseField type="List[str]">
  Array of keys matching the pattern.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  keys = redis.keys("prefix*")
  ```

  ```py Match All theme={"system"}
  keys = redis.keys("*")
  ```
</RequestExample>


# PERSIST
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/persist

Remove any timeout set on the key.

## Arguments

<ParamField body="key" type="str" required>
  The key to persist
</ParamField>

## Response

<ResponseField type="bool">
  `True` if the timeout was set
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")
  redis.expire("key1", 10)

  assert redis.ttl("key1") == 10

  redis.persist("key1")

  assert redis.ttl("key1") == -1
  ```
</RequestExample>


# PEXPIRE
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/pexpire

Sets a timeout on key. After the timeout has expired, the key will automatically be deleted.

## Arguments

<ParamField body="key" type="str" required>
  The key to expire.
</ParamField>

<ParamField body="milliseconds | datetime.timedelta" type="int" required>
  The timeout in milliseconds as int or datetime.timedelta
</ParamField>

<ParamField body="nx" type="bool">
  Set expiry only when the key has no expiry
</ParamField>

<ParamField body="xx" type="bool">
  Set expiry only when the key has an existing expiry
</ParamField>

<ParamField body="gt" type="bool">
  Set expiry only when the new expiry is greater than current one
</ParamField>

<ParamField body="lt" type="bool">
  Set expiry only when the new expiry is less than current one
</ParamField>

## Response

<ResponseField type="bool">
  `True` if the timeout was set
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # With milliseconds
  redis.set("mykey", "Hello")
  redis.expire("mykey", 500)

  # With a timedelta
  redis.set("mykey", "Hello")
  redis.expire("mykey", datetime.timedelta(milliseconds=500))
  ```
</RequestExample>


# PEXPIREAT
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/pexpireat

Sets a timeout on key. After the timeout has expired, the key will automatically be deleted.

## Arguments

<ParamField body="key" type="str" required>
  The key to expire.
</ParamField>

<ParamField body="unix_time_milliseconds" type="int | datetime.datetime" required>
  The timeout in unix milliseconds timestamp as int or a datetime.datetime object.
</ParamField>

<ParamField body="nx" type="bool">
  Set expiry only when the key has no expiry
</ParamField>

<ParamField body="xx" type="bool">
  Set expiry only when the key has an existing expiry
</ParamField>

<ParamField body="gt" type="bool">
  Set expiry only when the new expiry is greater than current one
</ParamField>

<ParamField body="lt" type="bool">
  Set expiry only when the new expiry is less than current one
</ParamField>

## Response

<ResponseField type="bool">
  `True` if the timeout was set
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # With a unix timestamp
  redis.set("mykey", "Hello")
  redis.pexpireat("mykey", int(time.time() * 1000) )

  # With a datetime object
  redis.set("mykey", "Hello")
  redis.pexpireat("mykey", datetime.datetime.now() + datetime.timedelta(seconds=5))
  ```
</RequestExample>


# PTTL
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/pttl

Return the expiration in milliseconds of a key.

## Arguments

<ParamField body="key" type="str" required>
  The key
</ParamField>

## Response

<ResponseField type="int" required>
  The number of milliseconds until this expires, negative if the key does not exist or does not have an expiration set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")

  assert redis.pttl("key1") == -1

  redis.expire("key1", 1000)

  assert redis.pttl("key1") > 0

  redis.persist("key1")

  assert redis.pttl("key1") == -1
  ```
</RequestExample>


# RANDOMKEY
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/randomkey

Returns a random key from database

## Arguments

No arguments

## Response

<ResponseField type="str">
  A random key from database, or `None` when database is empty.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  assert redis.randomkey() is None

  redis.set("key1", "Hello")
  redis.set("key2", "World")

  assert redis.randomkey() is not None
  ```
</RequestExample>


# RENAME
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/rename

Rename a key

Renames a key and overwrites the new key if it already exists.

Throws an exception if the key does not exist.

## Arguments

<ParamField body="source" type="str" required>
  The original key.
</ParamField>

<ParamField body="destination" type="str" required>
  A new name for the key.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if key was renamed
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")
  redis.rename("key1", "key2")

  assert redis.get("key1") is None
  assert redis.get("key2") == "Hello"

  # Renaming a nonexistent key throws an exception
  redis.rename("nonexistent", "key3")
  ```
</RequestExample>


# RENAMENX
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/renamenx

Rename a key if it does not already exist.

Renames a key, only if the new key does not exist.

Throws an exception if the key does not exist.

## Arguments

<ParamField body="source" type="str" required>
  The original key.
</ParamField>

<ParamField body="destination" type="str" required>
  A new name for the key.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if key was renamed
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")
  redis.set("key2", "World")

  # Rename failed because "key2" already exists.
  assert redis.renamenx("key1", "key2") == False

  assert redis.renamenx("key1", "key3") == True

  assert redis.get("key1") is None
  assert redis.get("key2") == "World"
  assert redis.get("key3") == "Hello"
  ```
</RequestExample>


# SCAN
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/scan

Scan the database for keys.

## Arguments

<ParamField body="cursor" type="int" required>
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="match" type="str" required>
  Glob-style pattern to filter by field names.
</ParamField>

<ParamField body="count" type="int" required>
  Number of fields to return per call.
</ParamField>

<ParamField body="type" type="str">
  Filter by type.
  For example `string`, `hash`, `set`, `zset`, `list`, `stream`.
</ParamField>

## Response

<ResponseField type="Tuple[int, List[str]]" required>
  The new cursor and the keys as a tuple.
  If the new cursor is `0` the iteration is complete.

  Use the new cursor for subsequent calls.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Get all keys

  cursor = 0
  results = []

  while True:
      cursor, keys = redis.scan(cursor, match="*")

      results.extend(keys)
      if cursor == 0:
          break
  ```
</RequestExample>


# TOUCH
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/touch

Alters the last access time of one or more keys

## Arguments

<ParamField body="keys" type="*List[str]" required>
  One or more keys.
</ParamField>

## Response

<ResponseField type="int">
  The number of keys that were touched.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.touch("key1", "key2", "key3")
  ```
</RequestExample>


# TTL
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/ttl

Return the expiration in seconds of a key.

## Arguments

<ParamField body="key" type="str" required>
  The key
</ParamField>

## Response

<ResponseField type="int" required>
  The number of seconds until this expires, negative if the key does not exist or does not have an expiration set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Get the TTL of a key
  redis.set("my-key", "value")

  assert redis.ttl("my-key") == -1

  redis.expire("my-key", 10)

  assert redis.ttl("my-key") > 0

  # Non existent key
  assert redis.ttl("non-existent-key") == -2
  ```
</RequestExample>


# TYPE
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/type

Get the type of a key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="str" required>
  The type of the key.

  One of `string` | `list` | `set` | `zset` | `hash` | `none`
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "Hello")

  assert redis.type("key1") == "string"

  redis.lpush("key2", "Hello")

  assert redis.type("key2") == "list"

  assert redis.type("non-existent-key") == "none"
  ```
</RequestExample>


# UNLINK
Source: https://upstash.com/docs/redis/sdks/py/commands/generic/unlink

Removes the specified keys. A key is ignored if it does not exist.

## Arguments

<ParamField body="keys" type="*List[str]" required>
  One or more keys to unlink.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of keys that were unlinked.
</ResponseField>

<RequestExample>
  ```py Basic theme={"system"}
  assert redis.unlink("key1", "key2", "key3") == 3
  ```
</RequestExample>


# HDEL
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hdel

Deletes one or more hash fields.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="fields" type="*List[str]" required>
  One or more fields to delete.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of fields that were removed from the hash.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", "field1", "Hello")
  redis.hset("myhash", "field2", "World")

  assert redis.hdel("myhash", "field1", "field2") == 2
  ```
</RequestExample>


# HEXISTS
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hexists

Checks if a field exists in a hash.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="field" type="str" required>
  The field to check.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if the hash contains `field`. `False` if the hash does not contain `field`, or `key` does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("key", "field", "value")

  assert redis.hexists("key", "field") == True
  ```
</RequestExample>


# HEXPIRE
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hexpire

Set a timeout on a hash field in seconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields within the hash to set the expiry for.
</ParamField>

<ParamField body="seconds" type="Union[int, datetime.timedelta]" required>
  The timeout in seconds as an integer or a `datetime.timedelta` object.
</ParamField>

<ParamField body="nx" type="bool" optional>
  Set expiry only when the field has no expiry. Defaults to `False`.
</ParamField>

<ParamField body="xx" type="bool" optional>
  Set expiry only when the field has an existing expiry. Defaults to `False`.
</ParamField>

<ParamField body="gt" type="bool" optional>
  Set expiry only when the new expiry is greater than the current one. Defaults to `False`.
</ParamField>

<ParamField body="lt" type="bool" optional>
  Set expiry only when the new expiry is less than the current one. Defaults to `False`.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HEXPIRE documentation](https://redis.io/commands/hexpire).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)

  assert redis.hexpire(hash_name, field, 1) == [1]
  ```
</RequestExample>


# HEXPIREAT
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hexpireat

Sets an expiration time for field(s) in a hash in seconds since the Unix epoch.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to set an expiration time for.
</ParamField>

<ParamField body="timestamp" type="int" required>
  The expiration time as a Unix timestamp in seconds.
</ParamField>

<ParamField body="nx" type="bool" optional>
  Set expiry only when the field has no expiry. Defaults to `False`.
</ParamField>

<ParamField body="xx" type="bool" optional>
  Set expiry only when the field has an existing expiry. Defaults to `False`.
</ParamField>

<ParamField body="gt" type="bool" optional>
  Set expiry only when the new expiry is greater than the current one. Defaults to `False`.
</ParamField>

<ParamField body="lt" type="bool" optional>
  Set expiry only when the new expiry is less than the current one. Defaults to `False`.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HEXPIREAT documentation](https://redis.io/commands/hexpireat).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)

  assert redis.hexpireat(hash_name, field, int(time.time()) + 10) == [1]
  ```
</RequestExample>


# HEXPIRETIME
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hexpiretime

Retrieves the expiration time of field(s) in a hash in seconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to retrieve the expiration time for.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers representing the expiration time in seconds since the Unix epoch.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HEXPIRETIME documentation](https://redis.io/commands/hexpiretime).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)
  redis.hexpireat(hash_name, field, int(time.time()) + 10)

  assert redis.hexpiretime(hash_name, field) == [1697059200]
  ```
</RequestExample>


# HGET
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hget

Retrieves the value of a hash field.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="field" type="str" required>
  The field to get.
</ParamField>

## Response

<ResponseField type="Optional[str]">
  The value of the field, or `null`, when field is not present in the hash or key does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", "field1", "Hello")

  assert redis.hget("myhash", "field1") == "Hello"
  assert redis.hget("myhash", "field2") is None
  ```
</RequestExample>


# HGETALL
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hgetall

Retrieves all fields from a hash.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="Optional[str]" required>
  An object with all fields in the hash.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", values={
  "field1": "Hello",
  "field2": "World"
  })

  assert redis.hgetall("myhash") == {"field1": "Hello", "field2": "World"}
  ```
</RequestExample>


# HINCRBY
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hincrby

Increments the value of a hash field by a given amount

If the hash field does not exist, it is set to 0 before performing the operation.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="str" required>
  The field to increment
</ParamField>

<ParamField body="increment" type="int">
  How much to increment the field by. Can be negative to subtract.
</ParamField>

## Response

<ResponseField type="int" required>
  The new value of the field after the increment.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", "field1", 5)

  assert redis.hincrby("myhash", "field1", 10) == 15
  ```
</RequestExample>


# HINCRBYFLOAT
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hincrbyfloat

Increments the value of a hash field by a given float value.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="str" required>
  The field to increment
</ParamField>

<ParamField body="increment" type="float" required>
  How much to increment the field by. Can be negative to subtract.
</ParamField>

## Response

<ResponseField type="float" required>
  The new value of the field after the increment.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", "field1", 5.5)

  assert redis.hincrbyfloat("myhash", "field1", 10.1) - 15.6 < 0.0001
  ```
</RequestExample>


# HKEYS
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hkeys

Return all field names in the hash stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="List[str]" required>
  The field names of the hash
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hkeys("myhash") == ["field1", "field2"]
  ```
</RequestExample>


# HLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hlen

Returns the number of fields contained in the hash stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="int" required>
  How many fields are in the hash.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  assert redis.hlen("myhash") == 0

  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hlen("myhash") == 2
  ```
</RequestExample>


# HMGET
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hmget

Return the requested fields and their values.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="*List[str]" required>
  One or more fields to get.
</ParamField>

## Response

<ResponseField type="List[str | None]" required>
  An object containing the fields and their values.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hmget("myhash", "field1", "field2") == ["Hello", "World"]
  ```
</RequestExample>


# HMSET
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hmset

Write multiple fields to a hash.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Dict[str, Any]" required>
  A dictionary of fields and their values.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of fields that were added.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Set multiple fields
  assert redis.hset("myhash"{
    "field1": "Hello",
    "field2": "World"
  }) == 2
  ```
</RequestExample>


# HPERSIST
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hpersist

Remove the expiration from one or more hash fields.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields within the hash to remove the expiry from.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers indicating the result for each field:

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration set.
  * `1` if the expiration was successfully removed.

  For more details, see [HPERSIST documentation](https://redis.io/commands/hpersist).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)
  redis.hpexpire(hash_name, field, 1000)

  assert redis.hpersist(hash_name, field) == [1]
  ```
</RequestExample>


# HPEXPIRE
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hpexpire

Set a timeout on a hash field in milliseconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields within the hash to set the expiry for.
</ParamField>

<ParamField body="milliseconds" type="Union[int, datetime.timedelta]" required>
  The timeout in milliseconds as an integer or a `datetime.timedelta` object.
</ParamField>

<ParamField body="nx" type="bool" optional>
  Set expiry only when the field has no expiry. Defaults to `False`.
</ParamField>

<ParamField body="xx" type="bool" optional>
  Set expiry only when the field has an existing expiry. Defaults to `False`.
</ParamField>

<ParamField body="gt" type="bool" optional>
  Set expiry only when the new expiry is greater than the current one. Defaults to `False`.
</ParamField>

<ParamField body="lt" type="bool" optional>
  Set expiry only when the new expiry is less than the current one. Defaults to `False`.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HPEXPIRE documentation](https://redis.io/commands/hpexpire).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)

  assert redis.hpexpire(hash_name, field, 1000) == [1]
  ```
</RequestExample>


# HPEXPIREAT
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hpexpireat

Sets an expiration time for field(s) in a hash in milliseconds since the Unix epoch.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to set an expiration time for.
</ParamField>

<ParamField body="timestamp" type="int" required>
  The expiration time as a Unix timestamp in milliseconds.
</ParamField>

<ParamField body="nx" type="bool" optional>
  Set expiry only when the field has no expiry. Defaults to `False`.
</ParamField>

<ParamField body="xx" type="bool" optional>
  Set expiry only when the field has an existing expiry. Defaults to `False`.
</ParamField>

<ParamField body="gt" type="bool" optional>
  Set expiry only when the new expiry is greater than the current one. Defaults to `False`.
</ParamField>

<ParamField body="lt" type="bool" optional>
  Set expiry only when the new expiry is less than the current one. Defaults to `False`.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HPEXPIREAT documentation](https://redis.io/commands/hpexpireat).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)

  assert redis.hpexpireat(hash_name, field, int(time.time() * 1000) + 1000) == [1]
  ```
</RequestExample>


# HPEXPIRETIME
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hpexpiretime

Retrieves the expiration time of a field in a hash in milliseconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to retrieve the expiration time for.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers representing the expiration time in milliseconds since the Unix epoch.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HPEXPIRETIME documentation](https://redis.io/commands/hpexpiretime).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)
  redis.hpexpireat(hash_name, field, int(time.time() * 1000) + 1000)

  assert redis.hpexpiretime(hash_name, field) == [1697059200000]
  ```
</RequestExample>


# HPTTL
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hpttl

Retrieves the remaining time-to-live (TTL) for field(s) in a hash in milliseconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to retrieve the TTL for.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers representing the remaining TTL in milliseconds for each field.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HPTTL documentation](https://redis.io/commands/hpttl).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)
  redis.hpexpire(hash_name, field, 1000)

  assert redis.hpttl(hash_name, field) == [950]
  ```
</RequestExample>


# HRANDFIELD
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hrandfield

Return a random field from a hash

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="count" type="int">
  Optionally return more than one field.
</ParamField>

<ParamField body="withvalues" type="boolean">
  Return the values of the fields as well.
</ParamField>

## Response

<ResponseField type="Record<str, unknown>" required>
  An object containing the fields and their values.
</ResponseField>

<RequestExample>
  ```py Single theme={"system"}
  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hrandfield("myhash") in ["field1", "field2"]
  ```

  ```py Multiple theme={"system"}
  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hrandfield("myhash", count=2) in [
      ["field1", "field2"],
      ["field2", "field1"]
  ]
  ```

  ```py With Values theme={"system"}
  redis.hset("myhash", values={
      "field1": "Hello",
      "field2": "World"
  })

  assert redis.hrandfield("myhash", count=1, withvalues=True) in [
      {"field1": "Hello"},
      {"field2": "World"}
  ]
  ```
</RequestExample>


# HSCAN
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hscan

Scan a hash for fields.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="cursor" type="int" required>
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="match" type="str">
  Glob-style pattern to filter by field names.
</ParamField>

<ParamField body="count" type="int">
  Number of fields to return per call.
</ParamField>

## Response

<ResponseField type="Tuple[number, List[str]]" required>
  The new cursor and the fields.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```py Basic theme={"system"}
  # Get all members of a hash.

  cursor = 0
  results = []

  while True:
      cursor, keys = redis.hscan("myhash", cursor, match="*")

      results.extend(keys)
      if cursor == 0:
          break
  ```
</RequestExample>


# HSET
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hset

Write one or more fields to a hash.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="str">
  Field to set
</ParamField>

<ParamField body="value" type="str">
  Value to set
</ParamField>

<ParamField body="values" type="Dict[str, Any]">
  An object of fields and their values.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of fields that were added.
</ResponseField>

<RequestExample>
  ```py Single theme={"system"}
  # Set a single field
  assert redis.hset("myhash", "field1", "Hello") == 1
  ```

  ```py Multiple theme={"system"}
  # Set multiple fields
  assert redis.hset("myhash", values={
    "field1": "Hello",
    "field2": "World"
  }) == 2
  ```
</RequestExample>


# HSETNX
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hsetnx

Write a field to a hash but only if the field does not exist.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="str" required>
  The name of the field.
</ParamField>

<ParamField body="value" type="Any" required>
  The value to set.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if the field was set, `False` if it already existed.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  assert redis.hsetnx("myhash", "field1", "Hello") == True
  assert redis.hsetnx("myhash", "field1", "World") == False
  ```
</RequestExample>


# HSTRLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hstrlen

Returns the string length of a value in a hash.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="str" required>
  The name of the field.
</ParamField>

## Response

<ResponseField type="int" required>
  `0` if the hash or field does not exist. Otherwise the length of the string.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  length = redis.hstrlen("key", "field")
  ```
</RequestExample>


# HTTL
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/httl

Retrieves the remaining time-to-live (TTL) for field(s) in a hash in seconds.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="Union[str, List[str]]" required>
  The field or list of fields to retrieve the TTL for.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  A list of integers representing the remaining TTL in seconds for each field.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HTTL documentation](https://redis.io/commands/httl).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset(hash_name, field, value)
  redis.hexpire(hash_name, field, 10)

  assert redis.httl(hash_name, field) == [9]
  ```
</RequestExample>


# HVALS
Source: https://upstash.com/docs/redis/sdks/py/commands/hash/hvals

Returns all values in the hash stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="List[str]" required>
  All values in the hash, or an empty list when key does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.hset("myhash", values={
    "field1": "Hello",
    "field2": "World"
  })

  assert redis.hvals("myhash") == ["Hello", "World"]
  ```
</RequestExample>


# JSON.ARRAPPEND
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrappend

Append values to the array at path in the JSON document at key.

<Tip>
  To specify a string as an array value to append, wrap the quoted string with an additional set of single quotes. Example: '"silver"'.
</Tip>

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the array.
</ParamField>

<ParamField body="value" type="...TValue[]" required>
  One or more values to append to the array.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the array after the appending.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.arrappend("key", "$.path.to.array", "a")
  ```
</RequestExample>


# JSON.ARRINDEX
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrindex

Search for the first occurrence of a JSON value in an array.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the array.
</ParamField>

<ParamField body="value" type="TValue" required>
  The value to search for.
</ParamField>

<ParamField body="start" type="int" default={0}>
  The start index.
</ParamField>

<ParamField body="stop" type="int" default={0}>
  The stop index.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The index of the first occurrence of the value in the array, or -1 if not found.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  index = redis.json.arrindex("key", "$.path.to.array", "a")
  ```
</RequestExample>


# JSON.ARRINSERT
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrinsert

Insert the json values into the array at path before the index (shifts to the right).

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the array.
</ParamField>

<ParamField body="index" type="int" required>
  The index where to insert the values.
</ParamField>

<ParamField body="values" type="...TValue[]" required>
  One or more values to append to the array.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the array after the insertion.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  length = redis.json.arrinsert("key", "$.path.to.array", 2, "a", "b")
  ```
</RequestExample>


# JSON.ARRLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrlen

Report the length of the JSON array at `path` in `key`.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the array.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the array.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  length = redis.json.arrlen("key", "$.path.to.array")
  ```
</RequestExample>


# JSON.ARRPOP
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrpop

Remove and return an element from the index in the array. By default the last element from an array is popped.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the array.
</ParamField>

<ParamField body="index" type="int" default={-1}>
  The index of the element to pop.
</ParamField>

## Response

<ResponseField type="List[TValue | null]" required>
  The popped element or null if the array is empty.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  element = redis.json.arrpop("key", "$.path.to.array")
  ```

  ```py First theme={"system"}
  firstElement = redis.json.arrpop("key", "$.path.to.array", 0)
  ```
</RequestExample>


# JSON.ARRTRIM
Source: https://upstash.com/docs/redis/sdks/py/commands/json/arrtrim

Trim an array so that it contains only the specified inclusive range of elements.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the array.
</ParamField>

<ParamField body="start" type="int" required>
  The start index of the range.
</ParamField>

<ParamField body="stop" type="int" required>
  The stop index of the range.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the array after the trimming.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  length = redis.json.arrtrim("key", "$.path.to.array", 2, 10)
  ```
</RequestExample>


# JSON.CLEAR
Source: https://upstash.com/docs/redis/sdks/py/commands/json/clear

Clear container values (arrays/objects) and set numeric values to 0.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path to clear
</ParamField>

## Response

<ResponseField type="List[int]" required>
  How many keys cleared from the objects.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.clear("key")
  ```

  ```py With path theme={"system"}
  redis.json.clear("key", "$.my.key")
  ```
</RequestExample>


# JSON.DEL
Source: https://upstash.com/docs/redis/sdks/py/commands/json/del

Delete a key from a JSON document.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path to delete
</ParamField>

## Response

<ResponseField type="int" required>
  How many paths were deleted.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.del("key", "$.path.to.value")
  ```
</RequestExample>


# JSON.FORGET
Source: https://upstash.com/docs/redis/sdks/py/commands/json/forget

Delete a key from a JSON document.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path to forget.
</ParamField>

## Response

<ResponseField type="int" required>
  How many paths were deleted.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.forget("key", "$.path.to.value")
  ```
</RequestExample>


# JSON.GET
Source: https://upstash.com/docs/redis/sdks/py/commands/json/get

Get a single value from a JSON document.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="paths" type="*List[str]" default="$">
  One or more paths to retrieve from the JSON document.
</ParamField>

## Response

<ResponseField type="List[TValue | null]" required>
  The value at the specified path or `null` if the path does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  value = redis.json.get("key", "$.path.to.somewhere")
  ```
</RequestExample>


# JSON.MERGE
Source: https://upstash.com/docs/redis/sdks/py/commands/json/merge

Merges the JSON value at path in key with the provided value.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the value to set.
</ParamField>

<ParamField body="value" type="TValue" required>
  The value to merge with.
</ParamField>

## Response

<ResponseField type="true" required>
  Returns true if the merge was successful.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.merge("key", "$.path.to.value", {"new": "value"})
  ```
</RequestExample>


# JSON.MGET
Source: https://upstash.com/docs/redis/sdks/py/commands/json/mget

Get the same path from multiple JSON documents.

## Arguments

<ParamField body="keys" type="List[str]" required>
  One or more keys of JSON documents.
</ParamField>

<ParamField body="path" type="str" required>
  The path to get from the JSON document.
</ParamField>

## Response

<ResponseField type="List[List[TValue]]" required>
  The values at the specified path or `null` if the path does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  values = redis.json.mget(["key1", "key2"],  "$.path.to.somewhere")
  ```
</RequestExample>


# JSON.MSET
Source: https://upstash.com/docs/redis/sdks/py/commands/json/mset

Sets multiple JSON values at multiple paths in multiple keys.

## Arguments

<ParamField body="key_path_value_tuples" type="List[Tuple[string, string, TValue]]" required>
  A list of tuples where each tuple contains a key, a path, and a value.
</ParamField>

## Response

<ResponseField type="true" required>
  Returns true if the operation was successful.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.mset([(key, "$.path", value), (key2, "$.path2", value2)])
  ```
</RequestExample>


# JSON.NUMINCRBY
Source: https://upstash.com/docs/redis/sdks/py/commands/json/numincrby

Increment the number value stored at `path` by number.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the number.
</ParamField>

<ParamField body="increment" type="number" required>
  The number to increment by.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The new value after incrementing
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  newValue = redis.json.numincrby("key", "$.path.to.value", 2)
  ```
</RequestExample>


# JSON.NUMMULTBY
Source: https://upstash.com/docs/redis/sdks/py/commands/json/nummultby

Multiply the number value stored at `path` by number.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the number.
</ParamField>

<ParamField body="multiply" type="number" required>
  The number to multiply by.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The new value after multiplying
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  newValue = redis.json.nummultby("key", "$.path.to.value", 2)
  ```
</RequestExample>


# JSON.OBJKEYS
Source: https://upstash.com/docs/redis/sdks/py/commands/json/objkeys

Return the keys in the object that`s referenced by path.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the object.
</ParamField>

## Response

<ResponseField type="List[List[str]]" required>
  The keys of the object at the path.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  keys = redis.json.objkeys("key", "$.path")
  ```
</RequestExample>


# JSON.OBJLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/json/objlen

Report the number of keys in the JSON object at `path` in `key`.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the object.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The number of keys in the objects.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  lengths = redis.json.objlen("key", "$.path")
  ```
</RequestExample>


# JSON.RESP
Source: https://upstash.com/docs/redis/sdks/py/commands/json/resp

Return the value at the path in Redis serialization protocol format.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the object.
</ParamField>

## Response

<ResponseField type="TValue" required>
  Return the value at the path in Redis serialization protocol format.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  resp = redis.json.resp("key", "$.path")
  ```
</RequestExample>


# JSON.SET
Source: https://upstash.com/docs/redis/sdks/py/commands/json/set

Set the JSON value at path in key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the value to set.
</ParamField>

<ParamField body="value" type="TValue" required>
  The value to set.
</ParamField>

<ParamField body="nx" type="boolean" default="None">
  Sets the value at path only if it does not exist.
</ParamField>

<ParamField body="xx" type="boolean" default="None">
  Sets the value at path only if it does exist.
</ParamField>

## Response

<ResponseField type="true" required>
  Returns true if the value was set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.set(key, "$.path", value)
  ```

  ```py NX theme={"system"}
  value = ...
  redis.json.set(key, "$.path", value, nx=true)
  ```

  ```py XX theme={"system"}
  value = ...
  redis.json.set(key, "$.path", value, xx=true)
  ```
</RequestExample>


# JSON.STRAPPEND
Source: https://upstash.com/docs/redis/sdks/py/commands/json/strappend

Append the json-string values to the string at path.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the string.
</ParamField>

<ParamField body="value" type="str" required>
  The value to append to the existing string.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the string after the appending.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.strappend("key", "$.path.to.str", "abc")
  ```
</RequestExample>


# JSON.STRLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/json/strlen

Report the length of the JSON String at path in key

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the string.
</ParamField>

## Response

<ResponseField type="List[int]" required>
  The length of the string at the path.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.json.strlen("key", "$.path.to.str")
  ```
</RequestExample>


# JSON.TOGGLE
Source: https://upstash.com/docs/redis/sdks/py/commands/json/toggle

Toggle a boolean value stored at `path`.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the boolean.
</ParamField>

## Response

<ResponseField type="List[boolean]" required>
  The new value of the boolean.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  bool = redis.json.toggle("key", "$.path.to.bool")
  ```
</RequestExample>


# JSON.TYPE
Source: https://upstash.com/docs/redis/sdks/py/commands/json/type

Report the type of JSON value at `path`.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" default="$">
  The path of the value.
</ParamField>

## Response

<ResponseField type="List[str | null]" required>
  The type of the value at `path` or `null` if the value does not exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  myType = redis.json.type("key", "$.path.to.value")
  ```
</RequestExample>


# LINDEX
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lindex

Returns the element at index index in the list stored at key.

The index is zero-based, so 0 means the first element, 1 the second element and so on. Negative indices can be used to designate elements starting at the tail of the list.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="index" type="int" required>
  The index of the element to return, zero-based.
</ParamField>

## Response

<ResponseField type="Optional[str]" required>
  The value of the element at index index in the list. If the index is out of range, `None` is returned.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.rpush("key", "a", "b", "c")

  assert redis.lindex("key", 0) == "a"
  ```
</RequestExample>


# LINSERT
Source: https://upstash.com/docs/redis/sdks/py/commands/list/linsert

Insert an element before or after another element in a list

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="direction" type="&#x22;BEFORE&#x22; | &#x22;AFTER&#x22;" required>
  Whether to insert the element before or after pivot.
</ParamField>

<ParamField body="pivot" type="Any" required>
  The element to insert before or after.
</ParamField>

<ParamField body="value" type="Any" required>
  The element to insert.
</ParamField>

## Response

<ResponseField type="int" required>
  The list length after insertion, `0` when the list doesn't exist or `-1` when pivot was not found.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.rpush("key", "a", "b", "c")
  redis.linsert("key", "before", "b", "x")
  ```
</RequestExample>


# LLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/list/llen

Returns the length of the list stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the list at key.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.rpush("key", "a", "b", "c")

  assert redis.llen("key") == 3
  ```
</RequestExample>


# LMOVE
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lmove

Move an element from one list to another.

## Arguments

<ParamField body="source" type="str" required>
  The key of the source list.
</ParamField>

<ParamField body="destination" type="str" required>
  The key of the destination list.
</ParamField>

<ParamField body="wherefrom" type="&#x22;left&#x22; | &#x22;right&#x22;" required>
  The side of the source list from which the element was popped.
</ParamField>

<ParamField body="whereto" type="&#x22;left&#x22; | &#x22;right&#x22;" required>
  The side of the destination list to which the element was pushed.
</ParamField>

## Response

<ResponseField type="str" required>
  The element that was moved.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.rpush("source", "one", "two", "three")
  redis.lpush("destination", "four", "five", "six")

  assert redis.lmove("source", "destination", "RIGHT", "LEFT") == "three"

  assert redis.lrange("source", 0, -1) == ["one", "two"]
  ```
</RequestExample>


# LPOP
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lpop

Remove and return the first element(s) of a list

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="int">
  How many elements to pop. If not specified, a single element is popped.
</ParamField>

## Response

<ResponseField type="str | List[str] None" required>
  The popped element(s). If `count` was specified, an array of elements is
  returned, otherwise a single element is returned. If the list is empty, `None`
  is returned.
</ResponseField>

<RequestExample>
  ```py Single  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.lpop("mylist") == "one"
  ```

  ```py Multiple theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.lpop("mylist", 2) == ["one", "two"]
  ```
</RequestExample>


# LPOS
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lpos

Returns the index of matching elements inside a list.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="element" type="unknown" required>
  The element to match.
</ParamField>

<ParamField body="rank" type="int">
  Which match to return. 1 to return the first match, 2 to return the second match, and so on.
  1 by default.
</ParamField>

<ParamField body="count" type="int">
  The maximum number of elements to match. If specified, an array of elements
  is returned instead of a single element.
</ParamField>

<ParamField body="maxlen" type="int">
  Limit the number of comparisons to perform.
</ParamField>

## Response

<ResponseField type="int | List[int]" required>
  The index of the matching element or an array of indexes if `count` is
  specified.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.rpush("key", "a", "b", "c"); 

  assert redis.lpos("key", "b") == 1
  ```

  ```py With Rank  theme={"system"}
  redis.rpush("key", "a", "b", "c", "b"); 

  assert redis.lpos("key", "b", rank=2) == 3
  ```

  ```py With Count theme={"system"}
  redis.rpush("key", "a", "b", "b")

  assert redis.lpos("key", "b", count=2) == [1, 2]
  ```
</RequestExample>


# LPUSH
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lpush

Push an element at the head of the list.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="*List[Any]" required>
  One or more elements to push at the head of the list.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the list after the push operation.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  assert redis.lpush("mylist", "one", "two", "three") == 3

  assert lrange("mylist", 0, -1) == ["three", "two", "one"]
  ```
</RequestExample>


# LPUSHX
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lpushx

Push an element at the head of the list only if the list exists.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="*List[str]" required>
  One or more elements to push at the head of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list after the push operation.

  `0` if the list did not exist and thus no element was pushed.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  # Initialize the list
  redis.lpush("mylist", "one")

  assert redis.lpushx("mylist", "two", "three") == 3

  assert lrange("mylist", 0, -1) == ["three", "two", "one"]

  # Non existing key
  assert redis.lpushx("non-existent-list", "one") == 0
  ```
</RequestExample>


# LRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lrange

Returns the specified elements of the list stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="start" type="int" required>
  The starting index of the range to return.

  Use negative numbers to specify offsets starting at the end of the list.
</ParamField>

<ParamField body="end" type="int" required>
  The ending index of the range to return.

  Use negative numbers to specify offsets starting at the end of the list.
</ParamField>

## Response

<ResponseField type="List[str]">
  The list of elements in the specified range.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.lrange("mylist", 0, 1) == ["one", "two"]

  assert redis.lrange("mylist", 0, -1) == ["one", "two", "three"]
  ```
</RequestExample>


# LREM
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lrem

Remove the first `count` occurrences of an element from a list.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="number" required>
  How many occurrences of the element to remove.
</ParamField>

<ParamField body="element" type="Any" required>
  The element to remove
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements removed.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.rpush("mylist", "one", "two", "three", "two", "one")

  assert redis.lrem("mylist", 2, "two") == 2

  assert redis.lrange("mylist", 0, -1) == ["one", "three", "one"]
  ```
</RequestExample>


# LSET
Source: https://upstash.com/docs/redis/sdks/py/commands/list/lset

Set a value at a specific index.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="index" type="number" required>
  At which index to set the value.
</ParamField>

<ParamField body="element" type="str" required>
  The value to set.
</ParamField>

## Response

<ResponseField type="bool" required>
  Returns `True` if the index was in range and the value was set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.lset("mylist", 1, "Hello") == True

  assert redis.lrange("mylist", 0, -1) == ["one", "Hello", "three"]

  assert redis.lset("mylist", 5, "Hello") == False

  assert redis.lrange("mylist", 0, -1) == ["one", "Hello", "three"]
  ```
</RequestExample>


# LTRIM
Source: https://upstash.com/docs/redis/sdks/py/commands/list/ltrim

Trim a list to the specified range

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="start" type="int" required>
  The index of the first element to keep.
</ParamField>

<ParamField body="stop" type="int" required>
  The index of the first element to keep.
</ParamField>

## Response

<ResponseField type="bool" required>
  Returns `True` if the list was trimmed, `False` otherwise.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.ltrim("mylist", 0, 1) == True

  assert redis.lrange("mylist", 0, -1) == ["one", "two"]
  ```
</RequestExample>


# RPOP
Source: https://upstash.com/docs/redis/sdks/py/commands/list/rpop

Remove and return the last element(s) of a list

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="int">
  How many elements to pop. If not specified, a single element is popped.
</ParamField>

## Response

<ResponseField type="TValue | TValue[] | null" required>
  The popped element(s). If `count` was specified, an array of elements is
  returned, otherwise a single element is returned. If the list is empty, `null`
  is returned.
</ResponseField>

<RequestExample>
  ```py Single  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.rpop("mylist") == "three"
  ```

  ```py Multiple  theme={"system"}
  redis.rpush("mylist", "one", "two", "three")

  assert redis.rpop("mylist", 2) == ["three", "two"]
  ```
</RequestExample>


# RPUSH
Source: https://upstash.com/docs/redis/sdks/py/commands/list/rpush

Push an element at the end of the list.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="*List[str]" required>
  One or more elements to push at the end of the list.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the list after the push operation.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  assert redis.rpush("mylist", "one", "two", "three") == 3

  assert lrange("mylist", 0, -1) == ["one", "two", "three"]
  ```
</RequestExample>


# RPUSHX
Source: https://upstash.com/docs/redis/sdks/py/commands/list/rpushx

Push an element at the end of the list only if the list exists.

## Arguments

<ParamField body="key" type="str" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="*List[str]" required>
  One or more elements to push at the end of the list.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the list after the push operation.

  `0` if the list did not exist and thus no element was pushed.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  assert redis.rpushx("mylist", "one", "two", "three") == 3

  assert lrange("mylist", 0, -1) == ["one", "two", "three"]

  # Non existing key
  assert redis.rpushx("non-existent-list", "one") == 0
  ```
</RequestExample>


# Overview
Source: https://upstash.com/docs/redis/sdks/py/commands/overview

Available Commands in upstash-redis

<AccordionGroup>
  <Accordion title="Auth">
    <CardGroup cols={3}>
      <Card title="ECHO" href="/redis/sdks/py/commands/auth/echo">
        Echo the given string.
      </Card>

      <Card title="PING" href="/redis/sdks/py/commands/auth/ping">
        Ping the server.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Bitmap">
    <CardGroup cols={3}>
      <Card title="BITCOUNT" href="/redis/sdks/py/commands/bitmap/bitcount">
        Count set bits in a string.
      </Card>

      <Card title="BITFIELD" href="/redis/sdks/py/commands/bitmap/bitfield">
        Perform bitwise operations between strings.
      </Card>

      <Card title="BITOP" href="/redis/sdks/py/commands/bitmap/bitop">
        Perform bitwise operations between strings.
      </Card>

      <Card title="BITPOS" href="/redis/sdks/py/commands/bitmap/bitpos">
        Find first bit set or clear in a string.
      </Card>

      <Card title="GETBIT" href="/redis/sdks/py/commands/bitmap/getbit">
        Returns the bit value at offset in the string value stored at key.
      </Card>

      <Card title="SETBIT" href="/redis/sdks/py/commands/bitmap/setbit">
        Sets or clears the bit at offset in the string value stored at key.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Generic">
    <CardGroup cols={3}>
      <Card title="DEL" href="/redis/sdks/py/commands/generic/del">
        Delete one or multiple keys.
      </Card>

      <Card title="EXISTS" href="/redis/sdks/py/commands/generic/exists">
        Determine if a key exists.
      </Card>

      <Card title="EXPIRE" href="/redis/sdks/py/commands/generic/expire">
        Set a key's time to live in seconds.
      </Card>

      <Card title="EXPIREAT" href="/redis/sdks/py/commands/generic/expireat">
        Set the expiration for a key as a UNIX timestamp.
      </Card>

      <Card title="KEYS" href="/redis/sdks/py/commands/generic/keys">
        Find all keys matching the given pattern.
      </Card>

      <Card title="PERSIST" href="/redis/sdks/py/commands/generic/persist">
        Remove the expiration from a key.
      </Card>

      <Card title="PEXPIRE" href="/redis/sdks/py/commands/generic/pexpire">
        Set a key's time to live in milliseconds.
      </Card>

      <Card title="PEXPIREAT" href="/redis/sdks/py/commands/generic/pexpireat">
        Set the expiration for a key as a UNIX timestamp specified in milliseconds.
      </Card>

      <Card title="PTTL" href="/redis/sdks/py/commands/generic/pttl">
        Get the time to live for a key in milliseconds.
      </Card>

      <Card title="RANDOMKEY" href="/redis/sdks/py/commands/generic/randomkey">
        Return a random key from the keyspace.
      </Card>

      <Card title="RENAME" href="/redis/sdks/py/commands/generic/rename">
        Rename a key.
      </Card>

      <Card title="RENAMENX" href="/redis/sdks/py/commands/generic/renamenx">
        Rename a key, only if the new key does not exist.
      </Card>

      <Card title="SCAN" href="/redis/sdks/py/commands/generic/scan">
        Incrementally iterate the keys space.
      </Card>

      <Card title="TOUCH" href="/redis/sdks/py/commands/generic/touch">
        Alters the last access time of a key(s). Returns the number of existing keys specified.
      </Card>

      <Card title="TTL" href="/redis/sdks/py/commands/generic/ttl">
        Get the time to live for a key.
      </Card>

      <Card title="TYPE" href="/redis/sdks/py/commands/generic/type">
        Determine the type stored at key.
      </Card>

      <Card title="UNLINK" href="/redis/sdks/py/commands/generic/unlink">
        Delete one or more keys.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Hash">
    <CardGroup cols={3}>
      <Card title="HDEL" href="/redis/sdks/py/commands/hash/hdel" />

      <Card title="HEXISTS" href="/redis/sdks/py/commands/hash/hexists" />

      <Card title="HEXPIRE" href="/redis/sdks/py/commands/hash/hexpire" />

      <Card title="HEXPIREAT" href="/redis/sdks/py/commands/hash/hexpireat" />

      <Card title="HEXPIRETIME" href="/redis/sdks/py/commands/hash/hexpiretime" />

      <Card title="HGET" href="/redis/sdks/py/commands/hash/hget" />

      <Card title="HGETALL" href="/redis/sdks/py/commands/hash/hgetall" />

      <Card title="HINCRBY" href="/redis/sdks/py/commands/hash/hincrby" />

      <Card title="HINCRBYFLOAT" href="/redis/sdks/py/commands/hash/hincrbyfloat" />

      <Card title="HKEYS" href="/redis/sdks/py/commands/hash/hkeys" />

      <Card title="HLEN" href="/redis/sdks/py/commands/hash/hlen" />

      <Card title="HMGET" href="/redis/sdks/py/commands/hash/hmget" />

      <Card title="HRANDFIELD" href="/redis/sdks/py/commands/hash/hrandfield" />

      <Card title="HPERSIST" href="/redis/sdks/py/commands/hash/hpersist" />

      <Card title="HPEXPIRE" href="/redis/sdks/py/commands/hash/hpexpire" />

      <Card title="HPEXPIREAT" href="/redis/sdks/py/commands/hash/hpexpireat" />

      <Card title="HPEXPIRETIME" href="/redis/sdks/py/commands/hash/hpexpiretime" />

      <Card title="HPTTL" href="/redis/sdks/py/commands/hash/hpttl" />

      <Card title="HSCAN" href="/redis/sdks/py/commands/hash/hscan" />

      <Card title="HSET" href="/redis/sdks/py/commands/hash/hset" />

      <Card title="HSET" href="/redis/sdks/py/commands/hash/hmset" />

      <Card title="HSETNX" href="/redis/sdks/py/commands/hash/hsetnx" />

      <Card title="HSTRLEN" href="/redis/sdks/py/commands/hash/hstrlen" />

      <Card title="HTTL" href="/redis/sdks/py/commands/hash/httl" />

      <Card title="HVALS" href="/redis/sdks/py/commands/hash/hvals" />
    </CardGroup>
  </Accordion>

  <Accordion title="List">
    <CardGroup cols={3}>
      <Card title="LINDEX" href="/redis/sdks/py/commands/list/lindex" />

      <Card title="LINSERT" href="/redis/sdks/py/commands/list/linsert" />

      <Card title="LLEN" href="/redis/sdks/py/commands/list/llen" />

      <Card title="LMOVE" href="/redis/sdks/py/commands/list/lmove" />

      <Card title="LPOP" href="/redis/sdks/py/commands/list/lpop" />

      <Card title="LPOS" href="/redis/sdks/py/commands/list/lpos" />

      <Card title="LPUSH" href="/redis/sdks/py/commands/list/lpush" />

      <Card title="LPUSHX" href="/redis/sdks/py/commands/list/lpushx" />

      <Card title="LRANGE" href="/redis/sdks/py/commands/list/lrange" />

      <Card title="LREM" href="/redis/sdks/py/commands/list/lrem" />

      <Card title="LSET" href="/redis/sdks/py/commands/list/lset" />

      <Card title="LTRIM" href="/redis/sdks/py/commands/list/ltrim" />

      <Card title="RPOP" href="/redis/sdks/py/commands/list/rpop" />

      <Card title="RPUSH" href="/redis/sdks/py/commands/list/rpush" />

      <Card title="RPUSHX" href="/redis/sdks/py/commands/list/rpushx" />
    </CardGroup>
  </Accordion>

  <Accordion title="PubSub">
    <CardGroup cols={3}>
      <Card title="PUBLISH" href="/redis/sdks/py/commands/pubsub/publish">
        Publish messages to many clients
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Scripts">
    <CardGroup cols={3}>
      <Card title="EVAL" href="/redis/sdks/py/commands/scripts/eval" />

      <Card title="EVAL_RO" href="/redis/sdks/py/commands/scripts/eval_ro" />

      <Card title="EVALSHA" href="/redis/sdks/py/commands/scripts/evalsha" />

      <Card title="EVALSHA_RO" href="/redis/sdks/py/commands/scripts/evalsha_ro" />

      <Card title="SCRIPT EXISTS" href="/redis/sdks/py/commands/scripts/script_exists" />

      <Card title="SCRIPT FLUSH" href="/redis/sdks/py/commands/scripts/script_flush" />

      <Card title="SCRIPT LOAD" href="/redis/sdks/py/commands/scripts/script_load" />
    </CardGroup>
  </Accordion>

  <Accordion title="Server">
    <CardGroup cols={3}>
      <Card title="DBSIZE" href="/redis/sdks/py/commands/server/dbsize" />

      <Card title="FLUSHALL" href="/redis/sdks/py/commands/server/flushall" />

      <Card title="FLUSHDB" href="/redis/sdks/py/commands/server/flushdb" />
    </CardGroup>
  </Accordion>

  <Accordion title="Set">
    <CardGroup cols={3}>
      <Card title="SADD" href="/redis/sdks/py/commands/set/sadd" />

      <Card title="SCARD" href="/redis/sdks/py/commands/set/scard" />

      <Card title="SDIFF" href="/redis/sdks/py/commands/set/sdiff" />

      <Card title="SDIFFSTORE" href="/redis/sdks/py/commands/set/sdiffstore" />

      <Card title="SINTER" href="/redis/sdks/py/commands/set/sinter" />

      <Card title="SINTERSTORE" href="/redis/sdks/py/commands/set/sinterstore" />

      <Card title="SISMEMBER" href="/redis/sdks/py/commands/set/sismember" />

      <Card title="SMEMBERS" href="/redis/sdks/py/commands/set/smembers" />

      <Card title="SMISMEMBER" href="/redis/sdks/py/commands/set/smismember" />

      <Card title="SMOVE" href="/redis/sdks/py/commands/set/smove" />

      <Card title="SPOP" href="/redis/sdks/py/commands/set/spop" />

      <Card title="SRANDMEMBER" href="/redis/sdks/py/commands/set/srandmember" />

      <Card title="SREM" href="/redis/sdks/py/commands/set/srem" />

      <Card title="SSCAN" href="/redis/sdks/py/commands/set/sscan" />

      <Card title="SUNION" href="/redis/sdks/py/commands/set/sunion" />

      <Card title="SUNIONSTORE" href="/redis/sdks/py/commands/set/sunionstore" />
    </CardGroup>
  </Accordion>

  <Accordion title="Sorted Set">
    <CardGroup cols={3}>
      <Card title="ZADD" href="/redis/sdks/py/commands/zset/zadd" />

      <Card title="ZCARD" href="/redis/sdks/py/commands/zset/zcard" />

      <Card title="ZCOUNT" href="/redis/sdks/py/commands/zset/zcount" />

      <Card title="ZDIFF" href="/redis/sdks/py/commands/zset/zdiff" />

      <Card title="ZDIFFSTORE" href="/redis/sdks/py/commands/zset/zdiffstore" />

      <Card title="ZINCRBY" href="/redis/sdks/py/commands/zset/zincrby" />

      <Card title="ZINTER" href="/redis/sdks/py/commands/zset/zinter" />

      <Card title="ZINTERSTORE" href="/redis/sdks/py/commands/zset/zinterstore" />

      <Card title="ZLEXCOUNT" href="/redis/sdks/py/commands/zset/zlexcount" />

      <Card title="ZMSCORE" href="/redis/sdks/py/commands/zset/zmscore" />

      <Card title="ZPOPMAX" href="/redis/sdks/py/commands/zset/zpopmax" />

      <Card title="ZPOPMIN" href="/redis/sdks/py/commands/zset/zpopmin" />

      <Card title="ZRANDMEMBER" href="/redis/sdks/py/commands/zset/zrandmember" />

      <Card title="ZRANGE" href="/redis/sdks/py/commands/zset/zrange" />

      <Card title="ZRANK" href="/redis/sdks/py/commands/zset/zrank" />

      <Card title="ZREM" href="/redis/sdks/py/commands/zset/zrem" />

      <Card title="ZREMRANGEBYLEX" href="/redis/sdks/py/commands/zset/zremrangebylex" />

      <Card title="ZREMRANGEBYRANK" href="/redis/sdks/py/commands/zset/zremrangebyrank" />

      <Card title="ZREMRANGEBYSCORE" href="/redis/sdks/py/commands/zset/zremrangebyscore" />

      <Card title="ZREVRANK" href="/redis/sdks/py/commands/zset/zrevrank" />

      <Card title="ZSCAN" href="/redis/sdks/py/commands/zset/zscan" />

      <Card title="ZSCORE" href="/redis/sdks/py/commands/zset/zscore" />

      <Card title="ZUNION" href="/redis/sdks/py/commands/zset/zunion" />

      <Card title="ZUNIONSTORE" href="/redis/sdks/py/commands/zset/zunionstore" />
    </CardGroup>
  </Accordion>

  <Accordion title="String">
    <CardGroup cols={3}>
      <Card title="APPEND" href="/redis/sdks/py/commands/string/append">
        Append a value to a string stored at key.
      </Card>

      <Card title="DECR" href="/redis/sdks/py/commands/string/decr">
        Decrement the integer value of a key by one.
      </Card>

      <Card title="DECRBY" href="/redis/sdks/py/commands/string/decrby">
        Decrement the integer value of a key by the given number.
      </Card>

      <Card title="GET" href="/redis/sdks/py/commands/string/get">
        Get the value of a key.
      </Card>

      <Card title="GETDEL" href="/redis/sdks/py/commands/string/getdel">
        Get the value of a key and delete the key.
      </Card>

      <Card title="GETRANGE" href="/redis/sdks/py/commands/string/getrange">
        Get a substring of the string stored at a key.
      </Card>

      <Card title="GETSET" href="/redis/sdks/py/commands/string/getset">
        Set the string value of a key and return its old value.
      </Card>

      <Card title="INCR" href="/redis/sdks/py/commands/string/incr">
        Increment the integer value of a key by one.
      </Card>

      <Card title="INCRBY" href="/redis/sdks/py/commands/string/incrby">
        Increment the integer value of a key by the given amount.
      </Card>

      <Card title="INCRBYFLOAT" href="/redis/sdks/py/commands/string/incrbyfloat">
        Increment the float value of a key by the given amount.
      </Card>

      <Card title="MGET" href="/redis/sdks/py/commands/string/mget">
        Get the values of all the given keys.
      </Card>

      <Card title="MSET" href="/redis/sdks/py/commands/string/mset">
        Set multiple keys to multiple values.
      </Card>

      <Card title="MSETNX" href="/redis/sdks/py/commands/string/msetnx">
        Set multiple keys to multiple values, only if none of the keys exist.
      </Card>

      <Card title="SET" href="/redis/sdks/py/commands/string/set">
        Set the string value of a key.
      </Card>

      <Card title="SETRANGE" href="/redis/sdks/py/commands/string/setrange">
        Overwrite part of a string at key starting at the specified offset.
      </Card>

      <Card title="STRLEN" href="/redis/sdks/py/commands/string/strlen">
        Get the length of the value stored in a key.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Stream">
    <CardGroup cols={3}>
      <Card title="XACK" href="/redis/sdks/py/commands/stream/xack">
        Acknowledge one or multiple messages as processed for a consumer group.
      </Card>

      <Card title="XADD" href="/redis/sdks/py/commands/stream/xadd">
        Append a new entry to a stream.
      </Card>

      <Card title="XAUTOCLAIM" href="/redis/sdks/py/commands/stream/xautoclaim">
        Transfer ownership of pending messages to another consumer automatically.
      </Card>

      <Card title="XCLAIM" href="/redis/sdks/py/commands/stream/xclaim">
        Transfer ownership of pending messages to another consumer.
      </Card>

      <Card title="XDEL" href="/redis/sdks/py/commands/stream/xdel">
        Remove one or multiple entries from a stream.
      </Card>

      <Card title="XGROUP CREATE" href="/redis/sdks/py/commands/stream/xgroup_create">
        Create a new consumer group for a stream.
      </Card>

      <Card title="XGROUP CREATECONSUMER" href="/redis/sdks/py/commands/stream/xgroup_createconsumer">
        Create a new consumer in a consumer group.
      </Card>

      <Card title="XGROUP DELCONSUMER" href="/redis/sdks/py/commands/stream/xgroup_delconsumer">
        Delete a consumer from a consumer group.
      </Card>

      <Card title="XGROUP DESTROY" href="/redis/sdks/py/commands/stream/xgroup_destroy">
        Delete an entire consumer group.
      </Card>

      <Card title="XGROUP SETID" href="/redis/sdks/py/commands/stream/xgroup_setid">
        Set the last delivered ID for a consumer group.
      </Card>

      <Card title="XINFO CONSUMERS" href="/redis/sdks/py/commands/stream/xinfo_consumers">
        List all consumers in a consumer group.
      </Card>

      <Card title="XINFO GROUPS" href="/redis/sdks/py/commands/stream/xinfo_groups">
        List all consumer groups for a stream.
      </Card>

      <Card title="XLEN" href="/redis/sdks/py/commands/stream/xlen">
        Get the number of entries in a stream.
      </Card>

      <Card title="XPENDING" href="/redis/sdks/py/commands/stream/xpending">
        Get information about pending messages in a consumer group.
      </Card>

      <Card title="XRANGE" href="/redis/sdks/py/commands/stream/xrange">
        Get entries from a stream within a range of IDs.
      </Card>

      <Card title="XREAD" href="/redis/sdks/py/commands/stream/xread">
        Read data from one or multiple streams.
      </Card>

      <Card title="XREADGROUP" href="/redis/sdks/py/commands/stream/xreadgroup">
        Read data from streams as part of a consumer group.
      </Card>

      <Card title="XREVRANGE" href="/redis/sdks/py/commands/stream/xrevrange">
        Get entries from a stream within a range of IDs in reverse order.
      </Card>

      <Card title="XTRIM" href="/redis/sdks/py/commands/stream/xtrim">
        Trim a stream to a specified size.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Transactions">
    <Card title="TRANSACTION" href="/redis/sdks/py/features#pipelines-and-transactions">
      Run multiple commands in a transaction.
    </Card>
  </Accordion>
</AccordionGroup>


# PUBLISH
Source: https://upstash.com/docs/redis/sdks/py/commands/pubsub/publish

Publish a message to a channel

## Arguments

<ParamField body="channel" type="str" required>
  The channel to publish to.
</ParamField>

<ParamField body="message" type="str">
  The message to publish.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of clients who received the message.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  listeners = redis.publish("my-topic", "my-message")
  ```
</RequestExample>


# EVAL
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/eval

Evaluate a Lua script server side.

## Arguments

<ParamField body="script" type="str" required>
  The lua script to run.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="Any" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  script = """
  local value = redis.call("GET", KEYS[1])
  return value
  """

  redis.set("mykey", "Hello")

  assert redis.eval(script, keys=["mykey"]) == "Hello"
  ```

  ```py Accepting arguments theme={"system"}
  assert redis.eval("return ARGV[1]", args=["Hello"]) == "Hello"
  ```
</RequestExample>


# EVAL_RO
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/eval_ro

Evaluate a read-only Lua script server side.

## Arguments

<ParamField body="script" type="str" required>
  The read-only lua script to run.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="Any" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  script = """
  local value = redis.call("GET", KEYS[1])
  return value
  """

  redis.set("mykey", "Hello")

  assert redis.eval_ro(script, keys=["mykey"]) == "Hello"
  ```

  ```py Accepting arguments theme={"system"}
  assert redis.eval_ro("return ARGV[1]", args=["Hello"]) == "Hello"
  ```
</RequestExample>


# EVALSHA
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/evalsha

Evaluate a cached Lua script server side.

`EVALSHA` is like `EVAL` but instead of sending the script over the wire every time, you reference the script by its SHA1 hash. This is useful for caching scripts on the server side.

## Arguments

<ParamField body="sha" type="str" required>
  The sha1 hash of the script.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="List[str]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="?" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  result = redis.evalsha("fb67a0c03b48ddbf8b4c9b011e779563bdbc28cb", args=["hello"])
  assert result = "hello"
  ```
</RequestExample>


# EVALSHA_RO
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/evalsha_ro

Evaluate a cached read-only Lua script server side.

`EVALSHA_RO` is like `EVAL_RO` but instead of sending the script over the wire every time, you reference the script by its SHA1 hash. This is useful for caching scripts on the server side.

## Arguments

<ParamField body="sha" type="str" required>
  The sha1 hash of the read-only script.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="List[str]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="?" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  result = redis.evalsha_ro("fb67a0c03b48ddbf8b4c9b011e779563bdbc28cb", args=["hello"])
  assert result = "hello"
  ```
</RequestExample>


# SCRIPT EXISTS
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/script_exists

Check if scripts exist in the script cache.

## Arguments

<ParamField body="hashes" type="List[str]" required>
  The sha1 of the scripts to check.
</ParamField>

## Response

<ResponseField type="List[bool]" required>
  A list of booleans indicating if the script exists in the script cache.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Script 1 exists
  # Script 0 does not
  await redis.scriptExists("<sha1>", "<sha2>") == [1, 0]
  ```
</RequestExample>


# SCRIPT FLUSH
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/script_flush

Removes all scripts from the script cache.

## Arguments

<ParamField body="flush_type" type="&#x22;ASYNC&#x22; | &#x22;SYNC&#x22;" required>
  Whether to perform the flush asynchronously or synchronously.
</ParamField>

<RequestExample>
  ```py Example theme={"system"}
  redis.script_flush(flush_type="ASYNC")
  ```
</RequestExample>


# SCRIPT LOAD
Source: https://upstash.com/docs/redis/sdks/py/commands/scripts/script_load

Load the specified Lua script into the script cache.

## Arguments

<ParamField body="script" type="str" required>
  The script to load.
</ParamField>

## Response

<ResponseField type="str" required>
  The sha1 of the script.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  sha1 = redis.script_load("return 1")

  assert redis.evalsha(sha1) == 1
  ```
</RequestExample>


# DBSIZE
Source: https://upstash.com/docs/redis/sdks/py/commands/server/dbsize

Count the number of keys in the database.

## Arguments

This command has no arguments

## Response

<ResponseField type="int" required>
  The number of keys in the database
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.dbsize()
  ```
</RequestExample>


# FLUSHALL
Source: https://upstash.com/docs/redis/sdks/py/commands/server/flushall



<Warning>
  Deletes all keys permanently. Use with caution!
</Warning>

## Arguments

<ParamField body="flush_type" type="&#x22;ASYNC&#x22; | &#x22;SYNC&#x22;">
  Whether to perform the operation asynchronously.
  Defaults to synchronous.
</ParamField>

<RequestExample>
  ```py Sync theme={"system"}
  redis.flushall()
  ```

  ```py Async theme={"system"}
  redis.flushall(flush_type="ASYNC")
  ```
</RequestExample>


# FLUSHDB
Source: https://upstash.com/docs/redis/sdks/py/commands/server/flushdb



<Warning>
  Deletes all keys permanently. Use with caution!
</Warning>

## Arguments

<ParamField body="flush_type" type="&#x22;ASYNC&#x22; | &#x22;SYNC&#x22;">
  Whether to perform the operation asynchronously.
  Defaults to synchronous.
</ParamField>

<RequestExample>
  ```py Sync theme={"system"}
  redis.flushall()
  ```

  ```py Async theme={"system"}
  redis.flushall(flush_type="ASYNC")
  ```
</RequestExample>


# SADD
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sadd

Adds one or more members to a set.

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

<ParamField body="members" type="...TValue[]" required>
  One or more members to add to the set.
</ParamField>

## Response

<ResponseField type="number" required>
  The number of elements that were added to the set, not including all the elements already present in the set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  assert redis.sadd("key", "a", "b", "c") == 3
  ```
</RequestExample>


# SCARD
Source: https://upstash.com/docs/redis/sdks/py/commands/set/scard

Return how many members are in a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

## Response

<ResponseField type="int" required>
  How many members are in the set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("key", "a", "b", "c"); 

  assert redis.scard("key") == 3
  ```
</RequestExample>


# SDIFF
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sdiff

Return the difference between sets

## Arguments

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the difference operation on.
</ParamField>

## Response

<ResponseField type="set[str]" required>
  The resulting set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set1", "a", "b", "c"); 
  redis.sadd("set2", "c", "d", "e"); 

  assert redis.sdiff("set1", "set2") == {"a", "b"}
  ```
</RequestExample>


# SDIFFSTORE
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sdiffstore

Write the difference between sets to a new set

## Arguments

<ParamField body="destination" type="str" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the difference operation on.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("key1", "a", "b", "c")

  redis.sadd("key2", "c", "d", "e")

  # Store the result in a new set
  assert redis.sdiffstore("res", "key1", "key2") == 2

  assert redis.smembers("set") == {"a", "b"}
  ```
</RequestExample>


# SINTER
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sinter

Return the intersection between sets

## Arguments

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the intersection operation on.
</ParamField>

## Response

<ResponseField type="set[str]" required>
  The resulting set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set1", "a", "b", "c"); 
  redis.sadd("set2", "c", "d", "e"); 

  assert redis.sinter("set1", "set2") == {"c"}
  ```
</RequestExample>


# SINTER
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sinterstore

Return the intersection between sets and store the resulting set in a key

## Arguments

<ParamField body="destination" type="str" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the intersection operation on.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set1", "a", "b", "c"); 

  redis.sadd("set2", "c", "d", "e"); 

  assert redis.sinter("destination", "set1", "set2") == 1
  ```
</RequestExample>


# SISMEMBER
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sismember

Check if a member exists in a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set to check.
</ParamField>

<ParamField body="member" type="str">
  The member to check for.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if the member exists in the set, `False` if not.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set", "a", "b", "c")

  assert redis.sismember("set", "a") == True
  ```
</RequestExample>


# SMEMBERS
Source: https://upstash.com/docs/redis/sdks/py/commands/set/smembers

Return all the members of a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

## Response

<ResponseField type="set[str]" required>
  The members of the set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set", "a", "b", "c"); 
  assert redis.smembers("set") == {"a", "b", "c"}
  ```
</RequestExample>


# SMISMEMBER
Source: https://upstash.com/docs/redis/sdks/py/commands/set/smismember

Check if multiple members exist in a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set to check.
</ParamField>

<ParamField body="members" type="TMember[]">
  The members to check
</ParamField>

## Response

<ResponseField type="List[bool]" required>
  An array of `True` and `False` values.
  `True` if the member exists in the set, `False` if not.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.smismember("myset", "one", "four") == [True, False]

  assert redis.smismember("myset", "four", "five") == [False, False]
  ```
</RequestExample>


# SMOVE
Source: https://upstash.com/docs/redis/sdks/py/commands/set/smove

Move a member from one set to another

## Arguments

<ParamField body="source" type="str" required>
  The key of the set to move the member from.
</ParamField>

<ParamField body="destination" type="str" required>
  The key of the set to move the member to.
</ParamField>

<ParamField body="member" type="str">
  The members to move
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if the member was moved, `False` if it was not.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("src", "one", "two", "three")

  redis.sadd("dest", "four")

  assert redis.smove("src", "dest", "three") == True

  assert redis.smembers("source") == {"one", "two"}

  assert redis.smembers("destination") == {"three", "four"}
  ```
</RequestExample>


# SPOP
Source: https://upstash.com/docs/redis/sdks/py/commands/set/spop

Removes and returns one or more random members from a set.

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

<ParamField body="count" type="int">
  How many members to remove and return.
</ParamField>

## Response

<ResponseField type="str | set[str]" required>
  The popped member.
  If `count` is specified, a set of members is returned.
</ResponseField>

<RequestExample>
  ```py Single theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.spop("myset") in {"one", "two", "three"}
  ```

  ```py With Count  theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.spop("myset", 2) in {"one", "two", "three"}
  ```
</RequestExample>


# SRANDMEMBER
Source: https://upstash.com/docs/redis/sdks/py/commands/set/srandmember

Returns one or more random members from a set.

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

<ParamField body="count" type="number" default={1}>
  How many members to return.
</ParamField>

## Response

<ResponseField type="TMember | TMember[]" required>
  The random member.
  If `count` is specified, an array of members is returned.
</ResponseField>

<RequestExample>
  ```py Single theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.srandmember("myset") in {"one", "two", "three"}
  ```

  ```py With Count  theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.srandmember("myset", 2) in {"one", "two", "three"}
  ```
</RequestExample>


# SREM
Source: https://upstash.com/docs/redis/sdks/py/commands/set/srem

Remove one or more members from a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set to remove the member from.
</ParamField>

<ParamField body="members" type="*List[str]">
  One or more members to remove from the set.
</ParamField>

## Response

<ResponseField type="int" required>
  How many members were removed
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("myset", "one", "two", "three")

  assert redis.srem("myset", "one", "four") == 1
  ```
</RequestExample>


# SSCAN
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sscan

Scan a set

## Arguments

<ParamField body="key" type="str" required>
  The key of the set.
</ParamField>

<ParamField body="cursor" type="number">
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="options" type="Object">
  <ParamField body="match" type="str">
    Glob-style pattern to filter by members.
  </ParamField>

  <ParamField body="count" type="number">
    Number of members to return per call.
  </ParamField>
</ParamField>

## Response

<ResponseField type="Tuple[number, TMember[]]" required>
  The new cursor and the members.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Get all members of a set.

  cursor = 0
  results = set()

  while True:
      cursor, keys = redis.sscan("myset", cursor, match="*")

      results.extend(keys)
      if cursor == 0:
          break
  ```
</RequestExample>


# SUNION
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sunion

Return the union between sets

## Arguments

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the union operation on.
</ParamField>

## Response

<ResponseField type="set[str]" required>
  The resulting set
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("key1", "a", "b", "c")

  redis.sadd("key2", "c", "d", "e")

  assert redis.sunion("key1", "key2") == {"a", "b", "c", "d", "e"}
  ```
</RequestExample>


# SUNIONSTORE
Source: https://upstash.com/docs/redis/sdks/py/commands/set/sunionstore

Return the union between sets and store the resulting set in a key

## Arguments

<ParamField body="destination" type="str" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="*List[str]" required>
  The keys of the sets to perform the union operation on.
</ParamField>

## Response

<ResponseField type="set[str]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```py Example  theme={"system"}
  redis.sadd("set1", "a", "b", "c"); 
  redis.sadd("set2", "c", "d", "e"); 
  redis.sunionstore("destination", "set1", "set2")
  ```
</RequestExample>


# XACK
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xack

Removes one or multiple messages from the pending entries list of a stream consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="ids" type="str" required>
  The ID(s) of the message(s) to acknowledge. Can be multiple IDs as separate arguments.
</ParamField>

## Response

<ResponseField type="int">
  The number of messages successfully acknowledged.
</ResponseField>

<RequestExample>
  ```py Single message theme={"system"}
  result = redis.xack("mystream", "mygroup", "1638360173533-0")
  ```

  ```py Multiple messages theme={"system"}
  result = redis.xack("mystream", "mygroup", "1638360173533-0", "1638360173533-1")
  ```
</RequestExample>


# XADD
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xadd

Appends one or more new entries to a stream.

## Arguments

<ParamField body="key" type="str" required>
  The key to of the stream.
</ParamField>

<ParamField body="id" type="str | *" required>
  The stream entry ID. If `*` is passed, a new ID will be generated
  automatically.
</ParamField>

<ParamField body="data" type="Dict[str, Any]" required>
  Key-value data to be appended to the stream.
</ParamField>

<ParamField body="maxlen" type="int">
  The maximum number of entries to keep in the stream. Mutually exclusive with `minid`.
</ParamField>

<ParamField body="approximate_trim" type="bool" default="True">
  Use approximate trimming (more efficient). When `True`, Redis may keep slightly more entries than specified. Defaults to `True`.
</ParamField>

<ParamField body="nomkstream" type="bool" default="False">
  Prevent creating the stream if it does not exist. Defaults to `False`.
</ParamField>

<ParamField body="minid" type="str">
  The minimum ID to keep. Entries with IDs lower than this will be removed. Mutually exclusive with `maxlen`.
</ParamField>

<ParamField body="limit" type="int">
  Limit how many entries will be trimmed at most (only valid with approximate trimming).
</ParamField>

## Response

<ResponseField type="str">The ID of the newly added entry.</ResponseField>

<RequestExample>
  ```py Basic Example theme={"system"}
  redis.xadd("mystream", "*", {"name": "John Doe", "age": 30})
  ```

  ```py With Custom ID theme={"system"}
  redis.xadd("mystream", "1634567890123-0", {"temperature": 25.5, "humidity": 60})
  ```

  ```py Approximate trim with maxlen theme={"system"}
  redis.xadd("mystream", "*", {"log_level": "error", "message": "Database connection failed"}, maxlen=100)
  ```
</RequestExample>


# XAUTOCLAIM
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xautoclaim

Changes the ownership of pending messages from one consumer to another in a stream consumer group automatically.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="str" required>
  The consumer name that will claim the messages.
</ParamField>

<ParamField body="min_idle_time" type="int" required>
  The minimum idle time in milliseconds for messages to be claimed.
</ParamField>

<ParamField body="start" type="str" required>
  The stream entry ID to start claiming from.
</ParamField>

<ParamField body="count" type="int">
  The maximum number of messages to claim.
</ParamField>

<ParamField body="justid" type="bool">
  Return only the message IDs instead of the full message data.
</ParamField>

## Response

<ResponseField type="Tuple[str, List[Any], List[str]]">
  Returns a list containing:

  * Next start ID for pagination
  * List of claimed messages. If `justid` option is used, returns only message IDs.
  * List of deleted message IDs
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Auto-claim messages that have been idle for more than 60 seconds
  result = redis.xautoclaim(
      "mystream",
      "mygroup", 
      "consumer1",
      60000,  # 60 seconds
      start="0-0"
  )
  ```

  ```py With count and justid theme={"system"}
  result = redis.xautoclaim(
      "mystream",
      "mygroup",
      "consumer1", 
      60000,
      start="0-0",
      count=5,
      justid=True
  )
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    "1638360173533-1",  # next start ID
    [["1638360173533-0", ["field1", "value1", "field2", "value2"]]],  # claimed messages
    []  # deleted message IDs
  ]
  ```
</ResponseExample>


# XCLAIM
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xclaim

Changes the ownership of pending messages from one consumer to another in a stream consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="str" required>
  The consumer name that will claim the messages.
</ParamField>

<ParamField body="min_idle_time" type="int" required>
  The minimum idle time in milliseconds for messages to be claimed.
</ParamField>

<ParamField body="ids" type="str" required>
  The ID(s) of the message(s) to claim. Can be multiple IDs as separate arguments.
</ParamField>

<ParamField body="justid" type="bool">
  Return only the message IDs instead of the full message data.
</ParamField>

## Response

<ResponseField type="Union[List[List[Any]], List[str]]">
  Returns a list of claimed messages. If `justid` option is used, returns only message IDs.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Claim messages that have been idle for more than 60 seconds
  result = redis.xclaim(
      "mystream",
      "mygroup",
      "consumer1",
      60000,  # 60 seconds
      "1638360173533-0", "1638360173533-1"
  )
  ```

  ```py With justid option theme={"system"}
  result = redis.xclaim(
      "mystream",
      "mygroup", 
      "consumer1",
      60000,
      "1638360173533-0",
      justid=True
  )
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["1638360173533-0", ["field1", "value1", "field2", "value2"]],
    ["1638360173533-1", ["field1", "value3", "field2", "value4"]]
  ]
  ```
</ResponseExample>


# XDEL
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xdel

Removes the specified entries from a stream, and returns the number of entries deleted.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="ids" type="str" required>
  The ID(s) of the message(s) to delete. Can be multiple IDs as separate arguments.
</ParamField>

## Response

<ResponseField type="int">
  The number of entries actually deleted from the stream.
</ResponseField>

<RequestExample>
  ```py Single message theme={"system"}
  result = redis.xdel("mystream", "1638360173533-0")
  ```

  ```py Multiple messages theme={"system"}
  result = redis.xdel("mystream", "1638360173533-0", "1638360173533-1", "1638360173533-2")
  ```
</RequestExample>


# XGROUP CREATE
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xgroup_create

Create a new consumer group for a Redis stream.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="id" type="str" default="$">
  The stream entry ID to start consuming from. Use '\$' to start from the end.
</ParamField>

<ParamField body="mkstream" type="bool">
  Create the stream if it doesn't exist.
</ParamField>

## Response

<ResponseField type="str">
  Returns "OK" if the consumer group was created successfully.
</ResponseField>

<RequestExample>
  ```py Start from end theme={"system"}
  result = redis.xgroup_create("mystream", "mygroup", "$")
  ```

  ```py Create stream if not exists theme={"system"}
  result = redis.xgroup_create("newstream", "mygroup", "$", mkstream=True)
  ```

  ```py Start from beginning theme={"system"}
  result = redis.xgroup_create("mystream", "mygroup2", "0-0")
  ```
</RequestExample>


# XGROUP CREATECONSUMER
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xgroup_createconsumer

Create a new consumer in an existing consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="str" required>
  The consumer name to create.
</ParamField>

## Response

<ResponseField type="int">
  Returns 1 if the consumer was created, 0 if it already existed.
</ResponseField>

<RequestExample>
  ```py Create new consumer theme={"system"}
  result = redis.xgroup_createconsumer("mystream", "mygroup", "consumer1")
  ```
</RequestExample>


# XGROUP DELCONSUMER
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xgroup_delconsumer

Delete a consumer from a consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="str" required>
  The consumer name to delete.
</ParamField>

## Response

<ResponseField type="int">
  Returns the number of pending messages the consumer had.
</ResponseField>

<RequestExample>
  ```py Delete existing consumer theme={"system"}
  result = redis.xgroup_delconsumer("mystream", "mygroup", "consumer1")
  ```
</RequestExample>


# XGROUP DESTROY
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xgroup_destroy

Delete an entire consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name to destroy.
</ParamField>

## Response

<ResponseField type="int">
  Returns 1 if the group was destroyed, 0 if it didn't exist.
</ResponseField>

<RequestExample>
  ```py Destroy existing group theme={"system"}
  result = redis.xgroup_destroy("mystream", "mygroup")
  ```
</RequestExample>


# XGROUP SETID
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xgroup_setid

Set the last delivered ID for a consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="id" type="str" required>
  The stream entry ID to set as the last delivered ID. Use '\$' for the last entry.
</ParamField>

<ParamField body="entries_read" type="int">
  Set the number of entries read by the group.
</ParamField>

## Response

<ResponseField type="bool">
  Returns "OK" if the ID was set successfully.
</ResponseField>

<RequestExample>
  ```py Set to beginning theme={"system"}
  result = redis.xgroup_setid("mystream", "mygroup", "0-0")
  ```

  ```py Set to end with entries count theme={"system"}
  result = redis.xgroup_setid("mystream", "mygroup", "$", entries_read=10)
  ```
</RequestExample>


# XINFO CONSUMERS
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xinfo_consumers

List all consumers in a consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

## Response

<ResponseField type="List[List[Any]]">
  Returns a list of consumer information. Each consumer is represented as a list of key-value pairs.
</ResponseField>

<RequestExample>
  ```py Get consumers info theme={"system"}
  result = redis.xinfo_consumers("mystream", "mygroup")
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["name", "consumer1", "pending", 0, "idle", 1000, "inactive", 1000],
    ["name", "consumer2", "pending", 2, "idle", 2000, "inactive", 2000]
  ]
  ```
</ResponseExample>


# XINFO GROUPS
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xinfo_groups

List all consumer groups for a stream.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

## Response

<ResponseField type="List[List[Any]]">
  Returns a list of consumer group information. Each group is represented as a list of key-value pairs.
</ResponseField>

<RequestExample>
  ```py Get groups info theme={"system"}
  result = redis.xinfo_groups("mystream")
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["name", "group1", "consumers", 2, "pending", 0, "last-delivered-id", "1638360173533-0"],
    ["name", "group2", "consumers", 0, "pending", 3, "last-delivered-id", "0-0"]
  ]
  ```
</ResponseExample>


# XLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xlen

Returns the number of entries inside a stream.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

## Response

<ResponseField type="int">
  The number of entries in the stream. Returns 0 if the stream does not exist.
</ResponseField>

<RequestExample>
  ```py Get stream length theme={"system"}
  result = redis.xlen("mystream")
  ```
</RequestExample>


# XPENDING
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xpending

Returns information about pending messages in a stream consumer group.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="start" type="str">
  The minimum pending ID to return (use with end and count).
</ParamField>

<ParamField body="end" type="str">
  The maximum pending ID to return (use with start and count).
</ParamField>

<ParamField body="count" type="int">
  The maximum number of pending messages to return.
</ParamField>

<ParamField body="consumer" type="str">
  Filter results by a specific consumer.
</ParamField>

<ParamField body="idle" type="int">
  Filter by minimum idle time in milliseconds.
</ParamField>

## Response

<ResponseField type="Any">
  When called without range arguments, returns a summary with total count and range info.
  When called with range arguments, returns detailed pending message information.
</ResponseField>

<RequestExample>
  ```py Summary theme={"system"}
  result = redis.xpending("mystream", "mygroup")
  ```

  ```py Detailed with range theme={"system"}
  result = redis.xpending("mystream", "mygroup", start="-", end="+", count=10)
  ```

  ```py Specific consumer with idle filter theme={"system"}
  result = redis.xpending("mystream", "mygroup", start="-", end="+", count=5, consumer="consumer1", idle=10000)
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    2,  # total pending count
    "1638360173533-0",  # smallest pending ID
    "1638360173533-1",  # greatest pending ID
    [["consumer1", "2"]]  # consumers and their pending counts
  ]
  ```
</ResponseExample>


# XRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xrange

Returns stream entries matching a given range of IDs.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="start" type="str" default="-">
  The stream entry ID to start from. Use "-" for the first available ID.
</ParamField>

<ParamField body="end" type="str" default="+">
  The stream entry ID to end at. Use "+" for the last available ID.
</ParamField>

<ParamField body="count" type="int">
  The maximum number of entries to return.
</ParamField>

## Response

<ResponseField type="List[Tuple[str, List[str]]]">
  A list of stream entries, where each entry is a tuple containing the stream ID and its associated fields and values.
</ResponseField>

<RequestExample>
  ```py All entries theme={"system"}
  result = redis.xrange("mystream", "-", "+")
  ```

  ```py Range with specific IDs theme={"system"}
  result = redis.xrange("mystream", "1548149259438-0", "1548149259438-5")
  ```

  ```py Limited count theme={"system"}
  result = redis.xrange("mystream", "-", "+", count=10)
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  {
    "1548149259438-0": {
      "field1": "value1",
      "field2": "value2"
    },
    "1548149259438-1": {
      "field1": "value3",
      "field2": "value4"
    }
  }
  ```
</ResponseExample>


# XREAD
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xread

Reads data from one or multiple streams, starting from the specified IDs.

## Arguments

<ParamField body="streams" type="Dict[str, str]" required>
  A dictionary mapping stream keys to their starting IDs.
  Use "\$" to read only new messages added after the command is issued.
</ParamField>

<ParamField body="count" type="int">
  The maximum number of messages to return per stream.
</ParamField>

## Response

<ResponseField type="List[List[Any]]">
  Returns a list where each element represents a stream and contains:

  * The stream key
  * A list of messages (ID and field-value pairs)

  Returns empty list if no data is available.
</ResponseField>

<RequestExample>
  ```py Single stream theme={"system"}
  result = redis.xread({"mystream": "0-0"})
  ```

  ```py Multiple streams theme={"system"}
  result = redis.xread({"stream1": "0-0", "stream2": "0-0"})
  ```

  ```py With count limit theme={"system"}
  result = redis.xread({"mystream": "0-0"}, count=1)
  ```

  ```py Only new messages theme={"system"}
  result = redis.xread({"mystream": "$"})
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["mystream", [
      ["1638360173533-0", ["field1", "value1", "field2", "value2"]],
      ["1638360173533-1", ["field1", "value3", "field2", "value4"]]
    ]]
  ]
  ```
</ResponseExample>


# XREADGROUP
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xreadgroup

Reads data from a stream as part of a consumer group.

## Arguments

<ParamField body="group" type="str" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="str" required>
  The consumer name within the group.
</ParamField>

<ParamField body="streams" type="Dict[str, str]" required>
  A dictionary mapping stream keys to their starting IDs.
  Use ">" to read messages never delivered to any consumer in the group.
</ParamField>

<ParamField body="count" type="int">
  The maximum number of messages to return per stream.
</ParamField>

<ParamField body="noack" type="bool">
  Don't add messages to the pending entries list (messages won't need acknowledgment).
</ParamField>

## Response

<ResponseField type="List[List[Any]]">
  Returns a list where each element represents a stream and contains:

  * The stream key
  * A list of messages (ID and field-value pairs)

  Returns empty list if no data is available.
</ResponseField>

<RequestExample>
  ```py Read new messages theme={"system"}
  result = redis.xreadgroup("mygroup", "consumer1", {"mystream": ">"})
  ```

  ```py Multiple streams theme={"system"}
  result = redis.xreadgroup("mygroup", "consumer1", {"stream1": ">", "stream2": "0-0"})
  ```

  ```py With count and noack theme={"system"}
  result = redis.xreadgroup("mygroup", "consumer1", {"mystream": ">"}, count=5, noack=True)
  ```

  ```py Read pending messages theme={"system"}
  result = redis.xreadgroup("mygroup", "consumer1", {"mystream": "0"})
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["mystream", [
      ["1638360173533-0", ["field", "value1"]],
      ["1638360173533-1", ["field", "value2"]]
    ]]
  ]
  ```
</ResponseExample>


# XREVRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xrevrange

Returns stream entries matching a given range of IDs in reverse order.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="end" type="str" default="+">
  The stream entry ID to end at (highest ID).
</ParamField>

<ParamField body="start" type="str" default="-">
  The stream entry ID to start from (lowest ID).
</ParamField>

<ParamField body="count" type="int">
  The maximum number of entries to return.
</ParamField>

## Response

<ResponseField type="List[List[Any]]">
  Returns a list of stream entries in reverse chronological order. Each entry contains the ID and field-value pairs.
</ResponseField>

<RequestExample>
  ```py All entries (reverse order) theme={"system"}
  result = redis.xrevrange("mystream", "+", "-")
  ```

  ```py Limited count theme={"system"}
  result = redis.xrevrange("mystream", "+", "-", count=2)
  ```

  ```py Specific range theme={"system"}
  result = redis.xrevrange("mystream", end="1638360173533-2", start="1638360173533-0")
  ```
</RequestExample>

<ResponseExample>
  ```py  theme={"system"}
  [
    ["1638360173533-2", ["field1", "value5", "field2", "value6"]],
    ["1638360173533-1", ["field1", "value3", "field2", "value4"]],
    ["1638360173533-0", ["field1", "value1", "field2", "value2"]]
  ]
  ```
</ResponseExample>


# XTRIM
Source: https://upstash.com/docs/redis/sdks/py/commands/stream/xtrim

Trims the stream by removing entries to keep it at a reasonable size.

## Arguments

<ParamField body="key" type="str" required>
  The key of the stream.
</ParamField>

<ParamField body="maxlen" type="int">
  The maximum number of entries to keep in the stream. Mutually exclusive with `minid`.
</ParamField>

<ParamField body="approximate" type="bool" default="True">
  Use approximate trimming (more efficient). When `True`, Redis may keep slightly more entries than specified. Defaults to `True`.
</ParamField>

<ParamField body="minid" type="str">
  The minimum ID to keep. Entries with IDs lower than this will be removed. Mutually exclusive with `maxlen`.
</ParamField>

<ParamField body="limit" type="int">
  Limit how many entries will be trimmed at most.
</ParamField>

## Response

<ResponseField type="int">
  The number of entries removed from the stream.
</ResponseField>

<RequestExample>
  ```py Approximate trim (default) theme={"system"}
  result = redis.xtrim("mystream", maxlen=50)
  ```

  ```py Approximate trim (explicit) theme={"system"}
  result = redis.xtrim("mystream", maxlen=50, approximate=True)
  ```

  ```py Exact trim theme={"system"}
  result = redis.xtrim("mystream", maxlen=20, approximate=False)
  ```

  ```py Trim by minimum ID theme={"system"}
  result = redis.xtrim("mystream", minid="1638360173533-0")
  ```

  ```py Approximate trim with limit theme={"system"}
  result = redis.xtrim("mystream", maxlen=1000, approximate=True, limit=100)
  ```
</RequestExample>


# APPEND
Source: https://upstash.com/docs/redis/sdks/py/commands/string/append

Append a value to a string stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="value" required>
  The value to append.
</ParamField>

## Response

<ResponseField type="int" required>
  How many characters were added to the string.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "Hello")

  assert redis.append("key", " World") == 11

  assert redis.get("key") == "Hello World"
  ```
</RequestExample>


# DECR
Source: https://upstash.com/docs/redis/sdks/py/commands/string/decr

Decrement the integer value of a key by one

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="str" required>
  The key to decrement.
</ParamField>

## Response

<ResponseField type="int" required>
  The value at the key after the decrementing.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", 6)

  assert redis.decr("key") == 5
  ```
</RequestExample>


# DECRBY
Source: https://upstash.com/docs/redis/sdks/py/commands/string/decrby

Decrement the integer value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="str" required>
  The key to decrement.
</ParamField>

<ParamField body="decrement" type="int" required>
  The amount to decrement by.
</ParamField>

## Response

<ResponseField type="int" required>
  The value at the key after the decrementing.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", 6)

  assert redis.decrby("key", 4) == 2
  ```
</RequestExample>


# GET
Source: https://upstash.com/docs/redis/sdks/py/commands/string/get

Return the value of the specified key or `None` if the key doesn't exist.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `None` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "value")

  assert redis.get("key") == "value"
  ```
</RequestExample>


# GETDEL
Source: https://upstash.com/docs/redis/sdks/py/commands/string/getdel

Return the value of the specified key and delete the key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `None` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "value")

  assert redis.getdel("key") == "value"

  assert redis.get("key") == None
  ```
</RequestExample>


# GETRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/string/getrange

Return a substring of value at the specified key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="start" type="int" required>
  The start index of the substring.
</ParamField>

<ParamField body="end" type="int" required>
  The end index of the substring.
</ParamField>

## Response

<ResponseField type="str" required>
  The substring.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "Hello World")

  assert redis.getrange("key", 0, 4) == "Hello"
  ```
</RequestExample>


# GETSET
Source: https://upstash.com/docs/redis/sdks/py/commands/string/getset

Return the value of the specified key and replace it with a new value.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="value" type="Any" required>
  The new value to store.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `None` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "old-value")

  assert redis.getset("key", "newvalue") == "old-value"
  ```
</RequestExample>


# INCR
Source: https://upstash.com/docs/redis/sdks/py/commands/string/incr

Increment the integer value of a key by one

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="str" required>
  The key to increment.
</ParamField>

## Response

<ResponseField type="int" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", 6)

  assert redis.incr("key") == 7
  ```
</RequestExample>


# INCRBY
Source: https://upstash.com/docs/redis/sdks/py/commands/string/incrby

Increment the integer value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="str" required>
  The key to decrement.
</ParamField>

<ParamField body="increment" type="int" required>
  The amount to increment by.
</ParamField>

## Response

<ResponseField type="int" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", 6)

  assert redis.incrby("key", 4) == 10
  ```
</RequestExample>


# INCRBYFLOAT
Source: https://upstash.com/docs/redis/sdks/py/commands/string/incrbyfloat

Increment the float value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="str" required>
  The key to decrement.
</ParamField>

<ParamField body="increment" type="float" required>
  The amount to increment by.
</ParamField>

## Response

<ResponseField type="float" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", 6)

  # returns 10.5
  redis.incrbyfloat("key", 4,5)
  ```
</RequestExample>


# MGET
Source: https://upstash.com/docs/redis/sdks/py/commands/string/mget

Load multiple keys from Redis in one go.

For billing purposes, this counts as a single command.

## Arguments

<ParamField body="keys" type="*List[str]" required>
  Multiple keys to load from Redis.
</ParamField>

## Response

<ResponseField type="List[str]" required>
  An array of values corresponding to the keys passed in. If a key doesn't exist, the value will be `None`.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key1", "value1")

  redis.set("key2", "value2")

  assert redis.mget("key1", "key2") == ["value1", "value2"]
  ```
</RequestExample>


# MSET
Source: https://upstash.com/docs/redis/sdks/py/commands/string/mset

Set multiple keys in one go.

For billing purposes, this counts as a single command.

## Arguments

<ParamField type="Dict[str, Any]" required>
  An object where the keys are the keys to set, and the values are the values to set.
</ParamField>

## Response

<ResponseField type="bool" required>
  `True` if the operation succeeded.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.mset({
    "key1": "value1",
    "key2": "value2"
  })
  ```
</RequestExample>


# MSETNX
Source: https://upstash.com/docs/redis/sdks/py/commands/string/msetnx

Set multiple keys in one go unless they exist already.

For billing purposes, this counts as a single command.

## Arguments

<ParamField type="Record<str, TValue>" required>
  An object where the keys are the keys to set, and the values are the values to set.
</ParamField>

## Response

<ResponseField required>
  `1` if all keys were set, `0` if at least one key was not set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.msetnx({
      key1: 1,
      key2: "hello",
      key3: { a: 1, b: "hello" },
  })
  ```
</RequestExample>


# SET
Source: https://upstash.com/docs/redis/sdks/py/commands/string/set

Set a key to hold a string value.

## Arguments

<ParamField body="key" type="str" required>
  The key
</ParamField>

<ParamField body="value" type="TValue" required>
  The value, if this is not a string, we will use `JSON.stringify` to convert it
  to a string.
</ParamField>

<ParamField body="get" type="bool">
  Instead of returning `True`, this will cause the command to return the old
  value stored at key, or `None` when key did not exist.
</ParamField>

<ParamField body="ex" type="int">
  Sets an expiration (in seconds) to the key.
</ParamField>

<ParamField body="px" type="int">
  Sets an expiration (in milliseconds) to the key.
</ParamField>

<ParamField body="exat" type="int">
  Set the UNIX timestamp in seconds until the key expires.
</ParamField>

<ParamField body="pxat" type="int">
  Set the UNIX timestamp in milliseconds until the key expires.
</ParamField>

<ParamField body="keepttl" type="bool">
  Keeps the old expiration if the key already exists.
</ParamField>

<ParamField body="nx" type="bool">
  Only set the key if it does not already exist.
</ParamField>

<ParamField body="xx" type="bool">
  Only set the key if it already exists.
</ParamField>

## Response

<ResponseField required>
  `True` if the key was set.
  If `get` is specified, this will return the old value stored at key, or `None` when
  the key did not exist.
</ResponseField>

<RequestExample>
  ```py Basic theme={"system"}
  assert redis.set("key", "value") == True

  assert redis.get("key") == "value"
  ```

  ```py With nx and xx theme={"system"}
  # Only set the key if it does not already exist.
  assert redis.set("key", "value", nx=True) == False

  # Only set the key if it already exists.
  assert redis.set("key", "value", xx=True) == True
  ```

  ```py With expiration theme={"system"}
  # Set the key to expire in 10 seconds.
  assert redis.set("key", "value", ex=10) == True

  # Set the key to expire in 10000 milliseconds.
  assert redis.set("key", "value", px=10000) == True
  ```

  ```py With old value theme={"system"}
  # Get the old value stored at the key.
  assert redis.set("key", "new-value", get=True) == "old-value"
  ```
</RequestExample>


# SETRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/string/setrange

Writes the value of key at offset.

The SETRANGE command in Redis is used to modify a portion of the value of a key by replacing a substring within the key's existing value. It allows you to update part of the string value associated with a specific key at a specified offset.

## Arguments

<ParamField body="key" type="str" required>
  The name of the Redis key for which you want to modify the value.
</ParamField>

<ParamField body="offset" type="int" required>
  The zero-based index in the value where you want to start replacing characters.
</ParamField>

<ParamField body="value" type="str" required>
  The new string that you want to insert at the specified offset in the existing value.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the value after it was modified.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "Hello World")

  assert redis.setrange("key", 6, "Redis") == 11

  assert redis.get("key") == "Hello Redis"
  ```
</RequestExample>


# STRLEN
Source: https://upstash.com/docs/redis/sdks/py/commands/string/strlen

Return the length of a string stored at a key.

The \`STRLEN\`\` command in Redis is used to find the length of the string value associated with a key. In Redis, keys can be associated with various data types, and one of these data types is the "string." The STRLEN command specifically operates on keys that are associated with string values.

## Arguments

<ParamField body="key" type="str" required>
  The name of the Redis key.
</ParamField>

## Response

<ResponseField type="int" required>
  The length of the value.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.set("key", "Hello World")

  assert redis.strlen("key") == 11
  ```
</RequestExample>


# ZADD
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zadd

Add a member to a sorted set, or update its score if it already exists.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set.
</ParamField>

<ParamField body="scores" type="Dict[str, float]" required>
  A dictionary of elements and their scores.
</ParamField>

<ParamField body="xx" type="bool">
  Only update elements that already exist. Never add elements.
</ParamField>

<ParamField body="nx" type="bool">
  Only add new elements. Never update elements.
</ParamField>

<ParamField body="gt" type="bool">
  Update scores if the new score is greater than the old score.
</ParamField>

<ParamField body="lt" type="bool">
  Update scores if the new score is less than the old score.
</ParamField>

<ParamField body="ch" type="bool">
  Return the number of elements changed instead.
</ParamField>

<ParamField body="incr" type="bool">
  When this option is specified `ZADD` acts like `ZINCRBY`. Only one score-element pair can be specified in this mode.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements added to the sorted sets, not including elements already existing for which the score was updated.

  If `ch` was specified, the number of elements that were updated.

  If `incr` was specified, the new score of `member`.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  # Add three elements
  assert redis.zadd("myset", {
      "one": 1,
      "two": 2,
      "three": 3
  }) == 3

  # No element is added since "one" and "two" already exist
  assert redis.zadd("myset", {
      "one": 1,
      "two": 2
  }, nx=True) == 0

  # New element is not added since it does not exist
  assert redis.zadd("myset", {
      "new-element": 1
  }, xx=True) == 0

  # Only "three" is updated since new score was greater
  assert redis.zadd("myset", {
      "three": 10, "two": 0
  }, gt=True) == 1

  # Only "three" is updated since new score was greater
  assert redis.zadd("myset", {
      "three": 10,
      "two": 0
  }, gt=True) == 1
  ```
</RequestExample>


# ZCARD
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zcard

Returns the number of elements in the sorted set stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements in the sorted set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"one": 1, "two": 2, "three": 3})

  assert redis.zcard("myset") == 3
  ```
</RequestExample>


# ZCOUNT
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zcount

Returns the number of elements in the sorted set stored at key filterd by score.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="min" type="int | str" required>
  The minimum score to filter by.

  Use `-inf` to effectively ignore this filter.

  Use `(number` to exclude the value.
</ParamField>

<ParamField body="max" type="int | str" required>
  The maximum score to filter by.

  Use `+inf` to effectively ignore this filter.

  Use `(number` to exclude the value.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements where score is between min and max.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("key", 
      { score: 1, member: "one"}, 
      { score: 2, member: "two" },
  )
  elements = redis.zcount("key", "(1", "+inf")
  print(elements); # 1
  ```
</RequestExample>


# ZDIFF
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zdiff

Returns the difference between sets.

## Arguments

<ParamField body="keys" type="List[str]" required>
  The keys of the sets to compare.
</ParamField>

<ParamField body="withscores" type="bool" default="false">
  Whether to include scores in the result.
</ParamField>

## Response

<ResponseField type="List[str] | List[Tuple[str, float]]">
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zdiff(["key1", "key2"])

  assert result == ["a", "b"]
  ```

  ```py With scores theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zdiff(["key1", "key2"], withscores=True)

  assert result == [("a", 1), ("b", 2)]
  ```
</RequestExample>


# ZDIFFSTORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zdiffstore

Writes the difference between sets to a new key.

## Arguments

<ParamField body="destination" type="str" required>
  The key to write the difference to.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  The keys to compare.
</ParamField>

## Response

<ResponseField type="int">
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  # a and b
  assert redis.zdiffstore("dest", ["key1", "key2"]) == 2
  ```
</RequestExample>


# ZINCRBY
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zincrby

Increment the score of a member.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set.
</ParamField>

<ParamField body="increment" type="int" required>
  The increment to add to the score.
</ParamField>

<ParamField body="member" type="str" required>
  The member to increment.
</ParamField>

## Response

<ResponseField type="float" required>
  The new score of `member` after the increment operation.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"one": 1, "two": 2, "three": 3})

  assert redis.zincrby("myset", 2, "one") == 3
  ```
</RequestExample>


# ZINTER
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zinter

Returns the intersection between sets.

## Arguments

<ParamField body="keys" type="List[str]" required>
  The keys of the sets to compare.
</ParamField>

<ParamField body="weights" type="List[float]" default="None">
  The weights to apply to the sets.
</ParamField>

<ParamField body="aggregate" type="&#x22;SUM&#x22; | &#x22;MIN&#x22; | &#x22;MAX&#x22;" default="sum">
  The aggregation function to apply to the sets.
</ParamField>

<ParamField body="withscores" type="bool" default="false">
  Whether to include scores in the result.
</ParamField>

## Response

<ResponseField type="List[str] | List[Tuple[str, float]]">
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zinter(["key1", "key2"])

  assert result == ["c"]
  ```

  ```py Aggregation theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"a": 3, "b": 4, "c": 5})

  result = redis.zinter(["key1", "key2"], withscores=True, aggregate="SUM")

  assert result == [("a", 4), ("b", 6), ("c", 8)]
  ```

  ```py Weights theme={"system"}
  redis.zadd("key1", {"a": 1})

  redis.zadd("key2", {"a": 1})

  result = redis.zinter(["key1", "key2"],
                        withscores=True,
                        aggregate="SUM",
                        weights=[2, 3])

  assert result == [("a", 5)]
  ```
</RequestExample>


# ZINTERSTORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zinterstore

Calculates the intersection of sets and stores the result in a key

## Arguments

<ParamField body="destination" type="str" required>
  The key to store the result in.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  The keys of the sets to compare.
</ParamField>

<ParamField body="weights" type="List[float]" default="None">
  The weights to apply to the sets.
</ParamField>

<ParamField body="aggregate" type="&#x22;SUM&#x22; | &#x22;MIN&#x22; | &#x22;MAX&#x22;" default="sum">
  The aggregation function to apply to the sets.
</ParamField>

<ParamField body="withscores" type="bool" default="false">
  Whether to include scores in the result.
</ParamField>

## Response

## Response

<ResponseField required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zinterstore("dest", ["key1", "key2"])

  assert result == 1
  ```

  ```py Aggregation theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"a": 3, "b": 4, "c": 5})

  result = redis.zinterstore("dest", ["key1", "key2"], withscores=True, aggregate="SUM")

  assert result == 3
  ```

  ```py Weights theme={"system"}
  redis.zadd("key1", {"a": 1})

  redis.zadd("key2", {"a": 1})

  result = redis.zinterstore("dest", ["key1", "key2"],
                        withscores=True,
                        aggregate="SUM",
                        weights=[2, 3])

  assert result == 1
  ```
</RequestExample>


# ZLEXCOUNT
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zlexcount

Returns the number of elements in the sorted set stored at key filterd by lex.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="min" type="str" required>
  The lower lexicographical bound to filter by.

  Use `-` to disable the lower bound.
</ParamField>

<ParamField body="max" type="str" required>
  The upper lexicographical bound to filter by.

  Use `+` to disable the upper bound.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of matched.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zlexcount("myset", "-", "+") == 3
  ```
</RequestExample>


# ZMSCORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zmscore

Returns the scores of multiple members.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set.
</ParamField>

## Response

<ResponseField body="members" type="List[str]" required>
  The members of the sorted set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zlexcount("myset", "-", "+") == 3
  ```
</RequestExample>


# ZPOPMAX
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zpopmax

Removes and returns up to count members with the highest scores in the sorted set stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="count" type="int">
  The number of members to pop
</ParamField>

## Response

<ResponseField type="List[Tuple[str, float]]">
  A list of tuples containing the popped members and their scores
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zpopmax("myset") == [("c", 3)]
  ```
</RequestExample>


# ZPOPMIN
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zpopmin

Removes and returns up to count members with the lowest scores in the sorted set stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="count" type="int">
  The number of members to pop
</ParamField>

## Response

<ResponseField type="List[Tuple[str, float]]">
  A list of tuples containing the popped members and their scores
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zpopmin("myset") == [("a", 1)]
  ```
</RequestExample>


# ZRANDMEMBER
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zrandmember

Returns one or more random members from a sorted set, optionally with their scores.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="count" type="int">
  The number of members to return
</ParamField>

<ParamField body="withscores" type="bool">
  Whether to return the scores along with the members
</ParamField>

## Response

<ResponseField type="str | Tuple[str, float] | List[str] | List[Tuple[str, float]]">
  The random member(s) from the sorted set

  If no count is specified, a single member is returned. If count is specified, a list of members is returned.

  If withscores, members are returned as a tuple of (member, score).
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"one": 1, "two": 2, "three": 3})

  # "one"
  redis.zrandmember("myset")

  # ["one", "three"]
  redis.zrandmember("myset", 2)
  ```
</RequestExample>


# ZRANGE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zrange

Returns the specified range of elements in the sorted set stored at key.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="min" type="float | str" required>
  The minimum value to include.
</ParamField>

<ParamField body="max" type="float | str" required>
  The maximum value to include.
</ParamField>

"-inf" and "+inf" are also valid values for the ranges

<ParamField body="withscores" type="bool">
  Whether to include the scores in the response.
</ParamField>

<ParamField body="rev" type="bool">
  Whether to reverse the order of the response.
</ParamField>

<ParamField body="sortby" type="&#x22;BYSCORE&#x22; | &#x22;BYLEX&#x22;">
  If bylex
</ParamField>

<ParamField body="offset" type="int">
  The offset to start from.
</ParamField>

<ParamField body="count" type="int">
  The number of elements to return.
</ParamField>

## Response

<ResponseField type="List[str] | List[Tuple[str, float]]">
  The values in the specified range.

  If `withscores` is true, the members will be tuples of the form `(member, score)`.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrange("myset", 0, 1) == ["a", "b"]
  ```

  ```py Reverse theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrange("myset", 0, 1, rev=True) == ["c", "b"]

  ```

  ```py Sorted theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrange("myset", 0, 1, sortby="BYSCORE") == ["a", "b"]

  ```

  ```py With scores theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrange("myset", 0, 1, withscores=True) == [("a", 1), ("b", 2)]
  ```
</RequestExample>


# ZRANK
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zrank

Returns the rank of a member

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="member" type="TMember" required>
  The member to get the rank of.
</ParamField>

## Response

<ResponseField type="int" required>
  The rank of the member.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrank("myset", "a") == 0

  assert redis.zrank("myset", "d") == None

  assert redis.zrank("myset", "b") == 1

  assert redis.zrank("myset", "c") == 2
  ```
</RequestExample>


# ZREM
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zrem

Remove one or more members from a sorted set

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="members" type="*List[str]" required>
  One or more members to remove
</ParamField>

## Response

<ResponseField required>
  The number of members removed from the sorted set.
</ResponseField>

<RequestExample>
  ```py Single theme={"system"}
  redis.zadd("myset", {"one": 1, "two": 2, "three": 3})

  assert redis.zrem("myset", "one", "four") == 1
  ```
</RequestExample>


# ZREMRANGEBYLEX
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zremrangebylex

Remove all members in a sorted set between the given lexicographical range.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="str" required>
  The minimum lexicographical value to remove.
</ParamField>

<ParamField body="min" type="str" required>
  The maximum lexicographical value to remove.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zremrangebylex("key", "alpha", "omega")
  ```
</RequestExample>


# ZREMRANGEBYRANK
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zremrangebyrank

Remove all members in a sorted set between the given ranks.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="str | float" required>
  The minimum rank to remove.
</ParamField>

<ParamField body="min" type="str | float" required>
  The maximum rank to remove.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zremrangebyrank("key", 4, 20)
  ```
</RequestExample>


# ZREMRANGEBYSCORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zremrangebyscore

Remove all members in a sorted set between the given scores.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="str | float" required>
  The minimum score to remove.
</ParamField>

<ParamField body="min" type="str | float" required>
  The maximum score to remove.
</ParamField>

## Response

<ResponseField type="int" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zremrangebyscore("key", 2, 5)
  ```
</RequestExample>


# ZREVRANK
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zrevrank

Returns the rank of a member in a sorted set, with scores ordered from high to low.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

<ParamField body="member" type="str" required>
  The member to get the reverse rank of.
</ParamField>

## Response

<ResponseField type="int" required>
  The reverse rank of the member.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zrevrank("myset", "a") == 2
  ```
</RequestExample>


# ZSCAN
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zscan

Scan a sorted set

Return a paginated list of members and their scores of an ordered set matching a pattern.

## Arguments

<ParamField body="key" type="str" required>
  The key of the sorted set.
</ParamField>

<ParamField body="cursor" type="int" required>
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="match" type="str">
  Glob-style pattern to filter by members.
</ParamField>

<ParamField body="count" type="int">
  Number of members to return per call.
</ParamField>

## Response

<ResponseField type="Tuple[int, List[str]]" required>
  The new cursor and keys as a tuple.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  # Get all elements of an ordered set.

  cursor = 0
  results = []

  while True:
      cursor, keys = redis.zscan("myzset", cursor, match="*")

      results.extend(keys)
      if cursor == 0:
          break

  for key, score in results:
      print(key, score)
  ```
</RequestExample>


# ZSCORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zscore

Returns the scores of a member.

## Arguments

<ParamField body="key" type="str" required>
  The key to get.
</ParamField>

## Response

<ResponseField body="member" type="TMember" required>
  A member of the sortedset.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  redis.zadd("myset", {"a": 1, "b": 2, "c": 3})

  assert redis.zscore("myset", "a") == 1
  ```
</RequestExample>


# ZINTER
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zunion

Returns the intersection between sets.

## Arguments

<ParamField body="keys" type="List[str]" required>
  The keys of the sets to compare.
</ParamField>

<ParamField body="weights" type="List[float]" default="None">
  The weights to apply to the sets.
</ParamField>

<ParamField body="aggregate" type="&#x22;SUM&#x22; | &#x22;MIN&#x22; | &#x22;MAX&#x22;" default="sum">
  The aggregation function to apply to the sets.
</ParamField>

<ParamField body="withscores" type="bool" default="false">
  Whether to include scores in the result.
</ParamField>

## Response

<ResponseField type="List[str] | List[Tuple[str, float]]">
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zunion(["key1", "key2"])

  assert result == ["a", "b", "c", "d", "e"]
  ```

  ```py Aggregation theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"a": 3, "b": 4, "c": 5})

  result = redis.zunion(["key1", "key2"], withscores=True, aggregate="SUM")

  assert result == [("a", 4), ("b", 6), ("c", 8)]
  ```

  ```py Weights theme={"system"}
  redis.zadd("key1", {"a": 1})

  redis.zadd("key2", {"a": 1})

  result = redis.zunion(["key1", "key2"],
                        withscores=True,
                        aggregate="SUM",
                        weights=[2, 3])

  assert result == [("a", 5)]
  ```
</RequestExample>


# ZUNIONSTORE
Source: https://upstash.com/docs/redis/sdks/py/commands/zset/zunionstore

Writes the union between sets to a new key.

## Arguments

<ParamField body="destination" type="str" required>
  The key to store the resulting set in.
</ParamField>

<ParamField body="keys" type="List[str]" required>
  The keys of the sets to compare.
</ParamField>

<ParamField body="weights" type="List[float]" default="None">
  The weights to apply to the sets.
</ParamField>

<ParamField body="aggregate" type="&#x22;SUM&#x22; | &#x22;MIN&#x22; | &#x22;MAX&#x22;" default="sum">
  The aggregation function to apply to the sets.
</ParamField>

<ParamField body="withscores" type="bool" default="false">
  Whether to include scores in the result.
</ParamField>

## Response

<ResponseField required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```py Simple theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"c": 3, "d": 4, "e": 5})

  result = redis.zunionstore(["key1", "key2"])

  assert result == 5
  ```

  ```py Aggregation theme={"system"}
  redis.zadd("key1", {"a": 1, "b": 2, "c": 3})

  redis.zadd("key2", {"a": 3, "b": 4, "c": 5})

  result = redis.zunionstore(["key1", "key2"], withscores=True, aggregate="SUM")

  assert result == [("a", 4), ("b", 6), ("c", 8)]
  ```

  ```py Weights theme={"system"}
  redis.zadd("key1", {"a": 1})

  redis.zadd("key2", {"a": 1})

  result = redis.zunionstore(["key1", "key2"],
                        withscores=True,
                        aggregate="SUM",
                        weights=[2, 3])

  assert result == [("a", 5)]
  ```
</RequestExample>


# Features
Source: https://upstash.com/docs/redis/sdks/py/features



### BITFIELD and BITFIELD\_RO

One particular case is represented by these two chained commands, which are
available as functions that return an instance of the `BITFIELD` and,
respectively, `BITFIELD_RO` classes. Use the `execute` function to run the
commands.

```python  theme={"system"}
redis.bitfield("test_key") \
  .incrby(encoding="i8", offset=100, increment=100) \
  .overflow("SAT") \
  .incrby(encoding="i8", offset=100, increment=100) \
  .execute()

redis.bitfield_ro("test_key_2") \
  .get(encoding="u8", offset=0) \
  .get(encoding="u8", offset="#1") \
  .execute()
```

### Custom commands

If you want to run a command that hasn't been implemented, you can use the
`execute` function of your client instance and pass the command as a `list`.

```python  theme={"system"}
redis.execute(["XLEN", "test_stream"])
```

# Encoding

Although Redis can store invalid JSON data, there might be problems with the
deserialization. To avoid this, the Upstash REST proxy is capable of encoding
the data as base64 on the server and then sending it to the client to be
decoded.

For very large data, this can add a few milliseconds in latency. So, if you're
sure that your data is valid JSON, you can set `rest_encoding` to `None`.

# Retry mechanism

upstash-redis has a fallback mechanism in case of network or API issues. By
default, if a request fails it'll retry once, 3 seconds after the error. If you
want to customize that, set `rest_retries` and `rest_retry_interval` (in
seconds).

# Pipelines & Transactions

If you want to submit commands in batches to reduce the number of roundtrips, you can utilize pipelining or
transactions. The difference between pipelines and transactions is that transactions are atomic: no other
command is executed during that transaction. In pipelines there is no such guarantee.

To use a pipeline, simply call the `pipeline` method:

```python  theme={"system"}
pipeline = redis.pipeline()

pipeline.set("foo", 1)
pipeline.incr("foo")
pipeline.get("foo")

result = pipeline.exec()

print(result)
# prints [True, 2, '2']
```

For transaction, use `mutli`:

```python  theme={"system"}
pipeline = redis.multi()

pipeline.set("foo", 1)
pipeline.incr("foo")
pipeline.get("foo")

result = pipeline.exec()

print(result)
# prints [True, 2, '2']
```

You can also chain the commands:

```python  theme={"system"}
pipeline = redis.pipeline()

pipeline.set("foo", 1).incr("foo").get("foo")
result = pipeline.exec()

print(result)
# prints [True, 2, '2']
```

# Telemetry

This library sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Vercel, AWS)
* Python Runtime version

You can opt out by passing `allow_telemetry=False` when initializing the Redis client:

```py  theme={"system"}
redis = Redis(
  # ...,
  allow_telemetry=False,
)
```


# Getting Started
Source: https://upstash.com/docs/redis/sdks/py/gettingstarted



## Install

### PyPI

```bash  theme={"system"}
pip install upstash-redis
```

## Usage

To be able to use upstash-redis, you need to create a database on
[Upstash](https://console.upstash.com/) and grab `UPSTASH_REDIS_REST_URL` and
`UPSTASH_REDIS_REST_TOKEN` from the console.

```python  theme={"system"}
# for sync client
from upstash_redis import Redis

redis = Redis(url="UPSTASH_REDIS_REST_URL", token="UPSTASH_REDIS_REST_TOKEN")

# for async client
from upstash_redis.asyncio import Redis

redis = Redis(url="UPSTASH_REDIS_REST_URL", token="UPSTASH_REDIS_REST_TOKEN")
```

Or, if you want to automatically load the credentials from the environment:

```python  theme={"system"}
# for sync use
from upstash_redis import Redis
redis = Redis.from_env()

# for async use
from upstash_redis.asyncio import Redis
redis = Redis.from_env()
```

If you are in a serverless environment that allows it, it's recommended to
initialise the client outside the request handler to be reused while your
function is still hot.

Running commands might look like this:

```python  theme={"system"}
from upstash_redis import Redis

redis = Redis.from_env()

def main():
  redis.set("a", "b")
  print(redis.get("a"))

# or for async context:

from upstash_redis.asyncio import Redis

redis = Redis.from_env()

async def main():
  await redis.set("a", "b")
  print(await redis.get("a"))
```


# Overview
Source: https://upstash.com/docs/redis/sdks/py/overview



`upstash-redis` is a connectionless, HTTP-based Redis client for Python,
designed to be used in serverless and serverful environments such as:

* AWS Lambda
* Vercel Serverless
* Google Cloud Functions
* and other environments where HTTP is preferred over TCP.

Inspired by other Redis clients like
[@upstash/redis](https://github.com/upstash/upstash-redis) and
[redis-py](https://github.com/redis/redis-py), the goal of this SDK is to
provide a simple way to use Redis over the
[Upstash REST API](https://docs.upstash.com/redis/features/restapi).

The SDK is currently compatible with Python 3.8 and above.

You can find the Github Repository [here](https://github.com/upstash/redis-python).


# Ratelimiting Algorithms
Source: https://upstash.com/docs/redis/sdks/ratelimit-py/algorithms



## Fixed Window

This algorithm divides time into fixed durations/windows. For example each
window is 10 seconds long. When a new request comes in, the current time is used
to determine the window and a counter is increased. If the counter is larger
than the set limit, the request is rejected.

<Tip>
  In fixed & sliding window algorithms, the reset time is based on fixed time boundaries (which depend on the period), not on when the first request was made. So two requests made right before the window ends still count toward the current window, and limits reset at the start of the next window.
</Tip>

### Pros

* Very cheap in terms of data size and computation
* Newer requests are not starved due to a high burst in the past

### Cons

* Can cause high bursts at the window boundaries to leak through
* Causes request stampedes if many users are trying to access your server,
  whenever a new window begins

### Usage

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, FixedWindow
from upstash_redis import Redis

ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=FixedWindow(max_requests=10, window=10),
)
```

## Sliding Window

Builds on top of fixed window but instead of a fixed window, we use a rolling
window. Take this example: We have a rate limit of 10 requests per 1 minute. We
divide time into 1 minute slices, just like in the fixed window algorithm.
Window 1 will be from 00:00:00 to 00:01:00 (HH:MM:SS). Let's assume it is
currently 00:01:15 and we have received 4 requests in the first window and 5
requests so far in the current window. The approximation to determine if the
request should pass works like this:

```python  theme={"system"}
limit = 10

# 4 request from the old window, weighted + requests in current window
rate = 4 * ((60 - 15) / 60) + 5 = 8

return rate < limit # True means we should allow the request
```

### Pros

* Solves the issue near boundary from fixed window.

### Cons

* More expensive in terms of storage and computation
* It's only an approximation because it assumes a uniform request flow in the
  previous window

### Usage

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, SlidingWindow
from upstash_redis import Redis

ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=SlidingWindow(max_requests=10, window=10),
)
```

<Tip>
  `reset` field in the [`limit`](/redis/sdks/ratelimit-py/gettingstarted) method of sliding window does not
  provide an exact reset time. Instead, the reset time is the start time of
  the next window.
</Tip>

## Token Bucket

Consider a bucket filled with maximum number of tokens that refills constantly
at a rate per interval. Every request will remove one token from the bucket and
if there is no token to take, the request is rejected.

### Pros

* Bursts of requests are smoothed out and you can process them at a constant
  rate.
* Allows setting a higher initial burst limit by setting maximum number of
  tokens higher than the refill rate

### Cons

* Expensive in terms of computation

### Usage

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, TokenBucket
from upstash_redis import Redis

ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=TokenBucket(max_tokens=10, refill_rate=5, interval=10),
)
```


# Features
Source: https://upstash.com/docs/redis/sdks/ratelimit-py/features



## Block until ready

You also have the option to try and wait for a request to pass in the given
timeout.

It is very similar to the `limit` method and takes an identifier and returns the
same response. However if the current limit has already been exceeded, it will
automatically wait until the next window starts and will try again. Setting the
timeout parameter (in seconds) will cause the method to block a finite amount of
time.

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, SlidingWindow
from upstash_redis import Redis

# Create a new ratelimiter, that allows 10 requests per 10 seconds
ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=SlidingWindow(max_requests=10, window=10),
)

response = ratelimit.block_until_ready("id", timeout=30)

if not response.allowed:
    print("Unable to process, even after 30 seconds")
else:
    do_expensive_calculation()
    print("Here you go!")
```

## Using multiple limits

Sometimes you might want to apply different limits to different users. For
example you might want to allow 10 requests per 10 seconds for free users, but
60 requests per 10 seconds for paid users.

Here's how you could do that:

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, SlidingWindow
from upstash_redis import Redis

class MultiRL:
    def __init__(self) -> None:
        redis = Redis.from_env()
        self.free = Ratelimit(
            redis=redis,
            limiter=SlidingWindow(max_requests=10, window=10),
            prefix="ratelimit:free",
        )

        self.paid = Ratelimit(
            redis=redis,
            limiter=SlidingWindow(max_requests=60, window=10),
            prefix="ratelimit:paid",
        )

# Create a new ratelimiter, that allows 10 requests per 10 seconds
ratelimit = MultiRL()

ratelimit.free.limit("userIP")
ratelimit.paid.limit("userIP")
```

## Custom Rates

When rate limiting, you may want different requests to consume different amounts of tokens.
This could be useful when processing batches of requests where you want to rate limit based
on items in the batch or when you want to rate limit based on the number of tokens.

To achieve this, you can simply pass `rate` parameter when calling the limit method:

```python  theme={"system"}

from upstash_ratelimit import Ratelimit, FixedWindow
from upstash_redis import Redis

ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=FixedWindow(max_requests=10, window=10),
)

# pass rate as 5 to subtract 5 from the number of
# allowed requests in the window:
identifier = "api"
response = ratelimit.limit(identifier, rate=5)
```


# Getting Started
Source: https://upstash.com/docs/redis/sdks/ratelimit-py/gettingstarted



## Install

```bash  theme={"system"}
pip install upstash-ratelimit
```

## Create database

To be able to use upstash-ratelimit, you need to create a database on
[Upstash](https://console.upstash.com/).

## Usage

For possible Redis client configurations, have a look at the
[Redis SDK repository](https://github.com/upstash/redis-python).

> This library supports asyncio as well. To use it, import the asyncio-based
> variant from the `upstash_ratelimit.asyncio` module.

```python  theme={"system"}
from upstash_ratelimit import Ratelimit, FixedWindow
from upstash_redis import Redis

# Create a new ratelimiter, that allows 10 requests per 10 seconds
ratelimit = Ratelimit(
    redis=Redis.from_env(),
    limiter=FixedWindow(max_requests=10, window=10),
    # Optional prefix for the keys used in Redis. This is useful
    # if you want to share a Redis instance with other applications
    # and want to avoid key collisions. The default prefix is
    # "@upstash/ratelimit"
    prefix="@upstash/ratelimit",
)

# Use a constant string to limit all requests with a single ratelimit
# Or use a user ID, API key or IP address for individual limits.
identifier = "api"
response = ratelimit.limit(identifier)

if not response.allowed:
    print("Unable to process at this time")
else:
    do_expensive_calculation()
    print("Here you go!")
```

The `limit` method also returns the following metadata:

```python  theme={"system"}
@dataclasses.dataclass
class Response:
    allowed: bool
    """
    Whether the request may pass(`True`) or exceeded the limit(`False`)
    """

    limit: int
    """
    Maximum number of requests allowed within a window.
    """

    remaining: int
    """
    How many requests the user has left within the current window.
    """

    reset: float
    """
    Unix timestamp in seconds when the limits are reset
    """
```


# Overview
Source: https://upstash.com/docs/redis/sdks/ratelimit-py/overview



`upstash-ratelimit` is a connectionless rate limiting library for Python,
designed to be used in serverless environments such as:

* AWS Lambda
* Vercel Serverless
* Google Cloud Functions
* and other environments where HTTP is preferred over TCP.

The SDK is currently compatible with Python 3.8 and above.

You can find the Github Repository [here](https://github.com/upstash/ratelimit-python).


# Ratelimiting Algorithms
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/algorithms



We provide different algorithms to use out of the box. Each has pros and cons.

## Fixed Window

This algorithm divides time into fixed durations/windows. For example each
window is 10 seconds long. When a new request comes in, the current time is used
to determine the window and a counter is increased. If the counter is larger
than the set limit, the request is rejected.

<Tip>
  In fixed & sliding window algorithms, the reset time is based on fixed time boundaries (which depend on the period), not on when the first request was made. So two requests made right before the window ends still count toward the current window, and limits reset at the start of the next window.
</Tip>

### Pros

* Very cheap in terms of data size and computation
* Newer requests are not starved due to a high burst in the past

### Cons

* Can cause high bursts at the window boundaries to leak through
* Causes request stampedes if many users are trying to access your server,
  whenever a new window begins

### Usage

Create a new ratelimiter, that allows 10 requests per 10 seconds.

<Tabs>
  <Tab title="Regional">
    ```ts  theme={"system"}
    const ratelimit = new Ratelimit({
      redis: Redis.fromEnv(),
      limiter: Ratelimit.fixedWindow(10, "10 s"),
    });
    ```
  </Tab>

  <Tab title="Multi Regional">
    ```ts  theme={"system"}
    const ratelimit = new MultiRegionRatelimit({
      redis: [
        new Redis({
          /* auth */
        }),
        new Redis({
          /* auth */
        })
      ],
      limiter: MultiRegionRatelimit.fixedWindow(10, "10 s"),
    });
    ```
  </Tab>
</Tabs>

## Sliding Window

Builds on top of fixed window but instead of a fixed window, we use a rolling
window. Take this example: We have a rate limit of 10 requests per 1 minute. We
divide time into 1 minute slices, just like in the fixed window algorithm.
Window 1 will be from 00:00:00 to 00:01:00 (HH:MM:SS). Let's assume it is
currently 00:01:15 and we have received 4 requests in the first window and 5
requests so far in the current window. The approximation to determine if the
request should pass works like this:

```ts  theme={"system"}
limit = 10

// 4 request from the old window, weighted + requests in current window
rate = 4 * ((60 - 15) / 60) + 5 = 8

return rate < limit // True means we should allow the request
```

### Pros

* Solves the issue near boundary from fixed window.

### Cons

* More expensive in terms of storage and computation
* Is only an approximation, because it assumes a uniform request flow in the
  previous window, but this is fine in most cases

### Usage

Create a new ratelimiter, that allows 10 requests per 10 seconds.

<Tabs>
  <Tab title="Regional">
    ```ts  theme={"system"}
    const ratelimit = new Ratelimit({
      redis: Redis.fromEnv(),
      limiter: Ratelimit.slidingWindow(10, "10 s"),
    });
    ```
  </Tab>

  <Tab title="Multi Regional">
    **Warning:** Using sliding window algorithm with the multiregion setup results in large number of
    commands in Redis and long request processing times. If you want to keep the number of commands
    low, we recommend using the [fixed window algorithm in multi region setup](/redis/sdks/ratelimit-ts/algorithms#fixed-window).

    ```ts  theme={"system"}
    const ratelimit = new MultiRegionRatelimit({
      redis: [
        new Redis({
          /* auth */
        }),
        new Redis({
          /* auth */
        })
      ],
      limiter: MultiRegionRatelimit.slidingWindow(10, "10 s"),
    });
    ```
  </Tab>
</Tabs>

<Tip>
  `reset` field in the [`limit`](/redis/sdks/ratelimit-ts/methods#limit) and [`getRemaining`](/redis/sdks/ratelimit-ts/methods#getremaining) methods of sliding window do not
  provide an exact reset time. Instead, the reset time is the start time of
  the next window.
</Tip>

## Token Bucket

Consider a bucket filled with `{maxTokens}` tokens that refills constantly at
`{refillRate}` per `{interval}`. Every request will remove one token from the
bucket and if there is no token to take, the request is rejected.

### Pros

* Bursts of requests are smoothed out and you can process them at a constant
  rate.
* Allows to set a higher initial burst limit by setting `maxTokens` higher than
  `refillRate`

### Cons

* Expensive in terms of computation

### Usage

Create a new bucket, that refills 5 tokens every 10 seconds and has a maximum
size of 10.

<Tabs>
  <Tab title="Regional">
    ```ts  theme={"system"}
    const ratelimit = new Ratelimit({
      redis: Redis.fromEnv(),
      limiter: Ratelimit.tokenBucket(5, "10 s", 10),
      analytics: true,
    });
    ```
  </Tab>

  <Tab title="Multi Regional">
    *Not yet supported for `MultiRegionRatelimit`*
  </Tab>
</Tabs>


# Costs
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/costs



This page details the cost of the Ratelimit algorithms in terms of the number of Redis commands. Note that these are calculated for Regional Ratelimits. For [Multi Region Ratelimit](/redis/sdks/ratelimit-ts/features#multi-region), costs will be higher. Additionally, if a Global Upstash Redis is used as the database, number of commands should be calculated as `(1+readRegionCount) * writeCommandCount + readCommandCount` and plus 1 if analytics is enabled.

The Rate Limit SDK minimizes Redis calls to reduce latency overhead and cost. Number of commands executed by the Rate Limit algorithm depends on the chosen algorithm, as well as the state of the algorithm and the caching.

#### Algorithm State

By state of the algorithm, we refer to the entry in our Redis store regarding some identifier `ip1`. You can imagine that there is a state for every identifier. We name these states in the following manner for the purpose of attributing costs to each one:

| State        | Success | Explanation                                                              |
| ------------ | ------- | ------------------------------------------------------------------------ |
| First        | true    | First time the Ratelimit was called with identifier `ip1`                |
| Intermediate | true    | Second or some other time the Ratelimit was called with identifier `ip1` |
| Rate-Limited | false   | Requests with identifier `ip1` which are rate limited.                   |

For instance, first time we call the algorithm with `ip1`, `PEXPIRE` is called so that the key expires after some time. In the following calls, we still use the same script but don't call `PEXPIRE`. In the rate-limited state, we may avoid using Redis altogether if we can make use of the cache.

#### Cache Result

We distinguish the two cases when the identifier `ip1` is found in cache, resulting in a "hit" and the case when the identifier `ip1` is not found in the cache, resulting in a "miss". The cache only exists in the runtime environment and is independent of the Redis database. The state of the cache is especially relevant for serverless contexts, where the cache will usually be empty because of a cold start.

| Result | Explanation                                                                                             |
| ------ | ------------------------------------------------------------------------------------------------------- |
| Hit    | Identifier `ip1` is found in the runtime cache                                                          |
| Miss   | Identifier `ip1` is not found in cache or the value in the cache doesn't block (rate-limit) the request |

An identifier is saved in the cache only when a request is rate limited after a call to the Redis database. The request to Redis returns a timestamp for the time when such a request won't be rate limited anymore. We save this timestamp in the cache and this allows us to reject any request before this timestamp without having to consult the Redis database.

See the [section on caching](/redis/sdks/ratelimit-ts/features) for more details.

# Costs

### `limit()`

#### Fixed Window

| Cache Result | Algorithm State | Command Count | Commands            |
| ------------ | --------------- | ------------- | ------------------- |
| Hit/Miss     | First           | 3             | EVAL, INCR, PEXPIRE |
| Hit/Miss     | Intermediate    | 2             | EVAL, INCR          |
| Miss         | Rate-Limited    | 2             | EVAL, INCR          |
| Hit          | Rate-Limited    | 0             | *utilized cache*    |

#### Sliding Window

| Cache Result | Algorithm State | Command Count | Commands                      |
| ------------ | --------------- | ------------- | ----------------------------- |
| Hit/Miss     | First           | 5             | EVAL, GET, GET, INCR, PEXPIRE |
| Hit/Miss     | Intermediate    | 4             | EVAL, GET, GET, INCR          |
| Miss         | Rate-Limited    | 3             | EVAL, GET, GET                |
| Hit          | Rate-Limited    | 0             | *utilized cache*              |

#### Token Bucket

| Cache Result | Algorithm State    | Command Count | Commands                   |
| ------------ | ------------------ | ------------- | -------------------------- |
| Hit/Miss     | First/Intermediate | 4             | EVAL, HMGET, HSET, PEXPIRE |
| Miss         | Rate-Limited       | 2             | EVAL, HMGET                |
| Hit          | Rate-Limited       | 0             | *utilized cache*           |

### `getRemaining()`

This method doesn't use the cache or it doesn't have a state it depends on. Therefore, every call
results in the same number of commands in Redis.

| Algorithm      | Command Count | Commands       |
| -------------- | ------------- | -------------- |
| Fixed Window   | 2             | EVAL, GET      |
| Sliding Window | 3             | EVAL, GET, GET |
| Token Bucket   | 2             | EVAL, HMGET    |

### `resetUsedTokens()`

This method starts with a `SCAN` command and deletes every key that matches with `DEL` commands:

| Algorithm      | Command Count | Commands             |
| -------------- | ------------- | -------------------- |
| Fixed Window   | 3             | EVAL, SCAN, DEL      |
| Sliding Window | 4             | EVAL, SCAN, DEL, DEL |
| Token Bucket   | 3             | EVAL, SCAN, DEL      |

### `blockUntilReady()`

Works the same as `limit()`.

# Deny List

Enabling deny lists introduces a cost of 2 additional command per `limit` call.

Values passed in `identifier`, `ip`, `userAgent` and `country` are checked with a single `SMISMEMBER` command.
The other command is TTL which is for checking the status of the current ip deny list to figure out whether
it is expired, valid or disabled.

If [Auto IP deny list](/redis/sdks/ratelimit-ts/features#auto-ip-deny-list) is enabled,
the Ratelimit SDK will update the ip deny list everyday, in the first `limit` invocation after 2 AM UTC.
This will consume 9 commands per day.

If a value is found in the deny list at redis, the client saves this value in the cache and denies
any further requests with that value for a minute without calling Redis (except for analytics).

# Analytics

If analytics is enabled, all calls of `limit` will result in 1 more command since `ZINCRBY` will be called to update the analytics.


# Features
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/features



## Caching

For extreme load or denial of service attacks, it might be too expensive to call
redis for every incoming request, just to find out it should be blocked because
they have exceeded the limit.

You can use an ephemeral in memory cache by passing some variable of type
`Map<string, number>` as the `ephemeralCache` option:

```ts  theme={"system"}
const cache = new Map(); // must be outside of your serverless function handler

// ...

const ratelimit = new Ratelimit({
  // ...
  ephemeralCache: cache,
});
```

By default, `ephemeralCache` will be initialized with `new Map()` if no value is provided
as the `ephemeralCache` parameter. To disable the cache, one must pass `ephemeralCache: false`.

If enabled, the ratelimiter will keep track of the blocked identifiers and their
reset timestamps. When a request is received with some identifier `ip1` before the reset time of
`ip1`, the request will be denied without having to call Redis. [`reason` field of the
limit response will be `cacheBlock`](/redis/sdks/ratelimit-ts/methods#limit)

In serverless environments this is only possible if you create the cache or ratelimiter
instance outside of your handler function. While the function is still hot, the
ratelimiter can block requests without having to request data from Redis, thus
saving time and money.

See the section on how caching impacts the cost in the
[costs page](/redis/sdks/ratelimit-ts/costs#cache-result).

## Timeout

You can define an optional timeout in milliseconds, after which the request will
be allowed to pass regardless of what the current limit is. This can be useful
if you don't want network issues to cause your application to reject requests.

```ts  theme={"system"}
const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  timeout: 1000, // 1 second
  analytics: true,
});
```

Default value of the timeout is 5 seconds if no `timeout` is provided. When response
is success because of a timeout, this is shown in
[the `reason` field of the limit method](/redis/sdks/ratelimit-ts/methods#limit).

## Analytics & Dashboard

Another feature of the rate limiting algorithm is to collect analytics.

By default, analytics is disabled. To enable analytics, simply set the `analytics` parameter to `true`:

```js  theme={"system"}
const ratelimit = new Ratelimit({
  redis,
  analytics: true,
  limiter: Ratelimit.slidingWindow(60, "10s"),
});
```

Everytime we call `ratelimit.limit()`, analytics will be sent to the Redis database
([see costs page](/redis/sdks/ratelimit-ts/costs#analytics))
and information about the hour, identifier and the number of rate limit success and
failures will be collected. This information can be viewed from the Upstash console.

If you are using rate limiting in Cloudflare Workers, Vercel Edge or a similar environment,
you need to make sure that the analytics request is delivered correctly to the Redis.
Otherwise, you may observe lower numbers than the actual number of calls.

To make sure that the request completes, you can use the `pending` field returned by
the `limit` method. See the
[Asynchronous synchronization between databases](/redis/sdks/ratelimit-ts/features#asynchronous-synchronization-between-databases)
section to see how `pending` can be used.

### Dashboard

If the analytics is enabled, you can find information about how many requests were made
with which identifiers and how many of the requests were blocked from the [Rate Limit
dashboard in Upstash Console](https://console.upstash.com/ratelimit).

To find the dashboard, simply click the three dots and choose the "Rate Limit Analytics" tab:

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d5782de13e1625c535dfe7c6543a4599" alt="navigate.png" data-og-width="1972" width="1972" data-og-height="504" height="504" data-path="img/ratelimit/navigate.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=a649e7b04cc015b4309f103c24a717fe 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8f570ef3613bc1bbe64b1492abbf397d 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=97465419175782f2640a752424e27183 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=149c02fcb53a2cdf60d308efe6cdd75c 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=94c695feab166781f090d88465191328 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/navigate.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=03a3728a782e6e31d11feb4a063a3a6d 2500w" />

In the dashboard, you can find information on how many requests were accepted, how many were blocked
and how many were received in total. Additionally, you can see requests over time; top allowed, rate limited
and denied requests.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=be1859b6734170635a8054403236bd27" alt="dashboard.png" data-og-width="1029" width="1029" data-og-height="947" height="947" data-path="img/ratelimit/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=a5e8d7631c4a2167d61945805b6cca3b 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=893b6e95c914a2c6f477d2a673e59607 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=f00598c911f01728010710d25748e0a9 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=12e44615be887b54bb5fe0b904e8553f 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8ab998c7e0ad38d12b3024f8a61b1797 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/dashboard.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d284ed250bda6b970e667e9fca994b29 2500w" />

**Allowed requests** show the identifiers of the requests which succeeded. **Rate limited requests** show the
identifiers of the requests which were blocked because they surpassed the limit. **Denied requests** show the identifier,
user agent, country, or the IP address which caused the request to fail.

If you are using a custom prefix, you need to use the same in the dashboard‚Äôs top left corner.

## Using Multiple Limits

Sometimes you might want to apply different limits to different users. For
example you might want to allow 10 requests per 10 seconds for free users, but
60 requests per 10 seconds for paid users.

Here's how you could do that:

```ts  theme={"system"}
import { Redis } from "@upstash/redis";
import { Ratelimit } from "@upstash/ratelimit";

const redis = Redis.fromEnv();

const ratelimit = {
  free: new Ratelimit({
    redis,
    analytics: true,
    prefix: "ratelimit:free",
    limiter: Ratelimit.slidingWindow(10, "10s"),
  }),
  paid: new Ratelimit({
    redis,
    analytics: true,
    prefix: "ratelimit:paid",
    limiter: Ratelimit.slidingWindow(60, "10s"),
  }),
};

await ratelimit.free.limit(ip);
// or for a paid user you might have an email or userId available:
await ratelimit.paid.limit(userId);
```

## Custom Rates

When we call `limit`, it subtracts 1 from the number of calls/tokens available in
the timeframe by default. But there are use cases where we may want to subtract different
numbers depending on the request.

Consider a case where we receive some input from the user either alone or in batches.
If we want to rate limit based on the number of inputs the user can send, we need a way of
specifying what value to subtract.

This is possible thanks to the `rate` parameter. Simply call the `limit` method like the
following:

```ts  theme={"system"}
const { success } = await ratelimit.limit("identifier", { rate: batchSize });
```

This way, the algorithm will subtract `batchSize` instead of 1.

## Multi Region

Let's assume you have customers in the US and Europe. In this case you can
create 2 separate global redis databases on [Upstash](https://console.upstash.com)
(one with its primary in US and the other in Europe) and your users will enjoy
the latency of whichever db is closest to them.

Using a single Redis instance with replicas in different regions cannot offer
the same performance as `MultiRegionRatelimit` because all write commands have
to go through the primary, increasing latency in other regions.

Using a single redis instance has the downside of providing low latencies only
to the part of your userbase closest to the deployed db. That's why we also
built `MultiRegionRatelimit` which replicates the state across multiple redis
databases as well as offering lower latencies to more of your users.

`MultiRegionRatelimit` does this by checking the current limit in the closest db
and returning immediately. Only afterwards will the state be asynchronously
replicated to the other databases leveraging
[CRDTs](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type). Due
to the nature of distributed systems, there is no way to guarantee the set
ratelimit is not exceeded by a small margin. This is the tradeoff for reduced
global latency.

### Usage

The API is the same, except for asking for multiple redis instances:

```ts  theme={"system"}
import { MultiRegionRatelimit } from "@upstash/ratelimit"; // for deno: see above
import { Redis } from "@upstash/redis";

// Create a new ratelimiter, that allows 10 requests per 10 seconds
const ratelimit = new MultiRegionRatelimit({
  redis: [
    new Redis({
      /* auth */
    }),
    new Redis({
      /* auth */
    }),
    new Redis({
      /* auth */
    }),
  ],
  limiter: MultiRegionRatelimit.slidingWindow(10, "10 s"),
  analytics: true,
});

// Use a constant string to limit all requests with a single ratelimit
// Or use a userID, apiKey or ip address for individual limits.
const identifier = "api";
const { success } = await ratelimit.limit(identifier);
```

### Asynchronous synchronization between databases

The MultiRegion setup will do some synchronization between databases after
returning the current limit. This can lead to problems on Cloudflare Workers and
therefore Vercel Edge functions, because dangling promises must be taken care
of:

```ts  theme={"system"}
const { pending } = await ratelimit.limit("id");
context.waitUntil(pending);
```

See more information on `context.waitUntil` at
[Cloudflare](https://developers.cloudflare.com/workers/runtime-apis/context/#waituntil)
and [Vercel](https://vercel.com/docs/functions/edge-middleware/middleware-api#waituntil).
You can also utilize [`waitUntil` from Vercel Functions API](https://vercel.com/docs/functions/functions-api-reference#waituntil).


# Getting Started
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/gettingstarted



## Create your Redis instance

For the rate limit to work, we need to create an Upstash Redis and get its credentials. To create an Upstash Redis, you can follow the [Upstash Redis "Get Started" guide](/redis/overall/getstarted).

## Add Ratelimit to Your Project

Once we have a Redis instance, next step is adding the rate limit to your project in its most basic form.

### Install Ratelimit

First, we need to install `@upstash/ratelimit`:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/ratelimit
    ```
  </Tab>

  <Tab title="deno">
    ```ts  theme={"system"}
    import { Ratelimit } from "https://cdn.skypack.dev/@upstash/ratelimit@latest";
    ```
  </Tab>
</Tabs>

### Add Ratelimit to Your Endpoint

Next step is to add Ratelimit to your endpoint. In the example below, you can see how to initialize a Ratelimit and use it:

```ts  theme={"system"}
import { Ratelimit } from "@upstash/ratelimit"; // for deno: see above
import { Redis } from "@upstash/redis";

// Create a new ratelimiter, that allows 10 requests per 10 seconds
const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  analytics: true,
  /**
   * Optional prefix for the keys used in redis. This is useful if you want to share a redis
   * instance with other applications and want to avoid key collisions. The default prefix is
   * "@upstash/ratelimit"
   */
  prefix: "@upstash/ratelimit",
});

// Use a constant string to limit all requests with a single ratelimit
// Or use a userID, apiKey or ip address for individual limits.
const identifier = "api";
const { success } = await ratelimit.limit(identifier);

if (!success) {
  return "Unable to process at this time";
}
doExpensiveCalculation();
return "Here you go!";
```

For Cloudflare Workers and Fastly Compute\@Edge, you can use the following imports:

```ts  theme={"system"}
import { Redis } from "@upstash/redis/cloudflare"; // for cloudflare workers and pages
import { Redis } from "@upstash/redis/fastly"; // for fastly compute@edge
```

In this example, we initialize a Ratelimit with an Upstash Redis. The Uptash Redis instance is created from the environment variables and passed to the Ratelimit instance. Then, we check the access rate using the `ratelimit.limit(identifier)` method. If the `success` field is true, we allow the expensive calculation to go through.

For more examples, see the [Examples](/redis/sdks/ratelimit-ts/overview#examples).

### Set Environment Variables

Final step is to update the environment variables so that the Ratelimit can communicate with the Upstash Redis. `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` environment variables must be set in order for the `Redis.fromEnv()` command to work. You can get the values of these environment variables from the [Upstash Console](https://console.upstash.com/redis) by navigating to the page of the Redis instance you created.

An alternative of using the `Redis.fromEnv()` method is to pass the variables yourself. This can be useful if you save these environment variables with a different name:

```ts  theme={"system"}
new Redis({
  url: "https://****.upstash.io",
  token: "********",
});
```

Here is how you can set the environment variables in different cases:

<Tabs>
  <Tab title="Vercel">
    Go to the "Settings" tab in your project. In the menu to the left, click "Environment Variables". Add `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` environment variables and their values.
  </Tab>

  <Tab title="Cloudflare Worker (Wrangler)">
    Run:

    ```
    npx wrangler secret put UPSTASH_REDIS_REST_URL
    ```

    When prompted, enter the value of `UPSTASH_REDIS_REST_URL` when prompted. Do the same for `UPSTASH_REDIS_REST_TOKEN`:

    ```
    npx wrangler secret put UPSTASH_REDIS_REST_TOKEN
    ```
  </Tab>

  <Tab title="Local Nextjs Project">
    Go to the `.env.local` file and add the environment variables:

    ```
    UPSTASH_REDIS_REST_URL=****
    UPSTASH_REDIS_REST_TOKEN=****
    ```
  </Tab>
</Tabs>

## Serverless Environments

When we use ratelimit in a serverless environment like CloudFlare Workers or Vercel Edge,
we need to be careful about making sure that the rate limiting operations complete correctly
before the runtime ends after returning the response.

This is important in two cases where we do some operations in the backgroung asynchronously after `limit` is called:

1. Using MultiRegion: synchronize Redis instances in different regions
2. Enabling analytics: send analytics to Redis

In these cases, we need to wait for these operations to finish before sending the response to the user. Otherwise, the runtime will end and we won't be able to complete our chores.

In order to wait for these operations to finish, use the `pending` promise:

```ts  theme={"system"}
const { pending } = await ratelimit.limit("id");
context.waitUntil(pending);
```

See more information on `context.waitUntil` at
[Cloudflare](https://developers.cloudflare.com/workers/runtime-apis/context/#waituntil)
and [Vercel](https://vercel.com/docs/functions/edge-middleware/middleware-api#waituntil).
You can also utilize [`waitUntil` from Vercel Functions API](https://vercel.com/docs/functions/functions-api-reference#waituntil).

## Customizing the Ratelimit Algorithm

There are several algorithms we can use for rate limiting. Explore the different rate-limiting algorithms available; how they work, their advantages and disadvantages in the [Algorithms page](/redis/sdks/ratelimit-ts/algorithms). You can learn about the **cost in terms of the number of commands**, by referring to the [Costs page](/redis/sdks/ratelimit-ts/costs).

## Methods

In our example, we only used the `limit` method. There are other methods we can use in the Ratelimit. These are:

* `blockUntilReady`: Process a request only when the rate-limiting algorithm allows it.
* `resetUsedTokens`: Reset the rate limiter state for some identifier.
* `getRemaining`: Get the remaining tokens/requests left for some identifier.

To learn more about these methods, refer to the [Methods page](/redis/sdks/ratelimit-ts/methods).

## Features

To configure the your Ratelimit according to your needs, you can make use of several features:

<CardGroup cols={2}>
  <Card title="Caching" icon="shield-halved" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#caching">
    Handle blocked requests without having to call your Redis Database
  </Card>

  <Card title="Timeout" icon="stopwatch" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#timeout">
    If the Redis call of the ratelimit is not resolved in some timeframe, allow
    the request by default
  </Card>

  <Card title="Analytics & Dashboard" icon="magnifying-glass-chart" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#analytics-and-dashboard">
    Collect information on which identifiers made how many requests and how many
    were blocked
  </Card>

  <Card title="Traffic Protection" icon="lock" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/traffic-protection">
    Create a deny list to block requests based on user agents, countries, IP
    addresses an more
  </Card>

  <Card title="Custom Rates" icon="chart-simple" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#custom-rates">
    Consume different amounts of tokens in different requests (example: limiting
    based on request/response size)
  </Card>

  <Card title="Multi Region" icon="globe" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#multi-region">
    Utilize several Redis databases in different regions to serve users faster
  </Card>

  <Card title="Multiple Limits" icon="gears" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#using-multiple-limits">
    Use different limits for different kinds of requests (example: paid and free
    users)
  </Card>
</CardGroup>

For more information about the features, see the [Features page](/redis/sdks/ratelimit-ts/features).


# Configure Upstash Ratelimit Strapi Plugin
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/integrations/strapi/configurations



After setting up the plugin, it's possible to customize the ratelimiter algorithm and rates. You can also define different rate limits and rate limit algorithms for different routes.

## General Configurations

<ParamField path="enabled" type="boolean" default="true">
  Enable or disable the plugin.
</ParamField>

## Database Configurations

<ParamField path="token" type="string" required>
  The token to authenticate with the Upstash Redis REST API. You can find this
  credential on Upstash Console with the name `UPSTASH_REDIS_REST_TOKEN`
</ParamField>

<ParamField path="url" type="string" required>
  The URL for the Upstash Redis REST API. You can find this credential on
  Upstash Console with the name `UPSTASH_REDIS_REST_URL`
</ParamField>

<ParamField path="prefix" type="string" default="@strapi">
  The prefix for the rate limit keys. The plugin uses this prefix to store the
  rate limit data in Redis. <br />
  For example, if the prefix is `@strapi`, the key will be
  `@strapi:<method>:<route>:<identifier>`.
</ParamField>

<ParamField path="analytics" type="boolean" default="false">
  Enable analytics for the rate limit. When enabled, the plugin extra insights
  related to your ratelimits. You can use this data to analyze the rate limit
  usage on [Upstash Console](https://console.upstash.com/ratelimit).
</ParamField>

## Strategy

The plugin uses a strategy array to define the rate limits per route. Each strategy object has the following properties:

<ParamField path="methods" type="('GET' | 'POST' | 'DELETE' | 'PUT' | 'PATCH' |'ALL')[]" required>
  An array of HTTP methods to apply the rate limit. <br />
  For example, `["GET", "POST"]`
</ParamField>

<ParamField path="path" type="string" required>
  The path to apply the rate limit. You can use wildcards to match multiple
  routes. For example, `*` matches all routes. <br />
  Some examples: <br />

  * `path: "/api/restaurants/:id"` <br />
  * `path: "/api/restaurants"` <br />
</ParamField>

<ParamField path="identifierSource" type="string" required>
  The source to identifiy the user. Requests with the same identifier will be
  rate limited under the same limit. <br />
  Available sources are: <br />

  * `ip`: The IP address of the user. <br />
  * `header`: The value of a header key. You should pass the source in the `header.<HEADER_KEY>` format. <br />
    For example, `header.Authorization` will use the value of the `Authorization`
</ParamField>

<ParamField path="debug" type="string">
  Enable debug mode for the route. When enabled, the plugin logs the remaining
  limits and the block status for each request. <br />
</ParamField>

<ParamField path="limiter" type="object" required>
  The limiter configuration for the route. The limiter object has the following
  properties:

  <Card>
    <ParamField path="algorithm" type="'fixed-window' | 'sliding-window' | 'token-bucket'" required>
      The rate limit algorithm to use. For more information related to algorithms, see docs [**here**](/redis/sdks/ratelimit-ts/algorithms). <br />

      * `fixed-window`: The fixed-window algorithm divides time into fixed intervals. Each interval has a set limit of allowed requests. When a new interval starts, the count resets. <br />
      * `sliding-window`:
        The sliding-window algorithm uses a rolling time frame. It considers requests from the past X time units, continuously moving forward. This provides a smoother distribution of requests over time. <br />
      * `token-bucket`: The token-bucket algorithm uses a bucket that fills with tokens at a steady rate. Each request consumes a token. If the bucket is empty, requests are denied. This allows for bursts of traffic while maintaining a long-term rate limit.<br />
    </ParamField>

    <ParamField path="tokens" type="number" required>
      The number of tokens allowed in the time window. <br />
    </ParamField>

    <ParamField path="window" type="string" required>
      The time window for the rate limit. Available units are `"ms" | "s" | "m" | "h" | "d"` <br />
      For example, `20s` means 20 seconds.
    </ParamField>

    <ParamField path="refillRate" type="number">
      The rate at which the bucket refills. **This property is only used for the token-bucket algorithm.** <br />
    </ParamField>
  </Card>
</ParamField>

## Examples

<CodeGroup>
  ```json Apply rate limit for all routes theme={"system"}
  {
     "strapi-plugin-upstash-ratelimit":{
        "enabled":true,
        "resolve":"./src/plugins/strapi-plugin-upstash-ratelimit",
        "config":{
           "enabled":true,
           "token":"process.env.UPSTASH_REDIS_REST_TOKEN",
           "url":"process.env.UPSTASH_REDIS_REST_URL",
           "strategy":[
              {
                 "methods":[
                    "GET",
                    "POST"
                 ],
                 "path":"*",
                 "identifierSource":"header.Authorization",
                 "limiter":{
                    "algorithm":"fixed-window",
                    "tokens":10,
                    "window":"20s"
                 }
              }
           ],
           "prefix":"@strapi"
        }
     }
  }
  ```

  ```json Apply rate limit with IP theme={"system"}
  {
    "strapi-plugin-upstash-ratelimit": {
      "enabled": true,
      "resolve": "./src/plugins/strapi-plugin-upstash-ratelimit",
      "config": {
        "enabled": true,
        "token": "process.env.UPSTASH_REDIS_REST_TOKEN",
        "url": "process.env.UPSTASH_REDIS_REST_URL",
        "strategy": [
          {
            "methods": ["GET", "POST"],
            "path": "*",
            "identifierSource": "ip",
            "limiter": {
              "algorithm": "fixed-window",
              "tokens": 10,
              "window": "20s"
            }
          }
        ],
        "prefix": "@strapi"
      }
    }
  }
  ```

  ```json Routes with different rate limit algorithms theme={"system"}
  {
    "strapi-plugin-upstash-ratelimit": {
      "enabled": true,
      "resolve": "./src/plugins/strapi-plugin-upstash-ratelimit",
      "config": {
        "enabled": true,
        "token": "process.env.UPSTASH_REDIS_REST_TOKEN",
        "url": "process.env.UPSTASH_REDIS_REST_URL",
        "strategy": [
          {
            "methods": ["GET", "POST"],
            "path": "/api/restaurants/:id",
            "identifierSource": "header.x-author",
            "limiter": {
              "algorithm": "fixed-window",
              "tokens": 10,
              "window": "20s"
            }
          },
          {
            "methods": ["GET"],
            "path": "/api/restaurants",
            "identifierSource": "header.x-author",
            "limiter": {
              "algorithm": "tokenBucket",
              "tokens": 10,
              "window": "20s",
              "refillRate": 1
            }
          }
        ],
        "prefix": "@strapi"
      }
    }
  }
  ```
</CodeGroup>


# Upstash Ratelimit Strapi Integration
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/integrations/strapi/getting-started



Strapi is an open-source, Node.js based, Headless CMS that saves developers a lot of development time, enabling them to build their application backends quickly by decreasing the lines of code necessary.

You can use Upstash's HTTP and Redis based [Ratelimit package](https://github.com/upstash/ratelimit-js) integration with Strapi to protect your APIs from abuse.

## Getting started

### Installation

<CodeGroup>
  ```bash npm theme={"system"}
  npm install --save @upstash/strapi-plugin-upstash-ratelimit
  ```

  ```bash yarn theme={"system"}
  yarn add @upstash/strapi-plugin-upstash-ratelimit
  ```
</CodeGroup>

### Create database

Create a new redis database on [Upstash Console](https://console.upstash.com/). See [related docs](/redis/overall/getstarted) for further info related to creating a database.

### Set up environment variables

Get the environment variables from [Upstash Console](https://console.upstash.com/), and set it to `.env` file as below:

```shell .env theme={"system"}
UPSTASH_REDIS_REST_TOKEN="<YOUR_TOKEN>"
UPSTASH_REDIS_REST_URL="<YOUR_URL>"
```

### Configure the plugin

You can use

<CodeGroup>
  ```typescript /config/plugins.ts theme={"system"}
  export default () => ({
    "strapi-plugin-upstash-ratelimit": {
      enabled: true,
      resolve: "./src/plugins/strapi-plugin-upstash-ratelimit",
      config: {
        enabled: true,
        token: process.env.UPSTASH_REDIS_REST_TOKEN,
        url: process.env.UPSTASH_REDIS_REST_URL,
        strategy: [
          {
            methods: ["GET", "POST"],
            path: "*",
            limiter: {
              algorithm: "fixed-window",
              tokens: 10,
              window: "20s",
            },
          },
        ],
        prefix: "@strapi",
      },
    },
  });
  ```

  ```javascript /config/plugins.js theme={"system"}
  module.exports = () => ({
    "strapi-plugin-upstash-ratelimit": {
      enabled: true,
      resolve: "./src/plugins/strapi-plugin-upstash-ratelimit",
      config: {
        enabled: true,
        token: process.env.UPSTASH_REDIS_REST_TOKEN,
        url: process.env.UPSTASH_REDIS_REST_URL,
        strategy: [
          {
            methods: ["GET", "POST"],
            path: "*",
            limiter: {
              algorithm: "fixed-window",
              tokens: 10,
              window: "20s",
            },
          },
        ],
        prefix: "@strapi",
      },
    },
  });
  ```
</CodeGroup>


# Methods
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/methods



This page contains information on what methods are available in Ratelimit and how they can be used. For information on the
cost of these operations in term of number of Redis commands, refer to the [Costs page](/redis/sdks/ratelimit-ts/costs).

## `limit`

The `limit` method is the heart of the Ratelimit algorithm.

```ts  theme={"system"}
ratelimit.limit(
  identifier: string,
  req?: {
    geo?: Geo;
    rate?: number,
    ip?: string,
    userAgent?: string,
    country?: string
  },
): Promise<RatelimitResponse>
```

It receives an identifier to rate limit. Additionally, it can be passed a `req` parameter which can contain either a
`geo` or a `rate` field. `geo` field is passed to the analytics but is not in use currently. The `rate` field determines
the amount of tokens/requests to subtract from the state of the algorithm with regards to the provided identifier.

The `limit` method returns some more metadata that might be useful to you:

````ts  theme={"system"}
export type RatelimitResponse = {
  /**
   * Whether the request may pass(true) or exceeded the limit(false)
   */
  success: boolean;
  /**
   * Maximum number of requests allowed within a window.
   */
  limit: number;
  /**
   * How many requests the user has left within the current window.
   */
  remaining: number;
  /**
   * Unix timestamp in milliseconds when the limits are reset.
   */
  reset: number;

  /**
   * For the MultiRegion setup we do some synchronizing in the background, after returning the current limit.
   * Or when analytics is enabled, we send the analytics asynchronously after returning the limit.
   * In most case you can simply ignore this.
   *
   * On Vercel Edge or Cloudflare workers, you need to explicitly handle the pending Promise like this:
   *
   * ```ts
   * const { pending } = await ratelimit.limit("id")
   * context.waitUntil(pending)
   * ```
   *
   * See `waitUntil` documentation in
   * [Cloudflare](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/#contextwaituntil)
   * and [Vercel](https://vercel.com/docs/functions/edge-middleware/middleware-api#waituntil)
   * for more details.
   * ```
   */
  pending: Promise<unknown>;

  /**
   * Reason behind the result in `success` field.
   * - Is set to "timeout" when request times out
   * - Is set to "cacheBlock" when an identifier is blocked through cache without calling redis because it was
   *    rate limited previously.
   * - Is set to "denyList" when identifier or one of ip/user-agent/country parameters is in deny list. To enable
   *    deny list, see `enableProtection` parameter. To edit the deny list, see the Upstash Ratelimit Dashboard
   *    at https://console.upstash.com/ratelimit.
   * - Is set to undefined if rate limit check had to use Redis. This happens in cases when `success` field in
   *    the response is true. It can also happen the first time sucecss is false.
   */
  reason?: RatelimitResponseType;

  /**
   * The value which was in the deny list if reason: "denyList"
   */
  deniedValue?: string;
};
````

## `blockUntilReady`

In case you don't want to reject a request immediately but wait until it can be
processed, we also provide

```ts  theme={"system"}
ratelimit.blockUntilReady(
  identifier: string,
  timeout: number
): Promise<RatelimitResponse>
```

It is very similar to the `limit` method and takes an identifier and returns the
same response. However if the current limit has already been exceeded, it will
automatically wait until the next window starts and will try again. Setting the
timeout parameter (in milliseconds) will cause the returned Promise to resolve
in a finite amount of time.

```ts  theme={"system"}
// Create a new ratelimiter, that allows 10 requests per 10 seconds
const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  analytics: true,
});

// `blockUntilReady` returns a promise that resolves as soon as the request is allowed to be processed, or after 30 seconds
const { success } = await ratelimit.blockUntilReady("id", 30_000);

if (!success) {
  return "Unable to process, even after 30 seconds";
}
doExpensiveCalculation();
return "Here you go!";
```

<Warning>
  In **Cloudflare**, `blockUntilReady` will not work as intended due to
  `Date.now()` not behaving the same as in Node environments.

  <br />

  <br />

  **For more information, check**: <br />
  [https://developers.cloudflare.com/workers/runtime-apis/web-standards](https://developers.cloudflare.com/workers/runtime-apis/web-standards)
</Warning>

## `resetUsedTokens`

This method resets the state of the algorithm with respect to some identifier:

```ts  theme={"system"}
ratelimit.resetUsedTokens(identifier: string): Promise<void>
```

## `getRemaining`

This method returns the remaining tokens/requests available for some identifier:

```ts  theme={"system"}
ratelimit.getRemaining(identifier: string): Promise<{
  remaining: number;
  reset: number;
}>
```

`remaining` is the remaining tokens. `reset` is the reset timestamp.


# Overview
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/overview



# Upstash Rate Limit

[![npm (scoped)](https://img.shields.io/npm/v/@upstash/ratelimit)](https://www.npmjs.com/package/ratelimit)

It is the only connectionless (HTTP based) rate limiting library and designed
for:

* Serverless functions (AWS Lambda, Vercel ...)
* Cloudflare Workers
* Vercel Edge
* Fastly Compute\@Edge
* Next.js, Jamstack ...
* Client side web/mobile applications
* WebAssembly
* and other environments where HTTP is preferred over TCP.

## Quick Links:

* [Github Repository](https://github.com/upstash/ratelimit)
* [Getting Started](/redis/sdks/ratelimit-ts/gettingstarted)
* [Costs](/redis/sdks/ratelimit-ts/costs)

## Features

<CardGroup cols={2}>
  <Card title="Caching" icon="shield-halved" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#caching">
    Handle blocked requests without having to call your Redis Database
  </Card>

  <Card title="Timeout" icon="stopwatch" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#timeout">
    If the Redis call of the ratelimit is not resolved in some timeframe, allow
    the request by default
  </Card>

  <Card title="Analytics & Dashboard" icon="magnifying-glass-chart" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#analytics-and-dashboard">
    Collect information on which identifiers made how many requests and how many
    were blocked
  </Card>

  <Card title="Traffic Protection" icon="lock" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/traffic-protection">
    Create a deny list to block requests based on user agents, countries, IP
    addresses and more
  </Card>

  <Card title="Custom Rates" icon="chart-simple" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#custom-rates">
    Consume different amounts of tokens in different requests (example: limiting
    based on request/response size)
  </Card>

  <Card title="Multi Region" icon="globe" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#multi-region">
    Utilize several Redis databases in different regions to serve users faster
  </Card>

  <Card title="Multiple Limits" icon="gears" href="https://upstash.com/docs/redis/sdks/ratelimit-ts/features#using-multiple-limits">
    Use different limits for different kinds of requests (example: paid and free
    users)
  </Card>
</CardGroup>

For more information about the features, see the [Features tab](/redis/sdks/ratelimit-ts/features).

## Examples

<CardGroup cols={2}>
  <Card title="Nextjs" href="https://github.com/upstash/ratelimit/tree/main/examples/nextjs">
    Rate limit an API in a Nextjs project
  </Card>

  <Card title="Nextjs with Middleware" href="https://github.com/upstash/ratelimit/tree/main/examples/nextjs-middleware">
    Rate limit an API with a Middleware in a Nextjs project
  </Card>

  <Card title="Vercel Edge" href="https://github.com/upstash/ratelimit/tree/main/examples/vercel-edge">
    Rate limit an Vercel Edge Function
  </Card>

  <Card title="Enabling Protection" href="https://github.com/upstash/ratelimit/tree/main/examples/enable-protection">
    Use Deny Lists to Protect Your Website
  </Card>

  <Card title="Cloudflare Pages" href="https://github.com/upstash/ratelimit/tree/main/examples/cloudflare-pages">
    Rate limit access to your Cloudflare Pages app
  </Card>

  <Card title="Cloudflare Workers" href="https://github.com/upstash/ratelimit/tree/main/examples/cloudflare-workers">
    Rate limit access to your Cloudflare Workers
  </Card>

  <Card title="Remix" href="https://github.com/upstash/ratelimit/tree/main/examples/remix">
    Rate limit access to a Remix App
  </Card>

  <Card title="Rate limit using Vercel KV" href="https://github.com/upstash/ratelimit/tree/main/examples/with-vercel-kv">
    Rate limit a Nexjs app using Vercel KV
  </Card>

  <Card title="Deno App" href="https://github.com/upstash/ratelimit/tree/main/examples/deno">
    Rate limit your deno app
  </Card>

  <Card title="Rate limit your Chatbot" href="https://upstash.com/blog/degree-guru#rate-limiting">
    Limiting requests to a Chatbot endpoint which streams LLM outputs
  </Card>
</CardGroup>


# Traffic Protection
Source: https://upstash.com/docs/redis/sdks/ratelimit-ts/traffic-protection



### Deny List

Imagine that you want to block requests from certain countries or from some
user agents. In this case, you can make use of deny lists introduced in
ratelimit version 1.2.1.

Deny lists allow you to block based on IP addresses, user agents, countries
and [identifiers](/redis/sdks/ratelimit-ts/methods#limit).

To enable checking the deny list in your Ratelimit client, simply pass
`enableProtection` as `true`:

```tsx  theme={"system"}
const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  enableProtection: true
  analytics: true,
});
```

When `limit` is called, the client will check whether any of these values
are in the deny list and block the request if so.

```tsx  theme={"system"}
const { success, pending, reason, deniedValue } = ratelimit.limit("userId", {
  ip: "ip-address",
  userAgent: "user-agent",
  country: "country",
});

await pending; // await pending if you have analytics enabled

console.log(success, reason, deniedValue);
// prints: false, "denyList", "ip-address"
```

If a request fails because a value was in deny list, `reason` field will
be `"denyList"`. `deniedValue` will contain the value in the deny list.
See [limit method](/redis/sdks/ratelimit-ts/methods#limit)
for more detailts.

Client also keeps a **cache** of denied values. When a value is found
in the deny list, the client stores this value in the cache. If this value
is encountered in the following requests, it is **denied without calling
Redis at all**. Items are stored in the cache for a minute. This means that if
you add a new value to the deny list, it will immediately take affect but when you
remove a value, it can take up to a minute for clients to start
accepting the value. This can significantly reduce the number of calls to Redis.

Contents of the deny lists are managed from the [Ratelimit Dashboard](/redis/sdks/ratelimit-ts/features#dashboard).
You can use the dashboard to add items to the deny list or remove them.
If you have analytics enabled, you can also view the number of denied
requests per country/ip address/user agent/identifier on the dashboard.

<img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4109580b2d51e2ac5d2b58e8cca06c88" alt="denylist.png" data-og-width="1918" width="1918" data-og-height="806" height="806" data-path="img/ratelimit/denylist.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6787833776b61679a1d838d945a9ab7f 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2ed132bcbfef39ab5fc4b5ea43dab465 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=69d92d71b68aaffa822124379e783c36 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=c30435d861669c09a0a5a6968fb41655 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=ab0803a59914b17338dfd791fc8b083d 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/ratelimit/denylist.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=94f1809b65fbc3525145a4cf37d9c0e6 2500w" />

Note that we look for exact match when checking a value to see if it's in
the deny lists. **Pattern matching is not supported**.

### Auto IP Deny List

The Auto IP Deny List feature enables the automatic blocking of IP addresses
identified as malicious through open-source IP deny lists. This functionality
uses the [ipsum repository on GitHub](https://github.com/stamparm/ipsum),
which aggregates data from over 30 different deny lists.

To enable protection, set the enableProtection parameter to true. Once activated,
your SDK will automatically block IP addresses by leveraging the IP deny lists
when you provide the request IPs in the limit method.

```ts  theme={"system"}
const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  enableProtection: true,
});
```

The IP deny list is updated daily at 2 AM UTC. Upon expiration, the
first call to limit after 2 AM UTC will trigger an update, downloading
the latest IPs from GitHub and refreshing the list in your Redis
instance. The update process occurs asynchronously, allowing you to
return the result to the user while the IP list updates in the
background. To ensure the update completes successfully, utilize the
pending field:

```ts  theme={"system"}
const { success, pending } = await ratelimit.limit(
  content,
  {ip: "ip-address"}
);

await pending;
```

For more information on effectively using pending, refer to the
["Asynchronous synchronization between databases" section](/redis/sdks/ratelimit-ts/features#asynchronous-synchronization-between-databases).

Blocked IPs will be listed in the "Denied" section of the Ratelimit
dashboard, providing a clear overview of the addresses that have
been automatically blocked.

If you prefer to disable the Auto IP Deny List feature while still
using the deny lists, you can do so via the [Ratelimit dashboard on
the Upstash Console](https://console.upstash.com/ratelimit).


# Advanced
Source: https://upstash.com/docs/redis/sdks/ts/advanced



## Disable automatic serialization

Your data is (de)serialized as `json` by default. This works for most use cases
but you can disable it if you want:

```ts  theme={"system"}
const redis = new Redis({
  // ...
  automaticDeserialization: false,
});

// or
const redis = Redis.fromEnv({
  automaticDeserialization: false,
});
```

This probably breaks quite a few types, but it's a first step in that direction.
Please report bugs and broken types
[here](https://github.com/upstash/upstash-redis/issues/49).

## Keep-Alive

`@upstash/redis` optimizes performance by reusing connections wherever possible, reducing latency.
This is achieved by keeping the client in memory instead of reinitializing it with each new function invocation.
As a result, when a hot lambda function receives a new request, it uses the already initialized client, allowing for the reuse of existing connections to Upstash.

<Tip>This functionality is enabled by default.</Tip>

## Request Timeout

You can configure the SDK so that it will throw an error if the request takes longer than a specified time.

You can achieve this using the signal parameter like this:

```ts  theme={"system"}
try {
  const redis = new Redis({
    url: "<UPSTASH_REDIS_REST_URL>",
    token: "<UPSTASH_REDIS_REST_TOKEN>",
    // set a timeout of 1 second
    signal: () => AbortSignal.timeout(1000),
  });
} catch (error) {
  if (error.name === "TimeoutError") {
    console.error("Request timed out");
  } else {
    console.error("An error occurred:", error);
  }
}
```

## Telemetry

This library sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Deno, Cloudflare, Vercel)
* Runtime version ([node@18.x](mailto:node@18.x))

You can opt out by setting the `UPSTASH_DISABLE_TELEMETRY` environment variable
to any truthy value.

```sh  theme={"system"}
UPSTASH_DISABLE_TELEMETRY=1
```

Alternatively, you can pass `enableTelemetry: false` when initializing the Redis client:

```ts  theme={"system"}
const redis = new Redis({
  // ...,
  enableTelemetry: false,
});
```


# ECHO
Source: https://upstash.com/docs/redis/sdks/ts/commands/auth/echo



Returns a message back to you. Useful for debugging the connection.

## Arguments

<ParamField body="message" type="string" required>
  A message to send to the server.
</ParamField>

## Response

<ResponseField type="string" required>
  The same message you sent.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const response = await redis.echo("hello world");
  console.log(response); // "hello world"
  ```
</RequestExample>


# PING
Source: https://upstash.com/docs/redis/sdks/ts/commands/auth/ping

Send a ping to the server and get a response if the server is alive.

## Arguments

No arguments

## Response

<ResponseField type="string" required>
  `PONG`
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const response = await redis.ping();
  console.log(response); // "PONG"
  ```
</RequestExample>


# BITCOUNT
Source: https://upstash.com/docs/redis/sdks/ts/commands/bitmap/bitcount

Count the number of set bits.

The `BITCOUNT` command in Redis is used to count the number of set bits (bits with a value of 1) in a range of bytes within a key that is stored as a binary string. It is primarily used for bit-level operations on binary data stored in Redis.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="start" type="integer">
  Specify the range of bytes within the binary string to count the set bits. If not provided, it counts set bits in the entire string.

  Either specify both `start` and `end` or neither.
</ParamField>

<ParamField body="end" type="integer">
  Specify the range of bytes within the binary string to count the set bits. If not provided, it counts set bits in the entire string.

  Either specify both `start` and `end` or neither.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of set bits in the specified range.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const bits = await redis.bitcount(key);
  ```

  ```ts With Range theme={"system"}
  const bits = await redis.bitcount(key, 5, 10);
  ```
</RequestExample>


# BITOP
Source: https://upstash.com/docs/redis/sdks/ts/commands/bitmap/bitop

Perform bitwise operations between strings.

The `BITOP` command in Redis is used to perform bitwise operations on multiple keys (or Redis strings) and store the result in a destination key. It is primarily used for performing logical AND, OR, XOR, and NOT operations on binary data stored in Redis.

## Arguments

<ParamField body="operation" type="AND | OR | XOR | NOT" required>
  Specifies the type of bitwise operation to perform, which can be one of the following: `AND`, `OR`, `XOR`, or `NOT`.
</ParamField>

<ParamField body="destinationKey" type="string" required>
  The key to store the result of the operation in.
</ParamField>

<ParamField body="sourceKeys" type="...string[]" required>
  One or more keys to perform the operation on.
</ParamField>

## Response

<ResponseField type="integer" required>
  The size of the string stored in the destination key.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
   await redis.bitop("AND", "destKey", "sourceKey1", "sourceKey2");
  ```
</RequestExample>


# BITPOS
Source: https://upstash.com/docs/redis/sdks/ts/commands/bitmap/bitpos

Find the position of the first set or clear bit (bit with a value of 1 or 0) in a Redis string key.

## Arguments

<ParamField body="key" type="string" required>
  The key to search in.
</ParamField>

<ParamField body="bit" type="0 | 1" required>
  The key to store the result of the operation in.
</ParamField>

<ParamField body="start" type="number">
  The index to start searching at.
</ParamField>

<ParamField body="end" type="number">
  The index to stop searching at.
</ParamField>

## Response

<ResponseField type="integer" required>
  The index of the first occurrence of the bit in the string.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
   await redis.bitpos("key", 1);
  ```

  ```ts With Range theme={"system"}
   await redis.bitpos("key", 1, 5, 20);
  ```
</RequestExample>


# GETBIT
Source: https://upstash.com/docs/redis/sdks/ts/commands/bitmap/getbit

Retrieve a single bit.

## Arguments

<ParamField body="key" type="string" required>
  The key of the bitset
</ParamField>

<ParamField body="offset" type="integer" required>
  Specify the offset at which to get the bit.
</ParamField>

## Response

<ResponseField type="integer" required>
  The bit value stored at offset.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const bit = await redis.getbit(key, 4);
  ```
</RequestExample>


# SETBIT
Source: https://upstash.com/docs/redis/sdks/ts/commands/bitmap/setbit

Set a single bit in a string.

## Arguments

<ParamField body="key" type="string" required>
  The key of the bitset
</ParamField>

<ParamField body="offset" type="integer" required>
  Specify the offset at which to set the bit.
</ParamField>

<ParamField body="value" type="0 | 1" required>
  The bit to set
</ParamField>

## Response

<ResponseField type="0 | 1" required>
  The original bit value stored at offset.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const originalBit = await redis.setbit(key, 4, 1);
  ```
</RequestExample>


# DEL
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/del

Removes the specified keys. A key is ignored if it does not exist.

## Arguments

<ParamField body="keys" type="...string[]" required>
  One or more keys to remove.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of keys that were removed.
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  await redis.del("key1", "key2");
  ```

  ```ts Array theme={"system"}
  // in case you have an array of keys
  const keys = ["key1", "key2"];
  await redis.del(...keys)

  ```
</RequestExample>


# EXISTS
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/exists

Check if a key exists.

## Arguments

<ParamField body="keys" type="...string[]" required>
  One or more keys to check.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of keys that exist
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key1", "value1")
  await redis.set("key2", "value2")
  const keys = await redis.exists("key1", "key2", "key3");
  console.log(keys) // 2
  ```
</RequestExample>


# EXPIRE
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/expire

Sets a timeout on key. The key will automatically be deleted.

## Arguments

<ParamField body="key" type="string" required>
  The key to set the timeout on.
</ParamField>

<ParamField body="seconds" type="integer">
  How many seconds until the key should be deleted.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the timeout was set, `0` otherwise
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("mykey", "Hello");
  await redis.expire("mykey", 10);
  ```
</RequestExample>


# EXPIREAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/expireat

Sets a timeout on key. The key will automatically be deleted.

## Arguments

<ParamField body="key" type="string" required>
  The key to set the timeout on.
</ParamField>

<ParamField body="unix" type="integer">
  A unix timestamp in seconds at which point the key will expire.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the timeout was set, `0` otherwise
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("mykey", "Hello");
  const tenSecondsFromNow = Math.floor(Date.now() / 1000) + 10;
  await redis.expireat("mykey", tenSecondsFromNow);
  ```
</RequestExample>


# KEYS
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/keys

Returns all keys matching pattern.

<Warning>
  This command may block the DB for a long time, depending on its size. We advice against using it in production. Use [SCAN](/redis/sdks/ts/commands/generic/scan) instead.
</Warning>

## Arguments

<ParamField body="match" type="string" required>
  A glob-style pattern. Use `*` to match all keys.
</ParamField>

## Response

<ResponseField type="string[]" required>
  Array of keys matching the pattern.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const keys = await redis.keys("prefix*");
  ```

  ```ts Match All theme={"system"}
  const keys = await redis.keys("*");
  ```
</RequestExample>


# PERSIST
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/persist

Remove any timeout set on the key.

## Arguments

<ParamField body="key" type="string" required>
  The key to persist
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the timeout was removed, `0` if `key` does not exist or does not have an associated timeout.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.persist(key);
  ```
</RequestExample>


# PEXPIRE
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/pexpire

Sets a timeout on key. After the timeout has expired, the key will automatically be deleted.

## Arguments

<ParamField body="key" type="string" required>
  The key to expire.
</ParamField>

<ParamField body="milliseconds" type="integer">
  The number of milliseconds until the key expires.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the timeout was applied, `0` if `key` does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
   await redis.pexpire(key, 60_000); // 1 minute
  ```
</RequestExample>


# PEXPIREAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/pexpireat

Sets a timeout on key. After the timeout has expired, the key will automatically be deleted.

## Arguments

<ParamField body="key" type="string" required>
  The key to expire.
</ParamField>

<ParamField body="unixmilli" type="integer">
  The unix timestamp in milliseconds at which the key will expire.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the timeout was applied, `0` if `key` does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const 10MinutesFromNow = Date.now() + 10 * 60 * 1000;
   await redis.pexpireat(key, 10MinutesFromNow);
  ```
</RequestExample>


# PTTL
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/pttl

Return the expiration in milliseconds of a key.

## Arguments

<ParamField body="key" type="string" required>
  The key
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of milliseconds until this expires, negative if the key does not exist or does not have an expiration set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const millis = await redis.pttl(key);
  ```
</RequestExample>


# RANDOMKEY
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/randomkey

Returns a random key from database

## Arguments

No arguments

## Response

<ResponseField type="string" required>
  A random key from database, or `null` when database is empty.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const key = await redis.randomkey();
  ```
</RequestExample>


# RENAME
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/rename

Rename a key

## Arguments

<ParamField body="source" type="string" required>
  The original key.
</ParamField>

<ParamField body="destination" type="string" required>
  A new name for the key.
</ParamField>

## Response

<ResponseField type="string" required>
  `OK`
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
   await redis.rename("old", "new");
  ```
</RequestExample>


# RENAMENX
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/renamenx

Rename a key if it does not already exist.

## Arguments

<ParamField body="source" type="string" required>
  The original key.
</ParamField>

<ParamField body="destination" type="string" required>
  A new name for the key.
</ParamField>

## Response

<ResponseField type="0 | 1" required>
  `1` if key was renamed, `0` if key was not renamed.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const renamed = await redis.renamenx("old", "new");
  ```
</RequestExample>


# SCAN
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/scan

Scan the database for keys.

## Arguments

<ParamField body="cursor" type="string">
  The cursor value. Start with "0" on the first call, then use the cursor
  returned by each call for the next. It's a string to safely support large
  numbers that might exceed JavaScript's number limits.
</ParamField>

<ParamField body="options" type="Object">
  <ParamField body="match" type="string">
    Glob-style pattern to filter by field names.
  </ParamField>

  <ParamField body="count" type="number">
    Number of fields to return per call.
  </ParamField>

  <ParamField body="type" type="string">
    Filter by type. For example `string`, `hash`, `set`, `zset`, `list`,
    `stream`.
  </ParamField>
</ParamField>

## Response

<ResponseField type="[string, string[]]" required>
  Returns the next cursor and the list of matching keys. When the returned
  cursor is "0", the scan is complete.
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  const [cursor, keys] = await redis.scan(0, { match: "*" });
  ```
</RequestExample>


# TOUCH
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/touch

Alters the last access time of one or more keys

## Arguments

<ParamField body="keys" type="...string[]" required>
  One or more keys.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of keys that were touched.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.touch("key1", "key2", "key3");
  ```
</RequestExample>


# TTL
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/ttl

Return the expiration in seconds of a key.

## Arguments

<ParamField body="key" type="string" required>
  The key
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of seconds until this expires, negative if the key does not exist or does not have an expiration set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const seconds = await redis.ttl(key);
  ```
</RequestExample>


# TYPE
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/type

Get the type of a key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="string" required>
  The type of the key.

  One of `string` | `list` | `set` | `zset` | `hash` | `none`
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", "value");
  const t = await redis.type("key");
  console.log(t) // "string"
  ```
</RequestExample>


# UNLINK
Source: https://upstash.com/docs/redis/sdks/ts/commands/generic/unlink

Removes the specified keys. A key is ignored if it does not exist.

## Arguments

<ParamField body="keys" type="...string[]" required>
  One or more keys to unlink.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of keys that were unlinked.
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  await redis.unlink("key1", "key2");
  ```

  ```ts Array theme={"system"}
  // in case you have an array of keys
  const keys = ["key1", "key2"];
  await redis.unlink(...keys)

  ```
</RequestExample>


# HDEL
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hdel

Deletes one or more hash fields.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="fields" required>
  One or more fields to delete.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of fields that were removed from the hash.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hdel(key, 'field1', 'field2');
  // returns 5
  ```
</RequestExample>


# HEXISTS
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hexists

Checks if a field exists in a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="field" type="string" required>
  The field to check.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the hash contains `field`. `0` if the hash does not contain `field`, or `key` does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", "field", "value");
  const exists = await redis.hexists("key", "field");

  console.log(exists); // 1
  ```
</RequestExample>


# HEXPIRE
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hexpire

Sets an expiration time for one or more fields in a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string | number | (string | number)[]" required>
  The field or fields to set an expiration time for.
</ParamField>

<ParamField body="seconds" type="number" required>
  The time-to-live (TTL) in seconds.
</ParamField>

<ParamField body="option" type="string" optional>
  Optional condition for setting the expiration:

  * `NX`: Set the expiration only if the field does not already have an expiration.
  * `XX`: Set the expiration only if the field already has an expiration.
  * `GT`: Set the expiration only if the new TTL is greater than the current TTL.
  * `LT`: Set the expiration only if the new TTL is less than the current TTL.
</ParamField>

## Response

<ResponseField type="number[]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HEXPIRE documentation](https://redis.io/commands/hexpire).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  const expirationSet = await redis.hexpire("my-key", "my-field", 1);

  console.log(expirationSet); // 1
  ```
</RequestExample>


# HEXPIREAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hexpireat

Sets an expiration time for field(s) in a hash in seconds since the Unix epoch.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to set an expiration time for.
</ParamField>

<ParamField body="timestamp" type="number" required>
  The expiration time as a Unix timestamp in seconds.
</ParamField>

<ParamField body="option" type="string" optional>
  Optional condition for setting the expiration:

  * `NX`: Set the expiration only if the field does not already have an expiration.
  * `XX`: Set the expiration only if the field already has an expiration.
  * `GT`: Set the expiration only if the new TTL is greater than the current TTL.
  * `LT`: Set the expiration only if the new TTL is less than the current TTL.
</ParamField>

## Response

<ResponseField type="number[]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HEXPIREAT documentation](https://redis.io/commands/hexpireat).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  const expirationSet = await redis.hexpireat("my-key", "my-field", Math.floor(Date.now() / 1000) + 10);

  console.log(expirationSet); // [1]
  ```
</RequestExample>


# HEXPIRETIME
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hexpiretime

Retrieves the expiration time of field(s) in a hash in seconds.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to retrieve the expiration time for.
</ParamField>

## Response

<ResponseField type="number[]" required>
  The expiration time in seconds since the Unix epoch for each field.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HEXPIRETIME documentation](https://redis.io/commands/hexpiretime).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  await redis.hexpireat("my-key", "my-field", Math.floor(Date.now() / 1000) + 10);
  const expireTime = await redis.hexpiretime("my-key", "my-field");

  console.log(expireTime); // e.g., [1697059200]
  ```
</RequestExample>


# HGET
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hget

Retrieves the value of a hash field.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="field" type="string" required>
  The field to get.
</ParamField>

## Response

<ResponseField type="TValue | null" required>
  The value of the field, or `null`, when field is not present in the hash or key does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {field: "value"});
  const field = await redis.hget("key", "field");
  console.log(field); // "value"
  ```
</RequestExample>


# HGETALL
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hgetall

Retrieves all fields from a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="TValue | null" required>
  An object with all fields in the hash.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    field1: "value1",
    field2: "value2",
    });
  const hash = await redis.hgetall("key");
  console.log(hash); // { field1: "value1", field2: "value2" }
  ```
</RequestExample>


# HINCRBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hincrby

Increments the value of a hash field by a given amount

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string" required>
  The field to increment
</ParamField>

<ParamField body="increment" type="integer" required>
  How much to increment the field by. Can be negative to subtract.
</ParamField>

## Response

<ResponseField type="integer" required>
  The new value of the field after the increment.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    field: 20,
    });
  const after = await redis.hincrby("key", "field", 2);
  console.log(after); // 22
  ```
</RequestExample>


# HINCRBYFLOAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hincrbyfloat

Increments the value of a hash field by a given float value.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string" required>
  The field to increment
</ParamField>

<ParamField body="increment" type="float" required>
  How much to increment the field by. Can be negative to subtract.
</ParamField>

## Response

<ResponseField type="float" required>
  The new value of the field after the increment.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    field: 20,
    });
  const after = await redis.hincrby("key", "field", 2.5);
  console.log(after); // 22.5
  ```
</RequestExample>


# HKEYS
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hkeys

Return all field names in the hash stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="string[]" required>
  The field names of the hash
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    });
  const fields = await redis.hkeys("key");
  console.log(fields); // ["id", "username"]
  ```
</RequestExample>


# HLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hlen

Returns the number of fields contained in the hash stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="integer" required>
  How many fields are in the hash.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    });
  const fields = await redis.hlen("key");
  console.log(fields); // 2
  ```
</RequestExample>


# HMGET
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hmget

Return the requested fields and their values.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="...string[]" required>
  One or more fields to get.
</ParamField>

## Response

<ResponseField type="Record<string, unknown>" required>
  An object containing the fields and their values.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas"
    });
  const fields = await redis.hmget("key", "username", "name");
  console.log(fields); // { username: "chronark", name: "andreas" }
  ```
</RequestExample>


# HPERSIST
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hpersist

Remove the expiration from one or more fields in a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string | number | (string | number)[]" required>
  The field or fields to remove the expiration from.
</ParamField>

## Response

<ResponseField type="number[]" required>
  A list of integers indicating the result for each field:

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration set.
  * `1` if the expiration was successfully removed.

  For more details, see [HPERSIST documentation](https://redis.io/commands/hpersist).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  await redis.hpexpire("my-key", "my-field", 1000);

  const expirationRemoved = await redis.hpersist("my-key", "my-field");

  console.log(expirationRemoved); // [1]
  ```
</RequestExample>


# HPEXPIRE
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hpexpire

Sets an expiration time for a field in a hash in milliseconds.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field or list of fields within the hash to set the expiry for.
</ParamField>

<ParamField body="milliseconds" type="number" required>
  The time-to-live (TTL) in milliseconds.
</ParamField>

<ParamField body="option" type="string" optional>
  Optional condition for setting the expiration:

  * `NX`: Set the expiration only if the field does not already have an expiration.
  * `XX`: Set the expiration only if the field already has an expiration.
  * `GT`: Set the expiration only if the new TTL is greater than the current TTL.
  * `LT`: Set the expiration only if the new TTL is less than the current TTL.

  For more details, see [HPEXPIRE documentation](https://redis.io/commands/hpexpire).
</ParamField>

## Response

<ResponseField type="number[]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HPEXPIRE documentation](https://redis.io/commands/hpexpire).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  const expirationSet = await redis.hpexpire("my-key", "my-field", 1000);

  console.log(expirationSet); // [1]
  ```
</RequestExample>


# HPEXPIREAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hpexpireat

Sets an expiration time for field(s) in a hash in milliseconds since the Unix epoch.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to set an expiration time for.
</ParamField>

<ParamField body="timestamp" type="number" required>
  The expiration time as a Unix timestamp in milliseconds.
</ParamField>

<ParamField body="option" type="string" optional>
  Optional condition for setting the expiration:

  * `NX`: Set the expiration only if the field does not already have an expiration.
  * `XX`: Set the expiration only if the field already has an expiration.
  * `GT`: Set the expiration only if the new TTL is greater than the current TTL.
  * `LT`: Set the expiration only if the new TTL is less than the current TTL.
</ParamField>

## Response

<ResponseField type="number[]" required>
  A list of integers indicating whether the expiry was successfully set.

  * `-2` if the field does not exist in the hash or if key doesn't exist.
  * `0` if the expiration was not set due to the condition.
  * `1` if the expiration was successfully set.
  * `2` if called with 0 seconds/milliseconds or a past Unix time.

  For more details, see [HPEXPIREAT documentation](https://redis.io/commands/hpexpireat).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  const expirationSet = await redis.hpexpireat("my-key", "my-field", Date.now() + 1000);

  console.log(expirationSet); // [1]
  ```
</RequestExample>


# HPEXPIRETIME
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hpexpiretime

Retrieves the expiration time of a field in a hash in milliseconds.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to retrieve the expiration time for.
</ParamField>

## Response

<ResponseField type="integer" required>
  The expiration time in milliseconds since the Unix epoch.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HPEXPIRETIME documentation](https://redis.io/commands/hpexpiretime).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  await redis.hpexpireat("my-key", "my-field", Date.now() + 1000);
  const expireTime = await redis.hpexpiretime("my-key", "my-field");

  console.log(expireTime); // e.g., 1697059200000
  ```
</RequestExample>


# HPTTL
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hpttl

Retrieves the remaining time-to-live (TTL) for field(s) in a hash in milliseconds.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to retrieve the TTL for.
</ParamField>

## Response

<ResponseField type="number[]" required>
  The remaining TTL in milliseconds for each field.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HPTTL documentation](https://redis.io/commands/hpttl).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  await redis.hpexpire("my-key", "my-field", 1000);
  const ttl = await redis.hpttl("my-key", "my-field");

  console.log(ttl); // e.g., [950]
  ```
</RequestExample>


# HRANDFIELD
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hrandfield

Return a random field from a hash

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="count" type="integer">
  Optionally return more than one field.
</ParamField>

<ParamField body="withValues" type="boolean">
  Return the values of the fields as well.
</ParamField>

## Response

<ResponseField type="Record<string, unknown>" required>
  An object containing the fields and their values.
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas"
   });
  const randomField = await redis.hrandfield("key");
  console.log(randomField); // one of "id", "username" or  "name"
  ```

  ```ts Multiple Fields theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas",
  });
  const randomFields = await redis.hrandfield("key", 2);
  console.log(randomFields); // ["id", "username"] or any other combination
  ```

  ```ts With Values theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas",
  });
  const randomFields = await redis.hrandfield("key", 2, true);
  console.log(randomFields); // { id: "1", username: "chronark" } or any other combination
  ```
</RequestExample>


# HSCAN
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hscan

Scan a hash for fields.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="cursor" type="number">
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="options" type="Object">
  <ParamField body="match" type="string">
    Glob-style pattern to filter by field names.
  </ParamField>

  <ParamField body="count" type="number">
    Number of fields to return per call.
  </ParamField>
</ParamField>

## Response

<ResponseField type="[number, string[]]" required>
  The new cursor and the fields array in format `[field, value, field, value]`.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas"
   });
  const [newCursor, fields] = await redis.hscan("key", 0);
  console.log(newCursor); // likely `0` since this is a very small hash
  console.log(fields); // ["id", 1, "username", "chronark", "name", "andreas"]
  ```

  ```ts Match theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas",
  });
  const [newCursor, fields] = await redis.hscan("key", 0, { match: "user*" });
  console.log(newCursor); // likely `0` since this is a very small hash
  console.log(fields); // ["username", "chronark"]
  ```

  ```ts Count theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas",
  });
  const [newCursor, fields] = await redis.hscan("key", 0, { count: 2 });
  console.log(fields); // ["id", 1, "name", "andreas", "username", "chronark"]
  ```
</RequestExample>


# HSET
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hset

Write one or more fields to a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="{ [fieldName]: TValue }" required>
  An object of fields and their values.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of fields that were added.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    id: 1,
    username: "chronark",
    name: "andreas"
    });
  ```
</RequestExample>


# HSETNX
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hsetnx

Write a field to a hash but only if the field does not exist.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string" required>
  The name of the field.
</ParamField>

<ParamField body="value" type="TValue" required>
  Any value, if it's not a string it will be serialized to JSON.
</ParamField>

## Response

<ResponseField type="integer" required>
  `1` if the field was set, `0` if it already existed.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hsetnx("key", "id", 1)
  ```
</RequestExample>


# HSTRLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hstrlen

Returns the string length of a value in a hash.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="field" type="string" required>
  The name of the field.
</ParamField>

## Response

<ResponseField type="integer" required>
  `0` if the hash or field does not exist. Otherwise the length of the string.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const length = await redis.hstrlen("key", "field")
  ```
</RequestExample>


# HTTL
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/httl

Retrieves the remaining time-to-live (TTL) for field(s) in a hash in seconds.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

<ParamField body="fields" type="string | number | (string | number)[]" required>
  The field(s) to retrieve the TTL for.
</ParamField>

## Response

<ResponseField type="number[]" required>
  The remaining TTL in seconds for each field.

  * `-2` if the field does not exist in the hash or if the key doesn't exist.
  * `-1` if the field exists but has no associated expiration.

  For more details, see [HTTL documentation](https://redis.io/commands/httl).
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("my-key", "my-field", "my-value");
  await redis.hexpire("my-key", "my-field", 10);
  const ttl = await redis.httl("my-key", "my-field");

  console.log(ttl); // e.g., [9]
  ```
</RequestExample>


# HVALS
Source: https://upstash.com/docs/redis/sdks/ts/commands/hash/hvals

Returns all values in the hash stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the hash.
</ParamField>

## Response

<ResponseField type="unknown[]" required>
  All values in the hash, or an empty list when key does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.hset("key", {
    field1: "Hello",
    field2: "World",
  })
  const values = await redis.hvals("key")
  console.log(values) // ["Hello", "World"]
  ```
</RequestExample>


# JSON.ARRAPPEND
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrappend

Append values to the array at path in the JSON document at key.

<Tip>
  To specify a string as an array value to append, wrap the quoted string with an additional set of single quotes. Example: '"silver"'.
</Tip>

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="value" type="...TValue[]" required>
  One or more values to append to the array.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The length of the array after the appending.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.arrappend("key", "$.path.to.array", "a");
  ```
</RequestExample>


# JSON.ARRINDEX
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrindex

Search for the first occurrence of a JSON value in an array.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="value" type="TValue" required>
  The value to search for.
</ParamField>

<ParamField body="start" type="integer" default={0}>
  The start index.
</ParamField>

<ParamField body="stop" type="integer" default={0}>
  The stop index.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The index of the first occurrence of the value in the array, or -1 if not found.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const index = await redis.json.arrindex("key", "$.path.to.array", "a");
  ```
</RequestExample>


# JSON.ARRINSERT
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrinsert

Insert the json values into the array at path before the index (shifts to the right).

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="index" type="integer" required>
  The index where to insert the values.
</ParamField>

<ParamField body="values" type="...TValue[]" required>
  One or more values to append to the array.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The length of the array after the insertion.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const length = await redis.json.arrinsert("key", "$.path.to.array", 2, "a", "b");
  ```
</RequestExample>


# JSON.ARRLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrlen

Report the length of the JSON array at `path` in `key`.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The length of the array.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const length = await redis.json.arrlen("key", "$.path.to.array");
  ```
</RequestExample>


# JSON.ARRPOP
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrpop

Remove and return an element from the index in the array. By default the last element from an array is popped.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string">
  The path of the array.
</ParamField>

<ParamField body="index" type="number" default={-1}>
  The index of the element to pop.
</ParamField>

## Response

<ResponseField type="(TValue | null)[]" required>
  The popped element or null if the array is empty.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const element = await redis.json.arrpop("key", "$.path.to.array");
  ```

  ```ts First theme={"system"}
  const firstElement = await redis.json.arrpop("key", "$.path.to.array", 0);
  ```
</RequestExample>


# JSON.ARRTRIM
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/arrtrim

Trim an array so that it contains only the specified inclusive range of elements.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="start" type="integer" required>
  The start index of the range.
</ParamField>

<ParamField body="stop" type="integer" required>
  The stop index of the range.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The length of the array after the trimming.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const length = await redis.json.arrtrim("key", "$.path.to.array", 2, 10);
  ```
</RequestExample>


# JSON.CLEAR
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/clear

Clear container values (arrays/objects) and set numeric values to 0.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path to clear
</ParamField>

## Response

<ResponseField type="integer[]" required>
  How many values were cleared.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.clear("key");
  ```

  ```ts With path theme={"system"}
  await redis.json.clear("key", "$.my.key");
  ```
</RequestExample>


# JSON.DEL
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/del

Delete a key from a JSON document.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path to delete
</ParamField>

## Response

<ResponseField type="integer" required>
  How many paths were deleted.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.del("key", "$.path.to.value");
  ```
</RequestExample>


# JSON.FORGET
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/forget

Delete a key from a JSON document.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path to forget.
</ParamField>

## Response

<ResponseField type="integer" required>
  How many paths were deleted.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.forget("key", "$.path.to.value");
  ```
</RequestExample>


# JSON.GET
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/get

Get a single value from a JSON document.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="options">
  <Expandable>
    <ParamField body="indent" type="string">
      Sets the indentation string for nested levels.
    </ParamField>

    <ParamField body="newline" type="string">
      Sets the string that's printed at the end of each line.
    </ParamField>

    <ParamField body="space" type="string">
      Sets the string that is put between a key and a value.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="paths" type="...string[]" default="$">
  One or more paths to retrieve from the JSON document.
</ParamField>

## Response

<ResponseField type="(TValue | null)[]" required>
  The value at the specified path or `null` if the path does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const value = await redis.json.get("key", "$.path.to.somewhere");
  ```

  ```ts With Options theme={"system"}
  const value = await redis.json.get("key", {
      indent: "  ",
      newline: "\n",
      space: " ",
  }, "$.path.to.somewhere");
  ```
</RequestExample>


# JSON.MERGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/merge

Merges the JSON value at path in key with the provided value.

## Arguments

<ParamField body="key" type="str" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="str" required>
  The path of the value to set.
</ParamField>

<ParamField body="value" type="string | number | Record<string, unknown> | Array<unknown>" required>
  The value to merge with.
</ParamField>

## Response

<ResponseField type="string" required>
  Returns "OK" if the merge was successful.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.merge("key", "$.path.to.value", {"new": "value"})
  ```
</RequestExample>


# JSON.MGET
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/mget

Get the same path from multiple JSON documents.

## Arguments

<ParamField body="keys" type="...string[]" required>
  One or more keys of JSON documents.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path to get from the JSON document.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The values at the specified path or `null` if the path does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const values = await redis.json.mget(["key1", "key2"],  "$.path.to.somewhere");
  ```
</RequestExample>


# JSON.MSET
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/mset

Sets multiple JSON values at multiple paths in multiple keys.

## Arguments

<ParamField body="params" type="{ key: string, path: string, value: TData }[]" required>
  A list of objects where each tuple contains a key, a path, and a value.
  Type of value (`TData`) can be `Array<number>`, `string`, `boolean`, `Record<string, any>`, or `Array<any>`.
</ParamField>

## Response

<ResponseField type="string" required>
  Returns "OK" if the command was successful.
</ResponseField>

<RequestExample>
  ```py Example theme={"system"}
  await redis.json.mset([
    { key: key, path: "$.path", value: value}, 
    { key: key2, path: "$.path2", value: value2}
  ])
  ```
</RequestExample>


# JSON.NUMINCRBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/numincrby

Increment the number value stored at `path` by number.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="increment" type="number" required>
  The number to increment by.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The new value after incrementing
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const newValue = await redis.json.numincrby("key", "$.path.to.value", 2);
  ```
</RequestExample>


# JSON.NUMMULTBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/nummultby

Multiply the number value stored at `path` by number.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

<ParamField body="multiply" type="number" required>
  The number to multiply by.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The new value after multiplying
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const newValue = await redis.json.nummultby("key", "$.path.to.value", 2);
  ```
</RequestExample>


# JSON.OBJKEYS
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/objkeys

Return the keys in the object that`s referenced by path.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

## Response

<ResponseField type="string[][]" required>
  The keys of the object at the path.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const keys = await redis.json.objkeys("key", "$.path");
  ```
</RequestExample>


# JSON.OBJLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/objlen

Report the number of keys in the JSON object at `path` in `key`.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the object.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The number of keys in the objects.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const lengths = await redis.json.objlen("key", "$.path");
  ```
</RequestExample>


# JSON.SET
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/set

Set the JSON value at path in key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the value to set.
</ParamField>

<ParamField body="value" type="TValue" required>
  The value to set.
</ParamField>

## Response

<ResponseField type="OK" required>
  `OK`
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  Set the JSON value at path in key.
  redis.json.set(key, "$.path", value);
  ```

  ```ts NX theme={"system"}
  const value = ...
  redis.json.set(key, "$.path", value, { nx:true });
  ```

  ```ts XX theme={"system"}
  const value = ...
  redis.json.set(key, "$.path", value, { xx:true });
  ```
</RequestExample>


# JSON.STRAPPEND
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/strappend

Append the json-string values to the string at path.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the value.
</ParamField>

<ParamField body="value" type="string" required>
  The value to append to the existing string.
</ParamField>

## Response

<ResponseField type="integer[]" required>
  The length of the array after the appending.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.strappend("key", "$.path.to.str", "abc");
  ```
</RequestExample>


# JSON.STRLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/strlen

Report the length of the JSON String at path in key

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the array.
</ParamField>

## Response

<ResponseField type="array" required>
  JSON.STRLEN returns by recursive descent an array of integer replies for each path, the array's length, or nil, if the matching JSON value is not a string.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.json.strlen("key", "$.path.to.str", "a");
  ```
</RequestExample>


# JSON.TOGGLE
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/toggle

Toggle a boolean value stored at `path`.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the boolean.
</ParamField>

## Response

<ResponseField type="boolean" required>
  The new value of the boolean.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const bool = await redis.json.toggle("key", "$.path.to.bool");
  ```
</RequestExample>


# JSON.TYPE
Source: https://upstash.com/docs/redis/sdks/ts/commands/json/type

Report the type of JSON value at `path`.

## Arguments

<ParamField body="key" type="string" required>
  The key of the json entry.
</ParamField>

<ParamField body="path" type="string" default="$">
  The path of the value.
</ParamField>

## Response

<ResponseField type="(string | null)[]" required>
  The type of the value at `path` or `null` if the value does not exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const myType = await redis.json.type("key", "$.path.to.value");
  ```
</RequestExample>


# LINDEX
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lindex

Returns the element at index index in the list stored at key.

The index is zero-based, so 0 means the first element, 1 the second element and so on. Negative indices can be used to designate elements starting at the tail of the list.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="index" type="number" required>
  The index of the element to return, zero-based.
</ParamField>

## Response

<ResponseField type="TValue | null" required>
  The value of the element at index index in the list. If the index is out of range, `null` is returned.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.rpush("key", "a", "b", "c");
  const element = await redis.lindex("key", 0);
  console.log(element); // "a"
  ```
</RequestExample>


# LINSERT
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/linsert

Insert an element before or after another element in a list

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="direction" type="before | after" required>
  Whether to insert the element before or after pivot.
</ParamField>

<ParamField body="pivot" type="TValue" required>
  The element to insert before or after.
</ParamField>

<ParamField body="value" type="TValue" required>
  The element to insert.
</ParamField>

## Response

<ResponseField type="integer" required>
  The list length after insertion, `0` when the list doesn't exist or `-1` when pivot was not found.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.rpush("key", "a", "b", "c");
  await redis.linsert("key", "before", "b", "x");
  ```
</RequestExample>


# LLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/llen

Returns the length of the list stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list at key.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.rpush("key", "a", "b", "c");
  const length = await redis.llen("key");
  console.log(length); // 3
  ```
</RequestExample>


# LMOVE
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lmove

Move an element from one list to another.

## Arguments

<ParamField body="source" type="string" required>
  The key of the source list.
</ParamField>

<ParamField body="destination" type="string" required>
  The key of the destination list.
</ParamField>

<ParamField body="from" type="&#x22;left&#x22; | &#x22;right&#x22;" required>
  The side of the source list from which the element was popped.
</ParamField>

<ParamField body="to" type="&#x22;left&#x22; | &#x22;right&#x22;" required>
  The side of the destination list to which the element was pushed.
</ParamField>

## Response

<ResponseField type="TValue" required>
  The element that was moved.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
   await redis.rpush("source", "a", "b", "c"); 
   const element = await redis.move("source", "destination", "left", "left");  
  ```
</RequestExample>


# LPOP
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lpop

Remove and return the first element(s) of a list

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="integer">
  How many elements to pop. If not specified, a single element is popped.
</ParamField>

## Response

<ResponseField type="TValue | TValue[] | null" required>
  The popped element(s). If `count` was specified, an array of elements is
  returned, otherwise a single element is returned. If the list is empty, `null`
  is returned.
</ResponseField>

<RequestExample>
  ```ts Single  theme={"system"}
  await redis.rpush("key", "a", "b", "c"); 
  const element = await redis.lpop("key");
  console.log(element); // "a"
  ```

  ```ts Multiple  theme={"system"}
  await redis.rpush("key", "a", "b", "c"); 
  const element = await redis.lpop("key", 2);
  console.log(element); // ["a", "b"]
  ```
</RequestExample>


# LPOS
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lpos

Returns the index of matching elements inside a list.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="element" type="unknown" required>
  The element to match.
</ParamField>

<ParamField body="opts">
  <ParamField body="rank" type="number">
    The rank of the element to match. If specified, the element at the given
    rank is matched instead of the first element.
  </ParamField>

  <ParamField body="count" type="number">
    The maximum number of elements to match. If specified, an array of elements
    is returned instead of a single element.
  </ParamField>

  <ParamField body="maxLen" type="number">
    Limit the number of comparisons to perform.
  </ParamField>
</ParamField>

## Response

<ResponseField type="number | number[]" required>
  The index of the matching element or an array of indexes if `opts.count` is
  specified.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.rpush("key", "a", "b", "c"); 
  const index = await redis.lpos("key", "b");
  console.log(index); // 1
  ```

  ```ts With Rank  theme={"system"}
  await redis.rpush("key", "a", "b", "c", "b"); 
  const index = await redis.lpos("key", "b", { rank: 2 });
  console.log(index); // 3
  ```

  ```ts With Count theme={"system"}
  await redis.rpush("key", "a", "b", "b");
  const positions = await redis.lpos("key", "b", { count: 2 });
  console.log(positions); // [1, 2]
  ```
</RequestExample>


# LPUSH
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lpush

Push an element at the head of the list.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="...TValue[]" required>
  One or more elements to push at the head of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list after the push operation.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  const length1 = await redis.lpush("key", "a", "b", "c"); 
  console.log(length1); // 3
  const length2 = await redis.lpush("key", "d"); 
  console.log(length2); // 4
  ```
</RequestExample>


# LPUSHX
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lpushx

Push an element at the head of the list only if the list exists.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="...TValue[]" required>
  One or more elements to push at the head of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list after the push operation.

  `0` if the list did not exist and thus no element was pushed.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "b", "c"); 
  const length = await redis.lpushx("key", "d"); 
  console.log(length); // 4
  ```

  ```ts Without existing list  theme={"system"}
  const length = await redis.lpushx("key", "a"); 
  console.log(length); // 0
  ```
</RequestExample>


# LRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lrange

Returns the specified elements of the list stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="start" type="integer" required>
  The starting index of the range to return.

  Use negative numbers to specify offsets starting at the end of the list.
</ParamField>

<ParamField body="end" type="integer" required>
  The ending index of the range to return.

  Use negative numbers to specify offsets starting at the end of the list.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The list of elements in the specified range.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "b", "c"); 
  const elements = await redis.lrange("key", 1, 2); 
  console.log(elements) // ["b", "c"]
  ```
</RequestExample>


# LREM
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lrem

Remove the first `count` occurrences of an element from a list.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="number" required>
  How many occurrences of the element to remove.
</ParamField>

<ParamField body="element" type="TValue" required>
  The element to remove
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements removed.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "a", "b", "b", "c"); 
  const removed = await redis.lrem("key", 4, "b"); 
  console.log(removed) // 2
  ```
</RequestExample>


# LSET
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/lset

Set a value at a specific index.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="index" type="number" required>
  At which index to set the value.
</ParamField>

<ParamField body="data" type="TValue" required>
  The value to set.
</ParamField>

## Response

<ResponseField type="OK" required>
  `OK`
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "b", "c"); 
  await redis.lset("key", 1, "d"); 

  // list is now ["a", "d", "c"]
  ```
</RequestExample>


# LTRIM
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/ltrim

Trim a list to the specified range

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="start" type="number" required>
  The index of the first element to keep.
</ParamField>

<ParamField body="end" type="TValue" required>
  The index of the first element to keep.
</ParamField>

## Response

<ResponseField type="OK" required>
  `OK`
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "b", "c", "d"); 
  await redis.ltrim("key", 1, 2); 
  // the list is now ["b", "c"]
  ```
</RequestExample>


# RPOP
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/rpop

Remove and return the last element(s) of a list

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="count" type="integer">
  How many elements to pop. If not specified, a single element is popped.
</ParamField>

## Response

<ResponseField type="TValue | TValue[] | null" required>
  The popped element(s). If `count` was specified, an array of elements is
  returned, otherwise a single element is returned. If the list is empty, `null`
  is returned.
</ResponseField>

<RequestExample>
  ```ts Single  theme={"system"}
  await redis.rpush("key", "a", "b", "c"); 
  const element = await redis.rpop("key");
  console.log(element); // "c"
  ```

  ```ts Multiple  theme={"system"}
  await redis.rpush("key", "a", "b", "c"); 
  const element = await redis.rpop("key", 2);
  console.log(element); // ["c", "b"]
  ```
</RequestExample>


# RPUSH
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/rpush

Push an element at the end of the list.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="...TValue[]" required>
  One or more elements to push at the end of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list after the push operation.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  const length1 = await redis.rpush("key", "a", "b", "c"); 
  console.log(length1); // 3
  const length2 = await redis.rpush("key", "d"); 
  console.log(length2); // 4
  ```
</RequestExample>


# RPUSHX
Source: https://upstash.com/docs/redis/sdks/ts/commands/list/rpushx

Push an element at the end of the list only if the list exists.

## Arguments

<ParamField body="key" type="string" required>
  The key of the list.
</ParamField>

<ParamField body="elements" type="...TValue[]" required>
  One or more elements to push at the end of the list.
</ParamField>

## Response

<ResponseField type="number" required>
  The length of the list after the push operation.

  `0` if the list did not exist and thus no element was pushed.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.lpush("key", "a", "b", "c"); 
  const length = await redis.rpushx("key", "d"); 
  console.log(length); // 4
  ```

  ```ts Without existing list  theme={"system"}
  const length = await redis.rpushx("key", "a"); 
  console.log(length); // 0
  ```
</RequestExample>


# Overview
Source: https://upstash.com/docs/redis/sdks/ts/commands/overview

Available Commands in @upstash/redis

<AccordionGroup>
  <Accordion title="Auth">
    <CardGroup cols={3}>
      <Card title="ECHO" href="/redis/sdks/ts/commands/auth/echo">
        Echo the given string.
      </Card>

      <Card title="PING" href="/redis/sdks/ts/commands/auth/ping">
        Ping the server.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Bitmap">
    <CardGroup cols={3}>
      <Card title="BITCOUNT" href="/redis/sdks/ts/commands/bitmap/bitcount">
        Count set bits in a string.
      </Card>

      <Card title="BITOP" href="/redis/sdks/ts/commands/bitmap/bitop">
        Perform bitwise operations between strings.
      </Card>

      <Card title="BITPOS" href="/redis/sdks/ts/commands/bitmap/bitpos">
        Find first bit set or clear in a string.
      </Card>

      <Card title="GETBIT" href="/redis/sdks/ts/commands/bitmap/getbit">
        Returns the bit value at offset in the string value stored at key.
      </Card>

      <Card title="SETBIT" href="/redis/sdks/ts/commands/bitmap/setbit">
        Sets or clears the bit at offset in the string value stored at key.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Generic">
    <CardGroup cols={3}>
      <Card title="DEL" href="/redis/sdks/ts/commands/generic/del">
        Delete one or multiple keys.
      </Card>

      <Card title="EXISTS" href="/redis/sdks/ts/commands/generic/exists">
        Determine if a key exists.
      </Card>

      <Card title="EXPIRE" href="/redis/sdks/ts/commands/generic/expire">
        Set a key's time to live in seconds.
      </Card>

      <Card title="EXPIREAT" href="/redis/sdks/ts/commands/generic/expireat">
        Set the expiration for a key as a UNIX timestamp.
      </Card>

      <Card title="KEYS" href="/redis/sdks/ts/commands/generic/keys">
        Find all keys matching the given pattern.
      </Card>

      <Card title="PERSIST" href="/redis/sdks/ts/commands/generic/persist">
        Remove the expiration from a key.
      </Card>

      <Card title="PEXPIRE" href="/redis/sdks/ts/commands/generic/pexpire">
        Set a key's time to live in milliseconds.
      </Card>

      <Card title="PEXPIREAT" href="/redis/sdks/ts/commands/generic/pexpireat">
        Set the expiration for a key as a UNIX timestamp specified in milliseconds.
      </Card>

      <Card title="PTTL" href="/redis/sdks/ts/commands/generic/pttl">
        Get the time to live for a key in milliseconds.
      </Card>

      <Card title="RANDOMKEY" href="/redis/sdks/ts/commands/generic/randomkey">
        Return a random key from the keyspace.
      </Card>

      <Card title="RENAME" href="/redis/sdks/ts/commands/generic/rename">
        Rename a key.
      </Card>

      <Card title="RENAMENX" href="/redis/sdks/ts/commands/generic/renamenx">
        Rename a key, only if the new key does not exist.
      </Card>

      <Card title="SCAN" href="/redis/sdks/ts/commands/generic/scan">
        Incrementally iterate the keys space.
      </Card>

      <Card title="TOUCH" href="/redis/sdks/ts/commands/generic/touch">
        Alters the last access time of a key(s). Returns the number of existing keys specified.
      </Card>

      <Card title="TTL" href="/redis/sdks/ts/commands/generic/ttl">
        Get the time to live for a key.
      </Card>

      <Card title="TYPE" href="/redis/sdks/ts/commands/generic/type">
        Determine the type stored at key.
      </Card>

      <Card title="UNLINK" href="/redis/sdks/ts/commands/generic/unlink">
        Delete one or more keys.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Hash">
    <CardGroup cols={3}>
      <Card title="HDEL" href="/redis/sdks/ts/commands/hash/hdel" />

      <Card title="HEXISTS" href="/redis/sdks/ts/commands/hash/hexists" />

      <Card title="HEXPIRE" href="/redis/sdks/ts/commands/hash/hexpire" />

      <Card title="HEXPIREAT" href="/redis/sdks/ts/commands/hash/hexpireat" />

      <Card title="HEXPIRETIME" href="/redis/sdks/ts/commands/hash/hexpiretime" />

      <Card title="HGET" href="/redis/sdks/ts/commands/hash/hget" />

      <Card title="HGETALL" href="/redis/sdks/ts/commands/hash/hgetall" />

      <Card title="HINCRBY" href="/redis/sdks/ts/commands/hash/hincrby" />

      <Card title="HINCRBYFLOAT" href="/redis/sdks/ts/commands/hash/hincrbyfloat" />

      <Card title="HKEYS" href="/redis/sdks/ts/commands/hash/hkeys" />

      <Card title="HLEN" href="/redis/sdks/ts/commands/hash/hlen" />

      <Card title="HMGET" href="/redis/sdks/ts/commands/hash/hmget" />

      <Card title="HPERSIST" href="/redis/sdks/ts/commands/hash/hpersist" />

      <Card title="HPEXPIRE" href="/redis/sdks/ts/commands/hash/hpexpire" />

      <Card title="HPEXPIREAT" href="/redis/sdks/ts/commands/hash/hpexpireat" />

      <Card title="HPEXPIRETIME" href="/redis/sdks/ts/commands/hash/hpexpiretime" />

      <Card title="HPTTL" href="/redis/sdks/ts/commands/hash/hpttl" />

      <Card title="HRANDFIELD" href="/redis/sdks/ts/commands/hash/hrandfield" />

      <Card title="HSCAN" href="/redis/sdks/ts/commands/hash/hscan" />

      <Card title="HSET" href="/redis/sdks/ts/commands/hash/hset" />

      <Card title="HSETNX" href="/redis/sdks/ts/commands/hash/hsetnx" />

      <Card title="HSTRLEN" href="/redis/sdks/ts/commands/hash/hstrlen" />

      <Card title="HTTL" href="/redis/sdks/ts/commands/hash/httl" />

      <Card title="HVALS" href="/redis/sdks/ts/commands/hash/hvals" />
    </CardGroup>
  </Accordion>

  <Accordion title="JSON">
    <CardGroup cols={3}>
      <Card title="ARRAPPEND" href="/redis/sdks/ts/commands/json/arrappend" />

      <Card title="ARRINDEX" href="/redis/sdks/ts/commands/json/arrindex" />

      <Card title="ARRINSERT" href="/redis/sdks/ts/commands/json/arrinsert" />

      <Card title="ARRLEN" href="/redis/sdks/ts/commands/json/arrlen" />

      <Card title="ARRPOP" href="/redis/sdks/ts/commands/json/arrpop" />

      <Card title="ARRTRIM" href="/redis/sdks/ts/commands/json/arrtrim" />

      <Card title="CLEAR" href="/redis/sdks/ts/commands/json/clear" />

      <Card title="DEL" href="/redis/sdks/ts/commands/json/del" />

      <Card title="FORGET" href="/redis/sdks/ts/commands/json/forget" />

      <Card title="GET" href="/redis/sdks/ts/commands/json/get" />

      <Card title="MGET" href="/redis/sdks/ts/commands/json/mget" />

      <Card title="MSET" href="/redis/sdks/ts/commands/json/mset" />

      <Card title="MERGE" href="/redis/sdks/ts/commands/json/merge" />

      <Card title="NUMINCRBY" href="/redis/sdks/ts/commands/json/numincrby" />

      <Card title="NUMMULTBY" href="/redis/sdks/ts/commands/json/nummultby" />

      <Card title="OBJKEYS" href="/redis/sdks/ts/commands/json/objkeys" />

      <Card title="OBJLEN" href="/redis/sdks/ts/commands/json/objlen" />

      <Card title="SET" href="/redis/sdks/ts/commands/json/set" />

      <Card title="STRAPPEND" href="/redis/sdks/ts/commands/json/strappend" />

      <Card title="STRLEN" href="/redis/sdks/ts/commands/json/strlen" />

      <Card title="TOGGLE" href="/redis/sdks/ts/commands/json/toggle" />

      <Card title="TYPE" href="/redis/sdks/ts/commands/json/type" />
    </CardGroup>
  </Accordion>

  <Accordion title="List">
    <CardGroup cols={3}>
      <Card title="LINDEX" href="/redis/sdks/ts/commands/list/lindex" />

      <Card title="LINSERT" href="/redis/sdks/ts/commands/list/linsert" />

      <Card title="LLEN" href="/redis/sdks/ts/commands/list/llen" />

      <Card title="LMOVE" href="/redis/sdks/ts/commands/list/lmove" />

      <Card title="LPOP" href="/redis/sdks/ts/commands/list/lpop" />

      <Card title="LPOS" href="/redis/sdks/ts/commands/list/lpos" />

      <Card title="LPUSH" href="/redis/sdks/ts/commands/list/lpush" />

      <Card title="LPUSHX" href="/redis/sdks/ts/commands/list/lpushx" />

      <Card title="LRANGE" href="/redis/sdks/ts/commands/list/lrange" />

      <Card title="LREM" href="/redis/sdks/ts/commands/list/lrem" />

      <Card title="LSET" href="/redis/sdks/ts/commands/list/lset" />

      <Card title="LTRIM" href="/redis/sdks/ts/commands/list/ltrim" />

      <Card title="RPOP" href="/redis/sdks/ts/commands/list/rpop" />

      <Card title="RPUSH" href="/redis/sdks/ts/commands/list/rpush" />

      <Card title="RPUSHX" href="/redis/sdks/ts/commands/list/rpushx" />
    </CardGroup>
  </Accordion>

  <Accordion title="PubSub">
    <CardGroup cols={3}>
      <Card title="PUBLISH" href="/redis/sdks/ts/commands/pubsub/publish">
        Publish messages to many clients
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Scripts">
    <CardGroup cols={3}>
      <Card title="EVAL" href="/redis/sdks/ts/commands/scripts/eval" />

      <Card title="EVAL_RO" href="/redis/sdks/ts/commands/scripts/eval_ro" />

      <Card title="EVALSHA" href="/redis/sdks/ts/commands/scripts/evalsha" />

      <Card title="EVALSHA_RO" href="/redis/sdks/ts/commands/scripts/evalsha_ro" />

      <Card title="SCRIPT EXISTS" href="/redis/sdks/ts/commands/scripts/script_exists" />

      <Card title="SCRIPT FLUSH" href="/redis/sdks/ts/commands/scripts/script_flush" />

      <Card title="SCRIPT LOAD" href="/redis/sdks/ts/commands/scripts/script_load" />
    </CardGroup>
  </Accordion>

  <Accordion title="Server">
    <CardGroup cols={3}>
      <Card title="DBSIZE" href="/redis/sdks/ts/commands/server/dbsize" />

      <Card title="FLUSHALL" href="/redis/sdks/ts/commands/server/flushall" />

      <Card title="FLUSHDB" href="/redis/sdks/ts/commands/server/flushdb" />
    </CardGroup>
  </Accordion>

  <Accordion title="Set">
    <CardGroup cols={3}>
      <Card title="SADD" href="/redis/sdks/ts/commands/set/sadd" />

      <Card title="SCARD" href="/redis/sdks/ts/commands/set/scard" />

      <Card title="SDIFF" href="/redis/sdks/ts/commands/set/sdiff" />

      <Card title="SDIFFSTORE" href="/redis/sdks/ts/commands/set/sdiffstore" />

      <Card title="SINTER" href="/redis/sdks/ts/commands/set/sinter" />

      <Card title="SINTERSTORE" href="/redis/sdks/ts/commands/set/sinterstore" />

      <Card title="SISMEMBER" href="/redis/sdks/ts/commands/set/sismember" />

      <Card title="SMEMBERS" href="/redis/sdks/ts/commands/set/smembers" />

      <Card title="SMISMEMBER" href="/redis/sdks/ts/commands/set/smismember" />

      <Card title="SMOVE" href="/redis/sdks/ts/commands/set/smove" />

      <Card title="SPOP" href="/redis/sdks/ts/commands/set/spop" />

      <Card title="SRANDMEMBER" href="/redis/sdks/ts/commands/set/srandmember" />

      <Card title="SREM" href="/redis/sdks/ts/commands/set/srem" />

      <Card title="SSCAN" href="/redis/sdks/ts/commands/set/sscan" />

      <Card title="SUNION" href="/redis/sdks/ts/commands/set/sunion" />

      <Card title="SUNIONSTORE" href="/redis/sdks/ts/commands/set/sunionstore" />
    </CardGroup>
  </Accordion>

  <Accordion title="Sorted Set">
    <CardGroup cols={3}>
      <Card title="ZADD" href="/redis/sdks/ts/commands/zset/zadd" />

      <Card title="ZCARD" href="/redis/sdks/ts/commands/zset/zcard" />

      <Card title="ZCOUNT" href="/redis/sdks/ts/commands/zset/zcount" />

      <Card title="ZDIFFSTORE" href="/redis/sdks/ts/commands/zset/zdiffstore" />

      <Card title="ZINCRBY" href="/redis/sdks/ts/commands/zset/zincrby" />

      <Card title="ZINTERSTORE" href="/redis/sdks/ts/commands/zset/zinterstore" />

      <Card title="ZLEXCOUNT" href="/redis/sdks/ts/commands/zset/zlexcount" />

      <Card title="ZMSCORE" href="/redis/sdks/ts/commands/zset/zmscore" />

      <Card title="ZPOPMAX" href="/redis/sdks/ts/commands/zset/zpopmax" />

      <Card title="ZPOPMIN" href="/redis/sdks/ts/commands/zset/zpopmin" />

      <Card title="ZRANGE" href="/redis/sdks/ts/commands/zset/zrange" />

      <Card title="ZRANK" href="/redis/sdks/ts/commands/zset/zrank" />

      <Card title="ZREM" href="/redis/sdks/ts/commands/zset/zrem" />

      <Card title="ZREMRANGEBYLEX" href="/redis/sdks/ts/commands/zset/zremrangebylex" />

      <Card title="ZREMRANGEBYRANK" href="/redis/sdks/ts/commands/zset/zremrangebyrank" />

      <Card title="ZREMRANGEBYSCORE" href="/redis/sdks/ts/commands/zset/zremrangebyscore" />

      <Card title="ZREVRANK" href="/redis/sdks/ts/commands/zset/zrevrank" />

      <Card title="ZSCAN" href="/redis/sdks/ts/commands/zset/zscan" />

      <Card title="ZSCORE" href="/redis/sdks/ts/commands/zset/zscore" />

      <Card title="ZUNIONSTORE" href="/redis/sdks/ts/commands/zset/zunionstore" />
    </CardGroup>
  </Accordion>

  <Accordion title="Stream">
    <CardGroup cols={3}>
      <Card title="XADD" href="/redis/sdks/ts/commands/stream/xadd">
        Appends a new entry to a stream.
      </Card>

      <Card title="XRANGE" href="/redis/sdks/ts/commands/stream/xrange">
        Return a range of elements in a stream, with IDs matching the specified IDs interval.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="String">
    <CardGroup cols={3}>
      <Card title="APPEND" href="/redis/sdks/ts/commands/string/append">
        Append a value to a string stored at key.
      </Card>

      <Card title="DECR" href="/redis/sdks/ts/commands/string/decr">
        Decrement the integer value of a key by one.
      </Card>

      <Card title="DECRBY" href="/redis/sdks/ts/commands/string/decrby">
        Decrement the integer value of a key by the given number.
      </Card>

      <Card title="GET" href="/redis/sdks/ts/commands/string/get">
        Get the value of a key.
      </Card>

      <Card title="GETDEL" href="/redis/sdks/ts/commands/string/getdel">
        Get the value of a key and delete the key.
      </Card>

      <Card title="GETRANGE" href="/redis/sdks/ts/commands/string/getrange">
        Get a substring of the string stored at a key.
      </Card>

      <Card title="GETSET" href="/redis/sdks/ts/commands/string/getset">
        Set the string value of a key and return its old value.
      </Card>

      <Card title="INCR" href="/redis/sdks/ts/commands/string/incr">
        Increment the integer value of a key by one.
      </Card>

      <Card title="INCRBY" href="/redis/sdks/ts/commands/string/incrby">
        Increment the integer value of a key by the given amount.
      </Card>

      <Card title="INCRBYFLOAT" href="/redis/sdks/ts/commands/string/incrbyfloat">
        Increment the float value of a key by the given amount.
      </Card>

      <Card title="MGET" href="/redis/sdks/ts/commands/string/mget">
        Get the values of all the given keys.
      </Card>

      <Card title="MSET" href="/redis/sdks/ts/commands/string/mset">
        Set multiple keys to multiple values.
      </Card>

      <Card title="MSETNX" href="/redis/sdks/ts/commands/string/msetnx">
        Set multiple keys to multiple values, only if none of the keys exist.
      </Card>

      <Card title="SET" href="/redis/sdks/ts/commands/string/set">
        Set the string value of a key.
      </Card>

      <Card title="SETRANGE" href="/redis/sdks/ts/commands/string/setrange">
        Overwrite part of a string at key starting at the specified offset.
      </Card>

      <Card title="STRLEN" href="/redis/sdks/ts/commands/string/strlen">
        Get the length of the value stored in a key.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Stream">
    <CardGroup cols={3}>
      <Card title="XACK" href="/redis/sdks/ts/commands/stream/xack">
        Acknowledge one or multiple messages as processed for a consumer group.
      </Card>

      <Card title="XADD" href="/redis/sdks/ts/commands/stream/xadd">
        Append a new entry to a stream.
      </Card>

      <Card title="XAUTOCLAIM" href="/redis/sdks/ts/commands/stream/xautoclaim">
        Transfer ownership of pending messages to another consumer automatically.
      </Card>

      <Card title="XCLAIM" href="/redis/sdks/ts/commands/stream/xclaim">
        Transfer ownership of pending messages to another consumer.
      </Card>

      <Card title="XDEL" href="/redis/sdks/ts/commands/stream/xdel">
        Remove one or multiple entries from a stream.
      </Card>

      <Card title="XGROUP" href="/redis/sdks/ts/commands/stream/xgroup">
        Manage consumer groups for Redis streams.
      </Card>

      <Card title="XINFO" href="/redis/sdks/ts/commands/stream/xinfo">
        Get information about streams, consumer groups, and consumers.
      </Card>

      <Card title="XLEN" href="/redis/sdks/ts/commands/stream/xlen">
        Get the number of entries in a stream.
      </Card>

      <Card title="XPENDING" href="/redis/sdks/ts/commands/stream/xpending">
        Get information about pending messages in a consumer group.
      </Card>

      <Card title="XRANGE" href="/redis/sdks/ts/commands/stream/xrange">
        Get entries from a stream within a range of IDs.
      </Card>

      <Card title="XREAD" href="/redis/sdks/ts/commands/stream/xread">
        Read data from one or multiple streams.
      </Card>

      <Card title="XREADGROUP" href="/redis/sdks/ts/commands/stream/xreadgroup">
        Read data from streams as part of a consumer group.
      </Card>

      <Card title="XREVRANGE" href="/redis/sdks/ts/commands/stream/xrevrange">
        Get entries from a stream within a range of IDs in reverse order.
      </Card>

      <Card title="XTRIM" href="/redis/sdks/ts/commands/stream/xtrim">
        Trim a stream to a specified size.
      </Card>
    </CardGroup>
  </Accordion>

  <Accordion title="Transactions">
    <Card title="TRANSACTION" href="/redis/sdks/ts/commands/transaction">
      Run multiple commands in a transaction.
    </Card>
  </Accordion>
</AccordionGroup>


# PSUBSCRIBE
Source: https://upstash.com/docs/redis/sdks/ts/commands/pubsub/psubscribe

Subscribe to a channel by patterns/wildcards

## Arguments

<ParamField body="patterns" type="string | string[]" required>
  The patterns matching channels to publish to.
</ParamField>

## Response

<ResponseField type="Subscriber" required>
  A subscriber instance which can subscribe to channels.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const subscription = redis.psubscribe(["user:*"]);

  const messages = [];
  subscription.on("pmessage", (data) => {
    messages.push(data.message);
  });

  await redis.publish("user:123", "user:123 message"); // receives
  await redis.publish("user:456", "user:456 message"); // receives
  await redis.publish("other:789", "other:789 message"); // doesn't receive

  console.log(messages[0]) // user:123 message
  console.log(messages[1]) // user:456 message
  console.log(messages[2]) // undefined
  ```
</RequestExample>


# PUBLISH
Source: https://upstash.com/docs/redis/sdks/ts/commands/pubsub/publish

Publish a message to a channel

## Arguments

<ParamField body="channel" type="string" required>
  The channel to publish to.
</ParamField>

<ParamField body="message" type="TMessage">
  The message to publish.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of clients who received the message.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const listeners = await redis.publish("my-channel", "my-message");
  ```
</RequestExample>


# SUBSCRIBE
Source: https://upstash.com/docs/redis/sdks/ts/commands/pubsub/subscribe

Subscribe to a channel

## Arguments

<ParamField body="channels" type="string | string[]" required>
  The channel to publish to.
</ParamField>

## Response

<ResponseField type="Subscriber" required>
  A subscriber instance which can subscribe to channels.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const subscription = redis.subscribe(["my-channel"]);

  const messages = [];
  subscription.on("message", (data) => {
    messages.push(data.message);
  });
  ```
</RequestExample>


# EVAL
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/eval

Evaluate a Lua script server side.

## Arguments

<ParamField body="script" type="string" required>
  The lua script to run.
</ParamField>

<ParamField body="keys" type="string[]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="any" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const script = `
      return ARGV[1]
  `
  const result = await redis.eval(script, [], ["hello"]);
  console.log(result) // "hello"

  ```
</RequestExample>


# EVAL_RO
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/eval_ro

Evaluate a read-only Lua script server side.

## Arguments

<ParamField body="script" type="string" required>
  The read-only lua script to run.
</ParamField>

<ParamField body="keys" type="string[]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="any" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const script = `
      return ARGV[1]
  `
  const result = await redis.evalRo(script, [], ["hello"]);
  console.log(result) // "hello"

  ```
</RequestExample>


# EVALSHA
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/evalsha

Evaluate a cached Lua script server side.

`EVALSHA` is like `EVAL` but instead of sending the script over the wire every time, you reference the script by its SHA1 hash. This is useful for caching scripts on the server side.

## Arguments

<ParamField body="sha" type="string" required>
  The sha1 hash of the script.
</ParamField>

<ParamField body="keys" type="string[]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="?" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  const result = await redis.evalsha("fb67a0c03b48ddbf8b4c9b011e779563bdbc28cb", [], ["hello"]);
  console.log(result) // "hello"

  ```
</RequestExample>


# EVALSHA_RO
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/evalsha_ro

Evaluate a cached read-only Lua script server side.

`EVALSHA_RO` is like `EVAL_RO` but instead of sending the script over the wire every time, you reference the script by its SHA1 hash. This is useful for caching scripts on the server side.

## Arguments

<ParamField body="sha" type="string" required>
  The sha1 hash of the read-only script.
</ParamField>

<ParamField body="keys" type="string[]" required>
  All of the keys accessed in the script
</ParamField>

<ParamField body="args" type="unknown[]" required>
  All of the arguments you passed to the script
</ParamField>

## Response

<ResponseField type="?" required>
  The result of the script.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  const result = await redis.evalshaRo("fb67a0c03b48ddbf8b4c9b011e779563bdbc28cb", [], ["hello"]);
  console.log(result) // "hello"

  ```
</RequestExample>


# SCRIPT EXISTS
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/script_exists

Check if scripts exist in the script cache.

## Arguments

<ParamField body="hashes" type="string[]" required>
  The sha1 of the scripts to check.
</ParamField>

## Response

<ResponseField type="number[]" required>
  An array of numbers. `1` if the script exists, otherwise `0`.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.scriptExists("<sha1>", "<sha2>")

  // Returns 1 
  // [1, 0]
  ```
</RequestExample>


# SCRIPT FLUSH
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/script_flush

Removes all scripts from the script cache.

## Arguments

<ParamField body="options" type="Object">
  <ParamField body="async" type="boolean">
    Performs the flush asynchronously.
  </ParamField>

  <ParamField body="sync" type="boolean">
    Performs the flush synchronously.
  </ParamField>
</ParamField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.scriptFlush();
  ```

  ```ts With options theme={"system"}
  await redis.scriptFlush({
    async: true,
  });
  ```
</RequestExample>


# SCRIPT LOAD
Source: https://upstash.com/docs/redis/sdks/ts/commands/scripts/script_load

Load the specified Lua script into the script cache.

## Arguments

<ParamField body="script" type="string" required>
  The script to load.
</ParamField>

## Response

<ResponseField type="string" required>
  The sha1 of the script.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const script = `
    local value = redis.call('GET', KEYS[1])
    return value
  `;
  const sha1 = await redis.scriptLoad(script);

  ```
</RequestExample>


# DBSIZE
Source: https://upstash.com/docs/redis/sdks/ts/commands/server/dbsize

Count the number of keys in the database.

## Arguments

This command has no arguments

## Response

<ResponseField type="integer" required>
  The number of keys in the database
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const keys = await redis.dbsize();
  console.log(keys) // 20
  ```
</RequestExample>


# FLUSHALL
Source: https://upstash.com/docs/redis/sdks/ts/commands/server/flushall



<Warning>
  Deletes all keys permanently. Use with caution!
</Warning>

## Arguments

<ParamField body="async" type="boolean">
  Whether to perform the operation asynchronously.
  Defaults to synchronous.
</ParamField>

<RequestExample>
  ```ts Sync theme={"system"}
  await redis.flushall();
  ```

  ```ts Async theme={"system"}
  await redis.flushall({async: true})
  ```
</RequestExample>


# FLUSHDB
Source: https://upstash.com/docs/redis/sdks/ts/commands/server/flushdb



<Warning>
  Deletes all keys permanently. Use with caution!
</Warning>

## Arguments

<ParamField body="async" type="boolean">
  Whether to perform the operation asynchronously.
  Defaults to synchronous.
</ParamField>

<RequestExample>
  ```ts Sync theme={"system"}
  await redis.flushdb();
  ```

  ```ts Async theme={"system"}
  await redis.flushdb({async: true})
  ```
</RequestExample>


# SADD
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sadd

Adds one or more members to a set.

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

<ParamField body="members" type="...TValue[]" required>
  One or more members to add to the set.
</ParamField>

## Response

<ResponseField type="number" required>
  The number of elements that were added to the set, not including all the elements already present in the set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  // 3
  await redis.sadd("key", "a", "b", "c"); 

  // 0
  await redis.sadd("key", "a", "b"); 
  ```
</RequestExample>


# SCARD
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/scard

Return how many members are in a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

## Response

<ResponseField type="number" required>
  How many members are in the set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("key", "a", "b", "c"); 
  const cardinality = await redis.scard("key");
  console.log(cardinality); // 3
  ```
</RequestExample>


# SDIFF
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sdiff

Return the difference between sets

## Arguments

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the difference operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  const diff =  await redis.sdiff("set1", "set2");
  console.log(diff); // ["a", "b"]
  ```
</RequestExample>


# SDIFFSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sdiffstore

Write the difference between sets to a new set

## Arguments

<ParamField body="destination" type="string" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the difference operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  await redis.sdiff("dest", "set1", "set2");
  console.log(diff); // ["a", "b"]
  ```
</RequestExample>


# SINTER
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sinter

Return the intersection between sets

## Arguments

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the intersection operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  const intersection =  await redis.sinter("set1", "set2");
  console.log(intersection); // ["c"]
  ```
</RequestExample>


# SINTERSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sinterstore

Return the intersection between sets and store the resulting set in a key

## Arguments

<ParamField body="destination" type="string" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the intersection operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  await redis.sinterstore("destination", "set1", "set2");
  ```
</RequestExample>


# SISMEMBER
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sismember

Check if a member exists in a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set to check.
</ParamField>

<ParamField body="member" type="TMember">
  The member to check for.
</ParamField>

## Response

<ResponseField type="0 | 1" required>
  `1` if the member exists in the set, `0` if not.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const isMember =  await redis.sismember("set", "a");
  console.log(isMember); // 1
  ```
</RequestExample>


# SMEMBERS
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/smembers

Return all the members of a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

## Response

<ResponseField type="TMember[]" required>
  The members of the set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const members =  await redis.smembers("set");
  console.log(members); // ["a", "b", "c"]
  ```
</RequestExample>


# SMISMEMBER
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/smismember

Check if multiple members exist in a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set to check.
</ParamField>

<ParamField body="members" type="TMember[]">
  The members to check
</ParamField>

## Response

<ResponseField type="(0 | 1)[]" required>
  An array of `0` and `1` values.
  `1` if the member exists in the set, `0` if not.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const members =  await redis.smismember("set", ["a", "b", "d"]);
  console.log(members); // [1, 1, 0]
  ```
</RequestExample>


# SMOVE
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/smove

Move a member from one set to another

## Arguments

<ParamField body="source" type="string" required>
  The key of the set to move the member from.
</ParamField>

<ParamField body="destination" type="string" required>
  The key of the set to move the member to.
</ParamField>

<ParamField body="member" type="TMember">
  The members to move
</ParamField>

## Response

<ResponseField type="0 | 1" required>
  `1` if the member was moved, `0` if not.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("original", "a", "b", "c"); 
  const moved =  await redis.smove("original", "destination", "a");
  // moved:       1
  // original:    ["b", "c"]
  // destination: ["a"]
  ```
</RequestExample>


# SPOP
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/spop

Removes and returns one or more random members from a set.

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

<ParamField body="count" type="number" default={1}>
  How many members to remove and return.
</ParamField>

## Response

<ResponseField type="TMember | TMember[]" required>
  The popped member.
  If `count` is specified, an array of members is returned.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const popped = await redis.spop("set");
  console.log(popped); // "a"
  ```

  ```ts With Count  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const popped = await redis.spop("set", 2);
  console.log(popped); // ["a", "b"]
  ```
</RequestExample>


# SRANDMEMBER
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/srandmember

Returns one or more random members from a set.

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

<ParamField body="count" type="number" default={1}>
  How many members to return.
</ParamField>

## Response

<ResponseField type="TMember | TMember[]" required>
  The random member.
  If `count` is specified, an array of members is returned.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const member = await redis.srandmember("set");
  console.log(member); // "a"
  ```

  ```ts With Count  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const members = await redis.srandmember("set", 2);
  console.log(members); // ["a", "b"]
  ```
</RequestExample>


# SREM
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/srem

Remove one or more members from a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set to remove the member from.
</ParamField>

<ParamField body="members" type="...TMember[]">
  One or more members to remove from the set.
</ParamField>

## Response

<ResponseField type="integer" required>
  How many members were removed
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set", "a", "b", "c"); 
  const removed = await redis.srem("set", "a", "b", "d");
  console.log(removed); // 2
  ```
</RequestExample>


# SSCAN
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sscan

Scan a set

## Arguments

<ParamField body="key" type="string" required>
  The key of the set.
</ParamField>

<ParamField body="cursor" type="number">
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="options" type="Object">
  <ParamField body="match" type="string">
    Glob-style pattern to filter by members.
  </ParamField>

  <ParamField body="count" type="number">
    Number of members to return per call.
  </ParamField>
</ParamField>

## Response

<ResponseField type="[number, TMember[]]" required>
  The new cursor and the members.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.sadd("key", "a", "ab","b", "c");
  const [newCursor, fields] = await redis.sscan("key", 0, { match: "a*"});
  console.log(newCursor); // likely `0` since this is a very small set
  console.log(fields); // ["a", "ab"]
  ```
</RequestExample>


# SUNION
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sunion

Return the union between sets

## Arguments

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the union operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  const union =  await redis.sunion("set1", "set2");
  console.log(union); // ["a", "b", "c", "d", "e"]
  ```
</RequestExample>


# SUNIONSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/set/sunionstore

Return the union between sets and store the resulting set in a key

## Arguments

<ParamField body="destination" type="string" required>
  The key of the set to store the resulting set in.
</ParamField>

<ParamField body="keys" type="...string[]" required>
  The keys of the sets to perform the union operation on.
</ParamField>

## Response

<ResponseField type="TValue[]" required>
  The members of the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example  theme={"system"}
  await redis.sadd("set1", "a", "b", "c"); 
  await redis.sadd("set2", "c", "d", "e"); 
  await redis.sunionstore("destination", "set1", "set2");
  ```
</RequestExample>


# XACK
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xack

Removes one or multiple messages from the pending entries list of a stream consumer group.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="string" required>
  The consumer group name.
</ParamField>

<ParamField body="id" type="string | string[]" required>
  The ID(s) of the message(s) to acknowledge. Can be a single ID or an array of IDs.
</ParamField>

## Response

<ResponseField type="number">
  The number of messages successfully acknowledged.
</ResponseField>

<RequestExample>
  ```ts Single message theme={"system"}
  const result = await redis.xack("mystream", "mygroup", "1638360173533-0");
  ```

  ```ts Multiple messages theme={"system"}
  const result = await redis.xack("mystream", "mygroup", [
    "1638360173533-0",
    "1638360173533-1"
  ]);
  ```
</RequestExample>


# XADD
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xadd

Appends one or more new entries to a stream.

## Arguments

<ParamField body="key" type="string" required>
  The key to of the stream.
</ParamField>

<ParamField body="id" type="string | *" required>
  The stream entry ID. If `*` is passed, a new ID will be generated
  automatically.
</ParamField>

<ParamField body="entries" type="Record<string, unknown>" required>
  Key-value data to be appended to the stream.
</ParamField>

<ParamField body="options" type="object">
  <Expandable title="properties">
    <ParamField body="nomkStream" type="boolean">
      Prevent creating the stream if it does not exist.
    </ParamField>

    <ParamField body="trim" type="object">
      Trim options for the stream.

      <Expandable title="trim">
        <ParamField body="type" type="'MAXLEN' | 'MINID'" required>
          The trim strategy:

          * `MAXLEN`: Trim based on the maximum number of entries
          * `MINID`: Trim based on the minimum ID
        </ParamField>

        <ParamField body="threshold" type="number | string" required>
          The threshold value for trimming:

          * For `MAXLEN`: The maximum number of entries to keep (number)
          * For `MINID`: The minimum ID to keep (string)
        </ParamField>

        <ParamField body="comparison" type="'~' | '='" required>
          The comparison operator:

          * `~`: Approximate trimming (more efficient)
          * `=`: Exact trimming
        </ParamField>

        <ParamField body="limit" type="number">
          Limit how many entries will be trimmed at most
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="string">The ID of the newly added entry.</ResponseField>

<RequestExample>
  ```ts Basic Example theme={"system"}
  const result = await redis.xadd("mystream", "*", { name: "John Doe", age: 30 });
  ```

  ```ts With Custom ID theme={"system"}
  const result = await redis.xadd("mystream", "1634567890123-0", { temperature: 25.5, humidity: 60 });
  ```

  ```ts Trimming with MAXLEN theme={"system"}
  const result = await redis.xadd("mystream", "*", { event: "user_login", user_id: "12345" }, {
    trim: {
      type: "MAXLEN",
      threshold: 1000,
      comparison: "="
    }
  });
  ```

  ```ts Prevent Stream Creation theme={"system"}
  const result = await redis.xadd("existing_stream", "*", { data: "value" }, {
    nomkStream: true
  });
  ```

  ```ts Trimming with MINID theme={"system"}
  const result = await redis.xadd("mystream", "*", { action: "purchase", amount: 99.99 }, {
    trim: {
      type: "MINID",
      threshold: "1634567890000-0",
      comparison: "="
    }
  });
  ```
</RequestExample>


# XAUTOCLAIM
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xautoclaim

Changes the ownership of pending messages from one consumer to another in a stream consumer group.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="string" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="string" required>
  The consumer name that will claim the messages.
</ParamField>

<ParamField body="minIdleTime" type="number" required>
  The minimum idle time in milliseconds for messages to be claimed.
</ParamField>

<ParamField body="start" type="string" required>
  The stream entry ID to start claiming from.
</ParamField>

<ParamField body="options" type="object">
  <Expandable title="options">
    <ParamField body="count" type="number">
      The maximum number of messages to claim.
    </ParamField>

    <ParamField body="justid" type="boolean">
      Return only the message IDs instead of the full message data.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="[string, Array<[string, string[]]>, string[]]">
  Returns a tuple containing:

  * Next start ID for pagination
  * Array of claimed messages (ID and field-value pairs)
  * Array of deleted message IDs
</ResponseField>

<RequestExample>
  ```ts Basic autoclaim theme={"system"}
  const result = await redis.xautoclaim(
    "mystream",
    "mygroup", 
    "consumer1",
    60000,
    "0-0"
  );
  ```

  ```ts With count and justid theme={"system"}
  const result = await redis.xautoclaim(
    "mystream",
    "mygroup",
    "consumer1", 
    60000,
    "0-0",
    { count: 5, justid: true }
  );
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  [
    "1638360173533-1", // next start ID
    [["1638360173533-0", ["field1", "value1", "field2", "value2"]]], // claimed messages
    [] // deleted message IDs
  ]
  ```
</ResponseExample>


# XCLAIM
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xclaim

Changes the ownership of pending messages from one consumer to another in a stream consumer group.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="string" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="string" required>
  The consumer name that will claim the messages.
</ParamField>

<ParamField body="minIdleTime" type="number" required>
  The minimum idle time in milliseconds for messages to be claimed.
</ParamField>

<ParamField body="ids" type="string | string[]" required>
  The ID(s) of the message(s) to claim. Can be a single ID or an array of IDs.
</ParamField>

<ParamField body="options">
  <Expandable title="options">
    <ParamField body="idle" type="number">
      Set the idle time of the message.
    </ParamField>

    <ParamField body="time" type="number">
      Set the idle time to a specific Unix time.
    </ParamField>

    <ParamField body="retryCount" type="number">
      Set the retry counter to the specified value.
    </ParamField>

    <ParamField body="force" type="boolean">
      Create the pending message entry even if certain IDs are not already pending.
    </ParamField>

    <ParamField body="justid" type="boolean">
      Return only the message IDs instead of the full message data.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="Array<[string, string[]]> | string[]">
  Returns an array of claimed messages. If `justid` option is used, returns only message IDs.
</ResponseField>

<RequestExample>
  ```ts Basic claim theme={"system"}
  const result = await redis.xclaim(
    "mystream",
    "mygroup",
    "consumer1",
    60000,
    ["1638360173533-0", "1638360173533-1"]
  );
  ```

  ```ts With justid option theme={"system"}
  const result = await redis.xclaim(
    "mystream",
    "mygroup", 
    "consumer1",
    60000,
    ["1638360173533-0"],
    { justid: true, force: true }
  );
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  [
    ["1638360173533-0", ["field1", "value1", "field2", "value2"]],
    ["1638360173533-1", ["field1", "value3", "field2", "value4"]]
  ]
  ```
</ResponseExample>


# XDEL
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xdel

Removes the specified entries from a stream, and returns the number of entries deleted.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="ids" type="string | string[]" required>
  The ID(s) of the message(s) to delete. Can be a single ID or an array of IDs.
</ParamField>

## Response

<ResponseField type="number">
  The number of entries actually deleted from the stream.
</ResponseField>

<RequestExample>
  ```ts Single message theme={"system"}
  const result = await redis.xdel("mystream", "1638360173533-0");
  ```

  ```ts Multiple messages theme={"system"}
  const result = await redis.xdel("mystream", [
    "1638360173533-0",
    "1638360173533-1",
    "1638360173533-2"
  ]);
  ```
</RequestExample>


# XGROUP
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xgroup

Manage consumer groups for Redis streams.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="subcommand" type="object" required>
  The XGROUP subcommand and its parameters. Can be one of:

  <Expandable title="CREATE">
    <ParamField body="type" type="'CREATE'" required>
      Create a new consumer group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name.
    </ParamField>

    <ParamField body="id" type="string | '$'" required>
      The stream entry ID to start consuming from. Use '\$' to start from the end.
    </ParamField>

    <ParamField body="options">
      <Expandable title="options">
        <ParamField body="MKSTREAM" type="boolean">
          Create the stream if it doesn't exist.
        </ParamField>

        <ParamField body="ENTRIESREAD" type="number">
          Set the number of entries read by the group.
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>

  <Expandable title="CREATECONSUMER">
    <ParamField body="type" type="'CREATECONSUMER'" required>
      Create a new consumer in the group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name.
    </ParamField>

    <ParamField body="consumer" type="string" required>
      The consumer name to create.
    </ParamField>
  </Expandable>

  <Expandable title="DELCONSUMER">
    <ParamField body="type" type="'DELCONSUMER'" required>
      Delete a consumer from the group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name.
    </ParamField>

    <ParamField body="consumer" type="string" required>
      The consumer name to delete.
    </ParamField>
  </Expandable>

  <Expandable title="DESTROY">
    <ParamField body="type" type="'DESTROY'" required>
      Delete the entire consumer group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name to destroy.
    </ParamField>
  </Expandable>

  <Expandable title="SETID">
    <ParamField body="type" type="'SETID'" required>
      Set the last delivered ID for the group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name.
    </ParamField>

    <ParamField body="id" type="string | '$'" required>
      The stream entry ID to set as the last delivered ID.
    </ParamField>

    <ParamField body="options">
      <Expandable title="options">
        <ParamField body="ENTRIESREAD" type="number">
          Set the number of entries read by the group.
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField>
  The return type depends on the subcommand:

  * CREATE: Returns "OK" string
  * CREATECONSUMER: Returns 1 if created, 0 if already exists
  * DELCONSUMER: Returns the number of pending messages the consumer had
  * DESTROY: Returns 1 if destroyed, 0 if group didn't exist
  * SETID: Returns "OK" string
</ResponseField>

<RequestExample>
  ```ts Create group theme={"system"}
  const result = await redis.xgroup("mystream", {
    type: "CREATE",
    group: "mygroup",
    id: "$",
    options: { MKSTREAM: true }
  });
  ```

  ```ts Create consumer theme={"system"}
  const result = await redis.xgroup("mystream", {
    type: "CREATECONSUMER",
    group: "mygroup",
    consumer: "consumer1"
  });
  ```

  ```ts Delete consumer theme={"system"}
  const result = await redis.xgroup("mystream", {
    type: "DELCONSUMER", 
    group: "mygroup",
    consumer: "consumer1"
  });
  ```

  ```ts Set group ID theme={"system"}
  const result = await redis.xgroup("mystream", {
    type: "SETID",
    group: "mygroup", 
    id: "0-0"
  });
  ```

  ```ts Destroy group theme={"system"}
  const result = await redis.xgroup("mystream", {
    type: "DESTROY",
    group: "mygroup"
  });
  ```
</RequestExample>


# XINFO
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xinfo

Returns information about streams, consumer groups, and consumers.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="options" type="object" required>
  The XINFO subcommand options. Can be one of:

  <Expandable title="GROUPS">
    <ParamField body="type" type="'GROUPS'" required>
      List all consumer groups for the stream.
    </ParamField>
  </Expandable>

  <Expandable title="CONSUMERS">
    <ParamField body="type" type="'CONSUMERS'" required>
      List all consumers in a consumer group.
    </ParamField>

    <ParamField body="group" type="string" required>
      The consumer group name.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField>
  The return type depends on the subcommand:

  * GROUPS: Returns an array of consumer group information
  * CONSUMERS: Returns an array of consumer information
</ResponseField>

<RequestExample>
  ```ts List groups theme={"system"}
  const result = await redis.xinfo("mystream", {
    type: "GROUPS"
  });
  ```

  ```ts List consumers theme={"system"}
  const result = await redis.xinfo("mystream", {
    type: "CONSUMERS",
    group: "mygroup"
  });
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  // GROUPS response
  [
    {
      name: "mygroup",
      consumers: 2,
      pending: 1,
      "last-delivered-id": "1638360173533-2",
      "entries-read": 3,
      lag: 2
    }
  ]

  // CONSUMERS response
  [
    {
      name: "consumer1",
      pending: 1,
      idle: 15000,
      "inactive": 15000
    }
  ]
  ```
</ResponseExample>


# XLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xlen

Returns the number of entries inside a stream.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

## Response

<ResponseField type="number">
  The number of entries in the stream. Returns 0 if the stream does not exist.
</ResponseField>

<RequestExample>
  ```ts Get stream length theme={"system"}
  const result = await redis.xlen("mystream");
  ```
</RequestExample>


# XPENDING
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xpending

Returns information about pending messages in a stream consumer group.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="group" type="string" required>
  The consumer group name.
</ParamField>

<ParamField body="start" type="string" required>
  The minimum pending ID to return. Use "-" for the first available ID.
</ParamField>

<ParamField body="end" type="string" required>
  The maximum pending ID to return. Use "+" for the last available ID.
</ParamField>

<ParamField body="count" type="number" required>
  The maximum number of pending messages to return.
</ParamField>

<ParamField body="options">
  <Expandable title="properties">
    <ParamField body="idleTime" type="number">
      Filter by minimum idle time in milliseconds.
    </ParamField>

    <ParamField body="consumer" type="string">
      Filter results by a specific consumer.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField>
  Returns an array of pending message details.
</ResponseField>

<RequestExample>
  ```ts Summary theme={"system"}
  const result = await redis.xpending("mystream", "mygroup", "-", "+", 10);
  ```

  ```ts With idle time filter theme={"system"}
  const result = await redis.xpending("mystream", "mygroup", "-", "+", 5, {
    idleTime: 10000
  });
  ```

  ```ts Specific consumer filter theme={"system"}
  const result = await redis.xpending("mystream", "mygroup", "-", "+", 5, {
    consumer: "consumer1"
  });
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  [
    2, // total pending count
    "1638360173533-0", // smallest pending ID
    "1638360173533-1", // greatest pending ID
    [
      ["consumer1", "1"], // consumer and their pending count
      ["consumer2", "1"]
    ]
  ]
  ```
</ResponseExample>


# XRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xrange

Returns stream entries matching a given range of IDs.

## Arguments

<ParamField body="key" type="string" required>
  The key to of the stream.
</ParamField>

<ParamField body="start" type="string" required>
  The stream entry ID to start from.
</ParamField>

<ParamField body="end" type="string" required>
  The stream entry ID to end at.
</ParamField>

<ParamField body="count" type="number">
  The maximum number of entries to return.
</ParamField>

## Response

<ResponseField type="Record<streamId, Record<field, value>>">
  An object of stream entries, keyed by their stream ID
</ResponseField>

<RequestExample>
  ```ts All entries theme={"system"}
  const result = await redis.xrange("mystream", "-", "+");
  ```

  ```ts Range with specific IDs theme={"system"}
  const result = await redis.xrange("mystream", "1548149259438-0", "1548149259438-5");
  ```

  ```ts Limited count theme={"system"}
  const result = await redis.xrange("mystream", "-", "+", 10);
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  {
    "1548149259438-0": {
      "field1": "value1",
      "field2": "value2"
    },
    "1548149259438-1": {
      "field1": "value3",
      "field2": "value4"
    }
  }
  ```
</ResponseExample>


# XREAD
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xread

Reads data from one or multiple streams, starting from the specified IDs.

## Arguments

<ParamField body="key" type="string | string[]" required>
  The key(s) of the stream(s). Can be a single stream key or an array of stream keys.
</ParamField>

<ParamField body="id" type="string | string[]" required>
  The stream entry ID(s) to start reading from. Must match the number of keys provided.
  Use "\$" to read only new messages added after the command is issued.
</ParamField>

<ParamField body="options">
  <Expandable title="properties">
    <ParamField body="count" type="number">
      The maximum number of messages to return per stream.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="Array<[string, Array<[string, string[]]>]> | null">
  Returns an array where each element represents a stream and contains:

  * The stream key
  * An array of messages (ID and field-value pairs)

  Returns null if no data is available.
</ResponseField>

<RequestExample>
  ```ts Single stream theme={"system"}
  const result = await redis.xread("mystream", "0-0");
  ```

  ```ts Multiple streams theme={"system"}
  const result = await redis.xread(
    ["stream1", "stream2"], 
    ["0-0", "0-0"]
  );
  ```

  ```ts With count limit theme={"system"}
  const result = await redis.xread("mystream", "0-0", { count: 2 });
  ```

  ```ts Only new messages theme={"system"}
  const result = await redis.xread("mystream", "$");
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  [
    ["mystream", [
      ["1638360173533-0", ["field1", "value1", "field2", "value2"]],
      ["1638360173533-1", ["field1", "value3", "field2", "value4"]]
    ]]
  ]
  ```
</ResponseExample>


# XREADGROUP
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xreadgroup

Reads data from a stream as part of a consumer group.

## Arguments

<ParamField body="group" type="string" required>
  The consumer group name.
</ParamField>

<ParamField body="consumer" type="string" required>
  The consumer name within the group.
</ParamField>

<ParamField body="key" type="string | string[]" required>
  The stream key(s) to read from. Can be a single stream key or an array of stream keys for multiple streams.
</ParamField>

<ParamField body="ids" type="string | string[]" required>
  The starting ID(s) to read from. Use ">" to read messages never delivered to any consumer in the group.
  For multiple streams, provide an array of IDs corresponding to each stream.
</ParamField>

<ParamField body="options">
  <Expandable title="properties">
    <ParamField body="count" type="number">
      The maximum number of messages to return per stream.
    </ParamField>

    <ParamField body="NOACK" type="boolean">
      Don't add messages to the pending entries list (messages won't need acknowledgment).
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="Array<[string, Array<[string, string[]]>]> | null">
  Returns an array where each element represents a stream and contains:

  * The stream key
  * An array of messages (ID and field-value pairs)

  Returns null if no data is available.
</ResponseField>

<RequestExample>
  ```ts Read new messages theme={"system"}
  const result = await redis.xreadgroup("mygroup", "consumer1", "mystream", ">");
  ```

  ```ts With count option theme={"system"}
  const result = await redis.xreadgroup("mygroup", "consumer1", "mystream", ">", {
    count: 5
  });
  ```

  ```ts With NOACK option theme={"system"}
  const result = await redis.xreadgroup("mygroup", "consumer1", "mystream", ">", {
    NOACK: true
  });
  ```

  ```ts Multiple streams theme={"system"}
  const result = await redis.xreadgroup(
    "mygroup", 
    "consumer1", 
    ["stream1", "stream2"], 
    [">", ">"],
    { count: 1 }
  );
  ```

  ```ts Read pending messages theme={"system"}
  const result = await redis.xreadgroup("mygroup", "consumer1", "mystream", "0");
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  [
    ["mystream", [
      ["1638360173533-0", ["field1", "value1", "field2", "value2"]],
      ["1638360173533-1", ["field1", "value3", "field2", "value4"]]
    ]]
  ]
  ```
</ResponseExample>


# XREVRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xrevrange

Returns stream entries matching a given range of IDs in reverse order.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="end" type="string" required>
  The stream entry ID to end at (highest ID).
</ParamField>

<ParamField body="start" type="string" required>
  The stream entry ID to start from (lowest ID).
</ParamField>

<ParamField body="count" type="number">
  The maximum number of entries to return.
</ParamField>

## Response

<ResponseField type="Record<string, Record<string, unknown>>">
  An object of stream entries in reverse chronological order, keyed by their stream ID.
</ResponseField>

<RequestExample>
  ```ts All entries (reverse order) theme={"system"}
  const result = await redis.xrevrange("mystream", "+", "-");
  ```

  ```ts Limited count theme={"system"}
  const result = await redis.xrevrange("mystream", "+", "-", 2);
  ```

  ```ts Specific range theme={"system"}
  const result = await redis.xrevrange(
    "mystream",
    "1638360173533-3", 
    "1638360173533-1"
  );
  ```
</RequestExample>

<ResponseExample>
  ```ts  theme={"system"}
  {
    "1638360173533-4": {
      "field1": "value5",
      "field2": "value6"
    },
    "1638360173533-3": {
      "field1": "value3", 
      "field2": "value4"
    },
    "1638360173533-0": {
      "field1": "value1",
      "field2": "value2"
    }
  }
  ```
</ResponseExample>


# XTRIM
Source: https://upstash.com/docs/redis/sdks/ts/commands/stream/xtrim

Trims the stream by removing entries to keep it at a reasonable size.

## Arguments

<ParamField body="key" type="string" required>
  The key of the stream.
</ParamField>

<ParamField body="options" type="object" required>
  <Expandable title="properties">
    <ParamField body="strategy" type="'MAXLEN' | 'MINID'" required>
      The trimming strategy:

      * `MAXLEN`: Trim based on the maximum number of entries
      * `MINID`: Trim based on the minimum ID
    </ParamField>

    <ParamField body="threshold" type="number | string" required>
      The threshold value for trimming:

      * For `MAXLEN`: The maximum number of entries to keep (number)
      * For `MINID`: The minimum ID to keep (string). Entries with IDs lower than this will be removed
    </ParamField>

    <ParamField body="exactness" type="'~' | '='">
      Use `~` for approximate trimming (more efficient, default) or `=` for exact trimming.
    </ParamField>

    <ParamField body="limit" type="number">
      Limit how many entries will be trimmed at most (only valid with approximate trimming `~`).
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="number">
  The number of entries removed from the stream.
</ResponseField>

<RequestExample>
  ```ts Approximate trim by max length theme={"system"}
  const result = await redis.xtrim("mystream", {
    strategy: "MAXLEN",
    threshold: 100,
    exactness: "~"
  });
  ```

  ```ts Exact trim by max length theme={"system"}
  const result = await redis.xtrim("mystream", {
    strategy: "MAXLEN", 
    threshold: 50,
    exactness: "="
  });
  ```

  ```ts Trim by minimum ID theme={"system"}
  const result = await redis.xtrim("mystream", {
    strategy: "MINID",
    threshold: "1638360173533-0",
    exactness: "="
  });
  ```

  ```ts Approximate trim with limit theme={"system"}
  const result = await redis.xtrim("mystream", {
    strategy: "MAXLEN",
    threshold: 1000,
    exactness: "~",
    limit: 100
  });
  ```
</RequestExample>


# String Commands
Source: https://upstash.com/docs/redis/sdks/ts/commands/string



## MGET

Load multiple keys at once. For billing purposes, this counts as a single command.

If a key is not found, it will be returned as `null`, so you might end up with `null` values in your response array.

```ts  theme={"system"}
const values = await redis.mget("key1", "key2", "key3");
```

## MSET

Set multiple values at once. For billing purposes, this counts as a single command.

```ts  theme={"system"}
await redis.mset({
  key1: { a: 1 },
  key2: "value2",
  key3: true,
});
```

## MSETNX

```ts  theme={"system"}
```

## PSETEX

```ts  theme={"system"}
```

## SET

```ts  theme={"system"}
```

## SETEX

```ts  theme={"system"}
```

## SETNX

```ts  theme={"system"}
```

## SETRANGE

```ts  theme={"system"}
```

## STRLEN

```ts  theme={"system"}
```

## SUBSTR

```ts  theme={"system"}
```


# APPEND
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/append

Append a value to a string stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="value" required>
  The value to append.
</ParamField>

## Response

<ResponseField type="integer" required>
  How many characters were added to the string.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.append(key, "Hello");
  // returns 5
  ```
</RequestExample>


# DECR
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/decr

Decrement the integer value of a key by one

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="string" required>
  The key to decrement.
</ParamField>

## Response

<ResponseField type="integer" required>
  The value at the key after the decrementing.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", 6);
  await redis.decr("key");
  // returns 5
  ```
</RequestExample>


# DECRBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/decrby

Decrement the integer value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="string" required>
  The key to decrement.
</ParamField>

<ParamField body="decrementBy" type="integer" required>
  The amount to decrement by.
</ParamField>

## Response

<ResponseField type="integer" required>
  The value at the key after the decrementing.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", 6);
  await redis.decrby("key", 4);
  // returns 2
  ```
</RequestExample>


# GET
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/get

Return the value of the specified key or `null` if the key doesn't exist.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `null` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  type MyType = {
      a: number;
      b: string;
  }
  const value = await redis.get<MyType>("key");
  if (!value) {
      // key doesn't exist
  } else {
      // value is of type MyType
  }
  ```
</RequestExample>


# GETDEL
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/getdel

Return the value of the specified key and delete the key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `null` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  type MyType = {
      a: number;
      b: string;
  }
  await redis.getdel<MyType>("key");
  // returns {a: 1, b: "2"}
  ```
</RequestExample>


# GETRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/getrange

Return a substring of value at the specified key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="start" type="integer" required>
  The start index of the substring.
</ParamField>

<ParamField body="end" type="integer" required>
  The end index of the substring.
</ParamField>

## Response

<ResponseField type="string" required>
  The substring.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const substring = await redis.getrange("key", 2, 4);
  ```
</RequestExample>


# GETSET
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/getset

Return the value of the specified key and replace it with a new value.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="newValue" required>
  The new value to store.
</ParamField>

## Response

<ResponseField required>
  The response is the value stored at the key or `null` if the key doesn't exist.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  const oldValue = await redis.getset("key", newValue);
  ```
</RequestExample>


# INCR
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/incr

Increment the integer value of a key by one

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="string" required>
  The key to increment.
</ParamField>

## Response

<ResponseField type="integer" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", 6);
  await redis.incr("key");
  // returns 7
  ```
</RequestExample>


# INCRBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/incrby

Increment the integer value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="string" required>
  The key to decrement.
</ParamField>

<ParamField body="incrementBy" type="integer" required>
  The amount to increment by.
</ParamField>

## Response

<ResponseField type="integer" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", 6);
  await redis.incrby("key", 4);
  // returns 10
  ```
</RequestExample>


# INCRBYFLOAT
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/incrbyfloat

Increment the float value of a key by a given number.

If a key does not exist, it is initialized as 0 before performing the operation. An error is returned if the key contains a value of the wrong type or contains a string that can not be represented as integer.

## Arguments

<ParamField body="key" type="string" required>
  The key to decrement.
</ParamField>

<ParamField body="incrementBy" type="float" required>
  The amount to increment by.
</ParamField>

## Response

<ResponseField type="float" required>
  The value at the key after the incrementing.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", 6);
  await redis.incrbyfloat("key", 4,5);
  // returns 10.5
  ```
</RequestExample>


# MGET
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/mget

Load multiple keys from Redis in one go.

For billing purposes, this counts as a single command.

## Arguments

<ParamField body="keys" type="...string" required>
  Multiple keys to load from Redis.
</ParamField>

## Response

<ResponseField type="T[]" required>
  An array of values corresponding to the keys passed in. If a key doesn't exist, the value will be `null`.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  type MyType = {
      a: number;
      b: string;
  }
  const values = await redis.mget<MyType>("key1", "key2", "key3");
  // values.length -> 3
  ```
</RequestExample>


# MSET
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/mset

Set multiple keys in one go.

For billing purposes, this counts as a single command.

## Arguments

<ParamField body="params" type="Record<string, TValue>" required>
  An object where the keys are the keys to set, and the values are the values to set.
</ParamField>

## Response

<ResponseField type="string" required>
  "OK"
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.mset({
      key1: 1,
      key2: "hello",
      key3: { a: 1, b: "hello" },
  });
  ```
</RequestExample>


# MSETNX
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/msetnx

Set multiple keys in one go unless they exist already.

For billing purposes, this counts as a single command.

## Arguments

<ParamField type="Record<string, TValue>" required>
  An object where the keys are the keys to set, and the values are the values to set.
</ParamField>

## Response

<ResponseField required>
  `True` if all keys were set, `False` if at least one key was not set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  redis.msetnx({
    "key1": "value1",
    "key2": "value2"
  })
  ```
</RequestExample>


# SET
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/set

Set a key to hold a string value.

## Arguments

<ParamField body="key" type="string" required>
  The key
</ParamField>

<ParamField body="value" type="TValue" required>
  The value, if this is not a string, we will use `JSON.stringify` to convert it
  to a string.
</ParamField>

<ParamField body="opts" type="object">
  You can pass a few options to the command.

  <Expandable>
    <ParamField body="get" type="boolean">
      Instead of returning `"OK"`, this will cause the command to return the old
      value stored at key, or `null` when key did not exist.
    </ParamField>

    <ParamField body="ex" type="integer">
      Adds an expiration (in seconds) to the key.
    </ParamField>

    <ParamField body="px" type="integer">
      Adds an expiration (in milliseconds) to the key.
    </ParamField>

    <ParamField body="exat" type="integer">
      Expires the key after the given timestamp (in seconds).
    </ParamField>

    <ParamField body="pxat" type="integer">
      Expires the key after the given timestamp (in milliseconds).
    </ParamField>

    <ParamField body="keepTtl" type="boolean">
      Keeps the old expiration if the key already exists.
    </ParamField>

    <ParamField body="nx" type="boolean">
      Only set the key if it does not already exist.
    </ParamField>

    <ParamField body="xx" type="boolean">
      Only set the key if it already exists.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField required>
  `"OK"`
</ResponseField>

<RequestExample>
  ```ts Basic theme={"system"}
  await redis.set("my-key", {my: "value"});
  ```

  ```ts Expire in 60 seconds theme={"system"}
  await redis.set("my-key", {my: "value"}, {
    ex: 60
  });
  ```

  ```ts Only update theme={"system"}
  await redis.set("my-key", {my: "value"}, {
    xx: true
  });
  ```
</RequestExample>


# SETRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/setrange

Writes the value of key at offset.

The SETRANGE command in Redis is used to modify a portion of the value of a key by replacing a substring within the key's existing value. It allows you to update part of the string value associated with a specific key at a specified offset.

## Arguments

<ParamField body="key" type="string" required>
  The name of the Redis key for which you want to modify the value.
</ParamField>

<ParamField body="offset" type="integer" required>
  The zero-based index in the value where you want to start replacing characters.
</ParamField>

<ParamField body="value" type="string" required>
  The new string that you want to insert at the specified offset in the existing value.
</ParamField>

## Response

<ResponseField type="integer" required>
  The length of the value after it was modified.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", "helloworld")
  const length = await redis.setrange("key", 5, "redis");
  console.log(length); // 10

  // The value of "key" is now "helloredis"
  ```
</RequestExample>


# STRLEN
Source: https://upstash.com/docs/redis/sdks/ts/commands/string/strlen

Return the length of a string stored at a key.

The \`STRLEN\`\` command in Redis is used to find the length of the string value associated with a key. In Redis, keys can be associated with various data types, and one of these data types is the "string." The STRLEN command specifically operates on keys that are associated with string values.

## Arguments

<ParamField body="key" type="string" required>
  The name of the Redis key.
</ParamField>

## Response

<ResponseField type="integer" required>
  The length of the value.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.set("key", "helloworld")
  const length = await redis.strlen("key");
  console.log(length); // 10
  ```
</RequestExample>


# Transactions
Source: https://upstash.com/docs/redis/sdks/ts/commands/transaction

Transactions

You can use transactions or pipelines with the `multi` or `pipeline` method.

Transactions are executed atomically, while pipelines are not. In pipelines you can execute multiple commands at once, but other commands from other clients can be executed in between.

<CodeGroup>
  ```ts Pipeline theme={"system"}
  const p = redis.pipeline();
  p.set("foo", "bar");
  p.get("foo");
  const res = await p.exec();
  ```

  ```ts Transaction theme={"system"}
  const tx = redis.multi();
  tx.set("foo", "bar");
  tx.get("foo");
  const res = await tx.exec();
  ```
</CodeGroup>

For more information on pipelines and transactions, see
[the Pipeline page](https://docs.upstash.com/redis/sdks/ts/pipelining/pipeline-transaction).


# ZADD
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zadd

Add a member to a sorted set, or update its score if it already exists.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set.
</ParamField>

<ParamField body="options">
  <ParamField body="xx" type="boolean">
    Only update elements that already exist. Never add elements.
  </ParamField>

  <ParamField body="nx" type="boolean">
    Only add new elements. Never update elements.
  </ParamField>

  <ParamField body="ch" type="boolean">
    Return the number of elements added or updated.
  </ParamField>

  <ParamField body="incr" type="boolean">
    When this option is specified ZADD acts like ZINCRBY. Only one score-element pair can be specified in this mode.
  </ParamField>
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements added to the sorted sets, not including elements already existing for which the score was updated.

  If `ch` was specified, the number of elements that were updated.

  If `incr` was specified, the new score of `member`.
</ResponseField>

<RequestExample>
  ```ts Simple theme={"system"}

  await redis.zadd(
      "key", 
      { score: 2, member: "member" }, 
      { score: 3, member: "member2"},
  );
  ```

  ```ts XX  theme={"system"}
  await redis.zadd(
      "key",
      { xx: true },
      { score: 2, member: "member" },
  )
  ```

  ```ts NX  theme={"system"}
  await redis.zadd(
      "key",
      { nx: true },
      { score: 2, member: "member" },
  )
  ```

  ```ts CH  theme={"system"}
  await redis.zadd(
      "key",
      { ch: true },
      { score: 2, member: "member" },
  )
  ```

  ```ts INCR  theme={"system"}
  await redis.zadd(
      "key",
      { cincrh: true },
      { score: 2, member: "member" },
  )
  ```
</RequestExample>


# ZCARD
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zcard

Returns the number of elements in the sorted set stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements in the sorted set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  await redis.zadd("key", 
      { score: 1, member: "one"}, 
      { score: 2, member: "two" },
  );
  const elements = await redis.zrank("key");
  console.log(elements); // 2
  ```
</RequestExample>


# ZCOUNT
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zcount

Returns the number of elements in the sorted set stored at key filterd by score.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="min" type="integer | string" required>
  The minimum score to filter by.

  Use `-inf` to effectively ignore this filter.

  Use `(number` to exclude the value.
</ParamField>

<ParamField body="max" type="integer | string" required>
  The maximum score to filter by.

  Use `+inf` to effectively ignore this filter.

  Use `(number` to exclude the value.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements where score is between min and max.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "one"}, 
      { score: 2, member: "two" },
  );
  const elements = await redis.zcount("key", "(1", "+inf");
  console.log(elements); // 1
  ```
</RequestExample>


# ZDIFFSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zdiffstore

Writes the difference between sets to a new key.

## Arguments

<ParamField body="destination" type="string" required>
  The key to write the difference to.
</ParamField>

<ParamField body="keys" type="integer" required>
  How many keys to compare.
</ParamField>

<ParamField body="keys" type="...string[]" required>
  The keys to compare.
</ParamField>

## Response

<ResponseField required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const values = await redis.zdiffstore("destination", 2, "key1", "key2");
  ```
</RequestExample>


# ZINCRBY
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zincrby

Increment the score of a member.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set.
</ParamField>

<ParamField body="increment" type="integer" required>
  The increment to add to the score.
</ParamField>

<ParamField body="member" type="TMember" required>
  The member to increment.
</ParamField>

## Response

<ResponseField type="integer" required>
  The new score of `member` after the increment operation.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zadd("key", 1, "member");
  const value = await redis.zincrby("key", 2, "member");
  console.log(value); // 3
  ```
</RequestExample>


# ZINTERSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zinterstore

Writes the intersection between sets to a new key.

## Arguments

<ParamField body="destination" type="string" required>
  The key to write the intersection to.
</ParamField>

<ParamField body="keys" type="integer" required>
  How many keys to compare.
</ParamField>

<ParamField body="keys" type="string | string[]" required>
  The keys to compare.
</ParamField>

<ParamField body="options">
  <ParamField body="aggregate" type="sum | min | max">
    The aggregation method.
  </ParamField>

  <ParamField body="weight" type="number">
    The weight to apply to each key.
  </ParamField>

  <ParamField body="weights" type="number[]">
    The weights to apply to each key.
  </ParamField>
</ParamField>

## Response

<ResponseField required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```ts Simple theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )

  const res = await redis.zinterstore("destination", 2, ["key1", "key2"]);
  console.log(res) // 1
  ```

  ```ts With Weights theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )
  const res = await redis.zinterstore(
      "destination",
      2,
      ["key1", "key2"],
      { weights: [2, 3] },
  );
  console.log(res) // 1
  ```

  ```ts Aggregate theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )
  const res = await redis.zinterstore(
      "destination",
      2,
      ["key1", "key2"],
      { aggregate: "sum" },
  );
  console.log(res) // 1
  ```
</RequestExample>


# ZLEXCOUNT
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zlexcount

Returns the number of elements in the sorted set stored at key filtered by lex.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="min" type="string" required>
  The lower lexicographical bound to filter by.

  Use `-` to disable the lower bound.
</ParamField>

<ParamField body="max" type="string" required>
  The upper lexicographical bound to filter by.

  Use `+` to disable the upper bound.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of matched.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "one"}, 
      { score: 2, member: "two" },
  );
  const elements = await redis.zlexcount("key", "two", "+");
  console.log(elements); // 1
  ```
</RequestExample>


# ZMSCORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zmscore

Returns the scores of multiple members.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField body="members" type="TMember[]" required>
  The members of the sorted set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  await redis.zadd("key", 
      { score: 1, member: "m1" },
      { score: 2, member: "m2" },
      { score: 3, member: "m3" },
      { score: 4, member: "m4" },
  )

  const scores = await redis.zmscore("key", ["m2", "m4"])
  console.log(scores) // [2, 4]
  ```
</RequestExample>


# ZPOPMAX
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zpopmax

Removes and returns up to count members with the highest scores in the sorted set stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

## Response

<ResponseField body="count" type="integer">
  The number of elements removed. Defaults to 1.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const popped = await redis.zpopmax("key", 4);
  ```
</RequestExample>


# ZPOPMIN
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zpopmin

Removes and returns up to count members with the lowest scores in the sorted set stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

## Response

<ResponseField body="count" type="integer">
  The number of elements removed. Defaults to 1.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const popped = await redis.zpopmin("key", 4);
  ```
</RequestExample>


# ZRANGE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zrange

Returns the specified range of elements in the sorted set stored at key.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="min" type="number | string" required>
  The lower bound of the range.
</ParamField>

<ParamField body="max" type="number | string" required>
  The upper bound of the range.
</ParamField>

<ParamField body="options">
  <Expandable>
    <ParamField body="withScores" type="boolean">
      Whether to include the scores in the response.
    </ParamField>

    <ParamField body="rev" type="boolean">
      Whether to reverse the order of the response.
    </ParamField>

    <ParamField body="byScore" type="boolean">
      Whether to use the score as the sort order.
    </ParamField>

    <ParamField body="byLex" type="boolean">
      Whether to use lexicographical ordering.
    </ParamField>

    <ParamField body="offset" type="number">
      The offset to start from.
    </ParamField>

    <ParamField body="count" type="number">
      The number of elements to return.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField type="TMember[]">
  The values in the specified range.

  If `withScores` is true, the response will have interleaved members and scores: `[TMember, number, TMember, number, ...]`
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "m1" },
      { score: 2, member: "m2" },
  )
  const res = await redis.zrange("key", 1, 3)
  console.log(res) // ["m2"]
  ```

  ```ts WithScores theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "m1" },
      { score: 2, member: "m2" },
  )
  const res = await redis.zrange("key", 1, 3, { withScores: true })
  console.log(res) // ["m2", 2]
  ```

  ```ts ByScore theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "m1" },
      { score: 2, member: "m2" },
      { score: 3, member: "m3" },
  )
  const res = await redis.zrange("key", 1, 2, { byScore: true })
  console.log(res) // ["m1", "m2"]
  ```
</RequestExample>


# ZRANK
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zrank

Returns the rank of a member

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="member" type="TMember" required>
  The member to get the rank of.
</ParamField>

## Response

<ResponseField type="integer" required>
  The rank of the member.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const rank = await redis.rank("key", "member");
  ```
</RequestExample>


# ZREM
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zrem

Remove one or more members from a sorted set

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

<ParamField body="members" type="...TMember[]" required>
  One or more members to remove
</ParamField>

## Response

<ResponseField required>
  The number of members removed from the sorted set.
</ResponseField>

<RequestExample>
  ```ts Single theme={"system"}
  await redis.zrem("key", "member");
  ```

  ```ts Multiple theme={"system"}
  await redis.zrem("key", "member1", "member2");
  ```
</RequestExample>


# ZREMRANGEBYLEX
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zremrangebylex

Remove all members in a sorted set between the given lexicographical range.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="string" required>
  The minimum lexicographical value to remove.
</ParamField>

<ParamField body="max" type="string" required>
  The maximum lexicographical value to remove.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zremrangebylex("key", "alpha", "omega")
  ```
</RequestExample>


# ZREMRANGEBYRANK
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zremrangebyrank

Remove all members in a sorted set between the given ranks.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="number" required>
  The minimum rank to remove.
</ParamField>

<ParamField body="max" type="number" required>
  The maximum rank to remove.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zremrangebyrank("key", 4, 20)
  ```
</RequestExample>


# ZREMRANGEBYSCORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zremrangebyscore

Remove all members in a sorted set between the given scores.

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set
</ParamField>

<ParamField body="min" type="number" required>
  The minimum score to remove.
</ParamField>

<ParamField body="max" type="number" required>
  The maximum score to remove.
</ParamField>

## Response

<ResponseField type="integer" required>
  The number of elements removed from the sorted set.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zremrangebyscore("key", 2, 5)
  ```
</RequestExample>


# ZREVRANK
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zrevrank

Returns the rank of a member in a sorted set, with scores ordered from high to low.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

<ParamField body="member" type="TMember" required>
  The member to get the reverse rank of.
</ParamField>

## Response

<ResponseField type="integer" required>
  The reverse rank of the member.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  const rank = await redis.rank("key", "member");
  ```
</RequestExample>


# ZSCAN
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zscan

Scan a sorted set

## Arguments

<ParamField body="key" type="string" required>
  The key of the sorted set.
</ParamField>

<ParamField body="cursor" type="number">
  The cursor, use `0` in the beginning and then use the returned cursor for subsequent calls.
</ParamField>

<ParamField body="options" type="Object">
  <ParamField body="match" type="string">
    Glob-style pattern to filter by members.
  </ParamField>

  <ParamField body="count" type="number">
    Number of members to return per call.
  </ParamField>
</ParamField>

## Response

<ResponseField type="[number, TMember[]]" required>
  The new cursor and the members.
  If the new cursor is `0` the iteration is complete.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "a" },
      { score: 2, member: "ab" },
      { score: 3, member: "b" },
      { score: 4, member: "c" },
      { score: 5, member: "d" },
  )
  const [newCursor, members] = await redis.zscan("key", 0, { match: "a*"});
  console.log(newCursor); // likely `0` since this is a very small set
  console.log(members); // ["a", "ab"]
  ```

  ```ts withCount theme={"system"}
  await redis.zadd("key", 
      { score: 1, member: "a" },
      { score: 2, member: "ab" },
      { score: 3, member: "b" },
      { score: 4, member: "c" },
      { score: 5, member: "d" },
  )
  const [newCursor, members] = await redis.zscan("key", 0, { match: "a*", count: 1});
  console.log(newCursor); // likely `0` since this is a very small set
  console.log(members); // ["a"]
  ```
</RequestExample>


# ZSCORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zscore

Returns the scores of a member.

## Arguments

<ParamField body="key" type="string" required>
  The key to get.
</ParamField>

## Response

<ResponseField body="member" type="TMember" required>
  A member of the sortedset.
</ResponseField>

<RequestExample>
  ```ts Example theme={"system"}

  await redis.zadd("key", 
      { score: 1, member: "m1" },
      { score: 2, member: "m2" },
      { score: 3, member: "m3" },
      { score: 4, member: "m4" },
  )

  const score = await redis.zscore("key", "m2")
  console.log(score) // 2
  ```
</RequestExample>


# ZUNIONSTORE
Source: https://upstash.com/docs/redis/sdks/ts/commands/zset/zunionstore

Writes the union between sets to a new key.

## Arguments

<ParamField body="destination" type="string" required>
  The key to write the union to.
</ParamField>

<ParamField body="keys" type="integer" required>
  How many keys to compare.
</ParamField>

<ParamField body="keys" type="string | string[]" required>
  The keys to compare.
</ParamField>

<ParamField body="options">
  <ParamField body="aggregate" type="sum | min | max">
    The aggregation method.
  </ParamField>

  <ParamField body="weight" type="number">
    The weight to apply to each key.
  </ParamField>

  <ParamField body="weights" type="number[]">
    The weights to apply to each key.
  </ParamField>
</ParamField>

## Response

<ResponseField required>
  The number of elements in the resulting set.
</ResponseField>

<RequestExample>
  ```ts Simple theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )

  const res = await redis.zunionstore("destination", 2, ["key1", "key2"]);
  console.log(res) // 2
  ```

  ```ts With Weights theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )
  const res = await redis.zunionstore(
      "destination",
      2,
      ["key1", "key2"],
      { weights: [2, 3] },
  );
  console.log(res) // 2
  ```

  ```ts Aggregate theme={"system"}
  await redis.zadd(
      "key1", 
      { score: 1, member: "member1" },
  )
  await redis.zadd(
      "key2",
      { score: 1, member: "member1" },
      { score: 2, member: "member2" },
  )
  const res = await redis.zunionstore(
      "destination",
      2,
      ["key1", "key2"],
      { aggregate: "sum" },
  );
  console.log(res) // 2
  ```
</RequestExample>


# Deployment
Source: https://upstash.com/docs/redis/sdks/ts/deployment



We support various platforms, such as nodejs, cloudflare and fastly. Platforms
differ slightly when it comes to environment variables and their `fetch` api.
Please use the correct import when deploying to special platforms.

## Node.js / Browser

Examples: Vercel, Netlify, AWS Lambda

If you are running on nodejs you can set `UPSTASH_REDIS_REST_URL` and
`UPSTASH_REDIS_REST_TOKEN` as environment variable and create a redis instance
like this:

```ts  theme={"system"}
import { Redis } from "@upstash/redis"

const redis = new Redis({
  url: <UPSTASH_REDIS_REST_URL>,
  token: <UPSTASH_REDIS_REST_TOKEN>,
})

// or load directly from env
const redis = Redis.fromEnv()
```

<Info>
  If you are running on nodejs v17 and earlier, `fetch` will not be natively
  supported. Platforms like Vercel, Netlify, Deno, Fastly etc. provide a polyfill
  for you. But if you are running on bare node, you need to either specify a
  polyfill yourself or change the import path slightly:

  ```typescript  theme={"system"}
  import { Redis } from "@upstash/redis/with-fetch";
  ```
</Info>

* [Code example](https://github.com/upstash/upstash-redis/blob/main/examples/nodejs)

## Cloudflare Workers

Cloudflare handles environment variables differently than Node.js. Please add
`UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` using
`wrangler secret put ...` or in the cloudflare dashboard.

Afterwards you can create a redis instance:

```ts  theme={"system"}
import { Redis } from "@upstash/redis/cloudflare"

const redis = new Redis({
  url: <UPSTASH_REDIS_REST_URL>,
  token: <UPSTASH_REDIS_REST_TOKEN>,
})


// or load directly from global env

// service worker
const redis = Redis.fromEnv()


// module worker
export default {
  async fetch(request: Request, env: Bindings) {
    const redis = Redis.fromEnv(env)
    // ...
  }
}
```

* [Code example](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers)
* [Code example typescript](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers-with-typescript)
* [Code example Wrangler 1](https://github.com/upstash/upstash-redis/tree/main/examples/cloudflare-workers-with-wrangler-1)
* [Documentation](https://docs.upstash.com/redis/tutorials/cloudflare_workers_with_redis)

## Fastly

Fastly introduces a concept called
[backend](https://developer.fastly.com/reference/api/services/backend/). You
need to configure a backend in your `fastly.toml`. An example can be found
[here](https://github.com/upstash/upstash-redis/blob/main/examples/fastly/fastly.toml).
Until the fastly api stabilizes we recommend creating an instance manually:

```ts  theme={"system"}
import { Redis } from "@upstash/redis/fastly"

const redis = new Redis({
  url: <UPSTASH_REDIS_REST_URL>,
  token: <UPSTASH_REDIS_REST_TOKEN>,
  backend: <BACKEND_NAME>,
})
```

* [Code example](https://github.com/upstash/upstash-redis/tree/main/examples/fastly)
* [Documentation](https://blog.upstash.com/fastly-compute-edge-with-redis)

## Deno

Examples: [Deno Deploy](https://deno.com/deploy),
[Netlify Edge](https://www.netlify.com/products/edge/)

```ts  theme={"system"}
import { Redis } from "https://deno.land/x/upstash_redis/mod.ts"

const redis = new Redis({
  url: <UPSTASH_REDIS_REST_URL>,
  token: <UPSTASH_REDIS_REST_TOKEN>,
})

// or
const redis = Redis.fromEnv();
```


# Developing or Testing
Source: https://upstash.com/docs/redis/sdks/ts/developing



When developing or testing your application, you might not want or can not use
Upstash over the internet. In this case, you can use a community project called
[Serverless Redis HTTP (SRH)](https://github.com/hiett/serverless-redis-http)
created by [Scott Hiett](https://x.com/hiettdigital).

SRH is a Redis proxy and connection pooler that uses HTTP rather than the Redis
binary protocol. The aim of this project is to be entirely compatible with
Upstash, and work with any Upstash supported Redis version.

We are working with Scott together to keep SRH up to date with the latest
Upstash features.

## Use cases for SRH:

* For usage in your CI pipelines, creating Upstash databases is tedious, or you
  have lots of parallel runs.
  * See [Using in GitHub Actions](#in-github-actions) on how to quickly get SRH
    setup for this context.
* For usage inside of Kubernetes, or any network whereby the Redis server is not
  exposed to the internet.
  * See [Using in Docker Compose](#via-docker-compose) for the various setup
    options directly using the Docker Container.
* For local development environments, where you have a local Redis server
  running, or require offline access.
  * See [Using the Docker Command](#via-docker-command), or
    [Using Docker Compose](#via-docker-compose).

## Setting up SRH

### Via Docker command

If you have a locally running Redis server, you can simply start an SRH
container that connects to it. In this example, SRH will be running on port
`8080`.

```bash  theme={"system"}
docker run \
    -it -d -p 8080:80 --name srh \
    -e SRH_MODE=env \
    -e SRH_TOKEN=your_token_here \
    -e SRH_CONNECTION_STRING="redis://your_server_here:6379" \
    hiett/serverless-redis-http:latest
```

### Via Docker Compose

If you wish to run in Kubernetes, this should contain all the basics would need
to set that up. However, be sure to read the Configuration Options, because you
can create a setup whereby multiple Redis servers are proxied.

```yml  theme={"system"}
version: "3"
services:
  redis:
    image: redis
    ports:
      - "6379:6379"
  serverless-redis-http:
    ports:
      - "8079:80"
    image: hiett/serverless-redis-http:latest
    environment:
      SRH_MODE: env
      SRH_TOKEN: example_token
      SRH_CONNECTION_STRING: "redis://redis:6379" # Using `redis` hostname since they're in the same Docker network.
```

### In GitHub Actions

SRH works nicely in GitHub Actions because you can run it as a container in a
job's services. Simply start a Redis server, and then SRH alongside it. You
don't need to worry about a race condition of the Redis instance not being
ready, because SRH doesn't create a Redis connection until the first command
comes in.

```yml  theme={"system"}
name: Test @upstash/redis compatibility
on:
  push:
  workflow_dispatch:

env:
  SRH_TOKEN: example_token

jobs:
  container-job:
    runs-on: ubuntu-latest
    container: denoland/deno
    services:
      redis:
        image: redis/redis-stack-server:6.2.6-v6 # 6.2 is the Upstash compatible Redis version
      srh:
        image: hiett/serverless-redis-http:latest
        env:
          SRH_MODE: env # We are using env mode because we are only connecting to one server.
          SRH_TOKEN: ${{ env.SRH_TOKEN }}
          SRH_CONNECTION_STRING: redis://redis:6379

    steps:
      # You can place your normal testing steps here. In this example, we are running SRH against the upstash/upstash-redis test suite.
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          repository: upstash/upstash-redis

      - name: Run @upstash/redis Test Suite
        run: deno test -A ./pkg
        env:
          UPSTASH_REDIS_REST_URL: http://srh:80
          UPSTASH_REDIS_REST_TOKEN: ${{ env.SRH_TOKEN }}
```

A huge thanks goes out to [Scott](https://hiett.dev/) for creating this project,
and for his continued efforts to keep it up to date with Upstash.


# Get Started
Source: https://upstash.com/docs/redis/sdks/ts/getstarted



`@upstash/redis` is written in Deno and can be imported from
[deno.land](https://deno.land)

```ts  theme={"system"}
import { Redis } from "https://deno.land/x/upstash_redis/mod.ts";
```

We transpile the package into an npm compatible package as well:

```bash  theme={"system"}
npm install @upstash/redis
```

```bash  theme={"system"}
yarn add @upstash/redis
```

```bash  theme={"system"}
pnpm add @upstash/redis
```

## Basic Usage:

```ts  theme={"system"}
import { Redis } from "@upstash/redis"

const redis = new Redis({
  url: <UPSTASH_REDIS_REST_URL>,
  token: <UPSTASH_REDIS_REST_TOKEN>,
})

// string
await redis.set('key', 'value');
let data = await redis.get('key');
console.log(data)

await redis.set('key2', 'value2', {ex: 1});

// sorted set
await redis.zadd('scores', { score: 1, member: 'team1' })
data = await redis.zrange('scores', 0, 100 )
console.log(data)

// list
await redis.lpush('elements', 'magnesium')
data = await redis.lrange('elements', 0, 100 )
console.log(data)

// hash
await redis.hset('people', {name: 'joe'})
data = await redis.hget('people', 'name' )
console.log(data)

// sets
await redis.sadd('animals', 'cat')
data  = await redis.spop('animals', 1)
console.log(data)
```


# Overview
Source: https://upstash.com/docs/redis/sdks/ts/overview



`@upstash/redis` is an HTTP/REST based Redis client for TypeScript, built on top
of [Upstash REST API](https://docs.upstash.com/features/restapi).

[![Tests](https://github.com/upstash/upstash-redis/actions/workflows/tests.yaml/badge.svg)](https://github.com/upstash/upstash-redis/actions/workflows/tests.yaml)
![npm (scoped)](https://img.shields.io/npm/v/@upstash/redis)
![npm bundle size](https://img.shields.io/bundlephobia/minzip/@upstash/redis)

You can find the Github Repository [here](https://github.com/upstash/upstash-redis).

It is the only connectionless (HTTP based) Redis client and designed for:

* Serverless functions (AWS Lambda ...)
* Cloudflare Workers (see
  [the example](https://github.com/upstash/upstash-redis/tree/master/examples/cloudflare-workers))
* Fastly Compute\@Edge (see
  [the example](https://github.com/upstash/upstash-redis/tree/master/examples/fastly))
* Next.js, Jamstack ...
* Client side web/mobile applications
* WebAssembly
* and other environments where HTTP is preferred over TCP.

See
[the list of APIs](https://docs.upstash.com/features/restapi#rest---redis-api-compatibility)
supported.


# Auto-Pipelining
Source: https://upstash.com/docs/redis/sdks/ts/pipelining/auto-pipeline



### Auto Pipelining

Auto pipelining allows you to use the Redis client as usual
while in the background it tries to send requests in batches
whenever possible.

In a nutshell, the client will accumulate commands in a pipeline
and wait for a short amount of time for more commands to arrive.
When there are no more commands, it will execute them as a batch.

To enable the feature, simply pass `enableAutoPipelining: true`
when creating the Redis client:

<CodeGroup>
  ```ts Redis theme={"system"}
  import { Redis } from "@upstash/redis";

  const redis = Redis.fromEnv({
    latencyLogging: false,
    enableAutoPipelining: true
  });
  ```

  ```ts fromEnv theme={"system"}
  import { Redis } from "@upstash/redis";

  const redis = new Redis({
    url: <UPSTASH_REDIS_REST_URL>,
    token: <UPSTASH_REDIS_REST_TOKEN>,
    enableAutoPipelining: true
  })
  ```
</CodeGroup>

This is especially useful in cases when we want to make async
requests or when we want to make requests in batches.

```ts  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = Redis.fromEnv({
  latencyLogging: false,
  enableAutoPipelining: true
});

// async call to redis. Not executed right away, instead
// added to the pipeline
redis.hincrby("Brooklyn", "visited", 1);

// making requests in batches
const brooklynInfo = Promise.all([
  redis.hget("Brooklyn", "coordinates"),
  redis.hget("Brooklyn", "population")
]);

// when we call await, the three commands are executed
// as a pipeline automatically. A single PIPELINE command
// is executed instead of three requests and the results
// are returned:
const [ coordinates, population ] = await brooklynInfo;
```

The benefit of auto pipelining is that it reduces the number
of HTTP requests made like pipelining and transaction while
being extremely simple to enable and use. It's especially
useful in cases like Vercel Edge and [Cloudflare Workers, where the number of
simultaneous requests is limited by 6](https://developers.cloudflare.com/workers/platform/limits/#account-plan-limits).

To learn more about how auto pipelining can be utilized in a
project, see
[the auto-pipeline example project under `upstash-redis` repository](https://github.com/upstash/upstash-redis/tree/main/examples/auto-pipeline)

### How it Works

For auto pipeline to work, the client keeps an active pipeline
and adds incoming commands to this pipeline. After the command
is added to the pipeline, execution of the pipeline is delayed
by releasing the control of the Node thread.

The pipeline executes when one of these two conditions are met:
No more commands are being added or at least one of the commands
added is being 'awaited'.

This means that if you are awaiting every time you run a command,
you won't benefit much from auto pipelining since each await will
trigger a pipeline:

```ts  theme={"system"}
const foo = await redis.get("foo") // makes a PIPELINE call
const bar = await redis.get("bar") // makes another PIPELINE call
```

In these cases, we suggest using `Promise.all`:

```ts  theme={"system"}
// makes a single PIPELINE call:
const [ foo, bar ] = await Promise.all([
  redis.get("foo"),
  redis.get("bar")
])
```

In addition to resulting in a single PIPELINE call, the commands
in `Promise.all` are executed in the order they are written!


# Pipeline & Transaction
Source: https://upstash.com/docs/redis/sdks/ts/pipelining/pipeline-transaction



### Pipeline

Pipelining commands allows you to send a single http request with multiple
commands. Keep in mind, that the execution of pipelines is not atomic and the
execution of other commands can interleave.

```ts  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = new Redis({
  /* auth */
});

const p = redis.pipeline();

// Now you can chain multiple commands to create your pipeline:

p.set("key", 2);
p.incr("key");

// or inline:
p.hset("key2", "field", { hello: "world" }).hvals("key2");

// Execute the pipeline once you are done building it:
// `exec` returns an array where each element represents the response of a command in the pipeline.
// You can optionally provide a type like this to get a typed response.
const res = await p.exec<[Type1, Type2, Type3]>();
```

For more information about pipelines using REST see
[here](https://blog.upstash.com/pipeline).

If you wish to benefit from pipeline automatically,
you can simply enable auto-pipelining to make your redis client
handle the commands in batches in the background. See
[the Auto-pipelining page](https://docs.upstash.com/redis/sdks/ts/pipelining/auto-pipeline).

### Transaction

Remember that the pipeline is able to send multiple commands at once but
can't execute them atomically. With transactions, you can make the commands
execute atomically.

```ts  theme={"system"}
import { Redis } from "@upstash/redis";

const redis = new Redis({
  /* auth */
});

const p = redis.multi();

p.set("key", 2);
p.incr("key");

// or inline:
p.hset("key2", "field", { hello: "world" }).hvals("key2");

// execute the transaction
const res = await p.exec<[Type1, Type2, Type3]>();
```


# Retries
Source: https://upstash.com/docs/redis/sdks/ts/retries



By default `@upstash/redis` will retry sending you request when network errors
occur. It will retry 5 times with a backoff of
`(retryCount) => Math.exp(retryCount) * 50` milliseconds.

You can customize this in the `Redis` constructor:

```ts  theme={"system"}
new Redis({
  url: UPSTASH_REDIS_REST_URL,
  token: UPSTASH_REDIS_REST_TOKEN,
  retry: {
    retries: 5,
    backoff: (retryCount) => Math.exp(retryCount) * 50,
  },
});
```

The exact type definition can be found
[here](https://github.com/upstash/upstash-redis/blob/4948b049e0d580d1de0a4cbfeac5565d7e035cc4/pkg/http.ts#LL31C1-L49C5).


# Troubleshooting
Source: https://upstash.com/docs/redis/sdks/ts/troubleshooting



## ReferenceError: fetch is not defined

#### Problem

If you are running on nodejs v17 and earlier, fetch will not be natively
supported. Platforms like Vercel, Netlify, Deno, Fastly etc. provide a polyfill
for you. But if you are running on bare node, you need to add a polyfill.

#### Solution

```bash  theme={"system"}
npm i isomorphic-fetch
```

```ts  theme={"system"}
import { Redis } from "@upstash/redis";
import "isomorphic-fetch";

const redis = new Redis({
  /*...*/
});
```

## Hashed Response

The response from a server is not what you expect but looks like a hash?

```ts  theme={"system"}
await redis.set("key", "value");
const data = await redis.get("key");
console.log(data);

// dmFsdWU=
```

#### Problem

By default `@upstash/redis` will request responses from the server to be base64
encoded. This is to prevent issues with some edge cases when storing data where
the http response fails to be deserialized using `res.json()`

This solves the problem for almost all edge cases, but it can cause new issues.

#### Solution

You can disable this behavior by setting `responseEncoding` to `false` in the
options.

```ts  theme={"system"}
const redis = new Redis({
  // ...
  responseEncoding: false,
});
```

This should no longer be necessary, but if you are still experiencing issues
with this, please let us know:

* [Discord](https://discord.gg/w9SenAtbme)
* [X](https://x.com/upstash)
* [GitHub](https://github.com/upstash/upstash-redis/issues/new)

## Large numbers are returned as string

You are trying to load a large number and it is returned as a string instead.

```ts  theme={"system"}
await redis.set("key", "101600000000150081467");
const res = await redis("get");

// "101600000000150081467"
```

#### Problem

Javascript can not handle numbers larger than `2^53 -1` safely and would return
wrong results when trying to deserialize them. In these cases the default
deserializer will return them as string instead. This might cause a mismatch
with your custom types.

#### Solution

Please be aware that this is a limitation of javascript and take special care
when handling large numbers.


# Unexpected Increase in Command Count
Source: https://upstash.com/docs/redis/troubleshooting/command_count_increases_unexpectedly



### Symptom

You notice an increasing command count for your Redis database in the Upstash Console, even when there are no connected clients.

### Diagnosis

The Upstash Console interacts with your Redis database to provide its functionality, which can result in an increased command count. This behavior is normal and expected. Here's a breakdown of why this occurs:

1. **Data Browser functionality:**
   The Data Browser tab sends various commands to list and display your keys, including:
   * SCAN: To iterate through the keyspace
   * GET: To retrieve values for keys
   * TTL: To check the time-to-live for keys

2. **Rate Limiting check:**
   The Console checks if your database is being used for Rate Limiting. This involves sending EXISTS commands for rate limiting-related keys.

3. **Other Console features:**
   Additional features in the Console may send commands to your database to retrieve or display information.

### Verification

You can use the Monitor tab in the Upstash Console to observe which commands are being sent by the Console itself. This can help you distinguish between Console-generated commands and those from your application or other clients.
Also, Usage tab contains 'Top Commands Usage' graph which shows the exact command history.

### Conclusion

The increasing command count you're seeing is likely due to the Console's normal operations and should not be a cause for concern. These commands do not significantly impact your database's performance or your usage limits.

If you have any further questions or concerns about command usage, please don't hesitate to contact Upstash support.


# ERR DB capacity quota exceeded
Source: https://upstash.com/docs/redis/troubleshooting/db_capacity_quota_exceeded



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR DB capacity quota exceeded
```

### Diagnosis

Your total database size exceeds the max data size limit of your current plan. When this limit is reached,
write requests may be rejected. Read and delete requests will not be affected.

### Solution-1

You can manually delete some entries to allow further writes. Additionally you
can consider setting TTL (expiration time) for your keys or enable
[eviction](../features/eviction) for your database.

### Solution-2

You can upgrade your database to Pro for higher limits.


# Error read ECONNRESET
Source: https://upstash.com/docs/redis/troubleshooting/econn_reset



### Symptom

The client can not connect to the database throwing an exception similar to:

```
[ioredis] Unhandled error event: Error: read ECONNRESET
    at TCP.onStreamRead (node:internal/stream_base_commons:211:20)
```

### Diagnosis

The server is TLS enabled but your connection (client) is not.

### Solution

Check your connection parameters and ensure you enable TLS.

If you are using a Redis URL then it should start with `rediss://`.

You can copy the correct client configuration from Upstash console clicking on
**Redis Connect** button.


# WRONGPASS invalid or missing auth token
Source: https://upstash.com/docs/redis/troubleshooting/http_unauthorized



### Symptom

The database rejects your request with an error similar to:

```
UpstashError: WRONGPASS invalid or missing auth token
```

### Diagnosis

The server rejects your request because the auth token is missing or invalid.

Most likely you have forgotten to set it in your environment variables, or you
are using a wrong token.

The connection password can only be used in traditional Redis clients. If you
want to connect over HTTP, you need to use the HTTP auth token.

### Solution

1. Check that you have set the `UPSTASH_REDIS_REST_TOKEN` in your environment
   variables and it is loaded correctly by your application at runtime.

2. Make sure you are using the correct HTTP auth token. You can copy the correct
   client configuration from the
   [Upstash console](https://console.upstash.com/redis) by copying the snippet
   from the `Connect to your database` -> `@upstash/redis` tab

<img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=6209760b747138fc787943506a201252" alt="" data-og-width="1981" width="1981" data-og-height="730" height="730" data-path="img/troubleshooting/rest/console_upstash_redis.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4ae457f93cdb787f8fb1b7bb51aa607a 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b2fefb3e70f7b9e106fcdfa90c2c3b4e 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=90a2ffdc9ca1652050aff49efd3f1dab 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d72ff8142eb9b2703caf02855dbd5d84 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e5136fc555176898fda2633ce154d1bb 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_upstash_redis.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=12ec155de0a225f79f855145ab8b0018 2500w" />

Or scroll further down to the `REST API` section and copy the
`UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` from there.

<img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0f64cdc01036d9144a9f35d544f6baf3" alt="" data-og-width="1981" width="1981" data-og-height="764" height="764" data-path="img/troubleshooting/rest/console_rest_api.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=9500d27d655732d9c170ec9a9d5b4192 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=feb6821d6de3810083e7f7121a3b2fab 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cd2e074c8767f9d1ba413d2cfc796132 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5c73b679a9202d0eb90f042b8f216579 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2e8848bb2ae95f1bdca73490439aa4aa 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/troubleshooting/rest/console_rest_api.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=7dd7cffe9ce3651a0a4a4e95e45399bd 2500w" />


# ERR max concurrent connections exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_concurrent_connections



### Symptom

New clients can not connect to the database throwing an exception similar to:

```
"message" : "[ioredis] Unhandled error event:
ReplyError: ERR max concurrent connections exceeded\r
at Object.onceWrapper (events.js:286:20)\r
at Socket.emit (events.js:203:15)\r    at Socket.EventEmitter.emit (domain.js:448:20)\r
at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1093:10)\n"
```

### Diagnosis

You have reached the concurrent connection limit.

### Solution-1

You need to manage connections more efficiently. If you are using serverless
functions, you can create the Redis client inside the function and close the
connection when you are done with the database as below.

<Note>
  This solution may have a latency overhead (about 4 ms). See [the blog
  post](https://blog.upstash.com/serverless-database-connections) for more.
</Note>

```javascript  theme={"system"}
exports.handler = async (event) => {
  const client = new Redis(process.env.REDIS_URL);
  /*
    do stuff with redis
     */
  await client.quit();
  /*
  do other stuff
   */
  return {
    response: "response",
  };
};
```

### Solution-2

You can use [@upstash/redis](https://github.com/upstash/upstash-redis) client
which is REST based so it does not have any connection related problems.

### Solution-3

You can upgrade your database to Pro for higher limits.

<Info>
  See [the blog post](https://blog.upstash.com/serverless-database-connections)
  about the database connections in serverless functions.
</Info>


# ERR max daily request limit exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_daily_request_limit



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR max daily request limit exceeded
```

### Diagnosis

Your database exceeds the max daily request count limit.

### Solution-1

You can refactor your application to send less number of commands.

### Solution-2

You can upgrade your database to a paid plan, such as pay-as-you-go or a fixed plan
by entering a payment method. When you entered your credit card, your database will be upgraded
automatically.

See [here](../howto/upgradedatabase) for more information.


# ERR max key size exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_key_size_exceeded



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR max key size exceeded. Limit: X bytes, Actual: Z bytes
```

### Diagnosis

Size of the key in the request exceeds the max key size limit, which is `32Kb`.

### Solution

This is a hardcoded limit and cannot be configured per database. You should
reduce the key size.


# ERR max single record size exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_record_size_exceeded



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR max single record size exceeded
```

### Diagnosis

An entry size exceeds the max record size limit which is `100Mb` for "Free" and
"Pay as you go" databases. You may reach this limit either by inserting a single
huge value or appending many small values to an entry. This entry can be a
String, List, Set, Hash etc. Read (`GET`, `LRANGE`, `HMGET`, `ZRANGE` etc) and
delete (`DEL`, `LPOP`, `HDEL`, `SREM` etc) requests will not be affected.

### Solution-1

You can split your data into smaller chunks and store them as separate entries
with different keys.

### Solution-2

You can upgrade your database to Pro as it has higher limits. Also
you can submit quota increase request in the console or contact
[support@upstash.com](mailto:support@upstash.com) about the options with higher max record size limit.


# ERR max request size exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_request_size_exceeded



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR max request size exceeded
```

### Diagnosis

Your command exceeds the max request size which is `10MB` for "Free" and "Pay as
you go" databases.

### Solution-1

You can split your data into smaller chunks and send them in separate commands.

### Solution-2

You can upgrade your database to a higher plan, or apply a custom quota increase if you are on Pay-as-You-Go plan. Please reach out to [support@upstash.com](mailto:support@upstash.com) about the options with higher max request size limit.

<Note>
  max-request-size-limit is about the size of a single request. Your data
  structure (like list, set) can exceed the max request size limit without any
  problem. If you try to load all elements in the list with a single request
  then it can throw the max-request-size-limit exception.
</Note>


# ERR max requests limit exceeded
Source: https://upstash.com/docs/redis/troubleshooting/max_requests_limit



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR max requests limit exceeded. 
```

### Diagnosis

Your database exceeds the max monthly request count limit.

### Solution-1

You can refactor your application to send less number of commands.

### Solution-2

You can upgrade your database to a paid plan, such as pay-as-you-go or a fixed plan
by entering a payment method. When you entered your credit card, your database will be upgraded
automatically.

See [here](../howto/upgradedatabase) for more information.


# NOAUTH Authentication Required
Source: https://upstash.com/docs/redis/troubleshooting/no_auth



### Symptom

The client can not connect to the database throwing an exception similar to:

```
[ioredis] Unhandled error event:
ReplyError: NOAUTH Authentication required
```

### Diagnosis

The server does not let you connect because the password is missing in your
connection parameters.

### Solution

Check your connection parameters and ensure they contain the password. If you
are using ioredis (Redis client) with a Redis URL, check the URL format. ioredis
requires a colon before the password. The format for IORedis - TLS enabled

```
rediss://:YOUR_PASSWORD@YOUR_ENDPOINT:YOUR_PORT
```

The format for IORedis - TLS disabled

```
redis://:YOUR_PASSWORD@YOUR_ENDPOINT:YOUR_PORT
```

You can copy the correct client configuration from Upstash console clicking on
**Redis Connect** button.


# ERR XReadGroup is cancelled
Source: https://upstash.com/docs/redis/troubleshooting/stream_pel_limit



### Symptom

The client gets an exception similar to:

```
ReplyError: ERR XReadGroup is cancelled. Pending Entries List limit per consumer is about to be reached. Limit: 1000, Current PEL size: 90, Requested Read: 20, Key: mstream, Group: group1, Consumer: consumer1.
```

### Diagnosis

Pending Entries List of the stream for the consumer is full. For each consumer
in a consumer group, there is a pending entries list. This list keeps the
messages that are delivered to a consumer but not yet acknowledged via
[XACK](https://redis.io/commands/xack/). This list is populated via
[XREADGROUP](https://redis.io/commands/xreadgroup/).

### Solution

Acknowledge the consumed messages via [XACK](https://redis.io/commands/xack/)
from the list of the associated group and consumer.


# Deploy a Serverless API with AWS CDK and AWS Lambda
Source: https://upstash.com/docs/redis/tutorials/api_with_cdk



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/aws-cdk-typescript" horizontal>
  You can find the project source code on GitHub.
</Card>

In this tutorial, we will implement a Serverless API using AWS Lambda and we
will deploy it using AWS CDK. We will use Typescript as the CDK language. It
will be a view counter where we keep the state in Redis.

### What is AWS CDK?

AWS CDK is an interesting project which allows you to provision and deploy AWS
infrastructure with code. Currently TypeScript, JavaScript, Python, Java,
C#/.Net and Go are supported. You can compare AWS CDK with following technologies:

* AWS CloudFormation
* AWS SAM
* Serverless Framework

The above projects allows you to set up the infrastructure with configuration
files (yaml, json) while with AWS CDK, you set up the resources with code. For
more information about CDK see the related
[AWS Docs](https://docs.aws.amazon.com/cdk/latest/guide/home.html).

### Prerequisites

* Complete all steps in [Getting started with the AWS CDK](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html)

### Project Setup

Create and navigate to a directory named `counter-cdk`. The CDK CLI uses this directory name to name things in your CDK code, so if you decide to use a different name, don't forget to make the appropriate changes when applying this tutorial.

```shell  theme={"system"}
mkdir counter-cdk && cd counter-cdk
```

Initialize a new CDK project.

```shell  theme={"system"}
cdk init app --language typescript
```

Install `@upstash/redis`.

```shell  theme={"system"}
npm install @upstash/redis
```

### Counter Function Setup

Create `/api/counter.ts`.

```ts /api/counter.ts theme={"system"}
import { Redis } from '@upstash/redis';

const redis = Redis.fromEnv();

export const handler = async function() {
    const count = await redis.incr("counter");
    return {
        statusCode: 200,
        body: JSON.stringify('Counter: ' + count),
    };
};
```

### Counter Stack Setup

Update `/lib/counter-cdk-stack.ts`.

```ts /lib/counter-cdk-stack.ts theme={"system"}
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as lambda from 'aws-cdk-lib/aws-lambda';
import * as nodejs from 'aws-cdk-lib/aws-lambda-nodejs';

export class CounterCdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const counterFunction = new nodejs.NodejsFunction(this, 'CounterFunction', {
      entry: 'api/counter.ts',
      handler: 'handler',
      runtime: lambda.Runtime.NODEJS_20_X,
      environment: {
        UPSTASH_REDIS_REST_URL: process.env.UPSTASH_REDIS_REST_URL || '',
        UPSTASH_REDIS_REST_TOKEN: process.env.UPSTASH_REDIS_REST_TOKEN || '',
      },
      bundling: {
        format: nodejs.OutputFormat.ESM,
        target: "node20",
        nodeModules: ['@upstash/redis'],
      },
    });

    const counterFunctionUrl = counterFunction.addFunctionUrl({
      authType: lambda.FunctionUrlAuthType.NONE,
    });

    new cdk.CfnOutput(this, "counterFunctionUrlOutput", {
      value: counterFunctionUrl.url,
    })
  }
}
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Deploy

Run in the top folder:

```shell  theme={"system"}
cdk synth
cdk bootstrap
cdk deploy
```

Visit the output URL.


# Autocomplete API with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/auto_complete_with_serverless_redis



This tutorial implements an autocomplete API powered by serverless Redis. See
[the demo](https://auto-complete-example.vercel.app/) and
[API endpoint](https://wfgz7cju24.execute-api.us-east-1.amazonaws.com/query?term=ca)
and
[the source code](https://github.com/upstash/examples/tree/main/examples/auto-complete-api).

We will keep country names in a Redis Sorted set. In Redis sorted set, elements
with the same score are sorted lexicographically. So in our case, all country
names will have the same score, 0. We keep all prefixes of country and use ZRANK
to find the terms to suggest. See
[this blog post](https://oldblog.antirez.com/post/autocomplete-with-redis.html)
for the details of the algorithm.

### Step 1: Project Setup

<Note>
  I will use Serverless framework for this tutorial. You can also use [AWS
  SAM](/redis/tutorials/using_aws_sam)
</Note>

If you do not have it already install serverless framework via:
`npm install -g serverless`

In any folder run `serverless` as below:

```text  theme={"system"}
>> serverless

Serverless: No project detected. Do you want to create a new one? Yes
Serverless: What do you want to make? AWS Node.js
Serverless: What do you want to call this project? test-upstash

Project successfully created in 'test-upstash' folder.

You can monitor, troubleshoot, and test your new service with a free Serverless account.

Serverless: Would you like to enable this? No
You can run the ‚Äúserverless‚Äù command again if you change your mind later.
```

Inside the project folder create a node project with the command:

```
npm init
```

Then install the redis client with:

```
npm install ioredis
```

### Step 2: API Implementation

Edit handler.js file as below. See
[the blog post](https://oldblog.antirez.com/post/autocomplete-with-redis.html)
for the details of the algorithm.

```javascript  theme={"system"}
var Redis = require("ioredis");
if (typeof client === "undefined") {
  var client = new Redis(process.env.REDIS_URL);
}
const headers = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Credentials": true,
};

module.exports.query = async (event, context, callback) => {
  if (!event.queryStringParameters || !event.queryStringParameters.term) {
    return {
      statusCode: 400,
      headers: headers,
      body: JSON.stringify({
        message: "Invalid parameters. Term needed as query param.",
      }),
    };
  }
  let term = event.queryStringParameters.term.toUpperCase();
  let res = [];
  let rank = await client.zrank("terms", term);
  if (rank != null) {
    let temp = await client.zrange("terms", rank, rank + 100);
    for (const el of temp) {
      if (!el.startsWith(term)) {
        break;
      }
      if (el.endsWith("*")) {
        res.push(el.substring(0, el.length - 1));
      }
    }
  }
  return {
    statusCode: 200,
    headers: headers,
    body: JSON.stringify({
      message: "Query:" + event.queryStringParameters.term,
      result: res,
    }),
  };
};
```

### Step 3: Create database on Upstash

If you do not have one, create a database following this
[guide](../overall/getstarted). Copy the Redis URL by clicking `Redis Connect`
button inside database page. Copy the URL for ioredis as we use ioredis in our
application. Create .env file and paste your Redis URL:

```text  theme={"system"}
REDIS_URL=YOUR_REDIS_URL
```

<Snippet file="redis/ioredisnote.mdx" />

### Step 4: Initialize Database

We will initialize the database with country names. Copy and run initdb.js
script from
[here](https://github.com/upstash/examples/tree/main/examples/auto-complete-api/initdb.js).

We simply put the country names and all their prefixes to the sorted set.

```javascript  theme={"system"}
require('dotenv').config()
var Redis = require("ioredis");

var countries = [
    {"name": "Afghanistan", "code": "AF"},
    {"name": "√Öland Islands", "code": "AX"},
    {"name": "Albania", "code": "AL"},
    {"name": "Algeria", "code": "DZ"},
    ...
]
var client = new Redis(process.env.REDIS_URL);

for (const country of countries) {
    let term = country.name.toUpperCase();
    let terms = [];

    for (let i = 1; i < term.length; i++) {
        terms.push(0);
        terms.push(term.substring(0, i));
    }
    terms.push(0);
    terms.push(term + "*");
    (async () => {
        await client.zadd("terms", ...terms)
    })();
}
```

### Step 5: Deploy Your Function

Edit `serverless.yml` as below and replace your Redis URL:

```yaml  theme={"system"}
service: auto-complete-api
# add this if you set REDIS_URL in .env
useDotenv: true
frameworkVersion: "2"

provider:
  name: aws
  runtime: nodejs14.x
  lambdaHashingVersion: 20201221
  environment:
    REDIS_URL: REPLACE_YOUR_REDIS_URL

functions:
  query:
    handler: handler.query
    events:
      - httpApi:
          path: /query
          method: get
          cors: true
```

In the project folder run:

```
serverless deploy
```

Now you can run your function with:

```shell  theme={"system"}
serverless invoke -f query -d '{ "queryStringParameters": {"term":"ca"}}'
```

It should give the following output:

```json  theme={"system"}
{
  "statusCode": 200,
  "headers": {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Credentials": true
  },
  "body": "{\"message\":\"Query:ca\",\"result\":[\"CAMBODIA\",\"CAMEROON\",\"CANADA\",\"CAPE VERDE\",\"CAYMAN ISLANDS\"]}"
}
```

You can also test your function using AWS console. In your AWS Lambda section,
click on your function. Scroll down to the code sections and click on the `Test`
button on the top right. Use `{ "queryStringParameters": {"term":"ar"}}` as your
event data.

### Step 6: Run Your Function Locally

In your project folder run:

```shell  theme={"system"}
serverless invoke local -f query -d '{ "queryStringParameters": {"term":"ca"}}'
```

It should give the following output:

```json  theme={"system"}
{
  "statusCode": 200,
  "headers": {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Credentials": true
  },
  "body": "{\"message\":\"Query:ca\",\"result\":[\"CAMBODIA\",\"CAMEROON\",\"CANADA\",\"CAPE VERDE\",\"CAYMAN ISLANDS\"]}"
}
```


# Build Stateful Applications with AWS App Runner and Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/aws_app_runner_with_redis

This tutorial shows how to create a serverless and stateful application using AWS App Runner and Redis

AWS App Runner is a container service where AWS runs and scales your container
in a serverless way. The container storage is ephemeral so you should keep the
state in an external data store. In this tutorial we will build a simple
application which will keep the state on Redis and deploy the application to AWS
App Runner.

### The Stack

* Serverless compute: AWS App Runner (Node.js)
* Serverless data store: Redis via Upstash
* Deployment source: github repo

### Project Setup

Create a directory for your project:

```
mkdir app_runner_example

cd app_runner_example
```

Create a node project and install dependencies:

```
npm init

npm install ioredis
```

Create a Redis DB from [Upstash](https://console.upstash.com). In the database
details page, copy the connection code (Node tab).

### The Code

In your node project folder, create server.js and copy the below code:

```javascript  theme={"system"}
var Redis = require("ioredis");
const http = require("http");

if (typeof client === "undefined") {
  var client = new Redis(process.env.REDIS_URL);
}

const requestListener = async function (req, res) {
  if (req.url !== "/favicon.ico") {
    let count = await client.incr("counter");
    res.writeHead(200);
    res.end("Page view:" + count);
  }
};

const server = http.createServer(requestListener);
server.listen(8080);
```

<Snippet file="redis/ioredisnote.mdx" />

As you see, the code simple increment a counter on Redis and returns the
response as the page view count.

### Deployment

You have two options to deploy your code to the App Runner. You can either share
your Github repo with AWS or register your docker image to ECR. In this
tutorial, we will share
[our Github repo](https://github.com/upstash/app_runner_example) with App
Runner.

Create a github repo for your project and push your code. In AWS console open
the App Runner service. Click on `Create Service` button. Select
`Source code repository` option and add your repository by connecting your
Github and AWS accounts.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=257c8e3c17c49e7ce4d540c115a44ab4" width="800" data-og-width="1690" data-og-height="1792" data-path="img/examples/apprunner/source.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9a0f79f37bf280d8d02ac5dbdedbfee8 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d68a216826709130447784bcd48c7d9e 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4367057cffb506ca6baf8a863342fe2d 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5cdf9e0c158382c5cc9aa3a631dfb0f5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2f54cf24a72fd76749cf73c887017215 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/source.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d70e31e959cedeccf917ed656c0e662c 2500w" />
</Frame>

In the next page, choose `Nodejs 12` as your runtime, `npm install` as your
build command, `node server` as your start command and `8080` as your port.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=bdc3f54a3954bfeacbde8a90a3e75c83" width="800" data-og-width="1672" data-og-height="1466" data-path="img/examples/apprunner/build.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6d130cb0552af083b47fa257ff042b19 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=8504c284a04e2c2c427889927c69b0e9 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=bc810f82cc68c21a9c2b82a16f487dac 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0a0795bca77f664b73e6d1262447a47c 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2b7c068eccfbb5ed0d1b92e76259d674 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/build.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=05cecd6d436103f0d41862edfe0f025d 2500w" />
</Frame>

The next page configures your App Runner service. Set a name for your service.
Set your Redis URL that you copied from Upstash console as `REDIS_URL`
environment variable. Your Redis URL should be something like this:
`rediss://:d34baef614b6fsdeb01b25@us1-lasting-panther-33618.upstash.io:33618`
You can leave other settings as default.

<Frame>
  <img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=085224000b55e35b2df639faa88d95be" width="800" data-og-width="1680" data-og-height="1842" data-path="img/examples/apprunner/config.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=132ec2c148eece5b4fa59787a319920b 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7cc6bfa0d010c77d4fcf8b31195578f0 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c463380067d8935fd9b0f0d061d0fd9e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=11b6129f85fc21430e744bb3884dfaf3 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e5164cab6f2648590b029f4c98db3f2e 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/apprunner/config.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=946dbca3821e4f355bb700fff8c02439 2500w" />
</Frame>

Click on `Create and Deploy` at the next page. Your service will be ready in a
few minutes. Click on the default domain, you should see the page with a view
counter as [here](https://xmzuanrpf3.us-east-1.awsapprunner.com/).

### App Runner vs AWS Lambda

* AWS Lambda runs functions, App Runner runs applications. So with App Runner
  you do not need to split your application to functions.
* App Runner is a more portable solution. You can move your application from App
  Runner to any other container service.
* AWS Lambda price scales to zero, App Runner's does not. With App Runner you
  need to pay for an at least one instance unless you pause the system.

App Runner is great alternative when you need more control on your serverless
runtime and application. Check out
[this video](https://www.youtube.com/watch?v=x_1X_4j16A4) to learn more about
App Runner.


# Session Management on Google Cloud Run with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/cloud_run_sessions

This tutorial shows how to manage user sessions on Google Cloud Run using Serverless Redis.

Developers are moving their apps to serverless architectures and one of the most
common questions is
[how to store user sessions](https://stackoverflow.com/questions/57711095/are-users-sessions-on-google-cloud-run-apps-directed-to-the-same-instance).
You need to keep your state and session data in an external data store because
serverless environments are stateless by design. Unfortunately most of the
databases are not serverless friendly. They do not support per-request pricing
or they require heavy and persistent connections. These also explain the
motivations why we built Upstash. Upstash is a serverless Redis database with
per-request pricing, durable storage.

In this article I will write a basic web application which will run on Google
Cloud Run and keep the user sessions in Upstash Redis. Google Cloud Run provides
Serverless Container service which is also stateless. Cloud Run is more powerful
than serverless functions (AWS Lambda, Cloud Functions) as you can run your own
container. But you can not guarantee that the same container instance will
process the requests of the same user. So you need to keep the user session in
an external storage. Redis is the most popular choice to keep the session data
thanks to its speed and simplicity. Upstash gives you the serverless Redis
database which fits perfectly to your serverless stack.

If you want to store your session data manually on Redis, check
[here](/redis/tutorials/using_google_cloud_functions). But in
this article I will use [Express session](https://github.com/expressjs/session)
middleware which can work with Redis for user session management.

Here is the [live demo.](https://cloud-run-sessions-dr7fcdmn3a-uc.a.run.app)

Here is the
[source code](https://github.com/upstash/examples/tree/master/examples/cloud-run-sessions)

## The Stack

Serverless processing: Google Cloud Run

Serverless data: Upstash

Web framework: Express

## Project Setup

Create a directory for your project:

```
mkdir cloud-run-sessions

cd cloud-run-sessions
```

Create a node project and install dependencies:

```
npm init

npm install express redis connect-redis express-session
```

Create a Redis DB from [Upstash](https://console.upstash.com). In the database
details page, click the Connect button, copy the connection code (Node.js
node-redis).

If you do not have it already, install Google Cloud SDK as described
[here.](https://cloud.google.com/sdk/docs/install) Set the project and enable
Google Run and Build services:

```
gcloud config set project cloud-run-sessions

gcloud services enable run.googleapis.com

gcloud services enable cloudbuild.googleapis.com
```

## The Code

Create index.js and update as below:

```javascript  theme={"system"}
var express = require("express");
var parseurl = require("parseurl");
var session = require("express-session");
const redis = require("redis");

var RedisStore = require("connect-redis")(session);
var client = redis.createClient({
  // REPLACE HERE
});

var app = express();

app.use(
  session({
    store: new RedisStore({ client: client }),
    secret: "forest squirrel",
    resave: false,
    saveUninitialized: true,
  })
);

app.use(function (req, res, next) {
  if (!req.session.views) {
    req.session.views = {};
  }

  // get the url pathname
  var pathname = parseurl(req).pathname;

  // count the views
  req.session.views[pathname] = (req.session.views[pathname] || 0) + 1;
  next();
});

app.get("/", function (req, res, next) {
  res.send("you viewed this page " + req.session.views["/"] + " times");
});

app.get("/foo", function (req, res, next) {
  res.send("you viewed this page " + req.session.views["/foo"] + " times");
});

app.get("/bar", function (req, res, next) {
  res.send("you viewed this page " + req.session.views["/bar"] + " times");
});

app.listen(8080, function () {
  console.log("Example app listening on port 8080!");
});
```

Run the app: `node index.js`

Check [http://localhost:3000/foo](http://localhost:3000/foo) in different
browsers to validate it keeps the session.

Add the start script to your `package.json`:

```json  theme={"system"}
"scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node index"
  }
```

## Build

Create a Docker file (Dockerfile) in the project folder as below:

```
# Use the official lightweight Node.js 12 image.
# https://hub.docker.com/_/node
FROM node:12-slim

# Create and change to the app directory.
WORKDIR /usr/src/app

# Copy application dependency manifests to the container image.
# A wildcard is used to ensure both package.json AND package-lock.json are copied.
# Copying this separately prevents re-running npm install on every code change.
COPY package*.json ./

# Install dependencies.
RUN npm install

# Copy local code to the container image.
COPY . ./

# Run the web service on container startup.
CMD [ "npm", "start" ]
```

Build your container image:

```
gcloud builds submit --tag gcr.io/cloud-run-sessions/main
```

List your container images: `gcloud container images list`

Run the container locally:

```
gcloud auth configure-docker

docker run -d -p 8080:8080 gcr.io/cloud-run-sessions/main:v0.1
```

In case you have an issue on docker run, check
[here](https://cloud.google.com/container-registry/docs/troubleshooting).

## Deploy

Run:

```
gcloud run deploy cloud-run-sessions \

  --image gcr.io/cloud-run-sessions/main:v0.1 \

  --platform managed \

  --region us-central1 \

  --allow-unauthenticated
```

This command should give you
[the URL of your application](https://cloud-run-sessions-dr7fcdmn3a-uc.a.run.app)
as below:

```
Deploying container to Cloud Run service [cloud-run-sessions] in project [cloud-run-sessions] region [us-central1]

  ‚úì Deploying... Done.

  ‚úì Creating Revision...

  ‚úì Routing traffic...

  ‚úì Setting IAM Policy...

Done.

Service [cloud-run-sessions] revision [cloud-run-sessions-00006-dun] has been deployed and is serving 100 percent of traffic.

Service URL: https://cloud-run-sessions-dr7fcdmn3a-uc.a.run.app
```

## Cloud Run vs Cloud Functions

I have developed two small prototypes with both. Here my impression:

* Simplicity: Cloud functions are simpler to deploy as it does not require any
  container building step.
* Portability: Cloud Run leverages your container, so anytime you can move your
  application to any containerized system. This is a plus for Cloud Run.
* Cloud Run looks more powerful as it runs your own container with more
  configuration options. It also allows running longer tasks (can be extended to
  60 minutes)
* Cloud Run looks more testable as you can run the container locally. Cloud
  Functions require a simulated environment.

Personally, I see Cloud Functions as a pure serverless solution where Cloud Run
is a hybrid solution. I would choose Cloud functions for simple, self contained
tasks or event driven solutions. If my use case is more complex with
portability/testability requirements, then I would choose Cloud Run.


# Cloudflare Workers with Websockets and Redis
Source: https://upstash.com/docs/redis/tutorials/cloudflare_websockets_redis





# Use Redis in Cloudflare Workers
Source: https://upstash.com/docs/redis/tutorials/cloudflare_workers_with_redis



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/cloudflare-workers-with-typescript" horizontal>
  You can find the project source code on GitHub.
</Card>

This tutorial showcases using Redis with REST API in Cloudflare Workers. We will
write a sample edge function (Cloudflare Workers) which will show a custom
greeting depending on the location of the client. We will load the greeting
message from Redis so you can update it without touching the code.

### Why Upstash?

* Cloudflare Workers does not allow TCP connections. Upstash provides REST API
  on top of the Redis database.
* Upstash is a serverless offering with per-request pricing which fits for edge
  and serverless functions.
* Upstash Global database provides low latency all over the world.

### Prerequisites

1. Install the Cloudflare Wrangler CLI with `npm install wrangler --save-dev`

### Project Setup

Create a Cloudflare Worker with the following options:

```shell  theme={"system"}
‚ûú  tutorials > ‚úó npx wrangler init
‚ï≠ Create an application with Cloudflare Step 1 of 3
‚îÇ
‚îú In which directory do you want to create your application?
‚îÇ dir ./greetings-cloudflare
‚îÇ
‚îú What would you like to start with?
‚îÇ category Hello World example
‚îÇ
‚îú Which template would you like to use?
‚îÇ type Hello World Worker
‚îÇ
‚îú Which language do you want to use?
‚îÇ lang TypeScript
‚îÇ
‚îú Copying template files
‚îÇ files copied to project directory
‚îÇ
‚îú Updating name in `package.json`
‚îÇ updated `package.json`
‚îÇ
‚îú Installing dependencies
‚îÇ installed via `npm install`
‚îÇ
‚ï∞ Application created

‚ï≠ Configuring your application for Cloudflare Step 2 of 3
‚îÇ
‚îú Installing @cloudflare/workers-types
‚îÇ installed via npm
‚îÇ
‚îú Adding latest types to `tsconfig.json`
‚îÇ added @cloudflare/workers-types/2023-07-01
‚îÇ
‚îú Retrieving current workerd compatibility date
‚îÇ compatibility date 2024-10-22
‚îÇ
‚îú Do you want to use git for version control?
‚îÇ no git
‚îÇ
‚ï∞ Application configured
```

Install Upstash Redis:

```shell  theme={"system"}
cd greetings-cloudflare
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `wrangler.toml` file.

```toml wrangler.toml theme={"system"}
# existing config

[vars]
UPSTASH_REDIS_REST_URL = <YOUR_URL>
UPSTASH_REDIS_REST_TOKEN = <YOUR_TOKEN>
```

Using CLI Tab in the Upstash Console, add some greetings to your database:

<img src="https://mintlify.s3.us-west-1.amazonaws.com/upstash/redis/tutorials/img/examples/tutorial-cloudflare-workers.png" alt="CLI Tab" />

### Greetings Function Setup

Update `src/index.ts`:

```typescript src/index.ts theme={"system"}
import { Redis } from '@upstash/redis/cloudflare';

type RedisEnv = {
	UPSTASH_REDIS_REST_URL: string;
	UPSTASH_REDIS_REST_TOKEN: string;
};

export default {
	async fetch(request: Request, env: RedisEnv) {
		const redis = Redis.fromEnv(env);

		const country = request.headers.get('cf-ipcountry');
		if (country) {
			const greeting = await redis.get<string>(country);
			if (greeting) {
				return new Response(greeting);
			}
		}

		return new Response('Hello!');
	},
};
```

The code tries to find out the user's location checking the "cf-ipcountry"
header. Then it loads the corresponding greeting for that location using the Redis
REST API.

### Run Locally

Run the following command to start your dev session:

```shell  theme={"system"}
npx wrangler dev
```

Visit [localhost:8787](http://localhost:8787)

### Build and Deploy

Build and deploy your app to Cloudflare:

```shell  theme={"system"}
npx wrangler deploy
```

Visit the output url.


# Backendless Coin Price List with GraphQL API, Serverless Redis and Next.JS
Source: https://upstash.com/docs/redis/tutorials/coin_price_list



In this tutorial, we will develop a simple coin price list using GraphQL API of
Upstash. You can call the application `backendless` because we will access the
database directly from the client (javascript). See the
[code](https://github.com/upstash/examples/tree/master/examples/coin-price-list).

<Frame>
  <img src="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=4cc171b213a162cdf7be374cb7fac8aa" width="800" data-og-width="978" data-og-height="838" data-path="img/coin-price-list/coin-price-list.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=280&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=1b11b6e6b6cfff8dd5ac4f6667729b0f 280w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=560&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=98661149f74b188766906b70c818594d 560w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=840&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=26ff2dd16d3b983ffd2232186b81663c 840w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=1100&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=5cf6db7c709559f0d3928c58a11b47cd 1100w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=1650&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=f41aab64d68ef20b3cca5ce108307435 1650w, https://mintcdn.com/upstash/ZVIIe-nWA4-ORRYS/img/coin-price-list/coin-price-list.png?w=2500&fit=max&auto=format&n=ZVIIe-nWA4-ORRYS&q=85&s=d73c91b72d1e6c8058839c4dc7bf2f09 2500w" />
</Frame>

## Motivation

We want to give a use case where you can use the GraphQL API without any backend
code. The use case is publicly available read only data for web applications
where you need low latency. The data is updated frequently by another backend
application, you want your users to see the last updated data. Examples:
Leaderboards, news list, blog list, product list, top N items in the homepages.

### `1` Project Setup:

Create a Next application: `npx create-next-app`.

Install Apollo GraphQL client: `npm i @apollo/client`

### `2` Database Setup

If you do not have one, create a database following this
[guide](../overall/getstarted). Connect your database via Redis CLI and run:

```shell  theme={"system"}
rpush coins '{ "name" : "Bitcoin", "price": 56819, "image": "https://s2.coinmarketcap.com/static/img/coins/64x64/1.png"}' '{ "name" : "Ethereum", "price": 2130, "image": "https://s2.coinmarketcap.com/static/img/coins/64x64/1027.png"}' '{ "name" : "Cardano", "price": 1.2, "image": "https://s2.coinmarketcap.com/static/img/coins/64x64/2010.png"}' '{ "name" : "Polkadot", "price": 35.96, "image": "https://s2.coinmarketcap.com/static/img/coins/64x64/6636.png"}' '{ "name" : "Stellar", "price": 0.506, "image": "https://s2.coinmarketcap.com/static/img/coins/64x64/512.png"}'
```

### `3` Code

In the Upstash console, copy the read only access key in your API configuration
page (GraphQL Explorer > Configure API). In the `_app.js` create the Apollo
client and replace the your access key as below:

<Warning>
  You need to use Read Only Access Key, because the key will be accessible
  publicly.
</Warning>

```javascript  theme={"system"}
import "../styles/globals.css";
import {
  ApolloClient,
  ApolloProvider,
  createHttpLink,
  InMemoryCache,
} from "@apollo/client";

const link = createHttpLink({
  uri: "https://graphql-us-east-1.upstash.io/",
  headers: {
    Authorization: "Bearer YOUR_ACCESS_TOKEN",
  },
});
const client = new ApolloClient({
  uri: "https://graphql-us-east-1.upstash.io/",
  cache: new InMemoryCache(),
  link,
});

function MyApp({ Component, pageProps }) {
  return (
    <ApolloProvider client={client}>
      <Component {...pageProps} />{" "}
    </ApolloProvider>
  );
}

export default MyApp;
```

Edit `index.js` as below:

```javascript  theme={"system"}
import Head from "next/head";
import styles from "../styles/Home.module.css";
import { gql, useQuery } from "@apollo/client";
import React from "react";

const GET_COIN_LIST = gql`
  query {
    redisLRange(key: "coins", start: 0, stop: 6)
  }
`;

export default function Home() {
  let coins = [];
  const { loading, error, data } = useQuery(GET_COIN_LIST);

  if (!loading && !error) {
    for (let x of data.redisLRange) {
      let dd = JSON.parse(x);
      coins.push(dd);
    }
  }

  return (
    <div className={styles.container}>
      <Head>
        <title>Create Next App</title>
        <link rel="icon" href="/favicon.ico" />
      </Head>

      <main className={styles.main}>
        <h3 className={styles.title}>Coin Price List</h3>

        <div className={styles.grid}>
          <table className={styles.coins}>
            <tbody>
              {!loading ? (
                coins.map((item, ind) => (
                  <tr key={ind}>
                    <td>
                      <img src={item.image} width="25" />
                    </td>
                    <td>{item.name}</td>
                    <td className={styles.price}>${item.price}</td>
                  </tr>
                ))
              ) : (
                <tr>
                  <td>
                    <img src="/loader.gif" />
                  </td>
                </tr>
              )}
            </tbody>
          </table>
        </div>
      </main>

      <footer className={styles.footer}>
        <p className={styles.description}>
          <a href="https://docs.upstash.com"> Click for the tutorial </a>
        </p>
      </footer>
    </div>
  );
}
```

### `4` Run

Run your application locally: `npm run dev`

### `5` Live!

Go to [http://localhost:3000/](http://localhost:3000/) üéâ


# Build a Leaderboard API At Edge using Cloudflare Workers and Redis
Source: https://upstash.com/docs/redis/tutorials/edge_leaderboard

This tutorial shows how to build a Leaderboard API At Edge using Cloudflare Workers and Redis.

With edge functions, it is possible to run your backend at the closest location
to your users. Cloudflare Workers and Fastly Compute\@Edge runs your function at
the closest location to your user using their CDN infrastructure.

In this article we will implement a very common web use case at Edge. We will
implement a leaderboard API without any backend servers, containers or even
serverless functions. We will just use edge functions. Leaderboard will have the
following APIs:

* addScore: Adds a score with the player's name. This will write the score to
  the Upstash Redis directly from the Edge functions.
* getLeaderBoard: Returns the list of score-player pairs. This call will first
  check the Edge cache. If the leaderboard does not exist at the Edge Cache then
  it will fetch it from the Upstash Redis.

<Info>Edge caching is deprecated. Please use global database instead.</Info>

## Project Setup

In this tutorial, we will use Cloudflare Workers and Upstash. You can create a
free database from [Upstash Console](https://console.upstash.com). Then create a
Workers project using
[Wrangler](https://developers.cloudflare.com/workers/get-started/guide).

Install wrangler: `npm install -g @cloudflare/wrangler`

Authenticate: `wrangler login` or `wrangler config`

Then create a project: `wrangler generate edge-leaderboard`

Open `wrangler.toml`. Run `wrangler whoami` and copy/paste your account id to
your wrangler.toml.

Find your REST token from database details page in the
[Upstash Console](https://console.upstash.com). Copy/paste your token to your
wrangler toml as below:

```
name = "edge-leaderboard"
type = "javascript"

account_id = "REPLACE_YOUR_ACCOUNT_ID"
workers_dev = true
route = ""
zone_id = ""

[vars]
TOKEN = "REPLACE_YOUR_UPSTASH_REST_TOKEN"
```

## The Code

The only file we need is the Workers Edge function. Update the index.js as
below:

```javascript  theme={"system"}
addEventListener("fetch", (event) => {
  event.respondWith(handleRequest(event.request));
});

async function handleRequest(request) {
  if (request.method === "GET") {
    return getLeaderboard();
  } else if (request.method === "POST") {
    return addScore(request);
  } else {
    return new Response("Invalid Request!");
  }
}

async function getLeaderboard() {
  let url =
    "https://us1-full-bug-31874.upstash.io/zrevrange/scores/0/1000/WITHSCORES/?_token=" +
    TOKEN;
  let res = await fetch(new Request(url), {
    cf: {
      cacheTtl: 10,
      cacheEverything: true,
      cacheKey: url,
    },
  });
  return res;
}

async function addScore(request) {
  const { searchParams } = new URL(request.url);
  let player = searchParams.get("player");
  let score = searchParams.get("score");
  let url =
    "https://us1-full-bug-31874.upstash.io/zadd/scores/" +
    score +
    "/" +
    player +
    "?_token=" +
    TOKEN;
  let res = await fetch(url);
  return new Response(await res.text());
}
```

We route the request to two methods: if it is a GET, we return the leaderboard.
If it is a POST, we read the query parameters and add a new score.

In the getLeaderboard() method, you will see we pass a cache configuration to
the fetch() method. It caches the result of the request at the Edge for 10
seconds.

## Test The API

In your project folder run `wrangler dev`. It will give you a local URL. You can
test your API with curl:

Add new scores:

```shell  theme={"system"}
curl -X POST http://127.0.0.1:8787\?player\=messi\&score\=13

curl -X POST http://127.0.0.1:8787\?player\=ronaldo\&score\=17

curl -X POST http://127.0.0.1:8787\?player\=benzema\&score\=18
```

Get the leaderboard:

```shell  theme={"system"}
curl -w '\n Latency: %{time_total}s\n' http://127.0.0.1:8787
```

Call the ‚Äúcurl -w '\n Total: %{time_total}s\n'
[http://127.0.0.1:8787](http://127.0.0.1:8787)‚Äù multiple times. You will see the
latency becomes very small with the next calls as the cached result comes from
the edge.

If you wait more than 10 seconds then you will see the latency becomes higher as
the cache is evicted and the function fetches the leaderboard from the Upstash
Redis again.

## Deploy The API

First change the type in the wrangler.toml to `webpack`

```
name = "edge-leaderboard"
type = "webpack"
```

Then, run `wrangler publish`. Wrangler will output the URL. If you want to
deploy to a custom domain see
[here](https://developers.cloudflare.com/workers/get-started/guide#optional-configure-for-deploying-to-a-registered-domain).


# Express Session with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/express_session

This tutorial shows how to use Upstash as the session storage of your Express application.

This tutorial shows how to use Serverless Redis as your session storage for your
Express Applications.

See the
[code](https://github.com/upstash/examples/tree/main/examples/express-session-with-redis)

### Step-1: Create Project

Create a folder for your project and run: `npm init`

### Step-2: Install Redis and Express

In your project folder run:
`npm install express redis connect-redis express-session`

### Step-3: Create a Redis (Upstash) Database For Free

Create a database as described [here](../overall/getstarted).

### Step-4: index.js

In Upstash console, click the `Connect` button, copy the connection code
(Node.js node-redis). Create index.js file as below and replace the Redis
connection part.

```javascript  theme={"system"}
var express = require("express");
var parseurl = require("parseurl");
var session = require("express-session");
const redis = require("redis");

var RedisStore = require("connect-redis")(session);
var client = redis.createClient({
  // REPLACE HERE
});

var app = express();

app.use(
  session({
    store: new RedisStore({ client: client }),
    secret: "forest squirrel",
    resave: false,
    saveUninitialized: true,
  })
);

app.use(function (req, res, next) {
  if (!req.session.views) {
    req.session.views = {};
  }

  // get the url pathname
  var pathname = parseurl(req).pathname;

  // count the views
  req.session.views[pathname] = (req.session.views[pathname] || 0) + 1;
  next();
});

app.get("/foo", function (req, res, next) {
  res.send("you viewed this page " + req.session.views["/foo"] + " times");
});

app.get("/bar", function (req, res, next) {
  res.send("you viewed this page " + req.session.views["/bar"] + " times");
});

app.listen(3000, function () {
  console.log("Example app listening on port 3000!");
});
```

### Step-5: Run the app

`node index.js`

### Step-6: Check your work

Open [http://localhost:3000/bar](http://localhost:3000/bar) and [http://localhost:3000/foo](http://localhost:3000/foo) in different
browsers. Check if the view-count is incrementing as expected.

### FAQ:

**There is a default session storage of express-session. Why do I need Redis?**

*Default session store loses the session data when the process crashes.
Moreover, it does not scale. You can not utilize multiple web servers to serve
your sessions.*

**Why Upstash?**

*You can use any Redis offering or self hosted one. But Upstash's serverless
approach with per-request-pricing will help you to minimize your cost with zero
maintenance.*

**How to configure the session storage?**

*See [here](https://github.com/expressjs/session#readme)*


# Serverless Golang API with Redis
Source: https://upstash.com/docs/redis/tutorials/goapi



This tutorial shows how to build a serverless API with Golang and Redis. The API
will simply count the page views and show it in JSON format.

### The Stack

* Serverless compute: AWS Lambda (Golang)
* Serverless data store: Redis via Upstash
* Deployment tool: AWS SAM

### Prerequisites:

* An AWS account for AWS Lambda functions.
* Install AWS SAM CLI tool as described here to create and deploy the project.
* An Upstash account for serverless Redis.

### Step 1: Init the Project

Run the sam init and then

* Select AWS Quick Start Templates
* Select 4 - go1.x
* Enter your project name: go-redis-example
* Select 1 - Hello World Example SAM will generate your project in a new folder.

### Step 2: Install a Redis Client

Our only dependency is redis client. Install go-redis via
`go get github.com/go-redis/redis/v8`

### Step 3: Create a Redis Database

Create a Redis database from Upstash console. Free tier should be enough. It is
pretty straight forward but if you need help, check
[getting started](../overall/getstarted) guide. In the database details page,
click the Connect button. You will need the endpoint and password in the next
step.

### Step 4: The function Code

Edit the hello-world>main.go as below:

```go  theme={"system"}
package main
import (
    "context"
    "encoding/json"
    "github.com/aws/aws-lambda-go/events"
    "github.com/aws/aws-lambda-go/lambda"
    "github.com/go-redis/redis/v8"
    "strconv"
)
var ctx = context.Background()

type MyResponse struct {
    Count string `json:"count:"`
}

var rdb = redis.NewClient(&redis.Options{
    Addr: "YOUR_REDIS_ENDPOINT",
    Password: "YOUR_REDIS_PASSWORD",
    DB: 0,
})

func handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
    count, err := rdb.Incr(ctx, "count").Result()
    if err != nil {
        panic(err)
    }
    response := &MyResponse{
        Count: strconv.FormatInt(count, 10),
    }
    body, err := json.Marshal(response)
    return events.APIGatewayProxyResponse{
        Headers: map[string]string{"Content-Type": "application/json"},
        Body: string(body),
        StatusCode: 200,
        }, nil
}

func main() {
    lambda.Start(handler)
}
```

Replace the "YOUR\_REDIS\_ENDPOINT" and "YOUR\_REDIS\_PASSWORD" with your database's
endpoint and password which you created in the Step 3. The code simply
increments a counter in Redis database and returns its value in json format.

### Step 5: Deployment

Now we are ready to deploy our API. First build it via `sam build`. Then run the
command `sam local start-api`. You can check your API locally on
[http://127.0.0.1:3000/hello](http://127.0.0.1:3000/hello)

<br />

<br /> If it is working, you can deploy your app to AWS by running `sam deploy --guided`.
Enter a stack name and pick your region. After confirming changes, the deployment
should begin. The command will output API Gateway endpoint URL, check the API in
your browser. You can also check your deployment on your AWS console. You will see
your function has been created.

<br />

<br /> Click on your function, you will see the code is uploaded and API Gateway
is configured.

### Notes

* Check the template.yaml file. You can add new functions and APIGateway
  endpoints editing this file.
* It is a good practice to keep your Redis endpoint and password as environment
  variable.
* You can use [serverless framework](https://www.serverless.com/) instead of AWS
  SAM to deploy your function.


# Build a Serverless Histogram API with Redis
Source: https://upstash.com/docs/redis/tutorials/histogram

This tutorial shows how to build a histogram API with Redis.

While developing
[the latency benchmark for the serverless databases (DynamoDB, FaunaDB, Upstash)](https://blog.upstash.com/latency-comparison),
I wished there was an API where I will record the latency numbers and get the
histogram back. In this tutorial, I will build such an API where you can record
your latency values from any application. It will be a REST API with following
methods:

* record: Records numeric values into the histogram.
* get: Returns the histogram object.

### Motivation

I will show how easy to develop a generic API using AWS Lambda and Serverless
Redis.

See [code](https://github.com/upstash/examples/tree/master/examples/histogram-api).

### `1` Create a Redis (Upstash) Database

Create a database as [getting started](../overall/getstarted)

### `2` Serverless Project Setup

If you do not have it already install serverless framework via:
`npm install -g serverless`

In any folder run `serverless` as below:

```text  theme={"system"}
>> serverless

Serverless: No project detected. Do you want to create a new one? Yes
Serverless: What do you want to make? AWS Node.js
Serverless: What do you want to call this project? histogram-api

Project successfully created in 'histogram-api' folder.

You can monitor, troubleshoot, and test your new service with a free Serverless account.

Serverless: Would you like to enable this? No
You can run the ‚Äúserverless‚Äù command again if you change your mind later.
```

<Note>
  See [Using AWS SAM](/redis/tutorials/using_aws_sam), if you prefer AWS SAM
  over Serverless Framework.
</Note>

Inside the project folder create a node project with the command:

```
npm init
```

Then install the redis client and histogram library with:

```
npm install ioredis

npm install hdr-histogram-js
```

Update the `serverless.yml` as below. Copy your Redis URL from console and
replace below:

```yaml  theme={"system"}
service: histogram-api
frameworkVersion: "2"

provider:
  name: aws
  runtime: nodejs12.x
  lambdaHashingVersion: 20201221
  environment:
    REDIS_URL: REPLACE_YOUR_URL_HERE

functions:
  record:
    handler: handler.record
    events:
      - httpApi:
          path: /record
          method: post
          cors: true
  get:
    handler: handler.get
    events:
      - httpApi:
          path: /get
          method: get
          cors: true
```

<Snippet file="redis/ioredisnote.mdx" />

### `3` Code

Edit handler.js as below.

```javascript  theme={"system"}
const hdr = require("hdr-histogram-js");
const Redis = require("ioredis");
if (typeof client === "undefined") {
  var client = new Redis(fixUrl(process.env.REDIS_URL));
}
const headers = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Credentials": true,
};
const SIZE = 10000;

module.exports.get = async (event) => {
  if (!event.queryStringParameters || !event.queryStringParameters.name) {
    return {
      statusCode: 400,
      headers: headers,
      body: JSON.stringify({
        message: "Invalid parameters. Name is needed.",
      }),
    };
  }
  const name = event.queryStringParameters.name;
  const data = await client.lrange(name, 0, SIZE);
  const histogram = hdr.build();
  data.forEach((item) => {
    histogram.recordValue(item);
  });

  return {
    statusCode: 200,
    body: JSON.stringify({
      histogram: histogram,
    }),
  };
};

module.exports.record = async (event) => {
  let body = JSON.parse(event.body);
  if (!body || !body.name || !body.values) {
    return {
      statusCode: 400,
      headers: headers,
      body: JSON.stringify({
        message: "Invalid parameters. Name and values are needed.",
      }),
    };
  }
  const name = body.name;
  const values = body.values;
  await client.lpush(name, values);
  return {
    statusCode: 200,
    body: JSON.stringify({
      message: "Success",
      name: name,
    }),
  };
};

function fixUrl(url) {
  if (!url) {
    return "";
  }
  if (url.startsWith("redis://") && !url.startsWith("redis://:")) {
    return url.replace("redis://", "redis://:");
  }
  if (url.startsWith("rediss://") && !url.startsWith("rediss://:")) {
    return url.replace("rediss://", "rediss://:");
  }
  return url;
}
```

We have two serverless functions above. `get` takes `name` as parameter and
loads a list from Redis. Then builds a histogram using the values in the list.

The `record` function takes `name` and `values` as parameters. It adds the
`values` to the Redis List with name `name`.

The `get` function calculates the histogram over the latest 10000 latency
records. Update the SIZE parameter to change this number.

The `fixUrl` is a helper method which corrects the Redis url format.

### `4` Deploy and Try the API

Deploy your functions with:

```bash  theme={"system"}
serverless deploy
```

The command will deploy two functions and output two endpoints. Try the
endpoints with setting parameters as below:

Record latency numbers to `perf-test-1`:

```shell  theme={"system"}
curl --header "Content-Type: application/json" -d "{\"name\":\"perf-test-1\", \"values\": [90,80,34,97,93,45,49,57,99,12]}" https://v7xx4aa2ib.execute-api.us-east-1.amazonaws.com/record
```

Get the histogram for `perf-test-1`:

```shell  theme={"system"}
curl https://v7xx4aa2ib.execute-api.us-east-1.amazonaws.com/get?name=perf-test-1
```

### Batching

It can be costly to call a remote function each time for latency calculation. In
your application, you should keep an array or queue as a buffer for the latency
numbers, then submit them in batches to the API when the array reaches the batch
size. Something like below:

```javascript  theme={"system"}
let records = [];
let batchSize = 1000;
function recordLatency(value) {
  records.push(value);
  if (records.length >= batchSize) {
    // the below submits the records to the API then empties the records array.
    submitToAPI(records);
  }
}
```


# Job Processing and Event Queue with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/job_processing

This tutorial shows how to use Upstash Redis for job/task processing.

### Motivation

Serverless functions are great for many tasks with their dynamic scaling and
flexible pricing models. But when you have a task which is composed of long
running complex steps, it is not feasible to run it in a single serverless
function. A simple solution is simply to offload complicated tasks from the
serverless function. You can process those asynchronously in your preferred
environment, this can be other serverless functions, serverless containers or
traditional server based processes too. To offload your tasks, you need a
reliable event queue. In this article we will use Upstash Redis for this
purpose.

### Scenario

You are developing a `New Employee Registration` form for your company. Saving
employee records to the database is the easy part. Here possible things to do:

* Create accounts (email, slack etc).
* Send email to the employee.
* Send email to the hiring manager and others.
* Create a JIRA ticket for the IT department so they will set up the employee‚Äôs
  computer.

This list can be longer for bigger companies.

* You want the form to be responsive. You do want a new employee to wait for
  minutes after clicking submit.
* The above steps are subject to change. You do not want to update your code
  whenever a new procedure is added.

Decoupling the side procedures will solve the above issues. When a new employee
is registered, you can push a new event to the related task queue; then another
process will consume the task.

Let‚Äôs build the sample application:

### Project Setup

The project will consist of two modules:

* Producer will be a serverless function which will receive input parameters
  required to register a new employee. It will also produce events for the task
  queue.
* Consumer will be a worker application which will continuously consume the task
  queue.

(See
[the source code](https://github.com/upstash/examples/tree/main/examples/task-queue))

### Tech Stack

* AWS Lambda for Serverless computing
* [Upstash](https://upstash.com) as Serverless Redis
* [Bull](https://github.com/OptimalBits/bull) as task queue implementation
* [Serverless framework](https://www.serverless.com/) for project deployment

### Upstash Database

You can create a free Redis database from [Upstash](https://docs.upstash.com/).

After creating a database, copy the endpoint, port and password as you will need
in the next steps.

### Producer Code

Our producer will be the serverless function which will get the request
parameters and produce the task for the queue. In the real world this code
should do things like saving to the database but I will not implement this for
the sake of simplicity.

1- Create a Serverless project by `serverless` command.

```shell  theme={"system"}
‚ûú  serverless

Serverless: No project detected. Do you want to create a new one? Yes

Serverless: What do you want to make? AWS Node.js

Serverless: What do you want to call this project? producer

Project successfully created in 'producer' folder.

You can monitor, troubleshoot, and test your new service with a free Serverless account.

Serverless: Would you like to enable this? No

You can run the ‚Äúserverless‚Äù command again if you change your mind later.
```

2- Install [bull](https://github.com/OptimalBits/bull):

`npm install bull`

3- Function code:

```javascript  theme={"system"}
var Queue = require("bull");

var settings = {
  stalledInterval: 300000, // How often check for stalled jobs (use 0 for never checking).
  guardInterval: 5000, // Poll interval for delayed jobs and added jobs.
  drainDelay: 300, // A timeout for when the queue is in drained state (empty waiting for jobs).
};

module.exports.hello = async (event) => {
  var taskQueue = new Queue(
    "employee registration",
    {
      redis: {
        port: 32016,
        host: "us1-upward-ant-32016.upstash.io",
        password: "ake4ff120d6b4216df220736be7eab087",
        tls: {},
      },
    },
    settings
  );
  await taskQueue.add({ event: event });

  // TODO save the employee record to a database
  return { message: "New employee event enqueued! 34", event };
};
```

Note1: Do not forget to replace your own Redis endpoint, port and password.
Remove the TLS part if you disabled TLS.

Note2: We give extra parameters (settings) to the event queue (Bull), so it will
not exploit Upstash quotas. Update the interval parameters depending on your
tolerance to event latency.

### Consumer Code

We will write a basic Node application to consume the events. Create a new
directory and run `npm init` and `npm install bull`. Then create index.js as
below:

```javascript  theme={"system"}
var Queue = require("bull");

var settings = {
  stalledInterval: 300000, // How often check for stalled jobs (use 0 for never checking).
  guardInterval: 5000, // Poll interval for delayed jobs and added jobs.
  drainDelay: 300, // A timeout for when the queue is in drained state (empty waiting for jobs).
};

var taskQueue = new Queue(
  "employee registration",
  {
    redis: {
      port: 32016,
      host: "us1-upward-ant-32016.upstash.io",
      password: "ake4ff120d6b4216df220736be7eab087",
      tls: {},
    },
  },
  settings
);

taskQueue
  .process(function (job, done) {
    console.log(job.data);
    // TODO process the new employee event
    done();
  })
  .catch((err) => {
    console.log(err);
  });
```

Note1: Do not forget to replace your own Redis endpoint, port and password.
Remove the TLS part if you disabled TLS.

Note2: We give extra parameters (settings) to the event queue (Bull), so it will
not exploit Upstash quotas. Update the interval parameters depending on your
tolerance to event latency.

### Test the Application

First run the consumer application with

`node index`

To test the producer code, run:

```shell  theme={"system"}
serverless invoke local -f hello -d "{name:'Bill Gates', email:'bill@upstash.com', position:'Developer', date:'20210620'}"
```

You will see producer will log as below:

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0eca0a962927e77180b460e861b46400" alt="alt_text" data-og-width="2162" width="2162" data-og-height="210" height="210" data-path="img/examples/producer.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6c90ec50e96384a69cc5245ae142cde6 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7730f3ad14edbe2b0a905c084443dafd 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=70d5762cd3db6d35d031e402b033878a 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c3a6c92a122c66a599e1837e4354e7e4 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=48fb71329d2b16315fb513d0f3d5584a 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/producer.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e2240e9b3cf7dddf8b7696cfcfdee7cd 2500w" />

And consumer will log as below:

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=517801e6cc84869e9e6e33d6a6ed9770" alt="alt_text" data-og-width="1606" width="1606" data-og-height="188" height="188" data-path="img/examples/consumer.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=597471c0e5363a7e780a4201c53d56cf 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=0bcdbab2070cff7feb6f4e0588605521 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=2b03654a4764758ba08a808b64350282 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=fea6f49563999d181af04e0d9e390787 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6ec846a0ffc2080cc4632306fe91ce29 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/consumer.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=660aa96b281b48d4b7d482cd2804da16 2500w" />


# Caching in Laravel with Redis
Source: https://upstash.com/docs/redis/tutorials/laravel_caching



## Project Setup

Create a new Laravel application:

```shell  theme={"system"}
laravel new todo-cache
cd todo-cache
```

## Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com). Go to the **Connect to your database** section and click on Laravel. Copy those values into your .env file:

```shell .env theme={"system"}
REDIS_HOST="<YOUR_ENDPOINT>"
REDIS_PORT=6379
REDIS_PASSWORD="<YOUR_PASSWORD>"
```

### Cache Setup

To use Upstash Redis as your caching driver, update the CACHE\_STORE in your .env file:

```shell .env theme={"system"}
CACHE_STORE="redis"
REDIS_CACHE_DB="0"
```

## Creating a Todo App

First, we'll create a Todo model with its associated controller, factory, migration, and API resource files:

```shell  theme={"system"}
php artisan make:model Todo -cfmr --api
```

Next, we'll set up the database schema for our todos table with a simple structure including an ID, title, and timestamps:

```php database/migrations/2025_02_10_111720_create_todos_table.php theme={"system"}
<?php

use Illuminate\Database\Migrations\Migration;
use Illuminate\Database\Schema\Blueprint;
use Illuminate\Support\Facades\Schema;

return new class extends Migration
{
    /**
     * Run the migrations.
     */
    public function up(): void
    {
        Schema::create('todos', function (Blueprint $table) {
            $table->id();
            $table->string('title');
            $table->timestamps();
        });
    }

    /**
     * Reverse the migrations.
     */
    public function down(): void
    {
        Schema::dropIfExists('todos');
    }
};
```

We'll create a factory to generate fake todo data for testing and development:

```php database/factories/TodoFactory.php theme={"system"}
<?php

namespace Database\Factories;

use Illuminate\Database\Eloquent\Factories\Factory;

/**
 * @extends \Illuminate\Database\Eloquent\Factories\Factory<\App\Models\Todo>
 */
class TodoFactory extends Factory
{
    /**
     * Define the model's default state.
     *
     * @return array<string, mixed>
     */
    public function definition(): array
    {
        return [
            'title' => $this->faker->sentence,
        ];
    }
}
```

In the database seeder, we'll set up the creation of 50 sample todo items:

```php database/seeders/DatabaseSeeder.php theme={"system"}
<?php

namespace Database\Seeders;

use App\Models\Todo;
use App\Models\User;
use Illuminate\Database\Seeder;

class DatabaseSeeder extends Seeder
{
    /**
     * Seed the application's database.
     */
    public function run(): void
    {
        Todo::factory()->times(50)->create();
    }
}
```

Run the migration to create the todos table in the database:

```shell  theme={"system"}
php artisan migrate
```

Seed the database with our sample todo items:

```shell  theme={"system"}
php artisan db:seed
```

Install the API package:

```shell  theme={"system"}
php artisan install:api
```

Set up the API routes for our Todo resource:

```php routes/api.php theme={"system"}
<?php

use Illuminate\Support\Facades\Route;
use \App\Http\Controllers\TodoController;

Route::resource('todos', TodoController::class);
```

Create a basic Todo controller with an index method to retrieve all todos:

```php app/Http/Controllers/TodoController.php theme={"system"}
<?php

namespace App\Http\Controllers;

use App\Models\Todo;
use Illuminate\Http\Request;

class TodoController extends Controller
{
    /**
     * Display a listing of the resource.
     */
    public function index()
    {
        return Todo::all();
    }
    ...
}
```

Finally, test the index route to verify our API is working correctly:

```shell  theme={"system"}
curl http://todo-cache.test/api/todos
```

## Using Cache in Laravel

Laravel offers a simple yet powerful unified interface for working with different caching systems. We will focus on `Cache::remember`, `Cache::flexible` and `Cache::forget` methods, to learn more about the available methods, check the [Laravel Cache Documentation](https://laravel.com/docs/11.x/cache).

### `Cache::remember`

The `Cache::remember` method retrieves the value of a key from the cache. If the key does not exist in the cache, the method will execute the given closure and store the result in the cache for the specified duration.

```php  theme={"system"}
$value = Cache::remember('todos', $seconds, function () {
    return Todo::all();
});
```

### `Cache::flexible`

The stale-while-revalidate pattern, implemented through `Cache::flexible`, is a caching strategy that balances performance and data freshness by defining two time periods: a "fresh" period where cached data is served immediately, and a "stale" period where outdated data is served while triggering a background refresh. When data is accessed during the stale period (in this example, between 5 and 10 seconds), users still get a fast response with slightly outdated data while the cache refreshes asynchronously, only forcing users to wait for a full recalculation if the data is accessed after both periods have expired.

```php  theme={"system"}
$value = Cache::flexible('todos', [5, 10], function () {
    return Todo::all();
});
```

### `Cache::forget`

The `Cache::forget` method removes the specified key from the cache:

```php  theme={"system"}
Cache::forget('todos');
```

## Caching the Todo List

Let's first update the Todo model to make it mass assignable:

```php app/Models/Todo.php theme={"system"}
<?php

namespace App\Models;

use Illuminate\Database\Eloquent\Factories\HasFactory;
use Illuminate\Database\Eloquent\Model;

class Todo extends Model
{
    /** @use HasFactory<\Database\Factories\TodoFactory> */
    use HasFactory;

    protected $fillable = ['title'];
}
```

Next, we'll update the methods in the TodoController to use caching:

```php app/Http/Controllers/TodoController.php theme={"system"}
<?php

namespace App\Http\Controllers;

use App\Models\Todo;
use Illuminate\Http\JsonResponse;
use Illuminate\Http\Request;
use Illuminate\Http\Response;
use Illuminate\Support\Facades\Cache;

class TodoController extends Controller
{
    private const CACHE_KEY = 'todos';

    private const CACHE_TTL = [300, 1800]; // 5 minutes fresh, 30 minutes stale

    /**
     * Display a listing of the resource.
     */
    public function index()
    {
        return Cache::flexible(self::CACHE_KEY, self::CACHE_TTL, function () {
            return Todo::all();
        });
    }

    /**
     * Store a newly created resource in storage.
     */
    public function store(Request $request): JsonResponse
    {
        $request->validate([
            'title' => 'required|string|max:255',
        ]);

        $todo = Todo::create($request->all());

        // Invalidate the todos cache
        Cache::forget(self::CACHE_KEY);

        return response()->json($todo, Response::HTTP_CREATED);
    }

    /**
     * Display the specified resource.
     */
    public function show(Todo $todo): Todo
    {
        return Cache::flexible(
            "todo.{$todo->id}",
            self::CACHE_TTL,
            function () use ($todo) {
                return $todo;
            }
        );
    }

    /**
     * Update the specified resource in storage.
     */
    public function update(Request $request, Todo $todo): JsonResponse
    {
        $request->validate([
            'title' => 'required|string|max:255',
        ]);

        $todo->update($request->all());

        // Invalidate both the collection and individual todo cache
        Cache::forget(self::CACHE_KEY);
        Cache::forget("todo.{$todo->id}");

        return response()->json($todo);
    }

    /**
     * Remove the specified resource from storage.
     */
    public function destroy(Todo $todo): JsonResponse
    {
        $todo->delete();

        // Invalidate both the collection and individual todo cache
        Cache::forget(self::CACHE_KEY);
        Cache::forget("todo.{$todo->id}");

        return response()->json(null, Response::HTTP_NO_CONTENT);
    }
}
```

Now we can test our methods with the following curl commands:

```shell  theme={"system"}
# Get all todos
curl http://todo-cache.test/api/todos

# Get a specific todo
curl http://todo-cache.test/api/todos/1

# Create a new todo
curl -X POST http://todo-cache.test/api/todos \
  -H "Content-Type: application/json" \
  -d '{"title":"New Todo"}'

# Update a todo
curl -X PUT http://todo-cache.test/api/todos/1 \
  -H "Content-Type: application/json" \
  -d '{"title":"Updated Todo"}'

# Delete a todo
curl -X DELETE http://todo-cache.test/api/todos/1
```

Visit Redis Data Browser in Upstash Console to see the cached data.


# Next.js with Redis
Source: https://upstash.com/docs/redis/tutorials/nextjs_with_redis



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/nextjs-app-router" horizontal>
  You can find the project source code on GitHub.
</Card>

<Info>
  This tutorial uses Next.js App Router. If you want to use Pages Router, check out our [Pages Router tutorial](/redis/quickstarts/nextjs-pages-router).
</Info>

This tutorial uses Redis as state store for a Next.js application. We simply add
a counter that pulls the data from Redis.

### Project Setup

Let's create a new Next.js application with App Router and install `@upstash/redis` package.

```shell  theme={"system"}
npx create-next-app@latest
cd my-app
npm install @upstash/redis
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

<Note>
  If you are using the Vercel & Upstash integration, you may use the following environment variables:

  ```shell .env theme={"system"}
  KV_REST_API_URL=<YOUR_URL>
  KV_REST_API_TOKEN=<YOUR_TOKEN>
  ```
</Note>

### Home Page Setup

Update `/app/page.tsx`:

```tsx /app/page.tsx theme={"system"}
import { Redis } from "@upstash/redis";

const redis = Redis.fromEnv();

export default async function Home() {
  const count = await redis.incr("counter");
  return (
    <div className="flex h-screen w-screen items-center justify-center">
      <h1 className="text-4xl font-bold">Counter: {count}</h1>
    </div>
  )
}
```

### Run & Deploy

Run the app locally with `npm run dev`, check `http://localhost:3000/`

Deploy your app with `vercel`

<Info>
  You can also integrate your Vercel projects with Upstash using Vercel
  Integration module. Check [this article](../howto/vercelintegration).
</Info>


# Building a Serverless Notification API for Your Web Application with Redis
Source: https://upstash.com/docs/redis/tutorials/notification

This tutorial shows how to create a Serverless Notification API for Your Web Application with Redis.

Notifications and announcements help you communicate with your web site
visitors. It is not feasible to update your code and redeploy your website each
time you want to show a new message. It may also be too much investment to set
up a backend and maintain it to just serve these notifications. In this article,
we will build a website which will load the notification message directly from
the Redis database without a backend.

### Backendless? How is that possible?

Yes, we will not use any backend service, even a serverless function. We will
access Redis from the client side directly. This is possible with the read only
REST API provided by Upstash.

### Requirements

* The page will display a notification if the user has not already seen the
  notification before.
* The page will only show the latest notification.

Check out
[the code here](https://github.com/upstash/examples/tree/master/examples/serverless-notification-api).

### Project Setup

I will create a React application but you can use any other web framework. It
will simply call the Redis REST API and show the message as a notification.

Create the app:

```shell  theme={"system"}
npx create-react-app serverless-notification-api
```

Install a toast component to show the notification:

```shell  theme={"system"}
npm install --save react-toastify
```

Create a free database from [Upstash](https://console.upstash.com/) and copy the
REST url and read only token. You should switch the Read-Only Token setting. In
the database details page, click on the `Read-Only Token` switch.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=674b186c9592c05dd01faf66642b3691" alt="alt_text" data-og-width="1406" width="1406" data-og-height="230" height="230" data-path="img/examples/restapi.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b88fee1f50e2035eb17b886e9f660e2 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e2770a511c8cd3ffd32289d82d7d5dcb 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=dc6bb0925816315aff765c2c4641c6b2 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=c018b7aa446ef674b824bcb70096bcbc 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f029092e5e0cd119f39d6711a5908a28 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/restapi.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7881d4ab4683a475de136022c40fd8c0 2500w" />

### Implementation

The logic is simple. We will keep the notifications in a Redis Sorted Set. We
will keep a version (integer) in the local storage. We will use the versions as
scores in the sorted set. Each notification message will have a version (score)
and the higher score means the newer message. At each page load, we will query
the Redis sorted set to load the messages which have higher scores than the
locally stored version. After loading a notification message I will set my local
version equal to the latest notification‚Äôs version. This will prevent showing
the same notification to the same users more than once. Here the implementation:

```javascript  theme={"system"}
import logo from "./logo.svg";
import "./App.css";
import { toast, ToastContainer } from "react-toastify";
import "react-toastify/dist/ReactToastify.css";
import { useEffect } from "react";

function App() {
  useEffect(() => {
    async function fetchData() {
      try {
        let version = localStorage.getItem("notification-version");
        version = version ? version : 0;
        const response = await fetch(
          "REPLACE_UPSTASH_REDIS_REST_URL/zrevrangebyscore/messages/+inf/" +
            version +
            "/WITHSCORES/LIMIT/0/1",
          {
            headers: {
              Authorization: "Bearer REPLACE_UPSTASH_REDIS_REST_TOKEN",
            },
          }
        );
        const res = await response.json();
        const v = parseInt(res.result[1]);
        if (v) {
          localStorage.setItem("notification-version", v + 1);
        }
        toast(res.result[0]);
      } catch (e) {
        console.error(e);
      }
    }
    fetchData();
  });

  return (
    <div className="App">
      <header className="App-header">
        <img src={logo} className="App-logo" alt="logo" />
        <p>
          Edit <code>src/App.js</code> and save to reload.
        </p>
        <a
          className="App-link"
          href="https://reactjs.org"
          target="_blank"
          rel="noopener noreferrer"
        >
          Learn React
        </a>
      </header>
      <ToastContainer />
    </div>
  );
}

export default App;
```

### How to Add New Notification Messages

You can simply add new messages to the Redis sorted set with a highest score so
it will be displayed to the user with page loads. For our application the name
of the sorted set is `messages`.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b67b4fc3620f906ffc0061f4be4fe005" alt="alt_text" data-og-width="1410" width="1410" data-og-height="142" height="142" data-path="img/examples/notif/cli.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3cc5eae3334aafc58415c047e717b652 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=43e45fddbf765d41026fe7e2877dc8c8 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b04310f0f2900df40dd3b7da2313ef9f 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=9a54e968e0afec09d043e99e55098c05 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=fad2a15ebadd1a8088ed5075f4415948 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/examples/notif/cli.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5cf2945da1739cdb4ae616a3392ee37b 2500w" />

You can also remove a message using the [ZREM](https://redis.io/commands/zrem)
command.

### Conclusion

You do not need a backend to access Upstash Redis thanks to the REST API. You
can expose the token with your client side application, as the token only allows
read-only access. This helps developers to build applications without backend
for many use cases where the data is already available publicly.


# Nuxt with Redis
Source: https://upstash.com/docs/redis/tutorials/nuxtjs_with_redis

This tutorial shows how to use Upstash inside your Nuxt application.

This tutorial uses Redis as state store for a Nuxt application. In it, we will build an application
which simply increments a counter and saves & fetches the last increment time.

See [code](https://github.com/upstash/examples/tree/master/examples/nuxt-with-redis) and
[demo](https://nuxt-with-redis.vercel.app)

### `1` Create Nuxt.js Project

Run this in terminal

```bash  theme={"system"}
npx nuxi@latest init nuxtjs-with-redis
```

Go to the new directory `nuxtjs-with-redis` and install `@upstash/redis`:

```
npm install @upstash/redis
```

### `2` Create a Upstash Redis database

Next, you will need an Upstash Redis database. You can follow
[our guide for creating a new database](/redis/overall/getstarted).

### `3` Set up environment variables

Copy the `.env.example` file in this directory to `.env`

```bash  theme={"system"}
cp .env.example .env
```

Then, set the following environment variables:

```
UPSTASH_REDIS_REST_URL=""
UPSTASH_REDIS_REST_TOKEN=""
```

You can get the values of these env variables on the page of your Redis database.

<Note>
  If you are using the Vercel & Upstash integration, you may use the following environment variables:

  ```shell .env theme={"system"}
  KV_REST_API_URL=<YOUR_URL>
  KV_REST_API_TOKEN=<YOUR_TOKEN>
  ```
</Note>

### `4` Define the endpoint

Next, we will define the endpoint which will call Redis:

```javascript title="server/api/increment.ts" theme={"system"}
import { defineEventHandler } from "h3";
import { Redis } from "@upstash/redis";

// Initialize Redis
const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL || "",
  token: process.env.UPSTASH_REDIS_REST_TOKEN || ""
});

export default defineEventHandler(async () => {
  const identifier = "api_call_counter";

  try {
    // Increment the API call counter and get the updated value
    const count = await redis.incr(identifier);

    // Optionally, you can also retrieve other information like the last time it was called
    const lastCalled = await redis.get("last_called");
    const lastCalledAt = lastCalled || "Never";

    // Store the current timestamp as the last called time
    await redis.set("last_called", new Date().toISOString());

    // Return the count and last called time
    return {
      success: true,
      count: count,
      lastCalled: lastCalledAt,
    };
  } catch (error) {
    console.error("Redis error:", error);
    return {
      success: false,
      message: "Error interacting with Redis",
    };
  }
});
```

### `5` Run

Finally, we can run the application and call our endpoint:

```bash  theme={"system"}
npm run dev
```

If you are using [our example app](https://github.com/upstash/examples/tree/master/examples/nuxt-with-redis),
you can simply click the `Increment` button to run the endpoint we defined.

Otherwise, you can simply make a curl request:

```
curl http://localhost:3000/api/increment
```

When you make the request, you should see something like this:

```
{
  "success": true,
  "count": 166,
  "lastCalled": "2024-10-10T07:04:42.381Z"
}
```

### Notes:

* For best performance the application should run in the same region with the
  Redis database's region.


# Redis as a Cache for Your FastAPI App
Source: https://upstash.com/docs/redis/tutorials/python_fastapi_caching



### Introduction

In this tutorial, we‚Äôll learn how to use Redis to add caching to a FastAPI application. By caching API responses in Redis, we can reduce database queries, improve response times, and ensure that frequently requested data is delivered quickly.

We‚Äôll create a simple FastAPI app that fetches weather data from an external API. The app will store the results in Redis, so the next time someone requests the same data, it can be returned from the cache instead of making a new API request. Let‚Äôs get started!

### Environment Setup

First, install FastAPI, the Upstash Redis client, and an ASGI server:

```shell  theme={"system"}
pip install fastapi upstash-redis uvicorn[standard]
```

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli), and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment:

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

We'll also need to generate a `WEATHER_API_KEY` from [Weather API Website](https://www.weatherapi.com) for free and we will export it.

```shell  theme={"system"}
export WEATHER_API_KEY=<YOUR_KEY>
```

You can also use `python-dotenv` to load environment variables from your `.env` file.

### Application Setup

In this example, we will build an API that fetches weather data and caches it in Redis.

Create `main.py`:

```python main.py theme={"system"}
from fastapi import FastAPI
from upstash_redis import Redis
import requests
import os

app = FastAPI()

# Connect to Redis using environment variables
redis = Redis.from_env()

# Mock API endpoint for weather data
WEATHER_API_URL = "https://api.weatherapi.com/v1/current.json"
API_KEY = os.getenv("WEATHER_API_KEY")

@app.get("/weather/{city}")
def get_weather(city: str):
    cache_key = f"weather:{city}"
    
    # Check if the data exists in cache
    cached_data = redis.get(cache_key)
    if cached_data:
        return {"source": "cache", "data": cached_data}
    
    # Fetch data from external API
    response = requests.get(f"{WEATHER_API_URL}?key={API_KEY}&q={city}")
    weather_data = response.json()
    
    # Store the data in Redis cache with a 10-minute expiration
    redis.setex(cache_key, 600, weather_data)
    
    return {"source": "api", "data": weather_data}
```

### Running the Application

Run the FastAPI app with Uvicorn:

```shell  theme={"system"}
uvicorn main:app --reload
```

To test the application you can visit `http://127.0.0.1:8000/weather/istanbul` in your browser or use curl to get the weather data for Istanbul. The first request will fetch the data from the weather API and cache it, and subsequent requests will return the cached data until the cache expires after 10 minutes.

To monitor your data in Redis, you can use the [Upstash Console](https://console.upstash.com) and check out the Data Browser tab.

### Code Breakdown

1. **Redis Setup**: We use `Redis.from_env()` to initialize the Redis connection using the environment variables. Redis will store the weather data with city names as cache keys.

2. **Cache Lookup**: When a request is made to the `/weather/{city}` endpoint, we check if the weather data is already cached by looking up the `weather:{city}` key in Redis. If the data is found in cache, it's returned immediately.

3. **Fetching External Data**: If the data is not in cache, the app sends a request to the external weather API to fetch the latest data. The response is then cached using `redis.setex()`, which stores the data with a 10-minute expiration.

4. **Cache Expiration**: We use a 10-minute TTL (time-to-live) for the cached weather data to ensure it's periodically refreshed. After the TTL expires, the next request will fetch fresh data from the external API and store it in cache again.


# Multithreaded Web Scraping with Redis Caching
Source: https://upstash.com/docs/redis/tutorials/python_multithreading



In this tutorial, we‚Äôll build a multithreaded web scraper in Python that leverages Redis for caching responses to minimize redundant HTTP requests. The scraper will be capable of handling groups of URLs across multiple threads while caching responses to reduce load and improve performance.

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli), and add `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your `.env` file:

```bash  theme={"system"}
UPSTASH_REDIS_REST_URL=your_upstash_redis_url
UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token
```

This file will be used to load environment variables.

### Installation

First, install the necessary libraries using the following command:

```bash  theme={"system"}
pip install threading requests upstash-redis python-dotenv
```

### Code Explanation

We‚Äôll create a multithreaded web scraper that performs HTTP requests on a set of grouped URLs. Each thread will check if the response for a URL is cached in Redis. If the URL has been previously requested, it will retrieve the cached response; otherwise, it will perform a fresh HTTP request, cache the result, and store it for future requests.

### Code

Here‚Äôs the complete code:

```python  theme={"system"}
import threading
import requests
from upstash_redis import Redis
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Initialize Redis client
redis = Redis.from_env()

# Group URLs by thread, with one or two overlapping URLs across groups
urls_to_scrape_groups = [
    [
        'https://httpbin.org/delay/1',
        'https://httpbin.org/delay/4',
        'https://httpbin.org/delay/2',
        'https://httpbin.org/delay/5',
        'https://httpbin.org/delay/3',
    ],
    [
        'https://httpbin.org/delay/5',  # Overlapping URL
        'https://httpbin.org/delay/6',
        'https://httpbin.org/delay/7',
        'https://httpbin.org/delay/2',  # Overlapping URL
        'https://httpbin.org/delay/8',
    ],
    [
        'https://httpbin.org/delay/3',  # Overlapping URL
        'https://httpbin.org/delay/9',
        'https://httpbin.org/delay/10',
        'https://httpbin.org/delay/4',  # Overlapping URL
        'https://httpbin.org/delay/11',
    ],
]

class Scraper(threading.Thread):
    def __init__(self, urls):
        threading.Thread.__init__(self)
        self.urls = urls
        self.results = {}

    def run(self):
        for url in self.urls:
            cache_key = f"url:{url}"
            
            # Attempt to retrieve cached response
            cached_response = redis.get(cache_key)
            
            if cached_response:
                print(f"[CACHE HIT] {self.name} - URL: {url}")
                self.results[url] = cached_response
                continue  # Skip to the next URL if cache is found
            
            # If no cache, perform the HTTP request
            print(f"[FETCHING] {self.name} - URL: {url}")
            response = requests.get(url)
            if response.status_code == 200:
                self.results[url] = response.text
                # Store the response in Redis cache
                redis.set(cache_key, response.text)
            else:
                print(f"[ERROR] {self.name} - Failed to retrieve {url}")
                self.results[url] = None

def main():
    threads = []
    for urls in urls_to_scrape_groups:
        scraper = Scraper(urls)
        threads.append(scraper)
        scraper.start()

    # Wait for all threads to complete
    for scraper in threads:
        scraper.join()

    print("\nScraping results:")
    for scraper in threads:
        for url, result in scraper.results.items():
            print(f"Thread {scraper.name} - URL: {url} - Response Length: {len(result) if result else 'Failed'}")

if __name__ == "__main__":
    main()
```

### Explanation

1. **Threaded Scraper Class**: The `Scraper` class is a subclass of `threading.Thread`. Each thread takes a list of URLs and iterates over them to retrieve or fetch their responses.

2. **Redis Caching**:
   * Before making an HTTP request, the scraper checks if the response is already in the Redis cache.
   * If a cached response is found, it uses that response instead of making a new request, marked with `[CACHE HIT]` in the logs.
   * If no cached response exists, it fetches the content from the URL, caches the result in Redis, and proceeds.

3. **Overlapping URLs**:
   * Some URLs are intentionally included in multiple groups to demonstrate the cache functionality across threads. Once a URL‚Äôs response is cached by one thread, another thread retrieving the same URL will pull it from the cache instead of re-fetching.

4. **Main Function**:
   * The `main` function initiates and starts multiple `Scraper` threads, each handling a group of URLs.
   * It waits for all threads to complete before printing the results.

### Running the Code

Once everything is set up, run the script using:

```bash  theme={"system"}
python your_script_name.py
```

### Sample Output

You will see output similar to this:

```
[FETCHING] Thread-1 - URL: https://httpbin.org/delay/1
[FETCHING] Thread-1 - URL: https://httpbin.org/delay/4
[CACHE HIT] Thread-2 - URL: https://httpbin.org/delay/5
[FETCHING] Thread-3 - URL: https://httpbin.org/delay/3
...
```

### Benefits of Using Redis Cache

Using Redis as a cache reduces the number of duplicate requests, particularly for overlapping URLs. It allows for quick retrieval of previously fetched responses, enhancing performance and reducing load.


# Rate Limiting for Your FastAPI App
Source: https://upstash.com/docs/redis/tutorials/python_rate_limiting



### Introduction

In this tutorial, we‚Äôll learn how to add rate limiting to a FastAPI application using Upstash Redis. Rate limiting is essential for controlling API usage and with Upstash Redis, you can easily implement rate limiting to protect your API resources.

We‚Äôll set up a simple FastAPI app and apply rate limiting to its endpoints. With Upstash Redis, we‚Äôll configure a fixed window rate limiter that allows a specific number of requests per given time period.

### Environment Setup

First, install FastAPI, the Upstash Redis client, the Upstash rate limiting package, and an ASGI server:

```shell  theme={"system"}
pip install fastapi upstash-redis upstash-ratelimit uvicorn[standard]
```

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli), and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment:

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

You can also use `python-dotenv` to load environment variables from your `.env` file.

### Application Setup

In this example, we will build an API endpoint that is rate-limited to a certain number of requests per time window. If the limit is exceeded (e.g., by making more than 10 requests in 10 seconds), the API will return an HTTP 429 error with the message "Rate limit exceeded. Please try again later."

Create `main.py`:

```python main.py theme={"system"}
from fastapi import FastAPI, HTTPException
from upstash_ratelimit import Ratelimit, FixedWindow
from upstash_redis import Redis
from dotenv import load_dotenv
import requests

# Load environment variables from .env file
load_dotenv()

# Initialize the FastAPI app
app = FastAPI()

# Initialize Redis client
redis = Redis.from_env()

# Create a rate limiter that allows 10 requests per 10 seconds
ratelimit = Ratelimit(
    redis=redis,
    limiter=FixedWindow(max_requests=10, window=10),  # 10 requests per 10 seconds
    prefix="@upstash/ratelimit"
)

@app.get("/expensive_calculation")
def expensive_calculation():
    identifier = "api"  # Common identifier for rate limiting all users equally
    response = ratelimit.limit(identifier)

    if not response.allowed:
        raise HTTPException(status_code=429, detail="Rate limit exceeded. Please try again later.")
    
    # Placeholder for a resource-intensive operation
    result = do_expensive_calculation()
    return {"message": "Here is your result", "result": result}

# Simulated function for an expensive calculation
def do_expensive_calculation():
    return "Expensive calculation result"

# Test function to check rate limiting
def test_rate_limiting():
    url = "http://127.0.0.1:8000/expensive_calculation"
    success_count = 0
    fail_count = 0

    # Attempt 15 requests in quick succession
    for i in range(15):
        response = requests.get(url)
        
        if response.status_code == 200:
            success_count += 1
            print(f"Request {i+1}: Success - {response.json()['message']}")
        elif response.status_code == 429:
            fail_count += 1
            print(f"Request {i+1}: Failed - Rate limit exceeded")

        # Small delay to avoid flooding

    print("\nTest Summary:")
    print(f"Total Successful Requests: {success_count}")
    print(f"Total Failed Requests due to Rate Limit: {fail_count}")

if __name__ == "__main__":
    # Run the FastAPI app in a separate thread or terminal with:
    # uvicorn main:app --reload

    # To test rate limiting after the server is running
    test_rate_limiting()
```

### Running the Application

Run the FastAPI app with Uvicorn:

```shell  theme={"system"}
uvicorn main:app --reload
```

Run the test function to check the rate limiting:

```shell  theme={"system"}
python main.py
```

### Testing Rate Limiting

Here's the output you should see when running the test function:

```
Request 1: Success - Here is your result
Request 2: Success - Here is your result
Request 3: Success - Here is your result
Request 4: Success - Here is your result
Request 5: Success - Here is your result
Request 6: Success - Here is your result
Request 7: Success - Here is your result
Request 8: Success - Here is your result
Request 9: Success - Here is your result
Request 10: Success - Here is your result
Request 11: Failed - Rate limit exceeded
Request 12: Failed - Rate limit exceeded
Request 13: Failed - Rate limit exceeded
Request 14: Failed - Rate limit exceeded
Request 15: Failed - Rate limit exceeded

Test Summary:
Total Successful Requests: 10
Total Failed Requests due to Rate Limit: 5
```

### Code Breakdown

1. **Redis and Rate Limiter Setup**:
   * We initialize a `Redis` client with `Redis.from_env()` using environment variables for configuration.
   * We create a rate limiter using `Ratelimit` with a `FixedWindow` limiter that allows 10 requests per 10 seconds. The `prefix` option is set to organize the Redis keys used by the rate limiter.

2. **Rate Limiting the Endpoint**:
   * For the `/expensive_calculation` endpoint, the rate limiter is applied by calling `ratelimit.limit(identifier)`.
   * The `identifier` variable uniquely identifies this rate limit. You could use user-specific identifiers (like user IDs) to implement per-user limits.
   * If the request exceeds the allowed limit, an HTTP 429 error is returned.

3. **Expensive Calculation Simulation**:
   * The `do_expensive_calculation` function simulates a resource-intensive operation. In real scenarios, this could represent database queries, file processing, or other time-consuming tasks.

### Benefits of Rate Limiting with Redis

Using Redis for rate limiting helps control API usage across multiple instances of your app, making it highly scalable. Redis‚Äôs in-memory storage provides fast access to rate-limiting data, ensuring minimal performance impact on your API.


# Build a Real-Time Chat Application with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/python_realtime_chat



In this tutorial, we will build a real-time chat application using Flask and SocketIO, leveraging Upstash Redis for efficient message handling. Redis, being a fast, in-memory data store, provides an ideal backbone for real-time messaging systems due to its low latency and support for Pub/Sub messaging patterns.

## Why Upstash Redis?

* **Scalability:** Handles large volumes of messages with minimal latency.
* **Simplicity:** Easy to set up with minimal configuration.
* **Cost-Efficiency:** Serverless model reduces operational costs.

***

## **Setup**

### **1. Install the Required Libraries**

Install Flask, Flask-SocketIO, and the Redis library by running:

```bash  theme={"system"}
pip install flask flask-socketio redis
```

### **2. Create a Redis Database**

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli).

Create a `.env` file in the root of your project with the following content:

```bash  theme={"system"}
UPSTASH_REDIS_HOST=your_upstash_redis_host
UPSTASH_REDIS_PORT=your_upstash_redis_port
UPSTASH_REDIS_PASSWORD=your_upstash_redis_password
```

## **Code**

Now, it's time to implement the chat application. We'll create a Flask server that uses SocketIO for real-time communication. We'll also configure the server to use Upstash Redis as the message queue.

<Note type="info">
  We need to use the `rediss://` protocol instead of `redis://` to connect to Redis over TLS. This ensures secure communication between the server and the Redis instance.
</Note>

```python main.py theme={"system"}
from flask import Flask, render_template
from flask_socketio import SocketIO
import os

# Initialize Flask app
app = Flask(__name__)
app.config["SECRET_KEY"] = os.getenv("SECRET_KEY", os.urandom(24))

# Set up Redis URL with TLS
redis_password = os.getenv('UPSTASH_REDIS_PASSWORD')
redis_host = os.getenv('UPSTASH_REDIS_HOST')
redis_port = int(os.getenv('UPSTASH_REDIS_PORT', 6379))
redis_url = f"rediss://:{redis_password}@{redis_host}:{redis_port}"

# Initialize SocketIO with Redis message queue
socketio = SocketIO(app, message_queue=redis_url, cors_allowed_origins="*")

# WebSocket handlers
@socketio.on("connect")
def handle_connect():
    print("Client connected.")

@socketio.on("disconnect")
def handle_disconnect():
    print("Client disconnected.")

@socketio.on("message")
def handle_message(data):
    """Handle incoming chat messages."""
    print(f"Message received: {data}")
    # Broadcast the message to all connected clients except the sender
    socketio.emit("message", data, include_self=False)

# Serve the chat HTML page
@app.route("/")
def index():
    return render_template("chat.html")  # Render the chat interface template

if __name__ == "__main__":
    socketio.run(app, debug=True, host="0.0.0.0", port=8000)
```

### **Code Explanation**

* We initialized a Flask app and set a secret key for session management.
* We set up the Redis URL with TLS for secure communication.
* We initialize a SocketIO instance with the Flask app and configure it to use Redis as the message queue.
* We define WebSocket event handlers for `connect`, `disconnect`, and `message` events.
* The `handle_message` function broadcasts the received message to all connected clients except the sender.
* We define a route to serve the chat interface template.

Now let's create a template for the chat interface. We're not going to go into the details of the HTML and CSS, as the focus is on the real-time messaging functionality.

```html chat.html theme={"system"}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Chat</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #f4f6f9;
        }

        #chat-container {
            width: 90%;
            max-width: 600px;
            height: 70%;
            border: 1px solid #ddd;
            border-radius: 10px;
            background-color: #fff;
            display: flex;
            flex-direction: column;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        #chat-box {
            flex: 1;
            overflow-y: auto;
            padding: 15px;
            border-bottom: 1px solid #ddd;
            scrollbar-width: thin;
            scrollbar-color: #ccc #f4f6f9;
        }

        #chat-box::-webkit-scrollbar {
            width: 8px;
        }

        #chat-box::-webkit-scrollbar-thumb {
            background: #ccc;
            border-radius: 5px;
        }

        .message {
            margin: 10px 0;
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 70%;
            word-wrap: break-word;
        }

        .message.sent {
            align-self: flex-end;
            background-color: #007BFF;
            color: white;
        }

        .message.received {
            align-self: flex-start;
            background-color: #f1f1f1;
            color: black;
        }

        #input-container {
            display: flex;
            padding: 10px;
            gap: 10px;
            background-color: #f4f6f9;
            border-radius: 0 0 10px 10px;
        }

        #message-input {
            flex: 1;
            padding: 10px;
            font-size: 16px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }

        #send-button {
            padding: 10px 20px;
            font-size: 16px;
            border: none;
            border-radius: 5px;
            background-color: #007BFF;
            color: white;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        #send-button:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <div id="chat-container">
        <div id="chat-box"></div>
        <div id="input-container">
            <input id="message-input" type="text" placeholder="Type your message...">
            <button id="send-button">Send</button>
        </div>
    </div>

    <script>
        const socket = io();

        const chatBox = document.getElementById("chat-box");
        const messageInput = document.getElementById("message-input");
        const sendButton = document.getElementById("send-button");

        // Generate or retrieve a random username for this tab
        function getUsername() {
            let username = sessionStorage.getItem("username");
            if (!username) {
                username = "User" + Math.floor(Math.random() * 1000); // Temporary random username
                sessionStorage.setItem("username", username);
            }
            return username;
        }

        const username = getUsername();

        // Append message to chat box
        function addMessage(message, type = "received") {
            const messageElement = document.createElement("div");
            messageElement.textContent = message;
            messageElement.classList.add("message", type);
            chatBox.appendChild(messageElement);
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        // Receive messages from server
        socket.on("message", (data) => {
            addMessage(`${data.user}: ${data.message}`, "received");
        });

        // Send message to server
        sendButton.addEventListener("click", () => {
            const message = messageInput.value.trim();
            if (message) {
                addMessage(`You: ${message}`, "sent");
                socket.emit("message", { user: username, message });
                messageInput.value = "";
            }
        });

        // Optional: Press Enter to send a message
        messageInput.addEventListener("keypress", (e) => {
            if (e.key === "Enter") {
                sendButton.click();
            }
        });
    </script>
</body>
</html>
```

***

### **Running the Application**

1. Start the server:
   ```bash  theme={"system"}
   python app.py
   ```
2. Open your web browser and go to `http://localhost:8000/`.

You should see the chat interface. You can send and recieve messages in real-time. Just open the same URL in multiple tabs or browsers to simulate multiple users chatting with each other.

<Frame>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8ea8e19425f64baa3e85ebd1cc379dd4" data-og-width="5088" width="5088" data-og-height="3782" height="3782" data-path="img/redis-realtime-chat/chat.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=1b6e09214c7dfb42259e87eac1d065f9 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=6d3814e890779ebdde7c090983b66d93 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=95e07083b0f245316edf93649abd8fb5 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=f6d82721348ac0a4ee42b8ae0856ee41 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=0e6f6734a94e2b7cea8b0cf820c91c4b 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-realtime-chat/chat.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=07ebc1bdca83995db62749fceaeb4518 2500w" />
</Frame>

***

## **Conclusion**

In this tutorial, we built a real-time chat application using Flask, SocketIO, and Upstash Redis. Redis, with its low latency and high throughput, is an ideal choice for real-time messaging systems.

To learn more about Upstash Redis, visit the [Upstash Redis Documentation](/redis).


# Manage Sessions in Python with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/python_session



In this tutorial, we‚Äôll see how to implement session management in a FastAPI application using Upstash Redis. We‚Äôll use cookies to store session IDs, while session data is maintained in Redis for its speed and expiration features.

## **What Are Sessions and Cookies?**

* **Session:** A session is a mechanism to store user-specific data (like authentication status) between requests. It allows the server to "remember" users as they interact with the application.
* **Cookie:** A small piece of data stored in the client‚Äôs browser. In this tutorial, we‚Äôll use cookies to store session IDs, which the server uses to fetch session details from Redis.

## **Why Redis?**

Redis is a great choice for session management because:

1. **Fast Lookups:** Redis is an in-memory database, ensuring near-instantaneous access to session data.
2. **Expiration Control:** Built-in expiration functionality allows sessions to automatically expire after a defined timeout.

***

## **Setup**

### **1. Install the Required Libraries**

Install FastAPI, Upstash Redis, and other necessary dependencies:

```bash  theme={"system"}
pip install fastapi upstash-redis uvicorn python-dotenv
```

### **2. Create a Redis Database**

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli).

Create a `.env` file in the root of your project with the following content:

```bash  theme={"system"}
UPSTASH_REDIS_REST_URL=your_upstash_redis_url
UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token
```

## **Code**

Let's implement a simple FastAPI application that handles login, profile access, and logout using Redis for session management. We use sliding expiration by updating the session expiration time on every request. If a session is inactive for 15 minutes (900 seconds), it will automatically expire.

```python main.py theme={"system"}
from fastapi import FastAPI, Response, Cookie, HTTPException
from pydantic import BaseModel
from upstash_redis import Redis
from dotenv import load_dotenv
import uuid

# Load environment variables
load_dotenv()
redis = Redis.from_env()

app = FastAPI()

SESSION_TIMEOUT_SECONDS = 900  # 15 minutes

# Define the request body model for login
class LoginRequest(BaseModel):
    username: str

@app.post("/login/")
async def login(request: LoginRequest, response: Response):
    session_id = str(uuid.uuid4())
    redis.hset(f"session:{session_id}", values={"user": request.username, "status": "active"})
    redis.expire(f"session:{session_id}", SESSION_TIMEOUT_SECONDS)

    response.set_cookie(key="session_id", value=session_id, httponly=True)
    return {"message": "Logged in successfully", "session_id": session_id}


@app.get("/profile/")
async def get_profile(session_id: str = Cookie(None)):
    if not session_id:
        raise HTTPException(status_code=403, detail="No session cookie found")

    session_data = redis.hgetall(f"session:{session_id}")
    if not session_data:
        response = Response()
        response.delete_cookie(key="session_id") # Clear the expired cookie
        raise HTTPException(status_code=404, detail="Session expired")

    # Update the session expiration time (sliding expiration)
    redis.expire(f"session:{session_id}", SESSION_TIMEOUT_SECONDS)

    return {"session_id": session_id, "session_data": session_data}


@app.post("/logout/")
async def logout(response: Response, session_id: str = Cookie(None)):
    if session_id:
        redis.delete(f"session:{session_id}")
        response.delete_cookie(key="session_id")
    return {"message": "Logged out successfully"}
```

Let's test the implementation using the following script:

```python test_script.py theme={"system"}
import requests

base_url = "http://127.0.0.1:8000"

# Test login
response = requests.post(f"{base_url}/login/", json={"username": "abdullah"})
print("Login Response:", response.json())

# In the browser, you don't need to set cookies manually. The browser will handle it automatically.
session_cookie = response.cookies.get("session_id")

# Test profile
profile_response = requests.get(f"{base_url}/profile/", cookies={"session_id": session_cookie})
print("Access Profile Response:", profile_response.json())

# Test logout
logout_response = requests.post(f"{base_url}/logout/", cookies={"session_id": session_cookie})
print("Logout Response:", logout_response.json())

# Test profile after logout
profile_after_logout_response = requests.get(f"{base_url}/profile/", cookies={"session_id": session_cookie})
print("Access Profile After Logout Response:", profile_after_logout_response.text)
```

***

### **Code Explanation**

1. **`/login/` Endpoint:**
   * Generates a unique session ID using `uuid.uuid4()`.
   * Stores the session data in Redis using the session ID as the key.
   * Sets a cookie named `session_id` with the generated session ID.
   * Returns a success message along with the session ID.

2. **`/profile/` Endpoint:**
   * Retrieves the session ID from the cookie.
   * Fetches the session data from Redis using the session ID.
   * Updates the session expiration time.
   * Returns the session ID and session data.

3. **`/logout/` Endpoint:**
   * Deletes the session data from Redis using the session ID.
   * Clears the `session_id` cookie.

***

### **Run the Application**

1. Start the FastAPI server:
   ```bash  theme={"system"}
   uvicorn main:app --reload
   ```

2. Run the test script:
   ```bash  theme={"system"}
   python test_script.py
   ```

Here's what you should expect:

```plaintext  theme={"system"}
Login Response: {'message': 'Logged in successfully', 'session_id': '68223c50-ede4-48eb-9d26-4a4dd735c10d'}
Access Profile Response: {'session_id': '68223c50-ede4-48eb-9d26-4a4dd735c10d', 'session_data': {'user': 'abdullah', 'status': 'active'}}
Logout Response: {'message': 'Logged out successfully'}
Access Profile After Logout Response: {"detail":"Session not found or expired"}
```

***

## **Conclusion**

By combining FastAPI, cookies, and Upstash Redis, we‚Äôve created a reliable session management system. With Redis‚Äôs speed and built-in expiration features, this approach ensures secure and efficient handling of user sessions.

To learn more about Upstash Redis, visit the [Upstash Redis Documentation](/redis).


# Building a URL Shortener with Redis
Source: https://upstash.com/docs/redis/tutorials/python_url_shortener



### Introduction

In this tutorial, we‚Äôll build a simple URL shortener using Redis and Python. The short URL service will generate a random short code for each URL, store it in Redis, and allow users to retrieve the original URL using the short code. We‚Äôll also implement an expiration time for each shortened URL, making it expire after a specified period.

### Environment Setup

First, install the necessary dependencies, including Upstash Redis and `python-dotenv` for environment variables:

```shell  theme={"system"}
pip install upstash-redis
```

### Database Setup

Create a Redis database using the [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli), and export the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REST_TOKEN` to your environment:

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

You can also use `python-dotenv` to load environment variables from a `.env` file:

```text .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Application Setup

In this example, we will build a URL shortener where each short URL will be stored in Redis with an expiration time.

Create `url_shortener.py`:

```py url_shortener.py theme={"system"}
import string
import random
from upstash_redis import Redis
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()

# Redis connection
redis = Redis.from_env()

# Characters to generate the short URL from
CHARS = string.ascii_letters + string.digits
BASE_URL = "https://short.url/"

# Function to generate a random string for the short URL
def generate_short_code(length=6):
    return ''.join(random.choices(CHARS, k=length))

# Function to shorten the URL with an expiration time
def shorten_url(url, expiration=3600):
    # Generate a random short code
    short_code = generate_short_code()
    # Save the short code in Redis
    redis.set(short_code, url, ex=expiration)
    return BASE_URL + short_code

# Function to get the original URL from the short URL
def get_original_url(short_code):
    return redis.get(short_code)

# Example usage
if __name__ == "__main__":
    original_url = "https://example.com/my-very-long-url"

    # Shorten the URL
    short_url = shorten_url(original_url, expiration=600)
    print(f"Shortened URL: {short_url}")

    # Get the original URL
    original_url = get_original_url(short_url.split("/")[-1])

    if original_url:
        print(f"Original URL: {original_url}")
    else:
        print("Short URL expired or not found")
```

### Running the Application

Simply run the Python script:

```shell  theme={"system"}
python url_shortener.py
```

This script will shorten a long URL, store the mapping in Redis, and print the shortened URL. It will then attempt to retrieve the original URL using the short code.

Here is an example output:

```shell  theme={"system"}
Shortened URL: https://short.url/0lSLFI
Original URL: https://example.com/my-very-long-url
```

To monitor your data in Redis, you can use the [Upstash Console](https://console.upstash.com) and check out the Data Browser tab.

### How to Use the URL Shortener for Web Applications

1. Extract the short code from the shortened URL (e.g., `0lSLFI`).

2. Look up the original URL in Redis using that code.

3. Redirect the user to the original URL.

### Code Breakdown

1. **Random Short Code Generation**: The `generate_short_code` function creates a random string of characters (letters and digits) that will serve as the short code for the URL.

2. **Storing in Redis**: The `shorten_url` function takes the original URL and stores it in Redis using the randomly generated short code as the key. The `ex` parameter sets an expiration time (in seconds) for how long the shortened URL will be valid.

3. **Retrieving the Original URL**: The `get_original_url` function takes the short code and looks it up in Redis to retrieve the original URL. If the short code doesn't exist (due to expiration or other reasons), it returns `None`.

4. **Expiration Handling**: If the short code has expired, Redis automatically removes the entry, and the script will print a message indicating that the URL has expired or cannot be found.


# Serverless Python API with Redis
Source: https://upstash.com/docs/redis/tutorials/pythonapi



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/aws-cdk-python" horizontal>
  You can find the project source code on GitHub.
</Card>

This tutorial shows how to build a serverless API for Page View Counter with
Python and Redis. The API will the count page views and show it in JSON format.

### Prerequisites

* Complete all steps in [Getting started with the AWS CDK](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html)

### Project Setup

Create and navigate to a directory named `counter-cdk`. CDK CLI uses this directory name to name things in your CDK code, so if you decide to use a different name, don't forget to make the appropriate changes when applying this tutorial.

```shell  theme={"system"}
mkdir counter-cdk && cd counter-cdk
```

Initialize a new CDK project.

```shell  theme={"system"}
cdk init app --language typescript
```

### Counter Function Setup

Create a folder named `api` under `lib`

```shell  theme={"system"}
mkdir lib/api
```

Create `/lib/api/requirements.txt`

```txt /lib/api/requirements.txt theme={"system"}
upstash-redis
```

Create `/lib/api/index.py`

```py /lib/api/index.py theme={"system"}
from upstash_redis import Redis

redis = Redis.from_env()

def handler(event, context):
    count = redis.incr('counter')
    return {
        'statusCode': 200,
        'body': f'Counter: {count}'
    }
```

### Counter Stack Setup

Update `/lib/counter-cdk-stack.ts`

```ts /lib/counter-cdk-stack.ts theme={"system"}
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as lambda from 'aws-cdk-lib/aws-lambda';
import * as path from 'path';

export class CounterCdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const counterFunction = new lambda.Function(this, 'CounterFunction', {
      code: lambda.Code.fromAsset(path.join(__dirname, 'api'), {
        bundling: {
          image: lambda.Runtime.PYTHON_3_9.bundlingImage,
          command: [
            'bash', '-c',
            'pip install -r requirements.txt -t /asset-output && cp -au . /asset-output'
          ],
        },
      }),
      runtime: lambda.Runtime.PYTHON_3_9,
      handler: 'index.handler',
      environment: {
        UPSTASH_REDIS_REST_URL: process.env.UPSTASH_REDIS_REST_URL || '',
        UPSTASH_REDIS_REST_TOKEN: process.env.UPSTASH_REDIS_REST_TOKEN || '',
      },
    });

    const counterFunctionUrl = counterFunction.addFunctionUrl({
      authType: lambda.FunctionUrlAuthType.NONE,
    });

    new cdk.CfnOutput(this, "counterFunctionUrlOutput", {
      value: counterFunctionUrl.url,
    })
  }
}
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and export `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your environment.

```shell  theme={"system"}
export UPSTASH_REDIS_REST_URL=<YOUR_URL>
export UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Deploy

Run in the top folder:

```shell  theme={"system"}
cdk synth
cdk bootstrap
cdk deploy
```

Visit the output url.


# AWS Lambda Rate Limiting with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/rate-limiting



In this tutorial, we will deploy a AWS Lambda function ratelimited based on the client's IP address using `@upstash/ratelimit` and Serverless Framework.

### Prerequisites

1. Install the Serverless Framework with `npm i serverless -g`

### Project Setup

Create a Serverless Framework application with the following options:

```shell  theme={"system"}
‚ûú  tutorials > ‚úó serverless
Serverless œü Framework

Welcome to Serverless Framework V.4

Create a new project by selecting a Template to generate scaffolding for a specific use-case.

‚úî Select A Template: ¬∑ AWS / Node.js / HTTP API

‚úî Name Your Project: ¬∑ ratelimit-serverless

‚úî Template Downloaded

‚úî Create Or Select An Existing App: ¬∑ Create A New App

‚úî Name Your New App: ¬∑ ratelimit-serverless

Your new Service "ratelimit-serverless" is ready. Here are next steps:

‚Ä¢ Open Service Directory: cd ratelimit-serverless
‚Ä¢ Install Dependencies: npm install (or use another package manager)
‚Ä¢ Deploy Your Service: serverless deploy
```

```shell  theme={"system"}
cd ratelimit-serverless
```

Create `package.json` with `@upstash/ratelimit` as a dependency:

```json package.json theme={"system"}
{
    "dependencies": {
      "@upstash/ratelimit": "latest",
      "@upstash/redis": "latest"
    }
  }
```

Install the dependencies:

```shell  theme={"system"}
npm install
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Ratelimited Function Setup

Update `handler.js`:

```js handler.js theme={"system"}
const { Ratelimit } = require("@upstash/ratelimit");
const { Redis } = require("@upstash/redis");

const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 s"),
  prefix: "@upstash/ratelimit",
  analytics: true,
});

exports.ratelimit = async (event) => {
  const identifier = event.requestContext.http.sourceIP;
  const { success, limit, remaining, pending } = await ratelimit.limit(
    identifier
  );
  const response = {
    success: success,
    limit: limit,
    remaining: remaining,
  };

  // pending is a promise for handling the analytics submission
  await pending;

  if (!success) {
    return {
      statusCode: 429,
      body: JSON.stringify(response),
    };
  }
  return {
    statusCode: 200,
    body: JSON.stringify(response),
  };
};
```

Update `serverless.yml` to pass the environment variables:

```yaml serverless.yml theme={"system"}
service: ratelimit-serverless

provider:
  name: aws
  runtime: nodejs20.x
  environment:
    UPSTASH_REDIS_REST_URL: ${env:UPSTASH_REDIS_REST_URL}
    UPSTASH_REDIS_REST_TOKEN: ${env:UPSTASH_REDIS_REST_TOKEN}

functions:
  ratelimit:
    handler: handler.ratelimit
    events:
      - httpApi:
          path: /
          method: get
```

### Developing

Run the following command to start your dev session.

```shell  theme={"system"}
serverless dev
```

### Deployment

Run the following command to deploy your service.

```shell  theme={"system"}
serverless deploy
```

Visit the output url.


# Serverless Redisson
Source: https://upstash.com/docs/redis/tutorials/redisson

This tutorial shows how to use Upstash with Redisson client.

This tutorial shows how to use Upstash with Redisson client.

See [code](https://github.com/upstash/examples/tree/master/examples/redisson)

### `1` Create a Maven Project

Create a maven project and copy the following dependency to your pom.xml

```xml  theme={"system"}
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.15.4</version>
</dependency>
```

### `2` Create a Redis (Upstash) Database

Create a database as [getting started](../overall/getstarted)

### `3` Code

Create your java file and replace Redis password and URL below. If you enabled
TLS, the endpoint should start with `rediss`

```typescript  theme={"system"}
public class Main {

    public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setPassword("YOUR_PASSWORD")
                // use "rediss://" for SSL connection
                .setAddress("YOUR_ENDPOINT");
        RedissonClient redisson = Redisson.create(config);
        RMap<String, String> map = redisson.getMap("map");
        map.put("foo", "bar");
        System.out.println(map.get("foo"));
    }
}
```


# Roadmap Voting App with Serverless Redis
Source: https://upstash.com/docs/redis/tutorials/roadmapvotingapp

This is a single page application powered by upstash and next.js.

<Info>
  We have developed an advanced version of Roadmap Voting App where users should
  log in to request or vote for a new feature. See it live version in [Upstash
  Roadmap](https://roadmap.upstash.com). See [the blog
  post](https://blog.upstash.com/roadmap-application) to learn about it. The
  below example allows users to request features anonymously.
</Info>

In this tutorial we will write a single page application which uses Redis as
state store in a Next.js application.

The example is a basic roadmap voting application where users enter and vote for
feature requests. You can check the complete application in
[Upstash Roadmap page](https://roadmap.upstash.com)

### Deploy Yourself

You can check the source code of the complete application
[here](https://github.com/upstash/serverless-examples/tree/master/roadmap-voting-app).
Thanks to [Upstash\&Vercel integration](https://vercel.com/integrations/upstash),
you can deploy the application yourself with zero cost/code by clicking below:
[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/git/external?repository-url=https%3A%2F%2Fgithub.com%2Fupstash%2Fserverless-tutorials%2Ftree%2Fmaster%2Froadmap-voting-app\&env=LOGO\&envDescription=Enter%20URL%20for%20your%20project%2Fcompany%20logo\&envLink=https%3A%2F%2Fdocs.upstash.com%2Fdocs%2Ftutorials%2Froadmap_voting_app\&project-name=roadmap-voting\&repo-name=roadmap-voting\&demo-title=Roadmap%20Voting\&demo-description=Roadmap%20Voting%20Page%20for%20Your%20Project\&demo-url=https%3A%2F%2Froadmap.upstash.com\&integration-ids=oac_V3R1GIpkoJorr6fqyiwdhl17)

### Create Next.js Project

We will use Next.js as web framework. So let's create a next.js app and install
the redis client first.

`npx create-next-app nextjs-with-redis`

`npm install ioredis`

### index.js

Our application will be a single page. We will list the features with their
order of votes. There will be 3 actions available for the page user:

* The user will suggest a new feature.
* The user will vote up an existing feature.
* The user will enter their email to be notified of a release of any feature.

The below are the parts that handles all those. If you want to check the full
page see
[here](https://github.com/upstash/serverless-tutorials/blob/master/roadmap-voting-app/pages/index.js)

```javascript  theme={"system"}
import Head from 'next/head'
import { ToastContainer, toast } from 'react-toastify';
import * as React from "react";

class Home extends React.Component {
    ...
    refreshData() {
        fetch("api/list")
            .then(res => res.json())
            .then(
                (result) => {
                    this.setState({
                        isLoaded: true,
                        items: result.body
                    });
                    this.inputNewFeature.current.value = "";
                },
                (error) => {
                    this.setState({
                        isLoaded: true,
                        error
                    });
                }
            )
    }

    vote(event, title) {
        const requestOptions = {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({"title": title})
        };
        console.log(requestOptions);
        fetch('api/vote', requestOptions)
            .then(response => response.json()).then(data => {
                console.log(data)
                if(data.error) {
                    toast.error(data.error, {hideProgressBar: true, autoClose: 3000});
                } else {
                    this.refreshData()
                }
        })
    }

    handleNewFeature(event) {
        const requestOptions = {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({"title": this.inputNewFeature.current.value})
        };
        fetch('api/create', requestOptions)
            .then(response => response.json()).then(data => {
            if(data.error) {
                toast.error(data.error, {hideProgressBar: true, autoClose: 5000});
            } else {
                toast.info("Your feature has been added to the list.", {hideProgressBar: true, autoClose: 3000});
                this.refreshData()
            }
        });
        event.preventDefault();
    }

    handleNewEmail(event) {
        const requestOptions = {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({"email": this.inputEmail.current.value})
        };
        console.log(requestOptions);
        fetch('api/addemail', requestOptions)
            .then(response => response.json()).then(data => {
            if(data.error) {
                toast.error(data.error, {hideProgressBar: true, autoClose: 3000});
            } else {
                toast.info("Your email has been added to the list.", {hideProgressBar: true, autoClose: 3000});
                this.refreshData()
            }
        });
        event.preventDefault();
    }
}
export default Home;
```

### APIs

With Next.js, you can write server-side APIs within your project. We will have 4
apis:

* list features
* vote a feature
* add a new feature
* add email

Now let's examine these API implementations:

#### list.js

The list API connects to the Redis and fetches feature requests ordered by their
scores (votes) from the Sorted Set `roadmap`.

<Snippet file="redis/ioredisnote.mdx" />

```javascript  theme={"system"}
import { fixUrl } from "./utils";
import Redis from "ioredis";

module.exports = async (req, res) => {
  let redis = new Redis(fixUrl(process.env.REDIS_URL));
  let n = await redis.zrevrange("roadmap", 0, 100, "WITHSCORES");
  let result = [];
  for (let i = 0; i < n.length - 1; i += 2) {
    let item = {};
    item["title"] = n[i];
    item["score"] = n[i + 1];
    result.push(item);
  }

  redis.quit();

  res.json({
    body: result,
  });
};
```

#### create.js

This API connects to the Redis server and add a new element to the sorted set
(roadmap) . We use "NX" flag together with ZADD, so a user will not be able to
overwrite an existing feature request with the same title.

```javascript  theme={"system"}
import Redis from "ioredis";
import { fixUrl } from "./utils";

module.exports = async (req, res) => {
  let redis = new Redis(fixUrl(process.env.REDIS_URL));
  const body = req.body;
  const title = body["title"];
  if (!title) {
    redis.quit();
    res.json({
      error: "Feature can not be empty",
    });
  } else if (title.length < 70) {
    await redis.zadd("roadmap", "NX", 1, title);
    redis.quit();
    res.json({
      body: "success",
    });
  } else {
    redis.quit();
    res.json({
      error: "Max 70 characters please.",
    });
  }
};
```

#### vote.js

This API updates (increments) the score of the selected feature request. It also
keeps the IP addresses of the user to prevent multiple votes on the same feature
request.

```javascript  theme={"system"}
import Redis from "ioredis";
import { fixUrl } from "./utils";

module.exports = async (req, res) => {
  let redis = new Redis(fixUrl(process.env.REDIS_URL));
  const body = req.body;
  const title = body["title"];
  let ip = req.headers["x-forwarded-for"] || req.headers["Remote_Addr"] || "NA";
  let c = ip === "NA" ? 1 : await redis.sadd("s:" + title, ip);
  if (c === 0) {
    redis.quit();
    res.json({
      error: "You can not vote an item multiple times",
    });
  } else {
    let v = await redis.zincrby("roadmap", 1, title);
    redis.quit();
    res.json({
      body: v,
    });
  }
};
```

#### addemail.js

This API simply adds the user's email to the Redis Set. As the Set already
ensures the uniqueness, we only need to check if the input is a valid email.

```javascript  theme={"system"}
import Redis from "ioredis";
import { fixUrl } from "./utils";

module.exports = async (req, res) => {
  let redis = new Redis(fixUrl(process.env.REDIS_URL));

  const body = req.body;
  const email = body["email"];

  redis.on("error", function (err) {
    throw err;
  });

  if (email && validateEmail(email)) {
    await redis.sadd("emails", email);
    redis.quit();
    res.json({
      body: "success",
    });
  } else {
    redis.quit();
    res.json({
      error: "Invalid email",
    });
  }
};

function validateEmail(email) {
  const re =
    /^(([^<>()\[\]\\.,;:\s@"]+(\.[^<>()\[\]\\.,;:\s@"]+)*)|(".+"))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/;
  return re.test(String(email).toLowerCase());
}
```

#### css and utils

[index.css](https://github.com/upstash/serverless-tutorials/blob/master/roadmap-voting-app/pages/index.css)
helps page to look good and
[utils.js](https://github.com/upstash/serverless-tutorials/blob/master/roadmap-voting-app/pages/api/utils.js)
fixes common mistakes on Redis URL.

### Notes:

* If you deploy this application with Vercel; Vercel runs AWS Lambda functions
  to back the API implementations. For best performance choose the the same
  region for both Vercel functions and Upstash cluster.
* You can access your database details via
  [Upstash Console](https://console.upstash.com)


# Serverless API with Java and Redis
Source: https://upstash.com/docs/redis/tutorials/serverless_java_redis



In this tutorial, we will build a stateful serverless API using Java and Redis
on AWS Lambda. The API will simply count the page views and return it as HTTP
response.

### Prerequisites

1. Install the Serverless Framework installed with an AWS account set up.

```shell  theme={"system"}
npm i serverless@3.39.0 -g
```

2. Install JDK and not Java JRE. Set your JAVA\_HOME.
3. Install Apache Maven.
4. Create a free Serverless Redis database from
   [Upstash](https://console.upstash.com) as described
   [here](/redis/overall/getstarted).

### Project Setup

Create the project:

```shell  theme={"system"}
serverless create --template aws-java-maven --name counter-api -p aws-java-counter-api
```

```shell  theme={"system"}
cd aws-java-counter-api
```

Add `jedis` as dependency to the `pom.xml`:

```xml pom.xml theme={"system"}
...
    <dependency>
        <groupId>redis.clients</groupId>
        <artifactId>jedis</artifactId>
        <version>3.6.0</version>
    </dependency>
...
```

Update `serverless.yml` as below:

```yaml serverless.yml theme={"system"}
service: counter-api

frameworkVersion: '3'

provider:
  name: aws
  runtime: java17

package:
  artifact: target/hello-dev.jar

functions:
 hello:
   handler: com.serverless.Handler
   events:
     - httpApi:
         path: /hello
         method: get
```

### Counter Function Setup

Update `src/main/java/com/serverless/Handler.java` as below:

```java src/main/java/com/serverless/Handler.java theme={"system"}
package com.serverless;

import java.util.Map;

import com.amazonaws.services.lambda.runtime.Context;
import com.amazonaws.services.lambda.runtime.RequestHandler;
import redis.clients.jedis.Jedis;

public class Handler implements RequestHandler<Map<String, Object>, ApiGatewayResponse> {
	@Override
	public ApiGatewayResponse handleRequest(Map<String, Object> input, Context context) {
		Jedis jedis = new Jedis("lasting-roughy-29092.upstash.io", 6379, true);
		jedis.auth("********");
		Long value = jedis.incr("counter");
		jedis.close();
		String message = "Hello World, Count:" + value;
		return ApiGatewayResponse.builder()
				.setStatusCode(200)
				.setObjectBody(message)
				.build();
	}
}
```

In the above code, you need to replace your Redis endpoint and password. You can copy Jedis connection code from the [Upstash Redis Console](https://console.upstash.com/redis) -> Your Database -> Connect to your database -> Java.

### Build and Deploy

Build your project:

```shell  theme={"system"}
mvn clean install
```

Deploy to AWS:

```shell  theme={"system"}
serverless deploy
```

Visit the output URL to see the counter in action.


# Using AWS SAM
Source: https://upstash.com/docs/redis/tutorials/using_aws_sam



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/aws-sam" horizontal>
  You can find the project source code on GitHub.
</Card>

This tutorial implements a serverless application and deploy it to AWS Lambda
using AWS SAM.

### Prerequisites

1. [Complete AWS SAM Prerequisites](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/prerequisites.html)
2. [Install the AWS SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html)

### Project Setup

Create a SAM application with the following options:

```shell  theme={"system"}
‚ûú  tutorials > ‚úó sam init
Which template source would you like to use?
	1 - AWS Quick Start Templates
	2 - Custom Template Location
Choice: 1

Choose an AWS Quick Start application template
	1 - Hello World Example
	2 - Data processing
	3 - Hello World Example with Powertools for AWS Lambda
	4 - Multi-step workflow
	5 - Scheduled task
	6 - Standalone function
	7 - Serverless API
	8 - Infrastructure event management
	9 - Lambda Response Streaming
	10 - Serverless Connector Hello World Example
	11 - Multi-step workflow with Connectors
	12 - GraphQLApi Hello World Example
	13 - Full Stack
	14 - Lambda EFS example
	15 - DynamoDB Example
	16 - Machine Learning
Template: 1

Use the most popular runtime and package type? (Python and zip) [y/N]: y

Would you like to enable X-Ray tracing on the function(s) in your application?  [y/N]: N

Would you like to enable monitoring using CloudWatch Application Insights?
For more info, please view https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-application-insights.html [y/N]: N

Would you like to set Structured Logging in JSON format on your Lambda functions?  [y/N]: N
```

```shell  theme={"system"}
cd sam-app
```

### Counter Function Setup

Update `/hello_world/requirements.txt` to include `upstash-redis`:

```txt /hello_world/requirements.txt theme={"system"}
requests
upstash-redis
```

Update `/hello_world/app.py`:

```python /hello_world/app.py theme={"system"}
from upstash_redis import Redis

redis = Redis.from_env()

def lambda_handler(event, context):
    count = redis.incr('counter')
    return {
        'statusCode': 200,
        'body': f'Counter: {count}'
    }
```

Update `/template.yaml` to pass Upstash Redis environment variables:

```yaml /template.yaml theme={"system"}
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: >
  sam-app

  Sample SAM Template for sam-app

Globals:
  Function:
    Timeout: 3
    MemorySize: 128

Parameters:
  UpstashRedisRestURL:
    Type: String
  UpstashRedisRestToken:
    Type: String

Resources:
  HelloWorldFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: hello_world/
      Handler: app.lambda_handler
      Runtime: python3.9
      Architectures:
        - x86_64
      Events:
        HelloWorld:
          Type: Api
          Properties:
            Path: /hello
            Method: get
      Environment:
        Variables:
          UPSTASH_REDIS_REST_URL: !Ref UpstashRedisRestURL
          UPSTASH_REDIS_REST_TOKEN: !Ref UpstashRedisRestToken

Outputs:
  HelloWorldApi:
    Description: "API Gateway endpoint URL for Prod stage for Hello World function"
    Value: !Sub "https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/"
  HelloWorldFunction:
    Description: "Hello World Lambda Function ARN"
    Value: !GetAtt HelloWorldFunction.Arn
  HelloWorldFunctionIamRole:
    Description: "Implicit IAM Role created for Hello World function"
    Value: !GetAtt HelloWorldFunctionRole.Arn

```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli). Copy `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` for the next steps.

### Build

```shell  theme={"system"}
sam build
```

### Deploy

Enter your database related environment variables when prompted.

```shell  theme={"system"}
sam deploy --guided
```

Visit the HelloWorld API Gateway URL to see the response.


# Serverless Redis on Google Cloud Functions
Source: https://upstash.com/docs/redis/tutorials/using_google_cloud_functions



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/google-cloud-functions" horizontal>
  You can find the project source code on GitHub.
</Card>

Google Cloud Functions is the second most popular serverless execution platform.
Similar to AWS Lambda it is stateless, namely you need to access external
resources to read or write your applications state. In this post, we will
introduce Redis as a database for your Google Cloud functions.

This tutorial shows how to build a serverless API with Redis on Google Cloud
Functions. The API will simply count the views and show it in JSON format.

### Prerequisites

1. [Create a Google Cloud Project.](https://cloud.google.com/resource-manager/docs/creating-managing-projects)
2. [Enable billing for your project.](https://cloud.google.com/billing/docs/how-to/verify-billing-enabled#console)
3. Enable Cloud Functions, Cloud Build, Artifact Registry, Cloud Run, Logging, and Pub/Sub APIs.

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli). Copy `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` for the next steps.

### Counter Function Setup & Deploy

1. Go to [Cloud Functions](https://console.cloud.google.com/functions/list) in Google Cloud Console.
2. Click **Create Function**.
3. Setup **Basics and Trigger** Configuration like below:
   <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=007ed606059c1a85715b71f3cc93f7d8" alt="" data-og-width="1090" width="1090" data-og-height="1082" height="1082" data-path="img/redis-gcloud/basics.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=43b1d3e50933c5dcfa82b66fc851a7a0 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=7004784999274823be6d91f4fada8507 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=f898ec6c37fe88ca6ea160cb5d6c128e 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2871baf9499c25407ad19cf314871b28 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=a3a3397a7490aaa2f81fde3081af7cdd 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/basics.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3c6c312c51df82b43ae09ff00d414a81 2500w" />
4. Using your `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN`, setup **Runtime environment variables** under **Runtime, build, connections and privacy settings** like below.
   <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e23d98d5b0c2619d971719dac8899931" alt="" data-og-width="1006" width="1006" data-og-height="432" height="432" data-path="img/redis-gcloud/environment.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d1d4089e0dab97bd4f9c722792e3f665 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2f0f5f385024764675ac77ca35de41e9 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2ffe0b80e0a93ac3eceb060fa0ae8bb6 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=321957fba3db5bdc17b51bf3af983cef 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d2821b72c40318f56fabb809970bbe62 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/redis-gcloud/environment.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=af5fbdb53b54bb2953ec0c56a6454c44 2500w" />
5. Click **Next**.
6. Set **Entry point** to `counter`.
7. Update `index.js`

```js index.js theme={"system"}
const { Redis } = require("@upstash/redis");
const functions = require('@google-cloud/functions-framework');

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN
});

functions.http('counter', async (req, res) => {
  const count = await redis.incr("counter");
  res.send("Counter:" + count);
});
```

8. Update `package.json` to include `@upstash/redis`.

```json package.json theme={"system"}
{
  "dependencies": {
    "@google-cloud/functions-framework": "^3.0.0",
    "@upstash/redis": "^1.31.6"
  }
}
```

9. Click **Deploy**.
10. Visit the given URL.


# Using Serverless Framework
Source: https://upstash.com/docs/redis/tutorials/using_serverless_framework



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/redis-js/tree/main/examples/serverless-framework/counter" horizontal>
  You can find the project source code on GitHub.
</Card>

This tutorial implements a serverless application and deploys it to AWS Lambda
using Serverless Framework

### Prerequisites

1. Install the Serverless Framework with `npm i serverless -g`

### Project Setup

Create a Serverless Framework application with the following options:

```shell  theme={"system"}
‚ûú  tutorials > ‚úó serverless
Serverless œü Framework

Welcome to Serverless Framework V.4

Create a new project by selecting a Template to generate scaffolding for a specific use-case.

‚úî Select A Template: ¬∑ AWS / Node.js / HTTP API

‚úî Name Your Project: ¬∑ counter-serverless

‚úî Template Downloaded

‚úî Create Or Select An Existing App: ¬∑ Create A New App

‚úî Name Your New App: ¬∑ counter-serverless

Your new Service "counter-serverless" is ready. Here are next steps:

‚Ä¢ Open Service Directory: cd counter-serverless
‚Ä¢ Install Dependencies: npm install (or use another package manager)
‚Ä¢ Deploy Your Service: serverless deploy
```

```shell  theme={"system"}
cd counter-serverless
```

Create `package.json` with `@upstash/redis` as a dependency:

```json package.json theme={"system"}
{
    "dependencies": {
      "@upstash/redis": "latest"
    }
  }
```

Install the dependencies:

```shell  theme={"system"}
npm install
```

### Database Setup

Create a Redis database using [Upstash Console](https://console.upstash.com) or [Upstash CLI](https://github.com/upstash/cli) and copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` into your `.env` file.

```shell .env theme={"system"}
UPSTASH_REDIS_REST_URL=<YOUR_URL>
UPSTASH_REDIS_REST_TOKEN=<YOUR_TOKEN>
```

### Counter Function Setup

Update `handler.js`:

```js handler.js theme={"system"}
const { Redis } = require('@upstash/redis');

const redis = Redis.fromEnv();

exports.counter = async (event) => {
    const count = await redis.incr("counter");
    return {
        statusCode: 200,
        body: JSON.stringify('Counter: ' + count),
    };
};
```

Update `serverless.yml` to pass the environment variables:

```yaml serverless.yml theme={"system"}
service: counter-serverless

provider:
  name: aws
  runtime: nodejs20.x
  environment:
    UPSTASH_REDIS_REST_URL: ${env:UPSTASH_REDIS_REST_URL}
    UPSTASH_REDIS_REST_TOKEN: ${env:UPSTASH_REDIS_REST_TOKEN}

functions:
  counter:
    handler: handler.counter
    events:
      - httpApi:
          path: /
          method: get
```

### Developing

Run the following command to start your dev session.

```shell  theme={"system"}
serverless dev
```

### Deployment

Run the following command to deploy your service.

```shell  theme={"system"}
serverless deploy
```

Visit the output url.


# Advanced Settings
Source: https://upstash.com/docs/search/features/advanced-settings



This page covers the advanced configuration options available in the Upstash Search. These parameters allow you to fine-tune search behavior for your specific use case and requirements.

## Reranking

The `reranking` parameter enables enhanced search result reranking using advanced AI models. It's disabled by default (`false`) and incurs additional costs when enabled.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const results = await index.search({
    query: "complex technical documentation",
    reranking: true // Enable reranking
  });
  ```

  ```python Python theme={"system"}
  results = index.search(
      query="complex technical documentation",
      reranking=True  # Enable reranking
  )
  ```
</CodeGroup>

**Reranking Options:**

* **Standard Reranking** (`reranking: false`, default): Uses a simpler, faster model with no additional cost
* **Advanced Reranking** (`reranking: true`): Uses state-of-the-art models for highest quality results at \$1 per 1K operations

Learn more about how reranking works in our [Algorithm documentation](/search/features/algorithm#3-reranking).

## Semantic Weight

The `semanticWeight` parameter controls the balance between semantic search and full-text search in the hybrid search process. It accepts values from 0 to 1, with a default of 0.75 (75% semantic, 25% full-text).

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  // More semantic matching (better for conceptual searches)
  const semanticResults = await index.search({
    query: "artificial intelligence concepts",
    semanticWeight: 0.9 // 90% semantic, 10% full-text
  });

  // More keyword matching (better for exact terms)
  const keywordResults = await index.search({
    query: "API documentation React hooks",
    semanticWeight: 0.3 // 30% semantic, 70% full-text
  });
  ```

  ```python Python theme={"system"}
  # More semantic matching
  semantic_results = index.search(
      query="artificial intelligence concepts",
      semantic_weight=0.9  # 90% semantic, 10% full-text
  )

  # More keyword matching
  keyword_results = index.search(
      query="API documentation React hooks",
      semantic_weight=0.3  # 30% semantic, 70% full-text
  )
  ```
</CodeGroup>

**Optimization Guidelines:**

* **Higher semantic weight (0.7-1.0)**: Better for conceptual searches, finding related content, and handling synonyms
* **Lower semantic weight (0.0-0.4)**: Better for exact keyword matching, technical queries, and specific terms

Read more about hybrid search in our [Algorithm documentation](/search/features/algorithm#2-hybrid-vector-search).

## Input Enrichment

The `inputEnrichment` parameter controls whether queries are enhanced using AI before searching. It's enabled by default (`true`) and significantly improves search quality at the cost of some additional latency.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  // Disable input enrichment for faster responses
  const results = await index.search({
    query: "space opera",
    inputEnrichment: false // Faster but less enhanced results
  });

  // Default behavior (enrichment enabled)
  const enrichedResults = await index.search({
    query: "space opera"
    // inputEnrichment: true is the default
  });
  ```

  ```python Python theme={"system"}
  # Disable input enrichment for faster responses
  results = index.search(
      query="space opera",
      input_enrichment=False  # Faster but less enhanced results
  )

  # Default behavior (enrichment enabled)
  enriched_results = index.search(
      query="space opera"
      # input_enrichment=True is the default
  )
  ```
</CodeGroup>

**When to Disable Input Enrichment:**

* When you need the fastest possible response times
* When you want to preserve the exact user query for full-text search

**Benefits of Input Enrichment:**

* Handles typos and alternative phrasings
* Expands queries with related terms and context
* Improves understanding of user intent
* Adds semantic context to ambiguous queries

Learn more about input enrichment in our [Algorithm documentation](/search/features/algorithm#1-input-enrichment).

## Keep Original Query After Enrichment

The `keepOriginalQueryAfterEnrichment` parameter controls whether the original user query is preserved alongside the AI-enriched version during search. It's disabled by default (`false`) and only has an effect when `inputEnrichment` is enabled.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  // Keep both original and enriched queries
  const results = await index.search({
    query: "space opera",
    keepOriginalQueryAfterEnrichment: true // Uses both original and enriched
  });
  ```
</CodeGroup>

**When to Enable This Option:**

* When you want to ensure exact keyword matches are included
* When the original query contains specific technical terms or identifiers
* When you want to balance AI enhancement with literal query matching

<Note>
  This parameter has no effect when `inputEnrichment` is set to `false`, since there's no enriched query to compare against.
</Note>

## Filter

The `filter` parameter allows you to restrict search results based on content criteria. It accepts either a string expression (SQL-like syntax) or a structured filter object (TypeScript SDK only).

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  // String filter expression (SQL-like syntax)
  const results = await index.search({
    query: "wireless headphones",
    filter: "category = 'Electronics' AND in_stock > 0"
  });

  // TypeSafe structured filter (TypeScript SDK only)
  const results2 = await index.search({
    query: "wireless headphones",
    filter: {
      AND: [
        { category: { equals: 'Electronics' } },
        { in_stock: { greaterThan: 0 } }
      ]
    }
  });
  ```

  ```python Python theme={"system"}
  # String filter expression (SQL-like syntax)
  results = index.search(
      query="wireless headphones",
      filter="category = 'Electronics' AND in_stock > 0"
  )
  ```
</CodeGroup>

For detailed information about filter syntax, operators, and examples, see the [Filtering documentation](/search/features/filtering).

## Example: Complete Configuration

Here's an example showing all parameters configured together:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const results = await index.search({
    query: "machine learning algorithms for data analysis",
    limit: 15,
    filter: "category = 'data-science' AND difficulty_level <= 'intermediate'",
    reranking: true,
    semanticWeight: 0.8,
    inputEnrichment: true
  });
  ```

  ```python Python theme={"system"}
  results = index.search(
      query="machine learning algorithms for data analysis",
      limit=15,
      filter="category = 'data-science' AND difficulty_level <= 'intermediate'",
      reranking=True,
      semantic_weight=0.8,
      input_enrichment=True
  )
  ```
</CodeGroup>

This configuration:

* Searches for ML content with enhanced query processing
* Returns up to 15 results
* Filters for data science content at beginner to intermediate levels
* Uses premium reranking for best quality results
* Emphasizes semantic matching (80%) over keyword matching (20%)
* Enables input enrichment for better intent understanding


# Algorithm
Source: https://upstash.com/docs/search/features/algorithm



Our algorithm combines AI-powered query enhancement, hybrid search techniques, and intelligent reranking to understand user intent (also known as [search intent](https://backlinko.com/hub/seo/search-intent)) and return the most accurate results.

Upstash Search processes every query through three key stages:

1. **Input Enrichment**: Enhances the search query using AI to better understand user intent.
2. **Hybrid Vector Search**: Combines semantic search and full-text search to find relevant documents.
3. **Reranking**: Uses AI models to reorder results based on relevance.

### 1. Input Enrichment

The first stage enhances your search query using a Large Language Model (LLM). This process:

* Expands the original query with related terms and context
* Improves understanding of user intent
* Handles typos and alternative phrasings
* Adds semantic context that might be missing from the original query

While input enrichment introduces some latency, it significantly improves search quality.

Input enrichment is enabled by default. You can disable this feature if you want to preserve the user query for full text-search or if you want to reduce latency.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const results = await index.search({
    query: "space opera",
    inputEnrichment: false // faster but less enhanced results
  });
  ```

  ```python Python theme={"system"}
  results = index.search(
      query="space opera",
      input_enrichment=False  # faster but less enhanced results
  )
  ```
</CodeGroup>

### 2. Hybrid Vector Search

The second stage performs hybrid search by combining semantic search and full-text search:

* **Semantic Search**: Uses vector embeddings to understand meaning and context
* **Full-Text Search**: Performs traditional keyword matching
* **Result Combination**: Merges results using configurable weights

By default, Upstash Search uses a 75% semantic weight and 25% full-text weight. You can adjust this balance based on your use case:

* Higher semantic weight: Better for conceptual searches and finding related content
* Lower semantic weight: Better for exact keyword matching and technical queries

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const results = await index.search({
    query: "artificial intelligence concepts",
    semanticWeight: 0.9 // 90% semantic, 10% full-text
  });
  ```

  ```python Python theme={"system"}
  results = index.search(
      query="artificial intelligence concepts",
      semantic_weight=0.9  # 90% semantic, 10% full-text
  )
  ```
</CodeGroup>

### 3. Reranking

The final stage reranks the hybrid search results using AI models. Upstash Search offers two reranking options:

**Advanced Reranking (`reranking: true`)**

* Uses a powerful, state-of-the-art reranking model
* Provides the highest quality results
* Costs \$1 per 1K reranking operations
* Recommended for applications where search quality is critical

**Standard Reranking (`reranking: false`, default)**

* Uses a simpler, faster reranking model
* Still provides significant improvements over raw hybrid results
* No additional cost

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const results = await index.search({
    query: "complex technical documentation",
    reranking: true // uses premium reranking model
  });
  ```

  ```python Python theme={"system"}
  results = index.search(
      query="complex technical documentation",
      reranking=True  # uses premium reranking model
  )
  ```
</CodeGroup>

## Conclusion

This three-stage approach ensures that Upstash Search:

* **Understands Intent**: Input enrichment helps the system understand what users are really looking for
* **Finds Relevant Content**: Hybrid search captures both semantic meaning and exact keyword matches
* **Prioritizes Quality**: Reranking ensures the most relevant results appear first
* **Stays Flexible**: Each stage can be configured based on your specific needs

The result is a search system that works well across all kinds of content and domains, handling everything from precise technical queries to broad conceptual searches.


# Content and Metadata
Source: https://upstash.com/docs/search/features/content-and-metadata

How to use content and metadata fields in your documents

***

## Content

The `content` field contains the searchable data of your documents. This is what gets indexed and can be queried.

* **Required**: You must provide `content` when upserting documents
* **Format**: JSON object structure
* **Searchable**: All fields within content are indexed for search
* **Filterable**: Content fields can be used in filter queries

<Tabs>
  <Tab title="Python">
    ```py  theme={"system"}
    index.upsert(
      documents=[
        {
          "id": "star-wars",
          "content": { "text": "Star Wars is a sci-fi space opera."}
        }
      ]
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    await index.upsert([
      {
        id: "star-wars",
        content: { title: "Star Wars", genre: "sci-fi", category: "classic" }
      }
    ]);
    ```
  </Tab>
</Tabs>

***

## Metadata

The `metadata` field stores additional context about your documents that won't be indexed for search. This is useful for data you want to retrieve with your search results but don't need to search through.

* **Optional**: You can upsert documents without metadata
* **Format**: JSON object structure
* **Not Searchable**: Metadata fields are not indexed

<Tabs>
  <Tab title="Python">
    ```py  theme={"system"}
    index.upsert(
      documents=[
        {
          "id": "star-wars",
          "content": { "text": "Star Wars is a sci-fi space opera."},
          "metadata": {
            "genre": "sci-fi",
          }
        }
      ]
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    await index.upsert([
      {
        id: "star-wars",
        content: { title: "Star Wars", genre: "sci-fi", category: "classic" },
        metadata: { director: "George Lucas" } ,
      }
    ]);
    ```
  </Tab>
</Tabs>

***

## Best Practices

| Use Content When                                      | Use Metadata When                                    |
| ----------------------------------------------------- | ---------------------------------------------------- |
| Users need to search for this information             | Information is for display/reference only (e.g. IDs) |
| The field is important for finding relevant documents | The field provides context after finding documents   |
| You want to filter results by this field              | You need to track internal system information        |

***

## Examples & Common Patterns

1. E-commerce Products

```javascript  theme={"system"}
{
  // üëá searchable and filterable
  content: {
    name: "Wireless Headphones",
    description: "Noise-cancelling bluetooth headphones", 
    brand: "Sony",
    category: "Electronics"
  },
  // üëá not searchable, for reference only
  metadata: {
    sku: "AT-WH-001",
    warehouse_location: "A3-15",
    supplier_id: "SUP-123"
  }
}
```

2. Knowledge Base Articles

```javascript  theme={"system"}
{
  // üëá searchable and filterable
  content: {
    title: "How to Reset Your Password",
    body: "Follow these steps to reset your password...",
    tags: ["password", "security", "account"]
  },
  // üëá not searchable, for reference only
  metadata: {
    author_id: "usr_123",
    version: 3,
    approved_by: "usr_456",
    view_count: 1523
  }
}
```

3. News Articles

```javascript  theme={"system"}
{
  // üëá searchable and filterable
  content: {
    headline: "Tech Company Announces New Product",
    excerpt: "In a press conference today...",
    category: "Technology",
    keywords: ["innovation", "product launch"]
  },
  // üëá not searchable, for reference only
  metadata: {
    source_url: "https://news.example.com/article/123",
    syndication_rights: true,
    word_count: 200
  }
}
```


# Filtering
Source: https://upstash.com/docs/search/features/filtering



Search queries with filters only return documents which have the content or metadata matching with the filter.

Upstash Search allows you to filter by content and metadata keys which have the following value types:

* string
* number
* boolean
* object
* array

Filtering is implemented as a combination of in and post-filtering. Every query is assigned a filtering budget,
determining the number of candidate documents that can be compared against the filter during query execution. If this
budget is exceeded, the system fallbacks into post-filtering. Therefore, with highly selective filters, fewer
than `topK` documents may be returned.

***

## Filter Syntax

A filter has a syntax that resembles SQL, which consists of operators on content and metadata keys and boolean operators
to combine them.

To distinguish fields in content and metadata, metadata keys must be prefixed with
the `@metadata` identifier.

Assuming you have content like below:

```typescript  theme={"system"}
{
  // üëá searchable and filterable
  content: {
    name: "Wireless Headphones",
    description: "Noise-cancelling bluetooth headphones",
    brand: "Sony",
    category: "Electronics",
    warehouse_location: "A3-15",
    in_stock: 3
  },
  // üëá not searchable, but filterable
  metadata: {
    sku: "AT-WH-001",
    supplier_id: "SUP-123",
  }
}
```

Filter documents like so:

<Tabs>
  <Tab title="Python">
    ```py  theme={"system"}
    scores = index.search(
        query="sony headphones",
        filter="warehouse_location = 'A3-15' AND @metadata.supplier_id = 'SUP-123'",
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    const searchResults = await index.search({
        query: "sony headphones",
        filter: "warehouse_location = 'A3-15' AND @metadata.supplier_id = 'SUP-123'",
    });
    ```
  </Tab>
</Tabs>

### TypeSafe Filters (TypeScript)

In our [TypeScript SDK](https://github.com/upstash/search-js), we support a typesafe way to build filters:

```ts  theme={"system"}
import { Search } from "@upstash/search";

type IndexContent = {
  name: string;
  description: string;
  brand: string;
  category: string[];
  warehouse_location: string;
  in_stock: number;
};

const client = new Client({ ... });
const index = client.index<IndexContent>("products");

const searchResults = await index.search({
  query: "sony headphones",
  filter: { category: { contains: 'electronics' } },
});
```

<Note>
  Note that we passed `IndexContent` as a type parameter to the `index` method. This allows the SDK to infer the type of the content, enabling type-safe filters.
</Note>

You can use the `AND` and `OR` operators to build complex filters.

<CodeGroup>
  ```ts AND theme={"system"}
  const searchResults = await index.search({
    query: "sony headphones",
    filter: {
      AND: [
        { warehouse_location: { equals: 'A3-15' } },
        { in_stock: { greaterThan: 0 } }
      ]
    },
  });
  ```

  ```ts OR theme={"system"}
  const searchResults = await index.search({
    query: "sony headphones",
    filter: {
      OR: [
        { warehouse_location: { equals: 'A3-15' } },
        { in_stock: { greaterThan: 0 } }
      ]
    },
  });
  ```

  ```ts Nested AND/OR theme={"system"}
  const searchResults = await index.search({
    query: "sony headphones",
    filter: {
      AND: [
        { category: { contains: 'electronics' } },
        { OR: [
          { warehouse_location: { equals: 'A3-15' } },
          { in_stock: { greaterThan: 0 } }
        ]}
      ]
    },
  });
  ```
</CodeGroup>

All the operations below except for filtering array elements and nested objects are supported in the typesafe filters.

***

## Operators

#### Equals (=)

The `equals` operator filters content whose values are equal to the given literal.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
warehouse_location = 'A3-15' AND in_stock = 3
```

***

#### Not Equals (!=)

The `not equals` operator filters content whose values are not equal to the given literal.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
warehouse_location != 'A3-15' AND in_stock != 3
```

***

#### Less Than (\<)

The `less than` operator filters content whose values are less than the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
in_stock < 3
```

***

#### Less Than or Equals (\<=)

The `less than or equals` operator filters content whose values are less than or equal to the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
in_stock <= 3
```

***

#### Greater Than (>)

The `greater than` operator filters content whose values are greater than the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
in_stock > 3
```

***

#### Greater Than or Equals (>=)

The `greater than or equals` operator filters content whose values are greater than or equal to the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
in_stock >= 3
```

***

#### Glob

The `glob` operator filters content whose values match with the given UNIX glob pattern.

It is applicable to *string* values.

It is a case sensitive operator.

The glob operator supports the following wildcards:

* `*` matches zero or more characters.
* `?` matches exactly one character.
* `[]` matches one character from the list
  * `[abc]` matches either `a`, `b`, or `c`.
  * `[a-z]` matches one of the range of characters from `a` to `z`.
  * `[^abc]` matches any one character other than `a`, `b`, or `c`.
  * `[^a-z]` matches any one character other than `a` to `z`.

For example, the filter below would only match with warehouse locations whose first character is `A` or `B`.

```SQL  theme={"system"}
warehouse_location GLOB '[AB]*'
```

***

#### Not Glob

The `not glob` operator filters content whose values do not match with the given UNIX glob pattern.

It is applicable to *string* values.

It has the same properties with the glob operator.

For example, the filter below would only match with warehouse locations whose first character is anything other than `A`.

```SQL  theme={"system"}
warehouse_location NOT GLOB 'A*'
```

***

#### In

The `in` operator filters content whose values are equal to any of the given literals.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
country IN ('Germany', 'Turkey', 'France')
```

Semantically, it is equivalent to equals operator applied to all of the given literals with `OR` boolean operator in between:

```SQL  theme={"system"}
country = 'Germany' OR country = 'Turkey' OR country = 'France'
```

***

#### Not In

The `not in` operator filters content whose values are not equal to any of the given literals.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
economy.currency NOT IN ('USD', 'EUR')
```

Semantically, it is equivalent to not equals operator applied to all of the given literals with `AND` boolean operator in between:

```SQL  theme={"system"}
economy.currency != 'USD' AND economy.currency != 'EUR'
```

***

#### Contains

The `contains` operator filters content whose values contain the given literal.

It is applicable to *array* values.

```SQL  theme={"system"}
economy.major_industries CONTAINS 'Tourism'
```

***

#### Not Contains

The `not contains` operator filters content whose values do not contain the given literal.

It is applicable to *array* values.

```SQL  theme={"system"}
economy.major_industries NOT CONTAINS 'Steel Production'
```

***

#### Has Field

The `has field` operator filters content which have the given JSON field.

```SQL  theme={"system"}
HAS FIELD geography.coordinates
```

***

#### Has Not Field

The `has not field` operator filters content which do not have the given JSON field.

```SQL  theme={"system"}
HAS NOT FIELD geography.coordinates.longitude
```

***

### Boolean Operators

Operators above can be combined with `AND` and `OR` boolean operators to form
compound filters.

```SQL  theme={"system"}
country = 'Turkey' AND population > 10000000
```

Boolean operators can be grouped with parentheses to have higher precedence.

```SQL  theme={"system"}
country = 'Turkey' AND (population > 10000000 OR is_capital = false)
```

When no parentheses are provided in ambiguous filters, `AND` will have higher
precedence than `OR`. So, the filter

```SQL  theme={"system"}
country = 'Turkey' AND population > 10000000 OR is_capital = false
```

would be equivalent to

```SQL  theme={"system"}
(country = 'Turkey' AND population > 10000000) OR is_capital = false
```

***

### Filtering Nested Objects

It is possible to filter nested object fields by referencing them with the `.` accessor.

Nested fields can be at arbitrary depths, so more than one `.` accessor can be used
in the same identifier.

```SQL  theme={"system"}
economy.currency != 'USD' AND geography.coordinates.latitude >= 35.0
```

***

### Filtering Array Elements

Apart from the `CONTAINS` and `NOT CONTAINS` operators, individual array elements can also
be filtered by referencing them with the `[]` accessor by their indexes.

Indexing is zero based.

```SQL  theme={"system"}
economy.major_industries[0] = 'Tourism'
```

Also, it is possible to index from the back using the `#` character with negative values.
`#` can be thought as the number of elements in the array, so `[#-1]` would reference the
last element.

```SQL  theme={"system"}
economy.major_industries[#-1] = 'Finance'
```

***

### Miscellaneous

* Identifiers (the left side of the operators) should be of the form `[a-zA-Z_][a-zA-Z_0-9.[\]#-]*`. In simpler terms, they should
  start with characters from the English alphabet or `_`, and can continue with same characters plus numbers and other accessors
  like `.`, `[0]`, or `[#-1]`.
* The string literals (strings in the right side of the operators) can be either single or double quoted.
* Boolean literals are represented as `1` or `0`.
* The operators, boolean operators, and boolean literals are case insensitive.


# Indexes
Source: https://upstash.com/docs/search/features/indexes



Upstash Search allows you to partition a single database into multiple isolated indexes.
Each index acts as a self-contained subset of the database,
search and upsert requests are limited to one index.

***

## Using an Index

Indexes are created implicitly when an upsert operation is performed,
so there is no specific endpoint for creating an index.

For example, the code snippet below will create the index `foo` if it does not already exist,
upsert and search the document only on that index.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    index = client.index("foo")
    index.upsert( ... )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    const index = client.index("movies");
    await index.upsert( ... );
    ```
  </Tab>
</Tabs>

***

## Listing Indexes

Names of all the active indexes of a database can be listed as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    client.list_indexes()
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    await client.listIndexes()
    ```
  </Tab>
</Tabs>

***

## Deleting an Index

Leftover indexes can be deleted as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    client.delete_index("foo")
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    await client.index("foo").deleteIndex();
    ```
  </Tab>
</Tabs>


# Reranking
Source: https://upstash.com/docs/search/features/reranking



Upstash Search combines semantic and full text search results for maximum relevancy. Optionally, you can re-rank the returned documents using a state of the art model to further improve relevancy.

We provide this additional re-ranking as an opt-in setting because it requires more computational resources and is charged at \$1 per 1K re-ranked documents.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    scores = index.search(
        query="space opera",
        limit=2,
        reranking=True,
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    const searchResults = await index.search({
      query: "space opera",
      limit: 2,
      reranking: true,
    });
    ```
  </Tab>
</Tabs>


# FAQ
Source: https://upstash.com/docs/search/help/faq

Questions And Answers About Upstash Search

***

## Upload & Storage

**How can I upload a large dataset quickly?**

To upload large datasets efficiently, write a script that upserts documents in batches of 100.

**What is the maximum size or number of documents I can index?**

You can index an unlimited number of documents, though the entire database is capped at 50GB. Each document can contain up to 1,500 characters.

**How is storage calculated and charged?**

We charge based on the number of documents you store, not the storage size they take up.

***

## Search & Indexing

**Do you support full-text search?**

Yes, we support full-text search through special embedding models called sparse indexes that simulate full-text search capabilities within the vector space.

**What is the maximum number of search indexes I can create?**

You can create up to 10,000 indexes per database.

**How do I remove specific fields from an indexed document?**

You can simply upsert the same document without the unwanted fields. When you remove or rewrite records, their associated indexes are automatically removed if they are empty.

***

## Billing

**If I upload documents but don't perform searches, will I still be charged?**

Yes, you'll be charged for the number of documents you store, regardless of whether you perform searches on them.

**How are searches and document updates counted for billing?**

Both searches and document updates are counted as requests and charged at the same rate as document creation.

**If a single query returns multiple documents, how is that counted for billing?**

A query that returns multiple documents counts as a single request. If you enable reranking, you'll be charged based on the number of documents reranked, with pricing per 100-document units. For example, reranking 99 documents costs 1 unit, while reranking 101 documents costs 2 units.


# Docusaurus Integration
Source: https://upstash.com/docs/search/integrations/docusaurus

AI-powered search component for Docusaurus using Upstash Search.

## Features

* ü§ñ AI-powered search results based on your documentation
* üé® Modern and responsive UI
* üåú Dark/Light mode support

## Installation

To install the package, run:

```bash  theme={"system"}
npm install @upstash/docusaurus-theme-upstash-search
```

## Configuration

### Enabling the Searchbar

To enable the searchbar, add the following to your docusaurus config file:

```js  theme={"system"}
export default {
  themes: ['@upstash/docusaurus-theme-upstash-search'],
  // ...
  themeConfig: {
    // ...
    upstash: {
      upstashSearchRestUrl: "UPSTASH_SEARCH_REST_URL",
      upstashSearchReadOnlyRestToken: "UPSTASH_SEARCH_READ_ONLY_REST_TOKEN",
      upstashSearchIndexName: "UPSTASH_SEARCH_INDEX_NAME",
    },
  },
};
```

The default index name is `docusaurus`. You can override it by setting the `upstashSearchIndexName` option.

You can fetch your URL and read only token from [Upstash Console](https://console.upstash.com/search). **Make sure to use the read only token!**

If you do not have a search database yet, you can create one from [Upstash Console](https://console.upstash.com/search). Make sure to use Upstash generated embedding model.

## Indexing Your Documentation

### Setting Up Environment Variables

To index your documentation, create a `.env` file with the following environment variables:

```bash  theme={"system"}
UPSTASH_SEARCH_REST_URL=
UPSTASH_SEARCH_REST_TOKEN=
UPSTASH_SEARCH_INDEX_NAME=
DOCS_PATH=
```

You can fetch your URL and token from [Upstash Console](https://console.upstash.com/search). This time **do not use the read only token** since we are upserting data.

### Running the Indexing Script

After setting up your environment variables, run the indexing command:

```bash  theme={"system"}
npx index-docs-upstash
```

### Configuration Options

* **DOCS\_PATH**: The indexing script looks for documentation in the `docs` directory by default. You can specify a different path using the `DOCS_PATH` option.
* **UPSTASH\_SEARCH\_INDEX\_NAME**: The default index name is `docusaurus`. You can override it by setting the `UPSTASH_SEARCH_INDEX_NAME` option. Make sure the name you set while indexing matches with your themeConfig `upstashSearchIndexName` option.

For more details on how this integration works, check out [the official repository](https://github.com/upstash/docusaurus-theme-upstash-search).


# Getting Started
Source: https://upstash.com/docs/search/overall/getstarted

Creating an Upstash Search Database

***

<iframe
  id="intro-video"
  width="560"
  height="315"
  src="https://www.youtube.com/embed/xVwdHZEkdGI?rel=0&disablekb=1"
  title="YouTube video player"
  frameBorder="0"
  allow="accelerometer; fullscreen;
clipboard-write; encrypted-media; gyroscope"
  allowFullScreen
/>

***

## Quickstart

Check out our Next.js quickstart guide if you're working in Next.js.

<CardGroup cols={1}>
  <Card title="Next.js" icon="node-js" href="/search/tutorials/nextjs">
    Use Upstash Search in your Next.js app
  </Card>
</CardGroup>

***

## Create a Database

Create a Search Database by navigating to the `Search` tab and clicking on the `Create Database` button.

<Frame style={{ width: "600px" }}>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=444d1e8659a2c3cab5e5fb2c21624493" data-og-width="1386" width="1386" data-og-height="954" height="954" data-path="img/search/create-database.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=cbd5c9ff6334f7d87b8024801dac8a9a 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=a138fe038732de20a8a962eacae32aa7 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4a151b31323a1550c2beff7103675062 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=647a3a39947a8877b4517274bb8fc6e3 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=0cfc44b8083951429950321e094b9523 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/create-database.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=c45271227adeb4ee6847e2172970e5d8 2500w" />
</Frame>

A dialog with the following options will open:

* **Name:** Type a name for your database (e.g. "product-search").

* **Region:** Choose the region for your database. For best performance, select the region closest to your application.

  *We plan to support additional regions and cloud providers. Feel free to send your requests to [support@upstash.com](mailto:support@upstash.com).*

Once you're done, click `Next`, choose a plan, and your Database is ready:

<Frame style={{ width: "600px" }}>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=1f1c586699ca58c64c9d1359343ab858" data-og-width="1414" width="1414" data-og-height="955" height="955" data-path="img/search/database-created.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=259d73961bc8fe1df2d1122f1eb86957 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=58d9a349b254789548321c1701217823 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=68ef6e0dbbf48eee0dcb62eff21b9dd6 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=8d7c413e9667c529271c26470638a0ef 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=d1a389bc21e76440a65a55bb91eb2468 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/database-created.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=465a75e257f320f62820e757788bd0cd 2500w" />
</Frame>

***

## Add Documents

Add documents to your database using our REST API, our SDKs, or directly in the dashboard.

### 1. Add Documents via Dashboard

Navigate to the `Data Browser` section of your Database and click `Upsert Documents`:

<Frame style={{ width: "600px" }}>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e7f4bb618858c4428ebb0a64fc92dc64" data-og-width="1427" width="1427" data-og-height="955" height="955" data-path="img/search/add-data.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=366863b43df8a069ed93da3c98c57981 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=1c7bf6b0a7873a09017c7982cee01e51 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=ff22a719dd4c1b20c0779c206f48a02a 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=30ab7208cb32076409fe09f8f7a839a3 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=709abe6179ff6933d3b2769708b25654 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-data.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=2bcf922f5b1c20fd873b92967df5c349 2500w" />
</Frame>

A dialog with the following options will open:

<Frame style={{ width: "600px" }}>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=887b8edefbc6f605aa7ef500f7dddd0c" data-og-width="1409" width="1409" data-og-height="956" height="956" data-path="img/search/add-document.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=b82aded7279103796f4d7fa718e36854 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e6d427a3318cd0570ca8feb4fca99b0c 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=720b6a6ff21a15c1ccda33b4383256d2 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=213316c5c5317916e22dcd03fafb6224 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=78b5e24b36200412a3af864dc52bca70 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/add-document.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3bccf20c83ef927aea68a4ab2e06bb5a 2500w" />
</Frame>

* **Index:** An [index](/search/features/indexes) to group your data.

  *If you plan to query all documents in one place, you only need one index (e.g. "product-search"). If you plan to add multi-tenancy, so that each user can only search their own data, for example, you can create one index per user ("user-1", "user-2", etc.).*

* **ID:** An automatically generated ID.

* **Content:** The searchable data in JSON format.

* **Metadata:** Optional information attached to this document.

More information about content and metadata can be found [here](/search/features/content-and-metadata).

***

### 2. Add Documents via SDKs

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_search import Search

    client = Search(
        url="<UPSTASH_SEARCH_REST_URL>",
        token="<UPSTASH_SEARCH_REST_TOKEN>",
    )

    index = client.index("movies")

    index.upsert(
        documents=[
            {
                "id": "movie-0",
                "content": {
                    "title": "Star Wars",
                    "overview": "Sci-fi space opera",
                    "genre": "sci-fi",
                    "category": "classic",
                },
                "metadata": {
                    "poster": "https://poster.link/starwars.jpg",
                },
            },
        ],
    )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    import { Search } from "@upstash/search"

    const client = new Search({
      url: "<SEARCH_INDEX_REST_URL>",
      token: "<SEARCH_INDEX_REST_TOKEN>",
    })

    const index = client.index("movies")

    await index.upsert([
      {
        id: "star-wars",
        content: { title: "Star Wars", genre: "sci-fi", category: "classic" },
        metadata: { director: "George Lucas" },
      },
    ])
    ```
  </Tab>
</Tabs>

***

## Search Your Database

You can search across your Database the same way: using our REST API, our SDKs or directly in your dashboard.

### 1. Searching via Dashboard

To search your documents, enter a search term and click `Search`:

<Frame style={{ width: "600px" }}>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3575f960b55c3c9f222f8ae28cd4cb9f" data-og-width="1447" width="1447" data-og-height="959" height="959" data-path="img/search/first-search.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=c870db15d65177c1a82dc58b2e769421 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=e4155b2af47ca96071be03b0eeb47e29 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=3870ff148b64ae7691abeabfd683b310 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=0ab1ff39d53cf4d20e48b6ab0fb84a72 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=680e50d0f1b489587c5188dc3dae3b8c 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/first-search.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4c0118ec40f1c472a1b738968a736940 2500w" />
</Frame>

### 2. Searching Data via SDKs

<Tabs>
  <Tab title="Python">
    ```py  theme={"system"}
    scores = index.search( query="space opera", limit=2, )
    ```
  </Tab>

  <Tab title="TypeScript">
    ```ts  theme={"system"}
    const searchResults = await index.search({
      query: "space opera",
      limit: 2,
      reranking: true,
    });
    ```
  </Tab>
</Tabs>

***

**That's it!** üéâ You've just created your first serverless search database with Upstash Search!

But this is just the beginning. Upstash Search also supports:

* Advanced reranking
* Fine-grained control over search results
* Metadata-based filtering

We'll get into those features in the next sections of this documentation. For now, you've already mastered the basics!


# Pricing & Limits
Source: https://upstash.com/docs/search/overall/pricing



Please check our [pricing page](https://upstash.com/pricing/search) for the most up-to-date information on pricing and limits.


# What is Upstash Search?
Source: https://upstash.com/docs/search/overall/whatisupstashsearch

Lightweight, AI-powered search for developers

Upstash Search is a **simple, lightweight, and scalable way to add AI-powered search to your app**.

We combine full-text and semantic search for highly relevant results. Search works out of the box and scales to massive data sizes with zero infrastructure to manage.

***

## Lightweight & Efficient

Most search products (we'll avoid names here üíÄ) are bloated, complicated, and hard to manage. We're building Upstash search to be the exact opposite: fast to set up, easy to use and optimized for real-world use cases.

* Set up in minutes
* Plug-and-play AI search with smart defaults
* Optimized for speed and simplicity

***

## Fast, Relevant Results

We have a deep understanding of LLM technology through [Upstash Vector](/vector/overall/whatisvector) and hosting our own models at scale. We're now using that experience to make search feel truly intelligent. While most search products add AI to catch up, we're making it a core part of Upstash Search from the start.

* Combines semantic & full-text search for relevancy
* Understands user search intent
* Smart ranking shows the best matches first

***

## Scales Automatically

We've scaled [Upstash Redis](/redis/overall/getstarted) to serve billions of requests each day with extremely high availability. That same experience is built into Search, so you never have to think about infra.

We're building Search for modern, serverless stacks from the ground up. It's ready for any data size you throw at it.

* Perfect for serverless apps and modern frameworks like Next.js
* Scales to any data size (seriously, we've indexed the entire Wikipedia in 7 languages)
* No infrastructure, clusters or servers to manage

***

## Start using Upstash Search

Whether you're building a side project or scaling your company, Upstash Search gives you fast, smart, production-ready search with zero infra to manage. Try it today, it only takes a few minutes to [get started](/search/overall/getstarted)!


# Delete
Source: https://upstash.com/docs/search/sdks/py/commands/delete



## Delete Command for Python SDK

The delete method allows you to delete documents from your index using various criteria.

### Arguments

<ResponseField name="DeletePayload" type="object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="ids" type="string[] | number[] | string | number">
      One or more document IDs to delete.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      A string prefix to match document IDs for deletion. All documents with IDs starting with this prefix will be deleted.
    </ResponseField>

    <ResponseField name="filter" type="string">
      A [filter](/search/features/filtering) to delete documents based on content fields.

      <Warning>
        Deleting document with filter is a O(N) operation that performs a full
        scan. Therefore, it might be slow for large indexes.
      </Warning>
    </ResponseField>
  </Expandable>
</ResponseField>

### Response

<ResponseField name="Response" type="int" required>
  The number of documents that were successfully deleted.
</ResponseField>

<RequestExample>
  ```typescript Delete by IDs Array theme={"system"}
  index.delete(ids=["star-wars", "inception"]);
  ```

  ```typescript Delete by Prefix theme={"system"}
  index.delete(prefix="star-");
  ```

  ```typescript Delete with Filter theme={"system"}
  index.delete(filter="age > 30");
  ```
</RequestExample>


# Fetch
Source: https://upstash.com/docs/search/sdks/py/commands/fetch



## Fetch Command for Python SDK

Used to retrieve documents by their IDs.

### Arguments

<ResponseField name="FetchPayload" type="object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="ids" type="string[]">
      The IDs of the documents you want to fetch.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      An ID prefix to match document IDs.
    </ResponseField>
  </Expandable>
</ResponseField>

### Response

<ResponseField name="Documents" type="List[Document]" required>
  This field is `null` if no document with the specified ID is found.

  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting document.
    </ResponseField>

    <ResponseField name="content" type="Record<string, unknown>">
      The main content of the document.
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      Additional metadata for the document.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```python By ID theme={"system"}
  documents = index.fetch(ids=["movie-0", "movie-1"])
  print(documents)
  ```

  ```python ID Prefix theme={"system"}
  documents = index.fetch(prefix=["movie-"])
  print(documents)
  ```
</RequestExample>


# Info
Source: https://upstash.com/docs/search/sdks/py/commands/info



## Info Command for Python SDK

Used to retrieve the stats of an index.

### Response

<ResponseField name="document_count" type="int" required>
  The total number of documents in the database, that are ready to use.
</ResponseField>

<ResponseField name="pending_document_count" type="int" required>
  The number of documents in the database, that are still processing and not ready to use.
</ResponseField>

<ResponseField name="disk_size" type="int" required>
  Size of the database in bytes.
</ResponseField>

<ResponseField name="indexes" required>
  Doctionary of index names and their information (`document_count` and `pending_document_count`)
</ResponseField>

<RequestExample>
  ```python  theme={"system"}
  from upstash_search import Search

  client = Search(
      url="<UPSTASH_SEARCH_REST_URL>",
      token="<UPSTASH_SEARCH_REST_TOKEN>",
  )

  info = client.info()
  print(info)
  ```
</RequestExample>


# Range
Source: https://upstash.com/docs/search/sdks/py/commands/range



## Range Command for Python SDK

The range method is used to retrieve documents in chunks with pagination.

### Arguments

<ResponseField name="Payload" type="dict" required>
  <Expandable defaultOpen="true">
    <ResponseField name="cursor" type="string" required>
      The cursor to the last retrieved document. Should be set to `""` in the initial range request.
    </ResponseField>

    <ResponseField name="limit" type="int" required>
      The number of maximum documents wanted in the response of range. (page size)
    </ResponseField>
  </Expandable>
</ResponseField>

### Response

<ResponseField name="Response" type="dict" required>
  <Expandable defaultOpen="true">
    <ResponseField name="Documents" type="List[Document]" required>
      This field is `null` if no document with the specified ID is found.

      <Expandable defaultOpen="true">
        <ResponseField name="id" type="string | number" required>
          The ID of the resulting document.
        </ResponseField>

        <ResponseField name="content" type="Record<string, unknown>">
          The main content of the document.
        </ResponseField>

        <ResponseField name="metadata" type="Record<string, unknown>">
          Additional metadata for the document.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="next_cursor" type="string">
      The cursor for the next page of documents.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```python  theme={"system"}
  range_documents = index.range(cursor="", limit=1)
  print(range_documents.documents)

  range_documents = index.range(
      cursor=range_documents.next_cursor,
      limit=3
  )
  print(range_documents.documents)
  ```
</RequestExample>


# Reset
Source: https://upstash.com/docs/search/sdks/py/commands/reset



## Reset Command for Python SDK

The `reset` method allows you to clear all documents from a particular index.

### Response

<ResponseField name="Response" type="string" required>
  `'Success'` if the database is successfully reset.
</ResponseField>

<RequestExample>
  ```python  theme={"system"}
  from upstash_search import Search

  client = Search(
      url="<UPSTASH_SEARCH_REST_URL>",
      token="<UPSTASH_SEARCH_REST_TOKEN>",
  )

  index = client.index("movies")
  index.reset()
  ```
</RequestExample>


# Search
Source: https://upstash.com/docs/search/sdks/py/commands/search



## Search Command for Python SDK

The search method is designed to retrieve the most relevant documents from the database, using AI-powered search capabilities.

For more details on how the search algorithm works, please refer to our [advanced settings documentation](/search/features/advanced-settings).

### Arguments

<ResponseField name="Payload" type="dict" required>
  <Expandable defaultOpen="true">
    <ResponseField name="query" type="string" required>
      The search query string.
    </ResponseField>

    <ResponseField name="limit" type="int" required>
      The maximum number of results to return. Defaults to 10.
    </ResponseField>

    <ResponseField name="reranking" type="bool">
      Whether to enable AI-powered reranking of results. Disabled by default.
    </ResponseField>

    <ResponseField name="filter" type="string">
      A [filter](/search/features/filtering) for narrowing down the search results based on content fields.
    </ResponseField>

    <ResponseField name="semantic_weight" type="number">
      Optional relevance balance between semantic and keyword search (0-1 range, defaults to 0.75).
      For instance, 0.2 applies 20% semantic matching with 80% full-text matching.
      You can learn more about how Upstash Search works from [our docs](/search/features/algorithm).
    </ResponseField>

    <ResponseField name="input_enrichment" type="boolean">
      Optional boolean to enhance queries before searching (enabled by default).
    </ResponseField>
  </Expandable>
</ResponseField>

### Response

<ResponseField name="Documents" type="List[DocumentScore]" required>
  This field is `null` if no document with the specified ID is found.

  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting document.
    </ResponseField>

    <ResponseField name="content" type="Record<string, unknown>">
      The main content of the document.
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      Additional metadata for the document.
    </ResponseField>

    <ResponseField name="score" type="float" required>
      Similarity score of the document
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```python Basic Search theme={"system"}
  results = index.search(
      query="space opera",
      limit=2
  )
  print(results)
  ```

  ```python Search with Reranking theme={"system"}
  results = index.search(
      query="space opera",
      limit=2,
      reranking=True
  )
  print(results)
  ```

  ```python Search with Filter theme={"system"}
  results = index.search(
      query="space", 
      limit=2, 
      filter="category = 'classic'"
  )
  print(results)
  ```
</RequestExample>


# Upsert
Source: https://upstash.com/docs/search/sdks/py/commands/upsert



## Upsert Command for Python SDK

Used to add new documents or update an existing document.

### Arguments

<ResponseField name="Documents" type="List[Document]" required>
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | int" required>
      The unique identifier for the document.
    </ResponseField>

    <ResponseField name="content" type="dict" required>
      The main content of the document.
    </ResponseField>

    <ResponseField name="metadata" type="dict">
      Additional metadata for the document.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```python  theme={"system"}
  from upstash_search import Search

  client = Search(
      url="<UPSTASH_SEARCH_REST_URL>",
      token="<UPSTASH_SEARCH_REST_TOKEN>",
  )

  index = client.index("movies")

  index.upsert(
      documents=[
          {
              "id": "movie-0",
              "content": {
                  "title": "Star Wars",
                  "overview": "Sci-fi space opera",
                  "genre": "sci-fi",
                  "category": "classic",
              },
              "metadata": {
                  "poster": "https://poster.link/starwars.jpg",
              },
          },
      ],
  )
  ```
</RequestExample>


# Getting Started
Source: https://upstash.com/docs/search/sdks/py/gettingstarted



`upstash-search` is a Python SDK for Upstash AI Search, enabling easier operations on Search Databases.

Using `upstash-search` you can:

* Perform AI-powered search queries with or without reranking.
* Upsert documents with metadata to an index.
* Fetch documents by their IDs.
* Delete documents from a database.
* Access database stats.
* Reset everything related to a database.

You can find the GitHub Repository [here](https://github.com/upstash/search-py).

## Install

```bash  theme={"system"}
pip install upstash-search
```

## Usage

### Initializing the client

There are two pieces of configuration required to use the Upstash search client: a REST token and REST URL. These values can be passed using environment variables or in code through a configuration object. Find your configuration values in [the console dashboard](https://console.upstash.com/search).

#### Using environment variables

The environment variables used to configure the client are the following. You can follow [this guide](/search/overall/getstarted) to retrieve credentials.

```bash  theme={"system"}
UPSTASH_SEARCH_REST_URL="your_rest_url"
UPSTASH_SEARCH_REST_TOKEN="your_rest_token"
```

When these environment variables are set, the client constructor does not require any additional arguments.

```python  theme={"system"}
from upstash_search import Search

client = Search.from_env()
```

#### Using a configuration object

If you prefer to pass configuration in code, the constructor accepts a config object containing the `url` and `token` values. This
could be useful if your application needs to interact with multiple databases, each with a different configuration.

```python  theme={"system"}
from upstash_search import Search

client = Search(
    url="<SEARCH_INDEX_REST_URL>",
    token="<SEARCH_INDEX_REST_TOKEN>",
)
```

***

### Using an Index

The `Search` client is for operations that are about manipulating the Search database. With it, you can create indexes which is where you can upsert and search documents.

```python  theme={"system"}
index = client.index("films")

index.upsert(
    documents=[
        {
            "id": "movie-0",
            "content": {
                "title": "Star Wars",
                "overview": "Sci-fi space opera",
                "genre": "sci-fi",
                "category": "classic",
            },
            "metadata": {
                "poster": "https://poster.link/starwars.jpg",
            },
        },
    ],
)
```

## Telemetry

This sdk sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Cloudflare, AWS or Vercel)
* Runtime version (python\@vX)

You can opt out using the allow\_telemetry flag when creating the client:

```ts  theme={"system"}
client = Search(
    url="UPSTASH_SEARCH_REST_URL",
    token="UPSTASH_SEARCH_REST_TOKEN",
    allow_telemetry=False,
)
```


# Delete
Source: https://upstash.com/docs/search/sdks/ts/commands/delete



The delete method allows you to delete documents from your index using various criteria. You can delete documents by their IDs, by ID prefix or with metadata filter.

## Arguments

<ResponseField name="IDs" type="string[] | number[] | string | number" required>
  One or more document IDs to delete.
</ResponseField>

**OR**

<ResponseField name="DeletePayload" type="object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="ids" type="string[] | number[] | string | number">
      One or more document IDs to delete.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      A string prefix to match document IDs for deletion. All documents with IDs starting with this prefix will be deleted.
    </ResponseField>

    <ResponseField name="filter" type="string">
      A [filter](/search/features/filtering) to delete documents based on content fields.

      <Warning>
        Deleting document with filter is a O(N) operation that performs a full
        scan. Therefore, it might be slow for large indexes.
      </Warning>
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="Response" type="DeleteResult" required>
  <Expandable defaultOpen="true">
    <ResponseField name="deleted" type="number" required>
      The number of documents that were successfully deleted.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Delete by IDs Array theme={"system"}
  const response = await index.delete(["star-wars", "inception"]);
  // { deleted: 2 }
  ```

  ```typescript Delete Single ID theme={"system"}
  const response = await index.delete("star-wars");
  // { deleted: 1 }
  ```

  ```typescript Delete by Prefix theme={"system"}
  const response = await index.delete({
    prefix: "star-",
  });
  // { deleted: 3 }
  ```

  ```typescript Delete with Filter theme={"system"}
  const response = await index.delete({
    filter: "age > 30",
  });
  // { deleted: 3 }
  ```
</RequestExample>


# Fetch
Source: https://upstash.com/docs/search/sdks/ts/commands/fetch



Used to retrieve documents by their IDs.

## Arguments

<ResponseField name="IDs" type="string[] | number[]" required>
  The IDs of the documents you want to fetch.
</ResponseField>

**OR**

<ResponseField name="FetchPayload" type="object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="ids" type="string[] | number[]">
      The IDs of the documents you want to fetch.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      An ID prefix to match document IDs.
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="FetchResult[]" type="Document[]" required>
  This field is `null` if no document with the specified ID is found.

  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting document.
    </ResponseField>

    <ResponseField name="content" type="Record<string, unknown>" />

    <ResponseField name="metadata" type="Record<string, unknown>" />
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic theme={"system"}
  await index.fetch({ ids: ["star-wars", "inception"] });
  /*
  [
    {
      id: "star-wars",
      content: { ... },
      metadata: { ... }
    },
    {
      id: "inception",
      content: { ... },
      metadata: { ... }
    }
  ]
  */
  ```

  ```typescript ID prefix theme={"system"}
  await index.fetch({ prefix: "star-" });
  /*
  [
    {
      id: "star-wars"
      content: { ... },
      metadata: { ... }
    },
    {
      id: "star-trek",
      content: { ... },
      metadata: { ... }
    }
  ]
  */
  ```
</RequestExample>


# Info
Source: https://upstash.com/docs/search/sdks/ts/commands/info



When it comes to info requests, there are two alternatives. One for index level and one for database level.

## Index Info

Used to retrieve the stats of an index.

### Response

<ResponseField name="documentCount" type="number" required>
  The total number of documents in the database, that are ready to use.
</ResponseField>

<ResponseField name="pendingDocumentCount" type="number" required>
  The number of documents in the database, that are still processing and not ready to use.
</ResponseField>

## Database Info

Alternatively, you can call `info` on the client itself, which will return information about the whole database:

### Response

<ResponseField name="documentCount" type="number" required>
  The total number of documents in the database, that are ready to use.
</ResponseField>

<ResponseField name="pendingDocumentCount" type="number" required>
  The number of documents in the database, that is still processing and not ready to
  use.
</ResponseField>

<ResponseField name="diskSize" type="number" required>
  The size of the database, in `b`.
</ResponseField>

<ResponseField name="indexes" type="Record<string, Object>" required>
  A map of indexes to their information in the following format

  <Expandable defaultOpen="true">
    <ResponseField name="documentCount" type="number" required>
      The total number of documents in the index, that are ready to use.
    </ResponseField>

    <ResponseField name="pendingDocumentCount" type="number" required>
      The number of documents in the index, that is still processing and not ready to
      use.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Index theme={"system"}
  const client = new Search();
  const index = client.index("movies");

  const infoResponse = await index.info();
  /*
  { 
    documentCount: 100,
    pendingDocumentCount: 5,
  }
  */
  ```

  ```typescript Database theme={"system"}
  const client = new Search();

  const infoResponse = await client.info();
  /*
  {
    diskSize: 456890
    pendingDocumentCount: 12,
    documentCount: 120,
    indexes: {
      "movies": {
        documentCount: 100,
        pendingDocumentCount: 5
      },
      "actors": {
        documentCount: 20,
        pendingDocumentCount: 7
      }
    }
  }
  */
  ```
</RequestExample>


# Range
Source: https://upstash.com/docs/search/sdks/ts/commands/range



The range method is used to retrieve documents in chunks with pagination. This method supports a variety of options to configure the query to your needs.

<Note>
  The range command is stateless, meaning you need to pass all of the parameters in each subsequent request.
</Note>

## Arguments

<ParamField body="cursor" type="string" required>
  The cursor to the last retrieved document. Should be set to `0` in the initial range request.
</ParamField>

<ParamField body="prefix" type="string">
  A string prefix to match document IDs. All documents with IDs that start with this prefix will be retrieved.
</ParamField>

<ParamField body="limit" type="number" required>
  The number of maximum documents wanted in the response of range. (page size)
</ParamField>

## Response

<ResponseField name="RangeResponse" type="Object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="nextCursor" type="string">
      The cursor for the next set of documents. When it becomes "", it means all documents were retrieved.
    </ResponseField>

    <ResponseField name="documents" type="Document[]">
      The list of documents retrieved in this range.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic theme={"system"}
  const responseRange = await index.range({
    cursor: "0",
    limit: 2,
  });

  /*
  {
    nextCursor: '2',
    documents: [
      { id: "doc1", content: { ... }, metadata: { ... } },
      { id: "doc2", content: { ... }, metadata: { ... } }
    ]
  }
  */
  ```

  ```typescript ID prefix theme={"system"}
  const responseRange = await index.range({
    cursor: "0",
    limit: 2,
    prefix: "test-",
  });

  /*
  {
    nextCursor: '2',
    documents: [
      { id: "test-1", content: { ... }, metadata: { ... } },
      { id: "test-2", content: { ... }, metadata: { ... } }
    ]
  }
  */
  ```
</RequestExample>


# Reset
Source: https://upstash.com/docs/search/sdks/ts/commands/reset



The `reset` method allows you to clear all documents from a particular index.

## Response

`'Success'` if the database is successfully reset.

<RequestExample>
  ```typescript Basic theme={"system"}
  const responseReset = await index.reset();
  // 'Success'
  ```
</RequestExample>


# Search
Source: https://upstash.com/docs/search/sdks/ts/commands/search



The search method is designed to retrieve the most relevant documents from the database, using AI-powered search capabilities. This method supports a variety of options to configure the query to your needs.

For more details on how the search algorithm works, please refer to our [advanced settings documentation](/search/features/advanced-settings).

<Note>
  The score returned from search requests is a normalized value between 0 and 1, where 1 indicates the highest relevance and 0 the lowest.
</Note>

## Arguments

<ResponseField name="Payload" type="SearchCommandPayload" required>
  <Expandable defaultOpen="true">
    <ResponseField name="query" type="string" required>
      The search query string.
    </ResponseField>

    <ResponseField name="limit" type="number" required>
      The maximum number of results to return. Defaults to 5.
    </ResponseField>

    <ResponseField name="reranking" type="boolean">
      Whether to enable AI-powered reranking of results. Disabled by default.
    </ResponseField>

    <ResponseField name="filter" type="string">
      A [filter](/search/features/filtering) for narrowing down the search results based on content fields.
      See [typesafe filtering section](/search/features/filtering#typesafe-filters-typescript) for advanced usage.
    </ResponseField>

    <ResponseField name="semanticWeight" type="number">
      Optional relevance balance between semantic and keyword search (0-1 range, defaults to 0.75).
      For instance, 0.2 applies 20% semantic matching with 80% full-text matching.
      You can learn more about how Upstash Search works from [our docs](/search/features/algorithm).
    </ResponseField>

    <ResponseField name="inputEnrichment" type="boolean">
      Optional boolean to enhance queries before searching (enabled by default).
    </ResponseField>

    <ResponseField name="keepOriginalQueryAfterEnrichment" type="boolean">
      Optional boolean to keep the original query alongside the enriched one (false by default).
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="Response" type="SearchResult" required>
  <Expandable defaultOpen="true">
    <ResponseField name="results" type="Document[]">
      The list of documents matching the search query.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic Search theme={"system"}
  const searchResults = await index.search({
    query: "space opera",
    limit: 2,
  });
  console.log(searchResults);
  ```

  ```typescript Search with Reranking theme={"system"}
  const searchResults = await index.search({
    query: "space opera",
    limit: 2,
    reranking: true,
  });
  console.log(searchResults);
  ```

  ```typescript Search with Filter theme={"system"}
  const searchResults = await index.search({
    query: "space",
    limit: 2,
    filter: "category = 'classic'",
  });
  console.log(searchResults);
  ```
</RequestExample>


# Upsert
Source: https://upstash.com/docs/search/sdks/ts/commands/upsert



Used to add new documents or update an existing document.

<Note>
  You can only upsert documents with the same structure as defined in your database.
</Note>

## Arguments

<ResponseField name="DocumentPayload" type="Document | Document[]" required>
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required />

    <ResponseField name="content" type="Record<string, unknown>" />

    <ResponseField name="metadata" type="Record<string, unknown>" />
  </Expandable>
</ResponseField>

## Response

<ResponseField type="str" required>
  `'Success'` on successful operation.
</ResponseField>

<RequestExample>
  ```typescript Single Document theme={"system"}
  await index.upsert({
    id: "star-wars",
    content: { title: "Star Wars", genre: "sci-fi" },
    metadata: { year: 1977 }
  });
  ```

  ```typescript Multiple Documents theme={"system"}
  await index.upsert([
    {
      id: "inception",
      content: { title: "Inception", genre: "action" }
      metadata: {
        year: 2010,
      },
    },
    { ... },
  ]);
  ```

  ```typescript Update Document theme={"system"}
  await index.upsert({
    id: "star-wars",
    content: {
      title: "Star Wars: Episode IV - A New Hope",
      genre: "sci-fi"
    },
  });
  ```
</RequestExample>


# Contributing
Source: https://upstash.com/docs/search/sdks/ts/contributing



## Preparing the environment

This project uses [Bun](https://bun.sh/) for packaging and dependency management. Make sure you have the relevant dependencies.

```commandline  theme={"system"}
curl -fsSL https://bun.sh/install | bash
```

You will also need a search database on [Upstash](https://console.upstash.com/search).

***

## Code Formatting

Run the following command to format code:

```bash  theme={"system"}
bun run fmt
```

***

## Running tests

To run all the tests, make sure you have the relevant environment variables.

```bash  theme={"system"}
bun run test
```


# Getting Started
Source: https://upstash.com/docs/search/sdks/ts/getting-started



`@upstash/search` is a TypeScript SDK for Upstash AI Search.

Using `@upstash/search` you can:

* Perform AI-powered search queries
* Upsert documents to an index
* Fetch documents by their IDs
* Delete documents from a database
* Access database stats
* Reset databases

You can find the GitHub Repository [here](https://github.com/upstash/search-js).

***

## Installation

<CodeGroup>
  ```bash npm theme={"system"}
  npm install @upstash/search
  ```

  ```bash yarn theme={"system"}
  yarn add @upstash/search
  ```

  ```bash pnpm theme={"system"}
  pnpm add @upstash/search
  ```

  ```bash bun theme={"system"}
  bun install @upstash/search
  ```
</CodeGroup>

***

## Usage

### Initializing the client

There are two pieces of configuration required to use the Upstash search client:

* a REST token
* a REST URL

These values can be passed using environment variables or through a configuration object. Find these connection details in [the console dashboard](https://console.upstash.com/search).

***

#### Using environment variables (recommended)

You can follow [this guide](/search/overall/getstarted) to retrieve the following credentials.

```bash  theme={"system"}
UPSTASH_SEARCH_REST_URL="your_rest_url"
UPSTASH_SEARCH_REST_TOKEN="your_rest_token"
```

When these environment variables are set, the client constructor does not require any additional arguments.

```typescript  theme={"system"}
import { Search } from "@upstash/search";

const client = Search.fromEnv();
const index = client.index("movies")
```

***

#### Using a configuration object

The `Search` class accepts a config object containing the `url` and `token` values. This
could be useful if your application needs to interact with multiple databases, each with a different configuration.

```typescript  theme={"system"}
import { Search } from "@upstash/search";

const client = new Search({
  url: "<SEARCH_INDEX_REST_URL>",
  token: "<SEARCH_INDEX_REST_TOKEN>",
});

const index = client.index("movies")
```

***

#### Typescript

The Search SDK supports defining your content and metadata types at the index level for complete type-safety.

```typescript {4,5,6} theme={"system"}
import { Search } from "@upstash/search";
const client = new Search();

type Content = { title: string, genre: string };
type Metadata = { year: number };
const index = client.index<Content, Metadata>("movies");

await index.upsert({
  id: "document-id",
  content: { title: "Star Wars", genre: "sci-fi" },
  metadata: { year: 1977 }
})
```

Passing a `Content` type at the index level will provide type safety for the content coming back from or required for the following commands:

* `search`
* `upsert`
* `fetch`
* `range`

In cases you don't want to define a content type at the index level, you can override the index level type definition for a specific command:

```typescript  theme={"system"}
const results = await index.upsert<Content>({
  id: "id",
  content: { title: "Movie title", ... }
});
```

## Telemetry

This sdk sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Cloudflare, AWS or Vercel)
* Runtime version ([node@18.x](mailto:node@18.x))

You can opt out by setting the `UPSTASH_DISABLE_TELEMETRY` environment variable
to any truthy value.

```sh  theme={"system"}
UPSTASH_DISABLE_TELEMETRY=1
```

Alternatively, you can disable telemetry programmatically:

```ts  theme={"system"}
const index = client.index("movies", {
  enableTelemetry: false,
});
```


# Database Migrator
Source: https://upstash.com/docs/search/tools/databasemigrator

a CLI tool to migrate your data to Upstash Search

## Introduction

This tool helps you to migrate your data from other service providers (e.g. Algolia, Meilisearch)
to your Upstash Search Database.

### Migrate Using npx

The command below prompts you to provide credentials for the indexes that you want to do the migration between.

```sh  theme={"system"}
npx @upstash/search-migrator
```

### Using Flags

You can also provide your credentials and other information as command-line flags.
Here are some examples:

#### Algolia to Upstash

```sh  theme={"system"}
npx @upstash/search-migrator \
  --upstash-url "UPSTASH_SEARCH_REST_URL" \
  --upstash-token "UPSTASH_SEARCH_REST_TOKEN" \
  --algolia-app-id "YOUR_ALGOLIA_APP_ID" \
  --algolia-api-key "YOUR_ALGOLIA_WRITE_API_KEY"
```

#### Meilisearch to Upstash

```sh  theme={"system"}
npx @upstash/search-migrator \
  --upstash-url "UPSTASH_SEARCH_REST_URL" \
  --upstash-token "UPSTASH_SEARCH_REST_TOKEN" \
  --meilisearch-host "YOUR_MEILISEARCH_HOST" \
  --meilisearch-api-key "YOUR_MEILISEARCH_API_KEY"
```

## Obtaining Credentials

### Upstash

1. Go to your [Upstash Console](https://console.upstash.com/).
2. Select your Search Database.
3. Under the **Details** section, you will find your `UPSTASH_SEARCH_REST_URL` and `UPSTASH_SEARCH_REST_TOKEN`.
   * `--upstash-url` corresponds to `UPSTASH_SEARCH_REST_URL`.
   * `--upstash-token` corresponds to `UPSTASH_SEARCH_REST_TOKEN`.

* You may want to check out
  [@upstash/search-migrator](https://www.npmjs.com/package/@upstash/search-migrator)
  to see how to find credentials for other service providers

## Migration Process

The migrator will:

1. **Connect** to your source database (Algolia or Meilisearch)
2. **Fetch** all documents from the specified index
3. **Transform** the data to match Upstash Search's format
4. **Upload** the documents to your Upstash Search database
5. **Verify** the migration by comparing document counts

### Data Transformation

The migrator automatically handles the transformation of your data:

* **Document IDs**: Preserved from the source
* **Content**: Mapped to Upstash Search's content field
* **Metadata**: Preserved as metadata in Upstash Search
* **Searchable fields**: All fields become searchable by default

<Note>
  For free tier, 10000 documents can be upserted daily,
  so a database migration with more than 10000 entries could
  be interrupted.
</Note>

### Getting Help

If you encounter any issues during migration:

1. Check the error messages for specific details
2. Verify your credentials are correct
3. Ensure your source database is accessible
4. Contact support at [support@upstash.com](mailto:support@upstash.com)

## Final Remarks

If you've come to this point without any issues, congratulations! you may resume your work
with upstash search, an advanced, developer frinedly search product.

For further insights, please visit [@upstash/search-migrator](https://www.npmjs.com/package/@upstash/search-migrator)


# Documentation Crawler
Source: https://upstash.com/docs/search/tools/documentationcrawler

A tool to crawl docs and feed Upstash Search database

## Introduction

This tool helps you crawl documentation websites incrementally, extract their content, and create a search index in Upstash Search.

## Usage

It is available both as a CLI tool and a library.

### CLI Usage

You can run the CLI directly using `npx` (no installation required):

```sh  theme={"system"}
npx @upstash/search-crawler
```

Or with command-line options:

```sh  theme={"system"}
npx @upstash/search-crawler \
  --upstash-url "UPSTASH_SEARCH_REST_URL" \
  --upstash-token "UPSTASH_SEARCH_REST_TOKEN" \
  --index-name "my-index" \
  --doc-url "https://example.com/docs"
```

You will be prompted for any missing options:

* Your Upstash Search URL
* Your Upstash Search token
* (Optional) Custom index name
* The documentation URL to crawl

#### What the Tool Does

1. **Discover** all internal documentation links
2. **Crawl** each page and extract content
3. **Track** new or obsolete data
4. **Upsert** the new records into your Upstash Search index

### Library Usage

You can also use this as a library in your own code:

```typescript  theme={"system"}
import {
  crawlAndIndex,
  type CrawlerOptions,
  type CrawlerResult,
} from "@upstash/search-crawler";

const options: CrawlerOptions = {
  upstashUrl: "UPSTASH_SEARCH_REST_URL",
  upstashToken: "UPSTASH_SEARCH_REST_TOKEN",
  indexName: "my-docs",
  docUrl: "https://example.com/docs",
  silent: true, // no console output
};

const result: CrawlerResult = await crawlAndIndex(options);
```

## Obtaining Upstash Credentials

1. Go to your [Upstash Console](https://console.upstash.com/).
2. Select your Search index. (See [How to Create Search Index](/search/overall/getstarted#create-a-database))
3. Under the **Details** section, copy your `UPSTASH_SEARCH_REST_URL` and `UPSTASH_SEARCH_REST_TOKEN`.
   * `--upstash-url` corresponds to `UPSTASH_SEARCH_REST_URL`
   * `--upstash-token` corresponds to `UPSTASH_SEARCH_REST_TOKEN`

## Further Reading

Try combining this tool with [Qstash Schedule](/qstash/features/schedules) to keep your database up to date with docs. You may deploy your crawler on a server and call it on a schedule regularly to fetch updates in your docs. Check out our example project for implementation details: [A modern documentation library to search and track the docs.](https://github.com/upstash/search-js/tree/main/examples/search-docs)

For further insights, see [@upstash/search-crawler](https://github.com/upstash/search-crawler)


# Docs Search Quickstart
Source: https://upstash.com/docs/search/tutorials/buildsearchbar

Add Upstash Search to your website in minutes

***

## Introduction

Upstash Search makes it easy to add a fast, ready-to-use search bar to
your docs site, no complex setup needed. In this tutorial, you‚Äôll learn
how to quickly integrate a modern search experience that helps your users
find what they need. With just a few tweaks, you can use this solution in
any project and deliver great search lightning fast.

***

### 1. Project Setup

First, create an Upstash Search Database
if you don't already have one ([Getting Started guide](/search/overall/getstarted))
and then create a new Next.js application and install the related packages:

```shell  theme={"system"}
npx create-next-app@latest search-docs-app
cd search-docs-app
npm install @upstash/search @upstash/search-ui lucide-react
```

***

### 2. Add Environment Variables

Find the environment variables from your database dashboard and add them to your `.env` file:

```bash  theme={"system"}
NEXT_PUBLIC_UPSTASH_SEARCH_URL=<YOUR_SEARCH_REST_URL>
NEXT_PUBLIC_UPSTASH_SEARCH_READONLY_TOKEN=<YOUR_SEARCH_READONLY_TOKEN>
```

***

### 3. Create the Component

Create the [search component](https://github.com/upstash/search-ui) in `app/components/search-bar.tsx`:

```typescript title="app/components/search-bar.tsx" theme={"system"}
"use client"

import { SearchBar } from "@upstash/search-ui"
import "@upstash/search-ui/dist/index.css"
import { Search } from "@upstash/search"
import { FileText } from "lucide-react"

const client = new Search({
  url: process.env.NEXT_PUBLIC_UPSTASH_SEARCH_URL! ,
  token: process.env.NEXT_PUBLIC_UPSTASH_SEARCH_READONLY_TOKEN!,
})
// üëá your search index name
const index = client.index<{ title: string }>("default")

export default function SearchComponent() {
  return (
    <div className="max-w-sm mt-24 mx-auto">
      <SearchBar.Dialog>
        <SearchBar.DialogTrigger placeholder="Search..." />

        <SearchBar.DialogContent>
          <SearchBar.Input placeholder="Type to search..." />
          <SearchBar.Results
            searchFn={(query) => {
              // üëá 100% type-safe: whatever you return here is
              // automatically typed as `result` below
              return index.search({ query, limit: 10, reranking: true })
            }}
          >
            {(result) => (
                <div key={result.id} onClick={() => {
                   window.open(result.metadata?.url as string, "_blank")
                 }}>
               <SearchBar.Result 
                 value={result.id} 
                 className="cursor-pointer hover:bg-gray-50 transition-colors duration-200"
               >
                <SearchBar.ResultIcon>
                    <FileText className="text-gray-600" />
                </SearchBar.ResultIcon>

                <SearchBar.ResultContent>
                  <SearchBar.ResultTitle>
                    {result.content.title}
                  </SearchBar.ResultTitle>
                  <p className="text-xs text-gray-500 mt-0.5">Docs</p>
                </SearchBar.ResultContent>
              </SearchBar.Result>
              </div>
            )}
          </SearchBar.Results>
        </SearchBar.DialogContent>
      </SearchBar.Dialog>
    </div>
  )
}
```

***

### 4. Crawl Docs to Feed the Component

Call [`npx @upstash/search-crawler`](https://github.com/upstash/search-crawler)
in your command line and follow the CLI, you will be prompted to provide:

* Upstash Search URL (as set in your environment variables)
* Upstash Search Rest Token (as set in your environment variables)
* Upstash Search Index Name (Go for `default` for convenience)
* Docs URL to crawl (Let's go for `https://upstash.com/docs`)

<Note>
  If you prefer not to choose `default` index name,
  don't forget to update the line in the `SearchComponent`
  where you provide the index name.
</Note>

***

### 5. Prepare the UI

Replace the following code snippet with the code in `app/page.tsx`:

```typescript title="app/page.tsx" theme={"system"}
import SearchComponent from "./components/search-bar";

export default function Home() {
  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 via-white to-indigo-50">
      <main className="flex-1">
        <div className="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 pt-20 pb-16">
          <div className="text-center mb-12">
            <h2 className="text-4xl md:text-5xl font-bold text-gray-900 mb-6">
              Search Upstash Documentation
            </h2>
            <p className="text-xl text-gray-600 max-w-2xl mx-auto leading-relaxed">
              Find exactly what you're looking for in our comprehensive documentation.
              Search through guides, APIs, tutorials, and more with lightning-fast results.
            </p>
          </div>
          {/* Search Component */}
          <div className="max-w-2xl mx-auto">
            <SearchComponent />
          </div>
          <div className="mt-20 grid md:grid-cols-3 gap-8">
            <div className="text-center">
              <div className="w-12 h-12 bg-blue-100 rounded-lg flex items-center justify-center mx-auto mb-4">
                <svg className="w-6 h-6 text-blue-600" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2}
                    d="M13 10V3L4 14h7v7l9-11h-7z" />
                </svg>
              </div>
              <h3 className="text-lg font-semibold text-gray-900 mb-2">Lightning Fast</h3>
              <p className="text-gray-600">Get instant search results powered by advanced indexing</p>
            </div>
            <div className="text-center">
              <div className="w-12 h-12 bg-green-100 rounded-lg flex items-center justify-center mx-auto mb-4">
                <svg className="w-6 h-6 text-green-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2}
                    d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z" />
                </svg>
              </div>
              <h3 className="text-lg font-semibold text-gray-900 mb-2">Accurate Results</h3>
              <p className="text-gray-600">Reranking ensures the most relevant content appears first</p>
            </div>
            <div className="text-center">
              <div className="w-12 h-12 bg-purple-100 rounded-lg flex items-center justify-center mx-auto mb-4">
                <svg className="w-6 h-6 text-purple-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2}
                    d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 
                  18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 
                  5c1.746 0 3.332.477 4.5 1.253v13C19.832 18.477 18.246 18 16.5 18c-1.746 
                  0-3.332.477-4.5 1.253" />
                </svg>
              </div>
              <h3 className="text-lg font-semibold text-gray-900 mb-2">Comprehensive</h3>
              <p className="text-gray-600">Search across all documentation, guides, and API references</p>
            </div>
          </div>
        </div>
      </main>
    </div>
  );
}


```

***

### 6. Start the Project

Run the following command to start the development server:

```bash  theme={"system"}
npm run dev
```

Open your browser and navigate to `http://localhost:3000` to test the application.

You can search through Upstash docs, and results will redirect you to the page you are looking for.

***

### Next Steps

Learn more about:

* [Typescript SDK](/search/sdks/ts/getting-started)
* [Docusaurus Integration](/search/integrations/docusaurus)


# Next.js Search Quickstart
Source: https://upstash.com/docs/search/tutorials/nextjs

Getting Started With Upstash Search and Next.js

***

### 1. Create a Search Database

Follow the instructions in the [Getting Started guide](/search/overall/getstarted) to create a Search Database.

***

### 2. Project Setup

Let's create a new Next.js application and install the `@upstash/search` package:

```shell  theme={"system"}
npx create-next-app@latest search-app
cd search-app
npm install @upstash/search
```

***

### 3. Add Environment Variables

Find the environment variables from your database dashboard and add them to your `.env` file:

```bash  theme={"system"}
UPSTASH_SEARCH_REST_URL=<YOUR_SEARCH_REST_URL>
UPSTASH_SEARCH_REST_TOKEN=<YOUR_SEARCH_REST_TOKEN>
```

***

### 4. Create an API Route to Upsert Documents

Create an API route in `app/api/upsert/route.ts`:

```typescript title="app/api/upsert/route.ts" theme={"system"}
import { Search } from "@upstash/search"

const client = new Search({
  url: process.env.UPSTASH_SEARCH_REST_URL,
  token: process.env.UPSTASH_SEARCH_REST_TOKEN,
})

const index = client.index("my-index")

export async function POST() {
  await index.upsert([
    {
      id: "movie-1",
      content: {
        title: "Inception",
        description: "A thriller about dreams within dreams.",
      },
      metadata: { genre: "sci-fi", year: 2010 },
    },
    {
      id: "movie-2",
      content: {
        title: "The Godfather",
        description: "A story about a powerful Italian-American crime family.",
      },
      metadata: { genre: "crime", year: 1972 },
    },
    {
      id: "movie-3",
      content: {
        title: "The Dark Knight",
        description: "A tale of Batman's fight against the Joker.",
      },
      metadata: { genre: "action", year: 2008 },
    },
  ])

  return new Response("OK")
}
```

***

### 5. Create a Route to Search Documents

Create an API route in `app/api/search/route.ts`:

```typescript title="app/api/search/route.ts" theme={"system"}
import { Search } from "@upstash/search"

const client = new Search({
  url: process.env.UPSTASH_SEARCH_REST_URL,
  token: process.env.UPSTASH_SEARCH_REST_TOKEN,
})

const index = client.index("my-index")

export async function POST(req: Request) {
  const { query } = (await req.json()) as { query: string }

  const results = await index.search({ query })

  return new Response(JSON.stringify(results))
}
```

***

### 6. Create a Simple Page

Add the following code in `app/page.tsx`:

```typescript title="app/page.tsx" theme={"system"}
"use client";

import { useState } from "react";

interface SearchResult {
  id: string;
  content: Record<string, unknown>;
  metadata: Record<string, unknown>;
  score: number;
}

export default function Home() {
  const [searchResults, setSearchResults] = useState<SearchResult[]>([]);
  const [query, setQuery] = useState("");
  const [isUpserting, setIsUpserting] = useState(false);
  const [upsertSuccess, setUpsertSuccess] = useState(false);

  const upsertData = async () => {
    setIsUpserting(true);
    setUpsertSuccess(false);
    await fetch("/api/upsert", { method: "POST" });
    setIsUpserting(false);
    setUpsertSuccess(true);
  };

  const search = async () => {
    const res = await fetch(`/api/search`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ query }),
    });
    const data = await res.json();
    setSearchResults(data || []);
  };

  return (
    <main className="min-h-screen bg-emerald-50 flex flex-col items-center py-10">
      <div className="w-full max-w-2xl bg-white shadow-md rounded-lg p-6">
        <header className="mb-6 text-center">
          <h1 className="text-2xl font-bold text-emerald-800">Search App</h1>
          <p className="text-emerald-600">
            Upsert data and search through the database.
          </p>
        </header>

        <div className="mb-6">
          <button
            onClick={upsertData}
            disabled={isUpserting}
            className={`w-full py-2 px-4 rounded-md text-white ${
              isUpserting
                ? "bg-emerald-300"
                : "bg-emerald-500 hover:bg-emerald-600"
            }`}
          >
            {isUpserting ? "Upserting..." : "Upsert Data"}
          </button>
          {upsertSuccess && (
            <p className="mt-2 text-sm text-emerald-600">
              Data upserted successfully!
            </p>
          )}
        </div>

        <div className="mb-6">
          <div className="flex gap-2">
            <input
              type="text"
              value={query}
              onChange={(e) => setQuery(e.target.value)}
              placeholder="Search..."
              className="flex-1 border border-emerald-300 rounded-md px-4 py-2 text-gray-800 focus:outline-none focus:ring-2 focus:ring-emerald-500"
            />
            <button
              onClick={search}
              className="bg-emerald-500 text-white px-4 py-2 rounded-md hover:bg-emerald-600"
            >
              Search
            </button>
          </div>
        </div>

        <ul className="space-y-2">
          {searchResults.map((result, index) => (
            <li
              key={index}
              className="bg-emerald-100 p-4 rounded-md shadow-sm text-emerald-800"
            >
              <p className="font-bold">ID: {result.id}</p>
              <p className="text-sm">Content: {JSON.stringify(result.content)}</p>
              <p className="text-sm">Metadata: {JSON.stringify(result.metadata)}</p>
              <p className="text-sm">Score: {result.score}</p>
            </li>
          ))}
        </ul>
      </div>
    </main>
  );
}
```

***

### 7. Start the Project

Run the following command to start the development server:

```bash  theme={"system"}
npm run dev
```

Open your browser and navigate to `http://localhost:3000` to test the application.

You can click the `Upsert Data` button to add three movies to your database and use the search bar to make a query.

***

### Next Steps

Learn more about:

* [Typescript SDK](/search/sdks/ts/getting-started)
* [Content and Metadata fields](/search/features/content-and-metadata)


# SearchBar
Source: https://upstash.com/docs/search/ui/search-bar

A beautifully-designed, accessible search component for React

***

## 1. Installation

```bash  theme={"system"}
npm install @upstash/search-ui
```

```typescript  theme={"system"}
// üëá import package and optimized styles
import { SearchBar } from "@upstash/search-ui"
import "@upstash/search-ui/dist/index.css"
```

***

## 2. Code Example

Our search component is designed to be **provider agnostic**.

In the code below we're using [Upstash Search](/search/overall/whatisupstashsearch) - our solution for fast, reliable and highly scalable serverless search.

Creating a search database takes less than a minute: [get started here](/search/overall/getstarted). To follow along with Upstash Search, install the package:

```bash  theme={"system"}
npm install @upstash/search
```

```tsx  theme={"system"}
"use client"

import { SearchBar } from "@upstash/search-ui"
import "@upstash/search-ui/dist/index.css"

import { Search } from "@upstash/search"
import { FileText } from "lucide-react"

const client = new Search({
  url: "<UPSTASH_SEARCH_URL>",
  token: "<YOUR_SEARCH_READONLY_TOKEN>",
})

// üëá your search index name
const index = client.index<{ title: string }>("movies")

export default function Page() {
  return (
    <div className="max-w-sm mt-24 mx-auto">
      <SearchBar.Dialog>
        <SearchBar.DialogTrigger placeholder="Search movies..." />

        <SearchBar.DialogContent>
          <SearchBar.Input placeholder="Type to search movies..." />
          <SearchBar.Results
            searchFn={(query) => {
              // üëá 100% type-safe: whatever you return here is
              // automatically typed as `result` below
              return index.search({ query, limit: 10, reranking: true })
            }}
          >
            {(result) => (
              <SearchBar.Result value={result.id} key={result.id}>
                <SearchBar.ResultIcon>
                  <FileText className="text-gray-600" />
                </SearchBar.ResultIcon>

                <SearchBar.ResultContent>
                  <SearchBar.ResultTitle>
                    {result.content.title}
                  </SearchBar.ResultTitle>
                  <p className="text-xs text-gray-500 mt-0.5">Movie</p>
                </SearchBar.ResultContent>
              </SearchBar.Result>
            )}
          </SearchBar.Results>
        </SearchBar.DialogContent>
      </SearchBar.Dialog>
    </div>
  )
}
```

***

## Using a Readonly Token (recommended)

The token used in the `Search` client above is a read-only token.

<Frame>
  <img src="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4f154e80c9d7af5d004624c9f5397066" data-og-width="1311" width="1311" data-og-height="668" height="668" data-path="img/search/readonly_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=280&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=db9c5099757cc7109f9c709fc4c05807 280w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=560&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=c3710968b2d9709700e6d9f9d4598860 560w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=840&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=4a9c6572e0c0b842bb75638b0c870f8d 840w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=1100&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=35daf3426a96f46ba2006d573bcd012a 1100w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=1650&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=b1f4b7db27961e02369159a97bd6af54 1650w, https://mintcdn.com/upstash/fy-PVAyWJaRFn1UN/img/search/readonly_token.png?w=2500&fit=max&auto=format&n=fy-PVAyWJaRFn1UN&q=85&s=be1e728e4c5d68b46328255d6170cbae 2500w" />
</Frame>

This token is safe to expose on the frontend. This allows your application to perform search queries without the need for a backend API.

To use environment variables for the token, set it as `NEXT_PUBLIC_YOUR_READONLY_TOKEN` in your `.env` file.

Optionally, you can also create a separate backend API to handle search on the server.

***

## Handling Results

You can perform actions with the search results by using the `onSelect` prop on `SearchBar.Item`:

```tsx  theme={"system"}
<SearchBar.Result
  onSelect={() => {
    // üëá do something with result
    console.log(result)
  }}
  value={result.id}
  key={result.id}
>
```

***

## Customization

This component is beautifully pre-styled, but 100% customizable. You can change every piece of it yourself by passing normal React props to each component (such as `className`).

**For example**: If you wanted to change the primary color, change the CSS classes:

```tsx  theme={"system"}
<SearchBar.Input
  className="focus:ring-red-500"
  placeholder="Type to search movies..."
/>

<SearchBar.ResultTitle
  className="font-medium text-gray-900"
  highlightClassName="decoration-red-500 text-red-500"
>
  {result.content.title}
</SearchBar.ResultTitle>
```

***

This component is based on the [Radix UI Dialog Primitive](https://www.radix-ui.com/primitives/docs/components/dialog) and Paco Coursey's [cmdk](https://cmdk.paco.me/) library.


# Delete Vectors
Source: https://upstash.com/docs/vector/api/endpoints/delete

DELETE https://{endpoint}/delete/{namespace}
Deletes the vectors with the given ids.

You can delete one or more vectors by providing their vector ids,
vector id prefix, or metadata filter.

<Tip>
  Vectors will be deleted from the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

<ParamField body="ids" type="string[]">
  Array of vector ids to delete.
</ParamField>

<ParamField body="prefix" type="string">
  Prefix of vector ids to delete.
</ParamField>

<ParamField body="filter" type="string">
  [Metadata filter](/vector/features/filtering) for the vectors to delete.
  <Warning>Deleting vectors with metadata filter is a O(N) operation that performs a full scan.
  Therefore, it might be slow for large indexes.</Warning>
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="deleted" type="number">
  The number of the successfully deleted vectors.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/delete \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "ids": [ "id-0", "id-1" ] }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/delete/ns \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "ids": [ "id-0", "id-1" ] }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": {
          "deleted": 2
      }
  }
  ```
</ResponseExample>


# Delete Namespace
Source: https://upstash.com/docs/vector/api/endpoints/delete-namespace

DELETE https://{endpoint}/delete-namespace/{namespace}
Deletes a namespace of an index.

<Note>
  The default namespace, which is the empty string `""`, cannot be deleted.
</Note>

## Request

This endpoint doesn't require any additional data.

## Path

<ParamField path="namespace" type="string" required>
  The namespace to delete.
</ParamField>

## Response

<ResponseField name="result" type="string">
  `"Success"` string.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/delete-namespace/ns \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": "Success"
  }
  ```

  ```json 404 Not Found theme={"system"}
  {
      "error": "Namespace ns for the index $NAME does not exist",
      "status": 404
  }
  ```
</ResponseExample>


# Fetch Vectors
Source: https://upstash.com/docs/vector/api/endpoints/fetch

GET https://{endpoint}/fetch/{namespace}
Fetches the vectors with the provided ids.

You can fetch vector values or metadata of one or more by providing
their vector ids or id prefix.

<Tip>
  Vectors will be fetched from the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

<ParamField body="ids" type="string[]">
  Array of vector ids to fetch.
</ParamField>

<ParamField body="prefix" type="string">
  Prefix of vector ids to fetch.

  <Info>When you fetch vectors with an id prefix, at most `1000` vectors will be returned.
  If there are more vectors, please use the [range](./range) API with an id prefix.</Info>
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any.
  It is recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response.
  It is recommended to set this to `false` as the vector values can be
  quite big, and not needed most of the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response, if any.
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="Vectors" type="Object[]">
  Array of vectors in the same order they provided in the ids array.
  Array elements can be `null` if no such vector exists with the provided id.

  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The unstructured data of the vector, if any.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/fetch \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "ids": ["id-0"], "includeMetadata": true }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/fetch/ns \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "ids": ["id-0", "id-1"], "includeMetadata": true }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": [
          {
              "id": "id-0",
              "metadata": {
                  "link": "upstash.com"
              }
          },
          {
              "id": "id-1"
          }
      ]
  }
  ```
</ResponseExample>


# Fetch Random Vector
Source: https://upstash.com/docs/vector/api/endpoints/fetch-random

GET https://{endpoint}/random/{namespace}
Fetches a random vector.

## Request

This endpoint doesn't require any additional data.

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

The response will be `null` if the namespace is empty.

<ResponseField name="id" type="string" required>
  The id of the vector.
</ResponseField>

<ResponseField name="vector" type="number[]">
  The dense vector value for dense and hybrid indexes.
</ResponseField>

<ResponseField name="sparseVector" type="Object[]">
  The sparse vector value for sparse and hybrid indexes.

  <Expandable defaultOpen="true">
    <ResponseField name="indices" type="number[]">
      Indices of the non-zero valued dimensions.
    </ResponseField>

    <ResponseField name="values" type="number[]">
      Values of the non-zero valued dimensions.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/random \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/random/ns \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": {
          "id": "id-0",
          "vector": [0.1, 0.2]
      }
  }
  ```
</ResponseExample>


# Index Info
Source: https://upstash.com/docs/vector/api/endpoints/info

GET https://{endpoint}/info
Returns some information about the index.

Info will be updated eventually, so it might take some time to see the effect of changes in this endpoint.

## Request

This request doesn't require any additional data.

## Response

<ResponseField name="vectorCount" type="number" required>
  The number of vectors in the index, that are ready to use. This is the total
  number of vectors across all namespaces.
</ResponseField>

<ResponseField name="pendingVectorCount" type="number" required>
  The number of vectors in the index, that are still processing and not ready to
  use. This is the total number of pending vectors across all namespaces.
</ResponseField>

<ResponseField name="indexSize" type="number" required>
  The total size of the index, in **bytes**.
</ResponseField>

<ResponseField name="dimension" type="number" required>
  Dimension of the vectors.
</ResponseField>

<ResponseField name="similarityFunction" type="string" required>
  Name of the similarity function used in indexing and queries.
</ResponseField>

<ResponseField name="indexType" type="string" required>
  Type of the index. Possible values: `"DENSE"`, `"SPARSE"`, `"HYBRID"`
</ResponseField>

<ResponseField name="denseIndex" type="object">
  Information about the dense vector index configuration.

  <Expandable>
    <ResponseField name="dimension" type="number" required>
      Dimension of the dense vectors.
    </ResponseField>

    <ResponseField name="similarityFunction" type="string" required>
      Similarity function used for dense vector comparisons.
      Possible values: `"COSINE"`, `"EUCLIDEAN"`, `"DOT_PRODUCT"`
    </ResponseField>

    <ResponseField name="embeddingModel" type="string" required>
      Name of the embedding model used for dense vectors.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="sparseIndex" type="object">
  Information about the sparse vector index configuration.

  <Expandable>
    <ResponseField name="embeddingModel" type="string" required>
      Name of the embedding model used for sparse vectors.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="namespaces" type="object" required>
  Map of namespace names to namespace .

  <Note>Every index has at least one namespace called default namespace, whose name is the empty string `""`.</Note>

  <Expandable defaultOpen="true">
    <ResponseField name="vectorCount" type="number" required>
      The number of vectors in the namespace, that are ready to use.
    </ResponseField>

    <ResponseField name="pendingVectorCount" type="number" required>
      The number of vectors in the namespace, that are still processing
      and not ready to use.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/info \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "result": {
      "vectorCount": 7,
      "pendingVectorCount": 0,
      "indexSize": 43501,
      "dimension": 1024,
      "similarityFunction": "COSINE",
      "indexType": "HYBRID",
      "denseIndex": {
        "dimension": 1024,
        "similarityFunction": "COSINE",
        "embeddingModel": "BGE_M3"
      },
      "sparseIndex": {
        "embeddingModel": "BM25"
      },
      "namespaces": {
        "": {
          "vectorCount": 6,
          "pendingVectorCount": 0
        },
        "ns": {
          "vectorCount": 1,
          "pendingVectorCount": 0
        }
      }
    }
  }
  ```
</ResponseExample>


# List Namespaces
Source: https://upstash.com/docs/vector/api/endpoints/list-namespaces

GET https://{endpoint}/list-namespaces
Lists the names of the namespaces of an index.

## Request

This endpoint doesn't require any additional data.

## Response

<ResponseField name="namespaces" type="string[]" required>
  Array of namespace names.

  <Note>Every index has at least one namespace called default namespace, whose name is the empty string `""`.</Note>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/list-namespaces \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": ["", "ns0", "ns1"]
  }
  ```
</ResponseExample>


# Query Vectors
Source: https://upstash.com/docs/vector/api/endpoints/query

POST https://{endpoint}/query/{namespace}
Queries the approximate nearest neighbors of a vector.

<Tip>
  Query will run against the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

It is also possible to send a batch query request by providing an array
of fields below.

<ParamField body="vector" name="vector" type="number[]" required>
  The query vector
  <Note>The query vector should have the same dimensions as your index.</Note>
</ParamField>

<ParamField body="topK" type="number" default="10">
  The total number of the vectors that you want to receive as a query
  result. The response will be sorted based on the distance metric score,
  and at most `topK` many vectors will be returned.
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any.
  It is recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response.
  It is recommended to set this to `false` as the vector values can be
  quite big, and not needed most of the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response, if any.
</ParamField>

<ParamField body="filter" type="string" default="">
  [Metadata filter](/vector/features/filtering) to apply.
</ParamField>

<ParamField body="weightingStrategy" type="string">
  For sparse vectors of sparse and hybrid indexes, specifies what kind of
  weighting strategy should be used while querying the matching non-zero
  dimension values of the query vector with the documents.

  If not provided, no weighting will be used.

  Only possible value is `IDF` (inverse document frequency).
</ParamField>

<ParamField body="fusionAlgorithm" type="string">
  Fusion algorithm to use while fusing scores
  from dense and sparse components of a hybrid index.

  If not provided, defaults to `RRF` (Reciprocal Rank Fusion).

  Other possible value is `DBSF` (Distribution-Based Score Fusion).
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

If the request was an array of a single element, or a JSON object,
an object with the following fields is returned.

If the request was an array of more than one items, an array of
objects below is returned, one for each query item.

<Note>
  For dense indexes, the score is normalized to always be between 0 and 1.
  The closer the score is to 1, the more similar the vector is to the query vector.
  This does not depend on the distance metric you use.

  For sparse and hybrid indexes, scores can be arbitrary values, but the score
  will be higher for more similar vectors.
</Note>

<ResponseField name="Scores" type="Object[]">
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The similarity score of the vector, calculated based on the distance metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The unstructured data of the vector, if any.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/query \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "vector": [0.1, 0.2], "topK": 2, "includeMetadata": true }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/query/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "vector": [0.1, 0.2], "topK": 2, "includeMetadata": true }'
  ```

  ```sh curl (Batch Query) theme={"system"}
  curl "$UPSTASH_VECTOR_REST_URL/query" \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '[
          {
            "vector": [0.1, 0.2],
            "topK": 2,
            "includeMetadata": true
          },
          {
            "vector": [0.2, 0.3],
            "topK": 3
          }
        ]'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": [
          {
              "id": "id-0",
              "score": 1.0,
              "metadata": {
                  "link": "upstash.com"
              }
          },
          {
              "id": "id-1",
              "score": 0.99996454
          }
      ]
  }
  ```
</ResponseExample>


# Query Data
Source: https://upstash.com/docs/vector/api/endpoints/query-data

POST https://{endpoint}/query-data/{namespace}
Queries the approximate nearest neighbors of a raw text data after embedding it.

<Warning>
  To use this endpoint, the index must be created with an [embedding model](/vector/features/embeddingmodels).
</Warning>

<Tip>
  Query will run against the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

It is also possible to send a batch query request by providing an array
of fields below.

<ParamField body="data" name="data" type="string" required>
  The raw text data to embed and query.
</ParamField>

<ParamField body="topK" type="number" required default="10">
  The total number of the vectors that you want to receive as a query
  result. The response will be sorted based on the distance metric score,
  and at most `topK` many vectors will be returned.
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any.
  It is recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response.
  It is recommended to set this to `false` as the vector values can be
  quite big, and not needed most of the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response.
  When set to true, data will contain the raw text data used
  while upserting.
</ParamField>

<ParamField body="filter" type="string" default="">
  [Metadata filter](/vector/features/filtering) to apply.
</ParamField>

<ParamField body="weightingStrategy" type="string">
  For sparse vectors of sparse and hybrid indexes, specifies what kind of
  weighting strategy should be used while querying the matching non-zero
  dimension values of the query vector with the documents.

  If not provided, no weighting will be used.

  Only possible value is `IDF` (inverse document frequency).
</ParamField>

<ParamField body="fusionAlgorithm" type="string">
  Fusion algorithm to use while fusing scores
  from dense and sparse components of a hybrid index.

  If not provided, defaults to `RRF` (Reciprocal Rank Fusion).

  Other possible value is `DBSF` (Distribution-Based Score Fusion).
</ParamField>

<ParamField body="queryMode" type="string">
  Query mode for hybrid indexes with Upstash-hosted
  embedding models.

  Specifies whether to run the query in only the
  dense index, only the sparse index, or in both.

  If not provided, defaults to `HYBRID`.

  Possible values are `HYBRID`, `DENSE`, and `SPARSE`.
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

If the request was an array of a single element, or a JSON object,
an object with the following fields is returned.

If the request was an array of more than one items, an array of
objects below is returned, one for each query item.

<Note>
  For dense indexes, the score is normalized to always be between 0 and 1.
  The closer the score is to 1, the more similar the vector is to the query vector.
  This does not depend on the distance metric you use.

  For sparse and hybrid indexes, scores can be arbitrary values, but the score
  will be higher for more similar vectors.
</Note>

<ResponseField name="Scores" type="Object[]">
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The similarity score of the vector, calculated based on the distance metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The textual data of the vector before embedding it.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/query-data \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "data": "What is Upstash?", "topK": 2, "includeMetadata": true }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/query-data/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "data": "What is Upstash?", "topK": 2, "includeMetadata": true }'
  ```

  ```sh curl (Batch Query) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/query-data \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '[
          {
            "data": "What is Upstash?",
            "topK": 2,
            "includeMetadata": true
          },
          {
            "data": "What is Upstash Vector?",
            "topK": 3
          }
        ]'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": [
          {
              "id": "id-0",
              "score": 1.0,
              "metadata": {
                  "link": "upstash.com"
              }
          },
          {
              "id": "id-1",
              "score": 0.99996454
          }
      ]
  }
  ```

  ```json 422 Unprocessable Entity theme={"system"}
  {
      "error": "Embedding data for this index is not allowed. The index must be created with an embedding model to use it.",
      "status": 422
  }
  ```
</ResponseExample>


# Range Vectors
Source: https://upstash.com/docs/vector/api/endpoints/range

GET https://{endpoint}/range/{namespace}
Ranges over vectors starting(inclusive) from a cursor until the end of the vectors in the or given limit.

<Tip>
  By default vectors from the default namespace will be iterated.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

<ParamField body="cursor" type="string" required>
  The offset to the last retrieved vector. Should be set to `"0"` in the initial
  range.
</ParamField>

<ParamField body="prefix" type="string">
  Prefix of the vector ids to range over.
</ParamField>

<ParamField body="limit" type="number" required>
  The number of maximum vectors that you want in the response of range. (page
  size)
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any.
  It is recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response.
  It is recommended to set this to `false` as the vector values can be
  quite big, and not needed most of the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response, if any.
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="nextCursor" type="string" required>
  The offset for the next range. You should place this in the `cursor` field for
  the next range. It will be equal to empty string if there are no other vectors to range.
</ResponseField>

<ResponseField name="vectors" type="Object[]" required>
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The unstructured data of the vector, if any.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/range \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "cursor": "0", "limit": 2, "includeMetadata": true }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/range/ns \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "cursor": "0", "limit": 2, "includeMetadata": true }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": {
          "nextCursor": "2",
          "vectors": [
              {
                  "id": "id-0",
                  "metadata": {
                      "link": "upstash.com"
                  }
              },
              {
                  "id": "id-1"
              }
          ]
      }
  }
  ```
</ResponseExample>


# Rename Namespace
Source: https://upstash.com/docs/vector/api/endpoints/rename-namespace

POST https://{endpoint}/rename-namespace
Renames a namespace of an index.

<Note>
  The default namespace, which is the empty string `""`, cannot be renamed.
</Note>

<Note>
  There should not be a namespace with the given new namespace name, unless the
  delete existing flag is passed.
</Note>

## Request

<ParamField body="namespace" type="string" required>
  The name of the namespace to rename.
</ParamField>

<ParamField body="newNamespace" type="string" required>
  The new name of the namespace.
</ParamField>

<ParamField body="deleteExisting" type="boolean" default="false">
  When the delete existing flag is passed, if there exists a namespace
  with the new namespace name, it is deleted before the rename operation.
</ParamField>

## Response

<ResponseField name="renamed" type="boolean">
  Whether the namespace is renamed or not.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/rename-namespace \
    -X POST \
    -d '{ "namespace": "ns", "newNamespace": "newNs" }' \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": { "renamed": true }
  }
  ```
</ResponseExample>


# Reset Namespace(s)
Source: https://upstash.com/docs/vector/api/endpoints/reset

DELETE https://{endpoint}/reset/{namespace}
Resets one or all namespaces of an index to its initial state by deleting all the vectors.

The namespace will be completely empty after `/reset` is called, but will not be deleted.

<Tip>
  Reset operation will be performed against the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

This request doesn't require any additional data.

## Query

<ParamField query="all" type="string">
  When given, resets all namespaces of an index.
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="result" type="string">
  `"Success"` string.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/reset \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/reset/ns \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```

  ```sh curl (All Namespaces) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/reset?all \
    -X DELETE \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": "Success"
  }
  ```
</ResponseExample>


# Resume
Source: https://upstash.com/docs/vector/api/endpoints/resumable-query/resume

POST https://{endpoint}/resumable-query-next
Resumes a previously started query to fetch additional results.

## Request

<ParamField body="uuid" type="string" required>
  The unique identifier returned from the start resumable query request.
</ParamField>

<ParamField body="additionalK" type="number" required>
  The number of additional results to fetch.
</ParamField>

## Response

<ResponseField name="Scores" type="Object[]">
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The similarity score of the vector, calculated based on the distance
      metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The unstructured data of the vector, if any.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/resumable-query-next \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{
      "uuid": "550e8400-e29b-41d4-a716-446655440000",
      "additionalK": 2
    }'
  ```
</RequestExample>


# Start with Data
Source: https://upstash.com/docs/vector/api/endpoints/resumable-query/start-with-data

POST https://{endpoint}/resumable-query-data/{namespace}
Perform queries using text data that can be resumed to fetch additional results.

## Request

<ParamField body="data" type="string" required>
  The text data to be embedded and used for querying.
</ParamField>

<ParamField body="topK" type="number" default="10">
  The total number of the vectors that you want to receive as a query result.
  The response will be sorted based on the distance metric score, and at most
  `topK` many vectors will be returned.
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any. It is
  recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response. It is recommended to set
  this to `false` as the vector values can be quite big, and not needed most of
  the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response, if any.
</ParamField>

<ParamField body="filter" type="string" default="">
  [Metadata filter](/vector/features/filtering) to apply.
</ParamField>

<ParamField body="maxIdle" type="number">
  Maximum idle time for the resumable query in seconds.
</ParamField>

<ParamField body="weightingStrategy" type="string">
  For sparse vectors of sparse and hybrid indexes, specifies what kind of
  weighting strategy should be used while querying the matching non-zero
  dimension values of the query vector with the documents.

  If not provided, no weighting will be used.

  Only possible value is `IDF` (inverse document frequency).
</ParamField>

<ParamField body="fusionAlgorithm" type="string">
  Fusion algorithm to use while fusing scores
  from dense and sparse components of a hybrid index.

  If not provided, defaults to `RRF` (Reciprocal Rank Fusion).

  Other possible value is `DBSF` (Distribution-Based Score Fusion).
</ParamField>

<ParamField body="queryMode" type="string">
  Query mode for hybrid indexes with Upstash-hosted
  embedding models.

  Specifies whether to run the query in only the
  dense index, only the sparse index, or in both.

  If not provided, defaults to `HYBRID`.

  Possible values are `HYBRID`, `DENSE`, and `SPARSE`.
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use. When no namespace is specified, the default namespace
  will be used.
</ParamField>

## Response

Same as Resumable Query.

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/resumable-query-data \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{
      "data": "Hello world",
      "topK": 2,
      "includeMetadata": true,
      "maxIdle": 3600
    }'
  ```
</RequestExample>


# Start with Vector
Source: https://upstash.com/docs/vector/api/endpoints/resumable-query/start-with-vector

POST https://{endpoint}/resumable-query/{namespace}
Perform queries that can be resumed to fetch additional results.

<Tip>
  Resumable queries allow you to fetch results in batches, which is useful for
  large result sets or when you want to implement pagination.
</Tip>

## Request

<ParamField body="vector" type="number[]" required>
  The query vector
  <Note>The query vector should have the same dimensions as your index.</Note>
</ParamField>

<ParamField body="topK" type="number" default="10">
  The total number of the vectors that you want to receive as a query result.
  The response will be sorted based on the distance metric score, and at most
  `topK` many vectors will be returned.
</ParamField>

<ParamField body="includeMetadata" type="boolean" default="false">
  Whether to include the metadata of the vectors in the response, if any. It is
  recommended to set this to `true` to easily identify vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean" default="false">
  Whether to include the vector values in the response. It is recommended to set
  this to `false` as the vector values can be quite big, and not needed most of
  the time.
</ParamField>

<ParamField body="includeData" type="boolean" default="false">
  Whether to include the data of the vectors in the response, if any.
</ParamField>

<ParamField body="filter" type="string" default="">
  [Metadata filter](/vector/features/filtering) to apply.
</ParamField>

<ParamField body="maxIdle" type="number">
  Maximum idle time for the resumable query in seconds.
</ParamField>

<ParamField body="weightingStrategy" type="string">
  For sparse vectors of sparse and hybrid indexes, specifies what kind of
  weighting strategy should be used while querying the matching non-zero
  dimension values of the query vector with the documents.

  If not provided, no weighting will be used.

  Only possible value is `IDF` (inverse document frequency).
</ParamField>

<ParamField body="fusionAlgorithm" type="string">
  Fusion algorithm to use while fusing scores
  from dense and sparse components of a hybrid index.

  If not provided, defaults to `RRF` (Reciprocal Rank Fusion).

  Other possible value is `DBSF` (Distribution-Based Score Fusion).
</ParamField>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use. When no namespace is specified, the default namespace
  will be used.
</ParamField>

## Response

<ResponseField name="uuid" type="string" required>
  A unique identifier for the resumable query.
</ResponseField>

<ResponseField name="scores" type="Object[]">
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string" required>
      The id of the vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The similarity score of the vector, calculated based on the distance
      metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The dense vector value for dense and hybrid indexes.
    </ResponseField>

    <ResponseField name="sparseVector" type="Object[]">
      The sparse vector value for sparse and hybrid indexes.

      <Expandable defaultOpen="true">
        <ResponseField name="indices" type="number[]">
          Indices of the non-zero valued dimensions.
        </ResponseField>

        <ResponseField name="values" type="number[]">
          Values of the non-zero valued dimensions.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="metadata" type="Object">
      The metadata of the vector, if any.
    </ResponseField>

    <ResponseField name="data" type="string">
      The unstructured data of the vector, if any.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/resumable-query \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{
      "vector": [0.1, 0.2],
      "topK": 2,
      "includeMetadata": true,
      "maxIdle": 3600
    }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/resumable-query/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{
      "vector": [0.1, 0.2],
      "topK": 2,
      "includeMetadata": true,
      "maxIdle": 3600
    }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "uuid": "550e8400-e29b-41d4-a716-446655440000",
    "scores": [
      {
        "id": "id-0",
        "score": 1.0,
        "metadata": {
          "link": "upstash.com"
        }
      },
      {
        "id": "id-1",
        "score": 0.99996454
      }
    ]
  }
  ```
</ResponseExample>


# Stop Resumable Query
Source: https://upstash.com/docs/vector/api/endpoints/resumable-query/stop

POST https://{endpoint}/resumable-query-end
Ends a resumable query and releases associated resources.

## Request

<ParamField body="uuid" type="string" required>
  The unique identifier of the resumable query to end.
</ParamField>

## Response

<ResponseField name="result" type="string">
  A success message indicating the query was ended.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/resumable-query-end \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{
      "uuid": "550e8400-e29b-41d4-a716-446655440000"
    }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "result": "Success"
  }
  ```
</ResponseExample>


# Update Vector
Source: https://upstash.com/docs/vector/api/endpoints/update

POST https://{endpoint}/update/{namespace}
Updates a vector, data or metadata.

<Tip>
  The vector will be updated int the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

You can update a vector value, data, or metadata; or any combination
of those.

<ParamField body="id" type="string" required>
  The id of the vector.
</ParamField>

<ParamField body="vector" type="number[]">
  The dense vector value to update to for dense and hybrid indexes.
  <Note>The vector should have the same dimensions as your index.</Note>
</ParamField>

<ParamField body="sparseVector" type="Object[]">
  The sparse vector value to update to for sparse and hybrid indexes.

  <Expandable defaultOpen="true">
    <ResponseField name="indices" type="number[]">
      Indices of the non-zero valued dimensions.
    </ResponseField>

    <ResponseField name="values" type="number[]">
      Values of the non-zero valued dimensions.
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField body="data" type="string">
  The raw text data to update to.
  <Note>If the index is created with an [embedding model](/vector/features/embeddingmodels)
  this will embed the data into a vector and will also update the vector, along with data.</Note>
</ParamField>

<ParamField body="metadata" type="Object">
  The metadata to update to.
</ParamField>

<ParamField body="metadataUpdateMode" type="string">
  Whether to overwrite the whole metadata while updating
  it, or patch the metadata (insert new fields or update or delete existing fields)
  according to the `RFC 7396 JSON Merge Patch` algorithm.

  `OVERWRITE` for overwrite, `PATCH` for patch.
</ParamField>

<Note>
  For hybrid indexes either none or both of `vector` and `sparseVector` fields
  must be present. It is not allowed to update only `vector` or `sparseVector`.
</Note>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="updated" type="number">
  `1` if any vector is updated, `0` otherwise.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/update \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "id": "id-1", "metadata": { "link": "upstash.com" } }'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/update/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "id": "id-2", "vector": [0.1, 0.2] }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": {
          "updated": 1
      }
  }
  ```
</ResponseExample>


# Upsert Vectors
Source: https://upstash.com/docs/vector/api/endpoints/upsert

POST https://{endpoint}/upsert/{namespace}
Upserts (inserts or updates) the vector.

<Tip>
  The vector will be upserted into the default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

You can either upsert a single vector, or multiple vectors in an array.

<ParamField body="id" type="string" required>
  The id of the vector.
</ParamField>

<ParamField body="vector" type="number[]">
  The dense vector value for dense and hybrid indexes.
  <Note>The vector should have the same dimensions as your index.</Note>
</ParamField>

<ParamField body="sparseVector" type="Object[]">
  The sparse vector value for sparse and hybrid indexes.

  <Expandable defaultOpen="true">
    <ResponseField name="indices" type="number[]">
      Indices of the non-zero valued dimensions.
    </ResponseField>

    <ResponseField name="values" type="number[]">
      Values of the non-zero valued dimensions.
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField body="metadata" type="Object">
  The metadata of the vector. This makes identifying vectors
  on retrieval easier and can be used to with filters on queries.
</ParamField>

<ParamField body="data" type="string">
  The data of the vector. This is an unstructured raw text
  data, which can be anything associated with this vector.
</ParamField>

<Note>
  For dense indexes, only `vector` should be provided, and `sparseVector` should not be set.

  For sparse indexes, only `sparseVector` should be provided, and `vector` should not be set.

  For hybrid indexes both of `vector` and `sparseVector` must be present.
</Note>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="result" type="string">
  `"Success"` string.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/upsert \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '[ 
      { "id": "id-0", "vector": [0.1, 0.2], "metadata": { "link": "upstash.com" } }, 
      { "id": "id-1", "vector": [0.2, 0.3] }
    ]'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/upsert/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "id": "id-2", "vector": [0.1, 0.2], "metadata": { "link": "upstash.com" } }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": "Success"
  }
  ```

  ```json 422 Unprocessable Entity theme={"system"}
  {
      "error": "Invalid vector dimension: 2, expected: 256",
      "status": 422
  }
  ```
</ResponseExample>


# Upsert Data
Source: https://upstash.com/docs/vector/api/endpoints/upsert-data

POST https://{endpoint}/upsert-data/{namespace}
Upserts (inserts or updates) the raw text data after embedding it.

<Warning>
  To use this endpoint, the index must be created with an [embedding model](/vector/features/embeddingmodels).
</Warning>

<Tip>
  Vector embedding of the raw text data will be upserted into the
  default namespace by default.
  You can use a different namespace by specifying it in the request path.
</Tip>

## Request

You can either upsert a single data, or multiple data in an array.

<ParamField body="id" type="string" required>
  The id of the vector.
</ParamField>

<ParamField body="data" type="string" required>
  The raw text data to embed and upsert.
</ParamField>

<ParamField body="metadata" type="Object">
  The metadata of the vector. This makes identifying vectors
  on retrieval easier and can be used to with filters on queries.
</ParamField>

<Note>
  Data field of the vector will be automatically set to the
  raw text data, so that you can access it later, during
  queries.
</Note>

## Path

<ParamField path="namespace" type="string" default="">
  The namespace to use.
  When no namespace is specified, the default namespace will be used.
</ParamField>

## Response

<ResponseField name="result" type="string">
  `"Success"` string.
</ResponseField>

<RequestExample>
  ```sh curl theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/upsert-data \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '[ 
      { "id": "id-0", "data": "Upstash is a serverless data platform.", "metadata": { "link": "upstash.com" } }, 
      { "id": "id-1", "data": "Upstash Vector is a serverless vector database." }
    ]'
  ```

  ```sh curl (Namespace) theme={"system"}
  curl $UPSTASH_VECTOR_REST_URL/upsert-data/ns \
    -X POST \
    -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
    -d '{ "id": "id-2", "data": "Upstash is a serverless data platform.", "metadata": { "link": "upstash.com" } }'
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
      "result": "Success"
  }
  ```

  ```json 422 Unprocessable Entity theme={"system"}
  {
      "error": "Embedding data for this index is not allowed. The index must be created with an embedding model to use it.",
      "status": 422
  }
  ```
</ResponseExample>


# Getting Started
Source: https://upstash.com/docs/vector/api/get-started



If you do not have a vector database already, follow [these steps](/vector/overall/getstarted) to create one.

In the database details section of the Upstash Console, scroll down to `Connect` section and select the `cURL` tab. You can simply copy the curl expression and run on your terminal.

```shell  theme={"system"}
curl $UPSTASH_VECTOR_REST_URL/upsert \
  -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
  -d '{"id": "id-0", "vector": [0.87, 0.99]}'
```

## Response

REST API returns a JSON response. When command execution is successful, response JSON will have a single result field and its value will contain the Redis response.

Example:

```json  theme={"system"}
{ "result": "Success" }
```

When command execution is not successful, response JSON will have a single error field and its value will contain the error message.

Example:

```json  theme={"system"}
{
  "error": "Unauthorized: Invalid auth token",
  "status": 401
}
```

#### HTTP Response Codes

| Status Code              | Description                                                                                         |
| ------------------------ | --------------------------------------------------------------------------------------------------- |
| `200 OK`                 | When request is accepted and successfully executed.                                                 |
| `400 Bad Request`        | When there's a syntax error, an invalid/unsupported command is sent or command execution fails.     |
| `401 Unauthorized`       | When authentication fails; auth token is missing or invalid.                                        |
| `405 Method Not Allowed` | When an unsupported HTTP method is used. Only `HEAD`, `GET`, `POST`, and `PUT` methods are allowed. |

***


# Examples
Source: https://upstash.com/docs/vector/examples



<iframe src="https://vector-example-dashboard.vercel.app" width="100%" height="1000px" style={{ border: "0" }} />


# Algorithm
Source: https://upstash.com/docs/vector/features/algorithm



## Approximate Nearest Neighbor Search

The primary functionality of the vector store is straightforward: identifying the most similar vectors to a given vector.
While the concept is simple, translating it into a practical product poses significant challenges.

A simple and basic approach to searching in a vector database is to perform an exhaustive search by comparing a query vector to every other vector stored in the database one by one. However, this consumes too many resources and results in very high latencies, making it not very practical. To address this problem, Approximate Nearest Neighbor (`ANN`) algorithms are used. `ANN` search approximates the true nearest neighbor, which means it might not find the absolute closest point, but it will find one that's close enough, with a **low-latency** and by consuming **fewer resources**.
In the literature, the comparison of the results of `ANNS` with exhaustive search is called the recall rate.
The higher the recall rate the better the results.

Several `ANNS` algorithms, such as `HNSW`\[1], `NSG`\[2], and `DiskANN`\[3], are available for use,
each with its distinct characteristics. One of the difficult problems in ANN algorithms is that indexing and querying vectors may require storing the whole data in memory. When the dataset is huge, then memory requirements for indexing may exceed available memory. `DiskANN` algorithm tries to solve this problem by using disk as the main storage for indexes and for performing queries directly on disk.`DiskANN` paper acknowledges that, if you try to store your vectors
in disk and use `HNSW` or `NSG`, you may end up with again very high latencies. `DiskANN` is focused
on serving queries from disk with **low-latency** and **good recall rate**.
And this helps Upstash Vector to be **cost-effective**, therefore cheaper compared to alternatives.

Even though `DiskANN` has its advantages, it also requires more work to be practical.
Main problem is that, you can't insert/update existing index without reindexing all the vectors.
For this problem, there is another improved paper `FreshDiskANN`\[4]. `FreshDiskANN` improves `DiskANN` via introducing
a temporary index for up-to-date data in memory. Queries are served from both the temporary (up-to-date) index
and also from the disk. And these temporary indexes are merged to the disk from time-to-time behind the scene.

Upstash Vector is based on `DiskANN` and `FreshDiskANN` with more improvements based on our
tests and observations.

### References

1. Malkov, Y. A., Yashunin, D. A. (2016). *Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs*. CoRR, abs/1603.09320 (2016). \[[https://arxiv.org/abs/1603.09320](https://arxiv.org/abs/1603.09320)]
2. Fu, C., Xiang, C., Wang, C., Cai, D. (2019). *Fast Approximate Nearest Neighbor Search with Navigating Spreading-Out Graphs*. Proceedings of the VLDB, 12(5), 461‚Äì474. doi: 10.14778/3303753.3303754. \[[https://www.vldb.org/pvldb/vol12/p461-fu.pdf](https://www.vldb.org/pvldb/vol12/p461-fu.pdf)]
3. Subramanya, S. J., Devvrit, Kadekodi, R., Krishaswamy, R., Simhadri, H. V. (2019). *DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node*. In Proceedings of the 33rd International Conference on Neural Information Processing Systems (NeurIPS '19), Article No.: 1233, Pages 13766‚Äì13776. \[[https://dl.acm.org/doi/abs/10.5555/3454287.3455520](https://dl.acm.org/doi/abs/10.5555/3454287.3455520)]
4. Singh, A., Subramanya, S. J., Krishnaswamy, R., Simhadri, H. V. (2021). *FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search*. CoRR abs/2105.09613 (2021). \[[https://arxiv.org/abs/2105.09613](https://arxiv.org/abs/2105.09613)]


# Embedding Models
Source: https://upstash.com/docs/vector/features/embeddingmodels



To store text in a vector database, it must first be converted into a vector,
also known as an embedding. Typically, this vectorization is done by a third
party.

By selecting an embedding model when you create your Upstash Vector database,
you can now upsert and query raw string data when using your database instead of
converting your text to a vector first. The vectorization is done automatically
by your selected model.

## Upstash Embedding Models - Video Guide

Let's look at how Upstash embeddings work, how the models we offer compare, and
which model is best for your use case.

<iframe id="intro-video" width="560" height="315" src="https://www.youtube.com/embed/aImBIYwn5Ew?rel=0&disablekb=1" title="YouTube video player" frameBorder="0" allow="accelerometer; fullscreen; clipboard-write; encrypted-media; gyroscope" allowFullScreen />

## Models

Upstash Vector comes with a variety of embedding models that score well in the
[MTEB](https://huggingface.co/spaces/mteb/leaderboard) leaderboard, a benchmark
for measuring the performance of embedding models. They support use cases such
as classification, clustering, or retrieval.

You can choose the following general purpose models for dense and hybrid indexes:

| Name                                                                                                    | Dimension | Sequence Length | MTEB  |
| ------------------------------------------------------------------------------------------------------- | --------- | --------------- | ----- |
| [mixedbread-ai/mxbai-embed-large-v1](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1)         | 1024      | 512             | 64.68 |
| [WhereIsAI/UAE-Large-V1](https://huggingface.co/WhereIsAI/UAE-Large-V1)                                 | 1024      | 512             | 64.64 |
| [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)                                 | 1024      | 512             | 64.23 |
| [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5)                                   | 768       | 512             | 63.55 |
| [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)                                 | 384       | 512             | 62.17 |
| [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) | 384       | 256             | 56.26 |
| [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)                                                       | 1024      | 8192            | \*    |
| [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased)                   | 768       | 512             | 38.33 |

<Note>
  The sequence length is not a hard limit. Models truncate the input
  appropriately when given a raw text data that would result in more tokens than
  the given sequence length. However, we recommend using appropriate models and
  not exceeding their sequence length to have more accurate results.
</Note>

<Note>
  MTEB score for the `BAAI/bge-m3` is not fully measured.
</Note>

For sparse and hybrid indexes, on the following models can be selected:

| Name                                              |
| ------------------------------------------------- |
| [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3) |
| [BM25](https://en.wikipedia.org/wiki/Okapi_BM25)  |

See [Creating Sparse Vectors](/vector/features/sparseindexes#creating-sparse-vectors) for the details of the above models.

## Using a Model

To start using embedding models, create the index with a model of your choice.

<Frame style={{ width: '600px' }}>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=49c1fc16b59ac3eb1c272fd0f249f49b" data-og-width="577" width="577" data-og-height="618" height="618" data-path="img/vector/create_index_with_model.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c96cba315017f24ddd939f4fd3a2ea90 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=93d6581a88ada8f9303b4c62da0b740d 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=07f0a789e6017ac45e786e7ad7d8febc 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3e916163d782124dd0bca31909c45e38 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=844afe84f3d8d134c23b380862a8774f 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/create_index_with_model.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=30d0657d6bd7ba2f2f747c3d81940a7c 2500w" />
</Frame>

Then, you can start upserting and querying raw text data without any extra
setup.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        [("id-0", "Upstash is a serverless data platform.", {"field": "value"})],
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert({
      id: "id-0",
      data: "Upstash is a serverless data platform.",
      metadata: {
        field: "value",
      },
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.UpsertData(vector.UpsertData{
    		Id:       "id-0",
    		Data:     "Upstash is a serverless data platform.",
    		Metadata: map[string]any{"field": "value"},
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertData(new DataUpsert(
      id: 'id-0',
      data: 'Upstash is a serverless data platform.',
      metadata: [
        'field' => 'value',
      ],
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert-data \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"id": "1", "data": "Upstash is a serverless data platform.", "metadata": {"field": "value"}}'
    ```
  </Tab>
</Tabs>

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        data="What is Upstash?",
        top_k=1,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({
      data: "What is Upstash?",
      topK: 1,
      includeMetadata: true,
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.QueryData(vector.QueryData{
    		Data:            "What is Upstash?",
    		TopK:            1,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->queryData(new DataQuery(
      data: 'What is Upstash?',
      topK: 1,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "What is Upstash?", "topK": 1, "includeMetadata": "true"}'
    ```
  </Tab>
</Tabs>


# Metadata Filtering
Source: https://upstash.com/docs/vector/features/filtering



You can further restrict the vector similarity search by providing a filter based on a specific metadata criteria.

Queries with metadata filters only return vectors which have metadata matching with the filter.

Upstash Vector allows you to filter keys which have the following value types:

* string
* number
* boolean
* object
* array

Filtering is implemented as a combination of in and post-filtering. Every query is assigned a filtering budget,
determining the number of candidate vectors that can be compared against the filter during query execution. If this
budget is exceeded, the system fallbacks into post-filtering. Therefore, with highly selective filters, fewer
than `topK` vectors may be returned.

## Filter Syntax

A filter has a syntax that resembles SQL, which consists of operators on object keys and boolean operators
to combine them.

Assuming you have a metadata like below:

```json  theme={"system"}
{
    "city": "Istanbul",
    "country": "Turkey",
    "is_capital": false,
    "population": 15460000,
    "geography": {
        "continent": "Asia",
        "coordinates": {
            "latitude": 41.0082,
            "longitude": 28.9784
        }
    },
    "economy": {
        "currency": "TRY",
        "major_industries": [
            "Tourism",
            "Textiles",
            "Finance"
        ]
    }
}
```

Then, you can query similar vectors with a filter like below:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
      url="UPSTASH_VECTOR_REST_URL",
      token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
      vector=[0.9215, 0.3897],
      filter="population >= 1000000 AND geography.continent = 'Asia'",
      top_k=5,
      include_metadata=True
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({
      vector: [0.9215, 0.3897],
      filter: "population >= 1000000 AND geography.continent = 'Asia'",
      topK: 5,
      includeMetadata: true,
    });
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.Query(vector.Query{
    		Vector:          []float32{0.9215, 0.3897},
    		Filter:          `population >= 1000000 AND geography.continent = 'Asia'`,
    		TopK:            5,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.9215, 0.3897],
      topK: 5,
      includeMetadata: true,
      filter: "population >= 1000000 AND geography.continent = 'Asia'",
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
       "vector":[0.9215,0.3897],
       "topK" : 5,
       "filter": "population >= 1000000 AND geography.continent = \"Asia\"",
       "includeMetadata": true
    }'
    ```
  </Tab>
</Tabs>

### Operators

#### Equals (=)

The `equals` operator filters keys whose values are equal to the given literal.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
country = 'Turkey' AND population = 15460000 AND is_capital = false
```

#### Not Equals (!=)

The `not equals` operator filters keys whose values are not equal to the given literal.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
country != 'Germany' AND population != 12500000 AND is_capital != true
```

#### Less Than (\<)

The `less than` operator filters keys whose values are less than the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
population < 20000000 OR geography.coordinates.longitude < 30.0
```

#### Less Than or Equals (\<=)

The `less than or equals` operator filters keys whose values are less than or equal to the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
population <= 20000000 OR geography.coordinates.longitude <= 30.0
```

#### Greater Than (>)

The `greater than` operator filters keys whose values are greater than the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
population > 10000000 OR geography.coordinates.latitude > 39.5
```

#### Greater Than or Equals (>=)

The `greater than or equals` operator filters keys whose values are greater than or equal to the given literal.

It is applicable to *number* values.

```SQL  theme={"system"}
population >= 10000000 OR geography.coordinates.latitude >= 39.5
```

#### Glob

The `glob` operator filters keys whose values match with the given UNIX glob pattern.

It is applicable to *string* values.

It is a case sensitive operator.

The glob operator supports the following wildcards:

* `*` matches zero or more characters.
* `?` matches exactly one character.
* `[]` matches one character from the list
  * `[abc]` matches either `a`, `b`, or `c`.
  * `[a-z]` matches one of the range of characters from `a` to `z`.
  * `[^abc]` matches any one character other than `a`, `b`, or `c`.
  * `[^a-z]` matches any one character other than `a` to `z`.

For example, the filter below would only match with city names whose second character is `s` or `z`,
and ends with anything other than `m` to `z`.

```SQL  theme={"system"}
city GLOB '?[sz]*[^m-z]'
```

#### Not Glob

The `not glob` operator filters keys whose values do not match with the given UNIX glob pattern.

It is applicable to *string* values.

It has the same properties with the glob operator.

For example, the filter below would only match with city names whose first character is anything other than `A`.

```SQL  theme={"system"}
city NOT GLOB 'A*'
```

#### In

The `in` operator filters keys whose values are equal to any of the given literals.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
country IN ('Germany', 'Turkey', 'France')
```

Semantically, it is equivalent to equals operator applied to all of the given literals with `OR` boolean operator in between:

```SQL  theme={"system"}
country = 'Germany' OR country = 'Turkey' OR country = 'France'
```

#### Not In

The `not in` operator filters keys whose values are not equal to any of the given literals.

It is applicable to *string*, *number*, and *boolean* values.

```SQL  theme={"system"}
economy.currency NOT IN ('USD', 'EUR')
```

Semantically, it is equivalent to not equals operator applied to all of the given literals with `AND` boolean operator in between:

```SQL  theme={"system"}
economy.currency != 'USD' AND economy.currency != 'EUR'
```

#### Contains

The `contains` operator filters keys whose values contain the given literal.

It is applicable to *array* values.

```SQL  theme={"system"}
economy.major_industries CONTAINS 'Tourism'
```

#### Not Contains

The `not contains` operator filters keys whose values do not contain the given literal.

It is applicable to *array* values.

```SQL  theme={"system"}
economy.major_industries NOT CONTAINS 'Steel Production'
```

#### Has Field

The `has field` operator filters keys which have the given JSON field.

```SQL  theme={"system"}
HAS FIELD geography.coordinates
```

#### Has Not Field

The `has not field` operator filters keys which do not have the given JSON field.

```SQL  theme={"system"}
HAS NOT FIELD geography.coordinates.longitude
```

### Boolean Operators

Operators above can be combined with `AND` and `OR` boolean operators to form
compound filters.

```SQL  theme={"system"}
country = 'Turkey' AND population > 10000000
```

Boolean operators can be grouped with parentheses to have higher precedence.

```SQL  theme={"system"}
country = 'Turkey' AND (population > 10000000 OR is_capital = false)
```

When no parentheses are provided in ambiguous filters, `AND` will have higher
precedence than `OR`. So, the filter

```SQL  theme={"system"}
country = 'Turkey' AND population > 10000000 OR is_capital = false
```

would be equivalent to

```SQL  theme={"system"}
(country = 'Turkey' AND population > 10000000) OR is_capital = false
```

### Filtering Nested Objects

It is possible to filter nested object keys by referencing them with the `.` accessor.

Nested objects can be at arbitrary depths, so more than one `.` accessor can be used
in the same identifier.

```SQL  theme={"system"}
economy.currency != 'USD' AND geography.coordinates.latitude >= 35.0
```

### Filtering Array Elements

Apart from the `CONTAINS` and `NOT CONTAINS` operators, individual array elements can also
be filtered by referencing them with the `[]` accessor by their indexes.

Indexing is zero based.

```SQL  theme={"system"}
economy.major_industries[0] = 'Tourism'
```

Also, it is possible to index from the back using the `#` character with negative values.
`#` can be thought as the number of elements in the array, so `[#-1]` would reference the
last element.

```SQL  theme={"system"}
economy.major_industries[#-1] = 'Finance'
```

### Miscellaneous

* Identifiers (the left side of the operators) should be of the form `[a-zA-Z_][a-zA-Z_0-9.[\]#-]*`. In simpler terms, they should
  start with characters from the English alphabet or `_`, and can continue with same characters plus numbers and other accessors
  like `.`, `[0]`, or `[#-1]`.
* The string literals (strings in the right side of the operators) can be either single or double quoted.
* Boolean literals are represented as `1` or `0`.
* The operators, boolean operators, and boolean literals are case insensitive.


# Hybrid Indexes
Source: https://upstash.com/docs/vector/features/hybridindexes



Dense indexes are useful to perform semantic searches over
a dataset to find the most similar items quickly. It relies on the
embedding models to generate dense vectors that are similar to each
other for similar concepts. And, they do it well for the
data or the domain of the data that the embedding model is trained on.
But they sometimes fail, especially in the case where the data
is out of the training domain of the model. For such cases, a more traditional
exact search with sparse vectors performs better.

Hybrid indexes allow you to combine the best of these two worlds so that
you can get semantically similar results, and enhance them with exact
token/word matching to make the query results more relevant.

Upstash supports hybrid indexes that manage a dense and a sparse index
component for you. When you perform a query, it queries both the dense
and the sparse index and fuses the results.

## Creating Dense And Sparse Vectors

Since a hybrid index is a combination of a dense and a sparse index,
you can use the same methods you have used for dense and sparse indexes,
and combine them.

Upstash allows you to upsert and query dense and sparse vectors to
give you full control over the models you would use.

Also, to make embedding easier for you, Upstash provides some hosted
models and allows you to upsert and query text data. Behind the scenes,
the text data is converted to dense and sparse vectors.

You can create your index with a dense and sparse embedding model
to use this feature.

## Using Hybrid Indexes

### Upserting Dense and Sparse Vectors

You can upsert dense and sparse vectors into Upstash Vector indexes in two different ways.

#### Upserting Dense and Sparse Vectors

You can upsert dense and sparse vectors into the index as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index, Vector
    from upstash_vector.types import SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        vectors=[
            Vector(id="id-0", vector=[0.1, 0.5], sparse_vector=SparseVector([1, 2], [0.1, 0.2])),
            Vector(id="id-1", vector=[0.3, 0.7], sparse_vector=SparseVector([123, 44232], [0.5, 0.4])),
        ]
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([{
      id: 'id-0',
      vector: [0.1, 0.5],
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
    }])
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	err := index.UpsertMany([]vector.Upsert{
    		{
    			Id:     "id-0",
    			Vector: []float32{0.1, 0.5},
    			SparseVector: &vector.SparseVector{
    				Indices: []int32{1, 2},
    				Values:  []float32{0.1, 0.2},
    			},
    		},
    		{
    			Id:     "id-1",
    			Vector: []float32{0.3, 0.7},
    			SparseVector: &vector.SparseVector{
    				Indices: []int32{123, 44232},
    				Values:  []float32{0.5, 0.4},
    			},
    		},
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;
    use Upstash\Vector\SparseVector;

    use function Upstash\Vector\createRandomVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsert(new VectorUpsert(
      id: 'id-0',
      vector: createRandomVector(384),
      sparseVector: new SparseVector(
        indices: [1, 2, 3],
        values: [5, 6, 7],
      ),
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '[
        {"id": "id-0", "vector": [0.1, 0.5], "sparseVector": {"indices": [1, 2], "values": [0.1, 0.2]}},
        {"id": "id-1", "vector": [0.3, 0.7], "sparseVector": {"indices": [123, 44232], "values": [0.5, 0.4]}}
      ]'
    ```
  </Tab>
</Tabs>

Note that, for hybrid indexes, you have to provide both dense and sparse
vectors. You can't omit one or both.

#### Upserting Text Data

If you created the hybrid index with Upstash-hosted dense and sparse embedding models,
you can upsert text data, and Upstash can embed it behind the scenes.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index, Vector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        vectors=[
            Vector(id="id-0", data="Upstash Vector provides dense and sparse embedding models."),
            Vector(id="id-1", data="You can upsert text data with these embedding models."),
        ]
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([
      {
        id: 'id-0',
        data: "Upstash Vector provides dense and sparse embedding models.",
      }
    ])
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	err := index.UpsertData(vector.UpsertData{
    		Id:   "id-0",
    		Data: "Upstash Vector provides dense and sparse embedding models.",
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertData(new DataUpsert(
      id: 'id-0',
      data: 'Upstash Vector provides dense and sparse embedding models.',
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '[
        {"id": "id-0", "data": "Upstash Vector provides dense and sparse embedding models."},
        {"id": "id-1", "data": "You can upsert text data with these embedding models."}
      ]'
    ```
  </Tab>
</Tabs>

### Querying Dense and Sparse Vectors

Similar to upserts, you can query dense and sparse vectors in two different ways.

#### Querying with Dense and Sparse Vectors

Hybrid indexes can be queried by providing dense and sparse vectors.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        vector=[0.5, 0.4],
        sparse_vector=SparseVector([3, 5], [0.3, 0.5]),
        top_k=5,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({
      vector: [0.5, 0.4],
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
      includeData: true,
      topK: 3,
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.Query(vector.Query{
    		Vector: []float32{0.5, 0.4},
    		SparseVector: &vector.SparseVector{
    			Indices: []int32{3, 5},
    			Values:  []float32{0.3, 05},
    		},
    		TopK:            5,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;
    use Upstash\Vector\SparseVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.5, 0.4],
      sparseVector: new SparseVector(
        indices: [3, 5],
        values: [0.3, 0.5],
      ),
      topK: 5,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector": [0.5, 0.4], "sparseVector": {"indices": [3, 5], "values": [0.3, 0.5]}, "topK": 5, "includeMetadata": true}'
    ```
  </Tab>
</Tabs>

The query results will be fused scores from the dense and sparse indexes.

#### Querying with Text Data

If you created the hybrid index with Upstash-hosted dense and sparse embedding models,
you can query with text data, and Upstash can embed it behind the scenes
before performing the actual query.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        data="Upstash Vector",
        top_k=5,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query(
      {
        data: "Upstash Vector",
        topK: 1,
      },
    )
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.QueryData(vector.QueryData{
    		Data: "Upstash Vector",
    		TopK: 5,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->queryData(new DataQuery(
      data: 'Upstash Vector',
      topK: 5,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "Upstash Vector", "topK": 5}'
    ```
  </Tab>
</Tabs>

### Fusing Dense And Sparse Query Scores

One of the most crucial parts of the hybrid search pipeline is the step
where we fuse or rerank dense and sparse search results.

By default, Upstash returns the hybrid query results by fusing/reranking
the dense and the sparse search results. It provides two fusing algorithms
to choose from to do so.

#### Reciprocal Rank Fusion

RRF is a method for combining results from dense and sparse indexes.
It focuses on the order of results, not their scores. Each result's score
is mapped using the formula:

```
Mapped Score = 1 / (rank + K)
```

Here, rank is the position of the result in the dense or sparse scores, and `K`
is a constant set to `60`.

If a result appears in both the dense and sparse indexes, its mapped scores are
added together. If it appears in only one of the indexes, its score remains unchanged.
After all scores are processed, the results are sorted by their combined scores,
and the top-K results are returned.

RRF effectively combines rankings from different sources, making use of their strengths,
while keeping the process simple and focusing on the order of results.

By default, hybrid indexes use RRF to fuse dense and sparse scores. It can be explicitly
set for queries as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import FusionAlgorithm, SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        vector=[0.5, 0.4],
        sparse_vector=SparseVector([3, 5], [0.3, 0.5]),
        fusion_algorithm=FusionAlgorithm.RRF,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { FusionAlgorithm, Index } from "@upstash/vector";

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    });

    await index.query({
      vector: [0.5, 0.4],
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
      fusionAlgorithm: FusionAlgorithm.RRF,
      topK: 3,
    });
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.Query(vector.Query{
    		Vector: []float32{0.5, 0.4},
    		SparseVector: &vector.SparseVector{
    			Indices: []int32{3, 5},
    			Values:  []float32{0.3, 05},
    		},
    		FusionAlgorithm: vector.FusionAlgorithmRRF,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;
    use Upstash\Vector\SparseVector;
    use Upstash\Vector\Enums\FusionAlgorithm;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.5, 0.4],
      sparseVector: new SparseVector(
        indices: [3, 5],
        values: [0.3, 0.5],
      ),
      topK: 5,
      includeMetadata: true,
      fusionAlgorithm: FusionAlgorithm::RECIPROCAL_RANK_FUSION,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector": [0.5, 0.4], "sparseVector": {"indices": [3, 5], "values": [0.3, 0.5]}, "fusionAlgorithm": "RRF"}'
    ```
  </Tab>
</Tabs>

#### Distribution-Based Score Fusion

DBSF is a method for combining results from dense and sparse indexes by considering
the distribution of scores. Each score is normalized using the formula:

```
                        s ‚àí (Œº ‚àí 3 * œÉ)
Normalized Score = -------------------------
                   (Œº + 3 * œÉ) ‚àí (Œº ‚àí 3 * œÉ)
```

Where:

* `s` is the score.
* `Œº` is the mean of the scores.
* `œÉ` is the standard deviation.
* `(Œº ‚àí 3 * œÉ)` represents the minimum value (lower tail of the distribution).
* `(Œº + 3 * œÉ)` represents the maximum value (upper tail of the distribution).

This formula scales each score to fit between 0 and 1 based on the range defined by
the distribution's tails.

If a result appears in both the dense and sparse indexes, the normalized scores
are added together. For results that appear in only one index, the individual
normalized score is used. After all scores are processed, the results are
sorted by their combined scores, and the top-K results are returned.

Unlike RRF, this approach takes the distribution of scores into account,
making it more sensitive to variations in score ranges from the dense and sparse indexes.

It can be used in hybrid index queries as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import FusionAlgorithm, SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        vector=[0.5, 0.4],
        sparse_vector=SparseVector([3, 5], [0.3, 0.5]),
        fusion_algorithm=FusionAlgorithm.DBSF,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { FusionAlgorithm, Index } from "@upstash/vector";

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    });

    await index.query({
      vector: [0.5, 0.4],
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
      fusionAlgorithm: FusionAlgorithm.DBSF,
      topK: 3,
    });
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.Query(vector.Query{
    		Vector: []float32{0.5, 0.4},
    		SparseVector: &vector.SparseVector{
    			Indices: []int32{3, 5},
    			Values:  []float32{0.3, 05},
    		},
    		FusionAlgorithm: vector.FusionAlgorithmDBSF,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;
    use Upstash\Vector\SparseVector;
    use Upstash\Vector\Enums\FusionAlgorithm;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.5, 0.4],
      sparseVector: new SparseVector(
        indices: [3, 5],
        values: [0.3, 0.5],
      ),
      topK: 5,
      includeMetadata: true,
      fusionAlgorithm: FusionAlgorithm::DISTRIBUTION_BASED_SCORE_FUSION,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector": [0.5, 0.4], "sparseVector": {"indices": [3, 5], "values": [0.3, 0.5]}, "fusionAlgorithm": "DBSF"}'
    ```
  </Tab>
</Tabs>

#### Using a Custom Reranker

For some use cases, you might need something other than RRF or DBSF.
Maybe you want to use the [bge-reranker-v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3),
or any reranker model or algorithm of your choice on the dense and sparse
components of the hybrid index.

For such scenarios, hybrid indexes allow you to perform queries over
only dense and only sparse components. This way, the hybrid index
would return semantically similar vectors from the dense index, and
exact query matches from the sparse index. Then, you can rerank them
as you like.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    dense_results = index.query(
        vector=[0.5, 0.4],
    )

    sparse_results = index.query(
        sparse_vector=SparseVector([3, 5], [0.3, 0.5]),
    )

    # Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    const denseResults = await index.query(
      {
        vector: [0.5, 0.4],
        topK: 3,
      },
    )

    const sparseResults = await index.query(
      {
        sparseVector: {
          indices: [2, 3],
          values: [0.13, 0.87],
        },
        topK: 3,
      },
    )

    // Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	denseScores, err := index.Query(vector.Query{
    		Vector: []float32{0.5, 0.4},
    	})

    	sparseScores, err := index.Query(vector.Query{
    		SparseVector: &vector.SparseVector{
    			Indices: []int32{3, 5},
    			Values:  []float32{0.3, 05},
    		},
    	})

    	// Rerank dense and sparse results as you like here
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;
    use Upstash\Vector\SparseVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $denseResults = $index->query(new VectorQuery(
      vector: [0.5, 0.4],
      topK: 3,
    ));

    $sparseResults = $index->query(new VectorQuery(
      sparseVector: new SparseVector(
        indices: [3, 5],
        values: [0.3, 0.5],
      ),
      topK: 3,
    ));

    // Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector": [0.5, 0.4]}'

    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"sparseVector": {"indices": [3, 5], "values": [0.3, 0.5]}}'
    ```
  </Tab>
</Tabs>

#### Using a Custom Reranker with Text Data

Similar the section above, you might want to use a custom reranker
for the hybrid indexes created with Upstash-hosted embedding models.

For such scenarios, hybrid indexes with Upstash-hosted embedding models
allow you to perform queries over only dense and only sparse components.
This way, the hybrid index would return semantically similar vectors
from the dense index by embedding the text data into a dense vector,
and exact query matches from the sparse index by embedding the text data
into a sparse vector. Then, you can rerank them as you like.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import SparseVector, QueryMode

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    dense_results = index.query(
        data="Upstash Vector",
        query_mode=QueryMode.DENSE,
    )

    sparse_results = index.query(
        data="Upstash Vector",
        query_mode=QueryMode.SPARSE,
    )

    # Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index, QueryMode } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    const denseResults = await index.query({
      data: "Upstash Vector",
      queryMode: QueryMode.DENSE,
    })

    const sparseResults = await index.query({
      data: "Upstash Vector",
      queryMode: QueryMode.SPARSE,
    })

    // Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	denseScores, err := index.QueryData(vector.QueryData{
    		Data:      "Upstash Vector",
    		QueryMode: vector.QueryModeDense,
    	})

    	sparseScores, err := index.QueryData(vector.QueryData{
    		Data:      "Upstash Vector",
    		QueryMode: vector.QueryModeSparse,
    	})

    	// Rerank dense and sparse results as you like here
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;
    use Upstash\Vector\Enums\QueryMode;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $denseResults = $index->queryData(new DataQuery(
      data: 'Upstash Vector',
      topK: 3,
      queryMode: QueryMode::DENSE,
    ));

    $sparseResults = $index->queryData(new DataQuery(
      data: 'Upstash Vector',
      topK: 3,
      queryMode: QueryMode::SPARSE,
    ));

    // Rerank dense and sparse results as you like here
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "Upstash Vector", "queryMode": "DENSE"}'

    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "Upstash Vector", "queryMode": "SPARSE"}'
    ```
  </Tab>
</Tabs>


# Metadata and Data
Source: https://upstash.com/docs/vector/features/metadata



## Metadata

Metadata feature allows you to store context with your vectors to make a connection.
There can be a couple of uses of this:

1. You can put the source of the vector in the metadata to use in your application from the query response.
2. You can put some metadata to further filter the results upon the query.

You can set metadata with your vector as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        [("id-0", [0.9215, 0.3897]), {"url": "https://imgur.com/z9AVZLb"}],
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert({
      "id": "id-0",
      vector: [0.9215, 0.3897],
      metadata: {
        url: "https://imgur.com/z9AVZLb",
      },
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.Upsert(vector.Upsert{
    		Id:       "id-0",
    		Vector:   []float32{0.9215, 0.3897},
    		Metadata: map[string]any{"url": "https://imgur.com/z9AVZLb"},
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;

    use function Upstash\Vector\createRandomVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsert(new VectorUpsert(
      id: 'id-0',
      vector: createRandomVector(384),
      metadata: [
        'url' => "https://imgur.com/z9AVZLb",
      ],
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
       "id":"id-0",
       "vector":[0.9215,0.3897],
       "metadata":{
          "url":"https://imgur.com/z9AVZLb"
       }
    }'
    ```
  </Tab>
</Tabs>

When you do a query or fetch, you can opt-in to retrieve the metadata as follows:

* **Query Example**

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        [0.9215, 0.3897],
        top_k=5,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({
      vector: [0.9215, 0.3897],
      topK: 5,
      includeMetadata: true,
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.Query(vector.Query{
    		Vector:          []float32{0.9215, 0.3897},
    		TopK:            5,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.9215, 0.3897],
      topK: 5,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
       "vector":[0.9215,0.3897],
       "topK" : 5,
       "includeMetadata": true
    }'
    ```
  </Tab>
</Tabs>

```json  theme={"system"}
{
  "result": [
    {
      "id": "id-0",
      "score": 1,
      "metadata": {
        "url": "https://imgur.com/z9AVZLb"
      }
    },
    {
      "id": "id-3",
      "score": 0.99961007,
      "metadata": {
        "url": "https://imgur.com/zfOPmnI"
      }
    }
  ]
}
```

Also, you can filter the results further by providing a metadata filter:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        [0.9215, 0.3897],
        top_k=5,
        include_metadata=True,
        filter="url GLOB '*imgur.com*'",
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({
      vector: [0.9215, 0.3897],
      topK: 5,
      includeMetadata: true,
      filter: "url GLOB '*imgur.com*'",
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.Query(vector.Query{
    		Vector:          []float32{0.9215, 0.3897},
    		TopK:            5,
    		IncludeMetadata: true,
    		Filter:          "url GLOB '*imgur.com*'",
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      vector: [0.9215, 0.3897],
      topK: 5,
      includeMetadata: true,
      filter: "url GLOB '*imgur.com*'",
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
       "vector":[0.9215,0.3897],
       "topK" : 5,
       "includeMetadata": true,
       "filter": "url GLOB \"*imgur.com*\""
    }'
    ```
  </Tab>
</Tabs>

See [Metadata Filtering documentation](/vector/features/filtering) for more details.

* **Range Example**

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.range(
        cursor="0",
        limit=3,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.range({
      cursor: "0",
      limit: 3,
      includeMetadata: true,
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.Range(vector.Range{
    		Cursor:          "0",
    		Limit:           3,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorRange;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->range(new VectorRange(
      limit: 3,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/range \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{ "cursor" : "0",  "limit" : 3, "includeMetadata": true}'
    ```
  </Tab>
</Tabs>

```json  theme={"system"}
{
  "result": {
    "nextCursor": "4",
    "vectors": [
      { "id": "id-0", "metadata": { "url": "https://imgur.com/z9AVZLb" } },
      { "id": "id-1", "metadata": { "url": "https://imgur.com/a2nCEIt" } },
      { "id": "id-2", "metadata": { "url": "https://imgur.com/zfOPmnI" } }
    ]
  }
}
```

## Data

Data is another kind of information you can store per vector
to attribute some context to it. Compared to metadata, it is not
structured, and it can only be fetched in queries, not used
to further filter them.

It is especially useful when you upsert raw text data, so that you
would have access to the textual form of vector along with the
embedded vector values.

It can save you from storing contextual information per vector
in a separate database.

You can set both the metadata and data, or only one of them
while upserting your vectors as follows:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        [
            {
                "id": "id-0",
                "vector": [0.9215, 0.3897],
                "metadata": {"url": "https://imgur.com/z9AVZLb"},
                "data": "data-0",
            },
            {
                "id": "id-1",
                "vector": [0.3897, 0.9215],
                "data": "data-1",
            },
        ],
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([
      {
        id: "id-0",
        vector: [0.9215, 0.3897],
        metadata: {"url": "https://imgur.com/z9AVZLb"},
        data: "data-0",
      },
      {
        id: "id-1",
        vector: [0.3897, 0.9215],
        data: "data-1",
      },
    ])
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertMany([
      new VectorUpsert(
        id: 'id-0',
        vector: [0.9215, 0.3897],
        data: 'data-0',
      ),
      new VectorUpsert(
        id: 'id-1',
        vector: [0.3897, 0.9215],
        data: 'data-1',
      ),
    ]);
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '[
            {
                "id": "id-0",
                "vector": [0.9215, 0.3897],
                "metadata": {"url": "https://imgur.com/z9AVZLb"},
                "data": "data-0"
            },
            {
                "id": "id-1",
                "vector": [0.3897, 0.9215],
                "data": "data-1"
            }
        ]'
    ```
  </Tab>
</Tabs>

When a raw text data is upserted, the data will be set to
the raw text data automatically:

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        [
            {
                "id": "id-2",
                "data": "Upstash is a serverless data platform.",
            },
        ],
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([
      {
        id: "id-2",
        data: "Upstash is a serverless data platform.",
      }
    ])
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertData(new DataUpsert(
      id: 'id-0',
      data: 'Upstash is a serverless data platform.',
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert-data \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
            "id": "id-0",
            "data": "Upstash is a serverless data platform."
          }'
    ```
  </Tab>
</Tabs>

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    result = index.query(
        data="What is Upstash?",
        include_data=True,
    )

    for res in result:
        print(f"{res.id}: {res.data}")
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    const result = await index.query({
      data: "What is Upstash?",
      includeData: true,
      topK: 3
    })

    for (const vector of result) {
      console.log(`${vector.id}: ${vector.data}`)
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $results = $index->queryData(new DataQuery(
      data: 'Upstash is a serverless data platform.',
      topK: 3
      includeData: true,
    ));

    foreach ($results as $result) {
      print_r($result->toArray());
    }
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
            "data": "What is Upstash?",
            "includeData": true,
          }'
    ```
  </Tab>
</Tabs>

Similar to metadata, the data field can be requested in queries, range
iterator, and fetch requests, by setting the `includeData` to `true` as
shown above.


# Namespaces
Source: https://upstash.com/docs/vector/features/namespaces



Upstash Vector allows you to partition a single index into multiple isolated namespaces. Each namespace acts as a self-contained subset of the index, and read and write requests are limited to one namespace.

Each vector index has at least one default namespace and optionally many more.

If no namespace is specified, the operations will use the default namespace, which has the name `""` (empty string).

<Note>
  Indexes created before the namespaces feature can still be used as they are,
  without modification. All operations are assumed to use the default namespace.
</Note>

## Using a Namespace

Namespaces are created implicitly when an upsert operation is performed, so there is no specific endpoint for creating a namespace.

For example, the code snippet below will create the namespace `ns` if it does not already exist, upsert and query the vector only on that namespace.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        [("id-0", [0.9215, 0.3897])],
        namespace="ns",
    )

    index.query(
        [0.9215, 0.3897],
        top_k=5,
        namespace="ns",
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    const namespace = index.namespace("ns")

    await namespace.upsert({
      id: "id-0",
      vector: [0.9215, 0.3897],
    })

    await namespace.query({
      vector: [0.9215, 0.3897],
      topK: 5,
    })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	namespace := index.Namespace("ns")

    	namespace.Upsert(vector.Upsert{
    		Id:     "id-0",
    		Vector: []float32{0.9215, 0.3897},
    	})

    	namespace.Query(vector.Query{
    		Vector: []float32{0.9215, 0.3897},
    		TopK:   5,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;
    use Upstash\Vector\VectorQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $namespace = $index->namespace('ns');

    $namespace->upsert(new VectorUpsert(
      id: 'id-0',
      vector: [0.9215, 0.3897],
    ));

    $namespace->query(new VectorQuery(
      vector: [0.9215, 0.3897],
      topK: 5,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert/ns \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"id":"id-0", "vector":[0.9215,0.3897]}'

    curl $UPSTASH_VECTOR_REST_URL/query/ns \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector":[0.9215,0.3897], "topK" : 5}'
    ```
  </Tab>
</Tabs>

Under the hood, when using a namespace, your requests are sent to `<vector-url>/<command>/namespace-name` to only be executed only against that namespace.

## Deleting a Namespace

Namespaces can be deleted by using the
[Delete Namespace](../api/endpoints/delete-namespace) API.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.delete_namespace("ns")
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.deleteNamespace("ns")
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	namespace := index.Namespace("ns")

    	namespace.DeleteNamespace()
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->namespace('ns')->deleteNamespace();
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/delete-namespace/ns \
      -X DELETE \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
    ```
  </Tab>
</Tabs>

## Listing Namespaces

All active namespaces can be listed by using the
[List Namespaces](../api/endpoints/list-namespaces) API.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.list_namespaces()
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.listNamespaces()
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

    	index.ListNamespaces()
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->listNamespaces();
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/list-namespaces \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN"
    ```
  </Tab>
</Tabs>


# Resumable Query
Source: https://upstash.com/docs/vector/features/resumablequery



When searching for approximate nearest neighbors of a vector with regular query API,
you specify a topK so that the vector index returns at most that many results.

In regular query API, it is not possible to continue the query where it is left off, as
each query runs from start to completion, before returning a response.

However, there might be cases where you want to get the next topK many similar vectors
after running a regular query. Perhaps, you wanted to fetch the next batch of vectors
for the next page of your search functionality.

Resumable query helps you to achieve that. It has the same features as the regular query;
you can specify a filter, get values, metadata or data of the vectors, or specify a topK
value. But, after getting the initial response from the server, it allows you to query
for more, starting from where it left off instead of the start.

## Starting a Resumable Query

Each resumable query starts in this phase. Using our SDKs or the REST API, you can
initiate a resumable query. The filter or flags to include vector values, metadata,
or data will be valid for the entire duration of the resumable query.

When you start the query, the server responds with the first batch of the most
similar vectors and a handle that uniquely identifies the query so that you
can continue the query where you left off.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    result, handle = index.resumable_query(
        vector=[0.1, 0.2],
        top_k=2,
        include_metadata=True,
    )

    # first batch of the results
    for r in result:
        print(r)
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    });

    const { result, fetchNext, stop } = await index.resumableQuery({
      vector: [0.1, 0.2],
      topK: 2,
      includeMetadata: true,
    });

    // first batch of the results
    for (let r of result) {
      console.log(r);
    }
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"fmt"
    	"log"

    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, handle, err := index.ResumableQuery(vector.ResumableQuery{
    		Vector:          []float32{0.1, 0.2},
    		TopK:            2,
    		IncludeMetadata: true,
    	})
    	if err != nil {
    		log.Fatal(err)
    	}

    	defer handle.Close()

    	// first batch of the results
    	for _, score := range scores {
    		fmt.Printf("%+v\n", score)
    	}
    }
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/resumable-query \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
        "vector": [0.1, 0.2],
        "topK": 2,
        "includeMetadata": true
      }'
    ```
  </Tab>
</Tabs>

We support resumable queries with raw vector values as shown above,
or with raw text data for indexes created with Upstash hosted embedding models.

## Resuming the Resumable Query

Using the handle returned by the initial call to resumable query,
you can get the next batch of the most similar vectors, starting
from the last response.

You can fetch as many next batch as possible until you iterate
over the entire index.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    # next batch of the results
    next_result = handle.fetch_next(
        additional_k=3,
    )

    for r in next_result:
        print(r)

    # it is possible to call fetch_next more than once
    next_result = handle.fetch_next(
        additional_k=5,
    )

    for r in next_result:
        print(r)
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    // next batch of the results
    let nextResult = await fetchNext(3);

    for (let r of nextResult) {
      console.log(r);
    }

    // it is possible to call fetch_next more than once
    nextResult = await fetchNext(3);

    for (let r of nextResult) {
      console.log(r);
    }
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    // next batch of the results
    scores, err = handle.Next(vector.ResumableQueryNext{
    	AdditionalK: 3,
    })
    if err != nil {
    	log.Fatal(err)
    }

    for _, score := range scores {
    	fmt.Printf("%+v\n", score)
    }

    // it is possible to call Next more than once
    scores, err = handle.Next(vector.ResumableQueryNext{
    	AdditionalK: 5,
    })
    if err != nil {
    	log.Fatal(err)
    }

    for _, score := range scores {
    	fmt.Printf("%+v\n", score)
    }
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/resumable-query-next \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
        "uuid": "550e8400-e29b-41d4-a716-446655440000",
        "additionalK": 3
      }'
    ```
  </Tab>
</Tabs>

## Stopping the Resumable Query

Each resumable query requires us to maintain a state in the server.
So, there is a limit for the maximum number of active resumable queries
at a time.

That's why it is important to stop the resumable query once you are
done with it.

Resumable queries can be stopped using the handle returned with the
initial call.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    handle.stop()
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    await stop();
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    handle.Close()
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/resumable-query-end \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
        "uuid": "550e8400-e29b-41d4-a716-446655440000"
      }'
    ```
  </Tab>
</Tabs>

We periodically scan resumable queries to stop the idle ones, so
queries that have not touched for some time are stopped automatically.

By default, the max idle time of a resumable query is 1 hour.
You can configure this behavior by specifying a max idle time in seconds
while starting the resumable query.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    result, handle = index.resumable_query(
        vector=[0.1, 0.2],
        top_k=2,
        include_metadata=True,
        max_idle = 7200, # two hours, in seconds
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    const { result, fetchNext, stop } = await index.resumableQuery({
      vector: [0.1, 0.2],
      topK: 2,
      includeMetadata: true,
      maxIdle: 7200, // two hours, in seconds
    });
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    scores, handle, err := index.ResumableQuery(vector.ResumableQuery{
    	Vector:          []float32{0.1, 0.2},
    	TopK:            2,
    	IncludeMetadata: true,
    	MaxIdle:         7200, // two hours, in seconds
    })
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/resumable-query \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{
        "vector": [0.1, 0.2],
        "topK": 2,
        "includeMetadata": true,
        "maxIdle": 7200
      }'
    ```
  </Tab>
</Tabs>


# Vector Similarity Functions
Source: https://upstash.com/docs/vector/features/similarityfunctions



When creating a vector index in Upstash Vector, you have the flexibility to choose from different vector similarity functions.
Each function yields distinct query results, catering to specific use cases. Here are the three supported similarity functions:

<Note>
  The score returned from query requests is a normalized value between 0 and 1,
  where 1 indicates the highest similarity and 0 the lowest regardless of the
  similarity function used.
</Note>

#### Cosine Similarity

Cosine similarity measures the cosine of the angle between two vectors. It is particularly useful when the magnitude of the vectors is not essential, and the focus is on the orientation.

**Use Cases:**

* **Natural Language Processing (NLP):** Ideal for comparing document embeddings or word vectors, as it captures semantic similarity irrespective of vector magnitude.
* **Recommendation Systems:** Effective in recommending items based on user preferences or content similarities.

**Score calculation:**
` (1 + cosine_similarity(v1, v2)) / 2;`

<Frame>
  <img className="block h-32 dark:hidden" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8cf075d97fdf99a8e2c8403e6c543fe2" data-og-width="264" width="264" data-og-height="39" height="39" data-path="img/vector/cosine_similarity.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=fc9c55f0c2ef40319c067f0c0140e763 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b9ea803a48a5292e96c7e724369e841a 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ac427776c3faa8f2f2810aa7d7525220 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0a599eb292d63b7d2e11f76be7ce13d8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=404858ef18bb054d8738a7a76eccc8cd 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c7cad49ae65f9a5edcc84a666dbd04da 2500w" />

  <img className="hidden h-32 dark:block" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=23f03f96f01b2d805ec8f6fd58030379" data-og-width="264" width="264" data-og-height="39" height="39" data-path="img/vector/cosine_similarity_dark.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a15381d917323dc84b0624b65c012d51 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8af75547873d319b3b1f3981d4ecfa24 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4e2d899566e38cbcfd7ac9f9e556be9a 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a9d2bf461b2432bb7f5d86a47e0ac61a 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=6212d67189ad29dd726b8b04f282883b 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/cosine_similarity_dark.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=749c46c7c0d8f80f2e4ba1442019972c 2500w" />
</Frame>

#### Euclidean Distance

Euclidean distance calculates the straight-line distance between two vectors in a multi-dimensional space. It is well-suited for scenarios where the magnitude of vectors is crucial, providing a measure of their spatial separation.

**Use Cases:**

* **Computer Vision:** Useful in image processing tasks, such as image recognition or object detection, where the spatial arrangement of features is significant.
* **Anomaly Detection:** Valuable for detecting anomalies in datasets, as it considers both the direction and magnitude of differences between vectors.

**Score calculation:**
`1 / (1 + squared_distance(v1, v2))`

<Frame>
  <img className="block h-32 dark:hidden" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=782afbe41e09f96b97b241cae539e398" data-og-width="248" width="248" data-og-height="52" height="52" data-path="img/vector/squared_distance.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=090f5f6527896ecc0f23798cdfeaba62 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=98d871d3ce08641a13143d3dd1a9233a 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c6dba07d3d3ab3eda1c04ee9455764e0 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c520f8847b53f4710e4b920ca34bebe7 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=db74ae03fb53ff3515a79ca3b0c7b4c1 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=daadb06cb259ef8acba628d02988a5c4 2500w" />

  <img className="hidden h-32 dark:block" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f540c058c1caee45ea45d79f759acb95" data-og-width="248" width="248" data-og-height="52" height="52" data-path="img/vector/squared_distance_dark.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=545ef97a82e1c287792c3505e42906a3 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8ce578734f1ca31eb5790f399380d98a 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b3a09be6a9a328f7c1fd6378d9a67754 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0b2f49ba96a5713ac1fda54fe6baa221 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=82b2ff2edff62b041376d303cbb34e79 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/squared_distance_dark.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c3f1014519582c08b34443aebfc72c59 2500w" />
</Frame>

#### Dot Product

The dot product measures the similarity by multiplying the corresponding components of two vectors and summing the results. It provides a measure of alignment between vectors.
Note that to use dot product, the vectors needs to be normalized to be of unit length.

**Use Cases:**

* **Machine Learning Models:** Commonly used in machine learning for tasks like sentiment analysis or classification, where feature alignment is critical.
* **Collaborative Filtering:** Effective in collaborative filtering scenarios, such as recommending items based on user behavior or preferences.

**Score calculation:**
` (1 + dot_product(v1, v2)) / 2`

<Frame>
  <img className="block h-32 dark:hidden" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3653225a6b17f76ae995316f8fa414d1" data-og-width="172" width="172" data-og-height="52" height="52" data-path="img/vector/dot_product.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d44c8bca574c139b1fa58ca65df5da70 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f18b611ba2a8663bb24688fe35fabbd4 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a718830873df76c2e7f0de7af31e68d0 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2ba62dfa3f53beabe2dc123263f7c7c4 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4e0e51eab3ec519c57071129972f5bab 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8a90dee80fe1a3712eb3d5f13cb984ba 2500w" />

  <img className="hidden h-32 dark:block" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=6f5375475124b8c2ffe6db5c1052d0f8" data-og-width="172" width="172" data-og-height="52" height="52" data-path="img/vector/dot_product_dark.svg" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3cfe09c3f8b784ef820f79f8f2da27b0 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=848249d0f130138b27e01f4fb92306d2 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=9cd18d2d67215e24fc08843b482461ee 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c28f0db887d2b9e34e915c3fee0ad2d8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=1c9c29c2098e9a5c0315d7be64b72130 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/dot_product_dark.svg?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2cc637a916fedaf4bafc156d023f4d11 2500w" />
</Frame>


# Sparse Indexes
Source: https://upstash.com/docs/vector/features/sparseindexes



Sparse vectors are representations in a high-dimensional space,
where only a small number of dimensions have non-zero values.

For example, for the same text, a dense vector representation with
the BGE-M3 model would have 1024 non-zero valued dimensions.
However, the sparse vector representation of the same text would
have less than a hundred non-zero valued dimensions, whereas vector
space potentially has more than 250 thousand dimensions. Also, unlike
dense vector representations, sparse vectors might have varying
non-zero valued dimensions depending on the text.

Generally, sparse vectors can be represented with two arrays of equal
sizes:

* The first array for the indices contains the indices of the non-zero
  dimensions.
* The second array for values contains the floating point values for
  the non-zero dimensions.

```python  theme={"system"}
dense = [0.1, 0.3, , ...thousands of non-zero values..., 0.5, 0.2]

sparse = (
    [23, 42, 5523, 123987, 240001], # some low number of dimension indices
    [0.1, 0.3, 0.1, 0.2, 0.5], # non-zero values corresponding to dimensions
)
```

Unlike dense vectors which excel at approximate semantic matching,
sparse vectors are particularly useful for tasks that require exact or
near exact matching of tokens/words/features. That makes it useful
for various tasks, such as:

* **Information Retrieval and Text Analysis**: By representing documents
  as sparse vectors where each token/word would correspond to a dimension
  in high dimensional vocabulary; and varying values by the frequencies
  of the tokens/words in the document or by weighting them with inverse
  document frequencies to favor rare terms, you can build complex
  search pipelines.
* **Recommender Systems**: By representing user interactions, preferences,
  ratings, or purchases as sparse vectors, you can identify relevant
  recommendations, and personalize content delivery.

## Creating Sparse Vectors

There are various ways to create sparse vectors. You can use
[BM25](https://en.wikipedia.org/wiki/Okapi_BM25) for information
retrieval tasks, or use models like [SPLADE](https://github.com/naver/splade)
that enhance documents and queries with term weighting and expansion.

Upstash gives you full control by allowing you to upsert and query
sparse vectors.

Also, to make embedding easier for you, Upstash provides some hosted
models and allows you to upsert and query text data. Behind the scenes,
the text data is converted to sparse vectors.

You can create your index with a sparse embedding model to use this feature.

### BGE-M3 Sparse Vectors

BGE-M3 is a multi-functional, multi-lingual, and multi-granular model
widely used for dense indexes.

We also provide BGE-M3 as a sparse vector embedder, which outputs
sparse vectors from `250_002` dimensional space.

These sparse vectors have values where each token is weighted
according to the input text, which enhances traditional sparse vectors
with contextuality.

### BM25 Sparse Vectors

BM25 is a popular algorithm used in full-text search systems to rank
documents based on their relevance to a query.

This algorithm relies on key principles of term frequency,
inverse document frequency, and document length normalization,
making it well-suited for text retrieval tasks.

* **Rare terms are important**: BM25 gives more weight to words that are
  less common in the collection of documents. For example, in a search
  for ‚ÄúUpstash Vector‚Äù, the word ‚ÄúUpstash‚Äù might be considered more
  important than ‚ÄúVector‚Äù if it appears less frequently across all documents.
* **Repeating a Word Helps‚ÄîBut Only Up to a Point**: BM25 considers how
  often a word appears in a document, but it limits the benefit of repeating
  the word too many times. This means mentioning ‚ÄúUpstash‚Äù a hundred times
  won‚Äôt make a document overly important compared to one that mentions
  it just a few times.
* **Shorter Documents Often Rank Higher**: Shorter documents that match
  the query are usually more relevant. BM25 adjusts for document length
  so longer documents don‚Äôt get unfairly ranked just because they contain
  more words.

Upstash provides a general purpose BM25 algorithm, that applies to documents
and queries in English. It tokenizes the text into words, removes stop words,
stems the remaining words, and assigns a weighted value to them, based on the
BM25 formula:

```
                       IDF(q·µ¢) * f(q·µ¢, D) * (k‚ÇÅ + 1)
BM25(D, Q) = Œ£ ----------------------------------------------
               f(q·µ¢, D) + k‚ÇÅ * (1 - b + b * (|D| / avg(|D|)))
```

Where:

* `f(q·µ¢, D)` is the frequency of term `q·µ¢` in document `D`.
* `|D|` is the length of document `D`.
* `avg(|D|)` is the average document length in the collection.
* `k‚ÇÅ` is the term frequency saturation parameter.
* `b` is the length normalization parameter.
* `IDF(q·µ¢)` is the inverse document frequency of term `q·µ¢`

To make it a general purpose model, we had to decide on some of the
constants mentioned above, which would differ from implementation
to implementation. We decided to use the following values for

* `k‚ÇÅ` = `1.2`, a widely used value in the absence of advanced optimizations
* `b` = `0.75`, a widely used value in the absence of advanced optimizations
* `avg(|D|)` = `32`, which was chosen by tokenizing and taking the average of
  [MSMARCO](https://microsoft.github.io/msmarco/) dataset vectors, rounded
  to the nearest power of two.

In the future, we might provide support for more languages and the ability to
provide different values for the above constants.

As for the inverse document frequency `IDF(q·µ¢)`, we maintain that information
per token in the vector database itself. You can use it by providing it
as the weighting strategy for your queries so that you don't have to weight
it yourself.

## Using Sparse Indexes

### Upserting Sparse Vectors

You can upsert sparse vectors into Upstash Vector indexes in two different ways.

#### Upserting Sparse Vectors

You can upsert sparse vectors by representing them as two arrays of equal
sizes. One signed 32-bit integer array for non-zero dimension indices,
and one 32-bit float array for the values.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index, Vector
    from upstash_vector.types import SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        vectors=[
            Vector(id="id-0", sparse_vector=SparseVector([1, 2], [0.1, 0.2])),
            Vector(id="id-1", sparse_vector=SparseVector([123, 44232], [0.5, 0.4])),
        ]
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([{
      id: 'id-0',
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
    }])
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	err := index.UpsertMany([]vector.Upsert{
    		{
    			Id: "id-0",
    			SparseVector: &vector.SparseVector{
    				Indices: []int32{1, 2},
    				Values:  []float32{0.1, 0.2},
    			},
    		},
    		{
    			Id: "id-1",
    			SparseVector: &vector.SparseVector{
    				Indices: []int32{123, 44232},
    				Values:  []float32{0.5, 0.4},
    			},
    		},
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;
    use Upstash\Vector\SparseVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertMany([
      new VectorUpsert(
        id: 'id-0',
        sparseVector: new SparseVector(
          indices: [1, 2],
          values: [0.1, 0.2],
        ),
      ),
      new VectorUpsert(
        id: 'id-1',
        sparseVector: new SparseVector(
          indices: [123, 44232],
          values: [0.5, 0.4],
        ),
      ),
    ]);
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '[
        {"id": "id-0", "sparseVector": {"indices": [1, 2], "values": [0.1, 0.2]}},
        {"id": "id-1", "sparseVector": {"indices": [123, 44232], "values": [0.5, 0.4]}}
      ]'
    ```
  </Tab>
</Tabs>

Note that, we do not allow sparse vectors to have more than `1_000` non-zero valued dimension.

#### Upserting Text Data

If you created the sparse index with an Upstash-hosted sparse embedding model,
you can upsert text data, and Upstash can embed it behind the scenes.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index, Vector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.upsert(
        vectors=[
            Vector(id="id-0", data="Upstash Vector provides sparse embedding models."),
            Vector(id="id-1", data="You can upsert text data with these embedding models."),
        ]
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert([
      {
        id: 'id-0',
        data: "Upstash Vector provides dense and sparse embedding models.",
      }
    ])
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	err := index.UpsertDataMany([]vector.UpsertData{
    		{
    			Id:   "id-0",
    			Data: "Upstash Vector provides sparse embedding models.",
    		},
    		{
    			Id:   "id-1",
    			Data: "You can upsert text data with these embedding models.",
    		},
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->upsertDataMany([
      new DataUpsert(
        id: 'id-0',
        data: 'Upstash Vector provides sparse embedding models.',
      ),
      new DataUpsert(
        id: 'id-1',
        data: 'You can upsert text data with these embedding models.',
      ),
    ]);
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '[
        {"id": "id-0", "data": "Upstash Vector provides sparse embedding models."},
        {"id": "id-1", "data": "You can upsert text data with these embedding models."}
      ]'
    ```
  </Tab>
</Tabs>

### Querying Sparse Vectors

Similar to upserts, you can query sparse vectors in two different ways.

#### Querying with Sparse Vectors

You can query sparse vectors by representing the sparse query vector
as two arrays of equal sizes. One signed 32-bit integer array for
non-zero dimension indices, and one 32-bit float array for the values.

We use the inner product similarity metric while calculating the
similarity scores, only considering the matching non-zero valued
dimension indices between the query vector and the indexed vectors.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import SparseVector

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        sparse_vector=SparseVector([3, 5], [0.3, 0.5]),
        top_k=5,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query(
      {
        sparseVector: {
          indices: [2, 3],
          values: [0.13, 0.87],
        },
        includeData: true,
        topK: 3,
      },
    )
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.Query(vector.Query{
    		SparseVector: &vector.SparseVector{
    			Indices: []int32{3, 5},
    			Values:  []float32{0.3, 05},
    		},
    		TopK:            5,
    		IncludeMetadata: true,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;
    use Upstash\Vector\SparseVector;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->query(new VectorQuery(
      sparseVector: new SparseVector(
        indices: [3, 5],
        values: [0.3, 0.5],
      ),
      topK: 5,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"sparseVector": {"indices": [3, 5], "values": [0.3, 0.5]}, "topK": 5, "includeMetadata": true}'
    ```
  </Tab>
</Tabs>

Note that, the similarity scores are exact, not approximate. So, if there
are no vectors with one or more matching non-zero valued dimension indices with
the query vector, the result might be less than the provided top-K value.

#### Querying with Text Data

If you created the sparse index with an Upstash-hosted sparse embedding model,
you can query with text data, and Upstash can embed it behind the scenes
before performing the actual query.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        data="Upstash Vector",
        top_k=5,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index } from "@upstash/vector"

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query(
      {
        data: "Upstash Vector",
        topK: 1,
      },
    )
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.QueryData(vector.QueryData{
    		Data: "Upstash Vector",
    		TopK: 5,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->queryData(new DataQuery(
      data: 'Upstash Vector',
      topK: 5,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "Upstash Vector", "topK": 5}'
    ```
  </Tab>
</Tabs>

#### Weighting Query Values

For algorithms like BM25, it is important to take the inverse
document frequencies that make matching rare terms more important
into account. It might be tricky to maintain that information
yourself, so Upstash Vector provides it out of the box. To make use
of IDF in your queries, you can pass it as a weighting strategy.

Since this is mainly meant to be used with BM25 models, the IDF
is defined as:

```
IDF(q·µ¢) = log((N - n(q·µ¢) + 0.5) / (n(q·µ¢) + 0.5))
```

* `N` is the total number of documents in the collection.
* `n(q·µ¢)` is the number of documents containing term `q·µ¢`.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index
    from upstash_vector.types import WeightingStrategy

    index = Index(
        url="UPSTASH_VECTOR_REST_URL",
        token="UPSTASH_VECTOR_REST_TOKEN",
    )

    index.query(
        data="Upstash Vector",
        top_k=5,
        weighting_strategy=WeightingStrategy.IDF,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```js  theme={"system"}
    import { Index, WeightingStrategy } from "@upstash/vector";

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    });

    await index.query({
      sparseVector: {
        indices: [2, 3],
        values: [0.13, 0.87],
      },
      weightingStrategy: WeightingStrategy.IDF,
      topK: 3,
    });
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    package main

    import (
    	"github.com/upstash/vector-go"
    )

    func main() {
    	index := vector.NewIndex(
    		"UPSTASH_VECTOR_REST_URL",
    		"UPSTASH_VECTOR_REST_TOKEN",
    	)

    	scores, err := index.QueryData(vector.QueryData{
    		Data:              "Upstash Vector",
    		TopK:              5,
    		WeightingStrategy: vector.WeightingStrategyIDF,
    	})
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\DataQuery;
    use Upstash\Vector\Enums\WeightingStrategy;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN',
    );

    $index->queryData(new DataQuery(
      data: 'Upstash Vector',
      topK: 5,
      weightingStrategy: WeightingStrategy::INVERSE_DOCUMENT_FREQUENCY,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query-data \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"data": "Upstash Vector", "topK": 5, "weightingStrategy": "IDF"}'
    ```
  </Tab>
</Tabs>


# FAQ
Source: https://upstash.com/docs/vector/help/faq



**Account and Usage:**

* **What is the maximum number of indexes I can create in my account?**

  You can create up to 10 indexes per account. For additional needs, please send us an email to  [support@upstash.com](mailto:support@upstash.com)

* **What is the maximum dimension I can set for my indexes?**

  For the free tier, the maximum dimension can be 1536, for fixed and pay as you go tiers, this can be 3072, and for the pro tier, this can go up to 5376

* **How do you calculate the storage to be charged?**

  Storage is a sum of vector storage, metadata, and data storage. Vector storage depends on the number of dimensions and the number of vectors in that index. Each dimension is estimated to be 4 bytes, resulting in vector storage being calculated as vector count \* dimension count \* 4 bytes. For metadata and data storage, it is calculated based on the vector count in an index multiplied by the average metadata and data size, which can be up to 48 Kbytes and 1 Mbytes respectively.

* **What happens when I exceed my Metadata / Data Storage limit?**

  Metadata / Data Storage has a soft limit, and you will receive an email reminder to optimize your index for optimal performance if you approach this limit. The storage cost remains at \$0.25 per GB. For enhanced performance, we recommend upgrading to Pro tier that meets your requirements, which includes incremental metadata and data storage

* **What happens when I exceed bandwidth limit of 200GB?**

  When you exceed the 200GB monthly bandwidth limit, you will be charged at \$0.03 per GB for the additional usage. The initial 200GB is provided free of charge.

* **If I upload my dataset for pay as you go tier and don‚Äôt have any read/write operation during the month, how much will I pay?**

  You will only be charged for the storage of your index and metadata at a rate of \$0.25 per GB. There are no hourly charges for having an index created on Upstash

* **How do you count Updates and Queries for billing purposes?**

  We charge \$0.40 per 100,000 operations, which includes ranges, queries, fetches, upserts and deletes, all counted equally. Ranges, Queries and Fetches are all categorized as query type of operation, whereas Upserts and Deletes are counted as updates. If upsert and delete operations involve multiple vectors at a time, the billable request count will be equal to number of vectors upserted or deleted at one request.

* **If an update/query return or insert multiple vectors at a time, will each vector be counted as separate operations or will that be counted as one operation for billing purposes?**

  For the query type of operations, irrespective of the number of vectors involved in it, we count the operation as one and bill accordingly. For example, a fetch operation can return 10 vectors, and this will be counted only as 1 operation for billing purposes. However for update operations (upsert and delete), number of vectors involved in the operations is reflected as billable request count. For example a batch upsert of 1000 vectors is counted as 1000 billable request.

* **What is the maximum number of vectors I can have in an index?**

  The maximum number of vectors in an index depends on the dimension size. Every plan has a max vector\*dimension limit. For pay as you go tier, this limit is set at 2 billion. For instance, under this plan a user can have an index with a size of 5 million vectors and a vector dimension of 400. For details about the limits of each plan, check our pricing page.

**Functionality:**

* **Do you support hybrid search?**

  We don‚Äôt support hybrid search at the moment. Although this is in our roadmap we still haven‚Äôt finalized the approach to help our users eliminate the need to have a secondary database for better search result. As we define our approach on implementing hybrid search and gather more user feedback, we will share this through our blog posts

* **Can I filter by metadata?**

  Yes, see [Metadata Filtering](../features/filtering).

* **Do you support replication?**

  Replication is not supported in the current release, but we are actively working on including it in our upcoming release.

* **If I do not specify a UUID during adding vectors, will Upstash Vector create one automatically?**

  No, ID field is required and cannot be an empty string while inserting vectors to your index

**Data Management:**

* **How can I upload a large dataset quickly?**

  You can perform batch inserts to upload datasets more efficiently. You don't need a separate batch specific operation to insert multiple vectors. The 'upsert' operation accepts either a single vector or an array of vectors. We recommend using an array size of up to 1000 for efficient batch inserts. For more details, please refer to the documentation

* **How can I remove a metadata field from a vector?**

  You need to run Upsert¬†function on the same vector ID to remove existing metadata fields from a vector. Check our  documentation on using¬†`Upsert`,

**Infrastructure and Availability:**

* **Which cloud provider is Upstash Vector hosted on?**

  Upstash is currently offered on AWS. We have plans to expand it to other cloud providers, please reach out [support@upstash.com](mailto:support@upstash.com) to raise this request as this will help us prioritize accordingly.

* **In what regions is Upstash available?**

  Upstash Vector is currently available in two regions; AWS us-east1 and AWS eu-west-1. We are in the process of expanding to more regions where other Upstash products are currently offered.

* **Should I be on AWS to be able to use Upstash Vector?**

  No. Your client can be anywhere but the clients in AWS regions will give you better performance.

**Feature Request and Upgrade:**

* **How can I request a feature during this beta release?**

  Please reach out to [support@upstash.com](mailto:support@upstash.com). You can also raise your feature request through our chatbot, located at the bottom of Upstash page. The chatbot will guide you through the process of submitting your feature request.

* **How to upgrade from free tier to pay-as-you-go tier?**

  To upgrade from the free tier to the pay-as-you-go tier, simply enter your credit card information. This will automatically upgrade your account to the pay-as-you-go tier, allowing you to take advantage of the additional features and capabilities.


# Vercel AI SDK with Upstash Vector
Source: https://upstash.com/docs/vector/integrations/ai-sdk



The [AI SDK](https://sdk.vercel.ai/docs/introduction) is a TypeScript toolkit designed to help developers build AI-powered applications using React, Next.js, Vue, Svelte, Node.js, and more.

Upstash Vector integrates with the AI SDK to provide AI applications with the benefits of vector databases, enabling applications to perform semantic search and RAG (Retrieval-Augmented Generation).

In this guide, we‚Äôll build a RAG chatbot using the AI SDK. This chatbot will be able to both store and retrieve information from a knowledge base. We‚Äôll use Upstash Vector as our vector database, and the OpenAI API to generate responses.

## Prerequisites

Before getting started, make sure you have:

* An Upstash account (to upsert and query data)
* An OpenAI API key (to generate responses and embeddings)

## Setup and Installation

We will start by bootstrapping a Next.js application with the following command:

```bash  theme={"system"}
npx create-next-app rag-chatbot --typescript
cd rag-chatbot
```

Next, we will install the required packages using the following command:

<CodeGroup>
  ```bash npm theme={"system"}
  npm install @ai-sdk/openai ai zod @upstash/vector
  ```

  ```bash pnpm theme={"system"}
  pnpm install @ai-sdk/openai ai zod @upstash/vector
  ```

  ```bash bun theme={"system"}
  bun install @ai-sdk/openai ai zod @upstash/vector
  ```
</CodeGroup>

We need to set the following environment variables in our `.env` file:

```bash  theme={"system"}
OPENAI_API_KEY=your_openai_api_key
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
```

You can get your Upstash credentials after creating a Vector Index in the [Upstash Console](https://console.upstash.com).

<Info>
  If you are going to use Upstash hosted embedding models, you should select one of the available options when creating your index. If you are going to use custom embedding models, you should specify the dimensions of your embedding model.
</Info>

## Implementation

**RAG (Retrieval-Augmented Generation)** is the process of enabling the model to respond with information outside of its training data by embedding a user's query, retrieving the relevant source material (chunks) with the highest semantic similarity, and then passing them alongside the initial query as context.

Let's consider a simple example. Initially, a chatbot doesn't know who your favorite basketball player is. During a conversation, I inform the chatbot that my favorite player is Alperen Sengun, and it stores this information in its knowledge base. Later, in another conversation, when I ask, "Who is my favorite basketball player?" the chatbot retrieves this information from the knowledge base and responds with "Alperen Sengun."

### Chunking + Embedding Logic

**Embeddings** are a way to represent the semantic meaning of words and phrases. The larger the input to your embedding, the lower the quality the embedding will be. So, how should we approach long inputs?

One approach would be to use **chunking**. Chunking refers to the process of breaking down a particular source material into smaller pieces. Once your source material is appropriately chunked, you can embed each one and then store the embedding and the chunk together in a database (Upstash Vector in our case).

Using Upstash Vector, you can upsert embeddings generated from a custom embedding model, or you can directly upsert data, and Upstash Vector will generate embeddings for you.

In this guide, we demonstrate both methods‚Äîusing Upstash-hosted embedding models and using a custom embedding model (e.g., OpenAI).

### Using Upstash Hosted Embedding Models

```typescript lib/ai/upstashVector.ts theme={"system"}
import { Index } from '@upstash/vector'

// Configure Upstash Vector client
// Make sure UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN are in your .env
const index = new Index({
  url: process.env.UPSTASH_VECTOR_REST_URL!,
  token: process.env.UPSTASH_VECTOR_REST_TOKEN!,
})

// Chunking logic: split on period
function generateChunks(input: string): string[] {
  return input
    .trim()
    .split('.')
    .filter(i => i !== '')
}

// Upsert
export async function upsertEmbedding(resourceId: string, content: string) {
  const chunks = generateChunks(content)
  
  // Convert each chunk into an Upstash upsert object
  const toUpsert = chunks.map((chunk, i) => ({
    id: `${resourceId}-${i}`,
    data: chunk, // Using the data field instead of vector because embeddings are generated by Upstash
    metadata: {
      resourceId,
      content: chunk, // Store the chunk as metadata to use during response generation
    },
  }))

  await index.upsert(toUpsert)
}

// Query
export async function findRelevantContent(query: string, k = 4) {
  const result = await index.query({
    data: query, // Again, using the data field instead of vector field
    topK: k,
    includeMetadata: true, // Fetch metadata as well
  })

  return result
}
```

So, in this file, we create a function to upsert data into our index, and another function to query our index. While upserting data, we chunk the content into smaller pieces and store those chunks in our index.

This approach is a lot simpler compared to using a custom embedding model, because we don't need to generate embeddings ourselves, Upstash does it for us.

### Using a Custom Embedding Model

Now, let's look at how we can use a custom embedding model. We will use OpenAI's `text-embedding-ada-002` embedding model.

```typescript lib/ai/upstashVector.ts theme={"system"}
import { Index } from '@upstash/vector'
import { embed, embedMany } from 'ai'
import { openai } from '@ai-sdk/openai'

// Configure Upstash Vector client
const index = new Index({
  url: process.env.UPSTASH_VECTOR_REST_URL!,
  token: process.env.UPSTASH_VECTOR_REST_TOKEN!,
})

// Chunking logic: split on period
function generateChunks(input: string): string[] {
  return input
    .trim()
    .split('.')
    .filter(i => i !== '')
}

// Define the embedding model
const embeddingModel = openai.embedding('text-embedding-ada-002')

// Function to generate a single embedding
async function generateEmbedding(value: string): Promise<number[]> {
  const input = value.replaceAll('\\n', ' ')
  const { embedding } = await embed({
    model: embeddingModel,
    value: input,
  })
  return embedding
}

// Function to generate embeddings for multiple chunks
async function generateEmbeddings(
  value: string,
): Promise<Array<{ content: string; embedding: number[] }>> {
  const chunks = generateChunks(value)
  const { embeddings } = await embedMany({
    model: embeddingModel,
    values: chunks,
  })
  return embeddings.map((vector, i) => ({
    content: chunks[i],
    embedding: vector,
  }))
}

// Upsert
export async function upsertEmbeddings(resourceId: string, content: string) {
  // Generate embeddings for each chunk
  const chunkEmbeddings = await generateEmbeddings(content)
  // Convert each chunk into an Upstash upsert object
  const toUpsert = chunkEmbeddings.map((chunk, i) => ({
    id: `${resourceId}-${i}`, // e.g. "abc123-0"
    vector: chunk.embedding,
    metadata: {
      resourceId,
      content: chunk.content,
    },
  }))

  await index.upsert(toUpsert)
}

// Query
export async function findRelevantContent(query: string, k = 4) {
  const userEmbedding = await generateEmbedding(query)
  const result = await index.query({
    vector: userEmbedding,
    topK: k,
    includeMetadata: true,
  })

  return result
}
```

In this approach, we need to generate embeddings ourselves, which is an extra step. But the advantage is that we can use any embedding model we want.

OpenAI's `text-embedding-ada-002` generates embeddings with 1536 dimensions, so the index we created must have 1536 dimensions.

## Create Resource Server Action

We will create a server action to create a new resource and upsert it to the index. This will be used by our chatbot to store information.

```typescript lib/actions/resources.ts theme={"system"}
'use server'

import { z } from 'zod'
import { upsertEmbeddings } from '@/lib/ai/upstashVector'

// A simple schema for incoming resource content
const NewResourceSchema = z.object({
  content: z.string().min(1),
})

// Server action to parse the input and upsert to the index
export async function createResource(input: { content: string }) {
  const { content } = NewResourceSchema.parse(input)

  // Generate a random ID
  const resourceId = crypto.randomUUID()

  // Upsert the chunks/embeddings to Upstash Vector
  await upsertEmbeddings(resourceId, content)

  return `Resource ${resourceId} created and embedded.`
}
```

## Chat API route

This route will act as the ‚Äúbackend‚Äù for our chatbot. The Vercel AI SDK‚Äôs useChat hook will, by default, POST to `/api/chat` with the conversation state. We‚Äôll define that route and specify the AI model, system instructions, and any tools we‚Äôd like the model to use.

```typescript app/api/chat/route.ts theme={"system"}
import { openai } from '@ai-sdk/openai'
import { streamText, tool } from 'ai'
import { z } from 'zod'

// Tools
import { createResource } from '@/lib/actions/resources'
import { findRelevantContent } from '@/lib/ai/upstashVector'

// Allow streaming responses up to 30 seconds
export const maxDuration = 30

export async function POST(req: Request) {
  const { messages } = await req.json()

  const result = streamText({
    // 1. Choose your AI model
    model: openai('gpt-4o'),

    // 2. Pass along the conversation messages from the user
    messages,

    // 3. Prompt the model
    system: `You are a helpful RAG assistant. 
    You have the ability to add and retrieve content from your knowledge base.
    Only respond to the user with information found in your knowledge base.
    If no relevant information is found, respond with: "Sorry, I don't know."`,

    // 4. Provide your "tools": resource creation & retrieving content
    tools: {
      addResource: tool({
        description: `Add new content to the knowledge base.`,
        parameters: z.object({
          content: z.string().describe('The content to embed and store'),
        }),
        execute: async ({ content }) => {
          const msg = await createResource({ content })
          return msg
        },
      }),
      getInformation: tool({
        description: `Retrieve relevant knowledge from your knowledge base to answer user queries.`,
        parameters: z.object({
          question: z.string().describe('The question to search for'),
        }),
        execute: async ({ question }) => {
          const hits = await findRelevantContent(question)
          // Return array of metadata for each chunk
          // e.g. [{ id, score, metadata: { resourceId, content }}, ... ]
          return hits
        },
      }),
    },
  })

  // 5. Return the streaming response
  return result.toDataStreamResponse()
}
```

## Chat UI

Finally, we will implement our chat UI on the home page. We will use the Vercel AI SDK‚Äôs `useChat` hook to render the chat UI. By default, the Vercel AI SDK will POST to `/api/chat` on submit.

```typescript app/page.tsx theme={"system"}
'use client'

import { useChat } from 'ai/react'

export default function Home() {
  // This hook handles message state + streaming from /api/chat
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    // You can enable multi-step calls if you want the model to call multiple tools in one session
    maxSteps: 3,
  })

  return (
    <div className="mx-auto max-w-md py-6">
      <h1 className="text-xl font-bold mb-4">RAG Chatbot with Upstash Vector</h1>
      
      {/* Render messages */}
      <div className="space-y-2 mb-8">
        {messages.map(m => (
          <div key={m.id} className="border p-2 rounded">
            <strong>{m.role}:</strong> 
            <div>
              {/* If the model calls a tool, show which tool it called */}
              {m.content.length > 0 ? (
                m.content
              ) : (
                <i>calling tool: {m?.toolInvocations?.[0]?.toolName}</i>
              )}
            </div>
          </div>
        ))}
      </div>

      {/* Text input */}
      <form onSubmit={handleSubmit} className="flex gap-2">
        <input
          className="flex-1 border rounded px-2 py-1"
          placeholder="Say something..."
          value={input}
          onChange={handleInputChange}
        />
        <button className="px-4 py-1 bg-black text-white rounded" type="submit">
          Send
        </button>
      </form>
    </div>
  )
}
```

## Run the Chatbot

Now, we can run our chatbot with the following command:

```bash  theme={"system"}
npm run dev
```

Here is a screenshot of the chatbot in action:

<Frame caption="Adding information to the knowledge base">
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=caa0f9a7e4f20f11dc9aac90dde07e66" data-og-width="1360" width="1360" data-og-height="1310" height="1310" data-path="img/vector/integrations/ai-sdk/rag-chatbot-1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c0de9314cb8f8b32e6b872b27282ba4f 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=087656281c2df0ee71b72af6bc5e37c1 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a2c3572f5e7972ac82f8db6f89435fe4 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5e0ec709a29777ec03fd75b5dbee422b 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a6219c498a12387d8bc29e494d336417 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-1.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0d479fd57ae198892e8fb6eade707c6b 2500w" />
</Frame>

<Frame caption="Added information can be seen in Upstash Console">
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5b7b06056cafe28e09051099ce5863a8" data-og-width="2062" width="2062" data-og-height="1642" height="1642" data-path="img/vector/integrations/ai-sdk/console.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=49ac05e1f7873ec7dae712d5f4078676 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=9faa9e3ffc36254081e511fde27f6485 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=927dba93d99e781803bdd8d63adfff61 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b6f9775b9f57bbd2e8962de080b677de 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=52d1cd7397a984b9133385c71c2843b2 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/console.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=6da55885ceaa1977f10f6c4fe296a739 2500w" />
</Frame>

<Frame caption="Retrieving information from the knowledge base in another conversation">
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=cfaa2367a1b035638c43789cbf46687e" data-og-width="1096" width="1096" data-og-height="832" height="832" data-path="img/vector/integrations/ai-sdk/rag-chatbot-2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ac763a0e08bc79cee44419e253d414d0 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ea2f88d3134b6ae34767ae95b03dad53 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c48588c71be2033499e5dc2b391be87c 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5694b9bed48250989c0157584ecbeb2a 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=4370a47d8bfa17dff44c967f81f33cd6 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/ai-sdk/rag-chatbot-2.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=7a6cbff3db5a78b2bf73c3995579b351 2500w" />
</Frame>

If you would like to see the entire code of a slightly revised version of this chatbot, you can check out the [GitHub repository](https://github.com/Abdusshh/rag-chatbot-ai-sdk). In this version, the user chooses which embedding model to use through the UI.

## Conclusion

Congratulations! You have successfully created a RAG chatbot that uses Upstash Vector to store and retrieve information. To learn more about Upstash Vector, please visit the [Upstash Vector documentation](/vector).

To learn more about the AI SDK, visit the [Vercel AI SDK documentation](https://sdk.vercel.ai/docs/introduction). While creating this tutorial, we used the [RAG Chatbot guide](https://sdk.vercel.ai/docs/guides/rag-chatbot) created by Vercel, which uses PostgreSQL with pgvector as a vector database. Make sure to check it out if you want to learn how to create a RAG chatbot using pgvector.


# Flowise with Upstash Vector and Redis
Source: https://upstash.com/docs/vector/integrations/flowise



Flowise is an open source low-code tool for developers to build customized LLM orchestration flows & AI agents. With Upstash Vector and Upstash Redis, you can extend your Flowise flows to include semantic search, caching, and conversation memory.

## Install

To get started, you can install Flowise locally using npm. Run:

```bash  theme={"system"}
npm install -g flowise
```

Start Flowise:

```bash  theme={"system"}
npx flowise start
```

Open: [http://localhost:3000](http://localhost:3000)

You also need to set up Upstash services:

1. Create a **Vector Index** in the [Upstash Console](https://console.upstash.com/vector). To learn more about index creation, you can check out [this page](https://docs.upstash.com/vector/overall/getstarted).
2. Create a **Redis Database** in the [Upstash Console](https://console.upstash.com/redis). To learn more about Redis database creation, you can check out [this page](/redis/overall/getstarted).

## Nodes Overview

Flowise supports multiple Upstash integrations. Below are the nodes and their functionalities:

### 1. Upstash Vector Node

Use the **Upstash Vector** node to perform semantic search and store document embeddings. Connect the node to document loaders and embedding components for indexing and querying.

<Frame>
  <img width="400" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2e16b449c650649ad9eb43dfbf73dd61" data-og-width="944" data-og-height="1520" data-path="img/vector/integrations/flowise/vector-node.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=7c2671aafc53cab72b69bac48b1eeeb5 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0acc859973a46c88f510e4bdecb0c6e0 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ce251d9e914a6f5c9959a28a6c086367 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bc953d3bb70dfcaf59814acdc7224933 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=96370edc23725834cc9cf7cee4e17bbf 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/vector-node.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=75707988865124b42159f142d587e5d4 2500w" />
</Frame>

### 2. Upstash Redis Cache Node

The **Upstash Redis Cache** node caches LLM responses in a serverless Redis database.

<Frame>
  <img width="400" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=29fe2a921e26ac2b2fe95870b7be167b" data-og-width="1300" data-og-height="1192" data-path="img/vector/integrations/flowise/cache-node.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5c43b8ebcabbf4c440006155212e6e58 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8baf075e02d0620895841829943b86ea 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=bbf03f13809134617a60d5f6c943e9c6 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a50f298127802a6e55ab092341d8ae35 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=05b4f8c8be9f3c3ef64295ca0779d683 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/cache-node.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b03856afca6a62de3ed0b0a3d85a9db3 2500w" />
</Frame>

### 3. Upstash Redis-Backed Chat Memory Node

The **Upstash Redis-Backed Chat Memory** node summarizes conversations and stores the memory in Redis. This enables persistent, context-aware interactions across multiple sessions.

<Frame>
  <img width="400" src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5df675581ac40ed4ea0a3bb4d37915a2" data-og-width="1146" data-og-height="1602" data-path="img/vector/integrations/flowise/chat-memory-node.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d71367b889d24ae1253cea24bef7fd18 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=955fed5268e0900561e99fbb981e795f 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3ac3bc7a5f37ec677d78f94c82ef3037 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3a4cacbe3799aacf776b5274a1b1e7e6 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=daecd49a5208fda423b4a3620a6a6e97 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/chat-memory-node.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3346c12d18ec3d8a74d499b50d371d7c 2500w" />
</Frame>

## Example Flow

Below is an example flow using Upstash Vector:

<Frame caption="You can use a document loader to upload documents and connect it to the Upstash Vector node for indexing.">
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=97ad1ff7a88bf6dfd60f99dd54071637" data-og-width="2136" width="2136" data-og-height="1544" height="1544" data-path="img/vector/integrations/flowise/flow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c7c7d3097ae887609b8315e0b30ce971 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8cd669a856f13292499a86abbeedc7ac 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c7c828cabd82c11606d5d1153ed54579 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=58b5af8a786f3b82e1de8ec09629023a 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=06bd5dcbb1aa3b4e7d5adaed5ef04a86 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/flowise/flow.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=34be8a588c5d5041ac542899fc3380f6 2500w" />
</Frame>

## Learn More

For more details, visit the [Flowise documentation](https://docs.flowiseai.com/).


# LangChain with Upstash Vector
Source: https://upstash.com/docs/vector/integrations/langchain



You can use LangChain with Upstash Vector to perform semantic search and manage vector embeddings. LangChain is a powerful framework that integrates with vector databases, including Upstash Vector, making it easy to build intelligent applications.

First, we need to create a Vector Index in the [Upstash Console](https://console.upstash.com). To learn more about index creation, you can check out [this page](https://docs.upstash.com/vector/overall/getstarted).

## Install

```bash  theme={"system"}
pip install upstash-vector langchain langchain-community python-dotenv
```

## Usage

```python  theme={"system"}
from dotenv import load_dotenv
from langchain_community.vectorstores.upstash import UpstashVectorStore
from langchain.schema import Document

# Load environment variables
load_dotenv()

# Create a vector store instance
store = UpstashVectorStore(
    embedding=True,  # Embedding option enabled
)

# Sample documents to upload
documents = [
    Document(page_content="Upstash Vector is a scalable vector database."),
    Document(page_content="LangChain is a framework for building intelligent apps."),
    Document(page_content="Semantic search enables advanced query matching."),
]

# Add documents to the Upstash Vector index
store.add_documents(documents)

# Perform a similarity search
query = "What is LangChain?"
results = store.similarity_search(query, k=3)

print("Similarity Search Results:")
for res in results:
    print(res.page_content)
```

### Query Results

```plaintext  theme={"system"}
Similarity Search Results:
LangChain is a framework for building intelligent apps.
Semantic search enables advanced query matching.
Upstash Vector is a scalable vector database.
```

## Features

**Semantic Search**: Retrieve the most contextually relevant results using embeddings and vector similarity.

**Namespace Support**: Separate documents into different namespaces for better organization.

**Metada Filtering**: Metadata can be used to filter the results of a query.

## Notes

* Upstash Vector supports custom embeddings; you can specify an embedding model when initializing `UpstashVectorStore`.
* Use `.env` files to manage your Upstash credentials for secure and reusable configuration.

To learn more, visit the [LangChain documentation](https://python.langchain.com/docs/integrations/vectorstores/upstash/).


# Langflow with Upstash Vector
Source: https://upstash.com/docs/vector/integrations/langflow



Langflow provides an intuitive, visual interface to design LLM workflows. You can seamlessly integrate Upstash Vector into your Langflow projects to enable vector-based semantic search and context retrieval.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ea87c9c85e8f1056936977926f733bfa" data-og-width="3010" width="3010" data-og-height="938" height="938" data-path="img/vector/integrations/langflow/final-workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d0936f6c197eaa5a2b269c615d76aacc 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3febb6b3efad45baefe89f27f6473ff7 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=1e0a279e78bf1bd2faa1cd2f639b8000 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=931c8710ec67580a5a0c1572bc927fc8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e7f63e844cfa54de57408b5a35060913 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8f31bc3e9a675d386beaeb5dad53620c 2500w" />
</Frame>

## Install

To get started, install Langflow and Upstash Vector locally or use the Langflow dashboard from [DataStax](https://www.datastax.com/products/langflow). For local installation, run:

```bash  theme={"system"}
pip install langflow upstash-vector
```

## Usage

### Creating an Upstash Vector Index

Visit the [Upstash Console](https://console.upstash.com/vector) to create a vector index. To learn more about index creation, you can check out [this page](https://docs.upstash.com/vector/overall/getstarted).

### Adding Upstash Vector to Langflow

In Langflow, you can integrate Upstash Vector for document indexing and semantic search. Use the following steps:

1. Create a workflow with the **File**, **Split**, and **Upstash** components to process and store documents in the Upstash Vector index.
2. Perform a vector search by connecting the **Upstash** component to your query input.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a4bc2af35c8ad7c2108ea300dd8c4b43" data-og-width="2228" width="2228" data-og-height="1308" height="1308" data-path="img/vector/integrations/langflow/insert-workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=06f0d1a70ba3c7aa02c8ad47f56b3bfa 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=7524fba40a0ec5b3bfb564a2d021ac69 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8a6d5d6246e66739ca377c731fd2909e 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c133b9d44f1f18161d0d454e71b18907 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a7449fc8666288a9d6d09e62aecbe78d 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/insert-workflow.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=c5b7fe0f66bc88e3dbddbd09b4a1bd61 2500w" />
</Frame>

### Example Workflow

Enhance your chatbot by combining Langflow‚Äôs OpenAI integration with Upstash Vector. Create a RAG workflow to retrieve relevant context from your index and use it to answer user queries.

<Frame>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ea87c9c85e8f1056936977926f733bfa" data-og-width="3010" width="3010" data-og-height="938" height="938" data-path="img/vector/integrations/langflow/final-workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d0936f6c197eaa5a2b269c615d76aacc 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3febb6b3efad45baefe89f27f6473ff7 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=1e0a279e78bf1bd2faa1cd2f639b8000 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=931c8710ec67580a5a0c1572bc927fc8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=e7f63e844cfa54de57408b5a35060913 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/integrations/langflow/final-workflow.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8f31bc3e9a675d386beaeb5dad53620c 2500w" />
</Frame>

## Learn More

For a detailed guide on building a RAG chatbot with Langflow and Upstash Vector, check out this [blog post](https://upstash.com/blog/langflow-upstash-vector).


# LlamaIndex with Upstash Vector
Source: https://upstash.com/docs/vector/integrations/llamaindex



You can use LlamaIndex with Upstash Vector to perform Retrieval-Augmented Generation (RAG). LlamaIndex is a powerful tool that integrates seamlessly with vector databases like Upstash Vector, enabling advanced query and response capabilities.

## Install

```bash  theme={"system"}
pip install llama-index upstash-vector llama-index-vector-stores-upstash python-dotenv
```

## Setup

First, create a Vector Index in the [Upstash Console](https://console.upstash.com). Configure the index with:

* **Dimensions**: 1536
* **Distance Metric**: Cosine

Once the index is created, copy the `UPSTASH_VECTOR_REST_URL` and `UPSTASH_VECTOR_REST_TOKEN` and add them to your `.env` file along with your OpenAI API key:

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
OPENAI_API_KEY=your_openai_api_key
```

## Usage

Here‚Äôs how you can integrate LlamaIndex with Upstash Vector:

```python  theme={"system"}
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.vector_stores.upstash import UpstashVectorStore
from llama_index.core import StorageContext
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set OpenAI API key
openai.api_key = os.environ["OPENAI_API_KEY"]

# Initialize Upstash Vector store
upstash_vector_store = UpstashVectorStore(
    url=os.environ["UPSTASH_VECTOR_REST_URL"],
    token=os.environ["UPSTASH_VECTOR_REST_TOKEN"],
)

# Load documents using SimpleDirectoryReader
documents = SimpleDirectoryReader("./documents/").load_data()

# Create a storage context and initialize the index
storage_context = StorageContext.from_defaults(vector_store=upstash_vector_store)
index = VectorStoreIndex.from_documents(
    documents, storage_context=storage_context
)
```

## Querying

Once the index is created, you can query it to retrieve and generate responses based on document content.

```python  theme={"system"}
# Initialize the query engine
query_engine = index.as_query_engine()

# Perform queries
response_1 = query_engine.query("What is global warming?")
print(response_1)

response_2 = query_engine.query("How can we reduce our carbon footprint?")
print(response_2)
```

## Notes

* You can specify a namespace when creating the `UpstashVectorStore` instance:
  ```python  theme={"system"}
  vector_store = UpstashVectorStore(
      url="your_upstash_url",
      token="your_upstash_token",
      namespace="your_namespace"
  )
  ```

* Visit the [LlamaIndex documentation](https://docs.llamaindex.ai/en/latest) for more details.


# LlamaParse with Upstash Vector
Source: https://upstash.com/docs/vector/integrations/llamaparse



You can use LlamaParse with Upstash Vector to parse documents and perform semantic queries on the content. LlamaParse simplifies the extraction of structured information from files, which can then be indexed and queried using Upstash Vector.

## Install

```bash  theme={"system"}
pip install llama-index upstash-vector llama-index-vector-stores-upstash python-dotenv
```

## Setup

Create a Vector Index in the [Upstash Console](https://console.upstash.com). Set the index with:

* **Dimensions**: 1536
* **Distance Metric**: Cosine

Add the required environment variables to a `.env` file:

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
LLAMA_CLOUD_API_KEY=your_llama_cloud_api_key
```

## Usage

### Parsing Documents

Use LlamaParse to parse a document. For example:

```python  theme={"system"}
from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader

# Initialize the parser
parser = LlamaParse(result_type="markdown")

# Parse a document
file_extractor = {".txt": parser}
documents = SimpleDirectoryReader(
    input_files=["./documents/global_warming.txt"],
    file_extractor=file_extractor
).load_data()
```

### Querying the Parsed Content

Once the document is parsed, you can index it using Upstash Vector and query its content:

```python  theme={"system"}
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.upstash import UpstashVectorStore
from llama_index.core import StorageContext
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()

# Set up Upstash Vector Store
vector_store = UpstashVectorStore(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN")
)

# Create storage context and index the parsed document
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)

# Perform a query
query_engine = index.as_query_engine()
response = query_engine.query("What is the main topic discussed in the document?")
```

To learn more, visit the [LlamaParse documentation](https://docs.cloud.llamaindex.ai/llamaparse/getting_started/get_an_api_key).


# Changelog
Source: https://upstash.com/docs/vector/overall/changelog



<Update label="August 2025">
  * Introduced a new api to [rename a namespace](../api/endpoints/rename-namespace)
</Update>

<Update label="March 2025">
  * Allow deleting vectors with [id prefix](../api/endpoints/delete#param-prefix)
    or [metadata filter](../api/endpoints/delete#param-filter).
  * Allow [fetching](../api/endpoints/fetch#param-prefix)
    and [ranging](../api/endpoints/range#param-prefix) over vectors with id prefix.
</Update>

<Update label="February 2025">
  * Introduced official SDK's for [PHP & Laravel](../sdks/php/getting-started).
</Update>

<Update label="January 2025">
  * Introduced [Sparse and Hybrid indexes](https://upstash.com/blog/sparse-and-hybrid-indexes).
    * [Sparse Indexes](../features/sparseindexes) details.
    * [Hybrid Indexes](../features/hybridindexes) details.
</Update>

<Update label="September 2024">
  * Introduced [resumable query/search](../features/resumablequery) functionality, allowing to initiate and continue queries across multiple api calls.
    * [Typescript SDK](../sdks/ts/commands/resumable-query)
    * [Python SDK](../sdks/py/example_calls/resumable-query)
  * Added embedding latency charts to the Upstash Console vector usage page.
</Update>

<Update label="July 2024">
  Added new [`HAS FIELD`](../features/filtering#has-field) and [`HAS NOT FIELD`](../features/filtering#has-not-field) metadata filtering operators.
</Update>

<Update label="June 2024">
  * Implemented a new feature to store raw data in text format alongside metadata. See [Metadata and Data](../features/metadata#data).
  * Added an API for updating vector, data, or metadata. It's also possible to update the metadata without overwriting all.
    See [Update Vector](../api/endpoints/update) API.
  * Added reset all namespaces API. See [Reset Namespace](../api/endpoints/reset) API.
  * Improved query APIs to send a batch of queries in a single request. See [Query](../api/endpoints/query) API.
</Update>

<Update label="May 2024">
  * Introduced [namespaces feature](/vector/features/namespaces).
  * Added GCP US-Central1 region.
</Update>

<Update label="April 2024">
  Added option to upsert and query raw data using [Upstash embedding service](/vector/features/embeddingmodels).
</Update>

<Update label="February 2024">
  Implemented metadata filtering with SQL-like syntax. See [Metadata Filtering](/vector/features/filtering).
</Update>

<Update label="January 2024">
  [Initial release!](https://upstash.com/blog/introducing-vector-database)
</Update>


# Compare
Source: https://upstash.com/docs/vector/overall/compare



// todo melek


# Getting Started
Source: https://upstash.com/docs/vector/overall/getstarted



<Check>
  **Prerequisite**

  You need an Upstash account before creating a vector, create one
  [here](https://console.upstash.com).
</Check>

## Create an Index

Once you logged in, you can create a Vector Index by clicking on the `Create Index` button in the Vector tab.

<Frame style={{width: '600px'}}>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2c6931f926652c17cd8180638039660f" data-og-width="2106" width="2106" data-og-height="1336" height="1336" data-path="img/vector/getstarted/create_index.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=00ce06ab6cc5ec97cc5a0ec9bd18226f 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=351d1ecc229bbdcb879bf6de756b3bfc 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=b9a5a873ab0f13d92f09a8915e804935 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=fbf2ef3f2be8711c51f34f874b82fbb5 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=a7be1e837b64545349694c121e9abbe3 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/create_index.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=ff88644d1be62548730e82cdb1442ce2 2500w" />
</Frame>

**Name:** Type a name for your index.

**Region:** Choose the region for your index. For optimal performance, select the region closest to your applications. We plan to support additional regions and cloud providers. Feel free to send your requests to [support@upstash.com](mailto:support@upstash.com)

**Type:** The type of index: Dense, [Sparse](/vector/features/sparseindexes) or [Hybrid](/vector/features/hybridindexes). For semantic search, you can prefer dense. For full text (or keyword) search, you can prefer sparse. If you need a combination, you can choose hybrid.

If you choose Dense or Hybrid as index type, you will also be presented with options to select the dimensions and distance metric of your index.

<Tip>
  For the purpose of using the code samples on this page, you can create a dense index with `dimension: 2`. Distance metric can be any of the options.
</Tip>

Once you pick these options, you will choose a plan:

<Frame style={{width: '600px'}}>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0433e99277582c438bf254d08939ae33" data-og-width="2106" width="2106" data-og-height="1336" height="1336" data-path="img/vector/getstarted/select_plan.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=0c7c12c3cff737ef563bae803fc0e679 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=317820b91f3aeb9293a99a083befa9bb 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=7552db149e47e8634affccea5d7f6cbf 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3ae7f7478e89492b5d72ca50d33ced77 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f24e1b2a81faf18c8a19bbc4e1146092 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/select_plan.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=6dcf529363d3d90e2380a15a4a9f7a20 2500w" />
</Frame>

**Free:** The free plan is suitable for small projects. It has a limit of 10,000 queries and 10,000 updates daily.

**Pay as You Go:** Pay as you go plan is a flexible plan with per-request-pricing. It is suitable for projects with unpredictable traffic.

**Fixed:** Fixed plan is suitable for projects with predictable traffic. It has a fixed monthly price with 1M query and 1M updates daily.

**Pro:** Pro plan is suitable for projects with high traffic and storage needs. It has a fixed monthly price with extra security and isolation features.

**Enterprise:** If you plan to have over a billion vectors then Enterprise plan is for you. It has a fixed monthly price with extra security and isolation features. Contact us at [sales@upstash.com](mailto:sales@upstash.com) for more information.

## Insert Index

You can access data in your index using REST API or our SDKs. You can copy the sample code from the `Connect` section in the console.

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(url="UPSTASH_VECTOR_REST_URL", token="UPSTASH_VECTOR_REST_TOKEN")

    index.upsert(
      vectors=[
        ("1", [0.6, 0.8], {"field": "value"}),
      ]
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```ts  theme={"system"}
    import { Index } from "@upstash/vector";

    const index = new Index({
        url: "UPSTASH_VECTOR_REST_URL",
        token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.upsert({ id: "1", vector: [0.6, 0.8], metadata: {field: "value"} })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    import "github.com/upstash/vector-go"

    func main() {
      index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

      index.Upsert(vector.Upsert{
    	  Id:       "1",
    	  Vector:   []float32{0.6, 0.8},
    	  Metadata: map[string]any{"field": "value"},
      })
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorUpsert;

    $index = new Index(
      url: 'UPSTASH_VECTOR_REST_URL',
      token: 'UPSTASH_VECTOR_REST_TOKEN', 
    );

    $index->upsert(new VectorUpsert(
      id: '1',
      vector: [0.6, 0.8],
      metadata: ['field' => 'value'],
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/upsert \
      -X POST \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"id": "1", "vector": [0.6, 0.8], "metadata": {"field": "value"}}'
    ```
  </Tab>
</Tabs>

## Query Index

You can perform a similarity search by providing a query vector as a parameter. The dimension of the query vector must match the dimension of your index. Also, you can query by metadata filtering.

<Note>
  Upstash is eventually consistent, so there may be a delay before the newly inserted or updated vectors are ready for querying.
</Note>

<Tabs>
  <Tab title="Python">
    ```python  theme={"system"}
    from upstash_vector import Index

    index = Index(url="UPSTASH_VECTOR_REST_URL", token="UPSTASH_VECTOR_REST_TOKEN")

    index.query(
        vector=[0.6, 0.8],
        top_k=3,
        include_metadata=True,
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```ts  theme={"system"}
    import { Index } from "@upstash/vector";

    const index = new Index({
      url: "UPSTASH_VECTOR_REST_URL",
      token: "UPSTASH_VECTOR_REST_TOKEN",
    })

    await index.query({ vector: [0.6, 0.8], topK: 3, includeMetadata: true })
    ```
  </Tab>

  <Tab title="Go">
    ```go  theme={"system"}
    import "github.com/upstash/vector-go"

    func main() {
      index := vector.NewIndex("UPSTASH_VECTOR_REST_URL", "UPSTASH_VECTOR_REST_TOKEN")

      index.Query(vector.Query{
    	  Vector:          []float32{0.6, 0.8},
    	  TopK:            3,
    	  IncludeMetadata: true,
      })
    }
    ```
  </Tab>

  <Tab title="PHP">
    ```php  theme={"system"}
    use Upstash\Vector\Index;
    use Upstash\Vector\VectorQuery;

    $index = new Index(
      url: '<UPSTASH_VECTOR_REST_URL>',
      token: '<UPSTASH_VECTOR_REST_TOKEN>',
    );

    $index->query(new VectorQuery(
      vector: [0.6, 0.8],
      topK: 3,
      includeMetadata: true,
    ));
    ```
  </Tab>

  <Tab title="curl">
    ```shell  theme={"system"}
    curl $UPSTASH_VECTOR_REST_URL/query \
      -H "Authorization: Bearer $UPSTASH_VECTOR_REST_TOKEN" \
      -d '{"vector": [0.6, 0.8], "topK": 3, "includeMetadata": "true"}'
    ```
  </Tab>
</Tabs>

## Usage and Data Browser

In Upstash console, you can see the charts of your index:

<Frame style={{width: '600px'}}>
  <img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8046fd9b0d110ee76a345fe41008990f" data-og-width="2106" width="2106" data-og-height="1976" height="1976" data-path="img/vector/getstarted/usage.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=5ecca8c8b40c84375e78b463fbc740ed 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=2c570a5fea80e2cdd76ff7a3fe5b0449 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=34f8011747a690f4066bf4de59427903 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=92ec7ec826b6ff56e5a9c1a5300473b8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=28ca18081a99d08360581f415834fe64 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/usage.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=56dd323ef7257752e304dc425b4a1359 2500w" />
</Frame>

There are following charts:

* **Daily Requests:** The number of queries and updates to your index in the last 5 days.
* **Throughput:** The number of queries and updates to your index in the selected time period.
* **Latency:** The mean and P99 latency of queries and updates to your index in the selected time period.
* **Vector Count:** The number of vectors in your index in the selected time period.
* **Data Size:** The size of your index in the selected time period.

You can also query your index with a simple UI:

<img src="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=697ec948f800623acfab19ea6f094d99" data-og-width="2106" width="2106" data-og-height="1228" height="1228" data-path="img/vector/getstarted/browser.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=280&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=1b4529f8f7ac5121d7aa9227ebc13c70 280w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=560&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=8575b8b2dd65a472a8273b7aed44197b 560w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=840&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=f954d5dce582eb47e15175b4789565b1 840w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=1100&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=3c206a1bd0814b86bbc2a6e3fed338b8 1100w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=1650&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=19afd7f1310c854167eadb114926e0f7 1650w, https://mintcdn.com/upstash/EFJsv57gEAWfBXNv/img/vector/getstarted/browser.png?w=2500&fit=max&auto=format&n=EFJsv57gEAWfBXNv&q=85&s=d9ab19df48dbe2ffe5df2eec08c6e82b 2500w" />


# llms.txt
Source: https://upstash.com/docs/vector/overall/llms-txt





# Pricing & Limits
Source: https://upstash.com/docs/vector/overall/pricing



Please check our [pricing page](https://upstash.com/pricing/vector) for the most up-to-date information on pricing and limits.


# What is Upstash Vector?
Source: https://upstash.com/docs/vector/overall/whatisvector



Upstash Vector is a **serverless vector database designed for high-performance vector search at scale**. It powers advanced systems in areas such as:

* Natural Language Processing (NLP)
* Retrieval Augmented Generation (RAG)
* Recommendation engines
* Image recognition
* Clustering or classification

... without any infrastructure management.

***

## What is a Vector Database?

Vector databases are specifically designed to store and efficiently search high-dimensional vectors. These vectors can represent images, sounds, text, or other media for powerful similarity search across content that traditional databases struggle to represent properly.

Their specialization makes vector stores the perfect foundation for similarity-based search. Using specialized approximation algorithms such as Approximate Nearest Neighbor (ANN), they can typically provide much higher indexing and query performance than general-purpose databases or extensions like pgvector.

***

## Upstash Vector Core Features:

* **High-Performance Queries:** Upstash Vector is powered by DiskANN\[1], a highly efficient approximation algorithm that delivers very high recall rates (resulting in better output quality) and ultra-low latency. See [ANN Search Algorithm](../features/algorithm) for more insight into the technology behind our vector database.

* **Batteries Included:** A convenient REST API and SDKs with first-class Python and TypeScript support.

* **Serverless Pricing:** Upstash Vector is fully managed and serverless, we take care of the hosting and high availability complexities. You only pay for what you actually use. See our [Vector Pricing Page](https://upstash.com/pricing/vector) for more details.

* **Multiple Similarity Functions:** We natively support similarity functions such as Euclidean distance, cosine similarity, and dot product.
  See [Vector Similarity](../features/similarityfunctions) for more details.

* **Metadata Support:** Attach metadata to vectors to store additional information or context. When querying an index, you can then include a metadata filter to limit the search to records that match a filter expression. See [Metadata Documentation](../features/metadata) for more details.

***

### References

1. Subramanya, S. J., Devvrit, Kadekodi, R., Krishaswamy, R., Simhadri, H. V. (2019). *DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node*. In Proceedings of the 33rd International Conference on Neural Information Processing Systems (NeurIPS '19), Article No.: 1233, Pages 13766‚Äì13776. \[[https://dl.acm.org/doi/abs/10.5555/3454287.3455520](https://dl.acm.org/doi/abs/10.5555/3454287.3455520)]


# Go SDK
Source: https://upstash.com/docs/vector/sdk/gosdk





# Semantic Cache JS
Source: https://upstash.com/docs/vector/sdk/semantic-cache-js





# Semantic Cache Python
Source: https://upstash.com/docs/vector/sdk/semantic-cache-py





# Deleting Vectors
Source: https://upstash.com/docs/vector/sdks/php/commands/delete-vectors



You can easily delete vectors from our vector database, ensuring your data remains organized and up-to-date.

Our SDK allows you to delete vector data from indexes and/or namespaces.

## Delete

Every vector in our database has an ID defined by you. This ID is used to reference the vectors you want to delete.

We'll use the `delete()` method to instruct the SDK to delete vectors 1, 2, and 3, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->delete(['1', '2', '3']);
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->delete(['1', '2', '3']);
  ```
</CodeGroup>

### Delete using ID prefixes

In the case that you logically group your vectors by a common prefix, you can delete all those vectors at once using the code below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorDeleteByPrefix;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->delete(new VectorDeleteByPrefix(
    prefix: 'users:',
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorDeleteByPrefix;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->delete(new VectorDeleteByPrefix(
    prefix: 'users:',
  ));
  ```
</CodeGroup>

### Delete using a metadata filter

If you want to delete vectors based on some query result over the metadata, you can use the `VectorDeleteByMetadataFilter` class as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorDeleteByMetadataFilter;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->delete(new VectorDeleteByMetadataFilter(
    filter: 'salary > 1000',
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorDeleteByMetadataFilter;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->delete(new VectorDeleteByMetadataFilter(
    filter: 'salary > 1000',
  ));
  ```
</CodeGroup>

You can read more about [Namespaces](/vector/features/namespaces) on our docs.


# Fetching Vectors
Source: https://upstash.com/docs/vector/sdks/php/commands/fetch



Sometimes, you‚Äôre not just searching for something‚Äîyou know exactly which vector you want to retrieve.

In such cases, you can directly fetch specific vectors from your database.

## Fetch

Each record in Upstash Vector is assigned a unique ID, which you can use to retrieve a specific vector from your database.

Let's use the `fetch()` method to retrieve a vector from Upstash Vector.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorFetch;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->fetch(new VectorFetch(
    ids: ['1', '2'],
    includeMetadata: true, // (optional) if true the fetch results will contain metadata.
    includeVectors: true, // (optional) if true the fetch results will contain the indexed vectors.
    includeData: true, // (optional) if true the fetch results will contain the string data.
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorFetch;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->fetch(new VectorFetch(
    ids: ['1', '2'],
    includeMetadata: true, // (optional) if true the fetch results will contain metadata.
    includeVectors: true, // (optional) if true the fetch results will contain the indexed vectors.
    includeData: true, // (optional) if true the fetch results will contain the string data.
  ));
  ```
</CodeGroup>

The `fetch()` method returns a `Upstash\Vector\VectorFetchResult` object, which allows you to access the results of the query.

### Fetch by ID prefix

You can also use `fetch()` to get all vectors which their IDs match a defined prefix.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorFetchByPrefix;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->fetch(new VectorFetchByPrefix(
    prefix: 'users:',
    includeMetadata: true, // (optional) if true the fetch results will contain metadata.
    includeVectors: true, // (optional) if true the fetch results will contain the indexed vectors.
    includeData: true, // (optional) if true the fetch results will contain the string data.
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorFetchByPrefix;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->fetch(new VectorFetchByPrefix(
    prefix: 'users:',
    includeMetadata: true, // (optional) if true the fetch results will contain metadata.
    includeVectors: true, // (optional) if true the fetch results will contain the indexed vectors.
    includeData: true, // (optional) if true the fetch results will contain the string data.
  ));
  ```
</CodeGroup>


# Info
Source: https://upstash.com/docs/vector/sdks/php/commands/info



Your index contains valuable information that may be useful to retrieve for various purposes.

Our SDK provides the capability to fetch detailed information about your index, including metadata,
ready and pending vectors, similarity function, and associated namespaces.

## Index Info

To fetch the information about your index you can use the `getInfo()` method as shown below.

```php  theme={"system"}
use Upstash\Vector\Index;

$index = new Index(
  url: "<UPSTASH_VECTOR_REST_URL>",
  token: "<UPSTASH_VECTOR_REST_TOKEN>",
);

$info = $index->getInfo();
```

That call will return an instance of `Upstash\Vector\IndexInfo`.

We can use index info as follows:

```php  theme={"system"}
// To know the number of vectors ready to query.
$info->vectorCount;

// To know the number of vectors that are getting indexed.
$info->pendingVectorCount;

// To know the size of the index in bytes.
$info->indexSize;

// To know the dimensions of your vector index.
$info->dimension;

// To know which similarity function is being used.
$info->similarityFunction;

// To get information about a specific index you can (More on next section):
$namespaceInfo = $info->namespace('my-namespace');
```

You can read more about [Namespaces](/vector/features/namespaces) and [Similarity Functions](/vector/features/similarityfunctions) on our docs.

## Namespace Info

Namespaces also contain vectors, which may be pending indexing.

As shown above, you can fetch information about the namespaces when making a `getInfo()` call on the index.

Additionally, you can use the `getNamespaceInfo()` method:

```php  theme={"system"}
use Upstash\Vector\Index;

$index = new Index(
  url: "<UPSTASH_VECTOR_REST_URL>",
  token: "<UPSTASH_VECTOR_REST_TOKEN>",
);

// Fetch the information of the default namespace.
$defaultNamespaceInfo = $index->getNamespaceInfo();

// Fetch the information on a specific namespace.
$myNamespaceInfo = $index->namespace('my-namespace')->getNamespaceInfo();
```

The `getNamespaceInfo()` call will return an instance of `Upstash\Vector\NamespaceInfo`.

We can use namespace info as follows:

```php  theme={"system"}
// To know the number of vectors ready to query.
$myNamespaceInfo->vectorCount;

// To know the number of vectors that are getting indexed.
$myNamespaceInfo->pendingVectorCount;
```


# Querying Vectors
Source: https://upstash.com/docs/vector/sdks/php/commands/query



Now that our database contains data, we want to query it.

There are several ways to query the database, depending on the type of index you have configured.

## Querying

You can query your vector index for similar vectors.

Below, we will learn how to use the SDK to query Dense, Sparse, and Hybrid indexes.

You can read more about [Sparse Indexes](/vector/features/sparseindexes) and [Hybrid Indexes](/vector/features/hybridindexes) on our docs.

### Dense Indexes

We‚Äôll use the `query()` method to instruct the SDK to query vectors from Upstash Vector.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->query(new VectorQuery(
    vector: [0.1, 0.2, ...], // "..." represents the dimension size of your vector index.
    topK: 15, // topK is the limit number of records we want to be returned.
    includeMetadata: true, // (optional) if true the query results will contain metadata.
    includeVectors: true, // (optional) if true the query results will contain the indexed vectors.
    includeData: true, // (optional) if true the query results will contain the string data.
    filter: '', // (optional) if set, the query results will be filtered by the given filter.
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->query(new VectorQuery(
    vector: [0.1, 0.2, ...], // "..." represents the dimension size of your vector index.
    topK: 15, // topK is the limit number of records we want to be returned.
    includeMetadata: true, // (optional) if true the query results will contain metadata.
    includeVectors: true, // (optional) if true the query results will contain the indexed vectors.
    includeData: true, // (optional) if true the query results will contain the string data.
    filter: '', // (optional) if set, the query results will be filtered by the given filter.
  ));
  ```
</CodeGroup>

<Note>
  The dimension of the query vector must match the dimension of your index.
</Note>

<Note>
  The score returned from query requests is a normalized value between 0 and 1,
  where 1 indicates the highest similarity and 0 the lowest regardless of the
  similarity function used.
</Note>

### Sparse Indexes

We can also use the `query()` method to instruct the SDK to query our Sparse index, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->query(new VectorQuery(
    sparseVector: new SparseVector(
      indices: [1, 2, 3],
      values: [5.0, 6.0, 7.0],
    ),
    topK: 15,
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->query(new VectorQuery(
    sparseVector: new SparseVector(
      indices: [1, 2, 3],
      values: [5.0, 6.0, 7.0],
    ),
    topK: 15,
  ));
  ```
</CodeGroup>

<Note>Sparse indexes can only be queried using sparse vectors. If you attempt to pass a regular vector in the query, the SDK will throw an exception.</Note>

### Hybrid Indexes

Hybrid indexes work the same way; they also use the `query()` method to query our index, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->query(new VectorQuery(
    vector: [0.1, 0.2, ...],
    sparseVector: new SparseVector(
      indices: [1, 2, 3],
      values: [5.0, 6.0, 7.0],
    ),
    topK: 15,
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->query(new VectorQuery(
    vector: [0.1, 0.2, ...],
    sparseVector: new SparseVector(
      indices: [1, 2, 3],
      values: [5.0, 6.0, 7.0],
    ),
    topK: 15,
  ));
  ```
</CodeGroup>

## Embedding Models

### Query Data

If your index is configured with one of our embedding models, you can query the index using a simple string, which will be automatically converted into vector embeddings. See the example below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->queryData(new DataQuery(
    data: 'What is the capital of France?',
    topK: 1, // to only return 1 result.
    includeData: true,
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->queryData(new DataQuery(
    data: 'What is the capital of France?',
    topK: 1, // to only return 1 result.
    includeData: true,
  ));
  ```
</CodeGroup>

<Note>If your index is not configured with an embedding model, this call will throw an exception.</Note>

You can read more about [Embedding Models](/vector/features/embeddingmodels) on our docs.

## Metadata Filtering

Data stored in indexes on Upstash Vector can be populated with metadata, which can then be used for filtering vectors.

Our SDK makes it easy to filter vectors based on their metadata values. Check out the example below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->query(new VectorQuery(
    vector: [0.1, 0.2, ...],
    topK: 15,
    filter: "country = 'PT' AND continent = 'EU'"
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorQuery;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $results = $index->namespace('my-namespace')->query(new VectorQuery(
    vector: [0.1, 0.2, ...],
    topK: 15,
    filter: "country = 'PT' AND continent = 'EU'"
  ));
  ```
</CodeGroup>

You can read more about [Metadata Filtering](/vector/features/filtering) on our docs.


# Reset
Source: https://upstash.com/docs/vector/sdks/php/commands/reset



Sometimes, all you need is to clean everything and start over.

Our SDK provides the capability to reset your index and/or namespaces.

## Reset Namespace

You can reset a namespace by calling the `reset()` method on the index or namespace.

If the `reset()` method is called on the index, only the default namespace will be reset, not the whole index.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->reset();
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->reset();
  ```
</CodeGroup>

## Reset All Namespaces

To reset all namespaces, you can call the `resetAll()` method on the index, as shown below:

```php  theme={"system"}
use Upstash\Vector\Index;

$index = new Index(
  url: "<UPSTASH_VECTOR_REST_URL>",
  token: "<UPSTASH_VECTOR_REST_TOKEN>",
);

$index->resetAll();
```

You can read more about [Namespaces](/vector/features/namespaces) on our docs.


# Upserting Data with Embedding Models
Source: https://upstash.com/docs/vector/sdks/php/commands/upsert-data



Upstash Vector provides embedding models that can automatically generate vector embeddings for you.

You can read more about [Embedding Models](/vector/features/embeddingmodels) on our docs.

## Upsert Data

We‚Äôll use the `upsertData()` method to instruct the SDK to upsert data that generates vectors from one of our embedding models, as demonstrated below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataUpsert;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsertData(new DataUpsert(
    id: '1',
    data: 'The capital of Japan is Tokyo',
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataUpsert;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsertData(new DataUpsert(
    id: '1',
    data: 'The capital of Japan is Tokyo',
  ));
  ```
</CodeGroup>

You can also enhance your index by adding metadata, enabling more efficient filtering in the future.

You can read more about [Metadata](/vector/features/metadata#metadata), [Data](/vector/features/metadata#data) and [Metadata Filtering](/vector/features/filtering) on our docs.

## Upsert Data Many

Building on the previous section, Upstash Vector also supports generating multiple vectors at once.

To do this, we‚Äôll use the `upsertDataMany()` method, which enables you to efficiently insert or update multiple vectors in an index, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataUpsert;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsertDataMany([
    new DataUpsert(id: '1', data: 'The capital of Japan is Tokyo'),
    new DataUpsert(id: '2', data: 'The capital of France is Paris'),
    new DataUpsert(id: '3', data: 'The capital of Germany is Berlin'),
  ]);
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\DataUpsert;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsertDataMany([
    new DataUpsert(id: '1', data: 'The capital of Japan is Tokyo'),
    new DataUpsert(id: '2', data: 'The capital of France is Paris'),
    new DataUpsert(id: '3', data: 'The capital of Germany is Berlin'),
  ]);
  ```
</CodeGroup>

Upserting multiple records simultaneously improves performance by allowing you to batch your upserts efficiently.

<Note>For optimal results, we recommend limiting each batch to no more than 1,000 records at a time.</Note>

## Sparse Indexes & Hybrid Indexes

Sparse and hybrid indexes do not require a different API. They will generate their vectors and sparse vectors
based on the models you selected when creating your vector index.

You can read more about [Sparse Indexes](/vector/features/sparseindexes) and [Hybrid Indexes](/vector/features/hybridindexes) on our docs.


# Upserting Vectors
Source: https://upstash.com/docs/vector/sdks/php/commands/upsert-vectors



Every database needs data, and your vector database is no exception.

Our SDK makes it easy to insert or update (upsert) vector data in your indexes and/or namespaces.

## Upsert

With Upstash Vector, you can upsert one or more vectors. For now, let‚Äôs focus on upserting a single vector.

We‚Äôll use the `upsert()` method to instruct the SDK to upsert vectors into an index, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsert(new VectorUpsert(
    id: '1',
    vector: createRandomVector(dimensions: 1536)
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsert(new VectorUpsert(
    id: '1',
    vector: createRandomVector(dimensions: 1536)
  ));
  ```
</CodeGroup>

You can also enhance your index by adding metadata, enabling more efficient filtering in the future.

You can read more about [Metadata](/vector/features/metadata#metadata), [Data](/vector/features/metadata#data) and [Metadata Filtering](/vector/features/filtering) on our docs.

## Upsert Many

Building on the previous section, Upstash Vector also supports upserting multiple vectors at once.

To do this, we‚Äôll use the `upsertMany()` method, which allows you to efficiently insert or update multiple vectors into an index, as shown below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsertMany([
    new VectorUpsert(
      id: '1',
      vector: createRandomVector(dimensions: 1536)
    ),
    new VectorUpsert(
      id: '2',
      vector: createRandomVector(dimensions: 1536)
    ),
  ]);
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsertMany([
    new VectorUpsert(
      id: '1',
      vector: createRandomVector(dimensions: 1536)
    ),
    new VectorUpsert(
      id: '2',
      vector: createRandomVector(dimensions: 1536)
    ),
  ]);
  ```
</CodeGroup>

Upserting multiple records simultaneously improves performance by allowing you to batch your upserts efficiently.

<Note>For optimal results, we recommend limiting each batch to no more than 1,000 records at a time.</Note>

## Update

When you upsert data you are basicly overriding the data that is already in the index. If you want to update the data you can use the `update` method.

The `update` method is similar to the `upsert` method, but it will only update the data that is already in the index.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpdate;
  use Upstash\Vector\Enums\UpdateMode;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->update(new VectorUpdate(
    id: '1',
    metadata: ['foo' => 'baz'],
    metadataUpdateMode: UpdateMode::OVERWRITE,
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpdate;
  use Upstash\Vector\Enums\UpdateMode;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->update(new VectorUpdate(
    id: '1',
    metadata: ['foo' => 'baz'],
    metadataUpdateMode: UpdateMode::OVERWRITE,
  ));
  ```
</CodeGroup>

## Sparse Indexes

If you are using a sparse index, you‚Äôll need to modify your upsert call accordingly.

Sparse indexes require a set of indices and their corresponding values, which can be upserted as demonstrated below:

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsert(new VectorUpsert(
    id: '1',
    sparseVector: new SparseVector(
      indices: [0, 1],
      values: [1.0, 2.0],
    ),
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;
  use Upstash\Vector\SparseVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsert(new VectorUpsert(
    id: '1',
    sparseVector: new SparseVector(
      indices: [0, 1],
      values: [1.0, 2.0],
    ),
  ));
  ```
</CodeGroup>

You can read more about [Sparse Indexes](/vector/features/sparseindexes) on our docs.

## Hybrid Indexes

If you are using a hybrid index, you need to provide both sparse vectors and dense vectors.

<CodeGroup>
  ```php simple theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;
  use Upstash\Vector\SparseVector;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->upsert(new VectorUpsert(
    id: '1',
    vector: createRandomVector(dimensions: 1536),
    sparseVector: new SparseVector(
      indices: [0, 1],
      values: [1.0, 2.0],
    ),
  ));
  ```

  ```php using namespaces theme={"system"}
  use Upstash\Vector\Index;
  use Upstash\Vector\VectorUpsert;
  use Upstash\Vector\SparseVector;

  use function Upstash\Vector\createRandomVector;

  $index = new Index(
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
  );

  $index->namespace('my-namespace')->upsert(new VectorUpsert(
    id: '1',
    vector: createRandomVector(dimensions: 1536),
    sparseVector: new SparseVector(
      indices: [0, 1],
      values: [1.0, 2.0],
    ),
  ));
  ```
</CodeGroup>

You can read more about [Hybrid Indexes](/vector/features/hybridindexes) on our docs.


# Getting Started
Source: https://upstash.com/docs/vector/sdks/php/getting-started



`upstash/vector` is a PHP SDK for Upstash Vector, enabling easier operations on Vector Store.

Using `upstash/vector` you can:

* Upsert a vector with metadata to an index.
* Fetching the vectors with specified IDs.
* Querying a vector over pre-defined embeddings.
* Remove vectors from an index.
* Access index stats.
* Reset everything related to an index.

You can find the Github Repository [here](https://github.com/upstash/vector-php).

## Install

To install the SDK, you can use composer:

```shell composer theme={"system"}
composer require upstash/vector
```

<Note>
  We also built a Laravel package that you can use to integrate the SDK with your Laravel application.
  [Learn more about our Laravel SDK](./laravel)
</Note>

## Usage

### Initializing the client

There are two pieces of configuration required to use the Upstash vector client: a REST token and REST URL. These values can be passed using environment variables or in code through the initialization of the Index. Find your configuration values in the console dashboard at [https://console.upstash.com/](https://console.upstash.com/).

#### Using environment variables

The environment variables used to configure the client are the following. You can follow [this guide](/vector/overall/getstarted) to retrieve credentials.

```bash  theme={"system"}
UPSTASH_VECTOR_REST_URL="your_rest_url"
UPSTASH_VECTOR_REST_TOKEN="your_rest_token"
```

When these environment variables are set, you can initialize the client from the environment.

```php  theme={"system"}
use Upstash\Vector\Index;

$index = Index::fromEnv();
```

#### Manual Initialization

If you prefer to pass these values in code, the constructor accepts as parameters the `url` and `token` values. This
could be useful if your application needs to interact with multiple projects, each with a different configuration.

```php  theme={"system"}
use Upstash\Vector\Index;

$index = new Index(
  url: "<UPSTASH_VECTOR_REST_URL>",
  token: "<UPSTASH_VECTOR_REST_TOKEN>",
);
```


# Getting Started with Laravel
Source: https://upstash.com/docs/vector/sdks/php/laravel



`upstash/vector-laravel` is a dedicated Laravel SDK for Upstash Vector, that is built on top of our official PHP SDK.

By using `upstash/vector-laravel` you will be able to:

* Integrate Upstash Vector by only installing the package and setting environment variables.
* A native Vector facade to interact with your vector database.
* Able to maintain multiple index connections in your application.

You can find the Github Repository [here](https://github.com/upstash/vector-laravel).

## Install

To install the SDK, you can use composer:

```shell composer theme={"system"}
composer require upstash/vector-laravel
```

## Setup

There are two pieces of configuration required to use the Upstash vector client: a REST token and REST URL. These values can be passed using environment variables or in code through the initialization of the Index. Find your configuration values in the console dashboard at [https://console.upstash.com/](https://console.upstash.com/).

```bash  theme={"system"}
UPSTASH_VECTOR_REST_URL="your_rest_url"
UPSTASH_VECTOR_REST_TOKEN="your_rest_token"
```

## Usage

Our Laravel SDK will configure your index into the Laravel Service Container. You can access it by calling the `Vector` facade
or by injecting the `IndexInterface` into your controllers.

### Vector Facade

When these environment variables are set, you can start using your Index by calling the `Vector` facade.

```php  theme={"system"}
use Upstash\Vector\Laravel\Facades\Vector;

Vector::getInfo(); // Fetches the index info.
```

### Dependency Injection

If you prefer to avoid using the facade, you can inject the `IndexInterface` into your controllers.

```php  theme={"system"}
namespace App\Http\Controllers;

use Upstash\Vector\Contracts\IndexInterface;

class Controller
{
    public function index(IndexInterface $index)
    {
        $namespaces = $index->listNamespaces();
        
        return response()->json(['namespaces' => $namespaces]);
    }
}
```

## Configuration

You can also configure the SDK to be able to use multiple indexes in your application.

For doing that you can publish the configuration file by running the following command:

```shell  theme={"system"}
php artisan vendor:publish --tag="vector-config"
```

You'll get a new file under `config/vector.php` that you can edit to add your indexes.

```php  theme={"system"}
return [
    'default' => env('UPSTASH_VECTOR_CONNECTION', 'default'),

    'connections' => [
        'default' => [
            'url' => env('UPSTASH_VECTOR_REST_URL'),
            'token' => env('UPSTASH_VECTOR_REST_TOKEN'),
        ],
    ],
];
```

### Multiple Connections

If you want to use multiple connections in your application, you can add them to the `connections` array as shown below:

```php  theme={"system"}
return [
    'default' => env('UPSTASH_VECTOR_CONNECTION', 'default'),

    'connections' => [
        'default' => [
            'url' => env('UPSTASH_VECTOR_REST_URL'),
            'token' => env('UPSTASH_VECTOR_REST_TOKEN'),
        ],
        'another' => [
            'url' => env('SECOND_UPSTASH_VECTOR_REST_URL'),
            'token' => env('SECOND_UPSTASH_VECTOR_REST_TOKEN'),
        ],
    ],
];
```

To access a specific connection, you can use the `connection` method:

```php  theme={"system"}
use Upstash\Vector\Laravel\Facades\Vector;

Vector::connection('another')->getInfo();
```


# Delete
Source: https://upstash.com/docs/vector/sdks/py/example_calls/delete



## Method

The `delete` method allows you to remove vectors from the index based on their identifiers.
The command accepts the following parameters:

* `ids`: A list of identifiers of vectors to be deleted.
* `prefix`: A string prefix to match vector IDs. All vectors with IDs that start with this prefix will be deleted.
* `filter`: A metadata filter to match vectors to be deleted.

<Note>Only one of `ids`, `prefix`, or `filter` can be provided.</Note>

It returns the following field in response:

* `deleted`: An integer indicating how many vectors were deleted with the command.

## Delete Example

```python  theme={"system"}
from upstash_vector import Index

index = Index.from_env()

# Specify the identifiers of vectors to be deleted
ids_to_delete = ["id1", "id2", "id3"]

# Delete the specified vectors
delete_result = index.delete(ids=ids_to_delete)

# Display the number of vectors deleted
print("Number of Vectors Deleted:", delete_result.deleted)
```

Alternatively, you can delete a singular vector:

```python  theme={"system"}
index.delete("id-4")
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.delete("id-4", namespace="ns")
```

## Delete with metadata filter

This will delete all vectors with metadata that matches the provided filter. For more information, see [Metadata Filtering](/vector/features/filtering).

```python  theme={"system"}
index.delete(filter="age > 30")
```

## Delete with id prefix

This will delete all vectors with IDs that start with the prefix.

```python  theme={"system"}
index.delete(prefix="id-")
```


# Fetch
Source: https://upstash.com/docs/vector/sdks/py/example_calls/fetch



## Method

The `fetch` method allows you to retrieve vectors from the index based on their identifiers. It takes the following input parameters:

* `ids`: A string or a list of strings representing the identifiers of the vectors to be fetched.
* `prefix`: A string prefix to match vector IDs. All vectors with IDs that start with this prefix will be retrieved.
* `include_vectors`: A boolean flag indicating whether to include vectors in the fetch results.
* `include_metadata`: A boolean flag indicating whether to include metadata in the fetch results.
* `include_data`: A boolean flag indicating whether to include data in the fetch results.
* `namespace`: The namespace to use. When not specified, the default namespace is used.

As a response, following field is returned:

* `vectors`: A list containing information for each fetched vector, including `id`, `vector`, `sparse_vector`, `metadata`, and `data`.

## Fetch Example

```python  theme={"system"}
from upstash_vector import Index

index = Index.from_env()

# Specify the identifiers of vectors to be fetched
ids_to_fetch = ["id-1", "id-2", "id-3"]

# Fetch the specified vectors with vectors and metadata included
fetch_result = index.fetch(
    ids=ids_to_fetch,
    include_vectors=True,
    include_metadata=True,
    include_data=True,
)

# Display the fetched vectors
for vector_info in fetch_result:
    print("ID:", vector_info.id)
    print("Vector:", vector_info.vector)
    print("Metadata:", vector_info.metadata)
    print("Data:", vector_info.data)
```

Alternatively, you can fetch a singular vector:

```python  theme={"system"}
index.fetch("id-4")
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.fetch("id-4", namespace="ns")
```

## Fetch with id prefix

This will fetch all vectors with IDs that start with the prefix.

<Warning>
  For fetching larger datasets with id prefix, prefer using the paginated
  `range` command to prevent timeouts.
</Warning>

```python  theme={"system"}
index.fetch(prefix="id-")
```


# Info
Source: https://upstash.com/docs/vector/sdks/py/example_calls/info



## Method

The `info` method provides statistical information about the index, returning the following fields:

* `vector_count`: The total number of vectors in the index.
* `pending_vector_count`: The number of vectors that are currently pending (not yet fully processed).
* `index_size`: The size of the index in bytes.
* `dimension`: How many dimensions the index has
* `similarity_function`: Similarity function chosen for the index
* `namespaces`: Map of namespace names of the index to their statistics.

## Info Example

```python  theme={"system"}
from upstash_vector import Index

index = Index.from_env()

from upstash_vector import Index

index = Index.from_env()

# Get statistical information about the index
info_result = index.info()

# Display the info result
print("Vector Count:", info_result.vector_count)
print("Pending Vector Count:", info_result.pending_vector_count)
print("Index Size:", info_result.index_size)
print("Dimension:", info_result.dimension)
print("Similarity Function:", info_result.similarity_function)

for ns, ns_info in info_result.namespaces.items():
    print("Namespace:", ns, "Vector Count:", ns_info.vector_count)
    print("Namespace:", ns, "Pending Vector Count:", ns_info.pending_vector_count)
```


# Query
Source: https://upstash.com/docs/vector/sdks/py/example_calls/query



## Method

To retrieve vectors from the index based on specific criteria, you can use the `query` method, which accepts the following parameters:

* `vector`: The reference vector for similarity comparison.
* `sparse_vector`: The sparse vector value to query.
* `data`: A string for text-based queries (mutually exclusive with vector).
* `include_metadata`: A boolean flag indicating whether to include metadata in the query results.
* `include_vector`: A boolean flag indicating whether to include vectors in the query results.
* `include_data`: A boolean flag indicating whether to include data in the query results.
* `top_k`: The number of top matching vectors to retrieve.
* `filter`: Metadata filtering of the vector is used to query your data based on the filters and narrow down the query results.
* `namespace`: The namespace to use. When not specified, the default namespace is used.
* `weighting_strategy`: Weighting strategy to be used for sparse vectors.
* `fusion_algorithm`: Fusion algorithm to use while fusing scores from hybrid vectors.
* `query_mode`: Query mode for hybrid indexes with Upstash-hosted embedding models.

As response, the object has the following fields:

* `id`: The identifier associated with the matching vector.
* `metadata`: Additional information or attributes linked to the matching vector.
* `score`: A measure of similarity indicating how closely the vector matches the query vector. The score is normalized to the range \[0, 1], where 1 indicates a perfect match.
* `vector`: The vector itself (included only if `include_vector` is set to `True`).
* `sparse_vector`: The sparse vector itself (included only if `include_vector` is set to `True`).
* `data`: Additional unstructured information linked to the matching vector.

<Tip>If you wanna learn more about filtering check: [Metadata Filtering](/vector/features/filtering)</Tip>

## Query Example

```python  theme={"system"}
import random

from upstash_vector import Index

index = Index.from_env()

# Generate a random vector for similarity comparison
dimension = 128  # Adjust based on your index's dimension
query_vector = [random.random() for _ in range(dimension)]

# Execute the query
query_result = index.query(
    vector=query_vector,
    include_metadata=True,
    include_data=True,
    include_vectors=False,
    top_k=5,
    filter="genre = 'fantasy' and title = 'Lord of the Rings'",
)

# Print the query result
for result in query_result:
    print("Score:", result.score)
    print("ID:", result.id)
    print("Vector:", result.vector)
    print("Metadata:", result.metadata)
    print("Data:", result.data)
```

## Batch Query Method

It is also possible to perform a batch of queries in a single
call to eliminate round trips to server.

## Batch Query Example

```python  theme={"system"}
import random

from upstash_vector import Index

index = Index.from_env()

# Generate a random vector for similarity comparison
dimension = 128  # Adjust based on your index's dimension
query_vectors = [[random.random() for _ in range(dimension)] for _ in range(2)]

# Execute the query
query_results = index.query_many(
    queries=[
        {
            "vector": query_vectors[0],
            "include_metadata": True,
            "include_data": True,
            "include_vectors": False,
            "top_k": 5,
            "filter": "genre = 'fantasy' and title = 'Lord of the Rings'",
        },
        {
            "vector": query_vectors[1],
            "include_metadata": False,
            "include_data": False,
            "include_vectors": True,
            "top_k": 3,
            "filter": "genre = 'drama'",
        },
    ]
)

for i, query_result in enumerate(query_results):
    print(f"Query-{i} result:")

    # Print the query result
    for result in query_result:
        print("Score:", result.score)
        print("ID:", result.id)
        print("Vector:", result.vector)
        print("Metadata:", result.metadata)
        print("Data:", result.data)
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.query(..., namespace="ns")
```


# Range
Source: https://upstash.com/docs/vector/sdks/py/example_calls/range



## Method

The `range` method allows you to retrieve vectors from the index within a specified range. The function accepts the following parameters:

* `cursor`: A cursor to start the range query.
* `prefix`: A string prefix to match vector IDs. All vectors with IDs that start with this prefix will be retrieved.
* `limit`: The maximum number of vectors to retrieve in a single query.
* `include_vectors`: A boolean flag indicating whether to include vectors in the range results.
* `include_metadata`: A boolean flag indicating whether to include metadata in the range results.
* `include_data`: A boolean flag indicating whether to include data in the range results.

As response, the object has the following fields:

* `next_cursor`: A cursor indicating the position to start the next range query. If `""`, there are no more results.
* `vectors`: A list containing information for each vector, including `id`, `vector`, and `metadata`.

<Note>
  The range command is stateless, meaning you need to pass all of the parameters
  in each subsequent request.
</Note>

## Range Example

```python  theme={"system"}
from upstash_vector import Index

index = Index.from_env()

# Execute the range query
range_result = index.range(
    cursor="",
    limit=10,
    include_vectors=False,
    include_metadata=True,
    include_data=True,
)

# Print the range result
print("Next Cursor:", range_result.next_cursor)

for vector_info in range_result.vectors:
    print("ID:", vector_info.id)
    print("Vector:", vector_info.vector)
    print("Metadata:", vector_info.metadata)
    print("Data:", vector_info.data)
```

## Range with id prefix

This will retrieve all vectors with IDs that start with the prefix.

```python  theme={"system"}
index.range(prefix="id-")
```

## Scanning Whole Index

For scanning the entire index, you can use a similar loop as shown below:

```python  theme={"system"}
res = index.range(cursor="", limit=5)
print(res.vectors)

while res.next_cursor != "":
    res = index.range(cursor=res.next_cursor, limit=10)
    print(res.vectors)
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.range(..., namespace="ns")
```


# Reset
Source: https://upstash.com/docs/vector/sdks/py/example_calls/reset



## Method

The `reset` method allows you to clear all vectors and metadata from a particular
namespace or all namespaces of an index.

## Reset Example

Resets the default namespace.

```python  theme={"system"}
from upstash_vector import Index
index = Index.from_env()

index.reset()
```

## Reset Namespace Example

Resets the given namespace.

```python  theme={"system"}
from upstash_vector import Index
index = Index.from_env()

index.reset(namespace="ns")
```

## Reset All Namespaces

Resets all the namespaces of an index.

```python  theme={"system"}
from upstash_vector import Index
index = Index.from_env()

index.reset(all=True)
```


# Resumable Query
Source: https://upstash.com/docs/vector/sdks/py/example_calls/resumable-query



Resumable queries let you start a nearest-neighbor search and continue fetching
additional results later without restarting the search. This is useful for
pagination or when you want to stream results incrementally instead of loading
the whole result set into memory.

Quick example (sync):

```python  theme={"system"}
from upstash_vector import Index

index = Index()

# start a resumable query (returns initial results and a handle)
results, handle = index.resumable_query(
    vector=[0.1, 0.2],
    top_k=2,
    include_metadata=True,
    include_vectors=True,
    namespace="example-namespace",
)

with handle:
    # `results` contains the first batch
    for r in results:
        print(r.id, r.metadata, getattr(r, "vector", None))

    # fetch more results (fetch_next returns a list)
    more = handle.fetch_next(3)
    for r in more:
        print(r.id)

    # when the context block exits the handle is stopped automatically
```

Parameters

* vector (List\[float] | SupportsToList | None) ‚Äî query vector (mutually exclusive with `data`).
* top\_k (int, default 10) ‚Äî how many top matches to return in the initial batch.
* include\_vectors (bool, default False) ‚Äî include full vector values on results.
* include\_metadata (bool, default False) ‚Äî include metadata on results.
* filter (str, default "") ‚Äî filter expression to narrow results by metadata.
* data (str | None) ‚Äî text query for indexes using Upstash-hosted embedding models.
* namespace (str, default DEFAULT\_NAMESPACE) ‚Äî namespace to search in.
* include\_data (bool, default False) ‚Äî include stored `data` field (used for embedding indexes).
* max\_idle (int, default 3600) ‚Äî how long the server keeps the resumable query alive (seconds).
* sparse\_vector (SparseVector | TupleAsSparseVectorT | None) ‚Äî sparse vector for sparse/hybrid indexes.
* weighting\_strategy (WeightingStrategy | None) ‚Äî weighting strategy for sparse vectors.
* fusion\_algorithm (FusionAlgorithm | None) ‚Äî fusion algorithm for hybrid scoring.
* query\_mode (QueryMode | None) ‚Äî query mode for hybrid embedding indexes (e.g. SPARSE).

How it works

* The call to `resumable_query` returns a tuple `(result, handle)` where `result`
  is the first batch (list of QueryResult) and `handle` is a `ResumableQueryHandle`.
* Use `handle.fetch_next(n)` (or `await handle.fetch_next(n)`) to retrieve the next
  `n` results. If no more results are available an empty list is returned.
* Always stop the handle when finished (use `with handle:` / `async with handle:` or
  call `handle.stop()` / `await handle.stop()`). After the handle is stopped, further
  calls to `fetch_next` or `stop` raise an error (tests expect UpstashError).

Examples

Simple paging (sync)

```python  theme={"system"}
results, handle = index.resumable_query(vector=[0.1, 0.2], top_k=2, namespace="ns")

with handle:
    all_results = list(results)
    while True:
        next_batch = handle.fetch_next(2)
        if not next_batch:
            break
        all_results.extend(next_batch)

# handle is stopped after exiting the context manager
```

Sparse / hybrid example (showing advanced options)

```python  theme={"system"}
from upstash_vector.types import SparseVector, WeightingStrategy, FusionAlgorithm

scores, handle = index.resumable_query(
    vector=[0.1, 0.1],
    sparse_vector=([0], [0.1]),
    top_k=2,
    include_vectors=True,
    include_metadata=True,
    include_data=True,
    weighting_strategy=WeightingStrategy.IDF,
    fusion_algorithm=FusionAlgorithm.DBSF,
    namespace="hybrid-ns",
)

with handle:
    for s in scores:
        print(s.id, getattr(s, "vector", None), getattr(s, "sparse_vector", None))
    more = handle.fetch_next(1)
    print("more:", more)
```

Notes

* The server enforces a limit on the number of active resumable queries; keep them
  short-lived and call `stop()` when finished. The default `max_idle` is 3600 seconds.
* After calling `stop()` (explicitly or via context manager), further `fetch_next` or
  `stop` calls will raise an error.


# Update
Source: https://upstash.com/docs/vector/sdks/py/example_calls/update



## Methods

The `update` method enables you to update the `vector`, `metadata`, or `data`
of a vector.

## Update Example

```python  theme={"system"}
from upstash_vector import Index

index = Index.from_env()

updated = index.update(
    id="id1",
    metadata={"new": "metadata"},
    data="new-data",
)

print(updated)
```

## Patch Metadata Example

It is also possible to patch metadata (update or delete existing fields or
set new fields) according the [JSON Merge Patch](https://datatracker.ietf.org/doc/html/rfc7386) algorithm.

```python  theme={"system"}
from upstash_vector import Index
from upstash_vector.types import MetadataUpdateMode

index = Index.from_env()

updated = index.update(
    id="id2",
    metadata={
        "existing-field": "new-value",
        "existing-field-to-delete": None,
        "new-field": "new-value",
    },
    metadata_update_mode=MetadataUpdateMode.PATCH,
)

print(updated)
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.update(..., namespace="ns")
```


# Upsert
Source: https://upstash.com/docs/vector/sdks/py/example_calls/upsert



## Methods

The `upsert` method enables you to insert or update vectors in the index.
You can perform upsert operations in three ways: using a vector object, a tuple, or a dictionary.

### Upsert Via Vector Object

```python  theme={"system"}
import random

from upstash_vector import Index, Vector

index = Index.from_env()

dimension = 128  # Adjust based on your index's dimension
upsert_amount = 100

vectors = [
    Vector(
        id=f"generated-id-{i}",
        vector=[random.random() for _ in range(dimension)],
        metadata={"some_field": f"some_value-{i}"},
        data=f"some-unstructured-data-{i}",
    )
    for i in range(upsert_amount)
]

index.upsert(vectors=vectors)
```

### Upsert Via Tuple

```python  theme={"system"}
import random

from upstash_vector import Index

index = Index.from_env()

dimension = 128  # Adjust based on your index's dimension
upsert_amount = 100

vectors = [
    (
        f"generated-id-{i}",
        [random.random() for _ in range(dimension)],
        {"some_field": f"some_value-{i}"},
        f"some-unstructured-data-{i}",
    )
    for i in range(upsert_amount)
]

index.upsert(vectors=vectors)
```

### Upsert Via Dictionary

```python  theme={"system"}
import random

from upstash_vector import Index

index = Index.from_env()

dimension = 128  # Adjust based on your index's dimension
upsert_amount = 100

vectors = [
    {
        "id": f"generated-id-{i}",
        "vector": [random.random() for _ in range(dimension)],
        "metadata": {"some_field": f"some_value-{i}"},
        "data": f"some-unstructured-data-{i}",
    }
    for i in range(upsert_amount)
]

index.upsert(vectors=vectors)
```

Also, you can specify a namespace to operate on. When no namespace
is provided, the default namespace will be used.

```python  theme={"system"}
index.upsert(..., namespace="ns")
```


# Features
Source: https://upstash.com/docs/vector/sdks/py/features



# Retry Mechanism

The `upstash-vector` SDK incorporates a reliable retry mechanism to manage network or API issues.
In the event of a failed request, the SDK automatically attempts up to three retries,
with each attempt spaced one second apart.

For customization of the retry behavior, you have the flexibility to set the `retries` and
`retry_interval` (in seconds) parameters according to your specific requirements.
For instance:

```python  theme={"system"}
from upstash_vector import Index

# Try 5 times with a 2-second interval between retries
index = Index.from_env(retries=5, retry_interval=2.0)
```

# Telemetry

This library sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Vercel, AWS)
* Python Runtime version

You can opt out by passing `allow_telemetry=False` when initializing the Redis client:

```py  theme={"system"}
idx = Index("INDEX_URL", "INDEX_TOKEN", allow_telemetry=False)
```


# Getting Started
Source: https://upstash.com/docs/vector/sdks/py/gettingstarted



The `upstash-vector` SDK is a lightweight, HTTP-based Upstash Vector client designed for Python. It seamlessly operates in both serverless and serverful environments, ensuring optimal compatibility across various connection setups.

This SDK simplifies interaction with Upstash Vector through the [Upstash Vector API](https://docs.upstash.com/vector/api/get-started).

It is designed to work with Python versions 3.8 and above.

Explore the source code, contribute, and stay informed through our [GitHub Repository](https://github.com/upstash/vector-py).

## Install

To begin using `upstash-vector`, you can install it via PyPI using the following command:

```bash  theme={"system"}
pip install upstash-vector
```

## Usage

Before using upstash-vector, you'll need to set up a vector database on [Upstash](https://console.upstash.com/). Once created, grab your URL and TOKEN from the Upstash console.

To initialize the index client:

```python  theme={"system"}
from upstash_vector import Index
index = Index(url="UPSTASH_VECTOR_REST_URL", token="UPSTASH_VECTOR_REST_TOKEN")
```

Alternatively, you can automatically load the credentials from the environment:

```python  theme={"system"}
from upstash_vector import Index
index = Index.from_env()
```

For serverless environments that allow it, it's recommended to initialize the client outside the request handler to be reused while your function is still "hot."

Here's an example of how you can use the SDK in your Python application:

```python  theme={"system"}
import random
from upstash_vector import Index

# Initialize the index client using environment variables
index = Index.from_env()

def main():
    # Define the dimension based on the index configuration
    dimension = 128
    # Generate a random vector for upsert
    vector_to_upsert = [random.random() for _ in range(dimension)]
    # Additional metadata associated with the vector
    metadata = {"text": "example test for metadata"}

    # Upsert the vector into the index
    index.upsert(vectors=[
        ("id-for-vector", vector_to_upsert, metadata)
    ])

```

The example above demonstrates how to upsert a vector with metadata using the SDK into the Upstash Vector database.

## More SDK Features

For additional functionalities and usage examples, check out the [Commands](/vector/sdks/py/example_calls) section in the documentation.


# Advanced
Source: https://upstash.com/docs/vector/sdks/ts/advanced



## Request Timeout

You can configure the SDK so that it will throw an error if the request takes longer than a specified time.

You can achieve this using the signal parameter like this:

```ts  theme={"system"}
try {
  const index = new Index({
    url: "<UPSTASH_VECTOR_REST_URL>",
    token: "<UPSTASH_VECTOR_REST_TOKEN>",
    // set a timeout of 1 second
    signal: () => AbortSignal.timeout(1000),
  });
} catch (error) {
  if (error.name === "TimeoutError") {
    console.error("Request timed out");
  } else {
    console.error("An error occurred:", error);
  }
}
```

## Telemetry

This sdk sends anonymous telemetry data to help us improve your experience.
We collect the following:

* SDK version
* Platform (Cloudflare, AWS or Vercel)
* Runtime version ([node@18.x](mailto:node@18.x))

You can opt out by setting the `UPSTASH_DISABLE_TELEMETRY` environment variable
to any truthy value.

```sh  theme={"system"}
UPSTASH_DISABLE_TELEMETRY=1
```


# Delete
Source: https://upstash.com/docs/vector/sdks/ts/commands/delete



The delete method allows you to delete vectors from your index using various criteria. You can delete vectors by their IDs, by ID prefix, or using metadata filters.

## Arguments

<ResponseField name="IDs" type="string[] | number[] | string | number" required>
  One or more vector IDs to delete.
</ResponseField>

**OR**

<ResponseField name="DeletePayload" type="object" required>
  <Expandable defaultOpen="true">
    <Note>You can only use one of the `ids`, `prefix`, or `filter` fields.</Note>

    <ResponseField name="ids" type="string[] | number[] | string | number">
      One or more vector IDs to delete.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      A string prefix to match vector IDs for deletion. All vectors with IDs
      starting with this prefix will be deleted.
    </ResponseField>

    <ResponseField name="filter" type="string">
      A metadata filter for vector deletion. See [Metadata
      Filtering](/vector/features/filtering) for more information.

      <Warning>
        Deleting vectors with metadata filter is a O(N) operation that performs a full
        scan. Therefore, it might be slow for large indexes.
      </Warning>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="Options" type="DeleteCommandOptions">
  <Expandable defaultOpen="true">
    <ResponseField name="namespace" type="string">
      Namespace to delete from. If not set, default namespace is used.
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="Response" type="DeleteResult" required>
  <Expandable defaultOpen="true">
    <ResponseField name="deleted" type="number" required>
      The number of vectors that were successfully deleted.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Delete by IDs Array theme={"system"}
  const response = await index.delete(["2", "3"]);
  // { deleted: 2 }
  ```

  ```typescript Delete Single ID theme={"system"}
  const response = await index.delete("2");
  // { deleted: 1 }
  ```

  ```typescript Delete by Prefix theme={"system"}
  const response = await index.delete({
    prefix: "article_",
  });
  // { deleted: 3 }
  ```

  ```typescript Delete by Filter theme={"system"}
  const response = await index.delete({
    filter: "age > 30",
  });
  // { deleted: 3 }
  ```
</RequestExample>


# Fetch
Source: https://upstash.com/docs/vector/sdks/ts/commands/fetch



Used to retrieve the vector by ID.

## Arguments

<ResponseField name="IDs" type="string[] | number[]" required>
  The IDs of the vectors you want to fetch.
</ResponseField>

**OR**

<ResponseField name="FetchPayload" type="object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="ids" type="string[] | number[]">
      The IDs of the vectors you want to fetch.
    </ResponseField>

    <ResponseField name="prefix" type="string">
      An id prefix to match vector IDs.

      <Warning>
        For fetching larger datasets with prefix, it is recommended to use the
        paginated `range` command instead.
      </Warning>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="Options" type="Object">
  <Expandable defaultOpen="true">
    <ResponseField name="includeMetadata" type="boolean">
      Whether to include the metadata of the vectors in the response. Setting
      this `true` would be the best practice, since it will make it easier to
      identify the vectors.
    </ResponseField>

    <ParamField body="includeVectors" type="boolean">
      Whether to include the vector themselves in the response.
    </ParamField>

    <ParamField body="includeData" type="boolean">
      Whether to include [the data field](/vector/features/metadata#data) in the
      response.
    </ParamField>

    <ResponseField name="namespace" type="string">
      Namespace to fetch from. If not set, default namespace is used.
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="FetchResult[]" type="Vector[]" required>
  This field is `null` if no vector with the specified id is found.

  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting vector. <br />
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The vectors (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="sparseVector" type="SparseVector">
      The resulting sparseVector (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      The metadata of the vectors (if `includeMetadata` is set to true)
    </ResponseField>

    <ResponseField name="data" type="string">
      The data of the vector (if `includeData` is set to true)
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic theme={"system"}
  await index.fetch(["2", "3"]);
  // [{ id: "2" }, { id: "3" }]
  ```

  ```typescript Vector Not Found theme={"system"}
  await index.fetch(["2", "3"]);
  // [{ id: "2" }, null]
  ```

  ```typescript ID prefix theme={"system"}
  await index.fetch({ prefix: "test-" });
  // [{ id: "test-1" }, { id: "test-2" }, { id: "test-3" }]
  ```
</RequestExample>


# Info
Source: https://upstash.com/docs/vector/sdks/ts/commands/info



Used to retrieve the stats of an index.

## Response

<ResponseField name="vectorCount" type="number" required>
  The total number of vectors in the index, that are ready to use.
</ResponseField>

<ResponseField name="pendingVectorCount" type="number" required>
  The number of vectors in the index, that is still processing and not ready to
  use.
</ResponseField>

<ResponseField name="indexSize" type="number" required>
  The size of the index, in `b`.
</ResponseField>

<ResponseField name="dimension" type="number" required>
  Dimension of the vectors.
</ResponseField>

<ResponseField name="similarityFunction" type="string" required>
  Name of the similarity function used in indexing and queries.
</ResponseField>

<ResponseField name="namespaces" type="Record<string, Object>" required>
  A map of namespaces to their information in the following format

  <Expandable defaultOpen="true">
    <ResponseField name="vectorCount" type="number" required>
      The total number of vectors in the namespace, that are ready to use.
    </ResponseField>

    <ResponseField name="pendingVectorCount" type="number" required>
      The number of vectors in the namespace, that is still processing and not ready to
      use.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic theme={"system"}
  const infoResponse = await index.info();
  /*
  { 
    vectorCount: 17,
    pendingVectorCount: 0,
    indexSize: 551158,
    dimension: 1536,
    similarityFunction: "COSINE",
    namespaces: {
      "": { // default namespace
        vectorCount: 10,
        pendingVectorCount: 0,
      },
      "my-namespace": {
        vectorCount: 7,
        pendingVectorCount: 0,
      }
    }
  }
  */
  ```
</RequestExample>


# Query
Source: https://upstash.com/docs/vector/sdks/ts/commands/query



The query method is designed to retrieve the most similar vectors from the index, using the specific distance metric defined for your index. This method supports a variety of options to configure the query to your needs.

<Note>
  The dimension of the query vector must match the dimension of your index.
</Note>

<Note>
  The score returned from query requests is a normalized value between 0 and 1,
  where 1 indicates the highest similarity and 0 the lowest regardless of the
  similarity function used.
</Note>

## Arguments

<ResponseField name="Payload" type="QueryCommandPayload" required>
  <Expandable defaultOpen="true">
    <ResponseField name="vector | sparseVector | data" type="number[] | SparseVector | string" required>
      <Note>
        There are two ways to use the query method. You can either create the vectors on your own and pass directly the `vector` or `sparseVector` field, depending on your index type. Or you can pass the `data` field and create the embeddings using Upstash Embedding.
      </Note>

      The query data/vector that you want to search for in the index.
    </ResponseField>

    <ResponseField name="topK" type="number" required>
      The total number of the vectors that you want to receive as a query
      result. The response will be sorted based on the distance metric score,
      and `topK` vectors will be returned.
    </ResponseField>

    <ResponseField name="includeMetadata" type="boolean">
      Whether to include the metadata of the vectors in the response. Setting
      this `true` would be the best practice, since it will make it easier to
      identify the vectors.
    </ResponseField>

    <ResponseField name="includeVectors" type="boolean">
      Whether to include the vector themselves in the response.
    </ResponseField>

    <ResponseField name="includeData" type="boolean">
      Whether to include [the data field](/vector/features/metadata#data) in the response.
    </ResponseField>

    <ResponseField name="filter" type="string">
      The metadata filtering of the vector. This is used to query your data based on the filters and narrow down the query results.
      If you wanna learn more about filtering check: [Metadata Filtering](/vector/features/filtering)
    </ResponseField>

    <ResponseField name="weightingStrategy" type="WeightingStrategy">
      For sparse vectors, what kind of weighting strategy should be used while querying the matching non-zero dimension values of the query vector with the documents. If not provided, no weighting will be used.
    </ResponseField>

    <ResponseField name="fusionAlgorithm" type="FusionAlgorithm">
      Fusion algorithm to use while fusing scores from dense and sparse components of a hybrid index. If not provided, defaults to `RRF`.
    </ResponseField>

    <ResponseField name="queryMode" type="QueryMode">
      Query mode for hybrid indexes with Upstash-hosted embedding models. Specifies whether to run the query in only the dense index, only the sparse index, or in both. If not provided, defaults to `HYBRID`.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="Options" type="QueryCommandOptions">
  <Expandable defaultOpen="true">
    <ResponseField name="Namespace" type="string">
      Namespace to query. If not set, default namespace is used.
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="Response" type="QueryResult" required>
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The score of the vector data, calculated based on the distance metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The resulting vector (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="sparseVector" type="SparseVector">
      The resulting sparseVector (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      The metadata of the vector (if `includeMetadata` is set to true)
    </ResponseField>

    <ResponseField name="data" type="string">
      The data of the vector (if `includeData` is set to true)
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Using Vector theme={"system"}
  await index.query({
    topK: 2,
    vector: [ ... ],
    includeMetadata: true,
    includeVectors: true
  }, { namespace: "my-namespace" })
  /*
  [
    {
      id: '6345',
      score: 0.85,
      vector: [],
      metadata: {
        sentence: "Upstash is great."
      }
    },
    {
      id: '1233',
      score: 0.75,
      vector: [],
      metadata: undefined
    },
  ]
  */
  ```

  ```typescript Using Data theme={"system"}
  const results = await index.query({
    data: "Movie about an adventure of a hobbit in a fantasy world.",
    includeVectors: true,
    includeMetadata: true,
    topK: 1,
    filter: "genre = 'fantasy' and title = 'Lord of the Rings'",
  });
  /*
  [
    {
      id: "1234",
      vector: [0.1, 0.2, 0.3, 0.4, 0.5],
      score: 0.9999999,
      metadata: {
        title: "Lord of The Rings",
        genre: "fantasy",
        category: "classic",
      },
    }
  ]
  */
  ```

  ```typescript Improved Typechecking theme={"system"}
  type Metadata = {
    title: string,
    genre: 'sci-fi' | 'fantasy' | 'horror' | 'action'
  }

  const results = await index.query<Metadata>({
    vector: [
      ... // query embedding
    ],
    includeVectors: true,
    topK: 1,
    filter: "genre = 'fantasy' and title = 'Lord of the Rings'"
  })

  if (results[0].metadata) {
    // Since we passed the Metadata type parameter above,
    // we can interact with metadata fields without having to
    // do any typecasting.
    const { title, genre } = results[0].metadata;
    console.log(`The best match in fantasy was ${title}`)
  }
  ```
</RequestExample>


# Range
Source: https://upstash.com/docs/vector/sdks/ts/commands/range



The range method is used to retrieve vectors in chunks with pagination. This method supports a variety of options to configure the query to your needs.

<Note>
  The range command is stateless, meaning you need to pass all of the parameters
  in each subsequent request.
</Note>

## Arguments

<ParamField body="cursor" type="string | number" required>
  The cursor to the last retrieved vector. Should be set to `0` in the initial
  range request.
</ParamField>

<ParamField body="prefix" type="string">
  An string prefix to match vector IDs. All vectors with IDs that start with
  this prefix will be retrieved.
</ParamField>

<ParamField body="limit" type="number" required>
  The number of maximum vectors wanted in the response of range. (page size)
</ParamField>

<ParamField body="includeMetadata" type="boolean">
  Whether to include the metadata of the vectors in the response. Setting this
  `true` would be the best practice, since it will make it easier to identify
  the vectors.
</ParamField>

<ParamField body="includeVectors" type="boolean">
  Whether to include the vector themselves in the response.
</ParamField>

<ParamField body="includeData" type="boolean">
  Whether to include [the data field](/vector/features/metadata#data) in the
  response.
</ParamField>

<ParamField name="Namespace" type="{ namespace?: string }">
  Namespace to call range for. If not set, default namespace is used.
</ParamField>

## Response

<ResponseField name="RangeResponse" type="" required>
  <Expandable defaultOpen="true">
    <ResponseField name="nextCursor" type="string | number" required>
      Cursor to use in the next range request.
    </ResponseField>

    <ResponseField name="vectors" type="Vector | Vector[]" required>
      <Expandable defaultOpen="true">
        <ResponseField name="id" type="string | number" required>
          The ID of the vector
        </ResponseField>

        <ResponseField name="vector" type="number[]">
          The vectors (if `includeVectors` is set to true)
        </ResponseField>

        <ResponseField name="metadata" type="Record<string, unknown>">
          The metadata of the vectors (if `includeMetadata` is set to true)
        </ResponseField>

        <ResponseField name="data" type="string">
          The data of the vector (if `includeData` is set to true)
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript Basic theme={"system"}
  const responseRange = await index.range(
    {
      cursor: 0,
      limit: 2,
      includeMetadata: true,
    },
    { namespace: "my-namespace" }
  );

  /*
  {
    nextCursor: '2',
    vectors: [
      { 
        id: '0',
        metadata: {
          keyword: "Vector"
        } 
      },
      { 
        id: '19',
        metadata: {
          keyword: "Redis"
        } 
      }
    ]
  }
  */
  ```

  ```typescript ID prefix theme={"system"}
  const responseRange = await index.range({
    cursor: 0,
    limit: 2,
    prefix: "test-",
  });

  /*
  {
    nextCursor: '2',
    vectors: [
      { id: 'test-1' },
      { id: 'test-2' },
    ]
  }
  */
  ```

  ```typescript Improved Types theme={"system"}
  type Metadata = {
    title: string;
    genre: "sci-fi" | "fantasy" | "horror" | "action";
  };

  const responseRange = await index.range<Metadata>({
    cursor: 0,
    limit: 2,
    includeMetadata: true,
  });

  if (responseRange[0].metadata) {
    // Since we passed the Metadata type parameter above,
    // we can interact with metadata fields without having to
    // do any typecasting.
    const { title, genre } = results[0].metadata;
    console.log(`The best match in fantasy was ${title}`);
  }
  ```
</RequestExample>


# Reset
Source: https://upstash.com/docs/vector/sdks/ts/commands/reset



The `reset` method allows you to clear all vectors and metadata from a particular
namespace or all namespaces of an index.

## Arguments

There are two arguments available. You should only pass one of them:

<ResponseField name="namespace" type="string">
  Specifies a namespace to reset. Leave empty for the default namespace.
</ResponseField>

<ResponseField name="all" type="true | undefined">
  Whether to reset all namespaces. Can only be set to `true`.
</ResponseField>

## Response

`'Success'` if the index is successfully resetted.

<RequestExample>
  ```typescript Basic theme={"system"}
  const responseReset = await index.reset();
  // 'Successful'
  ```

  ```typescript All Namespaces theme={"system"}
  const responseReset = await index.reset({ all: true });
  // 'Successful'
  ```
</RequestExample>


# Resumable Query
Source: https://upstash.com/docs/vector/sdks/ts/commands/resumable-query



The resumableQuery method allows you to perform queries that can be resumed to fetch additional results. This is particularly useful for large result sets or when implementing pagination.

<Note>
  The dimension of the query vector must match the dimension of your index.
</Note>

<Note>
  The score returned from query requests is a normalized value between 0 and 1,
  where 1 indicates the highest similarity and 0 the lowest regardless of the
  similarity function used.
</Note>

## Arguments

<ResponseField name="Payload" type="ResumableQueryPayload" required>
  <Expandable defaultOpen="true">
    <ResponseField name="vector | sparseVector | data" type="number[] | SparseVector | string" required>
      <Note>
        There are two ways to use the resumableQuery method. You can either create the vectors on your own and pass directly the `vector` or `sparseVector` field, depending on your index type. Or you can pass the `data` field and create the embeddings using Upstash Embedding.
      </Note>

      The query data/vector that you want to search for in the index.
    </ResponseField>

    <ResponseField name="topK" type="number" required>
      The initial number of vectors to retrieve in the query result. The response will be sorted based on the distance metric score.
    </ResponseField>

    <ResponseField name="includeMetadata" type="boolean">
      Whether to include the metadata of the vectors in the response. Setting
      this `true` would be the best practice, since it will make it easier to
      identify the vectors.
    </ResponseField>

    <ResponseField name="includeVectors" type="boolean">
      Whether to include the vector values in the response.
    </ResponseField>

    <ResponseField name="includeData" type="boolean">
      Whether to include [the data field](/vector/features/metadata#data) in the response.
    </ResponseField>

    <ResponseField name="filter" type="string">
      The metadata filtering of the vector. This is used to query your data based on the filters and narrow down the query results.

      If you want to learn more about filtering check: [Metadata Filtering](/vector/features/filtering)
    </ResponseField>

    <ResponseField name="weightingStrategy" type="WeightingStrategy">
      For sparse vectors, what kind of weighting strategy should be used while querying the matching non-zero dimension values of the query vector with the documents. If not provided, no weighting will be used.
    </ResponseField>

    <ResponseField name="fusionAlgorithm" type="FusionAlgorithm">
      Fusion algorithm to use while fusing scores from dense and sparse components of a hybrid index. If not provided, defaults to `RRF`.
    </ResponseField>

    <ResponseField name="queryMode" type="QueryMode">
      Query mode for hybrid indexes with Upstash-hosted embedding models. Specifies whether to run the query in only the dense index, only the sparse index, or in both. If not provided, defaults to `HYBRID`.
    </ResponseField>

    <ResponseField name="maxIdle" type="number">
      Maximum idle time for the resumable query in seconds.
    </ResponseField>
  </Expandable>
</ResponseField>

## Response

<ResponseField name="ResumableQueryResponse" type="Object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="result" type="QueryResult[]" required>
      The initial query results.
    </ResponseField>

    <ResponseField name="fetchNext" type="(additionalK: number) => Promise<Vector[]>" required>
      A function to fetch the next batch of results.
    </ResponseField>

    <ResponseField name="stop" type="() => Promise<string>" required>
      A function to stop the resumable query and release resources.
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="QueryResult" type="Object" required>
  <Expandable defaultOpen="true">
    <ResponseField name="id" type="string | number" required>
      The ID of the resulting vector.
    </ResponseField>

    <ResponseField name="score" type="number" required>
      The score of the vector data, calculated based on the distance metric of your index.
    </ResponseField>

    <ResponseField name="vector" type="number[]">
      The resulting vector (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="sparseVector" type="SparseVector">
      The resulting sparseVector (if `includeVectors` is set to true)
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      The metadata of the vector (if `includeMetadata` is set to true)
    </ResponseField>

    <ResponseField name="data" type="string">
      The data of the vector (if `includeData` is set to true)
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```typescript with Vector theme={"system"}
  const { result, fetchNext, stop } = await index.resumableQuery({
    maxIdle: 3600,
    topK: 50,
    vector: [0, 1, 2, ..., 383], // 384-dimensional vector
    includeMetadata: true,
    includeVectors: true,
  });

  console.log(result);
  /*
  [
    {
      id: '6345',
      score: 1.00000012,
      vector: [0, 1, 2, ..., 383],
      metadata: {
        sentence: "Upstash is great."
      }
    },
    // ... more results
  ]
  */

  const nextBatch = await fetchNext(5); // Fetch next 5 results
  console.log(nextBatch);

  await stop(); // Stop the resumable query
  ```

  ```typescript with Data theme={"system"}
  const { result, fetchNext, stop } = await index.resumableQuery({
    maxIdle: 3600,
    topK: 50,
    data: "lord of the rings"
    includeMetadata: true,
    includeData: true,
  });

  console.log(result);
  /*
  [
    {
      id: '6345',
      score: 1.00000012,
      data: "hobbit",
      metadata: {
        sentence: "Upstash is great."
      }
    },
    // ... more results
  ]
  */

  const nextBatch = await fetchNext(5); // Fetch next 5 results
  console.log(nextBatch);

  await stop(); // Stop the resumable query
  ```

  ```typescript with Metadata Type theme={"system"}
  type Metadata = {
    title: string,
    genre: 'sci-fi' | 'fantasy' | 'horror' | 'action'
  }

  const { result, fetchNext, stop } = await index.resumableQuery<Metadata>({
    vector: [
      ... // query embedding
    ],
    includeMetadata: true,
    topK: 1,
    filter: "genre = 'fantasy' and title = 'Lord of the Rings'",
    maxIdle: 3600,
  })

  if (result[0].metadata) {
    // Since we passed the Metadata type parameter above,
    // we can interact with metadata fields without having to
    // do any typecasting.
    const { title, genre } = result[0].metadata;
    console.log(`The best match in fantasy was ${title}`)
  }

  await stop();
  ```
</RequestExample>


# Upsert
Source: https://upstash.com/docs/vector/sdks/ts/commands/upsert



Used to add new vectors or update an existing vector.

<Note>
  You can only upsert vectors with same dimension count(size) as your index.
</Note>

## Arguments

There are two ways to use the upsert method. You can either create the vectors on your own and pass them directly.
Or you can pass the data and create the embeddings using Upstash Embedding. The possible payloads are:

<ResponseField name="VectorPayload" type="Vector | Vector[]" required>
  <Expandable>
    <ResponseField name="id" type="string | number" required>
      The ID of the vector
    </ResponseField>

    <ResponseField name="vector" type="number[]" required>
      The vectors to add to the store
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      Metadata of the vector
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="Namespace" type="{ namespace?: string }">
  Namespace to upsert to. If not set, default namespace is used.
</ResponseField>

**OR**

<ResponseField name="DataPayload" type="Data | Data[]" required>
  <Expandable>
    <ResponseField name="id" type="string | number" required>
      The ID of the vector
    </ResponseField>

    <ResponseField name="data" type="string" required>
      The vectors to add to the store
    </ResponseField>

    <ResponseField name="metadata" type="Record<string, unknown>">
      Metadata of the vector
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="Namespace" type="{ namespace?: string }">
  Namespace to upsert to. If not set, default namespace is used.
</ResponseField>

## Response

<ResponseField type="str" required>
  `'Success'` on successful operation.
</ResponseField>

<RequestExample>
  ```typescript Single Vector theme={"system"}
  await index.upsert({
    id: "1234",
    vector: [0.1, 0.2, 0.3, 0.4, 0.5],
    metadata: {
      title: "Lord of The Rings",
      genre: "drama",
      category: "classic",
    },
  });
  ```

  ```typescript Multiple Vectors theme={"system"}
  await index.upsert([
    {
      id: "6789",
      vector: [0.6, 0.7, 0.8, 0.9, 0.9],
    },
    {
      id: "1234",
      vector: [0.1, 0.2, 0.3, 0.4, 0.5],
      metadata: {
        title: "Lord of The Rings",
        genre: "drama",
        category: "classic",
      },
    },
  ]);
  ```

  ```typescript Namespace theme={"system"}
  await index.upsert([
    {
      id: "6789",
      vector: [0.6, 0.7, 0.8, 0.9, 0.9],
    },
  ], { namespace: "my-namespace" });
  ```

  ```typescript Update Vector theme={"system"}
  await index.upsert({
  	id: "1234",
  	vector: [0.1, 0.2, 0.3, 0.4, 0.5]
  	metadata: {
  		title: "Redis"
  	}
  })

  await index.update({
  	id: "1234",
  	metadata: {
  		title: "QStash"
  	}
  })
  ```

  ```typescript Single Data theme={"system"}
  await index.upsert({
    id: "1234",
    data: "'The Lord of the Rings' follows Frodo Baggins and his allies on a quest to destroy a powerful ring and save Middle-earth from the dark lord Sauron.",
    metadata: {
      title: "Lord of The Rings",
      genre: "drama",
      category: "classic",
    },
  });
  ```

  ```typescript Multiple Data theme={"system"}
  await index.upsert([
    {
      id: "6789",
      data: "'Harry Potter' follows the journey of a young wizard, Harry Potter, as he attends Hogwarts School of Witchcraft and Wizardry, forms deep friendships, and confronts the dark wizard Voldemort, who seeks immortality and domination over the magical world.",
    },
    {
      id: "1234",
      data: "'The Lord of the Rings' follows Frodo Baggins and his allies on a quest to destroy a powerful ring and save Middle-earth from the dark lord Sauron.",
      metadata: {
        title: "Lord of The Rings",
        genre: "drama",
        category: "classic",
      },
    },
  ]);
  ```

  ```typescript Update data theme={"system"}
  await index.upsert({
  	id: "1234",
  	data: "Upstash product"
  	metadata: {
  		title: "Redis"
  	}
  })

  await index.upsert({
  	id: "1234",
  	metadata: {
  		title: "QStash"
  	}
  })
  ```
</RequestExample>


# Contributing
Source: https://upstash.com/docs/vector/sdks/ts/contributing



## Preparing the environment

This project uses [Bun](https://bun.sh/) for packaging and dependency management. Make sure you have the relevant dependencies.

```commandline  theme={"system"}
curl -fsSL https://bun.sh/install | bash
```

You will also need a vector database on [Upstash](https://console.upstash.com/).

## Code Formatting

```bash  theme={"system"}
bun run fmt
```

## Running tests

To run all the tests, make sure you have the relevant environment variables.

```bash  theme={"system"}
bun run test
```


# Getting Started
Source: https://upstash.com/docs/vector/sdks/ts/getting-started



`@upstash/vector` is a Typescript SDK for Upstash Vector, enabling easier operations on Vector Store with full type coverage.

Using `@upstash/vector` you can:

* Upsert a vector with metadata to an index.
* Fetching the vectors with specified IDs.
* Querying a vector over pre-defined embeddings.
* Delete vectors from an index.
* Access index stats.
* Reset everything related to an index.

You can find the Github Repository [here](https://github.com/upstash/vector-js).

## Install

<CodeGroup>
  ```shell npm theme={"system"}
  npm install @upstash/vector
  ```

  ```shell pnpm theme={"system"}
  pnpm add @upstash/vector
  ```
</CodeGroup>

## Usage

### Initializing the client

There are two pieces of configuration required to use the Upstash vector client: a REST token and REST URL. These values can be passed using environment variables or in code through a configuration object. Find your configuration values in the console dashboard at [https://console.upstash.com/](https://console.upstash.com/).

#### Using environment variables

The environment variables used to configure the client are the following. You can follow [this guide](/vector/overall/getstarted) to retrieve credentials.

```bash  theme={"system"}
UPSTASH_VECTOR_REST_URL="your_rest_url"
UPSTASH_VECTOR_REST_TOKEN="your_rest_token"
```

When these environment variables are set, the client constructor does not require any additional arguments.

```typescript  theme={"system"}
import { Index } from "@upstash/vector";

const index = new Index();
```

#### Using a configuration object

If you prefer to pass configuration in code, the constructor accepts a config object containing the `url` and `token` values. This
could be useful if your application needs to interact with multiple projects, each with a different configuration.

```typescript  theme={"system"}
import { Index } from "@upstash/vector";

const index = new Index({
  url: "<UPSTASH_VECTOR_REST_URL>",
  token: "<UPSTASH_VECTOR_REST_TOKEN>",
});
```

## TypeScript Usage

### Index level types

The Vector SDK supports defining your metadata type at the index level for complete type-safety.

```typescript  theme={"system"}
import { Index } from "@upstash/vector";

type Metadata = { genre: string, year: number };

const index = new Index<Metadata>();
```

Passing a metadata type at the index level will provide strong type safety for the metadata coming back from or required for the following commands:

* `query`
* `upsert`
* `fetch`
* `range`

### Command level types

In some cases, you might not want to define a metadata type at the index level. In this case, you can either override the index level type definition for a specific command, or pass a metadata type to specific commands instead.

```typescript  theme={"system"}
import { Index } from "@upstash/vector";

type Metadata = { genre: string, year: number };

const index = new Index();

index.upsert<Metadata>({ id: 1, vector: [...], metadata: { 
  genre: "comedy",
  year: 1990
}});
```

The passing of a strong metadata type is possible for each of the four index operations listed above, we use upsert as an example.


# Create and Deploy RAG Applications with Gradio
Source: https://upstash.com/docs/vector/tutorials/gradio-application



In this tutorial, we'll demonstrate how to use Gradio to build an interactive Semantic Search and Question Answering app using Hugging Face embeddings, Upstash Vector, and LangChain. Users can enter a question, and the app will retrieve relevant information and provide an answer.

### Important Note on Python Version

Recent Python versions may cause compatibility issues with `torch`, a dependency for Hugging Face models. Therefore, we recommend using **Python 3.9** to avoid any installation issues.

### Installation and Setup

First, we need to set up our environment and install the necessary libraries. Install the dependencies by running the following command:

```bash  theme={"system"}
pip install gradio langchain sentence_transformers upstash-vector python-dotenv transformers langchain-community langchain-huggingface
```

Next, create a `.env` file in your project directory with the following content, replacing `your_upstash_url` and `your_upstash_token` with your actual Upstash credentials:

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
```

This configuration file will allow us to load the required environment variables.

### Code

We will load our environment variables, initialize the Hugging Face embeddings model, set up Upstash Vector, and configure a Hugging Face Question Answering model.

```python  theme={"system"}
# Import libraries
import gradio as gr
from dotenv import load_dotenv
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores.upstash import UpstashVectorStore
from transformers import pipeline
from langchain.schema import Document

# Load environment variables
load_dotenv()

# Set up embeddings and Upstash Vector store
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
vector_store = UpstashVectorStore(embedding=embeddings)
```

Next, we will create sample documents, embed them using Hugging Face embeddings, and store them in Upstash Vector.

```python  theme={"system"}
# Sample documents to embed and store
documents = [
    Document(page_content="Global warming is causing sea levels to rise."),
    Document(page_content="AI is transforming many industries."),
    Document(page_content="Renewable energy is vital for sustainable development.")
]
vector_store.add_documents(documents=documents, batch_size=100, embedding_chunk_size=200)
```

When inserting documents, they are first embedded using the `Embeddings` object. Many embedding models, such as the Hugging Face models, support embedding multiple documents at once. This allows for efficient processing by batching documents and embedding them in parallel.

* The `embedding_chunk_size` parameter controls the number of documents processed in parallel when creating embeddings.

Once the embeddings are created, they are stored in Upstash Vector. To reduce the number of HTTP requests, the vectors are also batched when they are sent to Upstash Vector.

* The `batch_size` parameter controls the number of vectors included in each HTTP request when sending to Upstash Vector.

<Note type="info">
  In the Upstash Vector free tier, there is a limit of 1000 vectors per batch.
</Note>

Now, we can set up a Question Answering model and the Gradio interface.

```python  theme={"system"}
# Set up a Hugging Face Question Answering model
qa_pipeline = pipeline("question-answering", model="distilbert-base-cased-distilled-squad")

# Gradio interface function
def answer_question(query):
    # Retrieve relevant documents from Upstash Vector
    results = vector_store.similarity_search(query, k=3)
    
    # Use the most relevant document for QA
    if results:
        context = results[0].page_content
        qa_input = {"question": query, "context": context}
        answer = qa_pipeline(qa_input)["answer"]
        return f"Answer: {answer}\n\nContext: {context}"
    else:
        return "No relevant context found."

# Set up Gradio interface
iface = gr.Interface(
    fn=answer_question,
    inputs="text",
    outputs="text",
    title="RAG Application",
    description="Ask a question, and the app will retrieve relevant information and provide an answer."
)

# Launch the Gradio app
iface.launch()
```

### Running the App

After setting up the code, run your script to start the Gradio app. You will be presented with an interface where you can enter a question. The app will retrieve the most relevant information from the embedded documents and provide an answer based on the content.

### Notes

* **Deployment**: To create a public link, set `share=True` in `launch()`. This will generate a public URL for your Gradio app. This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to [Hugging Face Spaces](https://huggingface.co/spaces)
* **Batch Processing**: The `batch_size` and `embedding_chunk_size` parameters allow you to control the efficiency of document processing and storage in Upstash Vector.
* **Namespaces**: Upstash Vector supports namespaces for organizing different types of documents. You can set a namespace while creating the `UpstashVectorStore` instance.


# Use Hugging Face Embeddings with Upstash Vector
Source: https://upstash.com/docs/vector/tutorials/huggingface-embeddings



In this tutorial, we'll demonstrate how to use Hugging Face embeddings with Upstash Vector and LangChain to perform a similarity search. We will upload a few sample documents, embed them using Hugging Face, and then perform a search query to find the most semantically similar documents.

### Important Note on Python Version

Recent Python versions may cause compatibility issues with `torch`, a dependency for Hugging Face models. Therefore, we recommend using **Python 3.9** to avoid any installation issues.

### Installation and Setup

First, we need to set up our environment and install the necessary libraries. Install the dependencies by running the following command:

```bash  theme={"system"}
pip install langchain sentence_transformers upstash-vector python-dotenv langchain-community langchain-huggingface
```

Next, create a `.env` file in your project directory with the following content, replacing `your_upstash_url` and `your_upstash_token` with your actual Upstash credentials:

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
```

This configuration file will allow us to load the required environment variables.

### Code

We will load our environment variables and initialize the Hugging Face embeddings model along with the Upstash Vector store.

```python  theme={"system"}
# Load environment variables for API keys and Upstash configuration
from dotenv import load_dotenv
import os
load_dotenv()

# Import required libraries
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores.upstash import UpstashVectorStore

# Initialize Hugging Face embeddings model
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

# Set up Upstash Vector Store (automatically uses the environment variables)
vector_store = UpstashVectorStore(embedding=embeddings)
```

Next, we will create sample documents and embed them using Hugging Face embeddings, then store them in Upstash Vector.

```python  theme={"system"}
# Import the required Document class from LangChain
from langchain.schema import Document

# Sample documents to embed and store as Document objects
documents = [
    Document(page_content="Global warming is causing sea levels to rise."),
    Document(page_content="Artificial intelligence is transforming many industries."),
    Document(page_content="Renewable energy is vital for sustainable development.")
]

# Embed documents and store in Upstash Vector with batching
vector_store.add_documents(
    documents=documents,
    batch_size=100,               
    embedding_chunk_size=200      
)

print("Documents with embeddings have been stored in Upstash Vector.")
```

When inserting documents, they are first embedded using the `Embeddings` object. Many embedding models, such as the Hugging Face models, support embedding multiple documents at once. This allows for efficient processing by batching documents and embedding them in parallel.

* The `embedding_chunk_size` parameter controls the number of documents processed in parallel when creating embeddings.

Once the embeddings are created, they are stored in Upstash Vector. To reduce the number of HTTP requests, the vectors are also batched when they are sent to Upstash Vector.

* The `batch_size` parameter controls the number of vectors included in each HTTP request when sending to Upstash Vector.

<Note type="info">
  In the Upstash Vector free tier, there is a limit of 1000 vectors per batch.
</Note>

Now, we can perform a semantic search.

```python  theme={"system"}
# Querying Vectors using a text query
query_text = "What are the effects of global warming?"
query_embedding = embeddings.embed_query(query_text)

# Perform similarity search with the query text
result_text_query = vector_store.similarity_search(
    query=query_text,
    k=5  # Number of top results to return
)

print("Results for text-based similarity search:")
for res in result_text_query:
    print(res.page_content)
```

Here's the output of our text-based similarity search:

```
Results for text-based similarity search:
Global warming is causing sea levels to rise.
Renewable energy is vital for sustainable development.
Artificial intelligence is transforming many industries.
```

Alternatively, you can perform a similarity search using the vector directly.

```python  theme={"system"}
# Querying Vectors using a vector directly
result_vector_query = vector_store.similarity_search_by_vector(
    embedding=query_embedding,
    k=5
)

print("Results for vector-based similarity search:")
for res in result_vector_query:
    print(res.page_content)
```

This will output similar results, as it is searching based on the similarity of the embedding.

### Notes

* You can specify batch sizes and chunk sizes to control the efficiency of document processing and storage in Upstash Vector.
* Upstash Vector supports namespaces for organizing different types of documents. You can set a namespace while creating the `UpstashVectorStore` instance.

To learn more about LangChain and its integration with Upstash Vector, visit the [LangChain documentation](https://python.langchain.com/docs/integrations/vectorstores/upstash/).


# Implement Semantic Search with LangChain
Source: https://upstash.com/docs/vector/tutorials/langchain



In this tutorial, we'll demonstrate how to use Upstash Vector with LangChain to perform a similarity search. We will upload a document about global warming and perform a search query to find the most semantically similar documents using embeddings generated automatically by Upstash.

### Installation and Setup

First, we need to create a Vector Index in the [Upstash Console](https://console.upstash.com). Once we have our index, we will copy the `UPSTASH_VECTOR_REST_URL` and `UPSTASH_VECTOR_REST_TOKEN` and paste them to our `.env` file. To learn more about index creation, you can check out [this page](https://docs.upstash.com/vector/overall/getstarted).

Add the following content to your `.env` file (replace with your actual URL and token):

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
```

We now need to install the following libraries via PyPI:

```bash  theme={"system"}
pip install upstash-vector python-dotenv langchain langchain-community
```

### Code

We will load our environment variables and initialize the index from the environment variables (URL and token).

```python  theme={"system"}
from dotenv import load_dotenv
from langchain_community.vectorstores.upstash import UpstashVectorStore

load_dotenv()

# Create a vector store instance where embeddings are generated by Upstash
store = UpstashVectorStore(embedding=True)
```

Next, we will upload the `global_warming.txt` document to the Upstash Vector index.

```python  theme={"system"}
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter

# Load the document
loader = TextLoader("documents/global_warming.txt")
documents = loader.load()

# Split the document into chunks
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)
```

We will now insert the documents into the Upstash Vector index.

```python  theme={"system"}
inserted_vectors = store.add_documents(docs)
```

Finally, we will perform a semantic search.

```python  theme={"system"}
result = store.similarity_search("Technology's role in global warming.", k=5)
print(result)
```

Here's the output:

```
[Document(metadata={'source': 'documents/global_warming.txt'}, page_content='Technology and innovation play a crucial role in advancing sustainable food systems and mitigating the impact of global warming. Precision agriculture, for example, uses data analytics, remote sensing, and GPS technology to optimize the use of resources such as water, fertilizer, and pesticides. By applying inputs more efficiently, precision agriculture reduces waste, lowers GHG emissions, and improves crop yields.\n\nIn the realm of food production, alternative proteins‚Äîsuch as plant-based meats, lab-grown meats, and insect-based proteins‚Äîoffer promising solutions to reduce the environmental impact of livestock farming. These innovations require fewer resources to produce and generate lower GHG emissions compared to traditional animal agriculture. Additionally, vertical farming and hydroponics allow for the cultivation of crops in controlled environments, using less land and water while reducing the need for chemical inputs.\n\nConclusion'),
 Document(metadata={'source': 'documents/global_warming.txt'}, page_content='Global warming presents a formidable challenge to food production systems, but sustainable food practices offer a viable solution to mitigate its effects. By adopting regenerative agriculture, reducing food waste, and shifting toward plant-based diets, humanity can reduce the environmental impact of agriculture while ensuring food security for future generations. Furthermore, technology and innovation will continue to play a pivotal role in advancing sustainable food systems, allowing for more efficient and eco-friendly food production methods. In the face of climate change, the integration of sustainable food practices is not only an environmental imperative but also a pathway toward a healthier and more resilient future for both people and the planet.'),
 Document(metadata={'source': 'documents/global_warming.txt'}, page_content='Global Warming and Sustainable Foods: An Inextricable Connection'),
 Document(metadata={'source': 'documents/global_warming.txt'}, page_content='One of the key components of sustainable food systems is regenerative agriculture, which focuses on restoring soil health, enhancing biodiversity, and sequestering carbon. Regenerative farming practices include crop rotation, cover cropping, agroforestry, and reduced tillage, all of which contribute to building healthy soils that can absorb and store carbon. By improving soil health, regenerative agriculture also increases the resilience of crops to climate change, as healthy soils retain more water and nutrients, making crops more resistant to droughts and pests.'),
 Document(metadata={'source': 'documents/global_warming.txt'}, page_content='Numerous studies have shown that shifting to plant-based diets can significantly reduce GHG emissions and mitigate the effects of global warming. According to a report by the United Nations Food and Agriculture Organization (FAO), reducing the consumption of animal-based foods could reduce global agricultural emissions by up to 50%. Moreover, plant-based diets are associated with reduced land and water use, as growing crops for direct human consumption is more resource-efficient than growing feed for livestock.\n\nIn addition to their environmental benefits, plant-based diets offer numerous health advantages. They are rich in fiber, vitamins, and minerals, and have been linked to lower risks of chronic diseases such as heart disease, diabetes, and certain cancers. As global populations grow and the demand for food increases, promoting plant-based diets offers a sustainable solution to addressing both environmental and nutritional challenges.\n\nThe Role of Technology and Innovation')]
```

### Notes

* You can also query with score using `similarity_search_with_score` method.

* Namespaces can be used to separate different types of documents. You can specify a namespace when creating the `UpstashVectorStore` instance.

```
store = UpstashVectorStore(embedding=True, namespace="my_namespace")
```

* You can use OpenAI's embeddings by setting `embedding=OpenAIEmbeddings()` in the `UpstashVectorStore` instance.

```
from langchain_openai import OpenAIEmbeddings
store = UpstashVectorStore(embedding=OpenAIEmbeddings())
```

To learn more about LangChain and its integration with Upstash Vector, you can visit the [LangChain documentation](https://python.langchain.com/docs/integrations/vectorstores/upstash/).


# RAG with LlamaIndex
Source: https://upstash.com/docs/vector/tutorials/llamaindex



In this tutorial, we‚Äôll demonstrate how to use Upstash Vector with LlamaIndex to perform RAG (Retrieval-Augmented Generation). We will upload a document about global warming and generate responses to our questions based on the contents of the document.

### Installation and Setup

First, we need to create a Vector Index in the [Upstash Console](https://console.upstash.com). Make sure to set the index dimensions to 1536 and the distance metric to Cosine. Once we have our index, we will copy the `UPSTASH_VECTOR_REST_URL` and `UPSTASH_VECTOR_REST_TOKEN` and paste them into our `.env` file. To learn more about index creation, you can check out our [getting started page](https://docs.upstash.com/vector/overall/getstarted).

Add the following content to your `.env` file (replace with your actual URL, token and API key):

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
OPENAI_API_KEY=your_openai_api_key
```

We now need to install the following libraries via PyPI:

```bash  theme={"system"}
pip install llama-index upstash-vector llama-index-vector-stores-upstash python-dotenv
```

### Code

We will load our environment variables, initialize the index, and configure it to use the specified dimensions and distance metric.

```python  theme={"system"}
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.vector_stores.upstash import UpstashVectorStore
from llama_index.core import StorageContext
import openai
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
openai.api_key = os.environ["OPENAI_API_KEY"]

# Setup the Upstash vector store 
upstash_vector_store = UpstashVectorStore(
    url=os.environ["UPSTASH_VECTOR_REST_URL"],
    token=os.environ["UPSTASH_VECTOR_REST_TOKEN"],
)

# Read the document about global warming from the documents directory
documents = SimpleDirectoryReader("./documents/").load_data()

# Initialize the storage context with the Upstash vector store
storage_context = StorageContext.from_defaults(vector_store=upstash_vector_store)

# Create the index from the loaded document with 1536 dimensions and cosine distance
index = VectorStoreIndex.from_documents(
    documents, storage_context=storage_context
)
```

Next, we will query the document:

```python  theme={"system"}
# Initialize the query engine
query_engine = index.as_query_engine()

# Query the document about global warming
res1 = query_engine.query("What is global warming?")
print(res1)

res2 = query_engine.query("How should we modify our diets to reduce our carbon footprint?")
print(res2)
```

### Sample Output

Here is the output of the queries:

```
Global warming refers to the long-term increase in Earth‚Äôs average temperature due to the accumulation of greenhouse gases (GHGs) such as carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O) in the atmosphere. The primary drivers of GHG emissions include the burning of fossil fuels for energy, industrial processes, deforestation, and unsustainable agricultural practices. As these gases trap heat, they create a ‚Äúgreenhouse effect,‚Äù leading to rising temperatures, melting polar ice caps, rising sea...

Shifting towards plant-based diets, which emphasize the consumption of vegetables, fruits, legumes, grains, and nuts, can significantly reduce our carbon footprint. Plant-based diets have a much lower environmental footprint compared to animal-based foods, particularly red meat, which is highly resource-intensive and contributes disproportionately to greenhouse gas emissions. Studies have shown that reducing the consumption of animal-based foods and increasing the intake of plant-based foods can help red...
```

### Notes

* Namespaces can be used to separate different types of documents. You can specify a namespace when creating the `UpstashVectorStore` instance:

```
vector_store = UpstashVectorStore(
    url=your_upstash_url, 
    token=your_upstash_token, 
    namespace=your_namespace,
    )
```

* To learn more about LlamaIndex and its integration with Upstash Vector, you can visit the [LlamaIndex documentation](https://docs.llamaindex.ai/en/latest).


# Parsing and Querying Documents with LlamaParse
Source: https://upstash.com/docs/vector/tutorials/llamaparse



In this tutorial, we‚Äôll learn how to parse a document using LlamaParse and then query it using an LLM with Upstash Vector.

We‚Äôll split this guide into two parts: parsing a document and then querying the parsed document.

## Installation and Setup

To get started, we need to set up our environment. You can install the necessary libraries using the following command in your terminal:

```bash  theme={"system"}
pip install llama-index upstash-vector llama-index-vector-stores-upstash python-dotenv
```

We also need to create a Vector Index in the [Upstash Console](https://console.upstash.com). Make sure to set the index dimensions to 1536 and the distance metric to Cosine. To learn more about index creation, you can check out our [getting started page](https://docs.upstash.com/vector/overall/getstarted).

Once we have our index, we will copy the `UPSTASH_VECTOR_REST_URL` and `UPSTASH_VECTOR_REST_TOKEN` and paste them into our `.env` file.

#### Environment Variables

Create a `.env` file in your project directory and add the following content:

```plaintext  theme={"system"}
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
OPENAI_API_KEY=your_openai_api_key
LLAMA_CLOUD_API_KEY=your_llama_cloud_api_key
```

To get your `LLAMA_CLOUD_API_KEY`, you can follow the instructions in [the LlamaCloud documentation](https://docs.cloud.llamaindex.ai/llamaparse/getting_started/get_an_api_key).

## Part 1: Parsing a Document

We can now move on to parsing a document. In this example, we‚Äôll parse a file named `global_warming.txt`.

```python  theme={"system"}
from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader

# Initialize the LlamaParse parser with the desired result format
parser = LlamaParse(result_type="markdown")  # "markdown" and "text" are available

# Parse the document using the parser
file_extractor = {".txt": parser}
documents = SimpleDirectoryReader(input_files=["./documents/global_warming.txt"], file_extractor=file_extractor).load_data()
```

<Note type="info">
  If you are using Jupyter Notebook, you need to allow nested event loops to parse the document.

  You can do this by adding the following code snippet to your file:

  ```python  theme={"system"}
  import nest_asyncio
  nest_asyncio.apply()
  ```
</Note>

Now that we have our parsed data, we can query it.

## Part 2: Querying the Parsed Document with an LLM

In this part, we‚Äôll use the `UpstashVectorStore` to create an index, and query the content. We‚Äôll use OpenAI as the language model to interpret the data and respond to questions based on the document. You can use other LLMs that are supported by LlamaIndex as well.

```python  theme={"system"}
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.upstash import UpstashVectorStore
from llama_index.core import StorageContext
import openai

# Load environment variables for API keys and Upstash configuration
from dotenv import load_dotenv
import os
load_dotenv()

# Set up OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

# Set up Upstash Vector Store
upstash_vector_store = UpstashVectorStore(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN"),
)

# Create a storage context for Upstash Vector and index the parsed document
storage_context = StorageContext.from_defaults(vector_store=upstash_vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)

# Create a query engine for the index and perform a query
query_engine = index.as_query_engine()
query = "What are the main points discussed in the document?"
response = query_engine.query(query)
print(response)
```

Here's the code output:

```plaintext  theme={"system"}
The main points discussed in the document include the impact of global warming on agriculture 
and food production systems, the importance of adopting sustainable food practices to mitigate 
these effects, the role of agriculture in contributing to global warming through GHG emissions, 
deforestation, and the use of synthetic fertilizers, and the need for sustainable food systems 
to address environmental challenges and ensure food security for future generations.
```

### Conclusion

With the ability to parse and query documents, you can efficiently summarize content, extract essential information, and answer questions based on the document‚Äôs details.

To learn more about LlamaIndex and its integration with Upstash Vector, you can visit the [LlamaIndex documentation](https://docs.llamaindex.ai/en/latest).


# Simple Semantic Search
Source: https://upstash.com/docs/vector/tutorials/semantic_search



In this tutorial, we'll demonstrate how to use Upstash Vector for semantic search. We will upload several documents and perform a search query to find the most semantically similar documents using embeddings generated automatically by Upstash.

### Installation and Setup

First, we need to create a Vector Index in the [Upstash Console](https://console.upstash.com). Once we have our index, we will copy the `UPSTASH_VECTOR_REST_URL` and `UPSTASH_VECTOR_REST_TOKEN` and paste them to our `.env` file. To learn more about index creation, you can check out [this page](https://docs.upstash.com/vector/overall/getstarted).

Add the following content to your `.env` file (replace with your actual URL and token):

```
UPSTASH_VECTOR_REST_URL=your_upstash_url
UPSTASH_VECTOR_REST_TOKEN=your_upstash_token
```

We now need to install the `upstash-vector` library via PyPI. Additionally, we will install `python-dotenv` to load environment variables from the `.env` file.

```bash  theme={"system"}
pip install upstash-vector python-dotenv
```

### Code

Create a Python script (e.g., `main.py`) and add the following code to perform semantic search using Upstash Vector:

```python main.py theme={"system"}
from upstash_vector import Index
from dotenv import load_dotenv
import time

# Load environment variables from a .env file
load_dotenv()

# Initialize the index from environment variables (URL and token)
index = Index.from_env()

# Example documents to be indexed
documents = [
    {"id": "1", "text": "Python is a popular programming language."},
    {"id": "2", "text": "Machine learning enables computers to learn from data."},
    {"id": "3", "text": "Upstash provides low-latency database solutions."},
    {"id": "4", "text": "Semantic search is a technique for understanding the meaning of queries."},
    {"id": "5", "text": "Cloud computing allows for scalable and flexible resource management."}
]

# Reset the index to remove previous data
index.reset()

# Upsert documents into Upstash (embeddings are generated automatically)
for doc in documents:
    index.upsert(
        vectors=[
            (doc["id"], doc["text"], {"text": doc["text"]})
        ]
    )
    print(f"Document {doc['id']} inserted.")

# Wait for the documents to be indexed
time.sleep(1)

# Search for documents similar to the query
query = "What is Python?"
results = index.query(data=query, top_k=3, include_metadata=True)

# Display search results
print("Search Results:")
for result in results:
    print(f"ID: {result.id}")
    print(f"Score: {result.score:.4f}")
    print(f"Metadata: {result.metadata}")
    print("-" * 40)  # Separator line between results
```

### Running the Code

To run the code, execute the following command in your terminal:

```bash  theme={"system"}
python main.py
```

Here is an example output for the search query "What is Python?":

```
Document 1 inserted.
Document 2 inserted.
Document 3 inserted.
Document 4 inserted.
Document 5 inserted.
Search Results:
ID: 1
Score: 0.9080
Metadata: {'text': 'Python is a popular programming language.'}
----------------------------------------
ID: 2
Score: 0.7592
Metadata: {'text': 'Machine learning enables computers to learn from data.'}
----------------------------------------
ID: 4
Score: 0.7388
Metadata: {'text': 'Semantic search is a technique for understanding the meaning of queries.'}
----------------------------------------
```

### Code Breakdown

1. **Environment Setup**: We use `python-dotenv` to load our environment variables and use the `Index.from_env()` method to initialize the index client.

2. **Document Insertion**: We define a list of documents, each with a unique ID and text content. The `upsert()` function inserts these documents into our index. These documents are automatically converted into embeddings. To learn more about Upstash Embedding Models, you can check out [this page](https://docs.upstash.com/vector/features/embeddingmodels).

3. **Index Reset**: Before inserting documents, the `reset()` function clears any existing data in the index.

4. **Search Query**: After inserting the documents, we perform semantic search. The `query()` function returns the `top_k` most similar documents to the query along with their metadata if `include_metadata` is set to `True`.


# Examples
Source: https://upstash.com/docs/workflow/agents/examples



Explore our collection of examples to learn how to build robust agent systems. From architectural patterns to real-world implementations, these examples demonstrate the full potential of our Agents API.

<Snippet file="workflow/agent-examples.mdx" />


# null
Source: https://upstash.com/docs/workflow/agents/features



On this page, we explain the features of the Workflow Agents API in more detail.

Prerequisites:

* Setup your first Agent endpoint by following [the Getting Started page](/workflow/agents/getting-started).
* Install the following packages to define tools:

```bash  theme={"system"}
npm i ai mathjs zod @agentic/ai-sdk @agentic/weather @langchain/core @langchain/community
```

## Models

The `model` is responsible for deciding which tools to call and generating the final response

First, add `QSTASH_TOKEN` and `OPENAI_API_KEY` to your environment:

```
QSTASH_TOKEN="<QSTASH_TOKEN>"
OPENAI_API_KEY="<OPENAI_API_KEY>"
```

Next, define the model in your route:

```ts  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo')

  // ...
})
```

If you want to use an OpenAI compatible provider, you can do so by passing `baseURL` and `apiKey`:

```ts  theme={"system"}
const model = context.agents.openai('deepseek-chat', {
  baseURL: "https://api.deepseek.com",
  apiKey: process.env.DEEPSEEK_API_KEY
})
```

If you want to use other providers available on AI SDK, you can import the `create<Provider>` methods exported from provider packages. For example, in order to use Anthropic you can do the following:

```ts  theme={"system"}
import { createAnthropic } from "@ai-sdk/anthropic";

const model = context.agents.AISDKModel({
  context,
  provider: createAnthropic,
  providerParams: {
    apiKey: "<ANTHROPIC_API_KEY>",
  },
});
```

If you want to configure the calls made to the LLM APIs, you can use the `agentCallParams` parameter:

```ts  theme={"system"}
const model = context.agents.openai('gpt-3.5-turbo', {
  callSettings: {
    timeout: 1000, // optional request timeout
    retries: 0,    // optional retries
    flowControl: { // optional flow control
      key: "flow-control-key",
      rate: 10,
      period: "10s",
      parallelism: 10,
    },
  }
})
```

Same parameter is available in `agents.AISDKModel` as the `agentCallParams` parameter.

## Tools

Next, we will define the tools that our agents will use. The **Agents API** is compatible with both **AI SDK** and **LangChain** tools. This means you can either:

* Use existing tools that are compatible with these SDKs.
* Define your own custom tools that are compatible with these SDKs.

This flexibility allows you to tailor the tools to your specific needs while leveraging the power of these frameworks.

<CodeGroup>
  ```ts WorkflowTool (custom) theme={"system"}
  import { WorkflowTool } from '@upstash/workflow'
  import { z } from 'zod'
  import * as mathjs from 'mathjs'

  const tool = new WorkflowTool({
    description:
      'A tool for evaluating mathematical expressions. ' +
      'Example expressions: ' +
      "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'.",
    schema: z.object({ expression: z.string() }),
    invoke: async ({ expression }) => mathjs.evaluate(expression),
  })
  ```

  ```ts AI SDK (custom) theme={"system"}
  import { z } from 'zod'
  import { tool } from 'ai'
  import * as mathjs from 'mathjs'

  const mathTool = tool({
    description:
      'A tool for evaluating mathematical expressions. ' +
      'Example expressions: ' +
      "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'.",
    parameters: z.object({ expression: z.string() }),
    execute: async ({ expression }) => mathjs.evaluate(expression),
  })
  ```

  ```ts Agentic theme={"system"}
  import { createAISDKTools } from '@agentic/ai-sdk'
  import { WeatherClient } from '@agentic/weather'

  const weather = new WeatherClient()
  const tools = createAISDKTools(weather)
  ```

  ```ts LangChain (custom) theme={"system"}
  import { DynamicStructuredTool } from "@langchain/core/tools";

  const numberGenerator = new DynamicStructuredTool({
    name: "random-number-generator",
    description: "generates a random number between two input numbers",
    schema: z.object({
      low: z.number().describe("The lower bound of the generated number"),
      high: z.number().describe("The upper bound of the generated number"),
    }),
    func: async ({ low, high }) =>
      (Math.random() * (high - low) + low).toString(), // Outputs still must be strings
  })
  ```

  ```ts LangChain theme={"system"}
  import { WikipediaQueryRun } from '@langchain/community/tools/wikipedia_query_run'

  const wikiTool = new WikipediaQueryRun({
    topKResults: 1,
    maxDocContentLength: 500,
  })
  ```
</CodeGroup>

For available toolkits, you can explore the [LangChain Toolkits](https://js.langchain.com/v0.1/docs/modules/agents/tools/toolkits/) or other AI SDK-compatible toolkits like [Agentic](https://agentic.so/sdks/ai-sdk).

By default, the Workflow SDK will wrap the execute/invoke methods of the tools you pass with [`context.run`](/workflow/basics/context#context-run) to run them as a Workflow step. This means, you can't use steps like context.call, context.notify etc in execute/invoke right away. If you want to define steps in invoke/execute, you can use the `executeAsStep` option:

```ts {12} theme={"system"}
import { WorkflowTool } from '@upstash/workflow'
import { serve } from '@upstash/workflow/nextjs'

export const { POST } = serve(async (context) => {
  const tool = new WorkflowTool({
    description: ...,
    schema: ...,
    invoke: ( ... ) => {
      // make HTTP call inside the tool with context.call:
      await context.call( ... )
    },
    executeAsStep: false
  })

  // pass the tool to agent
})
```

## Agents

After defining a model and tools, we can define agents. Agents are essentially LLM models with access to a set of tools and background knowledge. In Upstash Workflow, agents are defined like this:

```ts route.ts theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo')

  const researcherAgent = context.agents.agent({
    model,
    name: 'academic',
    maxSteps: 2,
    tools: {
      wikiTool: new WikipediaQueryRun({
        topKResults: 1,
        maxDocContentLength: 500,
      })
    },
    background:
      'You are researcher agent with access to Wikipedia. ' +
      'Utilize Wikipedia as much as possible for correct information',
  })
})
```

The parameters for defining an agent are as follows:

* **`model`**: The LLM model that the agent will use.
* **`name`**: The name of the agent. This name will be used when naming the [context.call steps](/workflow/basics/context#context-call) for this agent. `context.call` is used when calling the LLM provider (such as OpenAI).
* **`maxSteps`**: The maximum number of times this agent can call the LLM provider (e.g., OpenAI).
* **`tools`**: The list of tools available to the agent for completing tasks.
* **`background`**: A description of the agent, which is used as a system prompt to provide context for the agent's behavior.

## Tasks

Now that we have agents defined, the only thing left is to assign tasks to them. A **task** is simply a prompt passed to the agent.

There are two ways to create a task:

1. **Single Agent Task**: The task is assigned to a single agent, which will complete it using the tools available to it.

2. **Multiple Agent Task**: A **manager agent** is used to decide which agents will be involved and in what order. The manager agent makes this decision based on the task prompt, the agents' backgrounds, and the tools available to them.

### Single Agent

```ts Single Agent {22-27} theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo');

  const researcherAgent = context.agents.agent({
    model,
    name: 'academic',
    maxSteps: 2,
    tools: {
      wikiTool: new WikipediaQueryRun({
        topKResults: 1,
        maxDocContentLength: 500,
      })
    },
    background:
      'You are researcher agent with access to Wikipedia. ' +
      'Utilize Wikipedia as much as possible for correct information',
  });

  const task = context.agents.task({
    agent: researcherAgent,
    prompt: "Tell me about 5 topics in advanced physics.",
  });
  const { text } = await task.run();
  console.log("result:", text)
})
```

As response to the task, the agent generates the following response:

```
Here are summaries of 5 topics in advanced physics:

1. **Quantum Mechanics**: Quantum mechanics is a fundamental theory that describes the behavior of nature at and below the scale of atoms. It is the foundation of all quantum physics, including quantum chemistry, quantum field theory, quantum technology, and quantum information science. Quantum mechanics can describe many systems that classical physics cannot.

2. **General Relativity**: General relativity, also known as Einstein's theory of gravity, is the geometric theory of gravitation published by Albert Einstein in 1915. It is the current description of gravitation in modern physics, generalizing special relativity and refining Newton's law of universal gravitation. General relativity provides a unified description of gravity as a geometric property of space and time.

3. **Particle Physics**: Particle physics, also known as high-energy physics, is the study of fundamental particles and forces that constitute matter and radiation. The field also studies combinations of elementary particles up to the scale of protons and neutrons. Fundamental particles in the universe are classified in the Standard Model as fermions (matter particles) and bosons (force-carrying particles).

4. **Astrophysics**: Astrophysics is a science that applies the methods and principles of physics and chemistry to the study of astronomical objects and phenomena. It seeks to ascertain the nature of heavenly bodies and is distinct from celestial mechanics, which focuses on the positions and motions of objects in space. Subjects studied in astrophysics include the Sun, stars, galaxies, and the universe.

5. **String Theory**: String theory is a theoretical framework in physics where point-like particles are replaced by one-dimensional objects called strings. These strings describe how they propagate through space and interact with each other. On distance scales larger than the string scale, a string behaves like a particle, with its properties determined by the vibrational state of the string
```

Here is the logs on Upstash Console:

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=2eb392c33e06bfef35c7f9ba47a9d1d8" data-og-width="1688" width="1688" data-og-height="964" height="964" data-path="img/workflow/agents/logs/logs-single.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=91ac436abaf4ec503c22a76c14cf3836 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=b38e9d20fe78b1aed8364a2c95fe7353 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=00c4f3a3ed613b9130de190929baa5e8 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=ebb31a39aa7663d3f34d958eec309539 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=a69d7d379eb15452544cdbdef44a7f11 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-single.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=fcc21ebc01199a41529ca7eb6066f050 2500w" />

In the logs, you can see that the **academic agent** was called. It decided to invoke **wikiTool** five times in parallel. Once the tool requests were completed, the agent summarized the results from the individual calls in one final response and returned the outcome.

### Multi Agents

```ts Multi Agents {45-53} theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";
import * as mathjs from 'mathjs'
import { tool } from "ai";
import { z } from "zod";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-4o');

  const researcherAgent = context.agents.agent({
    model,
    name: 'academic',
    maxSteps: 2,
    tools: {
      wikiTool: new WikipediaQueryRun({
        topKResults: 1,
        maxDocContentLength: 500,
      })
    },
    background:
      'You are researcher agent with access to Wikipedia. ' +
      'Utilize Wikipedia as much as possible for correct information',
  });

  const mathAgent = context.agents.agent({
    model,
    name: "mathematician",
    maxSteps: 2,
    tools: {
      calculate: tool({
        description:
          'A tool for evaluating mathematical expressions. ' +
          'Example expressions: ' +
          "'1.2 * (2 + 4.5)', '12.7 cm to inch', 'sin(45 deg) ^ 2'." +
          "only call this tool if you need to calculate a mathematical expression." +
          "when writing an expression, don't use words like 'thousand' or 'million'",
        parameters: z.object({ expression: z.string() }),
        execute: async ({ expression }) => mathjs.evaluate(expression),
      }),
    },
    background:
      "You are a mathematician agent which can utilize" +
      "a calculator to compute expressions"
  })

  const task = context.agents.task({
    model,
    maxSteps: 3,
    agents: [researcherAgent, mathAgent],
    prompt: "Tell me about 3 cities in Japan and calculate the sum of their populations",
  });
  const { text } = await task.run();
  console.log("result:", text)
})
```

As response to the task, the agents generate the following response:

```
Here is a brief overview of three cities in Japan:

### Tokyo
- **Official Name**: Tokyo Metropolis
- **Population**: Over 14 million in the city proper as of 2023.
- **Significance**: Capital of Japan and one of the most populous urban areas in the world.

### Osaka
- **Japanese Name**: √•¬§¬ß√©√•¬∏ (√Ösaka-shi)
- **Population**: 2.7 million as per the 2020 census.
- **Significance**: Capital and most populous city in Osaka Prefecture, third-most populous city in Japan.

### Kyoto
- **Japanese Name**: √§¬∫¬¨√©¬Ω√•¬∏ (Ky√Öto-shi)
- **Population**: 1.46 million as of 2020.
- **Significance**: Capital city of Kyoto Prefecture, ninth-most populous city in Japan.

The sum of their populations is approximately 18.16 million.
```

Here are the logs on Upstash Console:

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=227f8aedb17c44c05fc1a0f43d0c0edd" data-og-width="1432" width="1432" data-og-height="1128" height="1128" data-path="img/workflow/agents/logs/logs-multi.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=503c494bbc0762886cfac9b9795fb53d 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=147a11539d55081f9ec45f141a464aae 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=f65166e3d371f7c5c9841e76a59e666e 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=62254d2c1a7a58db3857ddbc7c0cf37c 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=0953b2c9b8ba3103a9a13a5271d7b8ad 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-multi.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=21741030eeddaafbe2245e4e5b4d242f 2500w" />

The logs show that the `Manager LLM` first called the `academic` agent. The `academic` agent used the `wikiTool` three times, each with a different Japanese city, and summarized the results. Next, the `Manager LLM` called the `mathematician` agent, which used its `calculate` tool to compute the total population of the three cities and returned the result to the `Manager LLM`. With information about the cities and their total population, the `Manager LLM` generated the final response.


# Getting Started
Source: https://upstash.com/docs/workflow/agents/getting-started



In this guide, we will be using **Next.js**. If you're working with a different supported framework, you can find instructions on how to define a workflow endpoint in the [quickstarts](/workflow/quickstarts/platforms).

If you're new to **Upstash Workflow**, it's a good idea to start by exploring the [Local Development documentation](/workflow/howto/local-development). This guide will help you set up and use Upstash Workflow in a local environment.

## Installation

First, create a new Next.js project with:

```
npx create-next-app@latest [project-name] [options]
```

Then, install the following packages:

```
npm i @upstash/workflow ai zod
```

## Start Local QStash Server

Next, start the local QStash server with the following:

<CodeGroup>
  ```bash npm theme={"system"}
  npx @upstash/qstash-cli dev
  ```

  ```bash pnpm theme={"system"}
  pnpm dlx @upstash/qstash-cli dev
  ```
</CodeGroup>

For other local development options, you can refer to [the local development documentation](/workflow/howto/local-development).

## Set Environment Variables

Once you start the QStash server, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env.local` file together with `OPENAI_API_KEY` env variable:

```txt .env.local theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"

OPENAI_API_KEY=<OPENAI_API_KEY>
```

## Define an endpoint

Next, we will define the endpoint to run the agent.

```ts app/workflow/route.ts theme={"system"}
import { z } from "zod";
import { tool } from "ai";

import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve<{ prompt: string }>(async (context) => {
  const prompt = context.requestPayload.prompt
  const model = context.agents.openai('gpt-3.5-turbo')

  const communicatorAgent = context.agents.agent({
    model,
    name: 'communicatorAgent',
    maxSteps: 2,
    tools: {
      communicationTool: tool({
        description: 'A tool for informing the caller about your inner thoughts',
        parameters: z.object({ message: z.string() }),
        execute: async ({ message }) => {
          console.log("Inner thought:", message)
          return "success"
        }
      })
    },
    background:
      'Answer questions directed towards you.' +
      ' You have access to a tool to share your inner thoughts' +
      ' with the caller. Utilize this tool at least once before' +
      ' answering the prompt. In your inner thougts, briefly' +
      ' explain what you will talk about and why. Keep your' +
      ' answers brief.',
  })

  const task = context.agents.task({
    agent: communicatorAgent,
    prompt
  })

  const { text } = await task.run()

  console.log("Final response:", text);
})
```

You can refer to the documentations for [defining a workflow endpoint](/workflow/basics/serve) and [the Agents API features](/workflow/agents/features) to learn more.

## Calling the Endpoint

To run the endpoint, first run the Next.js app with:

```bash  theme={"system"}
npm run dev
```

Then, we call the endpoint using [the Workflow Client](/workflow/basics/client):

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({
  baseUrl: process.env.QSTASH_URL,
  token: process.env.QSTASH_TOKEN!,
})

const workflowRunId = await client.trigger({
  url: "http://127.0.0.1:3000/workflow",
  body: { prompt: "Explain the future of space exploration" },
  keepTriggerConfig: true
})

console.log(workflowRunId);
```

<Tip>
  If you are using a local tunnel, replace the url above (`http://127.0.0.1:3000`)
  with the public URL.
</Tip>

In the console where you run the Next.js app, you should see logs like this:

```
Inner thought: I will discuss the future of space
exploration and the potential advancements in
technology and missions.

Final response: The future of space exploration
holds exciting possibilities with advancements
in technology, potential manned missions to
Mars, increased commercial space travel,
and exploration of distant celestial
bodies.
```

If you [run the same endpoint using a local tunnel](/workflow/howto/local-development#local-tunnel-with-ngrok), you can also see how Upstash Workflow runs the agent in steps:

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=06263d5c6a05215050ed332066e7cc9e" data-og-width="1500" width="1500" data-og-height="504" height="504" data-path="img/workflow/agents/logs/logs-getting-started.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=02ab9a40424c2b9444d6116570202051 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=e6021175a719d20742f8430265350aa7 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=140cbec73f3eead37714833734916945 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9ce60b030405c0804ee051eade94725c 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9637a6cf273b0c2c5d6d81ee3a442162 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-getting-started.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9d06b5804db577b1175c762a277f9a53 2500w" />

Each tool invocation and LLM call is a seperate step. Our agent first made a call to OpenAI to decide whether to use a tool or reply right away. OpenAI responded with a request to use the tool `communicationTool`. Tool was executed and OpenAI was called with the result of the tool. OpenAI then responded with the final response.


# Overview
Source: https://upstash.com/docs/workflow/agents/overview



The **Agents API** of Upstash Workflow enables you to:

* Execute an individual agent or facilitate collaboration among multiple agents.
* Integrate any tool compatible with AI SDK or LangChain.
* Reliably invoke agents without concerns about timeouts or transient errors.
* Unlike mainstream agent frameworks, we prioritize debuggability and extensibility.

To get started, you can refer to the [Getting Started page](/workflow/agents/getting-started). For more details about the features, you can refer to [the Features page](/workflow/agents/features).

<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

## Agent Patterns

If you're interested, you can also explore our rich examples that showcase how various patterns can be built using the Agents API:

<CardGroup cols={2}>
  <Card title="Prompt Chaining" icon="link" href="/workflow/agents/patterns/prompt-chaining">
    Sequential LLM calls where each output becomes the input for the next, enabling structured reasoning and step-by-step task completion.
  </Card>

  <Card title="Evaluator-optimizer" icon="arrows-rotate" href="/workflow/agents/patterns/evaluator-optimizer">
    A feedback loop where LLM outputs are evaluated and refined iteratively to improve accuracy and relevance.
  </Card>

  <Card title="Parallelization" icon="arrows-to-dot" href="/workflow/agents/patterns/parallelization">
    Distribute tasks across multiple LLMs and aggregate the results for efficient handling of complex or large-scale operations.
  </Card>

  <Card title="Orchestrator-workers" icon="sparkles" href="/workflow/agents/patterns/orchestrator-workers">
    A central orchestrator directs multiple worker LLMs to complete subtasks and synthesize their outputs for complex operations.
  </Card>
</CardGroup>

<Snippet file="workflow/agent-examples.mdx" />


# Evaluator-Optimizer
Source: https://upstash.com/docs/workflow/agents/patterns/evaluator-optimizer



<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=397ca67e5abd9c7a2a2adc010c53889d" data-og-width="1654" width="1654" data-og-height="740" height="740" data-path="img/workflow/agents/diagram/evaluator-diagram.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=bc93c85c311f4cba37fc0176535284b0 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=95a68c5e03c1b5ef8d4223eda31c0581 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8af28e72146c82aacc173da479c17a67 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=14a51520d0b8b163f790e2f2763eb389 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=212f123c10cad13a8e607f4ef9d326b5 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/evaluator-diagram.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=60b59c783ea112d1c3df2cd731c2d6a3 2500w" />

In this example, the generator creates output and passes it to the evaluator, which evaluates the response. If the evaluation fails, the evaluator returns corrections, and the generator is called again using the corrected output.

```ts  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo');

  // Generator agent that generates content
  const generator = context.agents.agent({
    model,
    name: 'generator',
    maxSteps: 1,
    background: 'You are an agent that generates text based on a prompt.',
    tools: {}
  });

  // Evaluator agent that evaluates the text and gives corrections
  const evaluator = context.agents.agent({
    model,
    name: 'evaluator',
    maxSteps: 1,
    background: 'You are an agent that evaluates the generated text and provides corrections if needed.',
    tools: {}
  });

  let generatedText = '';
  let evaluationResult = '';

  const prompt = "Generate a short explanation of quantum mechanics.";
  let nextPrompt = prompt;
  for (let i = 0; i < 3; i++) {
    // Construct prompt for generator: 
    // - If there's no evaluation, use the original prompt
    // - If there's an evaluation, provide the prompt, the last generated text, and the evaluator's feedback
    if (evaluationResult && evaluationResult !== "PASS") {
      nextPrompt = `Please revise the answer to the question "${prompt}". Previous answer was: "${generatedText}", which received this feedback: "${evaluationResult}".`;
    }

    // Generate content
    const generatedResponse = await context.agents.task({ agent: generator, prompt: nextPrompt }).run();
    generatedText = generatedResponse.text

    // Evaluate the generated content
    const evaluationResponse = await context.agents.task({ agent: evaluator, prompt: `Evaluate and provide feedback for the following text: ${generatedText}` }).run();
    evaluationResult = evaluationResponse.text

    // If the evaluator accepts the content (i.e., "PASS"), stop
    if (evaluationResult.includes("PASS")) {
      break;
    }
  }

  console.log(generatedText);
});
```

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=a4233550ccd453181bf070f154f0eb52" data-og-width="1418" width="1418" data-og-height="704" height="704" data-path="img/workflow/agents/logs/logs-evaluator.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=07ae6cc3eb68aae8f842c76bdbbe183d 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=6233eca76ffa2ed033845fdf43505f5d 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=83df7e9e7ae90ee6dc28161a55e488e1 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=f692b301051ab223c07a884bb6169268 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=c1e97fa08c6cbbf404cbc3ed6c6e9031 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-evaluator.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=876e3b25c1de8b0f8bc1ff79c85505bd 2500w" />

In response to the prompt, our agents generate this response:

```
Quantum mechanics is a branch of physics that describes the behavior of particles at the smallest scales, such as atoms and subatomic particles. It introduces the concept of quantized energy levels, wave-particle duality, and probabilistic nature of particles. In quantum mechanics, particles can exist in multiple states simultaneously until measured, and their behavior is governed by mathematical equations known as wave functions. This theory has revolutionized our understanding of the fundamental building blocks of the universe and has led to the development of technologies like quantum computing and quantum cryptography.
```


# Orchestrator-Workers
Source: https://upstash.com/docs/workflow/agents/patterns/orchestrator-workers



<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=7c8aebde675a468301b2f3c136ab1ecd" data-og-width="2234" width="2234" data-og-height="842" height="842" data-path="img/workflow/agents/diagram/orchestrator-diagram.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8fc7ae85a5d783ac46a41acc819ccb11 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=567d98e7e97f1ecd5de8c759288e6c65 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=d3176e7e279faac3cc5135333d2c57ca 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=e97f8ea8a2f72f1bb43cd1554d4641ef 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9527a8bfacd689c6925e7c5c19dec159 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/orchestrator-diagram.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=bbdc8e82d3fa5e902253ece140434df7 2500w" />

This workflow uses an orchestrator to direct multiple worker agents to handle different subtasks, then synthesizes their outputs.

```ts  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

const wikiTool = new WikipediaQueryRun({
  topKResults: 1,
  maxDocContentLength: 500,
})

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-4o');

  // Worker agents
  const worker1 = context.agents.agent({
    model,
    name: 'worker1',
    tools: { wikiTool },
    maxSteps: 3,
    background: 'You are a worker agent that answers general questions about advanced physics.'
  });

  const worker2 = context.agents.agent({
    model,
    name: 'worker2',
    tools: { wikiTool },
    maxSteps: 3,
    background: 'You are a worker agent that answers questions about quantum mechanics.'
  });

  const worker3 = context.agents.agent({
    model,
    name: 'worker3',
    tools: { wikiTool },
    maxSteps: 3,
    background: 'You are a worker agent that answers questions about relativity.'
  });

  // Synthesizing results
  const task = context.agents.task({
    model,
    prompt: `Create a Q&A for advanced topics in physics`,
    agents: [worker1, worker2, worker3],
    maxSteps: 3,
  })
  const { text } = await task.run();

  console.log(text);
});
```

If you wish to manually use the model results instead of utilizing a [manager LLM](/workflow/agents/overview#multi-agents) as we did in this example, see the [parallelization example](/workflow/agents/patterns/parallelization)

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=ee2002c8832b16d0c94dd4807bfbc58d" data-og-width="1290" width="1290" data-og-height="1386" height="1386" data-path="img/workflow/agents/logs/logs-manager.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=973c6e8c45b96926995784ef35bfdf6c 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8ab23efb24eee13e5cf3145809d0db83 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=62bc7677694fb9780b31059c51412d7f 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=0109884fcffd9941d8f7e494d5825b80 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=71cbe64f7bf0cd0117fa9ce1592e7697 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-manager.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=a0e78ea6de5beabf3e6f2232c39a507a 2500w" />

In response to the prompt, the agents create the following response:

```
### Quantum Mechanics

**Q: What is quantum mechanics?**
A: Quantum mechanics is a fundamental theory in physics that describes the behavior of nature at the atomic and subatomic levels. It serves as the foundation for all quantum physics, including quantum chemistry, quantum field theory, quantum technology, and quantum information science.

**Q: What are some key principles of quantum mechanics?**
A: 
1. **Wave-Particle Duality**: Particles exhibit both wave-like and particle-like properties.
2. **Uncertainty Principle**: Certain pairs of physical properties, like position and momentum, cannot be simultaneously measured with arbitrary precision.
3. **Quantum Superposition**: A quantum system can exist in multiple states at once until it is measured.
4. **Quantum Entanglement**: Particles become interconnected such that the state of one influences the state of another, regardless of distance.
5. **Quantization**: Energy levels in quantum systems are discrete.
6. **Probability and Wave Functions**: Quantum systems are described by wave functions, which provide probabilities of finding a system in a particular state.
7. **Observer Effect**: Measurement affects the system being observed.

### Relativity

**Q: What is the theory of relativity?**
A: Developed by Albert Einstein, the theory of relativity encompasses two interrelated theories: special relativity and general relativity.

**Q: What is special relativity?**
A: Proposed by Einstein in 1905, special relativity addresses the relationship between space and time in the absence of gravity. It is based on two key postulates: the invariance of physical laws in all inertial frames and the constancy of the speed of light in a vacuum.

**Q: What is general relativity?**
A: Published by Einstein in 1915, general relativity is a geometric theory of gravitation. It describes gravity as a geometric property of space and time, or four-dimensional spacetime, and explains how massive objects cause a distortion in spacetime.

These topics challenge classical intuitions and have led to significant advancements in our understanding of the universe and the development of new technologies.
```


# Parallelization
Source: https://upstash.com/docs/workflow/agents/patterns/parallelization



<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=e2a0c9d6b9087aa110a5552a0343a616" data-og-width="1856" width="1856" data-og-height="880" height="880" data-path="img/workflow/agents/diagram/parallel-diagram.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=b377332ee8b667f81791816d635edd91 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=b27d5a7c75ba10432b239ab0ac9e39d3 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=ac6a7bdc1da4f5b155826bcc9f996a79 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=dc1ac647c5d2cf7ad062e7753cc305cd 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=970752cda6b5a12bab4ec923f7f0ccbd 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/parallel-diagram.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8214652e3e4c8dca441346c945518675 2500w" />

This workflow calls multiple agents simultaneously to handle tasks, and then aggregates their results.

```ts  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo');

  // Define worker agents
  const worker1 = context.agents.agent({
    model,
    name: 'worker1',
    maxSteps: 1,
    background: 'You are an agent that explains quantum physics.',
    tools: {}
  });

  const worker2 = context.agents.agent({
    model,
    name: 'worker2',
    maxSteps: 1,
    background: 'You are an agent that explains relativity.',
    tools: {}
  });

  const worker3 = context.agents.agent({
    model,
    name: 'worker3',
    maxSteps: 1,
    background: 'You are an agent that explains string theory.',
    tools: {}
  });

  // Await results
  const [result1, result2, result3] = await Promise.all([
    context.agents.task({ agent: worker1, prompt: "Explain quantum physics." }).run(),
    context.agents.task({ agent: worker2, prompt: "Explain relativity." }).run(),
    context.agents.task({ agent: worker3, prompt: "Explain string theory." }).run(),
  ]);

  // Aggregating results
  const aggregator = context.agents.agent({
    model,
    name: 'aggregator',
    maxSteps: 1,
    background: 'You are an agent that summarizes multiple answers.',
    tools: {}
  });

  const task = await context.agents.task({
    agent: aggregator,
    prompt: `Summarize these three explanations: ${result1.text}, ${result2.text}, ${result3.text}`
  })
  const finalSummary = await task.run();

  console.log(finalSummary.text);
});

```

You can also see how the same thing can be achieved using an manager agent in [orchestrator-workers example](/workflow/agents/patterns/orchestrator-workers).

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=d77a76d3ecd3e82cda89da7e2115f4b1" data-og-width="1434" width="1434" data-og-height="622" height="622" data-path="img/workflow/agents/logs/logs-parallel.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=7abb49e99f1add232802f0f7274df800 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8ec77a3ee56aba8e6f6dfbf45fb87b1c 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=646834d1ee837f7a3e6872234632f461 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=cfd16d98af9a309c2b17d9a03a88644c 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=deb1ae1f7cea02570dbbed29d8acdfec 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-parallel.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=c6eb085d5559d66eca4dcf931d1c357b 2500w" />

In response to the prompt, our agents generate this response:

```
Quantum physics explores the behavior of very small particles, such as atoms and subatomic particles, in the strange world of quantum mechanics, where particles can exist in multiple states simultaneously. Key principles include superposition and entanglement, leading to technological advancements like quantum computers. Relativity, developed by Albert Einstein, consists of special relativity and general relativity, explaining the behavior of objects moving at high speeds and the warping of spacetime by massive objects. String theory proposes that the universe's fundamental building blocks are tiny vibrating strings, aiming to unify the four fundamental forces of nature and suggest extra dimensions beyond the familiar ones.
```


# Prompt Chaining
Source: https://upstash.com/docs/workflow/agents/patterns/prompt-chaining



<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9da3927de6a1ad5fb0f98f72cac0cf3e" data-og-width="2420" width="2420" data-og-height="558" height="558" data-path="img/workflow/agents/diagram/prompt-chain-diagram.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=e9a735fdeb2b78dbf59354c452ac66a9 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=f416bdab7c162b795d2f75d9cc1e6dcb 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=540400910092635e06e56bdd43e2a1c6 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=58e8a04126d3d1cfa331b42c0773f93d 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=fa20136d6c7b9505b6b4f475b5bf085c 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/diagram/prompt-chain-diagram.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9dc6a4d288b55c9b854efb6b895f7ddc 2500w" />

This workflow involves chaining multiple LLM calls, where the output of one agent becomes the input for the next agent.

```ts  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

export const { POST } = serve(async (context) => {
  const model = context.agents.openai('gpt-3.5-turbo');

  const agent1 = context.agents.agent({
    model,
    name: 'firstAgent',
    maxSteps: 1,
    background: 'You are an agent that lists famous physicists.',
    tools: {}
  });

  const agent2 = context.agents.agent({
    model,
    name: 'secondAgent',
    // set to 2 as this agent will first request tools
    // and then summarize them:
    maxSteps: 2,
    background:
      'You are an agent that describes the work of' +
      ' the physicists listed in the previous prompt.',
    tools: {
      wikiTool: new WikipediaQueryRun({
        topKResults: 1,
        maxDocContentLength: 500,
      })
    }
  });

  const agent3 = context.agents.agent({
    model,
    name: 'thirdAgent',
    maxSteps: 1,
    background:
      'You are an agent that summarizes the ' +
      'works of the physicists mentioned previously.',
    tools: {}
  });

  // Chaining agents
  const firstOutput = await context.agents.task({
    agent: agent1,
    prompt: "List 3 famous physicists."
  }).run();

  const secondOutput = await context.agents.task({
    agent: agent2,
    prompt: `Describe the work of: ${firstOutput.text}`
  }).run();
  

  const { text } = await context.agents.task({
    agent: agent3,
    prompt: `Summarize: ${secondOutput.text}`
  }).run();

  console.log(text);
});
```

<img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=3993f6d3eb9278bc17d2e6bbdab8e74f" data-og-width="1430" width="1430" data-og-height="852" height="852" data-path="img/workflow/agents/logs/logs-chain.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=fee5c241e9288fc6379f7f42842f1e54 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=98bd6c7e38a7692126c8c145e5bfa072 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=c7556e42ee5f501d7a09de14a10699b5 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=f690b9860bb163f8f8f68bf4de3d034d 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=ea4ee9de9daafb71ad2c679e108db74c 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/agents/logs/logs-chain.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=3aca877adf2e30f1b95523f9d4657027 2500w" />

In response to the prompt, our agents generate this response:

```
Albert Einstein was a German physicist known for his theory of relativity and the famous equation E=mc^2. He made significant contributions to quantum mechanics and was awarded the Nobel Prize in Physics in 1921. 

Isaac Newton, an English polymath, was a key figure in the Scientific Revolution and the Enlightenment. He is famous for his laws of motion and universal gravitation, as outlined in his book "Philosophi√É¬¶ Naturalis Principia Mathematica."

Marie Curie, a Polish-French physicist and chemist, conducted pioneering research on radioactivity and was the first woman to win a Nobel Prize. She is the only person to win Nobel Prizes in two scientific fields and her work has had a lasting impact on physics and chemistry.
```


# Caveats
Source: https://upstash.com/docs/workflow/basics/caveats



## Introduction

In this guide, we'll look at best practices and caveats for using Upstash Workflow.

## Core Principles

### Execute business logic in `context.run`

Your workflow endpoint will be called multiple times during a workflow run. Therefore:

* Place your business logic code inside the `context.run` function for each step
* Code outside `context.run` only serves to connect steps

Example:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    const result = await context.run("step-1", () => {
      return { success: true }
    })

    console.log("This log will appear multiple times")

    await context.run("step-2", () => {
      console.log("This log will appear just once")
      console.log("Step 1 status is:", result.success)
    })
  })
  ```

  ```python main.py theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      async def _step_1() -> Dict:
          return {"success": True}

      result = await context.run("step-1", _step_1)

      print("This log will appear multiple times")

      async def _step_2() -> None:
          print("This log will appear just once")
          print("Step 1 status is:", result["success"])

      await context.run("step-2", _step_2)

  ```
</CodeGroup>

### Return Results from context.run for Later Use

Always return step results if needed in subsequent steps.

<CodeGroup>
  ```typescript ‚ùå Incorrect - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    let result

    await context.run("step-1", async () => {
      result = await someWork(input)
    })
    await context.run("step-2", async () => {
      await someOtherWork(result)
    })
  })
  ```

  ```typescript ‚úÖ Correct - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    const result = await context.run("step-1", async () => {
      return await someWork(input)
    })

    await context.run("step-2", async () => {
      someOtherWork(result)
    })
  })
  ```

  ```python ‚ùå Incorrect - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      result = None

      async def _step_1() -> Dict:
          nonlocal result
          result = await some_work(input)

      await context.run("step-1", _step_1)

      async def _step_2() -> None:
          await some_other_work(result)

      await context.run("step-2", _step_2)

  ```

  ```python ‚úÖ Correct - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      async def _step_1() -> Dict:
          return await some_work(input)

      result = await context.run("step-1", _step_1)

      async def _step_2() -> None:
          await some_other_work(result)

      await context.run("step-2", _step_2)

  ```
</CodeGroup>

Because your workflow endpoint is called multiple times, `result` will be unitialized when the endpoint is called again to run `step-2`.

If you are curious about why an endpoint is called multiple times, see [how Workflow works](/workflow/basics/how).

## Avoiding Common Pitfalls

### Avoid Non-deterministic Code Outside `context.run`

A workflow endpoint should always produce the same results, even if it's called multiple times. Avoid:

* Non-idempotent functions
* Time-dependent code
* Randomness

Example of what to avoid:

<CodeGroup>
  ```typescript ‚ùå Non-idempotent functions - TypeScript theme={"system"}
  export const { POST } = serve<{ entryId: string }>(async (context) => {
    const { entryId } = context.requestPayload;

    // üëá Problem: Non-idempotent function outside context.run:
    const result = await getResultFromDb(entryId);
    if (result.return) {
      return;
    }

    // ...
  })
  ```

  ```typescript ‚ùå Time-dependent code - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    // üëá Problem: time-dependent code
    if (Date.now() % 5 == 2) {
      await context.run("step-1", () => {
        // ...
      })
    } else {
      await context.run("step-2", () => {
        // ...
      })
    }
  })
  ```

  ```typescript ‚ùå Random code - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    // üëá Problem: random code
    if (Math.floor(Math.random() * 10) % 5 == 2) {
      await context.run("step-1", () => {
        // ...
      })
    } else {
      await context.run("step-2", () => {
        // ...
      })
    }
  })
  ```

  ```python ‚ùå Non-idempotent functions - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      entry_id = context.request_payload["entry_id"]

      # üëá Problem: Non-idempotent function outside context.run:
      result = await get_result_from_db(entry_id)
      if result.should_return:
          return

      # ...

  ```

  ```python ‚ùå Time-dependent code - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      # üëá Problem: time-dependent code
      if time.time() % 5 == 2:
          await context.run("step-1", lambda: ...)
      else:
          await context.run("step-2", lambda: ...)

  ```

  ```python ‚ùå Random code - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      # üëá Problem: random code
      if random.randint(0, 9) % 5 == 2:
          await context.run("step-1", lambda: ...)
      else:
          await context.run("step-2", lambda: ...)

  ```
</CodeGroup>

If you implement a non-idempotent code like the one shown above, you might encounter `Failed to authenticate Workflow request.` errors. This can happen if you `return` based on the result of the non-idempotent code before any workflow step.

To prevent this, ensure that the non-idempotent code (such as `getResultFromDb` in the example) runs within `context.run`.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const result = await context.run(async () => {
    await getResultFromDb(entryId)
  });
  if (result.return) {
    return;
  }
  ```

  ```python Python theme={"system"}
  async def _get_result_from_db():
      return await get_result_from_db(entry_id)

  result = await context.run("get-result-from-db", _get_result_from_db)

  if result.should_return:
      return

  ```
</CodeGroup>

### Ensure Idempotency in `context.run`

Business logic should be idempotent due to potential retries in distributed systems. In other words, **when a workflow runs twice with the same input, the end result should be the same as if the workflow only ran once**.

In the example below, the `someWork` function must be idempotent:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    await context.run("step-1", async () => {
      return someWork(input)
    })
  })
  ```

  ```python main.py theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      async def _step_1() -> None:
          return await some_work(input)

      await context.run("step-1", _step_1)

  ```
</CodeGroup>

Imagine that `someWork` executes once and makes a change to a database. However, before the database had a chance to respond with the successful change, the connection is lost. Your Workflow cannot know if the database change was successful or not. The caller has no choice but to retry, which will cause `someWork` to run twice.

If `someWork` is not idempotent, this could lead to unintended consequences. For example duplicated records or corrupted data. Idempotency is crucial to maintaining the integrity and reliability of your workflow.

### Don't Nest Context Methods

Avoid calling `context.call`, `context.sleep`, `context.sleepFor`, or `context.run` within another `context.run`.

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"

  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload

    await context.run("step-1", async () => {
      await context.sleep(...) // ‚ùå INCORRECT
      await context.run(...) // ‚ùå INCORRECT
      await context.call(...) // ‚ùå INCORRECT
    })
  })
  ```

  ```python main.py theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      async def _step_1() -> None:
          await context.sleep(...) #  ‚ùå INCORRECT
          await context.run(...) #  ‚ùå INCORRECT
          await context.call(...) #  ‚ùå INCORRECT

      await context.run("step-1", _step_1)

  ```
</CodeGroup>

### Include At Least One Step in Workflow

Every workflow must include at least one step execution with `context.run`. If no steps are defined, the workflow will throw a `Failed to authenticate Workflow request.` error.

<CodeGroup>
  ```typescript ‚ùå Missing steps - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload
    
    // üëá Problem: No context.run call
    console.log("Processing input:", input)
    
    // This workflow will fail with "Failed to authenticate Workflow request."
  })
  ```

  ```typescript ‚úÖ Correct - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload
    
    // üëá At least one step is required
    await context.run("dummy-step", async () => {
      return
    })
  })
  ```

  ```python ‚ùå Missing steps - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload
      
      # üëá Problem: No context.run call
      print("Processing input:", input)
      
      # This workflow will fail with "Failed to authenticate Workflow request."
  ```

  ```python ‚úÖ Correct - Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload
      
      # üëá At least one step is required
      async def _dummy_step():
          return
          
      await context.run("dummy-step", _dummy_step)
  ```
</CodeGroup>

Even for the placeholder implementations, you must include one dummy step for the Workflow authentication mechanism to function properly.

### Avoid Promise.any

In workflow-js, you can use [`Promise.all` to run steps in parallel](/workflow/howto/parallel-runs). However, a similar method, [`Promise.any`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any), is not supported for workflow steps.

While `Promise.all` works seamlessly, `Promise.any` does not currently function with workflow steps. We are exploring the possibility of adding support for `Promise.any` in the future.

If you have a specific use case that requires `Promise.any`, don't hesitate to reach out to Upstash support.


# Overview
Source: https://upstash.com/docs/workflow/basics/client



The Workflow Client lets you programmatically interact with your workflow runs.
You can use it from the same application that hosts your workflows, or from any external service.

## Initialization

Initialize a new client with your credentials:

```javascript  theme={"system"}
import { Client } from "@upstash/workflow"

const client = new Client({
  baseUrl: process.env.QSTASH_URL!,
  token: process.env.QSTASH_TOKEN!
})
```

The client is lightweight and stateless. You can safely reuse a single instance across your application.

## Functionality

The client exposes a set of functions to manage workflow runs and inspect their state:

* [client.trigger](/workflow/basics/client/trigger)
* [client.cancel](/workflow/basics/client/cancel)
* [client.notify](/workflow/basics/client/notify)
* [client.logs](/workflow/basics/client/logs)
* [client.getWaiters](/workflow/basics/client/waiters)
* client.dlq
  * [client.dlq.list](/workflow/basics/client/dlq/list)
  * [client.dlq.restart](/workflow/basics/client/dlq/restart)
  * [client.dlq.resume](/workflow/basics/client/dlq/resume)
  * [client.dlq.retryFailureFunction](/workflow/basics/client/dlq/callback)


# client.cancel
Source: https://upstash.com/docs/workflow/basics/client/cancel



There are multiple ways you can cancel workflow runs:

* Pass one or more workflow run ids to cancel them
* Pass a workflow url to cancel all runs starting with this url
* cancel all pending or active workflow runs

## Arguments

<ParamField body="ids" type="array">
  The set of workflow run IDs you want to cancel
</ParamField>

<ParamField body="urlStartingWith" type="string">
  The URL address you want to filter while canceling
</ParamField>

<ParamField body="all" type="bool">
  Whether you want to cancel all workflow runs without any filter.
</ParamField>

## Usage

### Cancel a set of workflow runs

```ts  theme={"system"}
// cancel a single workflow
await client.cancel({ ids: "<WORKFLOW_RUN_ID>" });

// cancel a set of workflow runs
await client.cancel({ ids: ["<WORKFLOW_RUN_ID_1>", "<WORKFLOW_RUN_ID_2>"] });
```

### Cancel workflow runs with URL filter

If you have an endpoint called `https://your-endpoint.com` and you
want to cancel all workflow runs on it, you can use `urlStartingWith`.

Note that this will cancel workflows in all endpoints under
`https://your-endpoint.com`.

```ts  theme={"system"}
await client.cancel({ urlStartingWith: "https://your-endpoint.com" });
```

### Cancel *all* workflows

To cancel all pending and currently running workflows, you can
do it like this:

```ts  theme={"system"}
await client.cancel({ all: true });
```


# client.dlq.retryFailureFunction
Source: https://upstash.com/docs/workflow/basics/client/dlq/callback



If a workflow's `failureFunction` or `failureUrl` request has failed, you can retry it using the `retryFailureFunction` method:

## Arguments

## Response

## Usage

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

// Retry the failure callback for a specific DLQ message
const response = await client.dlq.retryFailureFunction({
  dlqId: "dlq-12345" // The ID of the DLQ message to retry
});
```


# client.dlq.list
Source: https://upstash.com/docs/workflow/basics/client/dlq/list



The `dlq.list` method retrieves messages that were sent to the **Dead Letter Queue (DLQ)**.

DLQ messages represent failed workflow or QStash deliveries that could not be retried successfully.

## Arguments

<ParamField body="cursor" type="string" optional>
  A pagination cursor from a previous request.
  Use this to fetch the next batch of results.
</ParamField>

<ParamField body="count" type="number" optional>
  Maximum number of DLQ messages to return.
  Defaults to a system-defined limit if not provided.
</ParamField>

<ParamField body="filter" type="object" optional>
  Filter options for narrowing down DLQ messages

  <Expandable defaultOpen>
    <ParamField body="fromData" type="number">
      Earliest timestamp (Unix ms) to include.
    </ParamField>

    <ParamField body="toDate" type="number">
      Latest timestamp (Unix ms) to include.
    </ParamField>

    <ParamField body="url" type="number">
      Filter messages that targeted a specific URL.
    </ParamField>

    <ParamField body="responseStatus" type="number">
      Filter by HTTP response status code.
    </ParamField>
  </Expandable>
</ParamField>

## Response

<ResponseField name="messages" type="DLQMessage[]">
  An array of DLQ messages that match the provided filters.
</ResponseField>

<ResponseField name="cursor" type="string">
  A cursor to paginate through additional results.
  If not returned, you have reached the end of the DLQ.
</ResponseField>

## Usage

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

// üëá List all DLQ messages
const { messages, cursor } = await client.dlq.list({ filter: dlqFilters });

// üëá List with pagination and filtering
const result = await client.dlq.list({
  cursor,
  count: 10,
  filter: {
    fromDate: Date.now() - 86400000, // last 24 hours
    toDate: Date.now(),
    url: "https://your-endpoint.com",
    responseStatus: 500
  }
});

```


# client.dlq.restart
Source: https://upstash.com/docs/workflow/basics/client/dlq/restart



The `dlq.restart` method restarts one or more workflow runs from **Dead Letter Queue (DLQ)**.
This allows you to reprocess workflow runs that previously failed after exhausting retries.

## Arguments

<ParamField body="dlqId" type="string|string[]" required>
  The DLQ entry ID or list of IDs to restart.
  Use the `dlqId` field from messages returned by `client.dlq.list()`.
</ParamField>

<ParamField body="flowControl" type="object" optional>
  An optional flow control configuration to limit concurrency and execution rate of restarted workflow runs.

  See [Flow Control](/workflow/features/flow-control) for details.

  <Expandable title="properties">
    <ParamField body="key" type="string">
      A logical grouping key that identifies which requests share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of concurrent requests allowed.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit. Default is `1s`.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="retries" type="number" optional>
  Number of retry attempts to apply to the restarted workflow invocation.
  Defaults to `3` if not provided.
</ParamField>

## Response

`client.dlq.restart()` returns one or more objects containing details of the restarted workflow run(s):

<ResponseField name="workflowRuns" type="object[]">
  <Expandable defaultOpen>
    <ResponseField name="workflowRunId" type="string">
      The ID of the new workflow run created from the restarted DLQ message.
    </ResponseField>

    <ResponseField name="workflowCreatedAt" type="number">
      The Unix timestamp (in milliseconds) when the new workflow run was created.
    </ResponseField>
  </Expandable>
</ResponseField>

## Usage

<CodeGroup>
  ```ts Single theme={"system"}
  const { messages } = await client.dlq.list();

  const response = await client.dlq.restart({
    dlqId: messages[0].dlqId, // Use the dlqId from the message
    flowControl: {
      key: "my-flow-control-key",
      parallelism: 10,
    },
    retries: 3,
  });

  ```

  ```ts Multiple theme={"system"}
  const responses = await client.dlq.restart({
    dlqId: ["dlq-12345", "dlq-67890"],
    retries: 5,
  });
  ```
</CodeGroup>


# client.dlq.resume
Source: https://upstash.com/docs/workflow/basics/client/dlq/resume



The `dlq.resume` method resumes one or more workflow runs from the **Dead Letter Queue (DLQ)** at the point where they previously failed.
This allows you to continue execution from the failed step instead of restarting the workflow from the beginning.

## Arguments

<ParamField body="dlqId" type="string|string[]" required>
  The DLQ entry ID or list of IDs to resume.
  Use the `dlqId` field from messages returned by `client.dlq.list()`.
</ParamField>

<ParamField body="flowControl" type="object" optional>
  An optional flow control configuration to limit concurrency and execution rate
  of resumed workflow runs.

  See [Flow Control](/workflow/features/flow-control) for details.

  <Expandable title="properties">
    <ParamField body="key" type="string">
      A logical grouping key that identifies which resumed runs share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed resumption requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of resumed runs that can execute concurrently.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit. Default is `1s`.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="retries" type="number" optional>
  Number of retry attempts to apply when resuming the workflow run.
  Defaults to `3` if not provided.
</ParamField>

## Response

`client.dlq.resume()` returns one or more objects with details of the resumed workflow run(s):

<ResponseField name="workflowRuns" type="object[]">
  <Expandable defaultOpen>
    <ResponseField name="workflowRunId" type="string">
      The ID of the workflow run resumed from the DLQ message.
    </ResponseField>

    <ResponseField name="workflowCreatedAt" type="number">
      The Unix timestamp (in milliseconds) when the resumed run was created.
    </ResponseField>
  </Expandable>
</ResponseField>

## Usage

<CodeGroup>
  ```ts Single theme={"system"}
  const { messages } = await client.dlq.list();

  const response = await client.dlq.resume({
    dlqId: messages[0].dlqId, // Use the dlqId from the message
    flowControl: {
      key: "my-flow-control-key",
      value: "my-flow-control-value",
    },
    retries: 3,
  });

  ```

  ```ts Multiple theme={"system"}
  const responses = await client.dlq.resume({
    dlqId: ["dlq-12345", "dlq-67890"],
    retries: 5,
  });
  ```
</CodeGroup>


# client.logs
Source: https://upstash.com/docs/workflow/basics/client/logs



The `logs` method retrieves workflow run logs using the [List Workflow Runs API](/workflow/rest/runs/logs).

## Arguments

<ParamField body="workflowRunId" type="string" optional>
  Filter by a specific workflow run ID.
</ParamField>

<ParamField body="count" type="number" optional>
  Maximum number of runs to return. Defaults to a system-defined value if not specified.
</ParamField>

<ParamField body="state" type="string" optional>
  Filter workflow runs by execution state.

  | State          | Description                              |
  | -------------- | ---------------------------------------- |
  | `RUN_STARTED`  | The workflow run is in progress.         |
  | `RUN_SUCCESS`  | The workflow run completed successfully. |
  | `RUN_FAILED`   | The run failed after all retries.        |
  | `RUN_CANCELED` | The run was manually canceled.           |
</ParamField>

<ParamField body="workflowUrl" type="string" optional>
  Filter by the exact workflow URL.
</ParamField>

<ParamField body="workflowCreatedAt" type="number" optional>
  Filter by the workflow creation time (Unix timestamp).
</ParamField>

<ParamField body="cursor" type="string" optional>
  A pagination cursor from a previous request.
  Use this to fetch the next set of results.
</ParamField>

## Response

<ResponseField name="cursor" type="string">
  A cursor to use for pagination.
  If no cursor is returned, there are no more workflow runs.
</ResponseField>

<Snippet file="workflow/logs.mdx" />

***

## Usage

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })
const { runs, cursor } = await client.logs({})
```


# client.notify
Source: https://upstash.com/docs/workflow/basics/client/notify



The `notify` method notifies workflows that are waiting for a specific event.

Workflows paused at a [`context.waitForEvent`](/workflow/basics/context/waitForEvent) step with the matching `eventId` will be resumed, and the provided `eventData` will be passed back to them.

## Arguments

<ParamField body="eventId" type="string" required>
  The identifier of the event to notify.
</ParamField>

<ParamField body="eventData" type="any" optional>
  Data to deliver to the waiting workflow(s).
  This value will be returned in the `eventData` field of `context.waitForEvent`.
</ParamField>

## Response

Returns a list of `Waiter` objects representing the workflows that were notified:

<Snippet file="qstash/waiter.mdx" />

## Usage

```javascript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

await client.notify({
  eventId: "my-event-id",
  eventData: "my-data", // data passed to the workflow run
});
```


# client.trigger
Source: https://upstash.com/docs/workflow/basics/client/trigger



The `trigger` method starts a new workflow run and returns its `workflowRunId`.

You can also trigger multiple workflow runs in a single call by passing an array of arguments instead of a single object.

## Arguments

<ParamField body="url" type="string" required>
  The public URL of the workflow endpoint.
</ParamField>

<ParamField body="keepTriggerConfig" type="bool" default="false" optional>
  If true, the trigger configuration (e.g. retries, flow-control) will be used for each step.

  If false, the trigger configuration will only be used in the initial request (initial step). Rest of the steps will use the configurations in the serve options.
</ParamField>

<ParamField body="workflowRunId" type="string" optional>
  A custom identifier for the workflow run.
  Each run must use a unique ID.

  The final ID will be prefixed with `wfr_`.
  For example: passing `my-workflow` results in `wfr_my-workflow`.

  If omitted, a run ID will be generated automatically.
</ParamField>

<ParamField body="body" type="string | object" optional>
  The request payload to pass into the workflow run.
  Accessible as `context.requestPayload` inside the workflow.
</ParamField>

<ParamField body="headers" type="object" optional>
  HTTP headers to pass into the workflow run.
  Accessible as `context.headers` inside the workflow.
</ParamField>

<ParamField body="retries" type="string">
  retry to use in the initial request. in the rest of the workflow, `retries` option of the `serve` will be used.
</ParamField>

<ParamField body="retryDelay" type="string">
  delay between retries.
</ParamField>

<ParamField body="flowControl" type="object" optional>
  An optional flow control configuration to limit concurrency and execution rate of the workflow runs.

  See [Flow Control](/workflow/features/flow-control) for details.

  <Expandable title="properties">
    <ParamField body="key" type="string">
      A logical grouping key that identifies which requests share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of concurrent requests allowed.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit. Default is `1s`.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="delay" type="string">
  Delay for the workflow run. This is used to delay the execution of the workflow run. The delay is in seconds or can be passed as a string with a time unit (e.g. "1h", "30m", "15s").
</ParamField>

<ParamField body="notBefore" type="number">
  Optionally set the absolute delay of this message.
  This will override the delay option.
  The message will not delivered until the specified time.

  Unix timestamp in seconds.
</ParamField>

<ParamField body="useFailureFunction" type="bool">
  If both `failureUrl` and `useFailureFunction` are provided, `useFailureFunction` takes precedence and the value of the `url` parameter is used as `failureUrl`.
</ParamField>

<ParamField body="label" type="string">
  An optional label to assign to the workflow run.
  This can be useful for identifying and filtering runs in the dashboard or logs.
</ParamField>

<ParamField body="disableTelemetry" type="boolean">
  If set to true, telemetry data collection for this workflow run will be disabled.
  By default, telemetry is enabled to help improve Upstash services.

  See the [`disableTelemetry` parameter in serve options](/workflow/basics/serve/advanced#param-disable-telemetry) for more details.
</ParamField>

## Usage

<CodeGroup>
  ```ts Single Workflow theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })

  const { workflowRunId } = await client.trigger({
    keepTriggerConfig: true,
    url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
    body: "hello there!",         // optional body
    headers: { ... },             // optional headers
    workflowRunId: "my-workflow", // optional workflow run id
    retries: 3,                   // optional retries in the initial request
    retryDelay: "1000 * (1 + retried)", // optional delay between retries
    delay: "10s"                  // optional delay value
    failureUrl: "https://<YOUR_FAILURE_URL>", // optional failure url
    useFailureFunction: true,     // whether a failure function is defined in the endpoint
    flowControl: {                // optional flow control
      key: "USER_GIVEN_KEY",
      rate: 10,
      parallelism: 5,
      period: "10m"
    },
  })
  ```

  ```ts Multiple Workflows theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })
  const results = await client.trigger([
    {
      url: "<YOUR_WORKFLOW_ENDPOINT>",
      // other options...
    },
    {
      url: "<YOUR_WORKFLOW_ENDPOINT>",
      // other options...
    },
  ])

  console.log(results[0].workflowRunId)
  // prints wfr_my-workflow
  ```
</CodeGroup>


# client.getWaiters
Source: https://upstash.com/docs/workflow/basics/client/waiters



The `getWaiters` method retrieves all waiters that are currently listening for a given event.

A **waiter** represents a workflow run that is paused at a `context.waitForEvent` step and is waiting for the specified `eventId`.

## Arguments

<ParamField body="eventId" type="string" required>
  The identifier of the event to look up.
</ParamField>

## Response

Returns a list of `Waiter` objects describing workflows that are waiting on the given event.

<Snippet file="qstash/waiter.mdx" />

## Usage

```javascript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

const result = await client.getWaiters({
  eventId: "my-event-id",
});
```


# Overview
Source: https://upstash.com/docs/workflow/basics/context



A workflow's **context** is an object provided by the route function.

The context object provides:

* **Workflow APIs** ‚Äì functions for defining workflow steps.
* **Workflow Run Properties** ‚Äì request payload, request headers, and other metadata.

<CodeGroup>
  ```typescript api/workflow/route.ts highlight={4-5} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(
    // üëá the workflow context
    async (context) => {
      // ...
    }
  );
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None: ...

  ```
</CodeGroup>

## Context Object Properties

<ParamField path="requestPayload" type="object">
  The request payload passed to the workflow run via `trigger()` call.
</ParamField>

<ParamField path="headers" type="object">
  The request headers passed to the workflow run via `trigger()` call.
</ParamField>

<ParamField path="workflowRunId" type="string">
  The unique identifier of the current workflow run.
</ParamField>

<ParamField path="url" type="string">
  The public URL of the workflow endpoint.
</ParamField>

<ParamField path="failureUrl" type="string">
  The URL used for workflow failure callback.

  If a failure function is defined, this is the same as the workflow's `url`.
</ParamField>

<ParamField path="env" type="object">
  The environment variables available to the workflow.
</ParamField>

<ParamField path="qstashClient" type="object">
  The QStash client instance used by the workflow endpoint.
</ParamField>

<ParamField path="label" type="srting | undefined">
  The label of the current workflow run, if set in [client.trigger](/workflow/basics/client/trigger).
</ParamField>

## Context Object Functions

You can use the functions exposed by context object to define workflow steps.

* [context.run](/workflow/basics/context/run)
* [context.sleep](/workflow/basics/context/sleep)
* [context.sleepUntil](/workflow/basics/context/sleepUntil)
* [context.waitForEvent](/workflow/basics/context/waitForEvent)
* [context.notify](/workflow/basics/context/notify)
* [context.invoke](/workflow/basics/context/invoke)
* [context.call](/workflow/basics/context/call)
* [context.cancel](/workflow/basics/context/cancel)
* [context.api](/workflow/basics/context/api)


# context.api
Source: https://upstash.com/docs/workflow/basics/context/api



In addition to `context.call`, you can also make third‚Äëparty requests using the `context.api` namespace.

This namespace provides built‚Äëin integrations for **OpenAI**, **Anthropic**, and **Resend**, allowing you to make requests in a **type‚Äësafe** manner.

<CodeGroup>
  ```typescript OpenAI theme={"system"}
  const { status, body } = await context.api.openai.call("Call OpenAI", {
    token: "<OPENAI_API_KEY>",
    operation: "chat.completions.create",
    body: {
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "Assistant says 'hello!'",
        },
        { role: "user", content: "User shouts back 'hi!'" },
      ],
    },
  });
  ```

  ```typescript Anthropic theme={"system"}
  const { status, body } = await context.api.anthropic.call(
    "Call Anthropic",
    {
      token: "<ANTHROPIC_API_KEY>",
      operation: "messages.create",
      body: {
        model: "claude-3-5-sonnet-20241022",
        max_tokens: 1024,
        messages: [
            {"role": "user", "content": "Hello, world"}
        ]
      },
    }
  );
  ```

  ```typescript Resend theme={"system"}
  const { status, body } = await context.api.resend.call("Call Resend", {
    token: "<RESEND_API_KEY>",
    body: {
      from: "Acme <onboarding@resend.dev>",
      to: ["delivered@resend.dev"],
      subject: "Hello World",
      html: "<p>It works!</p>",
    },
    headers: {
      "content-type": "application/json",
    },
  });
  ```
</CodeGroup>

We'll continue adding more integrations over time. If you'd like to see a specific integration, feel free to contribute to the SDK or contact us with your suggestion.

For detailed guides on usage and configuration, see the [Integrations section](/workflow/integrations/openai).


# context.call
Source: https://upstash.com/docs/workflow/basics/context/call



`context.call()` performs an HTTP request as a workflow step, supporting longer response times up to 12 hours.

The request is executed by **Upstash on your behalf**, so your application does not consume compute resources during the request duration.

If the endpoint responds with a non‚Äësuccess status code (anything outside `200‚Äì299`),
`context.call()` still returns the response and the workflow continues.
This allows you to inspect the response (via the `status` field) and decide how to handle failure cases in your logic.

If you want requests to retry automatically, you can explicitly pass a retry configuration.

## Arguments

<ParamField body="url" type="string">
  The URL of the HTTP endpoint to call.
</ParamField>

<ParamField body="method" type="string">
  TThe HTTP method to use (`GET`, `POST`, `PUT`, etc.). Defaults to `GET`.
</ParamField>

<ParamField body="body" type="string">
  The request body.
</ParamField>

<ParamField body="headers" type="object">
  A map of headers to include in the request.
</ParamField>

<ParamField body="retries">
  Number of retry attempts if the request fails. Defaults to `0` (no retries).
</ParamField>

<ParamField body="retryDelay">
  Delay between retries (in milliseconds). By default, uses exponential backoff. You can use mathematical expressions and the special variable `retried` (current retry attempt count starting from 0). Examples: `1000`, `pow(2, retried)`, `max(10, pow(2, retried))`.
</ParamField>

<ParamField body="flowControl" type="object" optional>
  Throttle outbound requests.

  See [Flow Control](/workflow/features/flow-control) for details.

  <Expandable title="properties">
    <ParamField body="key" type="string">
      A logical grouping key that identifies which requests share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of concurrent requests allowed.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit. Default is `1s`.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="timeout" type="number">
  Maximum time (in seconds) to wait for a response.
  If retries are enabled, this timeout applies individually to each attempt.
</ParamField>

<ParamField body="workflow">
  When using [`serveMany`](/workflow/howto/invoke#servemany), you can call another workflow defined in the same `serveMany` by passing it to this parameter.
</ParamField>

<ParamField body="stringifyBody" type="string" optional>
  Whether to automatically stringify the body as JSON. Defaults to `true`

  If set to `false`, the body will be required to be a string and will be sent as-is.
</ParamField>

## Response

<ResponseField name="status" type="number">
  The HTTP response status code.
</ResponseField>

<ResponseField name="body" type="string">
  The response body.

  `context.call()` attempts to parse the body as JSON.
  If parsing fails, the raw body string is returned.
</ResponseField>

<ResponseField name="headers" type="dictionary">
  The response headers.
</ResponseField>

<Tip>
  In TypeScript, you can declare the expected result type for strong typing:

  ```typescript  theme={"system"}
  type ResultType = {
    field1: string,
    field2: number
  };

  const result = await context.call<ResultType>( ... );
  ```
</Tip>

## Usage

<CodeGroup>
  ```javascript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<{ topic: string }>(async (context) => {
    const { userId, name } = context.requestPayload;

    const { status,  headers,  body } = await context.call("sync-user-data", {
        url: "https://my-third-party-app", // Endpoint URL
        method: "POST",
        body: {
          userId,
          name
        },
        headers: {
          authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
      }
    );
  });

  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @dataclass
  class Request:
      topic: str


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[Request]) -> None:
      request: Request = context.request_payload

      result = await context.call(
          "generate-long-essay",
          url="https://api.openai.com/v1/chat/completions",
          method="POST",
          body={
              "model": "gpt-4o",
              "messages": [
                  {
                      "role": "system",
                      "content": "You are a helpful assistant writing really long essays that would cause a normal serverless function to timeout.",
                  },
                  {"role": "user", "content": request["topic"]},
              ],
          },
          headers={
              "authorization": f"Bearer {os.environ['OPENAI_API_KEY']}",
          },
      )

      status, headers, body = result.status, result.headers, result.body

  ```
</CodeGroup>

<Tip>
  We provide integrations for **OpenAI, Anthropic, and Resend**, allowing you to call their APIs with strongly typed request bodies using `context.call`.
  See [`context.api`](/workflow/basics/context#context-api) for details.
</Tip>

<Info>
  The `context.call()` function can make requests to any public API endpoint. However, it cannot:

  * Make requests to localhost (unless you set up a local tunnel, [here's how](http://localhost:3000/workflow/howto/local-development))
  * Make requests to internal Upstash QStash endpoints.
</Info>


# context.cancel
Source: https://upstash.com/docs/workflow/basics/context/cancel



All of the methods covered so far are used to define workflow steps.

`context.cancel` is different ‚Äî it allows you to **explicitly cancel the current workflow run**.

```ts  theme={"system"}
export const { POST } = serve<{ topic: string }>(async (context) => {
  const payload = context.requestPayload

  const result = await context.run("check if canceled", () => { ... });

  if (result.cancel) {
    await context.cancel() // cancel the workflow run
  }
})
```

When a workflow run is canceled:

* It is labeled as **canceled** (not failed).
* The configured `failureFunction` **is not triggered**.
* No entries are sent to the **dead-letter queue (DLQ)**.


# context.invoke
Source: https://upstash.com/docs/workflow/basics/context/invoke



`context.invoke()` triggers another workflow run and pauses until the invoked workflow finishes.

The calling workflow resumes once the invoked workflow either **succeeds**, **fails**, or is **canceled**.

<Note>
  Workflows can only invoke other workflows that were served together in the same `serveMany` route.
  For details, see [Invoke other workflows](/workflow/features/invoke).
</Note>

## Arguments

<ParamField body="workflow" type="function" required>
  The workflow definition to invoke.
  Must be a workflow exposed under the same `serveMany`.
</ParamField>

<ParamField body="body" type="any">
  The payload to send to the invoked workflow.
  This value will be set as `context.requestPayload` in the invoked workflow.
</ParamField>

<ParamField body="headers" type="object" optional>
  Optional HTTP headers to forward to the invoked workflow.
  This value will be set as `context.headers` in the invoked workflow.
</ParamField>

<ParamField body="workflowRunId" type="string" optional>
  Override the workflow run ID for the invoked workflow.
  Defaults to a new ID if not specified.
</ParamField>

<ParamField body="retries" type="number" optional>
  Number of retry attempts configuration of the invoked workflow.
  Defaults to `3`. Retries use exponential backoff.
</ParamField>

<ParamField body="retryDelay" type="number|string" optional>
  Delay between retries of the invoked workflow.
</ParamField>

<ParamField body="flowControl" type="object" optional>
  Flow control configuration of the invoked workflow.

  See [Flow Control](/workflow/features/flow-control) for details.

  <Expandable title="properties">
    <ParamField body="key" type="string">
      A logical grouping key that identifies which requests share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of concurrent requests allowed.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit. Default is `1s`.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="stringifyBody" type="string" optional>
  Whether to automatically stringify the body as JSON. Defaults to `true`

  If set to `false`, the body will be required to be a string and will be sent as-is.
</ParamField>

## Response

<ResponseField name="body" type="any">
  The response body returned by the invoked workflow.
</ResponseField>

<ResponseField name="isFailed" type="boolean">
  `true` if the invoked workflow completed with failure.
</ResponseField>

<ResponseField name="isCanceled" type="boolean">
  `true` if the invoked workflow was canceled before completion.
</ResponseField>

## Usage

```ts  theme={"system"}
const { body, isFailed, isCanceled } = await context.invoke(
  "invoke another workflow",
  {
    workflow: anotherWorkflow,
    body: "test",
    header: {...}, // headers to pass to anotherWorkflow (optional)
    retries,       // number of retries (optional, default: 3)
    retryDelay,    // delay between retries (optional, uses exponential backoff by default)
    flowControl,   // flow control settings (optional)
    workflowRunId  // workflowRunId to set (optional)
  }
);
```


# context.notify
Source: https://upstash.com/docs/workflow/basics/context/notify



`context.notify()` notifies workflows that are waiting for a specific event, passing along an optional payload.

It is typically used in combination with [`context.waitForEvent`](/workflow/basics/context#context-waitforevent).

## Arguments

<ParamField body="stepName" type="string">
  A unique identifier for the step.
</ParamField>

<ParamField body="eventId" type="string">
  The identifier of the event to notify.
  Must match the `eventId` used in `context.waitForEvent`.
</ParamField>

<ParamField body="eventData" type="any">
  Data to deliver to the waiting workflow(s).
  This value will be returned in `eventData` from the corresponding `waitForEvent` call.
</ParamField>

## Response

`context.notify()` returns a list of waiters describing the workflows that were notified.

<ResponseField name="notifyResponse" type="NotifyResponse[]">
  A list of `NotifyResponse` objects describing each workflow that was waiting on the event.

  <Expandable defaultOpen>
    <ResponseField name="messageId" type="string">
      The ID of the notification message delivered to the workflow.
      This is unique to every notification.
    </ResponseField>

    <ResponseField name="workflowRunId" type="string">
      The unique identifier of the workflow run that was notified.
    </ResponseField>

    <ResponseField name="workflowCreatedAt" type="number">
      Unix timestamp (in milliseconds) representing when the workflow was created.
    </ResponseField>

    <Snippet file="qstash/waiter.mdx" />
  </Expandable>
</ResponseField>

## Usage

```javascript  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve<{ topic: string }>(async (context) => {
  const payload = context.requestPayload;

  const {
    notifyResponse, // result of notify, which is a list of notified waiters
  } = await context.notify("notify step", "my-event-Id", payload);
});

```


# context.run
Source: https://upstash.com/docs/workflow/basics/context/run



`context.run()` executes a piece of custom business logic as a workflow step.

It returns a `Promise`, so you can decide how steps execute:

* **Sequentially** by awaiting them one by one.
* **In parallel** by awaiting multiple steps together.

## Arguments

<ParamField body="stepName" type="string">
  A unique identifier for the step.
</ParamField>

<ParamField body="stepFunction" type="function">
  The business logic to run inside this step.
</ParamField>

## Response

Each step can return a JSON-serializable value‚Äîanything from simple primitives to complex objects.

The value is **JSON-serialized** and automatically restored across requests.

<Warning>
  Avoid returning stateful resources such as database connections or file handles.

  Instead, return plain data (numbers, strings, arrays, objects) so the result can be safely persisted and restored across workflow executions.
</Warning>

## Usage

<CodeGroup>
  ```typescript Serial execution (TypeScript) highlight={6-8, 10-12} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(async (context) => {
    const input = context.requestPayload;

    const result1 = await context.run("step-1", async () => {
      return someWork(input);
    });

    await context.run("step-2", async () => {
      someOtherWork(result1);
    });
  });

  ```

  ```typescript Parallel execution (TypeScript) theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"

  export const { POST } = serve<string>(
    async (context) => {
      const input = context.requestPayload;

      const promise1 = context.run("step-1", async () => {
        return someWork(input);
      });

      const promise2 = context.run("step-2", async () => {
        return someOtherWork(input);
      });

      await Promise.all([promise1, promise2]);
    },
  );
  ```

  ```python Serial execution (Python) theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      input = context.request_payload

      async def _step1():
          return some_work(input)

      result1 = await context.run("step-1", _step1)

      async def _step2():
          return some_other_work(result1)

      await context.run("step-2", _step2)

  ```
</CodeGroup>

<Info>
  Because results are JSON-serialized, **class instances are restored as plain objects**.
  This means instance methods will not be available unless you explicitly rehydrate the object.

  To fix this, you can recreate the instance using Object.assign() or a custom factory:

  ```typescript  theme={"system"}
  export const { POST } = serve(
  async (context) => {

     let user = await context.run("step-1", async () => {
       // üëá Return a class instance from step
       return new User("John Doe", "john.doe@example.com");
     });

     // üëá Properties are accessible by default
     console.log(user.name)

     // üëá Create a Proper Instance with Object.assign()
     user = Object.assign(new User(), user);

     await context.run("greet", async () => {
       // üëá Now instance methods are available as well
       console.log(user.greet());
     });
   }
  );
  ```
</Info>


# context.sleep
Source: https://upstash.com/docs/workflow/basics/context/sleep



`context.sleep()` pauses workflow execution for a specified duration.

When a workflow is paused, the current request completes and a new one is automatically scheduled to resume after the delay.
This ensures no compute resources are consumed during the sleep period.

<Note>Always `await` a `sleep` step to properly pause execution.</Note>

## Arguments

<ParamField body="stepName" type="string">
  A unique identifier for the step.
</ParamField>

<ParamField body="duration" type="number|string">
  The duration to pause workflow execution.

  * **Human-readable string format:**

  | Input   | Duration   |
  | ------- | ---------- |
  | `"10s"` | 10 seconds |
  | `"1m"`  | 1 minute   |
  | `"30m"` | 30 minutes |
  | `"2h"`  | 2 hours    |
  | `"1d"`  | 1 day      |
  | `"1w"`  | 1 week     |
  | `"1mo"` | 1 month    |
  | `"1y"`  | 1 year     |

  * **Numeric format (seconds):**

  | Input   | Duration              |
  | ------- | --------------------- |
  | `60`    | 60 seconds (1 minute) |
  | `3600`  | 3600 seconds (1 hour) |
  | `86400` | 86400 seconds (1 day) |
</ParamField>

## Usage

<CodeGroup>
  ```typescript TypeScript highlight={12-13} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";
  import { signIn, sendEmail } from "@/utils/onboarding-utils";

  export const { POST } = serve<User>(async (context) => {
    const userData = context.requestPayload;

    const user = await context.run("sign-in", async () => {
      const signedInUser = await signIn(userData);
      return signedInUser;
    });

    // üëá Wait for one day (in seconds)
    await context.sleep("wait-until-welcome-email", "1d");

    await context.run("send-welcome-email", async () => {
      return sendEmail(user.name, user.email);
    });
  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext
  from onboarding_utils import sign_in, send_email

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/onboarding")
  async def onboarding(context: AsyncWorkflowContext[User]) -> None:
      user_data = context.request_payload

      async def _sign_in():
          return await sign_in(user_data)

      user = await context.run("sign-in", _sign_in)

      # üëá Wait for one day (in seconds)
      await context.sleep("wait-until-welcome-email", "1d")

      async def _send_email():
          return await send_email(user.name, user.email)

      await context.run("send-welcome-email", _send_email)

  ```
</CodeGroup>


# context.sleepUntil
Source: https://upstash.com/docs/workflow/basics/context/sleepUntil



`context.sleepUntil()` pauses workflow execution until a specific timestamp.

When a workflow is paused, the current request completes and a new one is automatically scheduled to resume at the target time.
This ensures no compute resources are consumed while sleeping.

<Note>Always await a `sleepUntil` step to properly pause execution.</Note>

## Arguments

<ParamField body="stepName" type="string">
  A unique identifier for the step.
</ParamField>

<ParamField body="datetime" type="Date|number|string">
  The target time when the workflow should resume.
  Accepted formats:

  * A **number**: Unix timestamp in seconds
  * A **Date object**
  * A **string** that can be parsed by `new Date(string)` in JavaScript
</ParamField>

## Usage

<CodeGroup>
  ```typescript TypeScript highlight={11-16} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";
  import { signIn, sendEmail } from "@/utils/onboarding-utils";

  export const { POST } = serve<User>(async (context) => {
    const userData = context.requestPayload;

    const user = await context.run("sign-in", async () => {
      return signIn(userData);
    });

    // üëá Calculate the date for one week from now
    const oneWeekFromNow = new Date();
    oneWeekFromNow.setDate(oneWeekFromNow.getDate() + 7);

    // üëá Sleep until the calculated date
    await context.sleepUntil("wait-for-one-week", oneWeekFromNow);

    await context.run("send-welcome-email", async () => {
      return sendEmail(user.name, user.email);
    });
  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from datetime import datetime, timedelta
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext
  from onboarding_utils import sign_in, send_email

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/onboarding")
  async def onboarding(context: AsyncWorkflowContext[User]) -> None:
      user_data = context.request_payload

      async def _sign_in():
          return await sign_in(user_data)

      user = await context.run("sign-in", _sign_in)

      # üëá Calculate the date for one week from now
      one_week_from_now = datetime.now() + timedelta(days=7)

      # üëá Wait until the calculated date
      await context.sleep_until("wait-for-one-week", one_week_from_now)

      async def _send_email():
          return await send_email(user.name, user.email)

      await context.run("send-welcome-email", _send_email)

  ```
</CodeGroup>


# context.waitForEvent
Source: https://upstash.com/docs/workflow/basics/context/waitForEvent



`context.waitForEvent` pauses workflow execution until a given event occurs or a timeout is reached.

Default timeout value is 7 days.

## Arguments

<ParamField body="stepId" type="string" required>
  A unique identifier for the step.
</ParamField>

<ParamField body="eventId" type="string" required>
  A unique identifier for the event to wait on.
</ParamField>

<ParamField body="timeout" type="number|string">
  The maximum time to wait before continuing execution.

  * **String format**: Human‚Äëreadable duration (e.g., `"10s"`, `"2h"`, `"1d"`).
  * **Number format**: Duration in seconds (e.g., `60`, `3600`).

  Defaults to `7d` (7 days).
</ParamField>

## Response

<ResponseField name="eventData" type="string|object">
  The data passed in when the event is triggered via `notify()`.
</ResponseField>

<ResponseField name="timeout" type="boolean">
  `true` if execution resumed because the timeout elapsed,
  `false` if resumed due to the event being received.
</ResponseField>

## Usage

```javascript highlight={6-11} theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve<{ topic: string }>(async (context) => {
  const request = context.requestPayload;

  const {
    eventData,
    timeout,
  } = await context.waitForEvent("wait for some event", "my-event-id", {
    timeout: "1000s", // 1000 second timeout
  });
});

```


# How Workflow Works
Source: https://upstash.com/docs/workflow/basics/how



Upstash Workflow is an orchestration layer that allows you to write **multi‚Äëstep workflows** which are:

* **Durable** ‚Äì steps automatically recover from errors or outages
* **Scalable** ‚Äì steps run independently and in parallel when possible
* **Cost‚Äëefficient** ‚Äì idle waiting (delays, sleeps, external calls) does not consume compute resources

Upstash Workflow is built on top of Upstash QStash, our serverless messaging and scheduling solution, to achieve these features.

## The Core Idea

Traditionally, backend functions are built in one of two ways: either everything is executed inside a single API function‚Äîwhich is difficult to maintain and prone to failures‚Äîor the flow is split across multiple APIs connected by a queueing system, which adds significant infrastructure and state‚Äëmanagement overhead.

These approaches can work, but they often fail to handle production load reliably or become increasingly difficult to maintain over time:

* **Timeouts** ‚Äì the whole function runs inside one execution window. A slow API can easily exceed serverless limits (often 10‚Äì60 seconds).
* **Temporary issues** ‚Äì slow or unreliable external services can exceed serverless limits or cause the entire request to fail.
* **Failures** ‚Äì if a step fails, the whole request fails. You either restart everything or you must write custom retry logic.
* **Rate limits** ‚Äì calling external APIs in bulk requires careful concurrency control, which is difficult to implement manually.
* **Complexity** ‚Äì to address these issues, teams often build custom queues, schedulers, or state trackers, adding unnecessary infrastructure overhead.

***

## How Upstash Workflow Solves This

Upstash Workflow takes a different approach:
instead of treating your entire function as one continuous execution, **it splits your logic into multiple steps in a workflow endpoint**, each managed and retried by the orchestration engine.

* Each step is executed in its own **HTTP call** to your application.
* After a step finishes, its result is **stored in durable state** inside Upstash Workflow.
* On the next execution, Workflow **skips completed steps** and **resumes exactly where it left off by restoring the previous step results**.
* If a step fails, it is retried automatically based on your retry configuration.

This means you no longer need custom queues, retry logic, or manual state management. You just define your workflow once, and the orchestration layer ensures that **every step runs once, in order, with full reliability.**

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=39a2c8c56f92813198d5990df8d8c9c2" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash-workflow/workflow-concept.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a90ec1a056cb6ac52a0db3527f19aea4 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2f8c7c37826de4ffcaa0d1ea5c6b5e0e 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a0e38b1b9edb79778a42707eb06e44a2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4ba0d847f0d305e4443cccf89f3b8d3a 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cadcf8674584a37fcf56b5de67715a7a 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3a0bbfd71074f1e7a247dd23aa98764b 2500w" />
</Frame>

***

## Extended Features

Upstash Workflow extends the basic step model with additional primitives:

* **Parallel Steps**
  Define multiple steps (e.g. inside a `Promise.all()`). The engine detects independent work and runs steps concurrently as separate HTTP executions.

* **Delays / Sleep**
  `context.sleep` and `context.sleepUntil` allow pausing a workflow for hours, days, or even months. No compute is held during the wait time; execution resumes when the delay has expired.

* **External Event Handling**
  `context.waitForEvent` pauses execution until you notify the workflow externally (e.g. via webhook or user action). State is persisted until the event arrives.

* **External Calls**
  Use `context.call` to have Upstash perform slow or unreliable HTTP calls. Instead of blocking your function, the call is handled by Upstash. When it completes, the workflow resumes with the response.

***

This architecture makes your serverless functions durable, reliable, and performance‚Äëoptimized, even in the face of runtime errors or temporary service outages.

It's quick and easy to get started: follow the [Quickstarts](/workflow/quickstarts/platforms) to define your first workflow in minutes.


# Overview
Source: https://upstash.com/docs/workflow/basics/serve



Use the `serve()` function to define an endpoint that runs a workflow.
It accepts two arguments:

1. **Route Function**: an async function that receives the workflow context and defines the workflow steps.
2. **Options**: configuration options for the workflow.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(async (context) => {
    // Route function
  }, {
    // Options
  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      async def _step1() -> str:
          # define a piece of business logic as step 1
          return "step 1 result"

      result = await context.run("step-1", _step1)

      async def _step2() -> None:
          # define another piece of business logic as step 2
          pass

      await context.run("step-2", _step2)
  ```
</CodeGroup>

## Route Function

The route function defines the execution logic of the workflow.
It is an async function that receives a context object, which is automatically created and passed by Upstash Workflow.

The context object provides:

* **Workflow APIs** ‚Äì functions for defining workflow steps.
* **Workflow Run Properties** ‚Äì request payload, request headers, and other metadata.

For a full list of available APIs and properties, see the [Workflow Context](/workflow/basics/context) documentation.

<CodeGroup>
  ```typescript TypeScript highlight={4-9} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(
    async (context) => {
      // üëá Access context properties
      const { userId } = context.requestPayload;
      // üëá Define a workflow step
      await context.run("step-1", async () => {})
    }
  );
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      async def _step1() -> str:
          # define a piece of business logic as step 1
          return "step 1 result"

      result = await context.run("step-1", _step1)

      async def _step2() -> None:
          # define another piece of business logic as step 2
          pass

      await context.run("step-2", _step2)

  ```
</CodeGroup>

## Options

Options provide additional configuration for workflow runs.
Most of them are advanced settings and are not required for typical use cases. See [Advanced Options](/workflow/basics/serve/advanced) for more details.

<CodeGroup>
  ```typescript TypeScript highlight={5-8} theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(
      async (context) => { ... },
      // üëá Workflow options
      {
          failureFunction: async ({ ... }) => {}
      }
  );
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      async def _step1() -> str:
          # define a piece of business logic as step 1
          return "step 1 result"

      result = await context.run("step-1", _step1)

      async def _step2() -> None:
          # define another piece of business logic as step 2
          pass

      await context.run("step-2", _step2)

  ```
</CodeGroup>


# Advanced Options
Source: https://upstash.com/docs/workflow/basics/serve/advanced



Advanced Options are intended to support edge cases or testing pipelines and are **not required for regular use**.

<ParamField path="failureFunction" type="string">
  Defines a function that executes if the workflow fails after all retries are exhausted.

  For details, see [failureFunction](/workflow/features/failure-callback).

  <Note>
    When adding a `failureFunction`, you must set `useFailureFunction: true` in `client.trigger()` when starting a workflow run.
  </Note>

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        failureFunction: async ({
          context,      // context during failure
          failStatus,   // failure status
          failResponse, // failure message
          failHeaders   // failure headers
          failStack.    // failure stack trace (if available)
        }) => {
          // handle the failure
        }
      }
    );
    ```

    ```python Python theme={"system"}
    async def failure_function(
      context,       # context during failure
      fail_status,   # failure status
      fail_response, # failure message
      fail_headers   # failure headers
    ):
      # handle the failure
      pass

    @serve.post("/api/example", failure_function=failure_function)
    async def example(context: AsyncWorkflowContext[str]) -> None: ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="failureUrl" type="string">
  The `failureUrl` option defines an external endpoint that will be called if the workflow fails after all retries are exhausted.

  This option is an advanced alternative to `failureFunction`.
  For more details, see [Advanced failureUrl Option](/workflow/features/failureFunction/advanced).

  <Note>
    When adding a `failureUrl`, you must set `failureUrl` in `client.trigger()` when starting a workflow run.
  </Note>

  <CodeGroup>
    ```typescript Typescript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        failureUrl: "https://<YOUR-FAILURE-ENDPOINT>/..."
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post("/api/example", failureUrl="https://<YOUR-FAILURE-ENDPOINT>/...")
    async def example(context: AsyncWorkflowContext[str]) -> None: ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="retries" type="number">
  Defines the number of retry attempts if a workflow step fails.
  The default value is 3.

  For details, see [retry configuration](/workflow/features/retries/configuration).

  <Warning>
    We recommend configuring workflow runs when starting them with `client.trigger()`, rather than applying configuration on the server side.

    See [Configure a Run](/workflow/howto/configure) for details.
  </Warning>

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        retries: 3
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post("/api/example", retries=3)
    async def example(context: AsyncWorkflowContext[str]) -> None: ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="retryDelay" type="string">
  Defines the delay between retry attempts.
  This option accepts an expression that evaluates to the number of milliseconds.

  You can use the `retried` variable‚Äîwhich starts at 0 for the first retry‚Äîto compute a dynamic delay.
  For a constant delay, provide a fixed millisecond value.

  For details, see [retry configuration](/workflow/features/retries/configuration).

  <Warning>
    We recommend configuring workflow runs when starting them with `client.trigger()`, rather than applying configuration on the server side.

    See [Configure a Run](/workflow/howto/configure) for details.
  </Warning>

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        retryDelay: "(retried + 1) * 1000" // delay in milliseconds
      }
    );
    ```
  </CodeGroup>
</ParamField>

<ParamField body="flowControl" type="object" optional>
  Applies throttling to workflow execution using rate limits or concurrency limits.

  See [flow control](/workflow/features/flow-control) for details.

  <Warning>
    We recommend configuring workflow runs when starting them with `client.trigger()`, rather than applying configuration on the server side.

    See [Configure a Run](/workflow/howto/configure) for details.
  </Warning>

  <Expandable title="properties" defaultOpen>
    <ParamField body="key" type="string">
      A logical grouping key that identifies which executions share the same flow control limits.
    </ParamField>

    <ParamField body="rate" type="number">
      The maximum number of allowed requests per second.
    </ParamField>

    <ParamField body="parallelism" type="number">
      The maximum number of concurrent requests allowed.
    </ParamField>

    <ParamField body="period" type="string|number">
      The time window used to enforce the defined rate limit.
    </ParamField>
  </Expandable>

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        flowControl: { key: "custom-flow-control-key",  rate: 10, parallelism: 3 }
      }
    );
    ```
  </CodeGroup>
</ParamField>

<ParamField path="initialPayloadParser" type="bool">
  Enables custom parsing of the initial request payload.

  Use this option if the incoming payload is not plain JSON or a simple string.
  The parser function lets you transform the raw request into a strongly typed
  object before workflow execution begins.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    type InitialPayload = {
      foo: string;
      bar: number;
    };

    // üëá 1: provide initial payload type
    export const { POST } = serve<InitialPayload>(
      async (context) => {
        // üëá 3: parsing result is available as requestPayload
        const payload: InitialPayload = context.requestPayload;
      },
      {
        // üëá 2: custom parsing for initial payload
        initialPayloadParser: (initialPayload) => {
          const payload: InitialPayload = parsePayload(initialPayload);
          return payload;
        },
      }
    );
    ```

    ```python Python theme={"system"}
    @dataclass
    class InitialPayload:
        foo: str
        bar: int


    def initial_payload_parser(initial_payload: str) -> InitialPayload:
        return parse_payload(initial_payload)


    @serve.post("/api/example", initial_payload_parser=initial_payload_parser)
    async def example(context: AsyncWorkflowContext[InitialPayload]) -> None:
        payload: InitialPayload = context.request_payload

    ```
  </CodeGroup>
</ParamField>

<ParamField path="schema" type="z.ZodType">
  Alternative to `initialPayloadParser`, you can pass a `schema` in the TypeScript SDK.

  The schema is used to validate and parse the initial request payload automatically using [Zod](https://zod.dev/).

  <CodeGroup>
    ```typescript TypeScript theme={"system"}

    import { z } from "zod";

    const parameters = z.object({ expression: z.string() });

    export const { POST } = serve(
      async (context) => {
        // context.requestPayload is typed as `{ expression: string }`
        const payload = context.requestPayload;
      },
      {
        schema: parameters,
      }
    );
    ```
  </CodeGroup>
</ParamField>

<ParamField path="url" type="string">
  Specifies the full endpoint URL of the workflow, including the route path.

  By default, Upstash Workflow infers the URL from `request.url` when scheduling the next step.
  However, in some environments, `request.url` may resolve to an internal or unreachable address.

  Use this option when running behind a proxy, reverse proxy, or local tunnel during development where `request.url` cannot be used directly.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        url: "https://<YOUR-DEPLOYED-APP>.com/api/workflow"
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post("/api/example", url="https://<YOUR-DEPLOYED-APP>.com/api/workflow")
    async def example(context: AsyncWorkflowContext[str]) -> None: ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="baseUrl" type="string">
  Similar to `url`, but `baseUrl` only overrides the base portion of the inferred URL rather than replacing the entire path.
  This is useful when you want to preserve the route structure while changing only the host or scheme.

  <Tip>
    If you have multiple workflow endpoints, you can set the `UPSTASH_WORKFLOW_URL` environment variable instead of configuring `baseUrl` on each endpoint.
    The `UPSTASH_WORKFLOW_URL` environment variable corresponds directly to this option and configures it globally.
  </Tip>

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => {
        ...
      },
      // options:
      {
        baseUrl: "<LOCAL-TUNNEL-PUBLIC-URL>"
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post("/api/example", base_url="<LOCAL-TUNNEL-PUBLIC-URL>")
    async def example(context: AsyncWorkflowContext[str]) -> None: ...

    ```
  </CodeGroup>
</ParamField>

<ParamField path="qstashClient" type="object">
  Use `qstashClient` if you want to provide your own QStash client instead of letting Workflow use the default from environment variables.

  This is useful if you're working with multiple QStash projects in the same app.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    import { Client } from "@upstash/qstash";
    import { serve } from "@upstash/workflow/nextjs";

    export const { POST } = serve(
      async (context) => { ... },
      {
        qstashClient: new Client({ token: "<QSTASH_TOKEN>" })
      }
    );
    ```

    ```python Python theme={"system"}
    from qstash import AsyncQStash


    @serve.post("/api/example", qstash_client=AsyncQStash(os.environ["QSTASH_TOKEN"]))
    async def example(context: AsyncWorkflowContext[str]) -> None: ...

    ```
  </CodeGroup>
</ParamField>

<ParamField path="receiver" type="object">
  The `Receiver` verifies that every request to your endpoint actually comes from QStash, blocking anyone else from triggering your workflow.

  The `receiver` option allows you to pass a QStash Receiver explicitly.

  By default, Workflow initializes the Receiver automatically using the environment variables `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY`.

  This is useful if you're working with multiple QStash projects in the same app.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    import { Receiver } from "@upstash/qstash";
    import { serve } from "@upstash/workflow/nextjs";

    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        receiver: new Receiver({
          currentSigningKey: "<QSTASH_CURRENT_SIGNING_KEY>",
          nextSigningKey: "<QSTASH_NEXT_SIGNING_KEY>",
        })
      }
    );
    ```

    ```python Python theme={"system"}
    from qstash import Receiver

    @serve.post(
        "/api/example",
        receiver=Receiver(
            current_signing_key=os.environ["QSTASH_CURRENT_SIGNING_KEY"],
            next_signing_key=os.environ["QSTASH_NEXT_SIGNING_KEY"],
        ),
    )
    async def example(context: AsyncWorkflowContext[str]) -> None:
        ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="env" type="object">
  By default, Workflow uses `process.env` to read credentials and initialize QStash.
  If you're in an environment where `process.env` isn't available, or you want to inject values manually, you can pass them with `env`.

  Inside your workflow, these values are also exposed on `context.env`.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    import { Receiver } from "@upstash/qstash";
    import { serve } from "@upstash/workflow/nextjs";

    export const { POST } = serve<string>(
      async (context) => {
        // the env option will be available in the env field of the context:
        const env = context.env;
      },
      {
        env: {
            QSTASH_URL: "<QSTASH_URL>",
            QSTASH_TOKEN: "<QSTASH_TOKEN>",
            QSTASH_CURRENT_SIGNING_KEY: "<QSTASH_CURRENT_SIGNING_KEY>",
            QSTASH_NEXT_SIGNING_KEY: "<QSTASH_NEXT_SIGNING_KEY>",
        }
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post(
        "/api/example",
        env={
            "QSTASH_CURRENT_SIGNING_KEY": os.environ["QSTASH_CURRENT_SIGNING_KEY"],
            "QSTASH_NEXT_SIGNING_KEY": os.environ["QSTASH_NEXT_SIGNING_KEY"],
        },
    )
    async def example(context: AsyncWorkflowContext[str]) -> None:
        ...
    ```
  </CodeGroup>
</ParamField>

<ParamField path="verbose" type="boolean">
  Enables verbose mode to print detailed logs of workflow execution to the application's `stdout`.

  Verbose mode is disabled by default.

  ```typescript  theme={"system"}
  export const { POST } = serve<string>(
    async (context) => { ... },
    {
      verbose: true
    }
  );
  ```

  Each log entry has the following structure:

  ```
  {
    timestamp: number,
    workflowRunId: string,
    logLevel: string,
    eventType: string,
    details: unknown,
  }
  ```

  | eventType                      | Description                                                     |
  | ------------------------------ | --------------------------------------------------------------- |
  | `ENDPOINT_START`               | each time the workflow endpoint is called                       |
  | `RUN_SINGLE` or `RUN_PARALLEL` | when step(s) are executed                                       |
  | `SUBMIT_STEP`                  | when a single step is executed                                  |
  | `SUBMIT_FIRST_INVOCATION`      | when a new workflow run starts                                  |
  | `SUBMIT_CLEANUP`               | when a workflow run finishes                                    |
  | `SUBMIT_THIRD_PARTY_RESULT`    | when a third-party call result is received (see `context.call`) |
</ParamField>

<ParamField path="disableTelemetry" type="boolean">
  Disables anonymous telemetry data collection for this workflow endpoint. Since we don't collect telemetry
  in Python SDK, this option is only available in the TypeScript SDK.

  By default, the Upstash Workflow SDK collects anonymous telemetry data to help improve the service.
  The collected data includes:

  * SDK version
  * Platform (Vercel, AWS, etc.)
  * Runtime version (Node.js, Python, etc.)

  Set `disableTelemetry` to `true` to opt out of telemetry for this specific workflow endpoint.

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    export const { POST } = serve<string>(
      async (context) => { ... },
      {
        disableTelemetry: true
      }
    );
    ```

    ```python Python theme={"system"}
    @serve.post("/api/example", disable_telemetry=True)
    async def example(context: AsyncWorkflowContext[str]) -> None: ...
    ```
  </CodeGroup>

  <Tip>
    You should also
    set [`disableTelemetry` when triggering workflow runs via `client.trigger()`](/workflow/basics/client/trigger#param-disable-telemetry) to fully disable telemetry
  </Tip>
</ParamField>


# Changelog
Source: https://upstash.com/docs/workflow/changelog



<Note>
  We have moved the roadmap and the changelog to [Github Discussions](https://github.com/orgs/upstash/discussions) starting from October 2025.Now you can follow `In Progress` features. You can see that your `Feature Requests` are recorded. You can vote for them and comment your specific use-cases to shape the feature to your needs.
</Note>

<Update label="September 2025">
  * **TypeScript SDK (`workflow-js`):**
    * `Label` feature is added. This will enable our users to label their workflow runs so that
      * Logs can be filtered with user given label.
      * DLQ can be filtered with user given label.
    * `notBefore` parameter is added to `trigger` function that will allow starting a workflow run at a later date
      given by the `notBefore` parameter.
  * **Console:**
    * A major Workflow redesign is landed to improve debugging and monitoring experience workflow runs logs.
      * `Flat view` is removed. All the data is moved to single view. This is also to avoid confusing our
        users and made over all experience simpler.
</Update>

<Update label="August 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Added `retryDelay` option to dynamicaly program the retry duration. It can be configured on
      [trigger](/workflow/basics/client#trigger-workflow) , [context.call](/workflow/basics/context#context-call)
      or [serve](/workflow/basics/serve#retrydelay)
    * Added ability to detect if a given url is a workflow or not. Starting with `0.2.17` trigger made via the sdk can fail (instead of hanging),
      if there is no workflow serve on the given url.
  * **Console:**
    * Local mode is added to enable our users to use the console with their local development envrionment and the locally deployed workflows.
      See [docs](/workflow/howto/local-development#development-server-recommended) for details.
</Update>

<Update label="July 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Restart/Resume for DLQ is added to allow more options to handle failed runs. See [here](/workflow/howto/failures#manually-handling-failed-workflow-runs)
    * Added `WorkflowNonRetryableError` to fail a workflow without causing any retries. See [here](/workflow/basics/context#error-handling-and-retries)
    * For additional bug fixes, see the full changelog [here](https://github.com/upstash/workflow-js/compare/v0.2.14...v0.2.16).
</Update>

<Update label="June 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Added `useFailureFunction` and `failureFunction` to `client.trigger`. See [here](https://github.com/upstash/workflow-js/pull/107).
    * Added batch triggering support to `client.trigger`. See [here](https://github.com/upstash/workflow-js/pull/110).
    * For additional bug fixes, see the release notes [here](https://github.com/upstash/workflow-js/releases/tag/v0.2.14).
  * **Python SDK (`workflow-py`):** ¬†
    * Failure function is implemented. This feature enables to act on a failure of a workflow on the code. See docs [here](/workflow/howto/failures#using-a-failurefunction-recommended)
    * For other bug fixes, see the full changelog [here](https://github.com/upstash/workflow-py/compare/v0.1.0...v0.1.1).
  * **Console:**
    * A major redesign is coming next month to improve Workflow usability.
  * **Workflow Server:** ¬†
    * An issue causing Workflows not usable with `CloudFront` is fixed.
</Update>

<Update label="May 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Added a `workflow` parameter to `context.call`, enabling type-safe workflow calls. See [here](https://github.com/upstash/workflow-js/pull/75).
    * Enabled passing `context.call` settings when defining an Agent. See [here](https://github.com/upstash/workflow-js/pull/90).
    * Added `delay` support to `client.trigger`. See [here](https://github.com/upstash/workflow-js/pull/100).
    * Introduced `period` and improved `rate` support in flow control. See [here](https://github.com/upstash/workflow-js/pull/101).\
      Previously, `period` was fixed at 1 second. For example, `rate: 3 period: 1d` throttles publishes to 3 per day.
    * For additional bug fixes, see the release notes [here](https://github.com/upstash/workflow-js/releases/tag/v0.2.13).
  * **Workflow Server:**
    * Added support for custom `period` in flow control, allowing users to set a period of up to 1 week.\
      Previously, `period` was fixed at 1 second. For example, `rate: 3 period: 1d` throttles publishes to 3 per day.
    * Implemented **Workflow Resume** and **Restart** features (SDK and Console support in progress):
      * **Resume** allows users to retry a workflow run from the point it stopped.
      * **Restart** allows users to retry a workflow run from the beginning.
  * **Console:**
    * A major redesign is coming to improve Workflow usability.
</Update>

<Update label="April 2025">
  * **Python SDK (`workflow-py`):** ¬†
    * Minor bug fixes.\
      See the full changelog [here](https://github.com/upstash/workflow-py/compare/v0.1.0...v0.1.1).
  * **Workflow Server:**
    * Prevented intermediate Workflow calls from failing due to request/message quota limits.
    * Fixed handling of `RUN_STARTED` so that it correctly returns unfinished Workflow Runs as documented.\
      Previously, some Workflow Runs could be skipped if internal state was logged after `RUN_STARTED`.
    * Applied several performance optimizations.
</Update>

<Update label="March 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Added `onError` support to `serve` by the community. See [here](https://github.com/upstash/workflow-js/pull/79).
    * Enabled support for all fetch-compatible models in Agents. See [more details here](https://github.com/upstash/workflow-js/pull/77).
    * For additional bug fixes, see the full changelog [here](https://github.com/upstash/workflow-js/compare/v0.2.11...v0.2.12).
</Update>

<Update label="February 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Fixed a Unicode issue in `context.call` where binary responses from endpoints could break. See [here](https://github.com/upstash/workflow-js/pull/71).
    * Introduced `WorkflowTool`, allowing Workflow Agents to define multi-step workflows as a tool. See [here](/workflow/agents/features#tools).
    * Added `context.invoke` to call one workflow from another with full type-safety. See the guide [here](/workflow/howto/invoke).
    * Introduced flow control parameters to limit the rate or concurrency of workflow runs. Learn more [here](/workflow/features/flow-control).
    * For additional bug fixes, see the full changelog [here](https://github.com/upstash/workflow-js/compare/v0.2.3...v0.2.6).
  * **Workflow Server:**
    * Added RateLimit and Parallelism controls to manage the frequency and concurrency of workflow runs. Learn more [here](/workflow/features/flow-control).
</Update>

<Update label="January 2025">
  * **TypeScript SDK (`workflow-js`):**
    * Added the Agents API to workflows. You can now create AI agents to run workflows on your own infrastructure with all the benefits of workflows: reduced environment costs, fault tolerance, and scalability. Learn more about agents [here](/workflow/agents/overview).
    * For other bug fixes, see the full changelog [here](https://github.com/upstash/workflow-js/compare/v0.2.3...v0.2.6).
  * **Python SDK (workflow-py):**
    * Released [`workflow-py`](https://github.com/upstash/workflow-py).
  * **Local Development Server:**
    * The local development server is now available for public use. This server allows you to test your workflows locally. Learn more about the local development server [here](/workflow/howto/local-development#development-server-recommended).
  * **Console:**
    * Separated Workflow and QStash consoles for a better user experience.
    * Separated their DLQ messages as well.
  * **Workflow Server:**
    * The core team focused on RateLimit and Parallelism features. These features are ready on the server and will be announced next month after the documentation and SDKs are completed.
</Update>

<Update label="December 2024">
  * **TypeScript SDK (`workflow-js`):**
    * Introduced third-party integrations, starting with Anthropic, Resend, and OpenAI. These integrations are automatically offloaded to workflows, ensuring long-running calls do not consume user environment time. See the related documentation [here](/workflow/basics/context#context-api).
    * Added a `timeout` parameter to `context.call`. Learn more in the [documentation](/workflow/basics/context#context-call).
    * Improved support for workflows in Express and SvelteKit by adding the `useJSONContent` option.
    * Resolved loop detection issues on Cloudflare and Render.
    * Full changelog, including all fixes, is available [here](https://github.com/upstash/workflow-js/compare/v0.2.0...v0.2.3).

  * **Workflow Server:**
    * Added the `WorkflowCreatedAt` filter for Dead Letter Queue (DLQ) and Events.
    * Prepared the local development server for public release (coming soon).
    * Enhanced `context.SleepUntil` to support float values.
    * Increased the event retention period from 10,000 events to up to 14 days. Learn more on the [Pricing page](https://upstash.com/pricing/workflow).
</Update>

<Update label="November 2024">
  * **Python SDK (workflow-py):**
    * Began development of the Python SDK.
  * **TypeScript SDK (workflow-js):**
    * Added support for string durations (e.g., `1d`, `30s`) in `context.sleep` and `context.waitForEvent`.
    * Introduced integrations for [Astro](/workflow/quickstarts/astro) and [Express](/workflow/quickstarts/express).
    * Added `client.trigger`, enabling workflows to start and return the workflow run ID. See the [documentation](/workflow/basics/client#trigger-workflow).
    * Added a retry option for `context.call`. See the [documentation](/workflow/basics/context#context-call).
    * Introduced a lazy fetch feature to support longer and larger workflows on resource-limited platforms.
    * Added `context.cancel` to cancel the current workflow. See the [documentation](/workflow/basics/context#context-cancel).
    * Full changelog, including fixes, is available [here](https://github.com/upstash/workflow-js/compare/v0.1.2...v0.2.0).
  * **Workflow Server:**
    * Added bulk cancel functionality for workflow runs. See the [REST API](/workflow/rest/runs/bulk-cancel).
    * Introduced content-based deduplication for workflows and retry-until-success functionality. This will allow workflows to be used in areas with unstable network connection.
</Update>

<Update label="October 2024">
  * Optimized the console by trimming event bodies, reducing resource usage and enabling efficient querying of events with large payloads.
  * Began development on a new architecture to deliver faster event processing on the server.
  * Added [Wait Notify](/workflow/howto/events) feature.
</Update>

<Update label="September 2024">
  * Bug fixes and internal logging improvements.
</Update>

<Update label="August 2024">
  * Released [Upstash Workflow](/workflow/getstarted).
</Update>


# AI Generation
Source: https://upstash.com/docs/workflow/examples/allInOne



## Introduction

This example demonstrates advanced AI data processing using Upstash Workflow. The following example workflow downloads a large dataset, processes it in chunks using OpenAI's GPT-4 model, aggregates the results and generates a report.

## Use Case

Our workflow will:

1. Receive a request to process a dataset
2. Download the dataset from a remote source
3. Process the data in chunks using OpenAI
4. Aggregate results
5. Generate and send a final report

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"
  import {
    downloadData,
    aggregateResults,
    generateReport,
    sendReport,
    getDatasetUrl,
    splitIntoChunks,
  } from "./utils"

  type OpenAiResponse = {
    choices: {
      message: {
        role: string,
        content: string
      }
    }[]
  }

  export const { POST } = serve<{ datasetId: string; userId: string }>(
    async (context) => {
      const request = context.requestPayload

      // Step 1: Download the dataset
      const datasetUrl = await context.run("get-dataset-url", async () => {
        return await getDatasetUrl(request.datasetId)
      })

      // HTTP request with much longer timeout (2hrs)
      const { body: dataset } = await context.call("download-dataset", {
        url: datasetUrl,
        method: "GET"
      })
        

      // Step 2: Process data in chunks using OpenAI
      const chunkSize = 1000
      const chunks = splitIntoChunks(dataset, chunkSize)
      const processedChunks: string[] = []

      for (let i = 0; i < chunks.length; i++) {
        const { body: processedChunk } = await context.api.openai.call(
          `process-chunk-${i}`,
          {
            token: process.env.OPENAI_API_KEY,
            operation: "chat.completions.create",
            body: {
              model: "gpt-4",
              messages: [
                {
                  role: "system",
                  content:
                    "You are an AI assistant tasked with analyzing data chunks. Provide a brief summary and key insights for the given data.",
                },
                {
                  role: "user",
                  content: `Analyze this data chunk: ${JSON.stringify(chunks[i])}`,
                },
              ],
              max_completion_tokens: 150,
            },
          }
        )

        processedChunks.push(processedChunk.choices[0].message.content!)

        // Every 10 chunks, we'll aggregate intermediate results
        if (i % 10 === 9 || i === chunks.length - 1) {
          await context.run(`aggregate-results${i}`, async () => {
            await aggregateResults(processedChunks)
            processedChunks.length = 0
          })
        }
      }

      // Step 3: Generate and send data report
      const report = await context.run("generate-report", async () => {
        return await generateReport(request.datasetId)
      })

      await context.run("send-report", async () => {
        await sendReport(report, request.userId)
      })
    }
  )
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  import json
  import os
  from typing import Dict, List, Any, TypedDict
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext, CallResponse
  from utils import (
      aggregate_results,
      generate_report,
      send_report,
      get_dataset_url,
      split_into_chunks,
  )


  app = FastAPI()
  serve = Serve(app)


  class RequestPayload(TypedDict):
      dataset_id: str
      user_id: str


  @serve.post("/ai-generation")
  async def ai_generation(context: AsyncWorkflowContext[RequestPayload]) -> None:
      request = context.request_payload
      dataset_id = request["dataset_id"]
      user_id = request["user_id"]

      # Step 1: Download the dataset
      async def _get_dataset_url() -> str:
          return await get_dataset_url(dataset_id)

      dataset_url = await context.run("get-dataset-url", _get_dataset_url)

      # HTTP request with much longer timeout (2hrs)
      response: CallResponse[Any] = await context.call(
          "download-dataset", url=dataset_url, method="GET"
      )
      dataset = response.body

      # Step 2: Process data in chunks using OpenAI
      chunk_size = 1000
      chunks = split_into_chunks(dataset, chunk_size)
      processed_chunks: List[str] = []

      for i, chunk in enumerate(chunks):
          openai_response: CallResponse[Dict[str, str]] = await context.call(
              f"process-chunk-{i}",
              url="https://api.openai.com/v1/chat/completions",
              method="POST",
              headers={
                  "authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
              },
              body={
                  "model": "gpt-4",
                  "messages": [
                  {
                      "role": "system",
                      "content":
                      "You are an AI assistant tasked with analyzing data chunks. Provide a brief summary and key insights for the given data.",
                  },
                  {
                      "role": "user",
                      "content": f"Analyze this data chunk: {json.dumps(chunk)}",
                  },
                  ],
                  "max_tokens": 150,
              },
          )

          processed_chunks.append(
              openai_response.body["choices"][0]["message"]["content"]
          )

          # Every 10 chunks, we'll aggregate intermediate results
          if i % 10 == 9 or i == len(chunks) - 1:

              async def _aggregate_results() -> None:
                  await aggregate_results(processed_chunks)
                  processed_chunks.clear()

              await context.run(f"aggregate-results{i}", _aggregate_results)

      # Step 3: Generate and send data report
      async def _generate_report() -> Any:
          return await generate_report(dataset_id)

      report = await context.run("generate-report", _generate_report)

      async def _send_report() -> None:
          await send_report(report, user_id)

      await context.run("send-report", _send_report)

  ```
</CodeGroup>

## Code Breakdown

### 1. Preparing our data

We start by retrieving the dataset URL and then downloading the dataset:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  const datasetUrl = await context.run("get-dataset-url", async () => {
    return await getDatasetUrl(request.datasetId)
  })

  const { body: dataset } = await context.call("download-dataset", {
    url: datasetUrl,
    method: "GET"
  })
  ```

  ```python main.py theme={"system"}
  async def _get_dataset_url() -> str:
      return await get_dataset_url(dataset_id)

  dataset_url = await context.run("get-dataset-url", _get_dataset_url)

  response: CallResponse[Any] = await context.call(
      "download-dataset", url=dataset_url, method="GET"
  )
  dataset = response.body

  ```
</CodeGroup>

Note that we use `context.call` for the download, a way to make HTTP requests that run for much longer than your serverless execution limit would normally allow.

### 2. Processing our data

We split the dataset into chunks and process each one using OpenAI's GPT-4 model:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  for (let i = 0; i < chunks.length; i++) {
    const { body: processedChunk } = await context.api.openai.call<OpenAiResponse>(
      `process-chunk-${i}`,
      {
        token: process.env.OPENAI_API_KEY!,
        operation: "chat.completions.create",
        body: {
          model: "gpt-4",
          messages: [
            {
              role: "system",
              content:
                "You are an AI assistant tasked with analyzing data chunks. Provide a brief summary and key insights for the given data.",
            },
            {
              role: "user",
              content: `Analyze this data chunk: ${JSON.stringify(chunks[i])}`,
            },
          ],
          max_completion_tokens: 150,
        },
      }
    )
  }
  ```

  ```python main.py theme={"system"}
  for i, chunk in enumerate(chunks):
      openai_response: CallResponse[Dict[str, str]] = await context.call(
          f"process-chunk-{i}",
          url="https://api.openai.com/v1/chat/completions",
          method="POST",
          headers={
              "authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
          },
          body={
              "model": "gpt-4",
              "messages": [
              {
                  "role": "system",
                  "content":
                  "You are an AI assistant tasked with analyzing data chunks. Provide a brief summary and key insights for the given data.",
              },
              {
                  "role": "user",
                  "content": f"Analyze this data chunk: {json.dumps(chunk)}",
              },
              ],
              "max_tokens": 150,
          },
      )

  ```
</CodeGroup>

### 3. Aggregating our data

After processing our data in smaller chunks to avoid any function timeouts, we aggregate results every 10 chunks:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  if (i % 10 === 9 || i === chunks.length - 1) {
    await context.run(`aggregate-results${i}`, async () => {
      await aggregateResults(processedChunks)
      processedChunks.length = 0
    })
  }

  ```

  ```python main.py theme={"system"}
  if i % 10 == 9 or i == len(chunks) - 1:

      async def _aggregate_results() -> None:
          await aggregate_results(processed_chunks)
          processed_chunks.clear()

      await context.run(f"aggregate-results{i}", _aggregate_results)

  ```
</CodeGroup>

### 4. Sending a report

Finally, we generate a report based on the aggregated results and send it to the user:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  const report = await context.run("generate-report", async () => {
    return await generateReport(request.datasetId)
  })

  await context.run("send-report", async () => {
    await sendReport(report, request.userId)
  })

  ```

  ```python main.py theme={"system"}
  async def _generate_report() -> Any:
      return await generate_report(dataset_id)

  report = await context.run("generate-report", _generate_report)

  async def _send_report() -> None:
      await send_report(report, user_id)

  await context.run("send-report", _send_report)

  ```
</CodeGroup>

## Key Features

1. **Non-blocking HTTP Calls**: We use `context.call` for API requests so they don't consume the endpoint's execution time (great for optimizing serverless cost).

2. **Long-running tasks**: The dataset download can take up to 2 hours, though is realistically limited by function memory.


# Auth Provider Webhook
Source: https://upstash.com/docs/workflow/examples/authWebhook



This example demonstrates an authentication provider webhook process using Upstash Workflow.
The workflow handles the user creation, trial management, email reminders and notifications.

## Use Case

Our workflow will:

1. Receive a webhook event from an authentication provider (e.g. Firebase, Auth0, Clerk etc.)
2. Create a new user in our database
3. Create a new user in Stripe
4. Start a trial in Stripe
5. Send a welcome email
6. Send a reminder email if the user hasn't solved any questions in the last 7 days
7. Send a trial warning email if the user hasn't upgraded 2 days before the trial ends
8. Send a trial ended email if the user hasn't upgraded

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";
  import { WorkflowContext } from '@upstash/qstash/workflow'

  /**
   * This can be the payload of the user created webhook event coming from your
   * auth provider (e.g. Firebase, Auth0, Clerk etc.)
   */
  type UserCreatedPayload = {
    name: string;
    email: string;
  };

  export const { POST } = serve<UserCreatedPayload>(async (context) => {
    const { name, email } = context.requestPayload;

    const { userid } = await context.run("sync user", async () => {
      return await createUserInDatabase({ name, email });
    });

    await context.run("create new user in stripe", async () => {
      await createNewUserInStripe(email);
    });

    await context.run("start trial in Stripe", async () => {
      await startTrialInStripe(email);
    });

    await context.run("send welcome email", async () => {
      await sendEmail(
        email,
        "Welcome to our platform!, You have 14 days of free trial."
      );
    });

    await context.sleep("wait", 7 * 24 * 60 * 60);

    // get user stats and send email with them
    const stats = await context.run("get user stats", async () => {
      return await getUserStats(userid);
    });
    await sendProblemSolvedEmail({context, email, stats});

    // wait until there are two days to the end of trial period
    // and check upgrade status
    await context.sleep("wait for trial warning", 5 * 24 * 60 * 60);
    const isUpgraded = await context.run("check upgraded plan", async () => {
      return await checkUpgradedPlan(email);
    });

    // end the workflow if upgraded
    if (isUpgraded) return;

    await context.run("send trial warning email", async () => {
      await sendEmail(
        email,
        "Your trial is about to end in 2 days. Please upgrade your plan to keep using our platform."
      );
    });

    await context.sleep("wait for trial end", 2 * 24 * 60 * 60);

    await context.run("send trial end email", async () => {
      await sendEmail(
        email,
        "Your trial has ended. Please upgrade your plan to keep using our platform."
      );
    });
  });

  async function sendProblemSolvedEmail({
    context: WorkflowContext<UserCreatedPayload>
    email: string,
    stats: { totalProblemsSolved: number }
  }) {
    if (stats.totalProblemsSolved === 0) {
      await context.run("send no answers email", async () => {
        await sendEmail(
          email,
          "Hey, you haven't solved any questions in the last 7 days..."
        );
      });
    } else {
      await context.run("send stats email", async () => {
        await sendEmail(
          email,
          `You have solved ${stats.totalProblemsSolved} problems in the last 7 days. Keep it up!`
        );
      });
    }
  }

  async function createUserInDatabase({
    name,
    email,
  }: {
    name: string;
    email: string;
  }) {
    console.log("Creating a user in the database:", name, email);
    return { userid: "12345" };
  }

  async function createNewUserInStripe(email: string) {
    // Implement logic to create a new user in Stripe
    console.log("Creating a user in Stripe for", email);
  }

  async function startTrialInStripe(email: string) {
    // Implement logic to start a trial in Stripe
    console.log("Starting a trial of 14 days in Stripe for", email);
  }

  async function getUserStats(userid: string) {
    // Implement logic to get user stats
    console.log("Getting user stats for", userid);
    return {
      totalProblemsSolved: 10_000,
      mostInterestedTopic: "JavaScript",
    };
  }

  async function checkUpgradedPlan(email: string) {
    // Implement logic to check if the user has upgraded the plan
    console.log("Checking if the user has upgraded the plan", email);
    return false;
  }

  async function sendEmail(email: string, content: string) {
    // Implement logic to send an email
    console.log("Sending email to", email, content);
  }
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import Dict, TypedDict
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  class UserCreatedPayload(TypedDict):
      name: str
      email: str


  class UserStats(TypedDict):
      total_problems_solved: int
      most_interested_topic: str


  async def create_user_in_database(name: str, email: str) -> Dict[str, str]:
      print("Creating a user in the database:", name, email)
      return {"userid": "12345"}


  async def create_new_user_in_stripe(email: str) -> None:
      # Implement logic to create a new user in Stripe
      print("Creating a user in Stripe for", email)


  async def start_trial_in_stripe(email: str) -> None:
      # Implement logic to start a trial in Stripe
      print("Starting a trial of 14 days in Stripe for", email)


  async def get_user_stats(userid: str) -> UserStats:
      # Implement logic to get user stats
      print("Getting user stats for", userid)
      return {"total_problems_solved": 10000, "most_interested_topic": "Python"}


  async def check_upgraded_plan(email: str) -> bool:
      # Implement logic to check if the user has upgraded the plan
      print("Checking if the user has upgraded the plan", email)
      return False


  async def send_email(email: str, content: str) -> None:
      # Implement logic to send an email
      print("Sending email to", email, content)


  async def send_problem_solved_email(
      context: AsyncWorkflowContext[UserCreatedPayload], email: str, stats: UserStats
  ) -> None:
      if stats["total_problems_solved"] == 0:

          async def _send_no_answers_email() -> None:
              await send_email(
                  email, "Hey, you haven't solved any questions in the last 7 days..."
              )

          await context.run("send no answers email", _send_no_answers_email)
      else:

          async def _send_stats_email() -> None:
              await send_email(
                  email,
                  f"You have solved {stats['total_problems_solved']} problems in the last 7 days. Keep it up!",
              )

          await context.run("send stats email", _send_stats_email)


  @serve.post("/auth-provider-webhook")
  async def auth_provider_webhook(
      context: AsyncWorkflowContext[UserCreatedPayload],
  ) -> None:
      payload = context.request_payload
      name = payload["name"]
      email = payload["email"]

      async def _sync_user() -> str:
          return await create_user_in_database(name, email)

      result = await context.run("sync user", _sync_user)
      userid = result["userid"]

      async def _create_new_user_in_stripe() -> None:
          await create_new_user_in_stripe(email)

      await context.run("create new user in stripe", _create_new_user_in_stripe)

      async def _start_trial_in_stripe() -> None:
          await start_trial_in_stripe(email)

      await context.run("start trial in Stripe", _start_trial_in_stripe)

      async def _send_welcome_email() -> None:
          await send_email(
              email, "Welcome to our platform!, You have 14 days of free trial."
          )

      await context.run("send welcome email", _send_welcome_email)

      await context.sleep("wait", 7 * 24 * 60 * 60)

      # get user stats and send email with them

      async def _get_user_stats() -> UserStats:
          return await get_user_stats(userid)

      stats: UserStats = await context.run("get user stats", _get_user_stats)

      await send_problem_solved_email(context, email, stats)

      # wait until there are two days to the end of trial period and check upgrade status
      await context.sleep("wait for trial warning", 5 * 24 * 60 * 60)

      async def _check_upgraded_plan() -> bool:
          return await check_upgraded_plan(email)

      is_upgraded = await context.run("check upgraded plan", _check_upgraded_plan)

      # end the workflow if upgraded
      if is_upgraded:
          return

      async def _send_trial_warning_email() -> None:
          await send_email(
              email,
              "Your trial is about to end in 2 days. Please upgrade your plan to keep using our platform.",
          )

      await context.run("send trial warning email", _send_trial_warning_email)

      await context.sleep("wait for trial end", 2 * 24 * 60 * 60)

      async def _send_trial_end_email() -> None:
          await send_email(
              email,
              "Your trial has ended. Please upgrade your plan to keep using our platform.",
          )

      await context.run("send trial end email", _send_trial_end_email)

  ```
</CodeGroup>

## Code Breakdown

### 1. Sync User

We start by creating a new user in our database:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const { userid } = await context.run("sync user", async () => {
    return await createUserInDatabase({ name, email });
  });
  ```

  ```python Python theme={"system"}
  async def _sync_user() -> str:
      return await create_user_in_database(name, email)

  result = await context.run("sync user", _sync_user)
  userid = result["userid"]

  ```
</CodeGroup>

### 2. Create New User in Stripe

Next, we create a new user in Stripe:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.run("create new user in stripe", async () => {
    await createNewUserInStripe(email);
  });
  ```

  ```python Python theme={"system"}
  async def _create_new_user_in_stripe() -> None:
      await create_new_user_in_stripe(email)

  await context.run("create new user in stripe", _create_new_user_in_stripe)

  ```
</CodeGroup>

### 3. Start Trial in Stripe

We start a trial in Stripe:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.run("start trial in Stripe", async () => {
    await startTrialInStripe(email);
  });
  ```

  ```python Python theme={"system"}
  async def _start_trial_in_stripe() -> None:
      await start_trial_in_stripe(email)

  await context.run("start trial in Stripe", _start_trial_in_stripe)

  ```
</CodeGroup>

### 4. Send Welcome Email

We send a welcome email to the user:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.run("send welcome email", async () => {
    await sendEmail(
      email,
      "Welcome to our platform!, You have 14 days of free trial."
    );
  });
  ```

  ```python Python theme={"system"}
  async def _send_welcome_email() -> None:
      await send_email(
          email, "Welcome to our platform!, You have 14 days of free trial."
      )

  await context.run("send welcome email", _send_welcome_email)

  ```
</CodeGroup>

### 5. Send Reminder Email

After 7 days, we check if the user has solved any questions. If not, we send a reminder email:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.sleep("wait", 7 * 24 * 60 * 60);

  const stats = await context.run("get user stats", async () => {
    return await getUserStats(userid);
  });
  await sendProblemSolvedEmail({context, email, stats});
  ```

  ```python Python theme={"system"}
  await context.sleep("wait", 7 * 24 * 60 * 60)

  async def _get_user_stats() -> UserStats:
      return await get_user_stats(userid)

  stats: UserStats = await context.run("get user stats", _get_user_stats)

  await send_problem_solved_email(context, email, stats)

  ```
</CodeGroup>

The `sendProblemSolvedEmail` method:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  async function sendProblemSolvedEmail({
    context: WorkflowContext<UserCreatedPayload>
    email: string,
    stats: { totalProblemsSolved: number }
  }) {
    if (stats.totalProblemsSolved === 0) {
      await context.run("send no answers email", async () => {
        await sendEmail(
          email,
          "Hey, you haven't solved any questions in the last 7 days..."
        );
      });
    } else {
      await context.run("send stats email", async () => {
        await sendEmail(
          email,
          `You have solved ${stats.totalProblemsSolved} problems in the last 7 days. Keep it up!`
        );
      });
    }
  }
  ```

  ```python Python theme={"system"}
  async def send_problem_solved_email(
      context: AsyncWorkflowContext[UserCreatedPayload], email: str, stats: UserStats
  ) -> None:
      if stats["total_problems_solved"] == 0:

          async def _send_no_answers_email() -> None:
              await send_email(
                  email, "Hey, you haven't solved any questions in the last 7 days..."
              )

          await context.run("send no answers email", _send_no_answers_email)
      else:

          async def _send_stats_email() -> None:
              await send_email(
                  email,
                  f"You have solved {stats['total_problems_solved']} problems in the last 7 days. Keep it up!",
              )

          await context.run("send stats email", _send_stats_email)

  ```
</CodeGroup>

### 6. Send Trial Warning Email

If the user hasn't upgraded 2 days before the trial ends, we send a trial warning email:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.sleep("wait for trial warning", 5 * 24 * 60 * 60);

  const isUpgraded = await context.run("check upgraded plan", async () => {
    return await checkUpgradedPlan(email);
  });

  if (isUpgraded) return;

  await context.run("send trial warning email", async () => {
    await sendEmail(
      email,
      "Your trial is about to end in 2 days. Please upgrade your plan to keep using our platform."
    );
  });
  ```

  ```python Python theme={"system"}
  await context.sleep("wait for trial warning", 5 * 24 * 60 * 60)

  async def _check_upgraded_plan() -> bool:
      return await check_upgraded_plan(email)

  is_upgraded = await context.run("check upgraded plan", _check_upgraded_plan)

  # end the workflow if upgraded
  if is_upgraded:
      return

  async def _send_trial_warning_email() -> None:
      await send_email(
          email,
          "Your trial is about to end in 2 days. Please upgrade your plan to keep using our platform.",
      )

  await context.run("send trial warning email", _send_trial_warning_email)

  ```
</CodeGroup>

If they upgraded, we end the workflow by returning.

### 7. Send Trial Ended Email

If the user hasn't upgraded after the trial ends, we send a trial ended email:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.sleep("wait for trial end", 2 * 24 * 60 * 60);

  await context.run("send trial end email", async () => {
    await sendEmail(
      email,
      "Your trial has ended. Please upgrade your plan to keep using our platform."
    );
  });
  ```

  ```python Python theme={"system"}
  await context.sleep("wait for trial end", 2 * 24 * 60 * 60)

  async def _send_trial_end_email() -> None:
      await send_email(
          email,
          "Your trial has ended. Please upgrade your plan to keep using our platform.",
      )

  await context.run("send trial end email", _send_trial_end_email)

  ```
</CodeGroup>


# Custom Retry Logic
Source: https://upstash.com/docs/workflow/examples/customRetry



## Key Features

This example demonstrates how to implement custom retry logic when using third-party services in your Upstash Workflow.

We'll use OpenAI as an example for such a third-party service. **Our retry logic uses response status codes and headers to control when to retry, sleep, or store the third-party API response**.

## Code Example

The following code:

1. Attempts to make an API call up to 10 times.
2. Dynamically adjusts request delays based on response headers or status.
3. Stores successful responses asynchronously.

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"
  import { storeResponse } from "@/lib/utils"

  const BASE_DELAY = 10;

  const createSystemMessage = () => ({
    role: "system",
    content: "You are an AI assistant providing a brief summary and key insights for any given data.",
  })

  const createUserMessage = (data: string) => ({
    role: "user",
    content: `Analyze this data chunk: ${data}`,
  })

  export const { POST } = serve<{ userData: string }>(async (context) => {
    // üëá initial data sent along when triggering the workflow
    const { userData } = context.requestPayload

    for (let attempt = 0; attempt < 10; attempt++) {
      const response = await context.api.openai.call(`call-openai`, {
        token: process.env.OPENAI_API_KEY!,
        operation: "chat.completions.create",
        body: {
          model: "gpt-3.5-turbo",
          messages: [createSystemMessage(), createUserMessage(userData)],
          max_completion_tokens: 150,
        },
      })

      // Success case
      if (response.status < 300) {
        await context.run("store-response-in-db", () => storeResponse(response.body))
        return
      }

      // Rate limit case - wait and retry
      if (response.status === 429) {
        const resetTime =
          response.header["x-ratelimit-reset-tokens"]?.[0] ||
          response.header["x-ratelimit-reset-requests"]?.[0] ||
          BASE_DELAY

        // assuming `resetTime` is in seconds
        await context.sleep("sleep-until-retry", Number(resetTime))

        continue
      }

      // Any other scenario - pause for 5 seconds to avoid overloading OpenAI API
      await context.sleep("pause-to-avoid-spam", 5)
    }
  })
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import Dict, Any, TypedDict
  import os
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext, CallResponse
  from utils import store_response

  app = FastAPI()
  serve = Serve(app)


  class InitialData(TypedDict):
      user_data: str


  def create_system_message() -> Dict[str, str]:
      return {
          "role": "system",
          "content": "You are an AI assistant providing a brief summary and key insights for any given data.",
      }


  def create_user_message(data: str) -> Dict[str, str]:
      return {"role": "user", "content": f"Analyze this data chunk: {data}"}


  @serve.post("/custom-retry-logic")
  async def custom_retry_logic(context: AsyncWorkflowContext[InitialData]) -> None:
      # üëá initial data sent along when triggering the workflow
      user_data = context.request_payload["user_data"]

      for attempt in range(10):
          response: CallResponse[Dict[str, Any]] = await context.call(
              "call-openai",
              url="https://api.openai.com/v1/chat/completions",
              method="POST",
              headers={
                  "authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
              },
              body={
                  "model": "gpt-4",
                  "messages": [create_system_message(), create_user_message(user_data)],
                  "max_tokens": 150,
              },
          )

          # Success case
          if response.status_code < 300:

              async def _store_response_in_db() -> None:
                  await store_response(response.body)

              await context.run("store-response-in-db", _store_response_in_db)
              return

          # Rate limit case - wait and retry
          if response.status_code == 429:
              ratelimit_tokens_header = response.header.get("x-ratelimit-reset-tokens")
              ratelimit_requests_header = response.header.get(
                  "x-ratelimit-reset-requests"
              )
              reset_time = (
                  (ratelimit_tokens_header[0] if ratelimit_tokens_header else None)
                  or (ratelimit_requests_header[0] if ratelimit_requests_header else None)
                  or 10
              )

              # assuming `reset_time` is in seconds
              await context.sleep("sleep-until-retry", float(reset_time))
              continue

          # Any other scenario - pause for 5 seconds to avoid overloading OpenAI API
          await context.sleep("pause-to-avoid-spam", 5)

  ```
</CodeGroup>

## Code Breakdown

### 1. Setting up our Workflow

This POST endpoint serves our workflow. We create a loop to attempt the API call (we're about to write) up to 10 times.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  export const { POST } = serve<{ userData: string }>(async (context) => {
    for (let attempt = 0; attempt < 10; attempt++) {
      // TODO: call API in here
    }
  })
  ```

  ```python Python theme={"system"}
  @serve.post("/custom-retry-logic")
  async def custom_retry_logic(context: AsyncWorkflowContext[InitialData]) -> None:
      for attempt in range(10):
          # TODO: call API in here

  ```
</CodeGroup>

### 2. Making a Third-Party API Call

We use `context.api.openai.call` to send a request to OpenAI.

<Note>
  `context.api.openai.call` uses `context.call` in the background and
  using `context.call` to request data from an API is one of the most powerful Upstash Workflow
  features. Your request can take much longer than any function timeout would normally allow,
  completely bypassing any platform-specific timeout limits.
</Note>

Our request to OpenAI includes an auth header, model parameters, and the data to be processed by the AI. The response from this function call (`response`) is used to determine our retry logic based on its status code and headers.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const response = await context.api.openai.call(`call-openai`, {
    token: process.env.OPENAI_API_KEY,
    operation: "chat.completions.create",
    body: {
      model: "gpt-3.5-turbo",
      messages: [createSystemMessage(), createUserMessage(userData)],
      max_completion_tokens: 150,
    },
  })
  ```

  ```python Python theme={"system"}
  response: CallResponse[Dict[str, Any]] = await context.call(
      "call-openai",
      url="https://api.openai.com/v1/chat/completions",
      method="POST",
      headers={
          "authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
      },
      body={
          "model": "gpt-4",
          "messages": [create_system_message(), create_user_message(user_data)],
          "max_tokens": 150,
      },
  )

  ```
</CodeGroup>

### 3. Processing a Successful Response (Status Code \< 300)

If the OpenAI response is successful (status code under 300), we store the response in our database. We create a new workflow task (`workflow.run`) to do this for maximum reliability.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  if (response.status < 300) {
    await context.run("store-response-in-db", () => storeResponse(response.body))
    return
  }
  ```

  ```python Python theme={"system"}
  if response.status_code < 300:

      async def _store_response_in_db() -> None:
          await store_response(response.body)

      await context.run("store-response-in-db", _store_response_in_db)
      return
      
  ```
</CodeGroup>

### 4. Handling Rate Limits (Status Code 429)

If the API response indicates a rate limit error (status code 429), we retrieve our rate limit reset values from the response headers. We calculate the time until the rate limit resets and then pause execution (`workflow.sleep`) for this duration.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  if (response.status === 429) {
    const resetTime =
      response.header["x-ratelimit-reset-tokens"]?.[0] ||
      response.header["x-ratelimit-reset-requests"]?.[0] ||
      BASE_DELAY

    // assuming `resetTime` is in seconds
    await context.sleep("sleep-until-retry", Number(resetTime))

    continue
  }
  ```

  ```python Python theme={"system"}
  if response.status_code == 429:
      ratelimit_tokens_header = response.header.get("x-ratelimit-reset-tokens")
      ratelimit_requests_header = response.header.get(
          "x-ratelimit-reset-requests"
      )
      reset_time = (
          (ratelimit_tokens_header[0] if ratelimit_tokens_header else None)
          or (ratelimit_requests_header[0] if ratelimit_requests_header else None)
          or 10
      )

      # assuming `reset_time` is in seconds
      await context.sleep("sleep-until-retry", float(reset_time))
      continue

  ```
</CodeGroup>

### 5. Waiting Before the Next Retry Attempt

To avoid making too many requests in a short period and possibly overloading the OpenAI API, we pause our workflow before the next retry attempt (i.e., 5 seconds), regardless of rate limits.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.sleep("pause-to-avoid-spam", 5)
  ```

  ```python Python theme={"system"}
  await context.sleep("pause-to-avoid-spam", 5)

  ```
</CodeGroup>


# Customer Onboarding
Source: https://upstash.com/docs/workflow/examples/customerOnboarding



This example demonstrates a customer onboarding process using Upstash Workflow. The following example workflow registers a new user, sends welcome emails, and periodically checks and responds to the user's activity state.

## Use Case

Our workflow will:

1. Register a new user to our service
2. Send them a welcome email
3. Wait for a certain time
4. Periodically check the user's state
5. Send appropriate emails based on the user's activity

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"

  type InitialData = {
    email: string
  }

  export const { POST } = serve<InitialData>(async (context) => {
    const { email } = context.requestPayload

    await context.run("new-signup", async () => {
      await sendEmail("Welcome to the platform", email)
    })

    await context.sleep("wait-for-3-days", 60 * 60 * 24 * 3)

    while (true) {
      const state = await context.run("check-user-state", async () => {
        return await getUserState()
      })

      if (state === "non-active") {
        await context.run("send-email-non-active", async () => {
          await sendEmail("Email to non-active users", email)
        })
      } else if (state === "active") {
        await context.run("send-email-active", async () => {
          await sendEmail("Send newsletter to active users", email)
        })
      }

      await context.sleep("wait-for-1-month", 60 * 60 * 24 * 30)
    }
  })

  async function sendEmail(message: string, email: string) {
    // Implement email sending logic here
    console.log(`Sending ${message} email to ${email}`)
  }

  type UserState = "non-active" | "active"

  const getUserState = async (): Promise<UserState> => {
    // Implement user state logic here
    return "non-active"
  }
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import Literal, TypedDict
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)

  UserState = Literal["non-active", "active"]


  class InitialData(TypedDict):
      email: str


  async def send_email(message: str, email: str) -> None:
      # Implement email sending logic here
      print(f"Sending {message} email to {email}")


  async def get_user_state() -> UserState:
      # Implement user state logic here
      return "non-active"


  @serve.post("/customer-onboarding")
  async def customer_onboarding(context: AsyncWorkflowContext[InitialData]) -> None:
      email = context.request_payload["email"]

      async def _new_signup() -> None:
          await send_email("Welcome to the platform", email)

      await context.run("new-signup", _new_signup)

      await context.sleep("wait-for-3-days", 60 * 60 * 24 * 3)

      while True:

          async def _check_user_state() -> UserState:
              return await get_user_state()

          state: UserState = await context.run("check-user-state", _check_user_state)

          if state == "non-active":

              async def _send_email_non_active() -> None:
                  await send_email("Email to non-active users", email)

              await context.run("send-email-non-active", _send_email_non_active)
          else:

              async def _send_email_active() -> None:
                  await send_email("Send newsletter to active users", email)

              await context.run("send-email-active", _send_email_active)

          await context.sleep("wait-for-1-month", 60 * 60 * 24 * 30)

  ```
</CodeGroup>

## Code Breakdown

### 1. New User Signup

We start by sending a newly signed-up user a welcome email:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  await context.run("new-signup", async () => {
    await sendEmail("Welcome to the platform", email)
  })
  ```

  ```python main.py theme={"system"}
  async def _new_signup() -> None:
      await send_email("Welcome to the platform", email)

  await context.run("new-signup", _new_signup)

  ```
</CodeGroup>

### 2. Initial Waiting Period

To leave time for the user to interact with our platform, we use `context.sleep` to pause our workflow for 3 days:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  await context.sleep("wait-for-3-days", 60 * 60 * 24 * 3)
  ```

  ```python main.py theme={"system"}
  await context.sleep("wait-for-3-days", 60 * 60 * 24 * 3)

  ```
</CodeGroup>

### 3. Periodic State Check

We enter an infinite loop to periodically (every month) check the user's engagement level with our platform and send appropriate emails:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  while (true) {
    const state = await context.run("check-user-state", async () => {
      return await getUserState()
    })

    if (state === "non-active") {
      await context.run("send-email-non-active", async () => {
        await sendEmail("Email to non-active users", email)
      })
    } else if (state === "active") {
      await context.run("send-email-active", async () => {
        await sendEmail("Send newsletter to active users", email)
      })
    }

    await context.sleep("wait-for-1-month", 60 * 60 * 24 * 30)
  }
  ```

  ```python main.py theme={"system"}
  while True:

      async def _check_user_state() -> UserState:
          return await get_user_state()

      state: UserState = await context.run("check-user-state", _check_user_state)

      if state == "non-active":

          async def _send_email_non_active() -> None:
              await send_email("Email to non-active users", email)

          await context.run("send-email-non-active", _send_email_non_active)
      else:

          async def _send_email_active() -> None:
              await send_email("Send newsletter to active users", email)

          await context.run("send-email-active", _send_email_active)

      await context.sleep("wait-for-1-month", 60 * 60 * 24 * 30)
      
  ```
</CodeGroup>

## Key Features

1. **Non-blocking sleep**: We use `context.sleep` for pausing the workflow without consuming execution time (great for optimizing serverless cost).

2. **Long-running task**: This workflow runs indefinitely, checking and responding to a users engagement state every month.


# E-commerce Order Fulfillment
Source: https://upstash.com/docs/workflow/examples/eCommerceOrderFulfillment



## Introduction

This example demonstrates an automated e-commerce order fulfillment process using Upstash Workflow. The workflow takes an order, verifies the stock, processes the payment, and handles order dispatch and customer notifications.

## Use Case

Our workflow will:

1. Receive an order request
2. Verify the availability of the items in stock
3. Process the payment
4. Initiate the dispatch of the order
5. Send confirmation and delivery notifications to the customer

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"
  import {
    createOrderId,
    checkStockAvailability,
    processPayment,
    dispatchOrder,
    sendOrderConfirmation,
    sendDispatchNotification,
  } from "./utils"

  type OrderPayload = {
    userId: string
    items: { productId: string, quantity: number }[]
  }

  export const { POST } = serve<OrderPayload>(async (context) => {
    const { userId, items } = context.requestPayload;

    // Step 1: Create Order Id
    const orderId = await context.run("create-order-id", async () => {
      return await createOrderId(userId);
    });

    // Step 2: Verify stock availability
    const stockAvailable = await context.run("check-stock", async () => {
      return await checkStockAvailability(items);
    });

    if (!stockAvailable) {
      console.warn("Some items are out of stock");
      return;
    };

    // Step 3: Process payment
    await context.run("process-payment", async () => {
      return await processPayment(orderId)
    })

    // Step 4: Dispatch the order
    await context.run("dispatch-order", async () => {
      return await dispatchOrder(orderId, items)
    })

    // Step 5: Send order confirmation email
    await context.run("send-confirmation", async () => {
      return await sendOrderConfirmation(userId, orderId)
    })

    // Step 6: Send dispatch notification
    await context.run("send-dispatch-notification", async () => {
      return await sendDispatchNotification(userId, orderId)
    })
  })
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import List, TypedDict
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext
  from utils import (
      create_order_id,
      check_stock_availability,
      process_payment,
      dispatch_order,
      send_order_confirmation,
      send_dispatch_notification,
  )

  app = FastAPI()
  serve = Serve(app)


  class OrderItem(TypedDict):
      product_id: str
      quantity: int


  class OrderPayload(TypedDict):
      user_id: str
      items: List[OrderItem]


  @serve.post("/order-fulfillment")
  async def order_fulfillment(context: AsyncWorkflowContext[OrderPayload]) -> None:
      # Get the order payload from the request
      payload = context.request_payload
      user_id = payload["user_id"]
      items = payload["items"]

      # Step 1: Create Order Id
      async def _create_order_id():
          return await create_order_id(user_id)

      order_id: str = await context.run("create-order-id", _create_order_id)

      # Step 2: Verify stock availability
      async def _check_stock():
          return await check_stock_availability(items)

      stock_available: bool = await context.run("check-stock", _check_stock)

      if not stock_available:
          print("Some items are out of stock")
          return

      # Step 3: Process payment
      async def _process_payment():
          return await process_payment(order_id)

      await context.run("process-payment", _process_payment)

      # Step 4: Dispatch the order
      async def _dispatch_order():
          return await dispatch_order(order_id, items)

      await context.run("dispatch-order", _dispatch_order)

      # Step 5: Send order confirmation email
      async def _send_confirmation():
          return await send_order_confirmation(user_id, order_id)

      await context.run("send-confirmation", _send_confirmation)

      # Step 6: Send dispatch notification
      async def _send_dispatch_notification():
          return await send_dispatch_notification(user_id, order_id)

      await context.run("send-dispatch-notification", _send_dispatch_notification)

  ```
</CodeGroup>

## Code Breakdown

### 1. Verifying Stock Availability

We start by creating an order id and verifying if the items in the order are available in stock. If not, we throw an error to halt the process:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  const orderId = await context.run("create-order-id", async () => {
    return await createOrderId(userId);
  });

  const stockAvailable = await context.run("check-stock", async () => {
    return await checkStockAvailability(items)
  })

  if (!stockAvailable) {
    console.warn("Some items are out of stock")
    return;
  }
  ```

  ```python main.py theme={"system"}
  async def _create_order_id():
      return await create_order_id(user_id)

  order_id: str = await context.run("create-order-id", _create_order_id)

  async def _check_stock():
      return await check_stock_availability(items)

  stock_available: bool = await context.run("check-stock", _check_stock)

  if not stock_available:
      print("Some items are out of stock")
      return

  ```
</CodeGroup>

### 2. Processing Payment

Once the stock is verified, the workflow processes the payment for the order:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  await context.run("process-payment", async () => {
    return await processPayment(orderId)
  })
  ```

  ```python main.py theme={"system"}
  async def _process_payment():
      return await process_payment(order_id)

  await context.run("process-payment", _process_payment)

  ```
</CodeGroup>

### 3. Dispatching the Order

After payment confirmation, we dispatch the order for delivery:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  await context.run("dispatch-order", async () => {
    return await dispatchOrder(orderId, items)
  })
  ```

  ```python main.py theme={"system"}
  async def _dispatch_order():
      return await dispatch_order(order_id, items)

  await context.run("dispatch-order", _dispatch_order)

  ```
</CodeGroup>

### 4. Sending Confirmation and Notification Emails

Lastly, we send an order confirmation email to the customer and notify them when the order is dispatched:

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  await context.run("send-confirmation", async () => {
    return await sendOrderConfirmation(userId, orderId)
  })

  await context.run("send-dispatch-notification", async () => {
    return await sendDispatchNotification(userId, orderId)
  })
  ```

  ```python main.py theme={"system"}
  async def _send_confirmation():
      return await send_order_confirmation(user_id, order_id)

  await context.run("send-confirmation", _send_confirmation)

  async def _send_dispatch_notification():
      return await send_dispatch_notification(user_id, order_id)

  await context.run("send-dispatch-notification", _send_dispatch_notification)

  ```
</CodeGroup>

## Key Features

1. **Stock Verification**: Ensures items are available in stock before processing the payment, avoiding issues with unavailable products.

2. **Payment Processing**: Handles payment securely and only proceeds to dispatch if successful.

3. **Customer Notifications**: Keeps the customer informed at each step of the order process, improving user experience.


# Image Processing
Source: https://upstash.com/docs/workflow/examples/imageProcessing



<Note>
  Since parallel steps are not yet available in
  [workflow-py](https://github.com/upstash/workflow-py), Python example is implemented in a sequential manner. See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

## Introduction

This example demonstrates how to process images using Upstash Workflow. The following workflow will upload an image, resize it into multiple resolutions, apply filters, and store the processed versions for later retrieval.

## Use Case

Our workflow will:

1. Receive an image upload request
2. Resize the image into different resolutions
3. Apply various filters to the resized images
4. Store the processed images in a cloud storage

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs"
  import {
    resizeImage,
    applyFilters,
    storeImage,
    getImageUrl,
  } from "./utils"

  type ImageResult = {
    imageUrl: string
  }

  export const { POST } = serve<{ imageId: string; userId: string }>(
    async (context) => {
      const { imageId, userId } = context.requestPayload

      // Step 1: Retrieve the uploaded image
      const imageUrl = await context.run("get-image-url", async () => {
        return await getImageUrl(imageId)
      })

      // Step 2: Resize the image to multiple resolutions
      const resolutions = [640, 1280, 1920]

      const resizedImages: { body: ImageResult }[] = await Promise.all(resolutions.map(
        resolution => context.call<ImageResult>(
          `resize-image-${resolution}`,
          {
            // endpoint which returns ImageResult type in response
            url: "https://image-processing-service.com/resize",
            method: "POST",
            body: {
              imageUrl,
              width: resolution,
            }
          }
        )
      ))

      // Step 3: Apply filters to each resized image
      const filters = ["grayscale", "sepia", "contrast"]
      const processedImagePromises: Promise<string>[] = []

      for (const resizedImage of resizedImages) {
        for (const filter of filters) {
          const processedImagePromise = context.call<ImageResult>(
            `apply-filter-${filter}`,
            {
              // endpoint which returns ImageResult type in response
              url: "https://image-processing-service.com/filter",
              method: "POST",
              body: {
                imageUrl: resizedImage.body.imageUrl,
                filter,
              }
            }
          )
          processedImagePromises.push(processedImagePromise)
        }
      }
      const processedImages: { body: ImageResult }[] = await Promise.all(processedImagePromises)

      // Step 4: Store processed images in cloud storage
      const storedImageUrls: string[] = await Promise.all(
        processedImages.map(
          processedImage => context.run(`store-image`, async () => {
            return await storeImage(processedImage.body.imageUrl)
          })
        )
      )
    }
  )
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import List, TypedDict
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext, CallResponse
  from utils import store_image, get_image_url

  app = FastAPI()
  serve = Serve(app)


  class ImageResult(TypedDict):
      image_url: str


  class ImageProcessingPayload(TypedDict):
      image_id: str
      user_id: str


  @serve.post("/process-image")
  async def process_image(context: AsyncWorkflowContext[ImageProcessingPayload]) -> None:
      payload = context.request_payload
      image_id = payload["image_id"]
      user_id = payload["user_id"]

      # Step 1: Retrieve the uploaded image
      async def _get_image_url() -> str:
          return await get_image_url(image_id)

      image_url: str = await context.run("get-image-url", _get_image_url)

      # Step 2: Resize the image to multiple resolutions
      resolutions = [640, 1280, 1920]
      resize_responses = []

      for resolution in resolutions:
          response: CallResponse[ImageResult] = await context.call(
              f"resize-image-{resolution}",
              # endpoint which returns ImageResult type in response
              url="https://image-processing-service.com/resize",
              method="POST",
              body={"imageUrl": image_url, "width": resolution},
          )
          resize_responses.append(response)

      resized_images = [response.body for response in resize_responses]

      # Step 3: Apply filters to each resized image
      filters = ["grayscale", "sepia", "contrast"]
      filter_responses = []

      for resized_image in resized_images:
          for filter in filters:
              response: CallResponse[ImageResult] = await context.call(
                  f"apply-filter-{filter}",
                  # endpoint which returns ImageResult type in response
                  url="https://image-processing-service.com/filter",
                  method="POST",
                  body={"imageUrl": resized_image["imageUrl"], "filter": filter},
              )
              filter_responses.append(response)

      processed_images = [response.body for response in filter_responses]

      # Step 4: Store processed images in cloud storage
      async def _store_image() -> str:
          return await store_image(processed_image["imageUrl"])

      stored_image_urls: List[str] = []
      for processed_image in processed_images:
          stored_image_url = await context.run("store-image", _store_image)
          stored_image_urls.append(stored_image_url)

  ```
</CodeGroup>

## Code Breakdown

### 1. Retrieving the Image

We begin by getting the URL of the uploaded image based on its ID:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const imageUrl = await context.run("get-image-url", async () => {
    return await getImageUrl(imageId)
  })
  ```

  ```python Python theme={"system"}
  async def _get_image_url() -> str:
      return await get_image_url(image_id)

  image_url: str = await context.run("get-image-url", _get_image_url)

  ```
</CodeGroup>

### 2. Resizing the Image

We resize the image into three different resolutions (640, 1280, 1920) using an external image processing service.

We call `context.call` for each resolution and use `Promise.all` to run them parallel:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const resolutions = [640, 1280, 1920]

  const resizedImages: { body: ImageResult }[] = await Promise.all(resolutions.map(
    resolution => context.call<ImageResult>(
      `resize-image-${resolution}`,
      {
        // endpoint which returns ImageResult type in response
        url: "https://image-processing-service.com/resize",
        method: "POST",
        body: {
          imageUrl,
          width: resolution,
        }
      }
    )
  ))
  ```

  ```python Python theme={"system"}
  resolutions = [640, 1280, 1920]
  resize_responses = []

  for resolution in resolutions:
      response: CallResponse[ImageResult] = await context.call(
          f"resize-image-{resolution}",
          # endpoint which returns ImageResult type in response
          url="https://image-processing-service.com/resize",
          method="POST",
          body={"imageUrl": image_url, "width": resolution},
      )
      resize_responses.append(response)

  resized_images = [response.body for response in resize_responses]

  ```
</CodeGroup>

### 3. Applying Filters

After resizing, we apply filters such as grayscale, sepia, and contrast to the resized images.

Again, we call `context.call` for each filter & image pair. We collect the promises of these requests in an array `processedImagePromise`. Then, we call `Promise.all` again to run them all parallel.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const filters = ["grayscale", "sepia", "contrast"]
  const processedImagePromises: Promise<string>[] = []

  for (const resizedImage of resizedImages) {
    for (const filter of filters) {
      const processedImagePromise = context.call<ImageResult>(
        `apply-filter-${filter}`,
        {
          // endpoint which returns ImageResult type in response
          url: "https://image-processing-service.com/filter",
          method: "POST",
          body: {
            imageUrl: resizedImage.body.imageUrl,
            filter,
          }
        }
      )
      processedImagePromises.push(processedImagePromise)
    }
  }
  const processedImages: { body: ImageResult }[] = await Promise.all(processedImagePromises)
  ```

  ```python Python theme={"system"}
  filters = ["grayscale", "sepia", "contrast"]
  filter_responses = []

  for resized_image in resized_images:
      for filter in filters:
          response: CallResponse[ImageResult] = await context.call(
              f"apply-filter-{filter}",
              # endpoint which returns ImageResult type in response
              url="https://image-processing-service.com/filter",
              method="POST",
              body={"imageUrl": resized_image["imageUrl"], "filter": filter},
          )
          filter_responses.append(response)

  processed_images = [response.body for response in filter_responses]

  ```
</CodeGroup>

### 4. Storing the Processed Images

We store each processed image in cloud storage and return the URLs of the stored images:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const storedImageUrls: string[] = await Promise.all(
    processedImages.map(
      processedImage => context.run(`store-image`, async () => {
        return await storeImage(processedImage.body.imageUrl)
      })
    )
  )
  ```

  ```python Python theme={"system"}
  async def _store_image() -> str:
      return await store_image(processed_image["imageUrl"])

  stored_image_urls: List[str] = []
  for processed_image in processed_images:
      stored_image_url = await context.run("store-image", _store_image)
      stored_image_urls.append(stored_image_url)

  ```
</CodeGroup>

## Key Features

1. **Batch Processing**: This workflow handles batch resizing and filtering of images in parallel to minimize processing time.
2. **Scalability**: Image resizing and filtering are handled through external services, making it easy to scale. Also, the requests to these services are handled by QStash, not by the compute where the workflow is hosted.
3. **Storage Integration**: The workflow integrates with cloud storage to persist processed images for future access.


# Payment Retries
Source: https://upstash.com/docs/workflow/examples/paymentRetry



This example demonstrates a payment retry process using Upstash Workflow.
The following example handles retrying a payment, sending emails, and suspending accounts.

## Use Case

Our workflow will:

1. Attempt to process a payment
2. Retry the payment if it fails with a 24-hour delay
3. If the payment succeeds:
   * Unsuspend the user's account if it was suspended
   * Send an invoice email
4. If the payment fails after 3 retries:
   * Suspend the user's account

## Code Example

<CodeGroup>
  ```typescript api/workflow/route.ts theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  type ChargeUserPayload = {
    email: string;
  };

  export const { POST } = serve<ChargeUserPayload>(async (context) => {
    const { email } = context.requestPayload;

    for (let i = 0; i < 3; i++) {
      // attempt to charge the user
      const result = await context.run("charge customer", async () => {
        try {
          return await chargeCustomer(i + 1),
        } catch (e) {
          console.error(e);
          return
        }
      });

      if (!result) {
        // Wait for a day
        await context.sleep("wait for retry", 24 * 60 * 60);
      } else {
        // Unsuspend User
        const isSuspended = await context.run("check suspension", async () => {
          return await checkSuspension(email);
        });
        if (isSuspended) {
          await context.run("unsuspend user", async () => {
            await unsuspendUser(email);
          });
        }

        // send invoice email
        await context.run("send invoice email", async () => {
          await sendEmail(
            email,
            `Payment successful. Invoice: ${result.invoiceId}, Total cost: $${result.totalCost}`
          );
        });

        // by returning, we end the workflow run
        return;
      }
    }

    // suspend user if the user isn't suspended
    const isSuspended = await context.run("check suspension", async () => {
      return await checkSuspension(email);
    });

    if (!isSuspended) {
      await context.run("suspend user", async () => {
        await suspendUser(email);
      });

      await context.run("send suspended email", async () => {
        await sendEmail(
          email,
          "Your account has been suspended due to payment failure. Please update your payment method."
        );
      });
    }
  });

  async function sendEmail(email: string, content: string) {
    // Implement the logic to send an email
    console.log("Sending email to", email, "with content:", content);
  }

  async function checkSuspension(email: string) {
    // Implement the logic to check if the user is suspended
    console.log("Checking suspension status for", email);
    return true;
  }

  async function suspendUser(email: string) {
    // Implement the logic to suspend the user
    console.log("Suspending the user", email);
  }

  async function unsuspendUser(email: string) {
    // Implement the logic to unsuspend the user
    console.log("Unsuspending the user", email);
  }

  async function chargeCustomer(attempt: number) {
    // Implement the logic to charge the customer
    console.log("Charging the customer");

    if (attempt <= 2) {
      throw new Error("Payment failed");
    }

    return {
      invoiceId: "INV123",
      totalCost: 100,
    } as const;
  }
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI
  from typing import TypedDict, Optional
  from dataclasses import dataclass
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @dataclass
  class ChargeResult:
      invoice_id: str
      total_cost: float


  class ChargeUserPayload(TypedDict):
      email: str


  async def send_email(email: str, content: str) -> None:
      # Implement the logic to send an email
      print("Sending email to", email, "with content:", content)


  async def check_suspension(email: str) -> bool:
      # Implement the logic to check if the user is suspended
      print("Checking suspension status for", email)
      return True


  async def suspend_user(email: str) -> None:
      # Implement the logic to suspend the user
      print("Suspending the user", email)


  async def unsuspend_user(email: str) -> None:
      # Implement the logic to unsuspend the user
      print("Unsuspending the user", email)


  async def charge_customer(attempt: int) -> Optional[ChargeResult]:
      # Implement the logic to charge the customer
      print("Charging the customer")
      if attempt <= 2:
          raise Exception("Payment failed")
      return ChargeResult(invoice_id="INV123", total_cost=100)


  @serve.post("/payment-retries")
  async def payment_retries(context: AsyncWorkflowContext[ChargeUserPayload]) -> None:
      email = context.request_payload["email"]

      async def _check_suspension() -> bool:
          return await check_suspension(email)

      for i in range(3):
          # attempt to charge the user
          async def _charge_customer() -> Optional[ChargeResult]:
              try:
                  return await charge_customer(i + 1)
              except Exception as e:
                  print(f"Error: {e}")
                  return None

          result = await context.run("charge customer", _charge_customer)

          if not result:
              # Wait for a day
              await context.sleep("wait for retry", 24 * 60 * 60)
          else:
              # Unsuspend User
              is_suspended = await context.run("check suspension", _check_suspension)

              if is_suspended:

                  async def _unsuspend_user() -> None:
                      await unsuspend_user(email)

                  await context.run("unsuspend user", _unsuspend_user)

              # send invoice email
              async def _send_invoice_email() -> None:
                  await send_email(
                      email,
                      f"Payment successful. Invoice: {result.invoice_id}, Total cost: ${result.total_cost}",
                  )

              await context.run("send invoice email", _send_invoice_email)

              # by returning, we end the workflow run
              return

      # suspend user if the user isn't suspended
      is_suspended = await context.run("check suspension", _check_suspension)

      if not is_suspended:

          async def _suspend_user() -> None:
              await suspend_user(email)

          await context.run("suspend user", _suspend_user)

          async def _send_suspended_email() -> None:
              await send_email(
                  email,
                  "Your account has been suspended due to payment failure. Please update your payment method.",
              )

          await context.run("send suspended email", _send_suspended_email)

  ```
</CodeGroup>

## Code Breakdown

### 1. Charge Customer

We attempt to charge the customer:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const result = await context.run("charge customer", async () => {
    try {
      return await chargeCustomer(i + 1),
    } catch (e) {
      console.error(e);
      return
    }
  });
  ```

  ```python Python theme={"system"}
  async def _charge_customer() -> Optional[ChargeResult]:
      try:
          return await charge_customer(i + 1)
      except Exception as e:
          print(f"Error: {e}")
          return None

  result = await context.run("charge customer", _charge_customer)

  ```
</CodeGroup>

<Note>
  If we haven't put a try-catch block here, the workflow would have retried the step.
  However, because we want to run custom logic when the payment fails, we catch the error here.
</Note>

### 2. Retry Payment

We try to charge the customer 3 times with a 24-hour delay between each attempt:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  for (let i = 0; i < 3; i++) {
    // attempt to charge the customer

    if (!result) {
      // Wait for a day
      await context.sleep("wait for retry", 24 * 60 * 60);
    } else {
      // Payment succeeded
      // Unsuspend user, send invoice email
      // end the workflow:
      return;
    }
  }
  ```

  ```python Python theme={"system"}
  for i in range(3):
      # attempt to charge the customer

      if not result:
          # Wait for a day
          await context.sleep("wait for retry", 24 * 60 * 60)
      else:
          # Payment succeeded
          # Unsuspend user, send invoice email
          # end the workflow:
          return

  ```
</CodeGroup>

### 3. If Payment Succeeds

#### 3.1. Unsuspend User

We check if the user is suspended and unsuspend them if they are:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const isSuspended = await context.run("check suspension", async () => {
    return await checkSuspension(email);
  });
  if (isSuspended) {
    await context.run("unsuspend user", async () => {
      await unsuspendUser(email);
    });
  }
  ```

  ```python Python theme={"system"}
  async def _check_suspension() -> bool:
      return await check_suspension(email)

  is_suspended = await context.run("check suspension", _check_suspension)

  if is_suspended:

      async def _unsuspend_user() -> None:
          await unsuspend_user(email)

      await context.run("unsuspend user", _unsuspend_user)

  ```
</CodeGroup>

#### 3.2. Send Invoice Email

We send an invoice we got from the payment step to the user:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  await context.run("send invoice email", async () => {
    await sendEmail(
      email,
      `Payment successful. Invoice: ${result.invoiceId}, Total cost: $${result.totalCost}`
    );
  });
  ```

  ```python Python theme={"system"}
  async def _send_invoice_email() -> None:
      await send_email(
          email,
          f"Payment successful. Invoice: {result.invoice_id}, Total cost: ${result.total_cost}",
      )

  await context.run("send invoice email", _send_invoice_email)

  ```
</CodeGroup>

<Tip>
  One of the biggest advantages of using Upstash Workflow is that you have access to the result of the previous steps.
  This allows you to pass data between steps without having to store it in a database.
</Tip>

### 4. If Payment Fails After 3 Retries

#### 4.1. Suspend User

If the payment fails after 3 retries, we suspend the user and send them an email to notify them:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  const isSuspended = await context.run("check suspension", async () => {
    return await checkSuspension(email);
  });

  if (!isSuspended) {
    await context.run("suspend user", async () => {
      await suspendUser(email);
    });

    await context.run("send suspended email", async () => {
      await sendEmail(
        context.requestPayload.email,
        "Your account has been suspended due to payment failure. Please update your payment method."
      );
    });
  }
  ```

  ```python Python theme={"system"}
  async def _check_suspension() -> bool:
      return await check_suspension(email)

  is_suspended = await context.run("check suspension", _check_suspension)

  if not is_suspended:

      async def _suspend_user() -> None:
          await suspend_user(email)

      await context.run("suspend user", _suspend_user)

      async def _send_suspended_email() -> None:
          await send_email(
              email,
              "Your account has been suspended due to payment failure. Please update your payment method.",
          )

      await context.run("send suspended email", _send_suspended_email)

  ```
</CodeGroup>


# Waiting for Events
Source: https://upstash.com/docs/workflow/examples/waitForEvent



<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

## Introduction

This example demonstrates how to handle order processing using Upstash Workflow. The workflow will wait for an external system to process an order and resume once it is 'notified'. See our documentation [for more details about events](/workflow/howto/events).

## Use Case

Our workflow will be:

1. Receive an order request.
2. Send an email to request order processing.
3. Wait for an external event that indicates the order has been processed.
4. Handle timeout scenarios if the event is not received in time.
5. Save the results

## Code Example

```typescript  theme={"system"}
import { serve } from "@upstash/workflow/nextjs";

export const { POST } = serve(async (context) => {
  const { orderId, userEmail } = context.requestPayload;

  // Step 1: request order processing
  await context.run("request order processing", async () => {
    await requestProcessing(orderId)
  })

  // Step 2: Wait for the order to be processed
  const { eventData, timeout } = await context.waitForEvent(
    "wait for order processing",
    `order-${orderId}`,
    {
      timeout: "10m" // 10 minutes timeout
    }
  );

  if (timeout) {
    // end workflow in case of timeout
    return;
  }

  const processedData = eventData;

  // Step 3: Log the processed order
  await context.run("process-order", async () => {
    console.log(`Order ${orderId} processed:`, processedData);
  });

  // Step 4: Send a confirmation email
  await context.run("send-confirmation-email", async () => {
    await sendEmail(
      userEmail,
      "Your order has been processed!",
      processedData
    );
  });
});
```

Code for notifying the worklfow:

```typescript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })
const orderId = "1324"

await client.notify({
  eventId: `order-${orderId}`,
  eventData: { deliveryTime: "2 days" }
});
```

## Code Breakdown

### 1. Requesting Order Processing

In its first step, we call a method to request processing of the order in the request payload:

```typescript  theme={"system"}
await context.run("request order processing", async () => {
  await requestProcessing(orderId)
})
```

You can imagine that this step sends an email to the company responsible for the delivery.

### 2. Waiting for the Event

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3df80343dc367c8fd09ad6481c499ef" data-og-width="1722" width="1722" data-og-height="968" height="968" data-path="img/qstash-workflow/events/wait.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=eaad3c3925ec650f24de49ab927eee9f 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=69e1e0c8056d8f595ad1e9c15f297bc7 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b0af5a4244d8988889dd01e7b83fd41 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a7d9eabbaddef6bbbabb6e6530c49950 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=968e19f9a4e634b25ae6cdea637e2cba 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/wait.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0ba58ebcf66045fa7d2ff148295adab4 2500w" />
</Frame>

Next, the workflow waits for the order to be processed. It uses [the `waitForEvent` method](/workflow/basics/context#context-waitforevent) to pause execution and listen for the event. A timeout of 10 minutes (600 seconds) is applied to avoid indefinite waiting.

```typescript  theme={"system"}
const { eventData, timeout } = await context.waitForEvent(
  "wait for order processing",
  `order-${orderId}`,
  {
    timeout: "10m" // 10 minutes timeout
  }
);

if (timeout) {
  // end workflow in case of timeout
  return;
}
```

The workflow listens for the event with the ID `order-${orderId}`. When the external service notifies the workflow with this ID, the workflow resumes. If no event is received in time, the timeout ensures the workflow doesn't hang.

### 3. Processing the Order

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f9bd8c9beaa9cd1a245d9ad05e9368a3" data-og-width="1818" width="1818" data-og-height="1134" height="1134" data-path="img/qstash-workflow/events/resume.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e8f187626788599658c3d01e90ba8a83 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b28dbb06f5b7d8d0056d15bdd56c9626 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5512887f292138f88b0e267f7913a0f4 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e8044982eb0a63e10b817b8f5bba4096 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=abf44426dba2d1381ab3266ef8df8dec 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/events/resume.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3523c231515576213c67bd0b0819b4e8 2500w" />
</Frame>

Once the workflow resumes, the order data (`eventData`) is logged. This step could include updates to the database, inventory adjustments, or other backend operations specific to order processing.

```typescript  theme={"system"}
await context.run("process-order", async () => {
  console.log(`Order ${orderId} processed:`, processedData);
});
```

### 4. Sending a Confirmation Email

Once the order is processed, the workflow sends a confirmation email to the user.

```typescript  theme={"system"}
await context.run("send-confirmation-email", async () => {
  await sendEmail(
    userEmail,
    "Your order has been processed!",
    processedData
  );
});
```

## External Event Notification

To notify the workflow that the order has been processed, the external system sends a notification to the workflow with relevant data using the [`notify` method from the `Client`](/workflow/basics/client#notify-waiting-workflow). Alternatively, you can use [`context.notify` method](/workflow/basics/context#context-notify).

```typescript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const orderId = "1324";

await client.notify({
  eventId: `order-${orderId}`,
  eventData: { deliveryTime: "2 days" }
});
```

## Key Features

1. **Asynchronous Event Handling**: The workflow waits for an external event (order processing) to occur and only resumes once the event is received.
2. **Timeout Control**: A timeout mechanism ensures that the workflow doesn't hang if the event isn't received within the expected time.
3. **Order Processing**: Once notified, the workflow handles order processing and sends a confirmation email to the customer.
4. **External Event Notifications**: The external system can notify the workflow, providing the necessary data to resume execution and complete the process.


# Overview
Source: https://upstash.com/docs/workflow/features/dlq



The Dead Letter Queue (DLQ) automatically captures failed workflow runs that have exhausted all retry attempts.

This ensures that no workflow execution is lost and provides multiple options for recovering from failures gracefully.

## How it works?

When a workflow step fails and exhausts all configured retries, Upstash Workflow automatically moves the failed run to the DLQ.
This happens automatically without any additional configuration required.

<Frame caption="Failed workflow runs are automatically moved to the Dead Letter Queue">
  <img src="https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=55c87055536c48c56216202e3a640ac5" data-og-width="2726" width="2726" data-og-height="1652" height="1652" data-path="img/workflow/dlq.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=280&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=6f0358afca9d674e292c64ea81d61da8 280w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=560&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=b45ac5fa1f9cdecb83d23f4ad6d5a51d 560w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=840&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=3e7254872b08ae214cd99eab4c40efdd 840w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=1100&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=713068e3a84d90bac77caa55c9cd7341 1100w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=1650&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=59c549301e52181ebd7169597d6dc108 1650w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/dlq.png?w=2500&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=d85e89f2716701a583c4e9236ba2906c 2500w" />
</Frame>

The DLQ serves as a safety net, preserving failed workflow runs with their complete execution context.

<Note>
  Dead Letter Queue entries have retention period based on your pricing plan:

  * **Free**: 3 days
  * **Pay-as-you-go**: 1 week
  * **Fixed pricing**: Up to 3 months

  After the retention duration expires, DLQ items are automatically removed and cannot be recovered.
</Note>

## Recovery Actions

Once a workflow run is in the DLQ, you can take the following actions:

* **[Restart](/workflow/features/dlq/restart)** ‚Äì trigger the workflow from the beginning.
* **[Resume](/workflow/features/dlq/resume)** ‚Äì continue the workflow from the point of failure.
* **[Re-run Failure Function](/workflow/features/dlq/callback)** ‚Äì execute the workflow's failure handling logic again.
* or delete the DLQ entry if no action is required.

You can apply these actions in bulk to multiple DLQ entries. Check the individual action pages for more details.


# Rerun Failure Function
Source: https://upstash.com/docs/workflow/features/dlq/callback



The **Rerun Failure Function** action allows you to retry the failure function that executes when a workflow run enters the Dead Letter Queue (DLQ).

The failure function is typically a cleanup or notification operation that runs automatically whenever a workflow is moved to the DLQ.

This feature is particularly helpful for:

* Ensuring that important cleanup operations are executed.
* Guaranteeing that logging or alerting is completed after a workflow failure.
* Recovering from temporary errors in the failure function itself.

By manually rerunning this function, you can ensure that critical operations‚Äîsuch as cleanup tasks, logging, or alerting‚Äîcomplete successfully even if the main workflow has failed.

<Frame caption="You can retry the failure function of a workflow run if it has failed">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b821a3bd718fe7f8dfbb9f3600659b99" data-og-width="2568" width="2568" data-og-height="1988" height="1988" data-path="img/workflow/retry_failure_callback.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=77fecfb6cf4a3dfe916f447adac2b6d4 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=119ab6e368e3c9268da35c3c3d367b21 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6bf3f9e9604924594b21166bfa297318 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c059230b1c21e93466ecb4380ddc95f2 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=50ba5df4a42e7dcba612a7a3d29e9365 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=feb1c2edd18cf8f8095f58d6d0a6ae4f 2500w" />
</Frame>

You can perform this action programmatically as well:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<WORKFLOW_TOKEN>" });

  await client.dlq.retryFailureFunction({
    dlqId: "dlq-12345",
  });
  ```
</CodeGroup>

<Note>
  This action is only available if the failure function itself has failed as well.
  If the failure function already succeeded, it cannot be rerun.

  You can view the status of the failure function in the **DLQ** and **Logs** dashboards, which indicate whether it succeeded or failed.
</Note>


# Restart
Source: https://upstash.com/docs/workflow/features/dlq/restart



The **Restart** action allows you to re-execute a failed workflow run from the beginning.
All previous step results are discarded, and the workflow executes from scratch using the original configuration and initial payload.

This approach is ideal when:

* Previous step results are no longer relevant.
* The failure was caused by corrupted or inconsistent state.
* You need a completely fresh execution with updated or clean data.

<Frame caption="Restart a workflow run from DLQ">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b14fdc6e477eeb40eebf0572529d9242" data-og-width="2658" width="2658" data-og-height="1976" height="1976" data-path="img/workflow/restart.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=3cf4bc6bae9f8bb83a0c56bd64be4809 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=fa306daa8f64ccdcf2c87996882985fc 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=945a74a448e66c6ff9b0463cc011becd 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=3ca2afeab17a88140b523a1d7c592c1d 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c9a48be1b7c69da853a47e8bb3e4ac6d 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/restart.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=78675c80199d831c2be56e1b0b91c12b 2500w" />
</Frame>

You can perform this action programmatically as well:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<WORKFLOW_TOKEN>" });

  await client.dlq.restart({
    dlqId: "dlq-12345",
    retries: 3,
  });
  ```
</CodeGroup>


# Resume
Source: https://upstash.com/docs/workflow/features/dlq/resume



The **Resume** action allows you to continue a failed workflow run from the exact point of failure, preserving all successfully completed steps and their results.

This approach is ideal when:

* The workflow has long-running or resource-intensive steps that have already succeeded.
* You want to preserve progress and avoid re-executing successful operations.
* The failure was a temporary issue that can now be resolved.

<Frame caption="You can retry the failure function of a workflow run if it has failed">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b6d936599c1cabce400857c628c902c9" data-og-width="2658" width="2658" data-og-height="1976" height="1976" data-path="img/workflow/resume.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=8a4cb509e051000f8b2e9fa95a47f3ad 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=3a6133751751c767007141d13f8da917 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=9ff34ef3815854b57ea6ced7da44ce9c 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=bd4e26a628b09b69ecf8cf5eb7eebc41 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b4ab85383aefe3b059c29be481bdf6b8 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/resume.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=ab2d4c843c34387fef9ed8d882225584 2500w" />
</Frame>

You can perform this action programmatically as well:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<WORKFLOW_TOKEN>" });

  await client.dlq.resume({
    dlqId: "dlq-12345",
    retries: 3,
  });
  ```
</CodeGroup>

<Note>
  You can modify workflow code as long as changes occur **after** the failed steps.
  Changes to steps prior to the failure are not allowed and may break the workflow.

  For more details, check out the [Handle workflow route code changes](/workflow/howto/changes) page.
</Note>


# Overview
Source: https://upstash.com/docs/workflow/features/failure-callback



When you define a workflow endpoint, you can attach a failure function to the workflow that allows you to execute custom logic when a workflow run fails after exhausting all retry attempts.

This feature ensures that you can perform cleanup operations, logging, alerting, or any other custom error handling logic before the failed workflow run is moved to the Dead Letter Queue (DLQ).

<Frame caption="Failure function is executed automatically when worklow run fails">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=65d05df8e2b6870a0f71164fbcac04b8" data-og-width="2728" width="2728" data-og-height="2068" height="2068" data-path="img/workflow/failure_function.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=adbc4d16270f2deb60df588faaa7c84c 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=1dbced323d50902d0175292eaa88e64c 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b1a91a444c572359d726bf255d568f55 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=06a319628696f4af84f5423af228ff62 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c198b70450e9d331aae0071f3f4b2570 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_function.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=de7f0d18b7530df7f59ecf22ccf45089 2500w" />
</Frame>

The failure function automatically receives the workflow run context and the reason for the failure, so you can decide how to handle it.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(
    async (context) => {
      // Your workflow logic...
    },
    {
      failureFunction: async ({
        context,
        failStatus,
        failResponse,
        failHeaders,
      }) => {

        // üëá Log error to monitoring system
        await logToSentry(...);

        // üëá Send alert to team
        await sendSlackAlert(...);

        // üëá Perform cleanup operations
        await cleanupWorkflowResources(...);
      },
    }
  ```

  );
</CodeGroup>

You cannot create new workflow steps inside the `failureFunction` using `context`.
The `context` provided here is only meant to expose workflow run properties (like URL, payload, and headers).
Think of the failure function as an individual `context.run` step. It executes once with the provided context but cannot define further steps.

<Info>
  If you use a custom authorization method to secure your workflow endpoint, add authorization to the `failureFunction` too.
  Otherwise, anyone could invoke your failure function with a request.

  Read more here: [securing your workflow endpoint](/workflow/howto/security).
</Info>

## Parameters

The `failureFunction` receives an object with the following parameters:

<ParamField body="context" type="object">
  The workflow context object containing:

  <Expandable>
    <ParamField body="workflowRunId" type="string">
      The ID of the failed workflow run
    </ParamField>

    <ParamField body="url" type="string">
      The publicly accessible workflow endpoint URL
    </ParamField>

    <ParamField body="requestPayload" type="string">
      The original request payload that triggered the workflow
    </ParamField>

    <ParamField body="headers" type="string">
      The original request headers
    </ParamField>

    <ParamField body="env" type="string">
      Environment variables
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="failStatus" type="number">
  The HTTP status code returned by the failed workflow step.
</ParamField>

<ParamField body="failResponse" type="number">
  The response body returned by the failed workflow step.
</ParamField>

<ParamField body="failHeaders" type="number">
  The response headers returned by the failed workflow step.
</ParamField>

## Configuration

You can enable failure function for a workflow run when starting it:

```typescript Configure Retry Attempt Count theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  // üëá Activates the failure function execution if it is defined
  useFailureFunction: true,
  keepTriggerConfig: true,
})
```


# Advanced failureUrl Option
Source: https://upstash.com/docs/workflow/features/failureFunction/advanced



The `failureUrl` is an advanced option that sends failure callback to a different endpoint rather than to the workflow endpoint (failure function).
This approach is useful for handling failures on separate infrastructure.

<Tip>You can use either `failureFunction` or `failureUrl`, but not both. These options are mutually exclusive.</Tip>

For most users, **Failure Function** is the better choice because:

* It runs alongside your workflow and has access to the same context and dependencies
* Failure function requests are automatically retried on failure as well.
* You can manually retry failure function if it fails via DLQ.

If you think this advanced option fits your need, you can configure it by passing `failureUrl` configuration.

<CodeGroup>
  ```typescript  theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })

  const { workflowRunId } = await client.trigger({
    url: "https://<YOUR_WORKFLOW_URL>/workflow"
    failureUrl: "https://<YOUR_FAILURE_URL>/workflow-failure",
    keepTriggerConfig: true,
  })
  ```

  ```python Python theme={"system"}
  @serve.post("/api/example", failure_url="https://<YOUR_FAILURE_URL>/workflow-failure")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      # Your workflow logic...
      pass
  ```
</CodeGroup>


# Reliability of Failure Function
Source: https://upstash.com/docs/workflow/features/failureFunction/reliability



The failure function is executed whenever a workflow run fails.

In some cases, the failure function itself may throw an error.
When this happens, it will be retried according to the workflow run's retry configuration.
If all retry attempts also fail, the failure function execution is marked as failed.

You can view and filter workflow runs with failed failure function executions in the DLQ dashboard.

<Frame caption="You can filter DLQ entries by failure function state">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=bb2e7876881dd34056eec3c76de7f4fe" data-og-width="2562" width="2562" data-og-height="1976" height="1976" data-path="img/workflow/failure_callback_state_filter.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=da2326f2f6a4e9150fc03f9ad10338ee 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=72659c9797764dd292603c98be068ca7 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=a603d1168489ffdc38b86a90f1ce1afd 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=596753274e040acadea3f40bad09176f 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=940a2b4ba4cd0a8ada87650bcffb0638 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/failure_callback_state_filter.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=90b1dd00d63775ea95ef4ab80977de4a 2500w" />
</Frame>

From the DLQ dashboard, you can retry the failure function.

<Frame caption="You can filter DLQ entries by failure function state">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b821a3bd718fe7f8dfbb9f3600659b99" data-og-width="2568" width="2568" data-og-height="1988" height="1988" data-path="img/workflow/retry_failure_callback.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=77fecfb6cf4a3dfe916f447adac2b6d4 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=119ab6e368e3c9268da35c3c3d367b21 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6bf3f9e9604924594b21166bfa297318 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c059230b1c21e93466ecb4380ddc95f2 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=50ba5df4a42e7dcba612a7a3d29e9365 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/retry_failure_callback.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=feb1c2edd18cf8f8095f58d6d0a6ae4f 2500w" />
</Frame>

You can perform this action programmatically as well:

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

const response = await client.dlq.retryFailureFunction({
  dlqId: "dlq-12345" // The ID of the DLQ message to retry
});
```


# Overview
Source: https://upstash.com/docs/workflow/features/flow-control



Flow Control allows you to limit how many workflow steps are executed by delaying and queuing their delivery.

This feature helps to:

* Manage resource consumption
* Prevent violations of external API rate limits
* Ensure workflows run within defined system constraints

## How Flow Control Works

When defined limits are exceeded, Flow Control automatically queues and delays step executions instead of rejecting them.
This guarantees that all steps are eventually processed while staying within configured thresholds.

To configure Flow Control, you define a flow control key, a unique identifier used to group related steps under the same rate and parallelism limits.
The steps that has the same flow control key respect the same constraints.

There are two main parameters to configure:

* [Rate and Period](/workflow/features/flow-control/rate-period): Maximum number of steps that may start within a time window
* [Parallelism](/workflow/features/flow-control/parallelism): Maximum number of steps allowed to run concurrently

These parameters can be combined for fine‚Äëgrained control.
For example, you can allow up to 10 steps per minute but restrict concurrency
to 5 steps in parallel, ensuring more predictable load patterns.

## Example

Suppose you have the following workflow:

```typescript  theme={"system"}
export const { POST } = serve<{ topic: string }>(async (context) => {
  const payload = context.requestPayload

  await context.run("step-1", () => { ... });

  await context.run("step-2", () => { ... });

  await context.run("step-3", () => { ... });
})
```

Now imagine you trigger **N workflow runs** for this workflow with the following configuration:

```typescript  theme={"system"}
const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  flowControl: {
    key: "fw_example",
    parallelism: 7,
    rate: 3,
    period: "1m",
  },
  keepTriggerConfig: true,
})
```

Without Flow Control, all workflow runs immediately execute their steps as soon as possible.
If the workflow calls an external API in a step, this would likely result in \~N concurrent requests being fired in a very short timeframe, potentially overloading services or breaching API limits.

<Frame caption="Workflow simplified by step types">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=00abee01364d02ee0de0885c718fd41f" data-og-width="658" width="658" data-og-height="241" height="241" data-path="img/workflow/flow_control_ex_3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c648645fabc40fccc428cd0a1d32a24a 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d3be1762f6ea88fce8e17f8315f5ee55 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=dd39cf7e6f01ad6ce9cc64c95a47eecd 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=7b76d616e49442c2ddcb81677230da08 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=f2f179932b85ee72b568bb84b6302263 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_3.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=ac25a92a95fd2346bb665326dfee5da7 2500w" />
</Frame>

With the configuration above:

* **Rate:** At most 3 steps per minute can start across all workflow runs.
* **Parallelism:** At most 7 steps can be running at the same time.

Steps that exceed these limits are automatically queued and executed later.

<Frame caption="Steps are enqueued for execution">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=bf64d6a7f4b4bb560d0de92e876bc0c9" data-og-width="1091" width="1091" data-og-height="451" height="451" data-path="img/workflow/flow_control_ex_2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6c029a364026f6a282cc6b0c8e8d7f6f 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=27f0c274948a17838028fa3b94bc01b3 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=07f6fa5c98e41cda83bc912e42e7b96f 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=32c239dba69eedbc277e08708e0a8f42 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=0e44ab27623808fd41999f763df36c34 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_2.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=8fb65f9e8a519387da080b6e5a502d84 2500w" />
</Frame>

Note that each step above corresponds to a separate workflow run.
Because this workflow is sequential, each workflow run has only one pending step at a time.
In workflows with **parallel branches**, multiple steps from the same workflow run may appear in the schedule simultaneously.

Parallelism slots are consumed by running steps.
If no slots are available, new steps enter the **waitlist** until resources free up:

<Frame caption="Parallelism waitlist for the flow-control">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=297f424a8fef25787e7e5d986cbd990b" data-og-width="1091" width="1091" data-og-height="491" height="491" data-path="img/workflow/flow_control_ex_1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=efbb88dcc4080e7db40872181e7f75a7 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=f831c8483222d7ba121a971a5b57c5c8 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=8292d0d265fbb91ec8483e9c2383a830 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c0076acee733bce0a253d3822b59c989 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=13c17407ffc2d6289761b5ec4266d624 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/flow_control_ex_1.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=eeb48b7cd2095685320971227712e2ab 2500w" />
</Frame>

<Note>
  Upstash Workflow does not support per-step level configuration. Meaning that you can attach a flow-control configuration
  to the workflow run and all the steps will inherit to the same limits.
  Following the analogy above, you cannot enforce parallelism limit on "green" steps natively.

  The context.call and context.invoke steps are exception this to this rule and accept their own flow control configuration:

  * [context.call](/workflow/basics/context/call) ‚Äì lets you run external HTTP requests under a separate key, so you can throttle third‚Äëparty API calls independently of your workflow logic.
  * [context.invoke](/workflow/basics/context/invoke) ‚Äì starts a new workflow run with its own flow control configuration. This allows the invoked workflow to run under different limits than the parent workflow, giving you more precise control.

  If you want to throttle a specific `context.run` step, the recommended approach is to **extract it into a separate workflow** and call it using `context.invoke()` with its own flow control configuration with a stricter limits.
</Note>

## Configuration

You can configure flow control when starting a workflow run:

```typescript Configure Retry Attempt Count theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  flowControl: {
    key: "user-signup",
    parallelism: 1,
    rate: 10,
    period: 100,
  },
  keepTriggerConfig: true,
})
```

All steps within a workflow run will adhere to the specified flow control configuration.

<Warning>
  Keep in mind that rate/period and parallelism info are kept on each step separately.
  If you change the rate/period or parallelism on a new deployment, the old fired ones will not be affected.
  They will keep their flow control configuration.

  During the period that old steps have not been delivered but there are also steps with new rates, Upstash Workflow will effectively allow the highest rate/period or highest parallelism. Eventually (after the old publishes are delivered), the new rate/period and parallelism will be used.
</Warning>


# Parallelism
Source: https://upstash.com/docs/workflow/features/flow-control/parallelism



The parallelism limit controls the maximum number of calls that can be executed concurrently.
Unlike rate limiting (which works per time window), parallelism enforces concurrency control with a token-based system.

```typescript Configure Retry Attempt Count theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  flowControl: {
    key: "user-signup",
    parallelism: 10,
  },
  keepTriggerConfig: true,
})
```

**Example**:
If `parallelism = 3`, at most 3 requests can run concurrently.

When tokens are available, requests acquire one and start execution:

<Frame caption="A failing step is automatically retried three times">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=33f44e2266b0d43208369e82f8e61553" data-og-width="2342" width="2342" data-og-height="1126" height="1126" data-path="img/workflow/parallelism_1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=008ec116f9e04594fa858e425c27fec0 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=dd4f3549250155403b639dc2d057c460 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6654cd13e6065d0c88b258b03619bf85 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=c56a93e6e50fb5320b4592307fab8247 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=376ac3452ec940edcf08b08818d33a5c 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_1.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d4df5ca83676cacbe16447f6b1a20a36 2500w" />
</Frame>

When all tokens are in use, additional requests are not failed ‚Äî they‚Äôre queued in a **waitlist**:

<Frame caption="A failing step is automatically retried three times">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=9ab65cc92230f2b03e40fb7743887aea" data-og-width="2342" width="2342" data-og-height="1126" height="1126" data-path="img/workflow/parallelism_2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=af67f3f0cc95401d6bf5a0f59a1561a0 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b4a72c08bd218232155931064aed17bd 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=8bb78014f2abf6529283605d2d288695 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=f001934c7f0993919bd60023593921f8 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=2d3471320aebf7d6550f7665f852f5dd 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_2.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=5fd70480fd5bdc5877784273a2d4e3f8 2500w" />
</Frame>

The step in the waitlist will wait for a step to complete and hand off it's token to a pending request:

<Tip>
  Token handoff does not guarantee strict ordering.
  A later request in the waitlist may acquire a token before an earlier one.
</Tip>

<Frame caption="A failing step is automatically retried three times">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=e9d284cf4ed9a0a8fcbe20f1cdefbedf" data-og-width="2342" width="2342" data-og-height="1126" height="1126" data-path="img/workflow/parallelism_3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=cea665805f66c25cd546f71faddf26c8 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=1eddc37c697205d2502a9e8365410fd5 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6f3c09fffa80698a3a0f308563e60401 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b669d35cb7827b3de34c934b9777be35 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=10623e574cbe4312d1351f525e013ccd 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallelism_3.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=19fc76d5912e823bfa437217c7492c1d 2500w" />
</Frame>

## Monitoring

You can monitor wait list size of your flow control key's using the REST API.

<CodeGroup>
  ```bash Single Flow Control Key theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/YOUR_FLOW_CONTROL_KEY \
    -H "Authorization: Bearer <token>"
  ```

  ```bash List All Flow Control Keys theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/ \
    -H "Authorization: Bearer <token>"
  ```
</CodeGroup>

It will return the wait list size. In case you request all flow-control keys, it is an array response.

<ResponseField name="flowControlKey" type="string">
  The identifier for your flow control configuration
</ResponseField>

<ResponseField name="waitListSize" type="number">
  Number of steps waiting to be executed due to parallelism limits
</ResponseField>

<Info>
  Adding a dashboard to list and manage flow control key's is on our roadmap.
</Info>


# Rate and Period
Source: https://upstash.com/docs/workflow/features/flow-control/rate-period



The rate specifies the maximum number of requests allowed in a given period (time window).

```typescript Configure Retry Attempt Count theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  flowControl: {
    key: "user-signup",
    rate: 10,
    period: 100,
  },
  keepTriggerConfig: true,
})
```

**Example**:
If `rate = 2` and `period = 1 minute`, then **a maximum of 2 steps** can be executed per minute.

The first 2 requests within the minute are executed immediately:

<Frame caption="Steps are executed within limit">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=416a2d089ba4026c18164a97375d69d9" data-og-width="2342" width="2342" data-og-height="848" height="848" data-path="img/workflow/rate_1.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=4e3d0b9b731bc9ccad4632eaba183731 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d861f5e56dede2b0e12af7af73ec8b94 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=434dd9eb6f00724d1bd3f10623fbe0b9 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=a9cb69cd57119b2f1fc7c5bdfc63e347 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=63dfa8c4a64ed57db37afc72e6fd121b 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_1.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=32aeff9c7f068699bc8f923711f68864 2500w" />
</Frame>

The 3rd request in the same minute is not executed immediately:

<Frame caption="A new step cannot execute immediately">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=bcf1550d87068c16aa182171bc240a97" data-og-width="2342" width="2342" data-og-height="848" height="848" data-path="img/workflow/rate_2.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=22f471bf05f0bc97b183571a117dd13f 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=be6de86526d51e7f9d2a66f27aced226 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=7ac0a3ae87ca971aa992a24341d7b12d 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=4e93f27eab21f11943b2070a80970045 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=31622b3aa4c8b3d045a269208cdbfe47 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_2.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=27bfcc08a5afb8318141305805fb095a 2500w" />
</Frame>

Instead of rejecting it, Workflow schedules the request in the next available time window:

<Frame caption="The new step is moved to the next time window">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=cd597a831970d7fc7dd1a9af6be0e2a7" data-og-width="2342" width="2342" data-og-height="848" height="848" data-path="img/workflow/rate_3.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=4131ef3ca8f884ec25c238351f3d8ff6 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=5fe76af569462d9c730fb478e9cc2301 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=9b2b574d1f5c513fae20559957862c2b 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=a06a1e8a2cad1ea6be29ead79c01d8bc 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=46b7fb277625a24d63aebaabdd134c82 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/rate_3.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=b89308e1ee820cb9fab082e923170eb7 2500w" />
</Frame>

Note that step executions may take longer than the defined period.
The rate limit only controls how many steps are **started** within each time window,
it does not limit their execution duration.


# Overview
Source: https://upstash.com/docs/workflow/features/invoke



You can start another workflow run inside a workflow and await its execution to complete.
This allows to orchestrate multiple workflows together without external synchronization.

When you use `context.invoke`, invoking workflow will wait until the invoked workflow finishes before running the next step.

```typescript  theme={"system"}
const {
  body,      // response from the invoked workflow
  isFailed,  // whether the invoked workflow was canceled
  isCanceled // whether the invoked workflow failed
} = await context.invoke(
  "analyze-content",
  {
    workflow: analyzeContent,
    body: "test",
    header: {...}, // headers to pass to anotherWorkflow (optional)
    retries,       // number of retries (optional, default: 3)
    flowControl,   // flow control settings (optional)
    workflowRunId  // workflowRunId to set (optional)
  }
)
```

You can return a response from a workflow, which will be delivered to invoker workflow run.

<Frame caption="You can navigate between the invoker and invoked workflow runs on the dashboard">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=be3ca055f5f46e428c84a7983c2402e5" data-og-width="2658" width="2658" data-og-height="1976" height="1976" data-path="img/workflow/invoke.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=95507fbe673befccc3556d4b4a6f718e 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=2bc7e59da157da8dd232093b4146f369 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=5bf2affd5061997df74054dd6b00694b 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=ac40691a971029998a0c40983295084f 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d057f384353c6dc8921c9df3b053becb 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/invoke.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d20b0e49e253ef8b825838fa14adf619 2500w" />
</Frame>

<Note>
  You cannot create an infinite chain of workflow invocations. If you set up an 'invoke loop' where workflows continuously invoke each other, the process will fail once it reaches a depth of 100.
</Note>


# Using Serve Many
Source: https://upstash.com/docs/workflow/features/invoke/serveMany



Normally, workflows are created with `serve()`, which exposes each workflow as its own HTTP endpoint.
If workflows were invoked only by their full URL, it would mean:

* You'd have to provide the URL explicitly like a trigger request
* You'd lose type safety for request and response payloads

To avoid these issues, Upstash Workflow lets you define workflows as objects and expose them under the same parent path.
This way, you can invoke a workflow simply by passing the object to `context.invoke`, with full type safety and no URLs required.

<Steps>
  <Step title="Create workflow objects">
    Use `createWorkflow()` to define workflows as objects.

    It works just like `serve()`‚Äîaccepting the same arguments‚Äîbut does **not** expose the workflow directly as an HTTP endpoint.
    Instead, it simply initializes a workflow object.

    ```typescript  theme={"system"}
    const anotherWorkflow = createWorkflow(
      // üëá Request Payload Type
      async (context: WorkflowContext<string>) => {

        await context.sleep("wait 1 second", 1)

        // üëá Workflow Response Type
        return { message: "This is the data returned by the workflow" };
      }
    );

    const someWorkflow = createWorkflow(async (context) => {
      // üëá Invoke the workflow with type-safe call
      const { body } = await context.invoke(
        "invoke anotherWorkflow",
        {
          workflow: anotherWorkflow,
          body: "user-1"
        }
      ),
    });
    ```
  </Step>

  <Step title="Expose multiple workflows under same endpoint">
    Use `serveMany()` instead of `serve()` to expose multiple workflows on a single catch‚Äëall route.

    If one workflow is going to invoke another, both must be included in the same `serveMany` definition.
    First step of using `serveMany` is to define a catch-all route.

    ```typescript app/serve-many/[...any]/route.ts theme={"system"}
    export const { POST } = serveMany(
      {
        "workflow-one-route": workflowOne,
        "workflow-two-route": workflowTwo,
      }
    )
    ```

    <Info>
      In Next.js, a catch‚Äëall route can be defined by creating a `route.ts` file inside a directory named with `[...]`, for example: `app/serve-many/[...any]/route.ts`.

      For implementations of `serveMany` in other frameworks, you can refer to the projects available in the [`examples` directory of the workflow-js repository](https://github.com/upstash/workflow-js/tree/main/examples).
    </Info>
  </Step>

  <Step title="Invoke by passing workflow object">
    When invoking, pass the workflow object created with `createWorkflow()` (from step 1) as the argument to `context.invoke()`.
    This removes the need to specify a URL explicitly and ensures the call is
    fully type‚Äësafe.

    ```ts  theme={"system"}
    const someWorkflow = createWorkflow(async (context) => {
      // üëá Invoke the workflow with type-safe call
      const { body } = await context.invoke(
        "invoke anotherWorkflow",
        {
          // üëá Pass the workflow object as argument
          workflow: anotherWorkflow,
          body: "user-1"
        }
      ),
    });
    ```
  </Step>

  <Step title="Trigger">
    In this example, both `workflowOne` and `workflowTwo` are exposed through `serveMany`, sharing the same parent path.

    You can start `workflowOne` by sending a trigger request to:
    `https://your-app/serve-many/workflow-one-route`.

    ```typescript  theme={"system"}
    import { Client } from "@upstash/workflow";

    const client = new Client({ token: "<QSTASH_TOKEN>" })

    const { workflowRunId } = await client.trigger({
      // üëá URL of workflow one
      url: "https://your-app/serve-many/workflow-one-route",
      keepTriggerConfig: true,
    })
    ```

    Route names are inferred from the keys you pass to `serveMany`.
    For example, you can start `workflowTwo` by sending trigger request to: `https://your-app/serve-many/workflow-two-route`.
  </Step>
</Steps>


# Notify
Source: https://upstash.com/docs/workflow/features/notify



You can notify all the workflow runs waitingi for a specific event ID.
There are two ways to send a notify request.

## Notify within Workflow

Notifies other workflows waiting for a specific event from within a workflow.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(async (context) => {
    const { orderId, processingResult } = context.requestPayload;

    await context.run("process-order", async () => {
      // ...
    })

    const { notifyResponse } = await context.notify(
      "notify-processing-complete",
      `order-${orderId}`,
      {
        orderId,
        status: "completed",
        result: processingResult,
        completedAt: new Date().toISOString()
      }
    );

  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext
  from datetime import datetime

  app = FastAPI()
  serve = Serve(app)

  @serve.post("/api/order-processor")
  async def order_processor(context: AsyncWorkflowContext[str]) -> None:
      order_id = context.request_payload["order_id"]
      processing_result = context.request_payload["processing_result"]

      # Process the order
      async def _process_order():
          return await process_order(order_id)

      result = await context.run("process-order", _process_order)

      # Notify waiting workflows that processing is complete
      notify_response = await context.notify(
          "notify-processing-complete",
          f"order-{order_id}",
          {
              "order_id": order_id,
              "status": "completed",
              "result": processing_result,
              "completed_at": datetime.utcnow().isoformat()
          }
      )

      # Log notification results
      async def _log_notification():
          print(f"Notified {len(notify_response)} waiting workflows")
          return notify_response

      await context.run("log-notification", _log_notification)
  ```
</CodeGroup>

## External Notification

You can also notify workflows from external systems using the Workflow Client:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<WORKFLOW_TOKEN>" });

  await client.notify({
    eventId: "order-completed-123",
    eventData: {
      orderId: "123",
      status: "completed",
      deliveryTime: "2 days",
      trackingNumber: "TRK123456"
    }
  });
  ```

  ```python Python theme={"system"}
  from upstash_workflow import Client

  client = Client("<WORKFLOW_TOKEN>")

  # Notify workflows waiting for a specific event
  await client.notify(
      event_id="order-completed-123",
      event_data={
          "order_id": "123",
          "status": "completed",
          "delivery_time": "2 days",
          "tracking_number": "TRK123456"
      }
  )
  ```
</CodeGroup>


# Parallel Steps
Source: https://upstash.com/docs/workflow/features/parallel-steps



Upstash Workflow supports executing multiple steps in parallel.

Since each step returns a `Promise`, you can execute multiple steps concurrently by using `Promise.all()`.
This behavior works out of the box. No additional configuration is required.

```typescript app/api/workflow/route.ts theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { checkInventory, brewCoffee, printReceipt } from "@/utils";

export const { POST } = serve(async (context) => {

  // üëá Execute steps in parallel
  const [coffeeBeansAvailable, cupsAvailable, milkAvailable] =
    await Promise.all([
      context.run("check-coffee-beans", () => checkInventory("coffee-beans")),
      context.run("check-cups", () => checkInventory("cups")),
      context.run("check-milk", () => checkInventory("milk")),
    ]);

});
```

The results of the parallel steps are available as usual once awaited.

The dashboard visualizes parallel execution as shown below:

<Frame caption="The workflow executes three steps in parallel">
  <img src="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=e7e8c68861f76152c98ca015fc3c0913" data-og-width="2620" width="2620" data-og-height="1992" height="1992" data-path="img/workflow/parallel_steps.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=280&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=4edfaaa0a9df3933dcee3df2e7c4db31 280w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=560&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=7e558fba7f0c775fde3cc6ee6ff1dee0 560w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=840&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=d9951af9065135f6c7da313637b8d345 840w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=1100&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=5fc4cbb09d7180979eabce86fb5a7b1a 1100w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=1650&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=6bbed50a4f2307529f7dc82e07b15169 1650w, https://mintcdn.com/upstash/veMt3N2QLOAoUf0w/img/workflow/parallel_steps.png?w=2500&fit=max&auto=format&n=veMt3N2QLOAoUf0w&q=85&s=35b85844e807fd61a79d796c46649653 2500w" />
</Frame>

You can also await different step types together. For example, you can run a `context.call()` and a `context.run()` in parallel.

<Warning>
  Whether executing sequentially or in parallel, you should always
  <code>await</code> all promises in a workflow.
  Leaving promises unawaited may cause unexpected behavior.
</Warning>


# Overview
Source: https://upstash.com/docs/workflow/features/retries



Upstash Workflow provides an automatic retry mechanism to improve reliability and make workflows resilient against temporary failures.
Workflow automatically handles transient errors such as network issues or service unavailability.

## How Retries Work

When a step fails, Upstash Workflow automatically retries the failed step with configurable retry attempts and delay strategy.
This allows temporary issues to resolve without manual intervention.

<Frame caption="A failing step is automatically retried three times by default">
  <img src="https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=b082701763068698f0c9cf799c0b103f" data-og-width="2712" width="2712" data-og-height="2062" height="2062" data-path="img/workflow/automatic_retry.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=280&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=812f44fe1af682d6f76d24fd2c6a596f 280w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=560&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=6ba50e0cf5663866adc1f7188c9ca005 560w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=840&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=140d6b7de2f3b1fec736f3da37eb72a4 840w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=1100&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=1dd701aab5c1bafa5bba097f62e5f070 1100w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=1650&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=98521bb337818bd4e4b353829858973a 1650w, https://mintcdn.com/upstash/GtBGrkScIq73E0LP/img/workflow/automatic_retry.png?w=2500&fit=max&auto=format&n=GtBGrkScIq73E0LP&q=85&s=92fccb600a8c71c94434416677aaa59d 2500w" />
</Frame>

By default, the retry count is set to **3**, and an **exponential backoff** delay strategy is used.

```javascript Default Backoff Algorithm theme={"system"}
// n = how many times this request has been retried
delay = min(86400, e ** (2.5*n)) // in seconds
```

| Retry Attempt | Algorithm | Delay |
| ------------- | --------- | ----- |
| 1             | $e^{2.5}$ | 12s   |
| 2             | $e^5$     | 2m28s |
| 3             | $e^{7.5}$ | 30m8s |
| 4+            | $86400$   | 24h   |

## Configuration

You can configure retry behavior when starting a new workflow run.

### Configure Retry Attempt Count

You can specify how many times a step should be retried upon failure.

```typescript Configure Retry Attempt Count theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  retries: 3,
  keepTriggerConfig: true,
})
```

### Configure Retry Delay Strategy

Retry delay is the time to wait before trying again after a failure. You can define a custom retry delay strategy.

The delay is defined as a math expression that is calculated on every retry.
The expression can use the `retried` variable, which represents how many times the step has already retried (starting from 0).

To apply a constant delay, you can simply provide a fixed value.

The expression must return the delay in **milliseconds**.

```typescript Configure Retry Delay Strategy theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" })

const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  retries: 3,
  retryDelay: "(1 + retried) * 1000",
  keepTriggerConfig: true,
})
```


# Prevent Retries
Source: https://upstash.com/docs/workflow/features/retries/prevent-retries



It is recommended to enable retries for workflow runs to improve reliability.

However, in some cases, you may want to stop execution immediately when an error occurs, without causing additional retries.
Upstash Workflow provides several mechanisms to terminate workflow execution gracefully.

## Using `WorkflowNonRetryableError`

`WorkflowNonRetryableError` lets you explicitly fail a workflow without entering the retry cycle.

When thrown, the workflow run is marked as failed, which:

* Triggers the failure function (if defined)
* Sends the workflow run to the DLQ

```ts TypeScript highlight={7} theme={"system"}
export const { POST } = serve<{ topic: string }>(async (context) => {
  const payload = context.requestPayload

  const isExists = await context.run("is-user-exists", () => { ... });

  if (!isExists) {
    throw new WorkflowNonRetryableError("The user does not exists!")
  }
})
```

## Using `context.cancel()`

You can cancel a workflow run explicitly from inside the workflow.

When canceled, the run is labeled as canceled instead of failed. This means:

* The failure handler will **NOT** be triggered
* The workflow will **NOT** be sent to the DLQ

<CodeGroup>
  ```typescript highlight={10-11} TypeScript theme={"system"}
  export const { POST } = serve<{ orderId: string }>(async (context) => {
    const { orderId } = context.requestPayload;

    // Check if order is still valid
    const orderStatus = await context.run("check-order-status", async () => {
      return await getOrderStatus(orderId);
    });

    if (orderStatus === "cancelled") {
      // Stop execution gracefully without error
      await context.cancel();
      return;
    }

    // Continue processing if order is valid
    await context.run("process-order", async () => {
      return await processOrder(orderId);
    });
  });
  ```

  ```python Python theme={"system"}
  @serve.post("/graceful-cancellation")
  async def graceful_cancellation(context: AsyncWorkflowContext[dict]) -> None:
      order_id = context.request_payload["order_id"]

      async def _check_order_status():
          return await get_order_status(order_id)

      # Check if order is still valid
      order_status = await context.run("check-order-status", _check_order_status)

      if order_status == "cancelled":
          # Stop execution gracefully without error
          await context.cancel()
          return

      # Continue processing if order is valid
      async def _process_order():
          return await process_order(order_id)

      await context.run("process-order", _process_order)
  ```
</CodeGroup>

## Using conditional execution

You can also use guard conditions to skip certain steps and exit early, without throwing errors or canceling the workflow.

In this case, the workflow run completes successfully because no error was raised.

<CodeGroup>
  ```typescript TypeScript highlight={10-11} theme={"system"}
  export const { POST } = serve<{ data: any }>(async (context) => {
    const { data } = context.requestPayload;

    // Check if order is still valid
    const orderStatus = await context.run("check-order-status", async () => {
      return await getOrderStatus(orderId);
    });

    if (orderStatus === "not-found") {
      // Stop execution without error
      return;
    }

    // Continue processing if order is valid
    await context.run("process-order", async () => {
      return await processOrder(orderId);
    });
  });
  ```

  ```python Python theme={"system"}
  @serve.post("/conditional-execution")
  async def conditional_execution(context: AsyncWorkflowContext[dict]) -> None:
      data = context.request_payload["data"]

      async def _validate_data():
          return validate_input_data(data)

      # Validate data first
      validation_result = await context.run("validate-data", _validate_data)

      if not validation_result["is_valid"]:
          # Log the validation failure
          async def _log_validation_failure():
              await log_validation_error(validation_result["errors"])

          await context.run("log-validation-failure", _log_validation_failure)

          # Stop execution without error
          return

      # Only execute if validation passes
      async def _process_valid_data():
          return await process_data(data)

      await context.run("process-valid-data", _process_valid_data)
  ```
</CodeGroup>


# Sleep
Source: https://upstash.com/docs/workflow/features/sleep



Upstash Workflow provides a **Sleep** feature that allows you to pause workflow execution for specified durations without consuming compute resources.

This feature enables you to build time-based workflows, implement delays between steps, and create scheduled operations without the limitations of traditional serverless timeouts.

## How Sleep Works

When you use `context.sleep` or `context.sleepUntil` in your workflow, Upstash Workflow automatically pauses execution and schedules the next step to run after the specified delay.
This happens without keeping your serverless function running, making it cost-effective and reliable for long delays.

<Note>
  **Important:** Sleep durations have limits based on your pricing plan:

  * **Free**: Maximum delay of 7 days
  * **Pay-as-you-go**: Maximum delay of 1 year
  * **Fixed pricing**: Custom delays (no limit)
</Note>

## Sleep Methods

Upstash Workflow provides two methods for implementing delays in your workflows:

### 1. context.sleep

Pauses workflow execution for a specified duration relative to the current time.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(async (context) => {
    const { userId } = context.requestPayload;

    // Send welcome email immediately
    await context.run("send-welcome-email", async () => {
      return await sendWelcomeEmail(userId);
    });

    // Wait for 3 days before sending follow-up
    await context.sleep("wait-for-follow-up", "3d");

    // Send follow-up email
    await context.run("send-follow-up-email", async () => {
      return await sendFollowUpEmail(userId);
    });
  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)

  @serve.post("/api/onboarding")
  async def onboarding(context: AsyncWorkflowContext[str]) -> None:
      user_id = context.request_payload["user_id"]
      
      # Send welcome email immediately
      async def _send_welcome_email():
          return await send_welcome_email(user_id)
      
      await context.run("send-welcome-email", _send_welcome_email)
      
      # Wait for 3 days before sending follow-up
      await context.sleep("wait-for-follow-up", "3d")
      
      # Send follow-up email
      async def _send_follow_up_email():
          return await send_follow_up_email(user_id)
      
      await context.run("send-follow-up-email", _send_follow_up_email)
  ```
</CodeGroup>

You can specify durations using human-readable strings:

* `"10s"` = 10 seconds
* `"1m"` = 1 minute
* `"30m"` = 30 minutes
* `"2h"` = 2 hours
* `"1d"` = 1 day
* `"1w"` = 1 week
* `"1mo"` = 1 month
* `"1y"` = 1 year

You can also use numeric values in seconds:

* `60` = 60 seconds (1 minute)
* `3600` = 3600 seconds (1 hour)
* `86400` = 86400 seconds (1 day)

### 2. context.sleepUntil

Pauses workflow execution until a specific timestamp in the future.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(async (context) => {
    const { userId, scheduledTime } = context.requestPayload;

    // Calculate the scheduled time
    const scheduledDate = new Date(scheduledTime);

    // Wait until the scheduled time
    await context.sleepUntil("wait-until-scheduled", scheduledDate);

    // Execute the scheduled task
    await context.run("execute-scheduled-task", async () => {
      return await executeTask(userId);
    });
  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext
  from datetime import datetime

  app = FastAPI()
  serve = Serve(app)

  @serve.post("/api/scheduled-task")
  async def scheduled_task(context: AsyncWorkflowContext[str]) -> None:
      user_id = context.request_payload["user_id"]
      scheduled_time = context.request_payload["scheduled_time"]
      
      # Calculate the scheduled time
      scheduled_date = datetime.fromisoformat(scheduled_time)
      
      # Wait until the scheduled time
      await context.sleep_until("wait-until-scheduled", scheduled_date)
      
      # Execute the scheduled task
      async def _execute_task():
          return await execute_task(user_id)
      
      await context.run("execute-scheduled-task", _execute_task)
  ```
</CodeGroup>

For `context.sleepUntil`, you can use:

* `Date` objects (JavaScript/TypeScript)
* Unix timestamps (Python)
* ISO string dates

<Tip>
  Sleep operations have a precision of approximately 1 second. Very short delays (less than 1 second) may not be exact.
</Tip>

The sleep feature in Upstash Workflow provides a powerful way to create time-based, reliable workflows without the limitations of traditional serverless timeouts.

By leveraging this feature, you can build sophisticated business logic that spans hours, days, or even months while maintaining cost efficiency and reliability.


# Wait
Source: https://upstash.com/docs/workflow/features/wait



You can pause a workflow run with the `waitForEvent` step. An event is uniquely identified by event ID.

The workflow will resume when the matching event is published.

`waitForEvent` supports configurable timeouts to prevent workflows from waiting indefinitely.
When a timeout occurs, the returned object includes `timeout: true`, allowing you to handle the failure case gracefully (for example, cancel an order, notify the user, or retry later).

<Tip>
  If no timeout is specified, the default is **7 days**.
</Tip>

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve<string>(async (context) => {
    const { orderId, userEmail } = context.requestPayload;

    // Wait for order processing completion
    const { eventData, timeout } = await context.waitForEvent(
      "wait-for-order-processing",
      `order-${orderId}`,
      {
        timeout: "1d" // 1 day timeout
      }
    );

    if (timeout) {
      // Handle timeout scenario
      await context.run("handle-timeout", async () => {
        return await handleOrderTimeout(orderId, userEmail);
      });
      return;
    }

  });
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)

  @serve.post("/api/order-processing")
  async def order_processing(context: AsyncWorkflowContext[str]) -> None:
      order_id = context.request_payload["order_id"]
      user_email = context.request_payload["user_email"]

      # Send order processing request
      async def _request_order_processing():
          return await request_order_processing(order_id)

      await context.run("request-order-processing", _request_order_processing)

      # Wait for order processing completion
      result = await context.wait_for_event(
          "wait-for-order-processing",
          f"order-{order_id}",
          timeout="10m"  # 10 minutes timeout
      )

      if result["timeout"]:
          # Handle timeout scenario
          async def _handle_timeout():
              return await handle_order_timeout(order_id, user_email)

          await context.run("handle-timeout", _handle_timeout)
          return

      # Process the completed order
      async def _process_completed_order():
          return await process_completed_order(order_id, result["event_data"])

      await context.run("process-completed-order", _process_completed_order)
  ```
</CodeGroup>


# Overview
Source: https://upstash.com/docs/workflow/features/wait-for-event



Wait for Event feature that allows you to pause workflow execution until an external event occurs.

This feature enables you to build asynchronous workflows that can wait for user interactions, external system responses, or any other events without consuming compute resources.

## How Wait for Event Works

When you use `context.waitForEvent()` in your workflow, Upstash Workflow automatically pauses execution and waits for an external notification to resume.
This happens without keeping your serverless function running, making it cost-effective and reliable for event-driven workflows.

Each waiter has a timeout duration to wait for the event and then fires automatically.

<Note>
  Wait for Event timeouts have limits based on your pricing plan:

  * **Free**: Maximum timeout of 7 days
  * **Pay-as-you-go**: Maximum timeout of 1 year
  * **Fixed pricing**: Custom timeouts (no limit)
</Note>

## Race Condition Between Wait and Notify

A race condition can occur when `notify` is called before `waitForEvent` is executed.
In this scenario, the notification will be sent but no workflow will be waiting to receive it, causing the event to be lost.

To prevent race conditions, always check the response of the `notify` operation.
The `notify` method returns a list of notified waiters.
If this list is empty, it means no workflows were waiting for the event, and you should retry the notification.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<WORKFLOW_TOKEN>" });

  const result = await client.notify({
      eventId,
      eventData
  });

  // Check if any workflows were notified
  if (result.waiters && result.waiters.length > 0) {
      console.log(`Notified ${result.waiters.length} workflows`);
      return result;
  }

  // If no workflows were waiting, wait and retry once
  console.log("No workflows waiting, retrying in 5 seconds...");
  await new Promise(resolve => setTimeout(resolve, 5000));

  return await client.notify({
      eventId,
      eventData
  });
  ```
</CodeGroup>

## Selecting an Event ID

When a workflow run waits on an event ID, it's appended to a list of waiters for the event ID.

When a notify request is sent, all workflow runs waiting for that event are notified sequentially.
To avoid heavy notify operations, it‚Äôs recommended to use unique event IDs instead of generic ones.
For example, instead of waiting on `user-sent-verification`, wait the workflow on `user-{userId}-sent-verification` event.


# Getting Started
Source: https://upstash.com/docs/workflow/getstarted



## Overview

Upstash Workflow lets you write **durable, reliable and performant serverless functions**. Get delivery guarantees, automatic retries on failure, scheduling and more without managing any infrastructure.

<iframe id="intro-video" width="720" height="405" src="https://www.youtube.com/embed/5As9tZMN3a8?rel=0&disablekb=1" title="YouTube video player" frameBorder="0" allow="accelerometer; fullscreen; clipboard-write; encrypted-media; gyroscope" allowFullScreen />

## Quickstarts

Upstash Workflow supports Next.js, Cloudflare Workers and [many other frameworks](/workflow/quickstarts/platforms) in TypeScript and Python.

<CardGroup cols={2}>
  <Card title="Next.js" icon="node-js" href="/workflow/quickstarts/vercel-nextjs">
    Build a Next.js application with QStash Workflow
  </Card>

  <Card title="Cloudflare Workers" icon="cloudflare" href="/workflow/quickstarts/cloudflare-workers">
    Use and deploy Upstash Workflow on Cloudflare Workers
  </Card>

  <Card title="Next.js & FastAPI" icon="python" href="/workflow/quickstarts/nextjs-fastapi">
    Use Upstash Workflow for Python with Next.js and FastAPI
  </Card>
</CardGroup>

## Key Features

<CardGroup cols={2}>
  <Card title="Failure Resilience" icon="shield">
    If your platform experiences a temporary outage, your workflow can pick up right where it left off, ensuring stability even in unstable environments.
  </Card>

  <Card title="Long-Running Executions" icon="clock">
    Run long-running REST endpoints, such as complex AI models or video processing tools, even on serverless platforms with strict time limits.
  </Card>

  <Card title="Events with Wait/Notify Mechanism" icon="bell" href="/workflow/features/wait-for-event">
    Create workflows that wait for external events before proceeding. Ideal for user confirmations and asynchronous notifications.
  </Card>

  <Card title="Scheduled Jobs" icon="calendar" href="/workflow/howto/schedule">
    Run jobs at regular intervals with support for cron expressions. Perfect for recurring tasks like reminders, reports, or newsletters.
  </Card>

  <Card title="Parallel Runs" icon="road" href="/workflow/features/parallel-steps">
    Start independent tasks in parallel and wait for them to finish simultaneously, reducing latency.
  </Card>

  <Card title="Long Delays" icon="hourglass" href="/workflow/basics/context/sleep">
    Need your code to ‚Äúsleep‚Äù for days, weeks, or even months? Supports long delays beyond serverless time limits.
  </Card>

  <Card title="Delivery Guarantees" icon="rotate-right">
    Ensures at-least-once delivery. Failed requests are logged in a Dead Letter Queue to prevent data loss.
  </Card>

  <Card title="Flow Control" icon="gauge" href="/workflow/features/flow-control">
    Prevent overwhelming your app or external services by configuring rate per second or parallelism limits.
  </Card>

  <Card title="Observability" icon="eye" href="/workflow/basics/client/logs">
    Monitor workflow steps with insights. Filter events to track successes, failures, retries, and stalls.
  </Card>
</CardGroup>

## Example Use Cases

Here are some example real world use-cases for Upstash Workflow:

<CardGroup cols={2}>
  <Card title="Agents" icon="robot" href="/workflow/agents/overview">
    Use LLM Agents equipped with custom tools to achieve tasks
  </Card>

  <Card title="AI Data Processing" icon="sparkles" href="/workflow/examples/allInOne">
    Download a large dataset without timeouts, process the data in chunks and generate a report.
  </Card>

  <Card title="Waiting For Events" icon="traffic-light" href="/workflow/examples/waitForEvent">
    Control workflow execution with events, log event data and send emails
  </Card>

  <Card title="Authorization Webhook" icon="webhook" href="/workflow/examples/authWebhook">
    Start a workflow from a webhook. Handle user creation, trial management,
    email reminders and notifications.
  </Card>

  <Card title="Customer Onboarding" icon="user" href="/workflow/examples/customerOnboarding">
    Register a new user, send welcome emails, and periodically check and respond
    to the user's activity state with emails.
  </Card>

  <Card title="E-Commerce Order Fulfillment" icon="cart-flatbed-boxes" href="/workflow/examples/eCommerceOrderFulfillment">
    Receive an order request, verify the stock, process the payment, and handle
    order dispatch and customer notifications.
  </Card>

  <Card title="Image Processing" icon="image" href="/workflow/examples/imageProcessing">
    Manage uploading images to the data store. Apply filters and resize the
    images to different resolutions in parallel.
  </Card>

  <Card title="Retry Payments" icon="credit-card" href="/workflow/examples/paymentRetry">
    Retry payments with a day of delay, send emails, and suspend account if
    payment fails after the retries.
  </Card>
</CardGroup>

## How it works

Upstash Workflow builds on the principle of steps. Instead of defining a single, complex piece of business logic, workflows contain multiple individual steps.

Each of the steps are executed by a separate request to your application, by preserving the output of previous steps.

In case of an error, a failed step is retried individually without needing to re-run any previous steps. Instead of the entire business logic, *each step* can take up your serverless function execution duration, and many more benefits.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=39a2c8c56f92813198d5990df8d8c9c2" data-og-width="1920" width="1920" data-og-height="1080" height="1080" data-path="img/qstash-workflow/workflow-concept.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a90ec1a056cb6ac52a0db3527f19aea4 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2f8c7c37826de4ffcaa0d1ea5c6b5e0e 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a0e38b1b9edb79778a42707eb06e44a2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4ba0d847f0d305e4443cccf89f3b8d3a 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cadcf8674584a37fcf56b5de67715a7a 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow-concept.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3a0bbfd71074f1e7a247dd23aa98764b 2500w" />
</Frame>

## Support

Need help or have questions? We're here to support you:

* Join our Discord community to ask questions and share feedback
* Open a ticket through the Intercom chatbox in the dashboard for any issue


# Cancel a Run
Source: https://upstash.com/docs/workflow/howto/cancel



You can cancel a running workflow both programatically and from your Upstash Workflow console.

## Cancelling via console

In your Upstash Workflow console, find the run you'd like to cancel and press the `Cancel Workflow` button on the right side:

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a0820dd3c265085f703634946cbee23a" data-og-width="2053" width="2053" data-og-height="813" height="813" data-path="img/qstash-workflow/cancel_workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8cc0c9c5fc13f91c7dd9b67256c734e1 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f6374cf1da32a125aa2de5ebeddbef29 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6e920e2c420d79d45625eb929dbb410e 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=90d47092b60c9c3cd8d0c0ab2bfeaf3c 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=287d3da7f8863f96c7ada4784009c609 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/cancel_workflow.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=86f962330aede7242e22bf8fe461df65 2500w" />
</Frame>

## Cancelling programatically

<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

```javascript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });
await client.cancel({ ids: "<WORKFLOW_RUN_ID>" });
```

And replace `<WORKFLOW_RUN_ID>` with your actual run ID. See [the documentation of `client.cancel` method for more information about other ways of canceling workflows](/workflow/basics/client/cancel).

You can also use the [Upstash Workflow REST API](/workflow/rest/runs/cancel) to cancel a run programatically.


# Update a Workflow
Source: https://upstash.com/docs/workflow/howto/changes



Workflows are composed of multiple steps. When you modify workflow code, it's important to consider how these changes might affect in-progress workflows.

## Issues

You cannot change the step order of a existing workflow.

If your code changes remove or reorder existing steps, in-progress workflows may attempt to continue from a point that no longer exists. This can lead to workflow failures, typically resulting in the following error:

```bash  theme={"system"}
HTTP status 400. Incompatible step name. Expected <STEP_NAME>, got <STEP_NAME>
```

## Safe changes

Updating workflow code is safe in the following cases:

* No active workflow runs exist
* Only new steps are added to the end of the workflow

## Guidelines for updating workflows

Consider the following approaches when updating your workflow code:

* **Accept potential failures:** If you're fine with in-progress workflows failing, you can make any code changes.
* **Use a different route:** To avoid failures, consider serving the updated workflow under a different route.
* **Stop traffic before deployment:** If you need to keep the same route, stop all traffic before deploying new code.
* **Add steps only:** If stopping traffic is not an option, limit your changes to adding new steps at the end of the workflow.

For a deeper understanding of these limitations, see our [how workflows work](/workflow/basics/how) section.


# Configure a Run
Source: https://upstash.com/docs/workflow/howto/configure



You can configure a workflow run when starting it. The following are the options you can configure:

1. Retries: The number of retry attempt Upstash Workflow does when a step fails in the workflow run
2. Retry Delay: The delay strategy between retries when Upstash Workflow attempts retries.
3. Flow Control: The rate, period and parallelism that steps should respect and logical grouping key to share with other workflow runs.
4. Failure Function: You can enable or disable failure function execution for the workflow run.

You can pass these configuration options when starting a workflow run:

```typescript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = Client()

const { workflowRunId } = await client.trigger({
    url: `http://localhost:3000/api/workflow`,
    retries: 3,
    retryDelay: "(1 + retries) * 1000",
    flowControl: {
        key: "limit-ads",
        rate: 1,
        parallelism: 10
    },
    useFailureFunction: true,
    keepTriggerConfig: true,
});
```

<Warning>
  You must set `keepTriggerConfig: true` to enable workflow run configuration.
  If this flag is not provided, your configuration will **not be applied** and the workflow will fall back to default values instead.
  This option is disabled by default for backward compatibility.
</Warning>

The workflow run configuration does **not** apply to `context.call()` and `context.invoke()` steps.
These steps accept their own configuration options, allowing fine-grained control over external requests.
If not specified, they fall back to their default values.

For details, see:

* [context.call](/workflow/basics/context/run)
* [context.invoke](/workflow/basics/context/run)

<Tip>
  Upstash Workflow does not support step level configuration. The configuration applies to all steps executed by a workflow run.

  If you want to specifically throttle a step, there is a workaround by splitting step to another workflow and using `context.invoke()`.
</Tip>


# Waiting for Events
Source: https://upstash.com/docs/workflow/howto/events



<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

You can use `context.waitForEvent` to pause a workflow until a specific event occurs and resume it with event data when the event is received.

<Tip>
  You can learn more about Workflow events from [our real-world
  example](/workflow/examples/waitForEvent).
</Tip>

## `context.waitForEvent`

The [`waitForEvent` method](/workflow/basics/context#context-waitforevent) pauses the execution of a workflow and waits for an external event to occur, identified by an event ID. This is particularly useful in asynchronous workflows that rely on external systems to provide data or signals.

```typescript  theme={"system"}
const { eventData, timeout } = await context.waitForEvent(
  "description of event",
  "event-id",
  {
    timeout: timeoutInSeconds,
  }
);
```

Third parameter is the timeout. It is the maximum time (in seconds) to wait for the event. If the event doesn't occur within this time, the workflow will proceed, and the `timeout` variable will be `true`.

Maximum timeout value is equal to [the "Max Delay" value of your QStash plan](https://upstash.com/pricing/workflow). It's 7 days for free users, 1 year for pay as you go users and unlimited for pro users.

## `client.notify`

[The `notify` method](/workflow/basics/client#notify-waiting-workflow) is used to notify a workflow that the expected event has occurred. It notifies all workflows waiting for the given `eventId` and provides the `eventData` to the waiting workflows, allowing them to resume execution.

```typescript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });

await client.notify({
  eventId: "event-id",
  eventData: { my: "data" },
});
```

`eventData` provided in `client.notify` will be available in the result of `context.waitForEvent` as it is.

## `context.notify`

You can also notify workflows in another workflow using [the `context.notify` method](/workflow/basics/context#context-notify).

```typescript  theme={"system"}
const { notifyResponse } = await context.notify(
  "notify step", // notify step name
  "event-Id", // event id
  { my: "data" } // event data
);

```


# Handle Failed Runs
Source: https://upstash.com/docs/workflow/howto/failures



This guide shows you how to **gracefully handle failed workflow runs**. This involves best practices on resolving runtime errors, logging and manually retrying runs that have failed multiple times.

## Why a workflow might fail

* A step in your workflow throws a database error that causes your code to fail at runtime.
* QStash calls your workflow URL, but the URL is not reachable - for example, because of a temporary outage of your deployment platform.
* A single step takes longer than your platform's function execution limit.

Workflow automatically retries a failed step based on your configuration (by default, it retries three times with exponential backoff).
This helps handle temporary outages or intermittent failures gracefully.

<Frame caption="A failed step is automatically retried three times">
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a6e70c331aaeb93e69c4730b5612c5e3" data-og-width="1198" width="1198" data-og-height="471" height="471" data-path="img/qstash-workflow/automatic_retry.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=deedaed474046368529e85cab0f124f3 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a8d354ea2e5facf66720bbc95140c2c4 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=acbdf86e85d73adc96bec84b9bef29b8 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b86adce5e106f66ba9d5a5b52be93e6f 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3961deabd5aa732b45166b7f5d729f4e 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/automatic_retry.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=ddb802d0fe619c53874ac52b27083bd9 2500w" />
</Frame>

If, even after all retries, your step does not succeed, we'll move the failed run into your [Dead Letter Queue (DLQ)](/qstash/howto/handling-failures#dead-letter-queue). That way, you can always manually retry it again and debug the issue.

<Frame caption="Manually retry from the Dead-Letter-Queue (DLQ)">
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=46470f382d7c44801bec8757ee8390a9" data-og-width="1541" width="1541" data-og-height="899" height="899" data-path="img/qstash-workflow/workflow_dlq.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=dc895fe3ea5fd8ef9f72638f25b7cbb7 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0387c9567506dab72f8ed6960c64367c 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d6ab8e123ed244dd1326d4db154b3b9f 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b28f0d262153b581132fa2ba2fa087fd 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8bd9e0d46eae935b3c5439a5b86534e6 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f15a0f8cf14b0169bb1e0f4fc949af62 2500w" />
</Frame>

If you want to take an action (a cleanup/log), you can configure either `failureFunction` or a `failureUrl` on the `serve` method of your workflow.
These options allow you to define custom logic or an external endpoint that will be triggered when a failure occurs.

## Using a `failureFunction` (recommended)

The `serve` function you use to create a workflow endpoint accepts a `failureFunction` parameter - an easy way to gracefully handle errors (i.e. logging them to Sentry) or your custom handling logic.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  export const { POST } = serve<string>(
    async (context) => {
      // Your workflow logic...
    },
    {
      failureFunction: async ({
        context,
        failStatus,
        failResponse,
        failHeaders,
      }) => {
        // Handle error, i.e. log to Sentry
        console.error("Workflow failed:", failResponse);
        
        // You can optionally return a string that will be visible
        // in the UI (coming soon) and in workflow logs
        return `Workflow failed with status ${failStatus}: ${failResponse}`;
      },
    }
  );
  ```

  ```python Python theme={"system"}
  async def failure_function(
      context,       # context during failure
      fail_status,   # failure status
      fail_response, # failure message
      fail_headers   # failure headers
  ):
      # handle the failure
      pass

  @serve.post("/api/example", failure_function=failure_function)
  async def example(context: AsyncWorkflowContext[str]) -> None: ...
  ```
</CodeGroup>

Note: If you use a custom authorization method to secure your workflow endpoint, add authorization to the `failureFunction` too. Otherwise, anyone can invoke your failure function. Read more here: [securing your workflow endpoint](/workflow/howto/security).

In `@upstash/workflow`, the `failureFunction` can optionally return a string value that will be displayed in the UI (coming soon) and included in the workflow logs. This is useful for providing custom error messages, debugging information, or tracking specific failure conditions.

## Using a `failureUrl`

Instead of using the built-in failure function, you can define a separate failure callback URL.
Unlike the failure function, which only works when your application is running, the failure URL allows you to handle errors even if your application is completely down.
If the URL is a different service other than your application, it will be reachable in these cases.

By pointing the failure URL to an external service (not hosted within your main application), you ensure that it remains accessible even when your primary app is unavailable.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  export const { POST } = serve<string>(
    async (context) => {
      // Your workflow logic...
    },
    {
      failureUrl: "https://<YOUR_FAILURE_URL>/workflow-failure",
    }
  );
  ```

  ```python Python theme={"system"}
  @serve.post("/api/example", failureUrl="https://<YOUR-FAILURE-ENDPOINT>/...")
  async def example(context: AsyncWorkflowContext[str]) -> None: ...
  ```
</CodeGroup>

The callback body sent to you will be a JSON object with the following fields:

```javascript JavaScript theme={"system"}
{
  "status": 200,
  "header": { "key": ["value"] },         // Response header
  "body": "YmFzZTY0IGVuY29kZWQgcm9keQ==", // base64 encoded response body
  "retried": 2,                           // How many times we retried to deliver the original message
  "maxRetries": 3,                        // Number of retries before the message assumed to be failed to delivered.
  "sourceMessageId": "msg_xxx",           // The ID of the message that triggered the callback
  "topicName": "myTopic",                 // The name of the URL Group (topic) if the request was part of a URL Group
  "endpointName": "myEndpoint",           // The endpoint name if the endpoint is given a name within a topic
  "url": "http://myurl.com",              // The destination url of the message that triggered the callback
  "method": "GET",                        // The http method of the message that triggered the callback
  "sourceHeader": { "key": "value" },     // The http header of the message that triggered the callback
  "sourceBody": "YmFzZTY0kZWQgcm9keQ==",  // The base64 encoded body of the message that triggered the callback
  "notBefore": "1701198458025",           // The unix timestamp of the message that triggered the callback is/will be delivered in milliseconds
  "createdAt": "1701198447054",           // The unix timestamp of the message that triggered the callback is created in milliseconds
  "scheduleId": "scd_xxx",                // The scheduleId of the message if the message is triggered by a schedule
  "callerIP": "178.247.74.179"            // The IP address where the message that triggered the callback is published from
}
```

In Next.js you can use the following code to handle the callback:

```javascript JavaScript theme={"system"}
// pages/api/callback.js

import { verifySignature } from "@upstash/qstash/nextjs";

function handler(req, res) {
  // responses from qstash are base64-encoded
  const decoded = atob(req.body.body);
  console.log(decoded);

  return res.status(200).end();
}

export default verifySignature(handler);

export const config = {
  api: {
    bodyParser: false,
  },
};
```

`verifySignature` allows to verify the signature of request, which is signed by Upstash using your signing keys.
If you don't want to verify the signature, you can remove `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` environment variables and remove `verifySignature` function.

## Manually Handling Failed Workflow Runs

When a workflow run fails and is moved to the Dead Letter Queue (DLQ), you have several options to handle it manually via the REST API:

### [Resume](/workflow/rest/dlq/resume)

* **What it does:** Continues a failed workflow run from exactly where it failed, preserving all successful step results.
* **When to use:** Use this if you want to retry only the failed/pending steps without re-executing the entire workflow.

### [Restart](/workflow/rest/dlq/restart)

* **What it does:** Starts the failed workflow run over from the beginning, discarding all previous step results.
* **When to use:** Use this if you want a clean execution, or if the failure may have been caused by a corrupted state that requires a fresh start.

### [Callback](/workflow/rest/dlq/callback)

* **What it does:** Reruns the failure callback for a workflow run, in case the original failure callback was not delivered or failed.
* **When to use:** Use this to ensure your system is notified of workflow failures, even if the original callback attempt did not succeed.

## Debugging failed runs

In your DLQ, filter messages via the `Workflow URL` or `Workflow Run ID` to search for a particular failure. We include all request and response headers and bodies to simplify debugging failed runs.

For example, let's debug the following failed run. Judging by the status code `404`, the `Ngrok-Error-Code` header of `ERR_NGROK_3200` and the returned HTML body, we know that the URL our workflow called does not exist.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4d3c3009eb90cb6ed35ef85e6dc19c85" data-og-width="1305" width="1305" data-og-height="624" height="624" data-path="img/qstash-workflow/workflow_dlq_debug.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cfb8c6376847301855e35c620dc19254 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=483ed2d0c6dd13b1d4abaf0f41b0a6cd 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=da3e585be2c206da2c66f4247039c5d5 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4790c24d528967c861d21b5e73916df4 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b7b6dd9b5def6ce1b34d32be963fc211 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workflow_dlq_debug.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=00c613a08a1c545af40aa85ffca31feb 2500w" />
</Frame>


# null
Source: https://upstash.com/docs/workflow/howto/flow-control





# Development Server
Source: https://upstash.com/docs/workflow/howto/local-development/development-server



Upstash Workflow is built on top of Upstash QStash.
The QStash CLI provides a local development server that performs QStash functionality locally for development and testing purposes.

<Steps>
  <Step title="Install and Start Development Server">
    Start the development server using the QStash CLI:

    ```javascript  theme={"system"}
    npx @upstash/qstash-cli dev
    ```

    The QStash CLI output will look something like this:

    ```plaintext QStash CLI Output theme={"system"}
    Upstash QStash development server is runnning at

    A default user has been created for you to authorize your requests.
    QSTASH_TOKEN=eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0=
    QSTASH_CURRENT_SIGNING_KEY=sig_7RvLjqfZBvP5KEUimQCE1pvpLuou
    QSTASH_NEXT_SIGNING_KEY=sig_7W3ZNbfKWk5NWwEs3U4ixuQ7fxwE

    Sample cURL request:
    curl -X POST http://127.0.0.1:8080/v2/publish/https://example.com -H "Authorization: Bearer eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0="

    Check out documentation for more details:
    https://upstash.com/docs/qstash/howto/local-development
    ```

    For detailed instructions on setting up the development server, see our [QStash Local Development Guide](/qstash/howto/local-development).
  </Step>

  <Step title="Enable Local Mode on Console">
    Once you start the local server, you can go to the Workflow tab on Upstash Console and enable local mode, which will allow you to monitor and debug workflow runs with the local server.

    <img src="https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=a2d6c7bd6c94fc93185aa45b57f5edfb" data-og-width="1210" width="1210" data-og-height="604" height="604" data-path="img/workflow/local-mode-workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=280&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=d9daf6c1bb467a2a465ea1982966a894 280w, https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=560&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=e9afd21ebc5c3647450e33dc4cb2a415 560w, https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=840&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=5cbd4227495ac09bca6110dd6ca4bda8 840w, https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=1100&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=c29dfcfe63bf66f035c9920970c5dba6 1100w, https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=1650&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=1dc3832b0c4b7f7f581dbeba0a9689a7 1650w, https://mintcdn.com/upstash/4dTuKpm1gmYgMWQj/img/workflow/local-mode-workflow.png?w=2500&fit=max&auto=format&n=4dTuKpm1gmYgMWQj&q=85&s=214bc906830095012847bc0b05834134 2500w" />
  </Step>

  <Step title="Update Environment Variables">
    Once your development server is running, update your environment variables to route QStash requests to your local server.

    ```env  theme={"system"}
    QSTASH_URL="http://127.0.0.1:8080"
    QSTASH_TOKEN="eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0="
    QSTASH_CURRENT_SIGNING_KEY="sig_7RvLjqfZBvP5KEUimQCE1pvpLuou"
    QSTASH_NEXT_SIGNING_KEY="sig_7W3ZNbfKWk5NWwEs3U4ixuQ7fxwE"
    ```
  </Step>

  <Step title="Use local addresses">
    It's all set up üéâ

    Now, you can use your local address when triggering the workflow runs.

    ```javascript  theme={"system"}
    import { Client } from "@upstash/workflow";

    const client = Client()

    const { workflowRunId } = await client.trigger({
        url: `http://localhost:3000/api/workflow`,
        retries: 3,
        keepTriggerConfig: true,
    });
    ```

    <Tip>
      Inside the `trigger()` call, you need to provide the URL of your workflow endpoint:

      * Local development ‚Üí use the URL where your app is running, for example: [http://localhost:3000/api/PATH](http://localhost:3000/api/PATH)
      * Production ‚Üí use the URL of your deployed app, for example: [https://yourapp.com/api/PATH](https://yourapp.com/api/PATH)

      To avoid hardcoding URLs, you can define a `BASE_URL` constant and set it based on the environment.
      A common pattern is to check an environment variable that only exists in production:

      ```javascript  theme={"system"}
      const BASE_URL = process.env.VERCEL_URL
        ? `https://${process.env.VERCEL_URL}`
        : `http://localhost:3000`

      const { workflowRunId } = await client.trigger({
          url: `${BASE_URL}/api/workflow`,
          retries: 3,
          keepTriggerConfig: true,
      });
      ```
    </Tip>
  </Step>
</Steps>


# Local Tunnel
Source: https://upstash.com/docs/workflow/howto/local-development/local-tunnel



Upstash Workflow requires your application to be publicly accessible in production.
The recommended approach is running the development server we provide locally and work with local addresses.
An alternative is to making your application publibly accessible so that you can work with the managed Upstash Workflow servers.

The easiest way to make a local URL publically available is [ngrok](https://ngrok.com), a free tunneling service.

Create an account on [dashboard.ngrok.com/signup](https://dashboard.ngrok.com/signup) and follow the [setup instructions](https://dashboard.ngrok.com/get-started/setup) to download the ngrok CLI and connect your account. This process takes only a few minutes and is totally free.

You can connect your account like this:

<Tabs>
  <Tab title="macOS">
    <Frame>
      <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b97dd2ce9a636055d0fb70f7b84b5bf1" data-og-width="1260" width="1260" data-og-height="693" height="693" data-path="img/qstash-workflow/ngrok_mac_setup.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3df753a45601667ae89c8658d3c48253 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=766620735f6509619dd325093044e6ed 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fcf3a57b8a88fc786855e54e9e1a253e 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d088accb952cab4e7fe961b130e1132c 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=817261037ab60ebd44f90b8fadfb041c 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_mac_setup.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c4de622057b2c6a4679a3f560b332cc6 2500w" />
    </Frame>
  </Tab>

  <Tab title="Windows">
    <Frame>
      <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=757344c0a66d7d545bc423d323d9345c" data-og-width="1260" width="1260" data-og-height="693" height="693" data-path="img/qstash-workflow/ngrok_windows_setup.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1286eb457ab23c519f1c41fd43151c88 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8c3be6746de77bdc207a57d165990706 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8f3927b79c7268496c02b7c1d2935abc 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b437d1540af03f06881153f4c6fe58da 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=a5c51508451cf37c0015bb1f59e04dbd 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/ngrok_windows_setup.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=987842abc4a3e7b94841882db40078b4 2500w" />
    </Frame>
  </Tab>
</Tabs>

Once you have installed the ngrok CLI, add your ngrok-issued auth token like this:

```bash Terminal theme={"system"}
ngrok config add-authtoken <YOUR-AUTH-TOKEN>
```

and replace `<YOUR-AUTH-TOKEN>` with your actual auth token.

### Start the tunnel

Make your local server available publically by running the following command:

```bash  theme={"system"}
ngrok http <PORT>
```

for example, if your Next.js server is running on port `3000`, the command is:

```bash  theme={"system"}
ngrok http 3000
```

The output will look something like this:

```plaintext  theme={"system"}
Session Status                online
Account                       <YOUR-NAME> (Plan: Free)
Version                       3.1.0
Region                        Europe (eu)
Latency                       -
Web Interface                 http://127.0.0.1:4040
Forwarding                    https://e02f-2a02-810d-af40-5284-b139-58cc-89df-b740.eu.ngrok.io -> http://localhost:3000
Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00
```

The long URL in the `Forwarding` line serves the same purpose as your localhost URL, the only difference being that it is publically accessible. We need this URL to make our workflow available to QStash for local development, either as the `baseUrl` parameter or the `UPSTASH_WORKFLOW_URL` environment variable (both options provide the same functionality).

Note: The `UPSTASH_WORKFLOW_URL` environment variable is only necessary for local development. In production, the `baseUrl` parameter is automatically set and can be omitted.

<Tip>
  Ensure that the port of your local server matches the one you're using with ngrok. For example, if your server is
  running on port 8080, use `ngrok http 8080`.
</Tip>


# Logging in Workflow
Source: https://upstash.com/docs/workflow/howto/logging



das


# Parallel Runs
Source: https://upstash.com/docs/workflow/howto/parallel-runs



<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

Just like you can execute multiple JavaScript promises at the same time using `Promise.all`, you can run multiple workflow steps at the same time:

```typescript  theme={"system"}
const [result1, result2, result3] =
  await Promise.all([
    ctx.run("parallel-step-1", async () => { ... }),
    ctx.run("parallel-step-2", async () => { ... }),
    ctx.run("parallel-step-3", async () => { ... }),
  ])
```

In a complete code example, your workflow could look like this:

```typescript app/api/workflow/route.ts theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { checkInventory, brewCoffee, printReceipt } from "@/utils";

export const { POST } = serve(async (ctx) => {
  const [coffeeBeansAvailable, cupsAvailable, milkAvailable] =
    await Promise.all([
      ctx.run("check-coffee-beans", () => checkInventory("coffee-beans")),
      ctx.run("check-cups", () => checkInventory("cups")),
      ctx.run("check-milk", () => checkInventory("milk")),
    ]);

  // If all ingedients available, brew coffee
  if (coffeeBeansAvailable && cupsAvailable && milkAvailable) {
    const price = await ctx.run("brew-coffee", async () => {
      return await brewCoffee({ style: "cappuccino" });
    });

    await printReceipt(price);
  }
});
```

After running your workflow, your dashboard shows each step in detail:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8a90ffc27d343e665833d4c497d1dd9d" data-og-width="1266" width="1266" data-og-height="627" height="627" data-path="img/qstash/parallel-workflow-runs.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=014537ac125a65f39fd1e5ab5a433e0e 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=96a6d41f1515536892a665c6a5e2561c 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=ff46f39f06c97e387370813e65f503bb 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=dd1533e3e27e87fb0b26629690fa6284 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=2fb6bb8d641837bb2584bc894cb6dbfe 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash/parallel-workflow-runs.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=47c72c728b956366d79989f9f0a2ebff 2500w" />
</Frame>


# Schedule a Workflow
Source: https://upstash.com/docs/workflow/howto/schedule



You can schedule a workflow to run periodically using a cron definition.

For this feature, you would need to use Upstash QStash's Schedules feature.

## Scheduling a workflow

For example, let's suppose that you have a workflow that creates a backup of some important data daily. Our workflow endpoint might look like this:

To run this endpoint on a schedule, navigate to `Schedules` in your QStash dashboard and click `Create Schedule`:

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6d93a7f91194bb013c613851db9e61cc" data-og-width="1530" width="1530" data-og-height="966" height="966" data-path="img/qstash-workflow/create_schedule.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=20784884de574336a15e7d418e0fc98a 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d5e5d841b361464f7bcedfbb6a392ad8 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4100cc81590f13296aaea95467ee5062 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8bf11d6cb765329928c561e09bda95f5 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0569a12089d58337dfc537018dc11d21 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/create_schedule.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=94a307e3eda756d3832c4502f6447a7b 2500w" />
</Frame>

Enter your live endpoint URL, add a CRON expression to define the interval at which your endpoint is called (i.e. every day, every 15 minutes, ...) and click `Schedule`:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=00802afbcc6a04e305cc95de995684fb" data-og-width="1285" width="1285" data-og-height="679" height="679" data-path="img/qstash-workflow/schedule_workflow.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=645c89f282743a30adeefd8a6a170d16 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f94c72be12071cdf6f8997433294c99f 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3cb250be15eea6a10c447a58f79ab77b 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f9cd84255e31bd3acfe7a3ee1a386f1e 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9576c03397775a4c93330905aa2d7dbd 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/schedule_workflow.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=06e7b0fa0e0a8fa9ed103c335024e5e4 2500w" />
</Frame>

Your workflow will now run repeatedly at the interval you have defined. For more details on CRON expressions, see our [QStash scheduling documentation](/qstash/features/schedules).

## Programmatically Schedule

In order to massively improve the user experience, many applications send weekly summary reports to their users. These could be weekly analytics summaries or SEO statistics to keep users engaged with the platform.

Let's create a user-specific schedule, sending a first report to each user exactly 7 days after they signed up:

<CodeGroup>
  ```typescript api/sign-up/route.ts theme={"system"}
  import { signUp } from "@/utils/auth-utils";
  import { Client } from "@upstash/qstash";

  const client = new Client({ token: process.env.QSTASH_TOKEN! });

  export async function POST(request: Request) {
    const userData: UserData = await request.json();

    // Schedule weekly account summary
    await client.schedules.create({
      scheduleId: `user-summary-${user.email}`,
      destination: "https://<YOUR_APP_URL>/api/send-weekly-summary",
      body: { userId: user.id },
      cron: cron,
    });

    return NextResponse.json(
      { success: true, message: "User registered and summary scheduled" },
      { status: 201 }
    );
  }
  ```

  ```python main.py theme={"system"}
  from fastapi import FastAPI, Request
  from fastapi.responses import JSONResponse
  from qstash import AsyncQStash
  from datetime import datetime, timedelta

  app = FastAPI()

  client = AsyncQStash("<QSTACK_TOKEN>")


  @app.post("/api/sign-up")
  async def sign_up(request: Request):
      user_data = await request.json()

      # Simulate user registration
      user = await sign_up(user_data)

      # Calculate the date for the first summary (7 days from now)
      first_summary_date = datetime.now() + timedelta(days=7)

      # Create cron expression for weekly summaries starting 7 days from signup
      cron = f"{first_summary_date.minute} {first_summary_date.hour} * * {first_summary_date.day}"

      # Schedule weekly account summary
      await client.schedule.create_json(
          schedule_id=f"user-summary-{user.email}",
          destination="https://<YOUR_APP_URL>/api/send-weekly-summary",
          body={"userId": user.id},
          cron=cron,
      )

      return JSONResponse(
          content={"success": True, "message": "User registered and summary scheduled"},
          status_code=201,
      )

  ```
</CodeGroup>

This code will call our workflow every week, starting exactly seven days after a user signs up. Each call to our workflow will contain the respective user's ID.

<Note>
  When creating a per-user schedule, pass a unique `scheduleId` to identify the schedule for better management and observability.
</Note>


# Secure a Workflow
Source: https://upstash.com/docs/workflow/howto/security



To prevent unauthorized access to your workflow endpoint, you can add an authorization layer.
Upstash Workflow supports two approaches:

* **Built-in request verification** (recommended)
* **Custom authorization method**

### Built-in request verification (recommended)

Upstash Workflow provides a built-in mechanism to secure your workflow endpoint by verifying request signatures.
Every request to your endpoint include a valid `Upstash-Signature` header.

How it works:

1. Upstash Workflow automatically adds the `Upstash-Signature` header to every request.
   This signature is generated using your signing keys.

2. When this mechanism is enabled, the SDK verifies that the signature is valid before processing the request.

This ensures that only requests originating from Upstash Workflow are processed.

To enable this verification, set the following environment variables in your application:

```bash .env theme={"system"}
QSTASH_CURRENT_SIGNING_KEY=xxxxxxxxx
QSTASH_NEXT_SIGNING_KEY=xxxxxxxxx
```

You can find the values in Upstash Workflow dashboard.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=80587de8e955411f9c092d3348056af3" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_signing_keys.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9aff13ae1e92d8e869d002ed08a9da07 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=796060edf979b7ce1e6710b9a4cdf78b 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=185f283f737442f131d8f3de95f88cc8 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=773c19bc5a6f25f3fa5f3616c7f7919f 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=cf56a1e230831d2bfdd539d8118df910 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_signing_keys.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e42354e5503790f53e952804d7ca0ead 2500w" />
</Frame>

<Info>
  For edge cases where environment variables cannot be used, you can explicitly create and pass a `Receiver` object to verify request signatures:

  <CodeGroup>
    ```typescript TypeScript theme={"system"}
    import { Receiver } from "@upstash/qstash";
    import { serve } from "@upstash/workflow/nextjs";

    export const { POST } = serve(
      async (context) => { ... },
      {
        receiver: new Receiver({
          currentSigningKey: "<QSTASH_CURRENT_SIGNING_KEY>",
          nextSigningKey: "<QSTASH_NEXT_SIGNING_KEY>",
        }),
      }
    );
    ```

    ```python Python theme={"system"}
    from qstash import Receiver

    @serve.post(
        "/api/example",
        receiver=Receiver(
            current_signing_key=os.environ["QSTASH_CURRENT_SIGNING_KEY"],
            next_signing_key=os.environ["QSTASH_NEXT_SIGNING_KEY"],
        ),
    )
    async def example(context: AsyncWorkflowContext[str]) -> None:
        ...

    ```
  </CodeGroup>
</Info>

## Custom Authorization Method

You can implement your own authorization mechanism with Upstash Workflow.

The context object provides access to the initial request headers and payload on every workflow step.
You can use them to pass your custom authentication token to verify the requests.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(
    async (context) => {
      // üëá Extract Bearer token form the request headers
      const authHeader = context.headers.get("authorization");
      const bearerToken = authHeader?.split(" ")[1];

      // üëá Use your authentication function to verify the token
      if (!isValid(bearerToken)) {
        console.error("Authentication failed.");
        return;
      }

      // Your workflow steps..
    },
    {
      failureFunction: async () => {
        // üëá Same auth check for failure function
        const authHeader = context.headers.get("authorization");
        const bearerToken = authHeader?.split(" ")[1];

        if (!isValid(bearerToken)) {
          // ...
        }
      },
    }
  );
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      auth_header = context.headers.get("authorization")
      bearer_token = auth_header.split(" ")[1] if auth_header else None

      if not is_valid(bearer_token):
          print("Authentication failed.")
          return

      # Your workflow steps...

  ```
</CodeGroup>

<Warning>
  If you implement custom authorization in your workflow route, you should also include the same authorization check in the failure function.

  The failure function executes independently of the route function, so without this check, unauthorized requests could trigger the failure function
</Warning>


# Start a Run
Source: https://upstash.com/docs/workflow/howto/start



You‚Äôve defined your workflow, and the final step is to trigger the endpoint!

There are two main ways to start your workflow:

### Using `client.trigger` (Recommended)

We recommend using [`client.trigger`](/workflow/basics/client/trigger) to start your workflow.

<CodeGroup>
  ```ts Single Workflow theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })
  const { workflowRunId } = await client.trigger({
    url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
    body: "hello there!",         // optional body
    headers: { ... },             // optional headers
    workflowRunId: "my-workflow", // optional workflow run id
    retries: 3                    // optional retries in the initial request
    delay: "10s"                  // optional delay value
    failureUrl: "https://<YOUR_FAILURE_URL>", // optional failure url
    useFailureFunction: true,     // whether a failure function is defined in the endpoint
    flowControl: { ... }          // optional flow control
    keepTriggerConfig: true,      // whether to keep the trigger config in all steps
  })

  console.log(workflowRunId)
  // prints wfr_my-workflow
  ```

  ```ts Multiple Workflows theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })
  const results = await client.trigger([
    {
      url: "<YOUR_WORKFLOW_ENDPOINT>",
      // other options...
    },
    {
      url: "<YOUR_WORKFLOW_ENDPOINT>",
      // other options...
    },
  ])

  console.log(results[0].workflowRunId)
  // prints wfr_my-workflow
  ```
</CodeGroup>

### 2. Sending an HTTP Request

This approach is recommended for quick testing via curl during development.

You should **NOT** start the workflow run in production by direct calls to your endpoint.

```bash  theme={"system"}
curl -X POST https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE> \
   -H "my-header: foo" \
   -d '{"foo": "bar"}'
```

<Warning>
  If you‚Äôve secured your endpoint with signing keys, only the `trigger` method will work. Direct calls to the endpoint (e.g., via `curl` or `fetch`) will not be possible since `Upstash-Signature` header is missing.

  For more information, read [Secure a workflow](/workflow/howto/security) documentation.
</Warning>


# Webhooks
Source: https://upstash.com/docs/workflow/howto/use-webhooks



This guide explains how to handle webhooks effectively in your Upstash Workflow applications. We'll walk through:

* setting up webhook endpoints
* verifying webhook requests
* and processing webhook events

<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/nextjs-webhook-stripe" horizontal>
  You can find the project source code on GitHub.
</Card>

## Overview

Webhooks allow external services to notify your application when events occur. For example, you can use webhooks to receive notifications when a new order is placed in your e-commerce store, a new user signs up, or a new message is sent in your chat application.

Upstash Workflow provides a simple way to receive these events and trigger workflows based on the incoming data autonomously.

### Setting Up Webhook Endpoints

#### Basic Setup

To create a webhook endpoint, use the `serve` function from `@upstash/workflow`:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow/nextjs";

  export const { POST } = serve(
    async (context) => {
      // Your webhook handling logic here
    },
    {
      initialPayloadParser: (payload) => {
        return payload;
      },
    }
  );
  ```

  ```python Python theme={"system"}
  from fastapi import FastAPI
  from upstash_workflow.fastapi import Serve
  from upstash_workflow import AsyncWorkflowContext

  app = FastAPI()
  serve = Serve(app)


  def initial_payload_parser(payload):
      return payload


  @serve.post("/api/example", initial_payload_parser=initial_payload_parser)
  async def example(context: AsyncWorkflowContext[str]) -> None:
      # Your webhook handling logic here

  ```
</CodeGroup>

#### Request Validation

Always validate incoming webhook requests to ensure they're legitimate. This way, no one other than the original webhook source can trigger your workflow. Here's an example using Clerk webhooks with Svix:

<CodeGroup>
  ```typescript Validate and Parse in Workflow - TypeScript theme={"system"}
  export const { POST } = serve<string>(async (context) => {
  	const payloadString = context.requestPayload;
  	const headerPayload = context.headers;

      let event: WebhookEvent;
      try {
      	event = await validateRequest(payloadString, headerPayload);
      } catch {
      	return
      }

      // Next steps based on the event

  })

  ```

  ```python Validate and Parse in Workflow - Python theme={"system"}
  async def validate_request(payload_string: str, header_payload: dict):
      # Validate the request
      pass


  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      payload_string = context.request_payload
      header_payload = context.headers

      try:
          event = await validate_request(payload_string, header_payload)
      except:
          return

      # Next steps based on the event

  ```

  ```typescript Validation Function - TypeScript theme={"system"}
  import { Webhook } from "svix";
  import { WebhookEvent } from "@clerk/nextjs/server";

  const webhookSecret = "YOUR_WEBHOOK_SECRET";

  async function validateRequest(payloadString: string, headerPayload: Headers) {
    const svixHeaders = {
      "svix-id": headerPayload.get("svix-id") as string,
      "svix-timestamp": headerPayload.get("svix-timestamp") as string,
      "svix-signature": headerPayload.get("svix-signature") as string,
    };
    const wh = new Webhook(webhookSecret);
    return wh.verify(payloadString, svixHeaders) as WebhookEvent;
  }
  ```
</CodeGroup>

### Handling Webhook events

Use the context.run method to process webhook events in discrete, trackable steps:

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  export const { POST } = serve(async (context) => {
    // ... Parse and validate the incoming request

    const user = await context.run<false | UserPayload>(
      "handle-webhook-event",
      async () => {
        if (event.type === "user.created") {
          const { id: clerkUserId, email_addresses, first_name } = event.data;
          const primaryEmail = email_addresses.find(
            (email) => (email.id = event.data.primary_email_address_id)
          );

          if (!primaryEmail) {
            return false;
          }

          return {
            event: event.type,
            userId: clerkUserId,
            email: primaryEmail.email_address,
            firstName: first_name,
          } as UserPayload;
        }
        return false;
      }
    );
  });
  ```

  ```python Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      # ... Parse and validate the incoming request

      async def _handle_webhook_event():
          if event.type == "user.created":
              clerk_user_id = event.data["id"]
              email_addresses = event.data["email_addresses"]
              first_name = event.data["first_name"]

              primary_email = next(
                  (
                      email
                      for email in email_addresses
                      if email.id == event.data["primary_email_address_id"]
                  ),
                  None,
              )

              if not primary_email:
                  return False

              return {
                  "event": event.type,
                  "user_id": clerk_user_id,
                  "email": primary_email["email_address"],
                  "first_name": first_name,
              }

          return False

      user = await context.run("handle-webhook-event", _handle_webhook_event)

  ```
</CodeGroup>

After validating the webhook and extracting the initial user data, you'll often need to perform additional operations like creating customer records, sending welcome emails etc.

<CodeGroup>
  ```typescript TypeScript theme={"system"}
  export const { POST } = serve(async (context) => {
    // ... Previous validation and user data extraction

    if (!user) {
      return;
    }

    const customer = await context.run("create-stripe-customer", async () => {
      return await stripe.customers.create({
        email: user.email,
        name: `${user.firstName} ${user.lastName}`,
        metadata: {
          userId: user.userId,
        },
      });
    });

    /// ... Additional steps
  });
  ```

  ```python Python theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      # ... Previous validation and user data extraction

      if not user:
          return

      async def _create_stripe_customer():
          return await stripe.customers.create(
              email=user["email"],
              name=f"{user['first_name']} {user['last_name']}",
              metadata={"user_id": user["user_id"]},
          )

      customer = await context.run("create-stripe-customer", _create_stripe_customer)

      # ... Additional steps

  ```
</CodeGroup>

You're now ready to perform any operation in the following steps.


# Vercel AI SDK
Source: https://upstash.com/docs/workflow/integrations/aisdk



<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/blob/main/examples/nextjs/app/vercel-ai-sdk/route.ts" horizontal>
  You can find the project source code which uses real APIs on Github.
</Card>

Upstash Workflow integrates with the Vercel AI SDK to provide durable and reliable AI applications. This allows you to:

* Build resilient AI applications with automatic retries
* Manage AI operations with workflow steps
* Implement tools and function calling with durability
* Handle errors gracefully across your AI operations
* Handle long-running AI operations with extended timeouts

This guide will walk you through setting up and implementing AI features using Upstash Workflow's durability guarantees with Vercel AI SDK's capabilities.

## Prerequisites

Before getting started, make sure you have:

* An OpenAI API key
* Basic familiarity with Upstash Workflow and Vercel AI SDK
* Vercel AI SDK version 4.0.12 or higher (required for ToolExecutionError handling)

## Installation

Install the required packages:

<CodeGroup>
  ```bash npm theme={"system"}
  npm install @ai-sdk/openai ai zod
  ```

  ```bash pnpm theme={"system"}
  pnpm install @ai-sdk/openai ai zod
  ```

  ```bash bun theme={"system"}
  bun install @ai-sdk/openai ai zod
  ```
</CodeGroup>

## Implementation

### Creating OpenAI client

AI SDKs (Vercel AI SDK, OpenAI SDK etc.) uses the client's default fetch implementation to make API requests, but allows you to provide a custom fetch implementation.

In the case of Upstash Workflow, we need to use the `context.call` method to make HTTP requests. We can create a custom fetch implementation that uses `context.call` to make requests. By using `context.call`, Upstash Workflow is the one making the HTTP request and waiting for the response, even if it takes too long to receive response from the LLM.

The following code snippet can also be generalized to work with other LLM SDKs, such as Anthropic or Google.

```typescript {18-24} theme={"system"}
import { createOpenAI } from '@ai-sdk/openai';
import { HTTPMethods } from '@upstash/qstash';
import { WorkflowAbort, WorkflowContext } from '@upstash/workflow';

export const createWorkflowOpenAI = (context: WorkflowContext) => {
  return createOpenAI({
    compatibility: "strict",
    fetch: async (input, init) => {
      try {
        // Prepare headers from init.headers
        const headers = init?.headers
          ? Object.fromEntries(new Headers(init.headers).entries())
          : {};

        // Prepare body from init.body
        const body = init?.body ? JSON.parse(init.body as string) : undefined;

        // Make network call
        const responseInfo = await context.call("openai-call-step", {
          url: input.toString(),
          method: init?.method as HTTPMethods,
          headers,
          body,
        });

        // Construct headers for the response
        const responseHeaders = new Headers(
          Object.entries(responseInfo.header).reduce((acc, [key, values]) => {
            acc[key] = values.join(", ");
            return acc;
          }, {} as Record<string, string>)
        );

        // Return the constructed response
        return new Response(JSON.stringify(responseInfo.body), {
          status: responseInfo.status,
          headers: responseHeaders,
        });
      } catch (error) {
        if (error instanceof WorkflowAbort) {
          throw error
        } else {
          console.error("Error in fetch implementation:", error);
          throw error; // Rethrow error for further handling
        }
      }
    },
  });
};
```

### Using OpenAI client to generate text

Now that we've created the OpenAI client, we can use it to generate the text.

For that, we're going to create a new workflow endpoint that uses the payload as prompt to generate text using the OpenAI client.

```typescript {8, 16-20} theme={"system"}
import { serve } from "@upstash/workflow/nextjs";
import { WorkflowAbort } from '@upstash/workflow';
import { generateText, ToolExecutionError } from 'ai';

import { createWorkflowOpenAI } from './model';

export const { POST } = serve<{ prompt: string }>(async (context) => {
  const openai = createWorkflowOpenAI(context);

  // Important: Must have a step before generateText
  const prompt = await context.run("get prompt", async () => {
    return context.requestPayload.prompt;
  });

  try {
    const result = await generateText({
      model: openai('gpt-3.5-turbo'),
      maxTokens: 2048,
      prompt,
    });

    await context.run("text", () => {
      console.log(`TEXT: ${result.text}`);
      return result.text;
    });
    
  } catch (error) {    
    if (error instanceof ToolExecutionError && error.cause instanceof WorkflowAbort) {
      throw error.cause;
    } else {
      throw error;
    }
  }
});
```

We can either [run the app locally](/workflow/howto/local-development) or deploy it. Once the app is running, we can trigger the workflow using the following code:

```ts  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: "<QSTASH_TOKEN>" });
const { workflowRunId } = await client.trigger({
  url: "https://<YOUR_WORKFLOW_ENDPOINT>/<YOUR-WORKFLOW-ROUTE>",
  body: { "prompt": "How is the weather in San Francisco around this time?" },
  keepTriggerConfig: true,
});
```

The workflow will execute, and we can view the logs in [the Workflow dashboard](/workflow/howto/monitor):

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=67020a90a3c074458dc673b548de501f" alt="Workflow logs in dashboard" data-og-width="2172" width="2172" data-og-height="600" height="600" data-path="img/qstash-workflow/ai-sdk/without-tool.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eb661b008f69cbcb8a531a25687aa3b6 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e388763ee91488cf272ca7bc5f72a906 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5c8883aca9f4e3a9a93876ee5255f691 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=945cf3bccb336c17fbfd2d24306dc808 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=5d656092b0a76ce1b8cca0d0d7eb747d 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/without-tool.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1b7e3c54fa46a632aca1ee8886076def 2500w" />
</Frame>

### Advanced Implementation with Tools

Tools allow the AI model to perform specific actions during text generation. You can learn more about tools in the [Vercel AI SDK documentation](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling).

When using tools with Upstash Workflow, each tool execution must be wrapped in a workflow step.

<Info>
  The `maxSteps` parameter must be greater than 1 when using tools to allow the model to process tool results and generate final responses. See the [tool steps documentation](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling#tool-steps) for detailed explanation.
</Info>

```typescript {24-30, 33} theme={"system"}
import { z } from 'zod';
import { serve } from "@upstash/workflow/nextjs";
import { WorkflowAbort } from '@upstash/workflow';
import { generateText, ToolExecutionError, tool } from 'ai';

import { createWorkflowOpenAI } from './model';

export const { POST } = serve<{ prompt: string }>(async (context) => {
  const openai = createWorkflowOpenAI(context);

  const prompt = await context.run("get prompt", async () => {
    return context.requestPayload.prompt;
  });

  try {
    const result = await generateText({
      model: openai('gpt-3.5-turbo'),
      tools: {
        weather: tool({
          description: 'Get the weather in a location',
          parameters: z.object({
            location: z.string().describe('The location to get the weather for'),
          }),
          execute: ({ location }) => context.run("weather tool", () => {
	        // Mock data, replace with actual weather API call
            return {
              location,
              temperature: 72 + Math.floor(Math.random() * 21) - 10,
            };
          })
        }),
      },
      maxSteps: 2,
      prompt,
    });
    
    await context.run("text", () => {
      console.log(`TEXT: ${result.text}`);
      return result.text;
    });
  } catch (error) {
    if (error instanceof ToolExecutionError && error.cause instanceof WorkflowAbort) {
      throw error.cause;
    } else {
      throw error;
    }
  }
});
```

When called with the same prompt as above, we will see the following logs:

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=feaa22e98e9bd424f67a06494c00715c" data-og-width="2172" width="2172" data-og-height="790" height="790" data-path="img/qstash-workflow/ai-sdk/with-tool.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2e3b6f135b6f59bf6aa07524d998befd 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a7da726a229ee05b06ae19e4a3e449ff 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=43e20af5a05b5d6786928097d40a4e96 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8dc2fb669846aaa6e783b7042c7e9fed 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4d042557b569a795cb3330ca43358eaf 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/ai-sdk/with-tool.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=04264f5ad160a798837b54e5c354b627 2500w" />
</Frame>

## Important Considerations

When using Upstash Workflow with the Vercel AI SDK, there are several critical requirements that must be followed:

### Step Execution Order

The most critical requirement is that `generateText` cannot be called before any workflow step. Always have a step before `generateText`. This could be a step which gets the prompt:

<CodeGroup>
  ```typescript ‚ùå Wrong {4} theme={"system"}
  export const { POST } = serve<{ prompt: string }>(async (context) => {
    const openai = createWorkflowOpenAI(context);

    // Will throw "prompt is undefined"
    const result = await generateText({
      model: openai('gpt-3.5-turbo'),
      prompt: context.requestPayload.prompt
    });
  });
  ```

  ```typescript ‚úÖ Correct {3-7} theme={"system"}
  export const { POST } = serve<{ prompt: string }>(async (context) => {
    const openai = createWorkflowOpenAI(context);

    // Get prompt in a step first
    const prompt = await context.run("get prompt", async () => {
      return context.requestPayload.prompt;
    });

    const result = await generateText({
      model: openai('gpt-3.5-turbo'),
      prompt
    });
  });
  ```
</CodeGroup>

### Error Handling Pattern

You must use the following error handling pattern exactly as shown. The conditions and their handling should not be modified:

```typescript {3-9} theme={"system"}
try {
  // Your generation code
} catch (error) {    
  if (error instanceof ToolExecutionError && error.cause instanceof WorkflowAbort) {
    throw error.cause;
  } else {
    throw error;
  }
}
```

### Tool Implementation

When implementing tools:

* Each tool's `execute` function must be wrapped in a `context.run()` call
* Tool steps should have descriptive names for tracking
* Tools must follow the same error handling pattern as above

Example:

```typescript  theme={"system"}
execute: ({ location }) => context.run("weather tool", () => {
  // Mock data, replace with actual weather API call
  return {
    location,
    temperature: 72 + Math.floor(Math.random() * 21) - 10,
  };
})
```


# Anthropic
Source: https://upstash.com/docs/workflow/integrations/anthropic



The standard way to call a third-party endpoint in your workflow is by using [`context.call`](/workflow/basics/context#context-call).

However, if you need to call the Anthropic endpoint for text generation ([`/v1/messages`](https://docs.anthropic.com/en/api/messages)), you can leverage the type-safe method `context.api.anthropic.call` method:

<Note>
  `context.api.anthropic.call` is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). You can use `context.call` instead to work with Anthropic. See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

```ts  theme={"system"}
const { status, body } = await context.api.anthropic.call(
  "Call Anthropic",
  {
    token: "<ANTHROPIC_API_KEY>",
    operation: "messages.create",
    body: {
      model: "claude-3-5-sonnet-20241022",
      max_tokens: 1024,
      messages: [
          {"role": "user", "content": "Hello, world"}
      ]
    },
  }
);

// get text:
console.log(body.content[0].text)
```

The SDK provides predefined types for the body field in both the request parameters and the response, simplifying common use cases. If you need to customize these types, you can override them as shown below:

```ts  theme={"system"}
type ResponseBodyType = { ... }; // Define your response body type
type RequestBodyType = { ... };  // Define your request body type

const { status, body } = await context.api.anthropic.call<
  ResponseBodyType,
  RequestBodyType
>(
  "Call Anthropic",
  {
    ...
  }
);
```


# Datadog - Upstash QStash Integration
Source: https://upstash.com/docs/workflow/integrations/datadog



This guide walks you through connecting your Datadog account with Upstash QStash for monitoring and analytics of your message delivery, retries, DLQ, and schedules.

<Check>
  **Integration Scope**

  Upstash Datadog Integration covers Prod Pack.
</Check>

## **Step 1: Log in to Your Datadog Account**

1. Go to [Datadog](https://www.datadoghq.com/) and sign in.

## **Step 2: Install Upstash Application**

1. In Datadog, open the Integrations page.
2. Search for "Upstash" and open the integration.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1d4018e79c0fedb23a2c8d21bc3b6a43" alt="integration-tab.png" data-og-width="2880" width="2880" data-og-height="1028" height="1028" data-path="img/datadog/integration-tab.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e20319650673fc0c2ddb267c8c521d59 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5eceb4e5af82406788781e8098229cf3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=1e0ba16abd0046c3e8a65815eaa3fc19 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=5ade8ad371aaf59d811824c6310887a2 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80c8644a9d8d417d9138d13143afaba0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/integration-tab.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=eda063436df126a626dd96a87f22a050 2500w" />

Click "Install" to add Upstash to your Datadog account.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=add4288783757921f62353223fbf39b5" alt="installation.png" data-og-width="2802" width="2802" data-og-height="1384" height="1384" data-path="img/datadog/installation.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=142c3fcc921b90a0abc94bbeb8a7bae3 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=b7a6aae307da8f8b9757e84cff0db8d3 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=413d45cfe27a64e38c4e422c97984c8e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=ba35ec57c2be78e999358a701e533812 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=52b29977b08a6500f380adea36c6881c 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/installation.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=811d297b670fc274b74322f932c80475 2500w" />

## **Step 3: Connect Accounts**

After installing Upstash, click "Connect Accounts". Datadog will redirect you to Upstash to complete account linking.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=64d0abd76d3037f01a3811cd531c46d4" alt="connect-acc.png" data-og-width="1756" width="1756" data-og-height="936" height="936" data-path="img/datadog/connect-acc.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=085212af402a08e0f7e89ba644529d48 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f379315b18a9f213fa92aa119ca32f81 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=3a7dadd01cdd15abded31929223a534e 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6b2fa6785253ca09d38a1c24cc081e4e 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f6630bbfe1b49efa9f4b6fc4f4cc3a22 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/connect-acc.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=80054d3b9fa019a5bf1c1ee60334b116 2500w" />

## **Step 4: Select Account to Integrate**

1. On Upstash, select the Datadog account to integrate.
2. Personal and team accounts are supported.

**Caveats**

* The integration can be established once at a time. To change the account scope (e.g., add/remove teams), re-establish the integration from scratch.

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=7d332ed4228eaba275329f458d1dbd2f" alt="personal.png" data-og-width="886" width="886" data-og-height="1026" height="1026" data-path="img/datadog/personal.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=f665cc6a4bbcf6d9d639c0b2b953fa0d 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=a1f4954abf4877df690e05633d0e0142 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=be4a2b8f7e038b224d48dada4132866c 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4b18d7807fa6df65216f98ed0d3526f5 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=4791a82eeec9a917746a8684751e99f0 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/personal.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=d5cc8d1e39f3ab8058127a7bfc5a4f84 2500w" />

<img src="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=91af03309be7ba54f5c1e605052fe3cd" alt="team.png" data-og-width="950" width="950" data-og-height="1104" height="1104" data-path="img/datadog/team.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=280&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e0bcf3f87626d2f35dad5e349d8d530a 280w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=560&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=e5a7d1921331a83c3b2b6d0485b418df 560w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=840&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=575a5ad465eaa4e5ff17a202f0dce775 840w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1100&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=67232bca77ab58e0be7a9ea6788caab9 1100w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=1650&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=71654ac0f72319d20778dacd0c9c2c3d 1650w, https://mintcdn.com/upstash/eu0laKPu7u_-Kw04/img/datadog/team.png?w=2500&fit=max&auto=format&n=eu0laKPu7u_-Kw04&q=85&s=6326dfc48f62069c3cb19a0f6b96a7ed 2500w" />

## **Step 5: Wait for Metrics Availability**

Once the integration is completed, metrics from QStash (publish counts, success/error rates, retries, DLQ, schedule executions) will start appearing in Datadog dashboards shortly.

<img src="https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=e4dbab20b620a015f5978e1ebce6ef18" alt="upstash-dashboard.png" data-og-width="2728" width="2728" data-og-height="1508" height="1508" data-path="img/datadog/upstash-qstash-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=280&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=2d5604424145437d8c65bf1f29961276 280w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=560&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=50b7cabece58a0ca711f1109a9ebee7a 560w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=840&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=60f1c33f2de64434705dc452a0f43c1e 840w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=1100&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=a69c642498a7621fcad8a236bd925534 1100w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=1650&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=a6e1d7ebfa95dc9f58e05c49eadb3868 1650w, https://mintcdn.com/upstash/dlfw7EZCyeFSjFPX/img/datadog/upstash-qstash-dashboard.png?w=2500&fit=max&auto=format&n=dlfw7EZCyeFSjFPX&q=85&s=d910a6cc1be7ac4d7a3f813694484808 2500w" />

## **Step 6: Datadog Integration Removal Process**

From Datadog ‚Üí Integrations ‚Üí Upstash, press "Remove" to break the connection.

### Confirm Removal

Upstash will stop publishing metrics after removal. Ensure any Datadog API keys/configurations for this integration are also removed on the Datadog side.

## **Conclusion**

You‚Äôve connected Datadog with Upstash QStash. Explore Datadog dashboards to monitor message delivery performance and reliability.

If you need help, contact support.


# OpenAI
Source: https://upstash.com/docs/workflow/integrations/openai



### Calling OpenAI

The standard way to call a third-party endpoint in your workflow is by using [`context.call`](/workflow/basics/context#context-call).

However, if you need to call the OpenAI endpoint for text generation ([`/v1/chat/completions`](https://platform.openai.com/docs/api-reference/chat)), you can leverage the type-safe method `context.api.openai.call` method:

<Note>
  `context.api.openai.call` is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). You can use `context.call` instead to work with OpenAI. See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

```typescript OpenAI theme={"system"}
const { status, body } = await context.api.openai.call(
  "Call OpenAI",
  {
    token: "<OPENAI_API_KEY>",
    operation: "chat.completions.create",
    body: {
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "Assistant says 'hello!'",
        },
        {
          role: "user",
          content: "User shouts back 'hi!'"
        }
      ],
    },
  }
);

// get text:
console.log(body.content[0].text)
```

The SDK provides predefined types for the body field in both the request parameters and the response, simplifying common use cases. If you need to customize these types, you can override them as shown below:

```ts  theme={"system"}
type ResponseBodyType = { ... }; // Define your response body type
type RequestBodyType = { ... };  // Define your request body type

const { status, body } = await context.api.openai.call<
  ResponseBodyType,
  RequestBodyType
>(
  "Call OpenAI",
  {
    ...
  }
);
```

### OpenAI Compatible Provider

If you want to call an OpenAI compatible provider, you can do so using the `baseURL` parameter:

```ts  theme={"system"}
const { status, body } = await context.api.openai.call(
  "Call Deepseek",
  {
    baseURL: "https://api.deepseek.com",
    token: process.env.DEEPSEEK_API_KEY,
    operation: "chat.completions.create",
    body: {
      model: "deepseek-chat",
      messages: [
        {
          role: "system",
          content: "Assistant says 'hello!'",
        },
        {
          role: "user",
          content: "User shouts back 'hi!'"
        }
      ],
    },
  }
);
```


# Prometheus - Upstash QStash Integration
Source: https://upstash.com/docs/workflow/integrations/prometheus



To monitor your QStash metrics in Prometheus and visualize in Grafana, follow these steps:

<Check>
  **Integration Scope**

  Upstash Prometheus Integration covers Prod Pack.
</Check>

## **Step 1: Enable Prometheus in Upstash Console**

1. Open the Upstash Console and navigate to QStash.
2. Go to Settings ‚Üí Monitoring.
3. Enable Prometheus to allow scraping QStash metrics.

<img src="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=09012029cd0b26d17391faadd590d250" alt="configuration.png" data-og-width="1956" width="1956" data-og-height="680" height="680" data-path="img/prometheus/configuration-qstash.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=280&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=9a8b41e736632ca22cdb6a9c1418be24 280w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=560&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=017a60eb3cd76ca2167b565acd8cffcd 560w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=840&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=465c0808c488881e9e7b75ab2630eca4 840w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=1100&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=ad55da6d698ba3afbe35a4e2f583bfb8 1100w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=1650&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=3ca73f05137987eeac02f6f8da3f2b8f 1650w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/configuration-qstash.png?w=2500&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=096f8dd337e73b3b37232fd14646eed8 2500w" />

## **Step 2: Copy Monitoring Token**

1. After enabling, a monitoring token is generated and displayed.
2. Copy the token. It will be used to authenticate Prometheus requests.

<Check>
  **Header Format**

  Send the token as `Authorization: Bearer <MONITORING_TOKEN>`.
</Check>

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2618f754b9209f28f30d27b16a652786" alt="monitoring-token.png" data-og-width="950" width="950" data-og-height="520" height="520" data-path="img/prometheus/monitoring-token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bd809c06e4421719c1195a3542a16cfb 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2721266c30939e15e371087ba8d8531 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=dbf58ef63addcf094f3cd2ea1e4ddd2b 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=65e3183a923ab6bfcb7c1e55cbce5a27 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=0d9ad474b754c5a3ac37fff5155f22c0 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/monitoring-token.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bb17a652adc3478d3b68704d29886aa4 2500w" />

## **Step 3: Configure Prometheus (via Grafana Data Source)**

1. In Grafana, add a Prometheus data source.
2. Set the address to `https://api.upstash.com/monitoring/prometheus`.
3. In HTTP headers, add the monitoring token.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=3dce2b10059a2eb96d8d560bdabb7303" alt="datasource.png" data-og-width="1848" width="1848" data-og-height="464" height="464" data-path="img/prometheus/datasource.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=325217df537ca2f7269c4d38803b952f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9264339789011443e61167e443c0ae8a 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c1a7c769e5b857d21a733aec149233a8 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1e156eabf6c5c92c9ab2aa54d175667a 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=eb464cb41c5bc5d8906f09c6a70f5c2b 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=9a0c6ef2b3f5989c557a6b9d054dc0b7 2500w" />

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=f32611d6c8cedb2b6a73d21e9b8a1cd5" alt="headers.png" data-og-width="1322" width="1322" data-og-height="346" height="346" data-path="img/prometheus/headers.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=613ce8cdff83bfadfbd95e40fac9548f 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3edb89b53a21ffc79173c03e0c0bd7b 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d624ffcce430e3014319386a7de649d5 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=4fb91d8f22449f95fc91704839fb1eb5 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6a5a66bed411dde641fbcf8a6111de7d 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/headers.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=1f60d9ffdf856ad140c8f470e1e9028e 2500w" />

Click <b>Test and Save</b>.

<img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=6e3f9cc214486c59085fe036a0dd6a28" alt="datasource-final.png" data-og-width="1560" width="1560" data-og-height="412" height="412" data-path="img/prometheus/datasource-final.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a97d2c20d4cae7002e57524de561937b 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=e93e44229ab80a44a9115225b65c8742 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2d542697335e6b8e3ca346cd5371292d 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=bde3d4b76f3d4f0f4712a307d1d90f12 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=a15201c139e232a3ca6a6599e35a119a 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/prometheus/datasource-final.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2950933a8fb225e5ddfc04143a36a111 2500w" />

## **Step 4: Import Dashboard**

You can use the Upstash Grafana dashboard to visualize QStash metrics.

Open the import dialog and use: <a href="https://grafana.com/grafana/dashboards/24206-upstash-qstash-dashboard/">Upstash QStash Dashboard</a>

<img src="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=e5deb2b23457a82d894690267e19fc7f" alt="grafana-dashboard.png" data-og-width="2978" width="2978" data-og-height="1250" height="1250" data-path="img/prometheus/grafana-qstash-dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=280&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=8604c43b9ff9932d5546baf4ae13c91f 280w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=560&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d9655dfabe3b43851627c919ff25a307 560w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=840&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d9c01c7d9cb73274aa769c592f2e32c2 840w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=1100&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d6326a999c61be656b3f516de281d338 1100w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=1650&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=ff94bf6ba50c4bb30d3af1d4545c5459 1650w, https://mintcdn.com/upstash/OUAG0YZr1j5tyfjW/img/prometheus/grafana-qstash-dashboard.png?w=2500&fit=max&auto=format&n=OUAG0YZr1j5tyfjW&q=85&s=d0a6c38bf6890cc44aa95843ffc952d5 2500w" />

## **Conclusion**

You‚Äôve integrated QStash with Prometheus. Use Grafana to explore message throughput, retries, DLQ, schedules, and Upstash Workflows.

If you encounter issues, contact support.


# Resend
Source: https://upstash.com/docs/workflow/integrations/resend



The standard way to call a third-party endpoint in your workflow is by using [`context.call`](/workflow/basics/context#context-call).

However, if you need to call the Resend endpoint to send emails ([`/emails`](https://resend.com/docs/api-reference/emails/send-email) or [`/emails/batch`](https://resend.com/docs/api-reference/emails/send-batch-emails)), you can leverage the type-safe method `context.api.resend.call` method:

<Note>
  `context.api.resend.call` is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). You can use `context.call` instead to work with Resend. See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

<CodeGroup>
  ```typescript Single Email theme={"system"}
  const { status, body } = await context.api.resend.call(
    "Call Resend",
    {
      token: "<RESEND_API_KEY>",
      body: {
        from: "Acme <onboarding@resend.dev>",
        to: ["delivered@resend.dev"],
        subject: "Hello World",
        html: "<p>It works!</p>",
      },
      headers: {
        "content-type": "application/json",
      },
    }
  );
  ```

  ```typescript Batch Email {4} theme={"system"}
  const { status, body } = await context.api.resend.call(
    "Call Resend",
    {
      batch: true,
      token: "<RESEND_API_KEY>",
      body: [
        {
          from: "Acme <onboarding@resend.dev>",
          to: ["delivered@resend.dev"],
          subject: "Hello World",
          html: "<p>It works!</p>",
        },
        {
          from: "Acme <onboarding@resend.dev>",
          to: ["delivered@resend.dev"],
          subject: "Hello World",
          html: "<p>It works!</p>",
        },
      ],
      headers: {
        "content-type": "application/json",
      },
    }
  );
  ```
</CodeGroup>

The SDK provides predefined types for the body field in both the request parameters and the response, simplifying common use cases. If you need to customize these types, you can override them as shown below:

```ts  theme={"system"}
type IsBatch = true; // Set to either true or false
type ResponseBodyType = { ... }; // Define your response body type
type RequestBodyType = { ... };  // Define your request body type

const { status, body } = await context.api.resend.call<
  IsBatch,
  ResponseBodyType,
  RequestBodyType
>(
  "Call Resend",
  {
    ...
  }
);
```


# llms.txt
Source: https://upstash.com/docs/workflow/llms-txt





# Migrate to the New SDK
Source: https://upstash.com/docs/workflow/migration



In October 2024, we released a new SDK, `@upstash/workflow`, for Upstash Workflow, separating its development from the QStash SDK. Although Upstash Workflow is built on QStash, our goal is to improve the developer experience and support with a dedicated SDK. Development for Upstash Workflow will occur in `@upstash/workflow`, and Workflow-related imports will be removed from `@upstash/qstash` in future releases.

If you started using Upstash Workflow with `@upstash/qstash`, you will need to migrate to `@upstash/workflow`. We have made some backward-incompatible changes, but we aim to make the transition as smooth as possible.
In this guide, we will explain the changes you may need to make for migration.

### Install `@upstash/workflow`

First, we will need to install the new package with:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

If you were using `@upstash/qstash` only for workflow, you can uninstall it from your project.

### Serve methods

You will need to change the imports from `@upstash/qstash` to @upstash/workflow:

```ts  theme={"system"}
// old
import { serve } from "@upstash/qstash/nextjs"

// new 
import { serve } from "@upstash/workflow/nextjs"
```

We have updated what our `serve` methods return. We made this change to make it
easier to extend the API in the future.

For instance, Next.js method changed like this:

```javascript  theme={"system"}
// old
export const POST = serve(...);

// new
export const { POST } = serve(...);
```

We kept the `serve` method of `Hono` the same. The rest are updated in a similar way.
See [the quickstarts](/workflow/quickstarts/platforms) for the new way `serve`
should be used.

Additionally, `@upstash/workflow/nuxt` import is removed. You should use `@upstash/workflow/h3`
instead. This change was made because `nuxt` uses `h3` under the hood and our `serve` method
for `nuxt` can work with any project using `h3`.

### Updating `context.call`

If you were using [`context.call` method](/workflow/basics/context#context-call) in your workflow, you will need to change
how it's called and what it returns. Here is what the change looks like:

```javascript  theme={"system"}
// old
const result = await context.call("call step", "<call-url>", "POST", ...)

// new
const {
  status,  // response status
  headers, // response headers
  body     // response body
} = await context.call("call step", {
  url: "<call-url>",
  method: "POST",
  ...
})
```

In the old version, we only returned the response body. Also, if the request
to the url failed, [the workflow run would fail](/workflow/howto/failures).

In the new version, we update how the parameters are passed to the `context.call`.
Additionally, we change the fail behavior: if the request fails, it doesn't make the
workflow fail. Instead, the status and the body is simply returned and workflow
continues as usual.

If you have ongoing workflow runs which call `context.call` during your transition,
`status` and `headers` fields may not be available in these old runs. After your
transition, all workflow runs will have all three fields.

### Renaming Errors

The errors in Workflow were renamed from `QStashWorkflowError` and `QStashWorkflowAbort` to `WorkflowError` and `WorkflowAbort`.


# Pricing
Source: https://upstash.com/docs/workflow/pricing



Upstash Workflow is based on QStash and uses a "pay-as-you-go" pricing model. You only incur costs when your app receives traffic, meaning there's no charge when it's not in use. Click [here](https://upstash.com/pricing/workflow) to view the pricing.

A workflow run consists of several QStash messages, with the total cost determined by the number of messages used.

You can track your current message usage and associated costs in the [Overview tab of the console](https://console.upstash.com/qstash?tab=details).

<Frame>
  <img src="https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=87f8e5ad70e6b84bf131fe4d681ea33d" data-og-width="1962" width="1962" data-og-height="956" height="956" data-path="img/qstash/message_cost.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=280&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=847ec477e510538e4b832fd60f48e78b 280w, https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=560&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=90552de39d3caf419425a3b22bae650c 560w, https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=840&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=ed22633e5fe15edca00a02ec3388e46a 840w, https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=1100&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=45e43cc65aeae17a139596e0e6313eff 1100w, https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=1650&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=402d24ff3531ddcfdcf7d81261b82c96 1650w, https://mintcdn.com/upstash/P7f-vmkf9yuOavEy/img/qstash/message_cost.png?w=2500&fit=max&auto=format&n=P7f-vmkf9yuOavEy&q=85&s=b10ff096e02b745252e5229afbae3cc3 2500w" />
</Frame>

For detailed pricing information based on different plans, visit our [Workflow pricing page](https://upstash.com/pricing/workflow).

### Message Usage per Workflow Run

* [context.run](/workflow/basics/context#context-run), [context.sleep](/workflow/basics/context#context-sleep), [context.sleepUntil](/workflow/basics/context#context-sleepuntil), or [context.waitForEvent](/workflow/basics/context#context-waitforevent) commands generate a single message.
* The [context.call](/workflow/basics/context#context-call) command generates two messages.
* Each step in a [parallel run](/workflow/howto/parallel-runs) costs 1 extra message.
* If the workflow endpoint or URL in [context.call](/workflow/basics/context#context-call) returns an error or is unreachable, the workflow SDK will retry the call (up to 3 times by default). Each retry counts as a new message.


# Astro
Source: https://upstash.com/docs/workflow/quickstarts/astro



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/astro" horizontal>
  You can find the project source code on GitHub.
</Card>

<Card title="Deploy With Vercel" icon="triangle" iconType="sharp-solid" href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fupstash%2Fworkflow-js%2Ftree%2Fmain%2Fexamples%2Fastro&env=QSTASH_TOKEN&envDescription=You%20can%20access%20this%20variable%20from%20Upstash%20Console%2C%20under%20QStash%20page.%20&project-name=workflow-astro&repository-name=workflow-astro&demo-title=Upstash%20Workflow%20Example&demo-description=A%20Astro%20application%20utilizing%20Upstash%20Workflows" horizontal>
  Deploy the project to Vercel with a single click.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy
Upstash Workflow with Astro. You can also explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/astro)
for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your Astro project:

<CodeGroup>
  ```bash npm theme={"system"}
  npm install @upstash/workflow 
  ```

  ```bash pnpm theme={"system"}
  pnpm install @upstash/workflow
  ```

  ```bash bun theme={"system"}
  bun add @upstash/workflow
  ```
</CodeGroup>

## Step 2: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This key is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```txt  theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint with Astro, navigate into your entrypoint file (usually `src/index.ts`) and add the following code:

<Tabs>
  <Tab title="Minimal example">
    ```typescript src/pages/api/workflow.ts theme={"system"}
    import { serve } from "@upstash/workflow/astro";


    export const { POST } = serve<string>(async (context) => {
      const result1 = await context.run("initial-step", () => {
        console.log("initial step ran")
        return "hello world!"
      })

      await context.run("second-step", () => {
        console.log(`second step ran with value ${result1}`)
      })
    }, {
      // env must be passed in astro.
      // for local dev, we need import.meta.env.
      // For deployment, we need process.env:
      env: {
        ...process.env,
        ...import.meta.env
      }
    })

    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

After defining the endpoint, you can trigger your workflow by starting your app:

```bash Terminal theme={"system"}
npm run dev
```

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST http://localhost:3000/api/workflow \
    -H "Content-Type: application/json" \
    -d '{"message": "Hello from the workflow!"}'

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e53201dceb3377bf5c88b05740dddc42" data-og-width="1756" width="1756" data-og-height="639" height="639" data-path="img/qstash-workflow/hono_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b4276f2a50adecd8bdd9b63aba46fbf8 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=69118bcc896aa763bb8198dbb43a3d4a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=494c2945791820c0c6a31146d0d0a370 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=952eb9a090da2d2ca0d2b75941fccc42 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=18d4dbbadacea16dae211bf39dc87de9 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6825103f01f307dfc2849ea21c1deacb 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your Astro app with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables from your `.env` file are set in your Vercel project settings. For example, your `QSTASH_TOKEN`, and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your Astro app to production as you normally would, for example to Vercel, Heroku, or AWS.

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

```bash Terminal theme={"system"}
curl -X POST <DEPLOYMENT_URL>/api/workflow \
    -H "Content-Type: application/json" \
    -d '{"message": "Hello from the workflow!"}'
```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/astro) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Cloudflare Workers
Source: https://upstash.com/docs/workflow/quickstarts/cloudflare-workers



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/cloudflare-workers" horizontal>
  You can find the project source code on GitHub.
</Card>

<Card title="Deploy With Cloudflare Workers" icon="cloudflare" href="https://deploy.workers.cloudflare.com/?url=https://github.com/upstash/qstash-workflow-example-cloudflare-workers" horizontal>
  Deploy the project to Cloudflare Workers with a single click.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with Cloudflare Workers. You can also explore our [Cloudflare Workers example](https://github.com/upstash/workflow-js/tree/main/examples/cloudflare-workers) or [Hono.js Cloudflare Workers example](https://github.com/upstash/workflow-js/tree/main/examples/cloudflare-workers-hono) for detailed, end-to-end examples and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your worker project:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.dev.vars` file in your project root and add your QStash token. This key is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .dev.vars
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.dev.vars` file:

```txt .dev.vars theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.dev.vars` file with the following:

```txt .dev.vars theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint with Cloudflare Workers, navigate into your workers entrypoint file (usually `src/index.ts`) and add the following code:

```typescript src/index.ts theme={"system"}
import { serve } from "@upstash/workflow/cloudflare"

interface Env {
  ENVIRONMENT: "development" | "production"
}

export default serve<{ text: string }>(
  async (context) => {
    const initialPayload = context.requestPayload.text

    const result = await context.run("initial-step", async () => {
        console.log(`Step 1 running with payload: ${initialPayload}`)

        return { text: "initial step ran" }
      }
    )

    await context.run("second-step", async () => {
      console.log(`Step 2 running with result from step 1: ${result.text}`)
    })
  }
)
```

## Step 4: Run the Workflow Endpoint

To start your worker locally, run the following command:

```bash Terminal theme={"system"}
npm run wrangler dev
```

Executing this command prints a local URL to your workflow endpoint. By default, this URL is `http://localhost:8787`.

You can verify your correct environment variable setup by checking the wrangler output, which should now have access to your `QSTASH_TOKEN` binding and log your local URL:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=707cec511359835449c86699cb91de29" data-og-width="1122" width="1122" data-og-height="524" height="524" data-path="img/qstash-workflow/wrangler.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0015387b2cb15a57dc551aa28a97eb5a 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fefc9cb350d93dcc2ba2ae75af33444a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=76795e5a692e024263b10123c4df1aa4 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0b95c822fdf5022159caa4bcdfe4f6cc 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1e347cb36ad119611d338dd3e7497c4d 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e2a023d8ab3f3a7fc0d9eee18ba2ed37 2500w" />
</Frame>

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:8787/ -D '{"text": "hello world!"}'

# result: {"workflowRunId":"wfr_xxxxxx"}
```

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=3536436ca84be611df74e8f0c9da3dd8" data-og-width="1765" width="1765" data-og-height="584" height="584" data-path="img/qstash-workflow/workers_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=bcceb8996cb4efcfd07b66f2d6f41256 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=feaba5ae13295f5749cda6187322cb48 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=5681fd9d6446929480e65e262360ccd6 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=9f41dfd3fdcdf275a630ad42c8cb836b 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=de4a09255a54bc0e31d0d4d13ddb2d20 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/workers_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=44e6b099d57d05ef9d696a3d125e6177 2500w" />
</Frame>

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

If you didn't set up local QStash development server, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your Cloudflare Worker with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables from your `.dev.vars` file are set in your Cloudflare Worker project settings. For example, your `QSTASH_TOKEN`, `ENVIRONMENT`, and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your Cloudflare Worker to production as you normally would, for example using the Cloudflare CLI:

   ```bash Terminal theme={"system"}
   wrangler deploy
   ```

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

   ```bash Terminal theme={"system"}
   curl -X POST https://<YOUR-PRODUCTION-URL>/ -D '{"text": "hello world!"}'
   ```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/cloudflare-workers) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Express.js
Source: https://upstash.com/docs/workflow/quickstarts/express



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/express" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy
Upstash Workflow with Express.js. You can also explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/express)
for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your Express.js project:

<Tabs>
  <Tab title="npm">`bash npm install @upstash/workflow `</Tab>
  <Tab title="pnpm">`bash pnpm install @upstash/workflow `</Tab>
  <Tab title="bun">`bash bun add @upstash/workflow `</Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This key is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```txt  theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint with Express.js, navigate into your entrypoint file (usually `src/index.ts`) and add the following code:

<Tabs>
  <Tab title="Minimal example">
    ```typescript src/index.ts theme={"system"}
    import { serve } from "@upstash/workflow/express";
    import express from 'express';
    import { config } from 'dotenv';

    config();

    const app = express();

    app.use(
      express.json()
    );

    app.post(
      '/workflow',
      serve<{ message: string }>(
        async (context) => {
          const res1 = await context.run("step1", async () => {
            const message = context.requestPayload.message;
            return message;
          })

          await context.run("step2", async () => {
              console.log(res1);
          })
        }
      )
    );

    app.listen(3000, () => {
      console.log('Server running on port 3000');
    });

    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

After defining the endpoint, you can trigger your workflow by starting your app:

```bash  theme={"system"}
npm run dev
```

Then make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST http://localhost:3000/workflow \
    -H "Content-Type: application/json" \
    -d '{"message": "Hello from the workflow!"}'

# result: {"workflowRunId":"wfr_xxxxxx"}
```

<Warning>
  Express.js integration only works with `Content-Type: application/json`
  header. Other payload types are not supported yet.
</Warning>

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e53201dceb3377bf5c88b05740dddc42" data-og-width="1756" width="1756" data-og-height="639" height="639" data-path="img/qstash-workflow/hono_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b4276f2a50adecd8bdd9b63aba46fbf8 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=69118bcc896aa763bb8198dbb43a3d4a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=494c2945791820c0c6a31146d0d0a370 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=952eb9a090da2d2ca0d2b75941fccc42 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=18d4dbbadacea16dae211bf39dc87de9 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6825103f01f307dfc2849ea21c1deacb 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your Hono app with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables from your `.env` file are set in your Vercel project settings. For example, your `QSTASH_TOKEN`, and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your Express.js app to production as you normally would, for example to fly.io, Heroku, or AWS.

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

```bash Terminal theme={"system"}
curl -X POST <DEPLOYMENT_URL>/workflow \
	-H "Content-Type: application/json" \
	-d '{"message": "Hello from the workflow!"}'
```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/express) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# FastAPI
Source: https://upstash.com/docs/workflow/quickstarts/fastapi



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-py/tree/master/examples/fastapi" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use Upstash Workflow with FastAPI. You can also explore [the source code](https://github.com/upstash/workflow-py/tree/master/examples/fastapi) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Python and pip installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, create a new directory and set up a virtual environment:

```bash  theme={"system"}
python -m venv venv
source venv/bin/activate
```

Then, install the Workflow SDK and FastAPI:

```bash  theme={"system"}
pip install fastapi uvicorn upstash-workflow
```

## Step 2: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```bash .env theme={"system"}
export QSTASH_URL="http://127.0.0.1:8080"
export QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```bash .env theme={"system"}
export QSTASH_TOKEN="***"
export UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint in a FastAPI project, create a `main.py` file that contains your workflow:

<Tabs>
  <Tab title="Example">
    ```python main.py theme={"system"}
    from fastapi import FastAPI
    from upstash_workflow.fastapi import Serve

    app = FastAPI()
    serve = Serve(app)


    @serve.post("/api/workflow")
    async def workflow(context) -> None:
        async def _step1() -> None:
            print("initial step ran")

        await context.run("initial-step", _step1)

        async def _step2() -> None:
            print("second step ran")

        await context.run("second-step", _step2)

    ```
  </Tab>

  <Tab title="Sleep">
    ```python main.py theme={"system"}
    from fastapi import FastAPI
    import time
    from upstash_workflow.fastapi import Serve
    from upstash_workflow import AsyncWorkflowContext

    app = FastAPI()
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @serve.post("/sleep")
    async def sleep(context: AsyncWorkflowContext[str]) -> None:
        input = context.request_payload

        async def _step1() -> str:
            output = some_work(input)
            print("step 1 input", input, "output", output)
            return output

        result1: str = await context.run("step1", _step1)

        await context.sleep_until("sleep1", time.time() + 3)

        async def _step2() -> str:
            output = some_work(result1)
            print("step 2 input", result1, "output", output)
            return output

        result2: str = await context.run("step2", _step2)

        await context.sleep("sleep2", 2)

        async def _step3() -> None:
            output = some_work(result2)
            print("step 3 input", result2, "output", output)

        await context.run("step3", _step3)

    ```
  </Tab>

  <Tab title="Call">
    ```python main.py theme={"system"}
    from fastapi import FastAPI
    from typing import Dict
    from upstash_workflow.fastapi import Serve
    from upstash_workflow import AsyncWorkflowContext, CallResponse

    app = FastAPI()
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @app.post("/get-data")
    async def get_data() -> Dict[str, str]:
        return {"message": "get data response"}


    @serve.post("/call")
    async def call(context: AsyncWorkflowContext[str]) -> None:
        input = context.request_payload

        async def _step1() -> str:
            output = some_work(input)
            print("step 1 input", input, "output", output)
            return output

        result1: str = await context.run("step1", _step1)

        response: CallResponse[Dict[str, str]] = await context.call(
            "get-data",
            url=f"{context.env.get('UPSTASH_WORKFLOW_URL', 'http://localhost:8000')}/get-data",
            method="POST",
            body={"message": result1},
        )

        async def _step2() -> str:
            output = some_work(response.body["message"])
            print("step 2 input", response, "output", output)
            return output

        await context.run("step2", _step2)

    ```
  </Tab>

  <Tab title="Auth">
    ```python main.py theme={"system"}
    from fastapi import FastAPI
    from upstash_workflow.fastapi import Serve
    from upstash_workflow import AsyncWorkflowContext

    app = FastAPI()
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @serve.post("/auth")
    async def auth(context: AsyncWorkflowContext[str]) -> None:
        if context.headers.get("authentication") != "Bearer secret_password":
            print("Authentication failed.")
            return

        async def _step1() -> str:
            return "output 1"

        await context.run("step1", _step1)

        async def _step2() -> str:
            return "output 2"

        await context.run("step2", _step2)

    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

Don't forget to source your environment file to set your environment variables:

```bash Terminal theme={"system"}
source .env
```

After setting your live URL as the environment variable or `base_url` option, trigger your workflow by first starting your FastAPI app:

```bash Terminal theme={"system"}
uvicorn main:app --reload
```

and then making a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:8000/api/workflow

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4f2cbb67caa1985c680629d89c96fca4" data-og-width="1737" width="1737" data-og-height="634" height="634" data-path="img/qstash-workflow/nextjs_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f41c789c5b932b1f055c0e268e5b9605 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=22cbc44e0f95850cc384949d6f7d89ae 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c87b767a909164536ed792b237ab7cb2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=42d2f62728e193974c5cec61189918fa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e1fabf80bcfe0aa313e60c593f807356 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1b5e61b1b8b06d07a84ac2f5f34810b0 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-py/tree/master/examples/fastapi) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Flask
Source: https://upstash.com/docs/workflow/quickstarts/flask



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-py/tree/master/examples/flask" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use Upstash Workflow with Flask. You can also explore [the source code](https://github.com/upstash/workflow-py/tree/master/examples/flask) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Python and pip installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, create a new directory and set up a virtual environment:

```bash  theme={"system"}
python -m venv venv
source venv/bin/activate
```

Then, install the Workflow SDK and Flask:

```bash  theme={"system"}
pip install fastapi uvicorn upstash-workflow
```

## Step 2: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```bash .env theme={"system"}
export QSTASH_URL="http://127.0.0.1:8080"
export QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```bash .env theme={"system"}
export QSTASH_TOKEN="***"
export UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint in a Flask project, create a `main.py` file that contains your workflow:

<Tabs>
  <Tab title="Example">
    ```python main.py theme={"system"}
    from flask import Flask
    from upstash_workflow.flask import Serve

    app = Flask(__name__)
    serve = Serve(app)


    @serve.route("/api/workflow")
    def workflow(context) -> None:
        def _step1() -> None:
            print("initial step ran")

        context.run("initial-step", _step1)

        def _step2() -> None:
            print("second step ran")

        context.run("second-step", _step2)

    ```
  </Tab>

  <Tab title="Sleep">
    ```python main.py theme={"system"}
    from flask import Flask
    import time
    from upstash_workflow.flask import Serve
    from upstash_workflow import WorkflowContext

    app = Flask(__name__)
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @serve.route("/sleep")
    def sleep(context: WorkflowContext[str]) -> None:
        input = context.request_payload

        def _step1() -> str:
            output = some_work(input)
            print("step 1 input", input, "output", output)
            return output

        result1: str = context.run("step1", _step1)

        context.sleep_until("sleep1", time.time() + 3)

        def _step2() -> str:
            output = some_work(result1)
            print("step 2 input", result1, "output", output)
            return output

        result2: str = context.run("step2", _step2)

        context.sleep("sleep2", 2)

        def _step3() -> None:
            output = some_work(result2)
            print("step 3 input", result2, "output", output)

        context.run("step3", _step3)

    ```
  </Tab>

  <Tab title="Call">
    ```python main.py theme={"system"}
    from flask import Flask
    from typing import Dict
    from upstash_workflow.flask import Serve
    from upstash_workflow import WorkflowContext, CallResponse

    app = Flask(__name__)
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @app.route("/get-data", methods=["POST"])
    def get_data() -> Dict[str, str]:
        return {"message": "get data response"}


    @serve.route("/call")
    def call(context: WorkflowContext[str]) -> None:
        input = context.request_payload

        def _step1() -> str:
            output = some_work(input)
            print("step 1 input", input, "output", output)
            return output

        result1: str = context.run("step1", _step1)

        response: CallResponse[Dict[str, str]] = context.call(
            "get-data",
            url=f"{context.env.get('UPSTASH_WORKFLOW_URL', 'http://localhost:8000')}/get-data",
            method="POST",
            body={"message": result1},
        )

        def _step2() -> str:
            output = some_work(response.body["message"])
            print("step 2 input", response, "output", output)
            return output

        context.run("step2", _step2)

    ```
  </Tab>

  <Tab title="Auth">
    ```python main.py theme={"system"}
    from flask import Flask
    from upstash_workflow.flask import Serve
    from upstash_workflow import WorkflowContext

    app = Flask(__name__)
    serve = Serve(app)


    def some_work(input: str) -> str:
        return f"processed '{input}'"


    @serve.route("/auth")
    def auth(context: WorkflowContext[str]) -> None:
        if context.headers.get("Authentication") != "Bearer secret_password":
            print("Authentication failed.")
            return

        def _step1() -> str:
            return "output 1"

        context.run("step1", _step1)

        def _step2() -> str:
            return "output 2"

        context.run("step2", _step2)

    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

Don't forget to source your environment file to set your environment variables:

```bash Terminal theme={"system"}
source .env
```

After setting your live URL as the environment variable or `base_url` option, trigger your workflow by first starting your Flask app:

```bash Terminal theme={"system"}
flask --app main run -p 8000
```

and then making a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:8000/api/workflow

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4f2cbb67caa1985c680629d89c96fca4" data-og-width="1737" width="1737" data-og-height="634" height="634" data-path="img/qstash-workflow/nextjs_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f41c789c5b932b1f055c0e268e5b9605 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=22cbc44e0f95850cc384949d6f7d89ae 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c87b767a909164536ed792b237ab7cb2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=42d2f62728e193974c5cec61189918fa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e1fabf80bcfe0aa313e60c593f807356 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1b5e61b1b8b06d07a84ac2f5f34810b0 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore our [the source code](https://github.com/upstash/workflow-py/tree/master/examples/flask) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Hono
Source: https://upstash.com/docs/workflow/quickstarts/hono



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/hono" horizontal>
  You can find the project source code on GitHub.
</Card>

<Card title="Deploy With Cloudflare Workers" icon="cloudflare" href="https://deploy.workers.cloudflare.com/?url=https://github.com/upstash/qstash-workflow-example-cloudflare-workers-hono" horizontal>
  Deploy the project to Cloudflare Workers with a single click.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with Hono. You can also explore our [Hono example](https://github.com/upstash/workflow-js/tree/main/examples/hono) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your Hono project:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.dev.vars` file in your project root and add your QStash token. This key is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .dev.vars
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.dev.vars` file:

```txt .dev.vars theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.dev.vars` file with the following:

```txt .dev.vars theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint with Hono, navigate into your entrypoint file (usually `src/index.ts`) and add the following code:

<Tabs>
  <Tab title="Minimal example">
    ```typescript src/index.ts theme={"system"}
    import { Hono } from "hono"
    import { serve } from "@upstash/workflow/hono"

    const app = new Hono()

    app.post("/workflow",
      serve(async (context) => {
        await context.run("initial-step", () => {
          console.log("initial step ran")
        })

        await context.run("second-step", () => {
          console.log("second step ran")
        })
      })
    )

    export default app
    ```
  </Tab>

  <Tab title="With Hono context">
    ```typescript src/index.ts theme={"system"}
    import { Hono } from "hono"
    import { serve, WorkflowBindings } from "@upstash/workflow/hono"
    import { env } from "hono/adapter"

    interface Bindings extends WorkflowBindings {
      ENVIRONMENT: "development" | "production"
    }

    const app = new Hono<{ Bindings: Bindings }>()

    app.post("/workflow", (c) => {
      // üëá access Honos native context, i.e. getting an env variable
      const { ENVIRONMENT } = env(c)

      // üëá `unknown` represents your initial payload data type
      const handler = serve<unknown, Bindings>(
        async (context) => { ... }
      )

      return await handler(c)
    })

    export default app
    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

To start your Hono app locally, run the following command:

```bash Terminal theme={"system"}
npm run dev
```

Executing this command prints a local URL to your workflow endpoint. By default, this URL is `http://localhost:8787`.

You can verify your correct environment variable setup by checking the wrangler output, which should now have access to your `QSTASH_TOKEN` binding and log your local URL:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=707cec511359835449c86699cb91de29" data-og-width="1122" width="1122" data-og-height="524" height="524" data-path="img/qstash-workflow/wrangler.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0015387b2cb15a57dc551aa28a97eb5a 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=fefc9cb350d93dcc2ba2ae75af33444a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=76795e5a692e024263b10123c4df1aa4 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=0b95c822fdf5022159caa4bcdfe4f6cc 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1e347cb36ad119611d338dd3e7497c4d 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/wrangler.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e2a023d8ab3f3a7fc0d9eee18ba2ed37 2500w" />
</Frame>

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:8787/workflow

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e53201dceb3377bf5c88b05740dddc42" data-og-width="1756" width="1756" data-og-height="639" height="639" data-path="img/qstash-workflow/hono_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b4276f2a50adecd8bdd9b63aba46fbf8 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=69118bcc896aa763bb8198dbb43a3d4a 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=494c2945791820c0c6a31146d0d0a370 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=952eb9a090da2d2ca0d2b75941fccc42 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=18d4dbbadacea16dae211bf39dc87de9 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/hono_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6825103f01f307dfc2849ea21c1deacb 2500w" />
</Frame>

If you didn't set up local QStash development server, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your Hono app with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables from your `.dev.vars` file are set in your Cloudflare Worker project settings. For example, your `QSTASH_TOKEN`, and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your Hono app to production as you normally would, for example using the Cloudflare CLI:

   ```bash Terminal theme={"system"}
   wrangler deploy
   ```

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

   ```bash Terminal theme={"system"}
   curl -X POST https://<YOUR-PRODUCTION-URL>/workflow
   ```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/hono) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Next.js & FastAPI
Source: https://upstash.com/docs/workflow/quickstarts/nextjs-fastapi



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-py/tree/master/examples/nextjs-fastapi" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with Next.js & FastAPI. You can also explore [the source code](https://github.com/upstash/workflow-py/tree/master/examples/nextjs-fastapi) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (or another package manager) installed.
3. Python and pip installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Setup

Clone the [Next.js & FastAPI example](https://github.com/upstash/workflow-py/tree/master/examples/nextjs-fastapi):

```bash  theme={"system"}
git clone https://github.com/upstash/workflow-py.git
cd workflow-py/examples/nextjs-fastapi
```

## Step 2: Installation

Create a virtual environment and activate it:

```bash Terminal theme={"system"}
python -m venv venv
source venv/bin/activate
```

Install the dependencies:

```bash  theme={"system"}
npm install
```

## Step 3: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```bash .env theme={"system"}
export QSTASH_URL="http://127.0.0.1:8080"
export QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```bash .env theme={"system"}
export QSTASH_TOKEN="***"
export UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 4: Start the Development Server

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), and QStash needs a publicly accessible URL to run your workflows. Here's how to [set up your workflow endpoint for local development](/workflow/howto/local-development).

In a nutshell, in local development, you can either use the QStash development server or use a local tunnel to make your workflow endpoint publicly accessible.

Don't forget to source your environment file to set your environment variables:

```bash Terminal theme={"system"}
source .env
```

After defining the endpoint, you can trigger your workflow by starting your app:

```bash Terminal theme={"system"}
npm run dev
```

Navigate to [http://localhost:3000](http://localhost:3000) to see your Next.js app in action.
FastAPI will be running on [http://localhost:8000](http://localhost:8000).

<Frame>
  <img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=b7edc924355a9e8bf65e098796250bf6" data-og-width="2880" width="2880" data-og-height="1554" height="1554" data-path="img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=7cc6dda64c2c28ece85b1e7e97a45a1d 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=c7663bd8f2b05fa4cb2cf6fbfa98e010 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=a8c125c57f05efd9e7c602232abdd14b 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=59b255e6e39b9b38b4d1566c4dcf5ece 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=96845f903d22b7dbece95b9105a46522 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=251e147ef824ddd40aa28dcef3e5ed15 2500w" />
</Frame>

## Step 5: Deploying the Project at Vercel

To deploy the project at vercel and try the endpoints, you should start with setting up the project by running:

```bash Terminal theme={"system"}
vercel
```

Next, you shoud go to vercel.com, find your project and add `QSTASH_TOKEN`, to the project as environment variables. You can find this env variables from the [Upstash Console](https://console.upstash.com/qstash). To learn more about other env variables and their use in the context of Upstash Workflow, you can read [the Secure your Endpoint in our documentation](/workflow/howto/security#using-qstashs-built-in-request-verification-recommended).

Once you add the env variables, you can deploy the project with:

```bash Terminal theme={"system"}
vercel --prod
```

Note that the project won't work in preview. It should be deployed to production like above. This is because preview requires authentication.

Once you have the app deployed, you can go to the deployment and call the endpoints using the form on the page.

You can observe the logs at [Upstash console under the Worfklow tab](https://console.upstash.com/qstash?tab=workflow) or vercel.com to see your workflow operate.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore \[the source code]\([https://github.com/upstash/workflow-js/tree/main/examples/nextjs-fastapi](https://github.com/upstash/workflow-js/tree/main/examples/nextjs-fastapi) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Next.js & Flask
Source: https://upstash.com/docs/workflow/quickstarts/nextjs-flask



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-py/tree/master/examples/nextjs-flask" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with Next.js & Flask. You can also explore [the source code](https://github.com/upstash/workflow-py/tree/master/examples/nextjs-flask) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (or another package manager) installed.
3. Python and pip installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Setup

Clone the [Next.js & Flask example](https://github.com/upstash/workflow-py/tree/master/examples/nextjs-flask):

```bash  theme={"system"}
git clone https://github.com/upstash/workflow-py.git
cd workflow-py/examples/nextjs-flask
```

## Step 2: Installation

Create a virtual environment and activate it:

```bash Terminal theme={"system"}
python -m venv venv
source venv/bin/activate
```

Install the dependencies:

```bash  theme={"system"}
npm install
```

## Step 3: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```bash .env theme={"system"}
export QSTASH_URL="http://127.0.0.1:8080"
export QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```bash .env theme={"system"}
export QSTASH_TOKEN="***"
export UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 4: Start the Development Server

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), and QStash needs a publicly accessible URL to run your workflows. Here's how to [set up your workflow endpoint for local development](/workflow/howto/local-development).

In a nutshell, in local development, you can either use the QStash development server or use a local tunnel to make your workflow endpoint publicly accessible.

Don't forget to source your environment file to set your environment variables:

```bash Terminal theme={"system"}
source .env
```

After defining the endpoint, you can trigger your workflow by starting your app:

```bash  theme={"system"}
npm run dev
```

Navigate to [http://localhost:3000](http://localhost:3000) to see your Next.js app in action.
Flask will be running on [http://localhost:8000](http://localhost:8000).

<Frame>
  <img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=b7edc924355a9e8bf65e098796250bf6" data-og-width="2880" width="2880" data-og-height="1554" height="1554" data-path="img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=7cc6dda64c2c28ece85b1e7e97a45a1d 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=c7663bd8f2b05fa4cb2cf6fbfa98e010 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=a8c125c57f05efd9e7c602232abdd14b 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=59b255e6e39b9b38b4d1566c4dcf5ece 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=96845f903d22b7dbece95b9105a46522 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/quickstarts/nextjs-fastapi/workflow-nextjs-fastapi.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=251e147ef824ddd40aa28dcef3e5ed15 2500w" />
</Frame>

## Step 5: Deploying the Project at Vercel

To deploy the project at vercel and try the endpoints, you should start with setting up the project by running:

```bash Terminal theme={"system"}
vercel
```

Next, you shoud go to vercel.com, find your project and add `QSTASH_TOKEN`, to the project as environment variables. You can find this env variables from the [Upstash Console](https://console.upstash.com/qstash). To learn more about other env variables and their use in the context of Upstash Workflow, you can read [the Secure your Endpoint in our documentation](/workflow/howto/security#using-qstashs-built-in-request-verification-recommended).

Once you add the env variables, you can deploy the project with:

```bash Terminal theme={"system"}
vercel --prod
```

Note that the project won't work in preview. It should be deployed to production like above. This is because preview requires authentication.

Once you have the app deployed, you can go to the deployment and call the endpoints using the form on the page.

You can observe the logs at [Upstash console under the Worfklow tab](https://console.upstash.com/qstash?tab=workflow) or vercel.com to see your workflow operate.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/nextjs-flask) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Nuxt
Source: https://upstash.com/docs/workflow/quickstarts/nuxt



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/nuxt" horizontal>
  You can find the project source code on GitHub.
</Card>

<Card title="Deploy With Vercel" icon="triangle" iconType="sharp-solid" href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fupstash%2Fworkflow-js%2Ftree%2Fmain%2Fworkflow%2Fnuxt&env=QSTASH_TOKEN&envDescription=You%20can%20access%20this%20variable%20from%20Upstash%20Console%2C%20under%20QStash%20page.%20&project-name=workflow-nuxt&repository-name=workflow-nuxt&demo-title=Upstash%20Workflow%20Example&demo-description=A%20Nuxt%20application%20utilizing%20Upstash%20Workflow" horizontal>
  Deploy the project to Vercel with a single click.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with Nuxt.js. You can also explore our [Nuxt example](https://github.com/upstash/workflow-js/tree/main/examples/nuxt) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your Nuxt project:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.env.local` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env.local
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env.local` file:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env.local` file with the following:

```txt  theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint in a Nuxt.js project, navigate into the Nuxt.js `server/api` directory and create a new file, for example called `workflow.ts`. This file will contain your workflow:

```typescript server/api/workflow.ts theme={"system"}
import { serve } from "@upstash/workflow/h3"

const { handler } = serve(
  async (context) => {
    await context.run("initial-step", () => {
      console.log("initial step ran")
    })

    await context.run("second-step", () => {
      console.log("second step ran")
    })
  },
)

export default handler;
```

## Step 4: Run the Workflow Endpoint

After defining the endpoint, you can trigger your workflow by starting your app:

```bash Terminal theme={"system"}
npm run dev
```

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:3000/api/workflow

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4f2cbb67caa1985c680629d89c96fca4" data-og-width="1737" width="1737" data-og-height="634" height="634" data-path="img/qstash-workflow/nextjs_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f41c789c5b932b1f055c0e268e5b9605 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=22cbc44e0f95850cc384949d6f7d89ae 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c87b767a909164536ed792b237ab7cb2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=42d2f62728e193974c5cec61189918fa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e1fabf80bcfe0aa313e60c593f807356 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1b5e61b1b8b06d07a84ac2f5f34810b0 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your Nuxt.js application with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables are set in your platforms project settings. For example, your `QSTASH_TOKEN` and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your Nuxt application to Vercel, Cloudflare Pages or other platforms as you normally would. These platforms will automatically detect and build your Nuxt application.

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

   ```bash Terminal theme={"system"}
   curl -X POST https://<YOUR-PRODUCTION-URL>/api/workflow
   ```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/nuxt) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# Supported Platforms
Source: https://upstash.com/docs/workflow/quickstarts/platforms



Upstash Workflow natively supports the following platforms:

### Javascript / Typescript

<Columns cols={3}>
  <Card href="/workflow/quickstarts/vercel-nextjs">
    **Next.js**
  </Card>

  <Card href="/workflow/quickstarts/cloudflare-workers">
    **Cloudflare Workers**
  </Card>

  <Card href="/workflow/quickstarts/nuxt">
    **Nuxt (H3)**
  </Card>

  <Card href="/workflow/quickstarts/solidjs">
    **Solid.js**
  </Card>

  <Card href="/workflow/quickstarts/svelte">
    **Svelte**
  </Card>

  <Card href="/workflow/quickstarts/hono">
    **Hono**
  </Card>

  <Card href="/workflow/quickstarts/express">
    **Express.js**
  </Card>

  <Card href="/workflow/quickstarts/astro">
    **Astro**
  </Card>

  <Card href="/workflow/quickstarts/tanstack-start">
    **TanStack Start**
  </Card>
</Columns>

### Python

<Columns cols={4}>
  <Card href="/workflow/quickstarts/fastapi">
    **FastAPI**
  </Card>

  <Card href="/workflow/quickstarts/nextjs-fastapi">
    **Next.js & FastAPI**
  </Card>

  <Card href="/workflow/quickstarts/flask">
    **Flask**
  </Card>

  <Card href="/workflow/quickstarts/nextjs-flask">
    **Next.js & Flask**
  </Card>
</Columns>

## Using Upstash Workflow with another platform

If you'd like to use Upstash Workflow for a platform not listed above, you can do so using the base `serve` method:

<CodeGroup>
  ```javascript TypeScript theme={"system"}
  import { serve } from "@upstash/workflow";
  ```

  ```python Python theme={"system"}
  from upstash_workflow import serve, async_serve
  ```
</CodeGroup>

and adjust this method for your platform. For details, see our platform-specific method implementations in [Javascript](https://github.com/upstash/workflow-js/tree/main/platforms) or [Python](https://github.com/upstash/workflow-py/tree/master/upstash_workflow).


# SolidJS
Source: https://upstash.com/docs/workflow/quickstarts/solidjs



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/solidjs" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflows with SolidJS. You can also explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/solidjs) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your SolidJS project:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.env` file in your project root and add your QStash token. This key is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env` file:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env` file with the following:

```txt  theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint in a SolidJS project, navigate into the SolidJS `routes/api` directory. Inside this folder, create a `workflow.ts` file that contains your workflow:

```typescript routes/api/workflow.ts theme={"system"}
import { serve } from "@upstash/workflow/solidjs"

export const { POST } = serve(async (context) => {
  await context.run("initial-step", () => {
    console.log("initial step ran")
  })

  await context.run("second-step", () => {
    console.log("second step ran")
  })
})
```

## Step 4: Run the Workflow Endpoint

After defining the endpoint, you can trigger your workflow by starting your app:

```bash Terminal theme={"system"}
npm run dev
```

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:3000/api/workflow

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4f2cbb67caa1985c680629d89c96fca4" data-og-width="1737" width="1737" data-og-height="634" height="634" data-path="img/qstash-workflow/nextjs_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f41c789c5b932b1f055c0e268e5b9605 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=22cbc44e0f95850cc384949d6f7d89ae 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c87b767a909164536ed792b237ab7cb2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=42d2f62728e193974c5cec61189918fa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e1fabf80bcfe0aa313e60c593f807356 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1b5e61b1b8b06d07a84ac2f5f34810b0 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your SolidJS application with Upstash Workflows to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables are set in your platforms project settings. For example, your `QSTASH_TOKEN` and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your SolidJS application to Netlify, Vercel or other platforms as you normally would. These platforms will automatically detect and build your SolidJS application.

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

   ```bash Terminal theme={"system"}
   curl -X POST https://<YOUR-PRODUCTION-URL>/api/workflow
   ```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/solidjs) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# SvelteKit
Source: https://upstash.com/docs/workflow/quickstarts/svelte



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/sveltekit" horizontal>
  You can find the project source code on GitHub.
</Card>

<Card title="Deploy With Vercel" icon="triangle" iconType="sharp-solid" href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fupstash%2Fworkflow-js%2Ftree%2Fmain%2Fworkflow%2Fsveltekit&env=QSTASH_TOKEN&envDescription=You%20can%20access%20this%20variable%20from%20Upstash%20Console%2C%20under%20QStash%20page.%20&project-name=workflow-sveltekit&repository-name=workflow-sveltekit&demo-title=Upstash%20Workflow%20Example&demo-description=A%20Svelte%20application%20utilizing%20Upstash%20Workflow" horizontal>
  Deploy the project to Vercel with a single click.
</Card>

This guide provides detailed, step-by-step instructions on how to use and deploy Upstash Workflow with SvelteKit. You can also explore our [SvelteKit example](https://github.com/upstash/workflow-js/tree/main/examples/sveltekit) for a detailed, end-to-end example and best practices.

## Prerequisites

1. An Upstash QStash API key.
2. Node.js and npm (another package manager) installed.

If you haven't obtained your QStash API key yet, you can do so by [signing up](https://console.upstash.com/login) for an Upstash account and navigating to your QStash dashboard.

## Step 1: Installation

First, install the Workflow SDK in your SvelteKit project:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Configure Environment Variables

Create a `.env.local` file in your project root and add your QStash token. This token is used to authenticate your application with the QStash service.

```bash Terminal theme={"system"}
touch .env.local
```

Upstash Workflow is powered by [QStash](/qstash/overall/getstarted), which requires access to your endpoint to execute workflows. When your app is deployed, QStash will use the app's URL. However, for local development, you have two main options: [use a local QStash server or set up a local tunnel](/workflow/howto/local-development).

### Option 1: Local QStash Server

To start the local QStash server, run:

```bash  theme={"system"}
npx @upstash/qstash-cli dev
```

Once the command runs successfully, you‚Äôll see `QSTASH_URL` and `QSTASH_TOKEN` values in the console. Add these values to your `.env.local` file:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="<QSTASH_TOKEN>"
```

This approach allows you to test workflows locally without affecting your billing. However, runs won't be logged in the Upstash Console.

### Option 2: Local Tunnel

Alternatively, you can set up a local tunnel. For this option:

1. Copy the `QSTASH_TOKEN` from the Upstash Console.
2. Update your `.env.local` file with the following:

```txt  theme={"system"}
QSTASH_TOKEN="***"
UPSTASH_WORKFLOW_URL="<UPSTASH_WORKFLOW_URL>"
```

* Replace `***` with your actual QStash token.
* Set `UPSTASH_WORKFLOW_URL` to the public URL provided by your local tunnel.

Here‚Äôs where you can find your QStash token:

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=df12ba48119bcdd13a675e53b43ab74d" data-og-width="1211" width="1211" data-og-height="833" height="833" data-path="img/qstash-workflow/qstash_token.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c251f0eeb0a6973ff498f9e9930aed70 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=d452c08e1a638dff258d938aa8544f25 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=6b197538fe5190c7936b751ec228ef39 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=63da8b3df03c88ff0a7700af7a5db6fb 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=8df98665037cf63deb6b48d5c22d3f6b 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/qstash_token.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=b3ef0ab4137bdec59b7cb772550933e1 2500w" />
</Frame>

Using a local tunnel connects your endpoint to the production QStash, enabling you to view workflow logs in the Upstash Console.

## Step 3: Create a Workflow Endpoint

A workflow endpoint allows you to define a set of steps that, together, make up a workflow. Each step contains a piece of business logic that is automatically retried on failure, with easy monitoring via our visual workflow dashboard.

To define a workflow endpoint, navigate into SvelteKit's `routes/api` directory and create a new folder, for example called `workflow`. Inside this folder, create a `+server.ts` file that contains your workflow:

```typescript routes/api/workflow/+server.ts theme={"system"}
import { serve } from "@upstash/workflow/svelte"
import { env } from "$env/dynamic/private"

export const { POST } = serve(
  async (context) => {
    await context.run("initial-step", () => {
      console.log("initial step ran")
    })

    await context.run("second-step", () => {
      console.log("second step ran")
    })
  },
  { env }
)
```

## Step 4: Run the Workflow Endpoint

After defining the endpoint, you can trigger your workflow by starting your app:

```bash Terminal theme={"system"}
npm run dev
```

Then, make a POST request to your workflow endpoint. For each workflow run, a unique workflow run ID is returned:

```bash Terminal theme={"system"}
curl -X POST https://localhost:5000/api/workflow \
     -H "content-type: application/json"

# result: {"workflowRunId":"wfr_xxxxxx"}
```

See the [documentation on starting a workflow](/workflow/howto/start) for other ways you can start your workflow.

<Frame>
  <img src="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=4f2cbb67caa1985c680629d89c96fca4" data-og-width="1737" width="1737" data-og-height="634" height="634" data-path="img/qstash-workflow/nextjs_local_request.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=280&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=f41c789c5b932b1f055c0e268e5b9605 280w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=560&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=22cbc44e0f95850cc384949d6f7d89ae 560w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=840&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=c87b767a909164536ed792b237ab7cb2 840w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1100&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=42d2f62728e193974c5cec61189918fa 1100w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=1650&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=e1fabf80bcfe0aa313e60c593f807356 1650w, https://mintcdn.com/upstash/V1WwT580M-elE8rq/img/qstash-workflow/nextjs_local_request.png?w=2500&fit=max&auto=format&n=V1WwT580M-elE8rq&q=85&s=1b5e61b1b8b06d07a84ac2f5f34810b0 2500w" />
</Frame>

If you are using a local tunnel, you can use this ID to track the workflow run and see its status in your QStash workflow dashboard. All steps are listed with their statuses, headers, and body for a detailed overview of your workflow from start to finish. Click on a step to see its detailed logs.

<Frame>
  <img src="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=d62fa91b9bcfc9c845105c42dae6f1e0" data-og-width="1656" width="1656" data-og-height="1080" height="1080" data-path="img/qstash-workflow/dashboard.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=280&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8b59e83f0dc4ac843391ad758f34f0e8 280w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=560&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=000f796c9f6977bd9918ffcb657fbee3 560w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=840&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=8609b0c44963e73b7be7b1eac2f855bf 840w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1100&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=2a37385f1f54c7ed8597051b02dfb783 1100w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=1650&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=b2b4cdfe944c486ed4c73078c2509222 1650w, https://mintcdn.com/upstash/pqZtv0gXFMQuy8rU/img/qstash-workflow/dashboard.png?w=2500&fit=max&auto=format&n=pqZtv0gXFMQuy8rU&q=85&s=c3a84ffafdd7cbe5b00be4e435dacf84 2500w" />
</Frame>

## Step 5: Deploying to Production

When deploying your SvelteKit application with Upstash Workflow to production, there are a few key points to keep in mind:

1. **Environment Variables**: Make sure that all necessary environment variables are set in your platforms project settings. For example, your `QSTASH_TOKEN` and any other configuration variables your workflow might need.

2. **Remove Local Development Settings**: In your production code, you can remove or conditionally exclude any local development settings. For example, if you used [local tunnel for local development](/workflow/howto/local-development#local-tunnel-with-ngrok)

3. **Deployment**: Deploy your app to Vercel, Netlify or other platforms as you normally would. These platforms will automatically detect and build your SvelteKit application.

4. **Verify Workflow Endpoint**: After deployment, verify that your workflow endpoint is accessible by making a POST request to your production URL:

   ```bash Terminal theme={"system"}
   curl -X POST https://<YOUR-PRODUCTION-URL>/api/workflow
   ```

5. **Monitor in QStash Dashboard**: Use the QStash dashboard to monitor your production workflows. You can track workflow runs, view step statuses, and access detailed logs.

6. **Set Up Alerts**: Consider setting up alerts in Sentry or other monitoring tools to be notified of any workflow failures in production.

## Next Steps

1. Learn how to protect your workflow endpoint from unauthorized access by [securing your workflow endpoint](/workflow/howto/security).

2. Explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/sveltekit) for a detailed, end-to-end example and best practices.

3. For setting up and testing your workflows in a local environment, check out our [local development guide](/workflow/howto/local-development).


# TanStack Start
Source: https://upstash.com/docs/workflow/quickstarts/tanstack-start



<Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/tanstack-start" horizontal>
  You can find the project source code on GitHub.
</Card>

This guide provides detailed, step-by-step instructions on how to use Upstash Workflow with TanStack Start. You can also explore [the source code](https://github.com/upstash/workflow-js/tree/main/examples/tanstack-start) for a detailed, end-to-end example and best practices.

## Prerequisites

* Node.js and pnpm installed.

You can integrate Upstash Workflow into an existing TanStack Start app, or create a new TanStack Start project from scratch.

## Step 1: Create a new TanStack Start project

Run the following command to create a new TanStack Start project:

```bash  theme={"system"}
pnpm create @tanstack/start@latest
```

Navigate to the project directory:

```bash  theme={"system"}
cd your-project-name
```

## Step 2: Installation

Run the following command to install the Upstash Workflow SDK in your TanStack Start app.

<Tabs>
  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 3: Run the development server

Upstash Workflow is built on top of Upstash QStash.

In a production environment, your application connects to the managed QStash servers hosted by Upstash.
This ensures that requests are delivered reliably, securely, and at scale without requiring you to run and maintain your own infrastructure.

For local development, you don't need to depend on the managed QStash servers. Instead, you can run a local QStash server directly on your machine.
This local server behaves just like the production version but does not require external network calls.

Start the local server with:

<Tabs>
  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpx @upstash/qstash-cli dev
    ```
  </Tab>

  <Tab title="npm">
    ```bash  theme={"system"}
    npx @upstash/qstash-cli dev
    ```
  </Tab>
</Tabs>

When the server starts, it will print the credentials.
You'll need these values in the next step to connect your TanStack Start app to QStash.

You can enable local mode in the Upstash Workflow dashboard to use the UI while developing locally.

<Frame>
  <img src="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=894b9d6a3d2dff99bed21683c3c01cd7" alt="Enable local mode on dashboard" data-og-width="2758" width="2758" data-og-height="1864" height="1864" data-path="img/qstash-workflow/local-dev.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=280&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=c408f8a396e346fc6bf86ce33f6453aa 280w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=560&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=b7c0049c3a1839305582c18b129192a5 560w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=840&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=85086a3a005d121cf4051e3ac405b1b0 840w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=1100&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=ba2c2aeb93018bf368c662d6424fc52d 1100w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=1650&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=35927ba49e0412a5658b869ee582b0c1 1650w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=2500&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=8f4dd395f0da6319f1d412b654749366 2500w" />
</Frame>

## Step 4: Configure Environment Variables

Next, you need to configure your TanStack Start app to connect with the local QStash server by setting environment variables.

In the root of your project, create a `.env` file (or update your existing one) and add the values printed by the QStash local server:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0="
QSTASH_CURRENT_SIGNING_KEY="sig_7kYjw48mhY7kAjqNGcy6cr29RJ6r"
QSTASH_NEXT_SIGNING_KEY="sig_5ZB6DVzB1wjE8S6rZ7eenA8Pdnhs"
```

<Tip>
  For production, replace these with your actual credentials from the Upstash Workflow dashboard.
</Tip>

## Step 5: Create a Workflow Endpoint

With your environment ready, the next step is to define your first workflow endpoint.

In Upstash Workflow, every workflow is exposed as an endpoint.
Every endpoint you expose using the SDK's `serve()` function acts as a workflow that can be triggered independently.

In TanStack Start, these endpoints are implemented as **API routes** using the file-based routing system.

Create a new file `src/routes/api/workflow.ts`:

```typescript src/routes/api/workflow.ts theme={"system"}
import { createFileRoute } from '@tanstack/react-router'
import { serve } from '@upstash/workflow/tanstack'

const someWork = (input: string) => {
  return `processed '${JSON.stringify(input)}'`
}

export const Route = createFileRoute('/api/workflow')({
  server: {
    handlers: serve<string>(async (context) => {
      const input = context.requestPayload
      
      const result1 = await context.run('step1', () => {
        const output = someWork(input)
        console.log('step 1 input', input, 'output', output)
        return output
      })

      await context.run('step2', () => {
        const output = someWork(result1)
        console.log('step 2 input', result1, 'output', output)
      })
    }),
  },
})
```

## Step 6: Start your TanStack Start app

Start your TanStack Start development server:

<Tabs>
  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm dev
    ```
  </Tab>

  <Tab title="npm">
    ```bash  theme={"system"}
    npm run dev
    ```
  </Tab>
</Tabs>

Your app should now be running on `http://localhost:3000`.

## Step 7: Run the Workflow Endpoint

Once your endpoint is defined, the next step is to trigger a workflow run.

You can start a new workflow run using the `trigger()` function from the Upstash Workflow SDK.

```javascript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = Client()

const { workflowRunId } = await client.trigger({
  url: `http://localhost:3000/api/workflow`,
  body: "Hello World!",
  retries: 3,
  keepTriggerConfig: true,
});
```

<Info>
  The `trigger()` function should typically be called from a server-side action (not directly in client-side code) to keep your credentials secure.
</Info>

Check the Upstash Workflow dashboard to view logs of your workflow run:

<Frame>
  <img src="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=e3f20497f5d50f6bfec30b4ed8ee90ff" alt="Debug a workflow run on UI" data-og-width="2758" width="2758" data-og-height="1864" height="1864" data-path="img/qstash-workflow/run-view.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=280&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=96c8fe0b3cb3662f3e41398a382cecbf 280w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=560&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=14594dfb7ed28e821056fabb40097a70 560w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=840&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=8f1b7a01cea89106d227d1d0372a1cc2 840w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=1100&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=9af11ef94799753afbd2c1c0953e76c3 1100w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=1650&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=be5d6a683aabc669a23a571e9c32bf1a 1650w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=2500&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=5e629fdf6f7dec028a97a9ce467030ba 2500w" />
</Frame>

<Tip>
  Inside the `trigger()` call, you need to provide the URL of your workflow endpoint:

  * Local development ‚Üí use the URL where your app is running, for example: [http://localhost:3000/api/workflow](http://localhost:3000/api/workflow)
  * Production ‚Üí use the URL of your deployed app, for example: [https://yourapp.com/api/workflow](https://yourapp.com/api/workflow)

  To avoid hardcoding URLs, you can define a `BASE_URL` constant and set it based on the environment:

  ```javascript  theme={"system"}
  const BASE_URL = process.env.NODE_ENV === 'production'
    ? 'https://yourapp.com'
    : 'http://localhost:3000'

  const { workflowRunId } = await client.trigger({
    url: `${BASE_URL}/api/workflow`,
    body: "Hello World!",
    retries: 3,
    keepTriggerConfig: true,
  });
  ```
</Tip>

## Next Steps

Now that you've created your first workflow, here are some recommended guides to continue learning:

1. **[Learn the Workflow API](/workflow/basics/context)**: Dive deeper into the full API surface and advanced capabilities.

2. **[Configure Workflow Runs](/workflow/basics/client)**: Learn how to configure workflow execution to fit your app's needs.

3. **[Handle Failures](/workflow/howto/failures)**: Understand how to detect and recover from failed workflow runs.


# Next.js
Source: https://upstash.com/docs/workflow/quickstarts/vercel-nextjs



This guide provides step-by-step instructions on how to use and deploy Upstash Workflow with Next.js.

<Columns cols={2}>
  <Card title="GitHub Repository" icon="github" href="https://github.com/upstash/workflow-js/tree/main/examples/nextjs" horizontal>
    You can find the project source code on GitHub.
  </Card>

  <Card title="Deploy With Vercel" icon="triangle" iconType="sharp-solid" href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fupstash%2Fworkflow-js%2Ftree%2Fmain%2Fworkflow%2Fnextjs&env=QSTASH_TOKEN&envDescription=You%20can%20access%20this%20variable%20from%20Upstash%20Console%2C%20under%20QStash%20page.%20&project-name=workflow-nextjs&repository-name=workflow-nextjs&demo-title=Upstash%20Workflow%20Example&demo-description=A%20Next.js%20application%20utilizing%20Upstash%20Workflow" horizontal>
    Deploy the project to Vercel with a single click.
  </Card>
</Columns>

## Prerequisites

* Node.js and npm (or another package manager) installed.

You can integrate Upstash Workflow into an existing Next.js app, or follow [this guide](https://nextjs.org/docs/app/getting-started/installation) to create a new Next.js project from scratch.

## Step 1: Installation

Run the following command to install the Upstash Workflow SDK in your Next.js app.

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npm install @upstash/workflow
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpm install @upstash/workflow
    ```
  </Tab>

  <Tab title="bun">
    ```bash  theme={"system"}
    bun add @upstash/workflow
    ```
  </Tab>
</Tabs>

## Step 2: Run the development server

Upstash Workflow is built on top of Upstash QStash.

In a production environment, your application connects to the managed QStash servers hosted by Upstash.
This ensures that requests are delivered reliably, securely, and at scale without requiring you to run and maintain your own infrastructure.

For local development, you don't need to depend on the managed QStash servers. Instead, you can run a local QStash server directly on your machine.
This local server behaves just like the production version but does not require external network calls.

Start the local server with:

<Tabs>
  <Tab title="npm">
    ```bash  theme={"system"}
    npx @upstash/qstash-cli dev
    ```
  </Tab>

  <Tab title="pnpm">
    ```bash  theme={"system"}
    pnpx @upstash/qstash-cli dev
    ```
  </Tab>
</Tabs>

When the server starts, it will print the credentials.
You'll need these values in the next step to connect your Next.js app to QStash.

You can enable local mode in the Upstash Workflow dashboard to use the UI while developing locally.

<Frame>
  <img src="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=894b9d6a3d2dff99bed21683c3c01cd7" alt="Enable local mode on dashboard" data-og-width="2758" width="2758" data-og-height="1864" height="1864" data-path="img/qstash-workflow/local-dev.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=280&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=c408f8a396e346fc6bf86ce33f6453aa 280w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=560&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=b7c0049c3a1839305582c18b129192a5 560w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=840&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=85086a3a005d121cf4051e3ac405b1b0 840w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=1100&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=ba2c2aeb93018bf368c662d6424fc52d 1100w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=1650&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=35927ba49e0412a5658b869ee582b0c1 1650w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/local-dev.png?w=2500&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=8f4dd395f0da6319f1d412b654749366 2500w" />
</Frame>

## Step 3: Configure Environment Variables

Next, you need to configure your Next.js app to connect with the local QStash server by setting environment variables.

In the root of your project, create a `.env.local` file (or update your existing one) and add the values printed by the QStash local server:

```txt  theme={"system"}
QSTASH_URL="http://127.0.0.1:8080"
QSTASH_TOKEN="eyJVc2VySUQiOiJkZWZhdWx0VXNlciIsIlBhc3N3b3JkIjoiZGVmYXVsdFBhc3N3b3JkIn0="
QSTASH_CURRENT_SIGNING_KEY="sig_7kYjw48mhY7kAjqNGcy6cr29RJ6r"
QSTASH_NEXT_SIGNING_KEY="sig_5ZB6DVzB1wjE8S6rZ7eenA8Pdnhs"
```

<Tip>
  For production, replace these with your actual credentials from the Upstash Workflow dashboard.
</Tip>

## Step 3: Create a Workflow Endpoint

With your environment ready, the next step is to define your first workflow endpoint.

In Upstash Workflow, every workflow is exposed as an endpoint.
Every endpoint you expose using the SDK‚Äôs `serve()` function acts as a workflow that can be triggered independently.

In Next.js, these endpoints are implemented as **API routes**.

Create the file according to your router setup:

* App Router ‚Üí put the endpoint under `app/api`
* Pages Router ‚Üí put the endpoint under `pages/api`

<Tabs>
  <Tab title="App router">
    ```typescript app/api/workflow/route.ts theme={"system"}
    import { serve } from "@upstash/workflow/nextjs"

    export const { POST } = serve(
      async (context) => {
        await context.run("initial-step", () => {
          console.log("initial step ran")
        })

        await context.run("second-step", () => {
          console.log("second step ran")
        })
      }
    )
    ```
  </Tab>

  <Tab title="App router with request object">
    ```typescript app/api/workflow/route.ts theme={"system"}
    import { serve } from "@upstash/workflow/nextjs";
    import { NextRequest } from "next/server";

    export const POST = async (request: NextRequest) => {
      // do something with the native request object
      const { POST: handler } = serve(async (context) => {
        // Your workflow steps
      });

      return await handler(request);
    }
    ```
  </Tab>

  <Tab title="Pages Router">
    ```typescript src/pages/api/workflow.ts theme={"system"}
    import { servePagesRouter } from "@upstash/workflow/nextjs";

    const { handler } = servePagesRouter<string>(
      async (context) => {
        await context.run("initial-step", () => {
          console.log("initial step ran")
        })

        await context.run("second-step", () => {
          console.log("second step ran")
        })
      }
    )
    export default handler;
    ```
  </Tab>

  <Tab title="Pages Router with request object">
    ```typescript src/pages/api/workflow.ts theme={"system"}
    import type { NextApiRequest, NextApiResponse } from "next";
    import { servePagesRouter } from "@upstash/workflow/nextjs";

    export default async function handler(
      req: NextApiRequest,
      res: NextApiResponse
    ) {
      // do something with the native request object
      const { handler } = servePagesRouter(
        async (context) => {
          // Your workflow steps
        }
      )

      await handler(req, res)
    }
    ```
  </Tab>
</Tabs>

## Step 4: Run the Workflow Endpoint

Once your endpoint is defined, the next step is to trigger a workflow run.

You can start a new workflow run using the `trigger()` function from the Upstash Workflow SDK.

```javascript  theme={"system"}
import { Client } from "@upstash/workflow";

const client = new Client({ token: process.env.QSTASH_TOKEN! })

const { workflowRunId } = await client.trigger({
  url: `http://localhost:3000/api/workflow`,
  retries: 3,
  keepTriggerConfig: true,
});
```

<Info>
  The `trigger()` function should typically be called from a server-side action (not directly in client-side code) to keep your credentials secure.
</Info>

Check the Upstash Workflow dashboard to view logs of your workflow run:

<Frame>
  <img src="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=e3f20497f5d50f6bfec30b4ed8ee90ff" alt="Debug a workflow run on UI" data-og-width="2758" width="2758" data-og-height="1864" height="1864" data-path="img/qstash-workflow/run-view.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=280&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=96c8fe0b3cb3662f3e41398a382cecbf 280w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=560&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=14594dfb7ed28e821056fabb40097a70 560w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=840&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=8f1b7a01cea89106d227d1d0372a1cc2 840w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=1100&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=9af11ef94799753afbd2c1c0953e76c3 1100w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=1650&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=be5d6a683aabc669a23a571e9c32bf1a 1650w, https://mintcdn.com/upstash/fkAt_mKC7aEhsSVz/img/qstash-workflow/run-view.png?w=2500&fit=max&auto=format&n=fkAt_mKC7aEhsSVz&q=85&s=5e629fdf6f7dec028a97a9ce467030ba 2500w" />
</Frame>

<Tip>
  Inside the `trigger()` call, you need to provide the URL of your workflow endpoint:

  * Local development ‚Üí use the URL where your app is running, for example: [http://localhost:3000/api/PATH](http://localhost:3000/api/PATH)
  * Production ‚Üí use the URL of your deployed app, for example: [https://yourapp.com/api/PATH](https://yourapp.com/api/PATH)

  To avoid hardcoding URLs, you can define a `BASE_URL` constant and set it based on the environment.
  A common pattern is to check an environment variable that only exists in production:

  ```javascript  theme={"system"}
  const BASE_URL = process.env.VERCEL_URL
    ? `https://${process.env.VERCEL_URL}`
    : `http://localhost:3000`

  const { workflowRunId } = await client.trigger({
    url: `${BASE_URL}/api/workflow`,
    retries: 3,
    keepTriggerConfig: true,
  });
  ```
</Tip>

## Step 5: Deploying to Production

You now have everything you need to deploy your application to production! üéâ

Before deploying, make sure your configuration no longer relies on local development settings:

* **Workflow URL**: Update the `trigger()` call to use your production domain (see the tip above for using a dynamic `BASE_URL`).
* **Credentials**: Replace local QStash credentials with your production tokens.
* **Environment Variables**: Verify that all required variables are set correctly in your deployment environment.

## Next Steps

Now that you've created and deployed your first workflow, here are some recommended guides to continue learning:

1. **[Learn the Workflow API](/workflow/basics/context)**: Dive deeper into the full API surface and advanced capabilities.

2. **[Configure Workflow Runs](/workflow/basics/client)**: Learn how to configure workflow execution to fit your app's needs.

3. **[Handle Failures](/workflow/howto/failures)**: Understand how to detect and recover from failed workflow runs.


# Bulk Restart Workflow Runs
Source: https://upstash.com/docs/workflow/rest/dlq/bulk-restart

POST https://qstash.upstash.io/v2/workflows/dlq/restart
Restart multiple failed workflow runs in a single request.

The bulk restart feature allows you to restart multiple failed workflow runs from the Dead Letter Queue (DLQ), using their original payloads and configurations.

You can specify individual DLQ IDs or apply filters to identify the workflow runs you want to restart.

A maximum of 50 workflow runs can be restarted per request. If more runs are available, a cursor is returned, which can be used in subsequent requests to continue the operation. When no cursor is returned, all entries have been processed.

Each restarted workflow run is assigned a new random Run ID.

## Request Parameters

<ParamField query="dlqIds" type="array">
  A list of DLQ IDs corresponding to the failed workflow runs you want to restart.
</ParamField>

<ParamField query="fromDate" type="integer">
  Optional. Restart workflow runs that failed on or after this unix millisecond timestamp.
</ParamField>

<ParamField query="toDate" type="integer">
  Optional. Restart workflow runs that failed on or before this unix millisecond timestamp.
</ParamField>

<ParamField query="workflowUrl" type="string">
  Optional. Restart workflow runs where the workflow URL matches this value.
</ParamField>

<ParamField query="workflowRunId" type="string">
  Optional. Restart workflow runs matching this specific Run ID or ID prefix.
</ParamField>

<ParamField query="workflowCreatedAt" type="integer">
  Optional. Restart workflow runs created at the specified unix millisecond timestamp.
</ParamField>

<ParamField header="Upstash-Flow-Control-Key" type="string">
  Optional. Override the flow control key for the restarted workflows. If not provided, the original key is reused.
</ParamField>

<ParamField header="Upstash-Flow-Control-Value" type="string">
  Optional. Override the flow control value for the restarted workflows. If not provided, the original value is reused.
</ParamField>

<ParamField header="Upstash-Retries" type="integer">
  Optional. Override the retry configuration for the steps in the restarted workflows.
</ParamField>

## Response

<ResponseField name="cursor" type="string">
  A cursor to paginate through additional matching DLQ entries. If not present, there are no more entries to process.
</ResponseField>

<ResponseField name="workflowRuns" type="array">
  A list of resumed workflow runs, each containing a new run ID and creation timestamp.
</ResponseField>

## Request Example

<RequestExample>
  ```sh  theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/workflows/dlq/restart \
    -H "Authorization: Bearer <token>" \
    -H "Upstash-Flow-Control-Key: custom-key" \
    -H "Upstash-Flow-Control-Value: parallelism=1" \
    -H "Upstash-Retries: 3" \
  ```
</RequestExample>

<ResponseExample>
  ```json  theme={"system"}
  {
    "cursor": "",
    "workflowRuns": [
      {
        "workflowRunId": "wfr_resumed_A",
        "workflowCreatedAt": 1748527971000
      },
      {
        "workflowRunId": "wfr_resumed_B",
        "workflowCreatedAt": 1748527971000
      }
    ]
  }
  ```
</ResponseExample>


# Bulk Resume Workflow Runs
Source: https://upstash.com/docs/workflow/rest/dlq/bulk-resume

POST https://qstash.upstash.io/v2/workflows/dlq/resume
Resume multiple workflow runs at once

The bulk resume feature allows you to resume multiple failed workflow runs from the Dead Letter Queue (DLQ) in a single request, continuing each run from the point of failure rather than starting over.

This is useful when you want to preserve the progress of long-running workflows that partially succeeded before failing, and resume them all efficiently without losing successful step results.

Each resumed workflow is created as a new run. All successfully completed steps from the original runs are preserved, and only the failed or pending steps are executed again.

A maximum of 50 workflow runs can be resumed per request. If more runs are available, a cursor is returned, which can be used in subsequent requests to continue the operation. When no cursor is returned, all entries have been processed.

You can specify exact DLQ IDs or apply filters to select which workflows to resume.

<Note>
  You may modify the workflow code **after the point of failure**, but changes **before the failed step** are not supported and may cause the resume to fail.

  For more information, see [Handle workflow route code changes](/workflow/howto/changes).
</Note>

## Request Parameters

<ParamField query="dlqIds" type="array">
  A list of DLQ IDs corresponding to the failed workflow runs you want to resume.
</ParamField>

<ParamField query="fromDate" type="integer">
  Optional. Resume workflow runs that failed on or after this unix millisecond timestamp.
</ParamField>

<ParamField query="toDate" type="integer">
  Optional. Resume workflow runs that failed on or before this unix millisecond timestamp.
</ParamField>

<ParamField query="workflowUrl" type="string">
  Optional. Resume workflow runs where the workflow URL matches this value.
</ParamField>

<ParamField query="workflowRunId" type="string">
  Optional. Resume workflow runs matching this specific Run ID or ID prefix.
</ParamField>

<ParamField query="workflowCreatedAt" type="integer">
  Optional. Resume workflow runs created at the specified unix millisecond timestamp.
</ParamField>

<ParamField header="Upstash-Flow-Control-Key" type="string">
  Optional. Override the flow control key for the resumed workflows. If not provided, the original key is reused.
</ParamField>

<ParamField header="Upstash-Flow-Control-Value" type="string">
  Optional. Override the flow control value for the resumed workflows. If not provided, the original value is reused.
</ParamField>

<ParamField header="Upstash-Retries" type="integer">
  Optional. Override the retry configuration for the steps in the resumed workflows.
</ParamField>

## Response

<ResponseField name="cursor" type="string">
  A cursor to paginate through additional matching DLQ entries. If not present, all matching entries have been processed.
</ResponseField>

<ResponseField name="workflowRuns" type="array">
  A list of resumed workflow runs, each containing a new run ID and creation timestamp.
</ResponseField>

## Request Example

<RequestExample>
  ```sh  theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/workflows/dlq/resume \
    -H "Authorization: Bearer <token>" \
    -H "Upstash-Flow-Control-Key: custom-key" \
    -H "Upstash-Flow-Control-Value: parallelism=1" \
    -H "Upstash-Retries: 3"
  ```
</RequestExample>

<ResponseExample>
  ```json  theme={"system"}
  {
    "cursor": "",
    "workflowRuns": [
      {
        "workflowRunId": "wfr_resumed_A",
        "workflowCreatedAt": 1748527971000
      },
      {
        "workflowRunId": "wfr_resumed_B",
        "workflowCreatedAt": 1748527971000
      }
    ]
  }
  ```
</ResponseExample>


# Rerun Failure Callback for Workflow Run
Source: https://upstash.com/docs/workflow/rest/dlq/callback

POST https://qstash.upstash.io/v2/workflows/dlq/callback/{dlqId}
Rerun the failure callback for a failed workflow run in the DLQ

If the failure callback for a workflow run has failed, you can use this endpoint to manually trigger the failure callback again.
This is useful for ensuring that your system is notified of workflow failures even if the original callback attempt did not succeed.

The state of the failure callback for each workflow run is included in the DLQ message response as failureCallbackInfo.state.
You can filter for all workflow runs with a failed failure callback by using the failureCallbackState filter when listing workflow runs in the DLQ with the `/v2/workflows/dlq` endpoint.

## Request

<ParamField path="dlqId" type="string" required>
  The DLQ id of the failed workflow run for which you want to rerun the failure callback. You can find this id when listing all workflow runs in the DLQ with the [/v2/workflows/dlq](/workflow/rest/dlq/list) endpoint.
</ParamField>

## Response

<ResponseField name="workflowRunId" type="string">
  The ID of the workflow run for which the failure callback was rerun.
</ResponseField>

<ResponseField name="workflowCreatedAt" type="integer">
  Unix timestamp when the workflow run was created.
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X POST "https://qstash.upstash.io/v2/workflows/dlq/callback/my-dlq-id" \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "workflowRunId": "wfr_abcde",
    "workflowCreatedAt": 1680000000000
  }
  ```
</ResponseExample>


# Delete a failed workflow run from the DLQ
Source: https://upstash.com/docs/workflow/rest/dlq/delete

DELETE https://qstash.upstash.io/v2/workflows/dlq/{dlqId}
Manually remove a failed workflow run from the DLQ

Delete a failed workflow run from the Dead Letter Queue (DLQ).

When a workflow run fails, it is moved to the DLQ. You can manually remove a failed workflow run from the DLQ using this endpoint. This is useful for cleaning up failed runs that you no longer wish to retry or analyze.

## Request

<ParamField path="dlqId" type="string">
  The DLQ id of the failed workflow run you want to remove. You will see this id when
  listing all workflow runs in the DLQ with the [/v2/workflows/dlq](/workflow/rest/dlq/list) endpoint.
</ParamField>

## Response

The endpoint doesn't return a response body. A status code of 200 means the workflow run was removed from the DLQ.
If the workflow run is not found in the DLQ (either it has already been removed by you, or automatically), the endpoint returns a 404 status code.

<RequestExample>
  ```sh  theme={"system"}
  curl -X DELETE https://qstash.upstash.io/v2/workflows/dlq/my-dlq-id \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# Get a failed workflow run from the DLQ
Source: https://upstash.com/docs/workflow/rest/dlq/get

GET https://qstash.upstash.io/v2/workflows/dlq/{dlqId}
Get a single failed workflow run from the DLQ

Get a single failed workflow run from the Dead Letter Queue (DLQ).

## Request

<ParamField path="dlqId" type="string">
  The DLQ id of the failed workflow run you want to retrieve. You will see this id when
  listing all workflow runs in the DLQ with the [/v2/workflows/dlq](/workflow/rest/dlq/list) endpoint.
</ParamField>

## Response

If the workflow run is not found in the DLQ (either it has already been removed by you, or automatically), the endpoint returns a 404 status code.

<Snippet file="workflow/workflow-dlq-message-type.mdx" />

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/workflows/dlq/my-dlq-id \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "messageId":"msg_26hZCxZCuWyyTWPmSVBrNC1RADwpgWxPcak2rQD51EMjFMuzcW7qYXpPiDyw8Gd",
    "url":"https://my.app/workflow",
    "method":"POST",
    "header":{
      "Content-Type":[
          "application/json"
      ]
    },
    "maxRetries":10,
    "notBefore":1752829294505,
    "createdAt":1752829294505,
    "failureCallback":"https://my.app/workflow",
    "callerIP":"88.240.188.2",
    "workflowRunId":"wfr_5XAx4IJergqkGK1v23VzR",
    "workflowCreatedAt":1752829293531,
    "workflowUrl":"https://my.app/workflow",
    "responseStatus":489,
    "responseHeader":{
      "Content-Type":[
          "text/plain;charset=UTF-8"
      ]
    },
    "responseBody":"{\"error\":\"WorkflowNonRetryableError\",\"message\":\"this workflow has stopped\"}",
    "failureCallbackInfo":{
      "state":"CALLBACK_SUCCESS",
      "responseStatus":200,
      "responseBody":"{\"workflowRunId\":\"wfr_Q_khHG-a414M-xKRh2kNI\"}",
      "responseHeaders":{
          "Content-Type":[
            "text/plain;charset=UTF-8"
          ]
      }
    },
    "dlqId":"1752829295505-0"
  }
  ```
</ResponseExample>


# List workflow runs in the DLQ
Source: https://upstash.com/docs/workflow/rest/dlq/list

GET https://qstash.upstash.io/v2/workflows/dlq
List and paginate through all failed workflow runs currently inside the DLQ

List all failed workflow runs currently inside the Dead Letter Queue.

## Request

<ParamField query="cursor" type="string">
  By providing a cursor you can paginate through all of the workflow runs in the DLQ
</ParamField>

<ParamField query="workflowRunId" type="string">
  Filter DLQ workflow runs by workflow run id.
</ParamField>

<ParamField query="workflowUrl" type="string">
  Filter DLQ workflow runs by workflow url.
</ParamField>

<ParamField query="fromDate" type="number">
  Filter DLQ workflow runs by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="toDate" type="number">
  Filter DLQ workflow runs by ending date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="responseStatus" type="number">
  Filter DLQ workflow runs by HTTP response status code.
</ParamField>

<ParamField query="callerIP" type="string">
  Filter DLQ workflow runs by IP address of the publisher.
</ParamField>

<ParamField query="failureCallbackState" type="string">
  Filter DLQ workflow runs by the state of failure callback (failure function or failure URL)
</ParamField>

<ParamField query="count" type="number">
  The number of workflow runs to return. Default and maximum is 100.
</ParamField>

<ResponseField name="label" type="string">
  Filter workflow run by the label assigned by the user.
</ResponseField>

## Response

<ResponseField name="cursor" type="string">
  A cursor which you can use in subsequent requests to paginate through all
  workflow runs. If no cursor is returned, you have reached the end of the workflow runs.
</ResponseField>

<ResponseField name="messages" type="Array">
  <Expandable defaultOpen title="message">
    <Snippet file="workflow/workflow-dlq-message-type.mdx" />
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl https://qstash.upstash.io/v2/workflows/dlq \
    -H "Authorization: Bearer <token>"
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
     "cursor":"1752570296426-0",
     "messages":[
        {
           "messageId":"msg_26hZCxZCuWyyTWPmSVBrNC1RADwpgWxPcak2rQD51EMjFMuzcW7qYXpPiDyw8Gd",
           "url":"https://my.app/workflow",
           "method":"POST",
           "header":{
              "Content-Type":[
                 "application/json"
              ]
           },
           "maxRetries":10,
           "notBefore":1752829294505,
           "createdAt":1752829294505,
           "failureCallback":"https://my.app/workflow",
           "callerIP":"88.240.188.2",
           "workflowRunId":"wfr_5XAx4IJergqkGK1v23VzR",
           "workflowCreatedAt":1752829293531,
           "workflowUrl":"https://my.app/workflow",
           "responseStatus":489,
           "responseHeader":{
              "Content-Type":[
                 "text/plain;charset=UTF-8"
              ]
           },
           "responseBody":"{\"error\":\"WorkflowNonRetryableError\",\"message\":\"this workflow has stopped\"}",
           "failureCallbackInfo":{
              "state":"CALLBACK_SUCCESS",
              "responseStatus":200,
              "responseBody":"{\"workflowRunId\":\"wfr_Q_khHG-a414M-xKRh2kNI\"}",
              "responseHeaders":{
                 "Content-Type":[
                    "text/plain;charset=UTF-8"
                 ]
              }
           },
           "dlqId":"1752829295505-0"
        }
     ]
  }
  ```
</ResponseExample>


# Restart Workflow Run
Source: https://upstash.com/docs/workflow/rest/dlq/restart

POST https://qstash.upstash.io/v2/workflows/dlq/restart/{dlqId}
Restart a failed workflow run from the beginning

When a workflow run fails, it's automatically moved to the DLQ (Dead Letter Queue) where it can be analyzed and restarted.
The restart feature allows you to start a failed workflow completely over from the beginning, re-executing all steps from scratch.

This is useful when you want to ensure a clean execution or when the workflow failure might have been caused by corrupted state that requires a fresh start.

When you restart a workflow,  completely new workflow run is created using the original workflow's initial configuration and payload.
All previous step results are discarded and the workflow executes as if it's running for the first time.

You can overwrite the retries and flow control settings by passing the respective headers in the restart request.

## Request

<ParamField path="dlqId" type="string" required>
  The ID of the DLQ message containing the failed workflow run
</ParamField>

<ParamField header="Upstash-Flow-Control-Key" type="string">
  Optional. Overwrite the flow control key for the restarted workflow. If not provided, the original workflow run configuration will be reused.
</ParamField>

<ParamField header="Upstash-Flow-Control-Value" type="string">
  Optional. Overwrite the flow control values for the restarted workflow. If not provided, the original workflow run configuration will be reused.
</ParamField>

<ParamField header="Upstash-Retries" type="integer">
  Optional. Overwrite the retry configuration for the restarted workflow steps.
</ParamField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/dlq/restart/dlq_XYZ \
  -H "Authorization: Bearer <token>" \
  -H "Upstash-Workflow-RunId: my-restarted-workflow-XYZ" 
  ```
</RequestExample>

## Response

<ResponseField name="workflowRunId" type="string">
  The ID of the restarted workflow run
</ResponseField>

<ResponseField name="workflowCreatedAt" type="integer">
  Unix timestamp when the restarted workflow was created
</ResponseField>

<ResponseExample>
  ```json  theme={"system"}
  {
    "workflowRunId": "my-restarted-workflow-XYZ",
    "workflowCreatedAt": 1748527971000
  }
  ```
</ResponseExample>


# Resume Workflow Run
Source: https://upstash.com/docs/workflow/rest/dlq/resume

POST https://qstash.upstash.io/v2/workflows/dlq/resume/{dlqId}
Resume a failed workflow run from where its left off

When a workflow run fails, it's automatically moved to the DLQ (Dead Letter Queue) where it can be analyzed and resumed.
The resume feature allows you to continue a failed workflow run from exactly where it failed, without re-executing successfully completed steps.

This is particularly useful for long-running workflows where you don't want to lose progress from successful steps when a single step fails.

When you resume a workflow, a fresh workflow run is created.
All data from successfully executed steps is maintained.

You can overwrite the workflow's run ID, retries and flow control settings by passing the respective headers in the resume request.

<Note>
  You can make changes to the workflow code as long as these changes come after the failed steps.
  However, making changes before the failed step will break the code and is not allowed.

  For more details, check out [Handle workflow route code changes](/workflow/howto/changes) page.
</Note>

## Request

<ParamField path="dlqId" type="string" required>
  The ID of the DLQ message containing the failed workflow run
</ParamField>

<ParamField header="Upstash-Flow-Control-Key" type="string">
  Optional. Overwrite the flow control key for the resumed workflow. If not provided, the original workflow run configuration will be reused.
</ParamField>

<ParamField header="Upstash-Flow-Control-Value" type="string">
  Optional. Overwrite the flow control values for the resumed workflow. If not provided, the original workflow run configuration will be reused.
</ParamField>

<ParamField header="Upstash-Retries" type="integer">
  Optional. Overwrite the retry configuration for the resumed workflow steps.
</ParamField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/dlq/resume/dlq_XYZ
  -H "Authorization: Bearer <token>" 
  -H "Upstash-Workflow-RunId: my-resumed-workflow-XYZ" 
  ```
</RequestExample>

## Response

<ResponseField name="workflowRunId" type="string">
  The ID of the resumed workflow run
</ResponseField>

<ResponseField name="workflowCreatedAt" type="integer">
  Unix timestamp when the resumed workflow run was created
</ResponseField>

<ResponseExample>
  ```json  theme={"system"}
  {
    "workflowRunId": "my-resumed-workflow-XYZ",
    "workflowCreatedAt": 1748527971000
  }
  ```
</ResponseExample>


# Get Flow-Control
Source: https://upstash.com/docs/workflow/rest/flow-control/get

GET https://qstash.upstash.io/v2/flowControl/{flowControlKey}
Get Information on Flow-Control

## Request

<ParamField path="flowControlKey" type="string">
  The key of the flow control. See the [flow control](/workflow/features/flow-control) for more details.
</ParamField>

## Response

<ResponseField name="flowControlKey" type="string">
  The key of of the flow control.
</ResponseField>

<ResponseField name="waitListSize" type="integer">
  The number of messages in the wait list that waits for `parallelism` set in the flow control.
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/YOUR_FLOW_CONTROL_KEY  -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# List Flow-Control Keys
Source: https://upstash.com/docs/workflow/rest/flow-control/list

GET https://qstash.upstash.io/v2/flowControl/
List All Flow Control Keys

## Response

<ResponseField name="flowControls" type="Array">
  <Expandable>
    <ResponseField name="flowControlKey" type="string">
      The key of the flow control. See the [flow control](/workflow/features/flow-control) for more details.
    </ResponseField>

    <ResponseField name="waitListSize" type="integer">
      The number of messages in the wait list that waits for `parallelism` set in the flow control.
    </ResponseField>
  </Expandable>
</ResponseField>

<RequestExample>
  ```sh  theme={"system"}
  curl -X GET https://qstash.upstash.io/v2/flowControl/  -H "Authorization: Bearer <token>"
  ```
</RequestExample>


# Bulk Cancel Workflows
Source: https://upstash.com/docs/workflow/rest/runs/bulk-cancel

DELETE https://qstash.upstash.io/v2/workflows/runs
Cancel multiple workflow runs

Bulk cancel allows you to cancel multiple workflow runs at once.

<Warning>
  If you provide a list of workflow run IDs in the request body, only those specific workflow runs will be canceled.

  If you include the workflow URL parameter, all workflow runs matching the URL filter will be canceled.

  If the request body is empty, all workflow runs will be canceled.
</Warning>

This operation scans all your workflow runs and attempts to cancel them.
If a specific workflow run cannot be canceled, it will return an error message.
Therefore, some workflow runs may not be cancelled at the end.
In such cases, you can run the bulk cancel operation multiple times.

## Request

<ParamField body="workflowRunIds" type="Array">
  The list of workflow run IDs to cancel.
</ParamField>

<ParamField body="workflowUrl" type="string">
  The prefix filter to match workflow run URLs. Workflow runs with URLs starting with this prefix will be canceled.
</ParamField>

## Response

A cancelled object with the number of cancelled workflow runs.

```JSON  theme={"system"}
{
  "cancelled": number
}
```

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/workflows/runs \
     -H "Content-Type: application/json" \
    -H "Authorization: Bearer <QSTASH_TOKEN>" \
    -d '{"workflowUrl": "https://example.com"}'
  ```

  ```js Workflow SDK theme={"system"}
  import { Client } from "@upstash/workflow";

  // cancel a set of workflow runs
  await client.cancel({ ids: [
    "<WORKFLOW_RUN_ID_1>",
    "<WORKFLOW_RUN_ID_2>",
  ]})

  // cancel workflows starting with a url
  await client.cancel({ urlStartingWith: "https://your-endpoint.com" })

  // cancel all workflows
  await client.cancel({ all: true })
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/workflows/runs', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
      body: {
          workflowRunIds: [
              "run_id_1",
              "run_id_2",
              "run_id_3",
          ],
      },
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
      'Content-Type': 'application/json',
  }

  data = {
    "workflowRunIds": [
      "run_id_1",
      "run_id_2",
      "run_id_3"
    ]
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/workflows/runs',
    headers=headers,
    data=data
  )
  ```

  ```go Go theme={"system"}
  var data = strings.NewReader(`{
    "workflowRunIds": [
      "run_id_1",
      "run_id_2",
      "run_id_3"
    ]
  }`)
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/workflows/runs", data)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  req.Header.Set("Content-Type", "application/json")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 202 Accepted theme={"system"}
  {
    "cancelled": 10
  }
  ```
</ResponseExample>


# Cancel Workflow
Source: https://upstash.com/docs/workflow/rest/runs/cancel

DELETE https://qstash.upstash.io/v2/workflows/runs/{workflowRunId}
Stop a running workflow run

Cancelling a workflow run will remove it from QStash and stop it from being delivered
in the future.

## Request

<ParamField path="workflowRunId" type="string" required>
  The id of the message to cancel.
</ParamField>

## Response

This endpoint returns

* `200 OK` when successful.
* `404 NOT FOUND` when a workflow run is not found with the given id.
* `500 INTERNAL SERVER` when an unexpected error occurs.

<RequestExample>
  ```sh curl theme={"system"}
  curl -XDELETE https://qstash.upstash.io/v2/workflows/runs/wfr_TzazoUCuZmFGp2u9cdy5K \
    -H "Authorization: Bearer <token>"
  ```

  ```js Workflow SDK theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })
  await client.cancel({ workflowRunId: "<WORKFLOW_RUN_ID>" })
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/workflows/runs/wfr_TzazoUCuZmFGp2u9cdy5K', {
    method: 'DELETE',
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.delete(
    'https://qstash.upstash.io/v2/workflows/runs/wfr_TzazoUCuZmFGp2u9cdy5K', 
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("DELETE", "https://qstash.upstash.io/v2/workflows/runs/wfr_TzazoUCuZmFGp2u9cdy5K", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```text 200 OK theme={"system"}
  OK
  ```
</ResponseExample>


# List workflow runs
Source: https://upstash.com/docs/workflow/rest/runs/logs

GET https://qstash.upstash.io/v2/workflows/logs
Fetch details about workflow runs

You can fetch details about workflow runs, including their state, completed and in-progress steps, and step details.

The retention duration for completed workflow runs depends on your quota. Please check the [pricing](https://upstash.com/pricing/workflow) page for details.

<Note>
  If you have executed multiple workflow runs with the same workflowRunId, the `workflowRunId` filter will return all of them.

  To uniquely identify a single workflow run, include the `workflowCreatedAt` timestamp in your filter.
</Note>

## Request

<ParamField query="cursor" type="string">
  By providing a cursor you can paginate through all of the workflow runs.
</ParamField>

<ParamField query="workflowRunId" type="string">
  Filter workflow runs by run id.
</ParamField>

<ParamField query="workflowUrl" type="string">
  Filter workflow runs by workflow url.
</ParamField>

<ParamField query="workflowCreatedAt" type="number">
  Filter workflow runs by the unix milliseconds value of creation timestamp
</ParamField>

<ParamField query="state" type="string">
  Filter workflow runs by state

  | Value          | Description                                                    |
  | -------------- | -------------------------------------------------------------- |
  | `RUN_STARTED`  | The workflow has started to run and currently in progress.     |
  | `RUN_SUCCESS`  | The workflow run has completed succesfully.                    |
  | `RUN_FAILED`   | Some errors has occured and workflow failed after all retries. |
  | `RUN_CANCELED` | The workflow run has canceled upon user request.               |
</ParamField>

<ParamField query="fromDate" type="number">
  Filter workflow runs by starting date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="toDate" type="number">
  Filter workflow runs by ending date, in milliseconds (Unix timestamp). This is inclusive.
</ParamField>

<ParamField query="count" type="number">
  The number of workflow runs to return. Default and max is 10.
</ParamField>

<ResponseField name="label" type="string">
  Filter workflow run by the label assigned by the user.
</ResponseField>

## Response

<ResponseField name="cursor" type="string">
  A cursor which you can use in subsequent requests to paginate through all
  workflow runs. If no cursor is returned, you have reached the end of the
  workflow runs.
</ResponseField>

<Snippet file="workflow/logs.mdx" />

<RequestExample>
  ```sh curl theme={"system"}
  curl https://qstash.upstash.io/v2/workflows/logs \
    -H "Authorization: Bearer <token>"
  ```

  ```js Workflow JS SDK theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" });

  // Filter by workflow run ID
  const { runs } = await client.logs({ workflowRunId: "<WORKFLOW_RUN_ID>"});

  // Filter by workflow server url
  const { runs } = await client.logs({ workflowUrl: "<WORKFLOW_URL>"});

  // Filter by state
  const { runs } = await client.logs({ state: "RUN_SUCCESS"});
  ```

  ```javascript Node theme={"system"}
  const response = await fetch("https://qstash.upstash.io/v2/workflows/logs", {
    headers: {
      Authorization: "Bearer <token>",
    },
  });
  ```

  ```python Python theme={"system"}
  import requests
  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.get(
    'https://qstash.upstash.io/v2/workflows/logs',
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("GET", "https://qstash.upstash.io/v2/workflows/logs", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  {
    "cursor": "1686652644442-12",
    "runs": [
      {
        "workflowRunId": "wfr_rj0Upr1rvdzGfz96fXNHh",
        "workflowUrl": "https://feasible-eft-notably.ngrok-free.app/api/call",
        "workflowState": "RUN_SUCCESS",
        "workflowRunCreatedAt": 1736340463061,
        "workflowRunCompletedAt": 1736340464684,
        "steps": [
          {
            "steps": [
              {
                "stepName": "init",
                "stepType": "Initial",
                "callType": "step",
                "messageId": "msg_7YoJxFpwkEy5zBp378JgvD6YBDPBEqkBPje2JGTCEUiASMJQ1FwY9",
                "concurrent": 1,
                "state": "STEP_SUCCESS",
                "createdAt": 1736340463064
              }
            ],
            "type": "sequential"
          },
          {
            "steps": [
              {
                "stepId": 1,
                "stepName": "external call",
                "stepType": "Run",
                "callType": "step",
                "messageId": "msg_26hZCxZCuWyyTWPmSVBrNCtiJGNsULmt63vFfcZxQ3sfYFKLZe2dKww4BSb2kVF",
                "out": "1",
                "concurrent": 2,
                "state": "STEP_SUCCESS",
                "createdAt": 1736340464111
              },
              {
                "stepId": 2,
                "stepName": "external call 2",
                "stepType": "Run",
                "callType": "step",
                "messageId": "msg_26hZCxZCuWyyTWPmSVBrNB882AMRP1TsgzpygELRcLWep4ACNTTsCHhrZuaNLij",
                "out": "2",
                "concurrent": 2,
                "state": "STEP_SUCCESS",
                "createdAt": 1736340463895
              }
            ],
            "type": "parallel"
          }
        ]
      }
    ]
  }
  ```
</ResponseExample>


# Notify Workflows
Source: https://upstash.com/docs/workflow/rest/runs/notify

POST https://qstash.upstash.io/v2/notify/{eventId}
Resume workflows waiting for an event

Notify workflows waiting for an event to resume them. See [our documentation to learn more](/workflow/howto/events).

## Request

<ParamField path="eventId" type="string" required>
  Event id to notify
</ParamField>

<ParamField body="body" type="string">
  Event data passed to the notified workflows
</ParamField>

## Response

The response contains a list of

* notified waiter objects,
* id of the message sent,
* workflowRunId and workflowCreatedAt fields for the related workflow runs, as a result of the notify request.

```typescript  theme={"system"}
type NotifyResponse = { waiter: Waiter, messageId: string, workflowRunId: string, workflowCreatedAt: number}[]
```

More information about the `Waiter` object:

<Snippet file="qstash/waiter.mdx" />

If there were no workflows waiting for the event, the result is an empty list.

<RequestExample>
  ```sh curl theme={"system"}
  curl -X POST https://qstash.upstash.io/v2/notify/myEvent \
    -H "Authorization: Bearer <token>" \
    -d "Hello World!"
  ```

  ```js Workflow SDK theme={"system"}
  import { Client } from "@upstash/workflow";

  const client = new Client({ token: "<QSTASH_TOKEN>" })
  await client.notify({
    eventId: "my-event-id",
    eventData: "Hello World!"
  });
  ```

  ```js Node theme={"system"}
  const response = await fetch('https://qstash.upstash.io/v2/notify/myEvent', {
    method: 'POST',
    body: "Hello world!",
    headers: {
      'Authorization': 'Bearer <token>'
    }
  });
  ```

  ```python Python theme={"system"}
  import requests

  headers = {
      'Authorization': 'Bearer <token>',
  }

  response = requests.post(
    'https://qstash.upstash.io/v2/notify/myEvent', 
    headers=headers
  )
  ```

  ```go Go theme={"system"}
  req, err := http.NewRequest("POST", "https://qstash.upstash.io/v2/notify/myEvent", nil)
  if err != nil {
    log.Fatal(err)
  }
  req.Header.Set("Authorization", "Bearer <token>")
  resp, err := http.DefaultClient.Do(req)
  if err != nil {
    log.Fatal(err)
  }
  defer resp.Body.Close()
  ```
</RequestExample>

<ResponseExample>
  ```json 200 OK theme={"system"}
  [
    {
      "waiter": {
        "url": "https://my-workflow.com/path",
        "headers": {
          "Upstash-Workflow-Runid": [
            "wfr_melCHYvPkVhDqIhhk2"
          ],
          "Upstash-Workflow-Url": [
            "https://my-workflow.com/path"
          ]
        },
        "deadline": 1729869206
      },
      "messageId": "msg_26hZCxxbG2TT3AnHEr1w"
    }
  ]
  ```
</ResponseExample>


# Roadmap
Source: https://upstash.com/docs/workflow/roadmap



<Note>
  We have moved the roadmap and the changelog to [Github Discussions](https://github.com/orgs/upstash/discussions) starting from October 2025.Now you can follow `In Progress` features. You can see that your `Feature Requests` are recorded. You can vote for them and comment your specific use-cases to shape the feature to your needs.
</Note>


# JavaScript SDK
Source: https://upstash.com/docs/workflow/sdk/workflow-js





# Python SDK
Source: https://upstash.com/docs/workflow/sdk/workflow-py





# General
Source: https://upstash.com/docs/workflow/troubleshooting/general



## Running Steps Inside try/catch Blocks

When running steps (run, sleep, call, or any other step) inside a try/catch block, you'll encounter the following error:

```
WorkflowAbort: This is an Upstash Workflow error thrown after
a step executes. It is expected to be raised. Make sure that
you await for each step. Also, if you are using try/catch
blocks, you should not wrap context.run/sleep/sleepUntil/call
methods with try/catch. Aborting workflow after executing
step 'some-step'.
```

The `WorkflowAbort` error is thrown by the Workflow SDK when a step executes successfully. When you run a step inside a try/catch block, you have two primary options:

1. **Re-throw WorkflowAbort**: If you need a try/catch block, re-throw the `WorkflowAbort` error:

2. **Avoid Running Steps in try/catch**: The simplest solution is to not wrap steps in try/catch blocks. If you have a `context.run` inside try/catch, you can try putting the try/catch inside the context.run.

<CodeGroup>
  ```typescript TypeScript {1, 6-7} theme={"system"}
  import { WorkflowAbort } from '@upstash/workflow';

  try {
    await context.run( ... );
  } catch (error) {    
    if (error instanceof WorkflowAbort) {
      throw error;
    } else {
      // handle other errors
    }
  }
  ```

  ```python Python {1, 6-7} theme={"system"}
  from upstash_workflow import WorkflowAbort

  try:
      await context.run( ... )
  except Exception as e:
      if isinstance(e, WorkflowAbort):
          raise e
      else:
          # handle other errors

  ```
</CodeGroup>

## `context.requestPayload` Becoming Undefined

### Headers Considerations

In some frameworks, you may need to pass specific headers for the workflow to access `requestPayload`:

* Try passing `Content-type: text/plain` or `Content-type: application/json` headers when starting the workflow.
* Note that `publishJSON` can only publish `Content-type: application/json`.

### `context.call` Execution

[During a workflow run, the endpoint will be called multiple times](/workflow/basics/how). While executing `context.call`, the endpoint is called at least twice, with the SDK attempting to run the route function until the first step for custom authorization.

Accessing `context.requestPayload` before any step can result in it becoming undefined:

<CodeGroup>
  ```typescript TypeScript {2-4, 8} theme={"system"}
  export const { POST } = serve(async (context) => {
    // Will print undefined while executing context.call
    const payload = context.requestPayload
    console.log(payload)

    // ... steps or any other code

    context.call( ... )
  })
  ```

  ```python Python {3-5, 9} theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      # Will print None while executing context.call
      payload = context.request_payload
      print(payload)

      # ... steps or any other code

      context.call( ... )

  ```
</CodeGroup>

This behavior stems from the internal mechanics of `context.call`, and resolving this specific interaction is on our roadmap. Note that if you are passing `context.requestPayload` as a parameter to `context.call`, the payload remains intact. However, during the actual execution of `context.call`, the `context.requestPayload` becomes undefined due to the SDK's internal workflow processing steps.

To fix this issue, you can try adding a step which returns the payload:

<CodeGroup>
  ```typescript TypeScript {2-4, 7} theme={"system"}
  export const { POST } = serve(async (context) => {
    // Payload will never be undefined
    const payload = await context.run("get payload", () => context.requestPayload)

    // ... steps or any other code

    context.call( ... )
  })
  ```

  ```python Python {4-8, 12} theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:

      async def _get_payload() -> str:
          return context.request_payload
      
      # Payload will never be None
      payload = await context.run("get payload", _get_payload)

      # ... steps or any other code

      context.call( ... )

  ```
</CodeGroup>

You can find an example of this usage in [our documentation on usage with AI SDK](/workflow/integrations/aisdk).

## Verification Failed Scenarios

When [QStash signature verification](/workflow/howto/security#using-qstashs-built-in-request-verification-recommended) is enabled, you might encounter an error like:

```
Failed to verify that the Workflow request comes from QStash: some-error

If signature is missing, trigger the workflow endpoint by publishing your request to QStash instead of calling it directly.

If you want to disable QStash Verification, you should clear env variables QSTASH_CURRENT_SIGNING_KEY and QSTASH_NEXT_SIGNING_KEY
```

Troubleshooting verification errors:

* Ensure you [start the workflow using `client.trigger` or by publishing to QStash](/workflow/howto/start).
* Verify that `QSTASH_CURRENT_SIGNING_KEY` and `QSTASH_NEXT_SIGNING_KEY` environment variables are correct.
* Pass [appropriate `Content-type` headers](/workflow/troubleshooting/general#headers-considerations) when starting the workflow.

## Authorization Error Handling

Consider this workflow:

<CodeGroup>
  ```typescript TypeScript {2-5} theme={"system"}
  export const { POST } = serve(async (context) => {
    
    if (someCondition()) => {
      return;
    }

    // rest of the workflow
  })
  ```

  ```python Python {3-4} theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:
      if some_condition():
          return

      # rest of the workflow

  ```
</CodeGroup>

Returning before running any steps will result in:

* HTTP status: 400
* Error message: `Failed to authenticate Workflow request.`

This behavior is a direct result of the [custom authorization mechanism](/workflow/howto/security#custom-authorization-method). The Workflow SDK interprets an early function return without executing any steps as an authentication failure.

If the function `someCondition()` is non-deterministic, the recommended approach is to transform this condition into an explicit workflow step. Here's the recommended pattern for handling such non-deterministic conditions:

<CodeGroup>
  ```typescript TypeScript {3-6} theme={"system"}
  export const { POST } = serve(async (context) => {
    
    const shouldReturn = await context.run("check condition", () => someCondition())
    if (shouldReturn) => {
      return;
    }

    // rest of the workflow
  })
  ```

  ```python Python {4-9} theme={"system"}
  @serve.post("/api/example")
  async def example(context: AsyncWorkflowContext[str]) -> None:

      async def _check_condition() -> bool:
          return some_condition()

      should_return = await context.run("check condition", _check_condition)
      if should_return:
          return

      # rest of the workflow

  ```
</CodeGroup>

## Retry Configuration

Retry settings can be configured in three locations:

1. [**Workflow Start** (publish/publishJSON or client.trigger)](/workflow/howto/start)
   * Default retries: 3

2. [**Context Call**](/workflow/basics/context#context-call)
   * Default retries: 0

3. [**Serve Options**](/workflow/basics/serve#retries)
   * Default retries: 3
   * Covers all other requests except the above two

## Verbose Mode Diagnostics

<Note>
  This feature is not yet available in
  [workflow-py](https://github.com/upstash/workflow-py). See our
  [Roadmap](/workflow/roadmap) for feature parity plans and
  [Changelog](/workflow/changelog) for updates.
</Note>

Use [verbose mode](/workflow/basics/serve#verbose) to diagnose workflow issues.

The logs in this section should be seen very rarely. If you observe these logs consistently, you can reach out to our support.

### Localhost in URL Warning

```
Workflow URL contains localhost. This can happen in local development,
but shouldn't happen in production unless you have a route which contains
localhost. Received: ...
```

This error indicates that the workflow URL has localhost. Publish requests will fail and workflow won't be able to run.

**Potential Solutions:**

* Verify [baseUrl](/workflow/basics/serve#baseurl)
* Check UPSTASH\_WORKFLOW\_URL
* Explicitly pass the full [url](/workflow/basics/serve#url)

### Deduplication Log

Since QStash has at least once delivery guarantee, there is a very small chance that a step will run twice. This is why we suggest [idempotancy](/workflow/basics/caveats#ensure-idempotency-in-context-run). When this happens, the duplicate step should print the following log and terminate:

```
Upstash Workflow: The step 'some-step' with id 'step-index' has run twice during workflow execution. Rest of the workflow will continue running as usual.
```

### Network Issue Warnings

In rare instances, the workflow endpoint may complete its task successfully but fail to send a proper response. The SDK is designed to detect such occurrences. When this happens, the workflow endpoint will return a `200` status code and log one of the following three warnings:

```
Workflow run wfr-*** already exists. A new one isn't created.
tried to append to a cancelled workflow. exiting without publishing.
Failed to remove workflow run wfr-*** as it doesn't exist.
```

A similar issue can occur if you have two parallel context.call steps at the end of your workflow. While the workflow will execute successfully, you may see this warnings:

```
Couldn't fetch workflow run steps. This can happen if the workflow run successfully ends before some callback is executed.
```

## HTTPS Protocol Issue

The Workflow SDK automatically infers the protocol (HTTP or HTTPS) based on the incoming request object in your application.

However, if your app is deployed behind a proxy (e.g., Railway or similar platforms), the proxy may terminate SSL and forward the request to your app using plain HTTP.
This can cause the SDK to mistakenly infer that the request is using HTTP instead of HTTPS.

To fix this, explicitly set the `UPSTASH_WORKFLOW_URL` environment variable to the base URL of your application.
This disables automatic protocol inference and uses the provided static URL instead.

If you‚Äôre using Express.js behind a front-facing proxy, an alternative solution is to enable [proxy trust](https://expressjs.com/en/api.html#app.set) so Express correctly identifies the original protocol from the X-Forwarded-Proto header:

```javascript  theme={"system"}
app.set("trust proxy", true)
```

## Workflow Stuck in First Step

Imagine that you trigger your workflow with [client.trigger](/workflow/basics/client/trigger) and the workflow starts (you see the run in the dashboard), but it doesn't proceed beyond the first step.

If it appears like the initial step has failed:

* Expand the step in the dashboard to see detailed logs to check for any error messages or stack traces that can provide insights into what went wrong.
* Ensure that the workflow endpoint is accessible. You can test by sending a `curl` request to see if the request lands on the endpoint.
* Ensure that the URL you passed to the `client.trigger` method matches the workflow endpoint URL.
* Verify that you're using the latest SDK version both in the workflow endpoint definition and in the code that calls `client.trigger`.

If it appears like the initial step has completed but the workflow is still stuck:

* Workflow SDK could be unable to correctly infer the workflow URL due to a proxy or an issue in the request object. To check if this is the issue, try passing the [`baseUrl` parameter to the `serve` method](/workflow/basics/serve/advanced#param-base-url). This will override the automatic URL inference and use the provided base URL instead.


# Vercel
Source: https://upstash.com/docs/workflow/troubleshooting/vercel



# Common Issues and Solutions

### Preview Deployment Protection

**Problem:**
When Deployment Protection setting is enabled on Vercel, it's not possible to trigger and complete a workflow run on a preview deployment.

**Solution:**
Vercel provides a way to bypass this protection by using a bypass secret. To create one, follow these steps:

<Steps>
  <Step title="Settings">Go to **Deployment Protection** section under your Vercel project settings.</Step>

  <Step title="Find related section">
    Click on **Add Secret** under **Protection Bypass for Automation** section.

    <Frame>
      <img src="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=f2009e2c2fef6af028da4fdad7171a33" data-og-width="1257" width="1257" data-og-height="827" height="827" data-path="img/workflow/troubleshooting/vercel-deployment-protection.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=280&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=8f365114b95d945dc41b5e20dc753272 280w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=560&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=88ffcf217af52b1b8c0b44d2d9aa60bb 560w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=840&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=41f11cf66b9b17ef7f1d21aa03359b3d 840w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=1100&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=4fd84d87a095adc3ebbeac886341e6b4 1100w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=1650&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=9685a2db3af0c538dfff4942421b09eb 1650w, https://mintcdn.com/upstash/pBXejvUl5XQn4tWO/img/workflow/troubleshooting/vercel-deployment-protection.png?w=2500&fit=max&auto=format&n=pBXejvUl5XQn4tWO&q=85&s=715936038c9c5a5a9540274b343fe8aa 2500w" />
    </Frame>
  </Step>

  <Step title="Generate a bypass token">Don't forget to save it.</Step>
</Steps>

Now that you have a bypass token, you can add it to your workflow URL as a query parameter.

Imagine that you have a Vercel Preview and there is a workflow endpoint at `https://vercel-preview.com/workflow`.
You can call the workflow like this in preview:

```bash  theme={"system"}
curl -X POST \
  'https://vercel-preview.com/workflow?x-vercel-protection-bypass=<PROTECTION_BYPASS_SECRET>' \
  -d 'Hello world!'
```


