# Source: https://docs.modular.com/max/api/python/nn/attention/attention_with_rope

<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-max/api/python/nn/attention/attention_with_rope" data-has-hydrated=false><head><meta charset=UTF-8><meta name=generator content="Docusaurus v3.9.2"><title data-rh=true>attention_with_rope | Modular</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"/><meta data-rh=true name=twitter:card content=summary_large_image /><meta data-rh=true property=og:url content=https://docs.modular.com/max/api/python/nn/attention/attention_with_rope /><meta data-rh=true property=og:locale content=en /><meta data-rh=true name=docusaurus_locale content=en /><meta data-rh=true name=docsearch:language content=en /><meta data-rh=true name=docusaurus_version content=current /><meta data-rh=true name=docusaurus_tag content=docs-default-current /><meta data-rh=true name=docsearch:version content=current /><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current /><meta data-rh=true property=og:title content="attention_with_rope | Modular"/><meta data-rh=true name=description content="An opaque KV Cache optimized attention mechanism with Rope."/><meta data-rh=true property=og:description content="An opaque KV Cache optimized attention mechanism with Rope."/><meta data-rh=true property=og:image content=https://docs.modular.com/images/modular-metadata.png /><meta data-rh=true name=twitter:image content=https://docs.modular.com/images/modular-metadata.png /><link data-rh=true rel=icon href=/images/favicon.ico /><link data-rh=true rel=canonical href=https://docs.modular.com/max/api/python/nn/attention/attention_with_rope /><link data-rh=true rel=alternate href=https://docs.modular.com/max/api/python/nn/attention/attention_with_rope hreflang=en /><link data-rh=true rel=alternate href=https://docs.modular.com/max/api/python/nn/attention/attention_with_rope hreflang=x-default /><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-X9RN6M7PSJ"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-X9RN6M7PSJ",{anonymize_ip:!0})</script><link rel=search type=application/opensearchdescription+xml title=Modular href=/opensearch.xml><script async defer type=text/javascript data-cookiecategory=tracking src=//js.hs-scripts.com/24141518.js></script></head><body class=navigation-with-keyboard><img referrerpolicy=no-referrer-when-downgrade data-cookiecategory=tracking src="https://static.scarf.sh/a.png?x-pxid=d240bcad-0bb5-4db6-8c37-9061bb991d8e" class="absolute bottom-0" alt=" ">
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css type=text/css integrity=sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM crossorigin=anonymous><script src=/cookieconsent.js async defer></script>
<script src=/customerio.js defer></script><link rel=stylesheet href=/assets/css/styles.e0d66a70.css />
<script src=/assets/js/runtime~main.9ad0803d.js defer></script>
<script src=/assets/js/main.17c1ccda.js defer></script>


<svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><style data-mantine-styles=true>:root{--mantine-cursor-type:pointer;--mantine-line-height:1.4;--mantine-font-family:Inter;--mantine-font-family-monospace:Roboto Mono,PT Mono,Courier New,Courier,monospace;--mantine-font-family-headings:Inter;--mantine-heading-font-weight:400;--mantine-radius-default:calc(.125rem*var(--mantine-scale));--mantine-breakpoint-sm:640px;--mantine-breakpoint-md:768px;--mantine-breakpoint-lg:1024px;--mantine-breakpoint-xl:1280px;--mantine-breakpoint-docs-desktop:997px;--mantine-breakpoint-xxl:1400px;--mantine-breakpoint-cbl:900px;--mantine-breakpoint-cbm:590px;--mantine-spacing-1:calc(.25rem*var(--mantine-scale));--mantine-spacing-2:calc(.5rem*var(--mantine-scale));--mantine-spacing-3:calc(.75rem*var(--mantine-scale));--mantine-spacing-4:calc(1rem*var(--mantine-scale));--mantine-spacing-5:calc(1.25rem*var(--mantine-scale));--mantine-spacing-6:calc(1.5rem*var(--mantine-scale));--mantine-spacing-7:calc(1.75rem*var(--mantine-scale));--mantine-spacing-8:calc(2rem*var(--mantine-scale));--mantine-spacing-9:calc(2.25rem*var(--mantine-scale));--mantine-spacing-10:calc(2.5rem*var(--mantine-scale));--mantine-spacing-11:calc(2.75rem*var(--mantine-scale));--mantine-spacing-12:calc(3rem*var(--mantine-scale));--mantine-spacing-14:calc(3.5rem*var(--mantine-scale));--mantine-spacing-16:calc(4rem*var(--mantine-scale));--mantine-spacing-20:calc(5rem*var(--mantine-scale));--mantine-spacing-24:calc(6rem*var(--mantine-scale));--mantine-spacing-28:calc(7rem*var(--mantine-scale));--mantine-spacing-32:calc(8rem*var(--mantine-scale));--mantine-spacing-36:calc(9rem*var(--mantine-scale));--mantine-spacing-40:calc(10rem*var(--mantine-scale));--mantine-spacing-44:calc(11rem*var(--mantine-scale));--mantine-spacing-48:calc(12rem*var(--mantine-scale));--mantine-spacing-52:calc(13rem*var(--mantine-scale));--mantine-spacing-56:calc(14rem*var(--mantine-scale));--mantine-spacing-60:calc(15rem*var(--mantine-scale));--mantine-spacing-64:calc(16rem*var(--mantine-scale));--mantine-spacing-72:calc(18rem*var(--mantine-scale));--mantine-spacing-80:calc(20rem*var(--mantine-scale));--mantine-spacing-96:calc(24rem*var(--mantine-scale));--mantine-spacing-xxs:calc(.5rem*var(--mantine-scale));--mantine-spacing-xxl:calc(2.5rem*var(--mantine-scale));--mantine-spacing-3x:calc(4rem*var(--mantine-scale));--mantine-spacing-4x:calc(5rem*var(--mantine-scale));--mantine-spacing-5x:calc(7.5rem*var(--mantine-scale));--mantine-line-height-sm:1.33;--mantine-line-height-md:1.4;--mantine-line-height-lg:1.5;--mantine-line-height-xl:1.66;--mantine-color-dark-0:#fff;--mantine-color-dark-1:#b8b8b8;--mantine-color-dark-4:#353d42;--mantine-color-dark-5:#020c13;--mantine-color-dark-6:#020c13;--mantine-color-dark-7:#020c13;--mantine-color-dark-8:#020c13;--mantine-color-dark-9:#020c13;--mantine-color-red-0:#ff9c9c;--mantine-color-red-1:#fd6666;--mantine-color-red-2:#fc3937;--mantine-color-red-3:#fd1f1b;--mantine-color-red-4:#fd0f0c;--mantine-color-red-5:#e20101;--mantine-color-red-6:#ca0000;--mantine-color-red-7:#ca0000;--mantine-color-red-8:#b10000;--mantine-color-red-9:#b10000;--mantine-color-blue-0:#e6ebff;--mantine-color-blue-1:#cdd7ff;--mantine-color-blue-2:#b5c0f6;--mantine-color-blue-3:#b5c0f6;--mantine-color-blue-4:#b5c0f6;--mantine-color-blue-5:#b5c0f6;--mantine-color-blue-6:#7584de;--mantine-color-blue-7:#6370be;--mantine-color-blue-8:#515d9e;--mantine-color-blue-9:#414a80;--mantine-h1-font-weight:400;--mantine-h2-font-weight:400;--mantine-h3-font-weight:400;--mantine-h4-font-weight:400;--mantine-h5-font-weight:400;--mantine-h6-font-weight:400}:root[data-mantine-color-scheme=dark]{--mantine-primary-color-contrast:var(--mantine-color-black);--mantine-color-dark-filled:var(--mantine-color-dark-5);--mantine-color-dark-filled-hover:var(--mantine-color-dark-6);--mantine-color-dark-light:#69696926;--mantine-color-dark-light-hover:#69696933;--mantine-color-dark-light-color:var(--mantine-color-dark-0);--mantine-color-dark-outline:var(--mantine-color-dark-1);--mantine-color-dark-outline-hover:#b8b8b80d;--mantine-color-gray-filled:var(--mantine-color-gray-5);--mantine-color-gray-filled-hover:var(--mantine-color-gray-6);--mantine-color-gray-light:#dee2e626;--mantine-color-gray-light-hover:#dee2e633;--mantine-color-gray-light-color:var(--mantine-color-gray-0);--mantine-color-gray-outline:var(--mantine-color-gray-1);--mantine-color-gray-outline-hover:#f1f3f50d;--mantine-color-red-filled:var(--mantine-color-red-5);--mantine-color-red-filled-hover:var(--mantine-color-red-6);--mantine-color-red-light:#fd1f1b26;--mantine-color-red-light-hover:#fd1f1b33;--mantine-color-red-light-color:var(--mantine-color-red-0);--mantine-color-red-outline:var(--mantine-color-red-1);--mantine-color-red-outline-hover:#fd66660d;--mantine-color-pink-filled:var(--mantine-color-pink-5);--mantine-color-pink-filled-hover:var(--mantine-color-pink-6);--mantine-color-pink-light:#faa2c126;--mantine-color-pink-light-hover:#faa2c133;--mantine-color-pink-light-color:var(--mantine-color-pink-0);--mantine-color-pink-outline:var(--mantine-color-pink-1);--mantine-color-pink-outline-hover:#ffdeeb0d;--mantine-color-grape-filled:var(--mantine-color-grape-5);--mantine-color-grape-filled-hover:var(--mantine-color-grape-6);--mantine-color-grape-light:#e599f726;--mantine-color-grape-light-hover:#e599f733;--mantine-color-grape-light-color:var(--mantine-color-grape-0);--mantine-color-grape-outline:var(--mantine-color-grape-1);--mantine-color-grape-outline-hover:#f3d9fa0d;--mantine-color-violet-filled:var(--mantine-color-violet-5);--mantine-color-violet-filled-hover:var(--mantine-color-violet-6);--mantine-color-violet-light:#b197fc26;--mantine-color-violet-light-hover:#b197fc33;--mantine-color-violet-light-color:var(--mantine-color-violet-0);--mantine-color-violet-outline:var(--mantine-color-violet-1);--mantine-color-violet-outline-hover:#e5dbff0d;--mantine-color-indigo-filled:var(--mantine-color-indigo-5);--mantine-color-indigo-filled-hover:var(--mantine-color-indigo-6);--mantine-color-indigo-light:#91a7ff26;--mantine-color-indigo-light-hover:#91a7ff33;--mantine-color-indigo-light-color:var(--mantine-color-indigo-0);--mantine-color-indigo-outline:var(--mantine-color-indigo-1);--mantine-color-indigo-outline-hover:#dbe4ff0d;--mantine-color-blue-filled:var(--mantine-color-blue-5);--mantine-color-blue-filled-hover:var(--mantine-color-blue-6);--mantine-color-blue-light:#b5c0f626;--mantine-color-blue-light-hover:#b5c0f633;--mantine-color-blue-light-color:var(--mantine-color-blue-0);--mantine-color-blue-outline:var(--mantine-color-blue-1);--mantine-color-blue-outline-hover:#cdd7ff0d;--mantine-color-cyan-filled:var(--mantine-color-cyan-5);--mantine-color-cyan-filled-hover:var(--mantine-color-cyan-6);--mantine-color-cyan-light:#66d9e826;--mantine-color-cyan-light-hover:#66d9e833;--mantine-color-cyan-light-color:var(--mantine-color-cyan-0);--mantine-color-cyan-outline:var(--mantine-color-cyan-1);--mantine-color-cyan-outline-hover:#c5f6fa0d;--mantine-color-teal-filled:var(--mantine-color-teal-5);--mantine-color-teal-filled-hover:var(--mantine-color-teal-6);--mantine-color-teal-light:#63e6be26;--mantine-color-teal-light-hover:#63e6be33;--mantine-color-teal-light-color:var(--mantine-color-teal-0);--mantine-color-teal-outline:var(--mantine-color-teal-1);--mantine-color-teal-outline-hover:#c3fae80d;--mantine-color-green-filled:var(--mantine-color-green-5);--mantine-color-green-filled-hover:var(--mantine-color-green-6);--mantine-color-green-light:#8ce99a26;--mantine-color-green-light-hover:#8ce99a33;--mantine-color-green-light-color:var(--mantine-color-green-0);--mantine-color-green-outline:var(--mantine-color-green-1);--mantine-color-green-outline-hover:#d3f9d80d;--mantine-color-lime-filled:var(--mantine-color-lime-5);--mantine-color-lime-filled-hover:var(--mantine-color-lime-6);--mantine-color-lime-light:#c0eb7526;--mantine-color-lime-light-hover:#c0eb7533;--mantine-color-lime-light-color:var(--mantine-color-lime-0);--mantine-color-lime-outline:var(--mantine-color-lime-1);--mantine-color-lime-outline-hover:#e9fac80d;--mantine-color-yellow-filled:var(--mantine-color-yellow-5);--mantine-color-yellow-filled-hover:var(--mantine-color-yellow-6);--mantine-color-yellow-light:#ffe06626;--mantine-color-yellow-light-hover:#ffe06633;--mantine-color-yellow-light-color:var(--mantine-color-yellow-0);--mantine-color-yellow-outline:var(--mantine-color-yellow-1);--mantine-color-yellow-outline-hover:#fff3bf0d;--mantine-color-orange-filled:var(--mantine-color-orange-5);--mantine-color-orange-filled-hover:var(--mantine-color-orange-6);--mantine-color-orange-light:#ffc07826;--mantine-color-orange-light-hover:#ffc07833;--mantine-color-orange-light-color:var(--mantine-color-orange-0);--mantine-color-orange-outline:var(--mantine-color-orange-1);--mantine-color-orange-outline-hover:#ffe8cc0d}:root[data-mantine-color-scheme=light]{--mantine-primary-color-contrast:var(--mantine-color-black);--mantine-color-anchor:var(--mantine-color-blue-5);--mantine-color-dark-filled:var(--mantine-color-dark-5);--mantine-color-dark-filled-hover:var(--mantine-color-dark-6);--mantine-color-dark-light:#020c131a;--mantine-color-dark-light-hover:#020c131f;--mantine-color-dark-light-color:var(--mantine-color-dark-5);--mantine-color-dark-outline:var(--mantine-color-dark-5);--mantine-color-dark-outline-hover:#020c130d;--mantine-color-gray-filled:var(--mantine-color-gray-5);--mantine-color-gray-filled-hover:var(--mantine-color-gray-6);--mantine-color-gray-light:#adb5bd1a;--mantine-color-gray-light-hover:#adb5bd1f;--mantine-color-gray-light-color:var(--mantine-color-gray-5);--mantine-color-gray-outline:var(--mantine-color-gray-5);--mantine-color-gray-outline-hover:#adb5bd0d;--mantine-color-red-filled:var(--mantine-color-red-5);--mantine-color-red-filled-hover:var(--mantine-color-red-6);--mantine-color-red-light:#e201011a;--mantine-color-red-light-hover:#e201011f;--mantine-color-red-light-color:var(--mantine-color-red-5);--mantine-color-red-outline:var(--mantine-color-red-5);--mantine-color-red-outline-hover:#e201010d;--mantine-color-pink-filled:var(--mantine-color-pink-5);--mantine-color-pink-filled-hover:var(--mantine-color-pink-6);--mantine-color-pink-light:#f065951a;--mantine-color-pink-light-hover:#f065951f;--mantine-color-pink-light-color:var(--mantine-color-pink-5);--mantine-color-pink-outline:var(--mantine-color-pink-5);--mantine-color-pink-outline-hover:#f065950d;--mantine-color-grape-filled:var(--mantine-color-grape-5);--mantine-color-grape-filled-hover:var(--mantine-color-grape-6);--mantine-color-grape-light:#cc5de81a;--mantine-color-grape-light-hover:#cc5de81f;--mantine-color-grape-light-color:var(--mantine-color-grape-5);--mantine-color-grape-outline:var(--mantine-color-grape-5);--mantine-color-grape-outline-hover:#cc5de80d;--mantine-color-violet-filled:var(--mantine-color-violet-5);--mantine-color-violet-filled-hover:var(--mantine-color-violet-6);--mantine-color-violet-light:#845ef71a;--mantine-color-violet-light-hover:#845ef71f;--mantine-color-violet-light-color:var(--mantine-color-violet-5);--mantine-color-violet-outline:var(--mantine-color-violet-5);--mantine-color-violet-outline-hover:#845ef70d;--mantine-color-indigo-filled:var(--mantine-color-indigo-5);--mantine-color-indigo-filled-hover:var(--mantine-color-indigo-6);--mantine-color-indigo-light:#5c7cfa1a;--mantine-color-indigo-light-hover:#5c7cfa1f;--mantine-color-indigo-light-color:var(--mantine-color-indigo-5);--mantine-color-indigo-outline:var(--mantine-color-indigo-5);--mantine-color-indigo-outline-hover:#5c7cfa0d;--mantine-color-blue-filled:var(--mantine-color-blue-5);--mantine-color-blue-filled-hover:var(--mantine-color-blue-6);--mantine-color-blue-light:#b5c0f61a;--mantine-color-blue-light-hover:#b5c0f61f;--mantine-color-blue-light-color:var(--mantine-color-blue-5);--mantine-color-blue-outline:var(--mantine-color-blue-5);--mantine-color-blue-outline-hover:#b5c0f60d;--mantine-color-cyan-filled:var(--mantine-color-cyan-5);--mantine-color-cyan-filled-hover:var(--mantine-color-cyan-6);--mantine-color-cyan-light:#22b8cf1a;--mantine-color-cyan-light-hover:#22b8cf1f;--mantine-color-cyan-light-color:var(--mantine-color-cyan-5);--mantine-color-cyan-outline:var(--mantine-color-cyan-5);--mantine-color-cyan-outline-hover:#22b8cf0d;--mantine-color-teal-filled:var(--mantine-color-teal-5);--mantine-color-teal-filled-hover:var(--mantine-color-teal-6);--mantine-color-teal-light:#20c9971a;--mantine-color-teal-light-hover:#20c9971f;--mantine-color-teal-light-color:var(--mantine-color-teal-5);--mantine-color-teal-outline:var(--mantine-color-teal-5);--mantine-color-teal-outline-hover:#20c9970d;--mantine-color-green-filled:var(--mantine-color-green-5);--mantine-color-green-filled-hover:var(--mantine-color-green-6);--mantine-color-green-light:#51cf661a;--mantine-color-green-light-hover:#51cf661f;--mantine-color-green-light-color:var(--mantine-color-green-5);--mantine-color-green-outline:var(--mantine-color-green-5);--mantine-color-green-outline-hover:#51cf660d;--mantine-color-lime-filled:var(--mantine-color-lime-5);--mantine-color-lime-filled-hover:var(--mantine-color-lime-6);--mantine-color-lime-light:#94d82d1a;--mantine-color-lime-light-hover:#94d82d1f;--mantine-color-lime-light-color:var(--mantine-color-lime-5);--mantine-color-lime-outline:var(--mantine-color-lime-5);--mantine-color-lime-outline-hover:#94d82d0d;--mantine-color-yellow-filled:var(--mantine-color-yellow-5);--mantine-color-yellow-filled-hover:var(--mantine-color-yellow-6);--mantine-color-yellow-light:#fcc4191a;--mantine-color-yellow-light-hover:#fcc4191f;--mantine-color-yellow-light-color:var(--mantine-color-yellow-5);--mantine-color-yellow-outline:var(--mantine-color-yellow-5);--mantine-color-yellow-outline-hover:#fcc4190d;--mantine-color-orange-filled:var(--mantine-color-orange-5);--mantine-color-orange-filled-hover:var(--mantine-color-orange-6);--mantine-color-orange-light:#ff922b1a;--mantine-color-orange-light-hover:#ff922b1f;--mantine-color-orange-light-color:var(--mantine-color-orange-5);--mantine-color-orange-outline:var(--mantine-color-orange-5);--mantine-color-orange-outline-hover:#ff922b0d}</style><style data-mantine-styles=classes>@media (width<=35.9938em){.mantine-visible-from-xs{display:none!important}}@media (width>=36em){.mantine-hidden-from-xs{display:none!important}}@media (width<=639.9px){.mantine-visible-from-sm{display:none!important}}@media (width>=640px){.mantine-hidden-from-sm{display:none!important}}@media (width<=767.9px){.mantine-visible-from-md{display:none!important}}@media (width>=768px){.mantine-hidden-from-md{display:none!important}}@media (width<=1023.9px){.mantine-visible-from-lg{display:none!important}}@media (width>=1024px){.mantine-hidden-from-lg{display:none!important}}@media (width<=1279.9px){.mantine-visible-from-xl{display:none!important}}@media (width>=1280px){.mantine-hidden-from-xl{display:none!important}}@media (width<=996.9px){.mantine-visible-from-docs-desktop{display:none!important}}@media (width>=997px){.mantine-hidden-from-docs-desktop{display:none!important}}@media (width<=1399.9px){.mantine-visible-from-xxl{display:none!important}}@media (width>=1400px){.mantine-hidden-from-xxl{display:none!important}}@media (width<=899.9px){.mantine-visible-from-cbl{display:none!important}}@media (width>=900px){.mantine-hidden-from-cbl{display:none!important}}@media (width<=589.9px){.mantine-visible-from-cbm{display:none!important}}@media (width>=590px){.mantine-hidden-from-cbm{display:none!important}}</style><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><div class="fixed left-0 top-0 z-[400] w-full bg-white"><div class="sticky top-0 z-10 border-0 border-b border-solid border-Elements-Twilight-Alpha bg-Elements-Twilight-0-90"><div class=mantine-visible-from-sm><div style="--group-gap:0rem;--group-align:center;--group-justify:space-between;--group-wrap:wrap;margin-inline:auto;padding-inline:calc(1.5rem * var(--mantine-scale));max-width:calc(90rem * var(--mantine-scale))" class="h-[72px] m_4081bf90 mantine-Group-root"><div style="--group-gap:calc(0.75rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:nowrap" class="m_4081bf90 mantine-Group-root"><a href=https://www.modular.com/ target=_blank rel="noopener noreferrer"><svg style="width:calc(4.75rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale))" xmlns=http://www.w3.org/2000/svg viewBox="0 0 132 28" class="mt-1.5 text-black"><path stroke=transparent fill=currentColor d="M42.5 7.5C37 7.5 33 11.6 33 17.7 33 24 37 28 42.5 28c5.3 0 9.4-4.1 9.4-10.3 0-6-4.1-10.2-9.4-10.2Zm0 17.7c-3.6 0-6.6-3-6.6-7.5s3-7.4 6.6-7.4c3.5 0 6.5 3 6.5 7.4 0 4.6-3 7.5-6.5 7.5Zm26.9-14.6h-.2a7.5 7.5 0 0 0-6.3-3.1c-5.2 0-9.1 4.1-9.1 10.2 0 6.2 3.9 10.3 9 10.3 2.9 0 4.8-1.1 6.4-3.2h.2v2.8h3V0h-3v10.6ZM63 25.2c-3.4 0-6.3-3-6.3-7.5s3-7.4 6.3-7.4 6.3 3 6.3 7.4c0 4.6-3 7.5-6.3 7.5ZM89.2 8h3v19.7h-3v-2.2H89a8 8 0 0 1-6 2.6c-4.4 0-7.8-3.4-7.8-8.3V8h3v11.8c0 3.2 2.4 5.5 5.3 5.5 3.2 0 5.7-2.5 5.7-5.5V8Zm6-7.9H98v27.6h-3V0Zm20.7 10.6h-.2a7.5 7.5 0 0 0-6.3-3.1c-5.2 0-9 4.1-9 10.2 0 6.2 3.8 10.3 9 10.3 2.8 0 4.7-1.1 6.3-3.2h.2v2.8h3V8h-3v2.7Zm-6.3 14.6c-3.4 0-6.3-3-6.3-7.5s3-7.4 6.3-7.4 6.3 3 6.3 7.4c0 4.6-3 7.5-6.3 7.5ZM132 8v2.7h-7c-.2 0-.3.1-.3.2v16.8h-3v-17h2.8l.2-.1V7.9h7.3ZM27.8 4h3v23.5h-3.2V4.3l-.2-.2H26l-8.3 23.5H13L4.7 4.1H3.2v23.5H0V0h6.5L15 24h.8l8.4-24h3.4v4l.2.1Z"/></svg></a><p style=margin:0rem;padding:0rem class="body-16-light !mt-[1px] mantine-Text-root">/<div class="grid grid-cols-2 !gap-2 rounded-sm bg-Elements-Twilight-5-80 p-1"><a class="flex h-[36px] cursor-pointer items-center justify-center text-black hover:text-black hover:no-underline sm:h-[29px] sm:w-[72px] sm:text-sm bg-Elements-Twilight-0-90 rounded-sm border border-solid border-Elements-Twilight-30-70 shadow-3" target=_self href=/>Docs</a><a href=https://builds.modular-dev.com target=_self rel="noopener noreferrer" class="flex h-[36px] cursor-pointer items-center justify-center text-black hover:text-black hover:no-underline sm:h-[29px] sm:w-[72px] sm:text-sm bg-transparent !text-Elements-Twilight-60-50 hover:bg-Elements-Twilight-20-70">Code</a></div><div style="width:calc(0.375rem * var(--mantine-scale));min-width:calc(0.375rem * var(--mantine-scale))" class=""></div><div class=mantine-visible-from-xl><div class=mantine-visible-from-xl><nav aria-label=Main class="navbar navbar--fixed-top"><div class="!pr-0 pl-6 xl:pl-0 navbar__inner"><div class=navbar__items><div style="--group-gap:calc(1.375rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="m_4081bf90 mantine-Group-root"><a class="navbar__item navbar__link" href=/max/intro>Guides</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/max/api/>APIs</a><a class="navbar__item navbar__link" href=/mojo/manual/>Mojo</a></div></div><div class="navbar__items navbar__items--right"></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav></div></div></div><div style=--group-gap:var(--mantine-spacing-md);--group-align:center;--group-justify:flex-start;--group-wrap:nowrap class="m_4081bf90 mantine-Group-root"><div class="dropdown dropdown--hoverable w-24"><a aria-current=page class="navbar__link version-dropdown-link mt-2 pb-2 active" aria-haspopup=true aria-expanded=false role=button href=/max/api/python/nn/attention/attention_with_rope><div class=versionDropdownLabel_EiAO><div style="--group-gap:calc(0.25rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:nowrap" class="m_4081bf90 mantine-Group-root"><svg viewBox="0 0 20 20" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))" color=var(--Elements-Neb-Ultra)><g stroke=currentColor stroke-width=1.5><path d="M16.04 11.24a5.4 5.4 0 0 1-7.28-7.28 7.19 7.19 0 1 0 7.28 7.28ZM13.18.96v3.65M17.21 5.2v3.65M15 2.79h-3.65M19.04 7.03h-3.65"/></g></svg><p style="font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root">Nightly</div></div></a><ul class="dropdown__menu !w-[205px] !rounded-sm border border-solid border-Elements-Twilight-5-80 !p-0"><div class=""><button class="mantine-focus-auto w-full p-6 hover:!bg-Elements-Twilight-5-80 md:px-2.5 md:py-1.5 bg-Elements-Twilight-5-80 m_87cf2631 mantine-UnstyledButton-root" type=button><div style=--stack-gap:0rem;--stack-align:stretch;--stack-justify:flex-start class="m_6d731127 mantine-Stack-root"><div style="--group-gap:calc(0.125rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="text-Elements-Neb-Ultra m_4081bf90 mantine-Group-root"><svg viewBox="0 0 20 20" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale))"><g stroke=currentColor stroke-width=1.5><path d="M16.04 11.24a5.4 5.4 0 0 1-7.28-7.28 7.19 7.19 0 1 0 7.28 7.28ZM13.18.96v3.65M17.21 5.2v3.65M15 2.79h-3.65M19.04 7.03h-3.65"/></g></svg><p style="font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root">Nightly</div><div class=text-xs color=var(--Elements-Twilight-60-40)>Work in progress</div></div></button><div style=--divider-color:var(--Elements-Twilight-5-80) class="m_3eebeb36 mantine-Divider-root" data-orientation=horizontal role=separator></div></div><div class=""><button class="mantine-focus-auto w-full p-6 hover:!bg-Elements-Twilight-5-80 md:px-2.5 md:py-1.5 m_87cf2631 mantine-UnstyledButton-root" type=button><div style=--stack-gap:0rem;--stack-align:stretch;--stack-justify:flex-start class="m_6d731127 mantine-Stack-root"><div style="--group-gap:calc(0.125rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="text-black m_4081bf90 mantine-Group-root"><p style="font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root">v25.7</div><div class=text-xs color=var(--Elements-Twilight-60-40)><div style="--group-gap:calc(0.125rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:nowrap" class="m_4081bf90 mantine-Group-root"><time datetime="Thu Nov 20 2025 00:00:00 GMT+0000 (Coordinated Universal Time)" itemprop=datePublished data-visual-test=blackout>Nov 20, 2025</time>/ Stable release</div></div></div></button></div></ul></div><div class=""><div class=toggle_vylO><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg aria-hidden=true class="toggleIcon_g3eP lightToggleIcon_pyhR" width=22 height=22 fill=none xmlns=http://www.w3.org/2000/svg><g stroke=currentColor stroke-width=1.5><path d="m3.5 18.5 2-2M16.5 16.5l2 2M18.5 3.5l-2 2M5.5 5.5l-2-2M11 22v-3M11 3V0M0 11h3M19 11h3M7.5 11a3.5 3.5 0 1 1 7 0 3.5 3.5 0 0 1-7 0Z"/></g></svg><svg aria-hidden=true class="toggleIcon_g3eP darkToggleIcon_wfgR" width=22 height=22 fill=none xmlns=http://www.w3.org/2000/svg><path d="M8 1a10 10 0 1 1-5.74 18.2 8.5 8.5 0 0 0 0-16.4A9.95 9.95 0 0 1 8 1Z" stroke=white stroke-width=1.5 /></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill=currentColor d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"/></svg></button></div></div><a href=https://github.com/modular/modular target=_blank rel="noopener noreferrer" style="--ai-size:calc(2rem * var(--mantine-scale));--ai-bg:transparent;--ai-hover:transparent;--ai-color:var(--mantine-color-blue-light-color);--ai-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent" class="mantine-focus-auto mantine-active m_8d3f4000 mantine-ActionIcon-root m_87cf2631 mantine-UnstyledButton-root" data-variant=transparent><span class="m_8d3afb97 mantine-ActionIcon-icon"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))" color=var(--Black) fill=currentColor><g clip-path=url(#:Rbatllldcleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rbatllldcleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg></span></a><div class="docs-search-bar DocSearch-Button-Only"><div class=shared-search-bar><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts=Meta+k><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 24 24" aria-hidden=true><circle cx=11 cy=11 r=8 stroke=currentColor fill=none stroke-width=1.4 /><path d="m21 21-4.3-4.3" stroke=currentColor fill=none stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div></div></div></div><div class=mantine-hidden-from-xl><nav aria-label=Main class="navbar navbar--fixed-top"><div class="!pr-0 pl-6 xl:pl-0 navbar__inner"><div class=navbar__items><div style="--group-gap:calc(1.375rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="m_4081bf90 mantine-Group-root"><a class="navbar__item navbar__link" href=/max/intro>Guides</a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/max/api/>APIs</a><a class="navbar__item navbar__link" href=/mojo/manual/>Mojo</a></div></div><div class="navbar__items navbar__items--right"></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav></div></div><div style="height:calc(4.5rem * var(--mantine-scale));min-height:calc(4.5rem * var(--mantine-scale))" class=""></div><div style="height:calc(2.625rem * var(--mantine-scale));min-height:calc(2.625rem * var(--mantine-scale))" class="mantine-hidden-from-xl mantine-visible-from-sm"></div><div id=__docusaurus_skipToContent_fallback class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class=docsWrapper_yGWD><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_oL3q><aside class="theme-doc-sidebar-container docSidebarContainer_XbDZ"><div class=sidebarViewport_cWno><div class=sidebar_YabQ><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/max/api/><span title=Overview class=linkLabel_WmDU>Overview</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-heading"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true href=/max/api/python/><span title=Python class=categoryLinkLabel_W154>Python</span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/><span title=max class=linkLabel_WmDU>max</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/max/api/python/diagnostics/gpu/><span title=diagnostics class=categoryLinkLabel_W154>diagnostics</span></a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/driver><span title=driver class=linkLabel_WmDU>driver</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/dtype><span title=dtype class=linkLabel_WmDU>dtype</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/engine><span title=engine class=linkLabel_WmDU>engine</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/entrypoints><span title=entrypoints class=linkLabel_WmDU>entrypoints</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/experimental/><span title=experimental class=categoryLinkLabel_W154>experimental</span></a><button aria-label="Expand sidebar category 'experimental'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/graph/><span title=graph class=categoryLinkLabel_W154>graph</span></a><button aria-label="Expand sidebar category 'graph'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/interfaces><span title=interfaces class=linkLabel_WmDU>interfaces</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/kv_cache/><span title=kv_cache class=categoryLinkLabel_W154>kv_cache</span></a><button aria-label="Expand sidebar category 'kv_cache'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex=0 href=/max/api/python/nn/><span title=nn class=categoryLinkLabel_W154>nn</span></a><button aria-label="Collapse sidebar category 'nn'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex=0 href=/max/api/python/nn/attention/><span title=attention class=categoryLinkLabel_W154>attention</span></a><button aria-label="Collapse sidebar category 'attention'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/max/api/python/nn/attention/attention_with_rope><span title=attention_with_rope class=linkLabel_WmDU>attention_with_rope</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/attention/interfaces><span title=interfaces class=linkLabel_WmDU>interfaces</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/attention/mask_config><span title=mask_config class=linkLabel_WmDU>mask_config</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/attention/multi_latent_attention><span title=multi_latent_attention class=linkLabel_WmDU>multi_latent_attention</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/attention/multihead_attention><span title=multihead_attention class=linkLabel_WmDU>multihead_attention</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/attention/ragged_attention><span title=ragged_attention class=linkLabel_WmDU>ragged_attention</span></a></ul><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/clamp><span title=clamp class=linkLabel_WmDU>clamp</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/comm/><span title=comm class=linkLabel_WmDU>comm</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/conv><span title=conv class=linkLabel_WmDU>conv</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/conv_transpose><span title=conv_transpose class=linkLabel_WmDU>conv_transpose</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/embedding><span title=embedding class=linkLabel_WmDU>embedding</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/float8_config><span title=float8_config class=linkLabel_WmDU>float8_config</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/hooks><span title=hooks class=linkLabel_WmDU>hooks</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/kernels><span title=kernels class=linkLabel_WmDU>kernels</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/nn/kv_cache/><span title=kv_cache class=categoryLinkLabel_W154>kv_cache</span></a><button aria-label="Expand sidebar category 'kv_cache'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/layer><span title=layer class=linkLabel_WmDU>layer</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/linear><span title=linear class=linkLabel_WmDU>linear</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/lora><span title=lora class=linkLabel_WmDU>lora</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/module_v3><span title=module_v3 class=linkLabel_WmDU>module_v3</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/moe><span title=moe class=linkLabel_WmDU>moe</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/norm><span title=norm class=linkLabel_WmDU>norm</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/rotary_embedding><span title=rotary_embedding class=linkLabel_WmDU>rotary_embedding</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/sampling><span title=sampling class=linkLabel_WmDU>sampling</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/nn/sequential><span title=sequential class=linkLabel_WmDU>sequential</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/nn/transformer/><span title=transformer class=categoryLinkLabel_W154>transformer</span></a><button aria-label="Expand sidebar category 'transformer'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/max/api/python/pipelines/><span title=pipelines class=categoryLinkLabel_W154>pipelines</span></a><button aria-label="Expand sidebar category 'pipelines'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/profiler><span title=profiler class=linkLabel_WmDU>profiler</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/python/torch><span title=torch class=linkLabel_WmDU>torch</span></a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-heading"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=true href=/mojo/lib><span title=Mojo class=categoryLinkLabel_W154>Mojo</span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/mojo/lib><span title=Overview class=linkLabel_WmDU>Overview</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/mojo/std/><span title="Standard library" class=categoryLinkLabel_W154>Standard library</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/mojo/kernels/comm/><span title="MAX AI kernels" class=categoryLinkLabel_W154>MAX AI kernels</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/mojo/manual/decorators/><span title=Decorators class=categoryLinkLabel_W154>Decorators</span></a></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-heading"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=true href=/max/api/serve><span title=REST class=categoryLinkLabel_W154>REST</span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve><span title="Get started" class=linkLabel_WmDU>Get started</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#section/OpenAI-API-compatibility><span title="OpenAI API compatibility" class=linkLabel_WmDU>OpenAI API compatibility</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#operation/createChatCompletion><span title="Create chat completion" class=linkLabel_WmDU>Create chat completion</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#operation/createCompletion><span title="Create completion" class=linkLabel_WmDU>Create completion</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#operation/createEmbedding><span title="Create embeddings" class=linkLabel_WmDU>Create embeddings</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#operation/createBatch><span title="Create batch" class=linkLabel_WmDU>Create batch</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/max/api/serve#operation/listModels><span title="List models" class=linkLabel_WmDU>List models</span></a></ul></ul></nav><div class=mantine-hidden-from-xl><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_JQXm"><div style="--group-gap:calc(0.75rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="m_4081bf90 mantine-Group-root"><svg viewBox="0 0 20 20" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1rem * var(--mantine-scale));height:calc(1rem * var(--mantine-scale))" class=collapseSidebarButtonIcon_Pv6V><path d="m6.958 1.042 8.75 8.75-8.75 8.75" stroke=currentColor stroke-width=1.5 /><path d="m.708 1.042 8.75 8.75-8.75 8.75" stroke=currentColor stroke-width=1.5 /></svg> <p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Collapse sidebar</div></button></div></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_R_bt"><div class=docItemContainer_qGQi><article class="sphinx-docs module"><div class=mantine-visible-from-sm><nav class="theme-doc-breadcrumbs line-clamp-1 w-[calc(100%-24px)] mb-6 mt-3 xl:mt-0" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 14 14" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" class=mt-0.5><path d="M6.5 1.042.542 7v5.953h4.875V9.161h2.166v3.797h3.792v-.812c0-.152.12-.27.27-.27h.813V7L6.5 1.042Zm2.167 7.041H4.333v3.792H1.625V7.45L6.5 2.575l4.875 4.875v4.154c0 .152-.12.271-.27.271H8.666V8.083Z" fill=currentColor /></svg> Docs</a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/><span itemprop=name>APIs</span></a><meta itemprop=position content=2 /><li class=breadcrumbs__item><span class=breadcrumbs__link>/</span><span class=breadcrumbs__link>Python</span><meta itemprop=position content=1 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/python/nn/><span itemprop=name>nn</span></a><meta itemprop=position content=2 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/python/nn/attention/><span itemprop=name>attention</span></a><meta itemprop=position content=3 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>/</span><span class=breadcrumbs__link itemprop=name>attention_with_rope</span><meta itemprop=position content=4 /></ul></nav></div><div class=mantine-hidden-from-sm><div class="my-4 theme-doc-toc-mobile tocMobile_ITEo !border-none"><div style=--group-gap:var(--mantine-spacing-md);--group-align:center;--group-justify:space-between;--group-wrap:nowrap class="mb-3 m_4081bf90 mantine-Group-root"><nav class="theme-doc-breadcrumbs line-clamp-1 w-[calc(100%-24px)] mb-6 mt-3 xl:mt-0" aria-label=Breadcrumbs><ul class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 14 14" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" class=mt-0.5><path d="M6.5 1.042.542 7v5.953h4.875V9.161h2.166v3.797h3.792v-.812c0-.152.12-.27.27-.27h.813V7L6.5 1.042Zm2.167 7.041H4.333v3.792H1.625V7.45L6.5 2.575l4.875 4.875v4.154c0 .152-.12.271-.27.271H8.666V8.083Z" fill=currentColor /></svg> Docs</a><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/><span itemprop=name>APIs</span></a><meta itemprop=position content=2 /><li class=breadcrumbs__item><span class=breadcrumbs__link>/</span><span class=breadcrumbs__link>Python</span><meta itemprop=position content=1 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/python/nn/><span itemprop=name>nn</span></a><meta itemprop=position content=2 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class=breadcrumbs__item><span class=breadcrumbs__link>/</span><a class=breadcrumbs__link itemprop=item href=/max/api/python/nn/attention/><span itemprop=name>attention</span></a><meta itemprop=position content=3 /><li itemscope itemprop=itemListElement itemtype=https://schema.org/ListItem class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>/</span><span class=breadcrumbs__link itemprop=name>attention_with_rope</span><meta itemprop=position content=4 /></ul></nav><button class="mantine-focus-auto clean-btn tocCollapsibleButton_QABo tocCollapsibleButtonCollapsed_CrWs m_87cf2631 mantine-UnstyledButton-root" type=button></button></div></div></div><div class="theme-doc-markdown markdown"><header class=api><p class=suptitle>Python <span class=page-type>module</span><h1>attention_with_rope</h1></header><p><a id=module-max.nn.attention.attention_with_rope class=anchorTargetStickyNavbar_Vzrq></a></p>
<p>An opaque KV Cache optimized attention mechanism with Rope.</p>
<section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope><code>AttentionWithRope</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.AttentionWithRope(*, rope, sharding_strategy=None, num_attention_heads, num_key_value_heads, hidden_size, kv_params, devices=None, dtype=float32, linear_cls=&lt;class 'max.nn.linear.Linear'>, stacked_qkv=False, scale=None, has_bias=False, float8_config=None, clip_qkv=None, use_qk_norm=False, rms_norm_eps=1e-06)</p>
</blockquote>
<p>Implementation of attention that uses Rotary Position Embedding (RoPE).</p>
<p>Initializes the attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>sharding_strategy</strong> (<em class=code>ShardingStrategy</em> <em class=code>|</em> <em class=code>None</em>)  Optional initial sharding strategy.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the QKV and output projection weights.</li>
<li class=""><strong class=code>devices</strong> (<em class=code>Sequence</em><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. If multiple are
provided, the first device is used for weight placement here.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for projections.</li>
<li class=""><strong class=code>stacked_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether Q/K/V weights are stacked in a single Weight.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Optional attention scale; defaults to sqrt(1/head_dim).</li>
<li class=""><strong class=code>has_bias</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether Q/K/V have bias (stacked_qkv forbids bias).</li>
<li class=""><strong class=code>float8_config</strong> (<a class="" href=/max/api/python/nn/float8_config#max.nn.float8_config.Float8Config><em class=code>Float8Config</em></a> <em class=code>|</em> <em class=code>None</em>)  Optional Float8 config (dynamic or static).</li>
<li class=""><strong class=code>clip_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  If provided, clamp Q/K/V weights to [-clip_qkv, clip_qkv].</li>
<li class=""><strong class=code>use_qk_norm</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether to use RMSNorm on Q/K.</li>
<li class=""><strong class=code>rms_norm_eps</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a>)  Value to use for numerical stability in RMSNorm.</li>
</ul>
</dl>
<section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale><code>qkv_input_scale</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale" translate=no></a></h3>
<blockquote>
<p>property qkv_input_scale: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a> | <a href=https://docs.python.org/3/library/constants.html#None target=_blank rel="noopener noreferrer" class="">None</a></p>
</blockquote>
<p>The max of q, k, and v scale input vectors.</p>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale><code>qkv_weight_scale</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale" translate=no></a></h3>
<blockquote>
<p>property qkv_weight_scale: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a></p>
</blockquote>
<p>The max of q, k, and v scale weight vectors.</p>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.rope><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.rope><code>rope</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.rope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.rope" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.rope" translate=no></a></h3>
<blockquote>
<p>rope: <a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding>RotaryEmbedding</a></p>
</blockquote>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.shard><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.shard><code>shard()</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.shard class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.shard" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.shard" translate=no></a></h3>
<blockquote>
<p>shard(devices)</p>
</blockquote>
<p>Create sharded views across devices (tensor-parallel).</p>
<p>Returns one AttentionWithRope per device with appropriately sliced weights.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<p><strong class=code>devices</strong> (<a href=https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable target=_blank rel="noopener noreferrer" class=""><em class=code>Iterable</em></a><em class=code>[</em><a class="" href=/max/api/python/graph/type#max.graph.type.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em>)</p>
<dt>
<p><strong>Return type:</strong></p>
<dd>
<p><a href=https://docs.python.org/3/library/stdtypes.html#list target=_blank rel="noopener noreferrer" class="">list</a>[<a href=#max.nn.attention.attention_with_rope.AttentionWithRope class=""><em class=code>AttentionWithRope</em></a>]</p>
</dl>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy><code>sharding_strategy</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy" translate=no></a></h3>
<blockquote>
<p>property sharding_strategy: ShardingStrategy | <a href=https://docs.python.org/3/library/constants.html#None target=_blank rel="noopener noreferrer" class="">None</a></p>
</blockquote>
<p>Get the Module sharding strategy.</p>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.wqkv><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.wqkv><code>wqkv</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.wqkv" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.wqkv" translate=no></a></h3>
<blockquote>
<p>property wqkv: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a></p>
</blockquote>
<p>The concatenation of q, k, and v weight vectors.</p>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias><code>wqkv_bias</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias" translate=no></a></h3>
<blockquote>
<p>property wqkv_bias: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a> | <a href=https://docs.python.org/3/library/constants.html#None target=_blank rel="noopener noreferrer" class="">None</a></p>
</blockquote>
<p>The concatenation of q, k, and v bias weight vectors.</p>
</section></section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque><code>AttentionWithRopeNoOpaque</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque(*, rope, num_attention_heads, num_key_value_heads, hidden_size, kv_params, devices=None, dtype=float32, linear_cls=&lt;class 'max.nn.linear.Linear'>, scale=None)</p>
</blockquote>
<p>Attention with RoPE without opaque KV cache.</p>
<dl><dt>Assumes:<dd><li class="">no float8</li></dl>
<ul>
<li class="">no stacked qkv</li>
<li class="">no bias</li>
<li class="">no clip_qkv</li>
<li class="">no float8_config</li>
</ul>
<p>Initializes the attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the QKV and output projection weights.</li>
<li class=""><strong class=code>devices</strong> (<em class=code>Sequence</em><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. If
multiple are provided, the first device is used. Use
TensorParallelAttentionWithRope to use all devices during
attention computation.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for the outputs dense layer.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Value used to scale the results of the attention output.</li>
</ul>
</dl>
<section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope><code>rope</code><a href=#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope" title="Direct link to max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope" translate=no></a></h3>
<blockquote>
<p>rope: <a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding>RotaryEmbedding</a></p>
</blockquote>
</section></section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.DataParallelAttentionWithRope><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.DataParallelAttentionWithRope><code>DataParallelAttentionWithRope</code><a href=#max.nn.attention.attention_with_rope.DataParallelAttentionWithRope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.DataParallelAttentionWithRope" title="Direct link to max.nn.attention.attention_with_rope.DataParallelAttentionWithRope" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.DataParallelAttentionWithRope(*, rope, num_attention_heads, num_key_value_heads, hidden_size, kv_params, devices=None, dtype=float32, linear_cls=&lt;class 'max.nn.linear.Linear'>, stacked_qkv=False, scale=None, has_bias=False, float8_config=None, clip_qkv=None, use_qk_norm=False, rms_norm_eps=1e-06)</p>
</blockquote>
<p>Data-parallel implementation of Attention with RoPE.</p>
<p>This replicates the attention module across devices and runs each replica on
its local inputs (x, kv, freqs_cis, input_row_offsets). No collective ops
are required; KV-cache remains local to each device.</p>
<p><strong>Notes:</strong></p>
<ul>
<li class="">Assumes the caller has already distributed xs, kv_collections,
freqs_cis, and input_row_offsets so that index i corresponds to
device i, with input_row_offsets[i] rebased to start at 0.</li>
</ul>
<p>Initializes the attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>sharding_strategy</strong>  Optional initial sharding strategy.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the QKV and output projection weights.</li>
<li class=""><strong class=code>devices</strong> (<em class=code>Sequence</em><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. If multiple are
provided, the first device is used for weight placement here.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for projections.</li>
<li class=""><strong class=code>stacked_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether Q/K/V weights are stacked in a single Weight.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Optional attention scale; defaults to sqrt(1/head_dim).</li>
<li class=""><strong class=code>has_bias</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether Q/K/V have bias (stacked_qkv forbids bias).</li>
<li class=""><strong class=code>float8_config</strong> (<a class="" href=/max/api/python/nn/float8_config#max.nn.float8_config.Float8Config><em class=code>Float8Config</em></a> <em class=code>|</em> <em class=code>None</em>)  Optional Float8 config (dynamic or static).</li>
<li class=""><strong class=code>clip_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  If provided, clamp Q/K/V weights to [-clip_qkv, clip_qkv].</li>
<li class=""><strong class=code>use_qk_norm</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether to use RMSNorm on Q/K.</li>
<li class=""><strong class=code>rms_norm_eps</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a>)  Value to use for numerical stability in RMSNorm.</li>
</ul>
</dl>
</section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope><code>GGUFQAttentionWithRope</code><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope" title="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.GGUFQAttentionWithRope(*, rope, num_attention_heads, num_key_value_heads, hidden_size, kv_params, dtype, quantization_encoding, devices=None, linear_cls=&lt;class 'max.nn.linear.Linear'>, scale=None, has_bias=False, clip_qkv=None)</p>
</blockquote>
<p>Implementation of attention with GGUF quantized weights.</p>
<p>Initializes the GGUF attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>layer_idx</strong>  The layer number associated with this Attention block.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the weights, should always be uint8.</li>
<li class=""><strong class=code>devices</strong> (<a href=https://docs.python.org/3/library/stdtypes.html#list target=_blank rel="noopener noreferrer" class=""><em class=code>list</em></a><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. If
multiple are provided, the first device is used. Use
TensorParallelAttentionWithRope to use all devices during
attention computation.</li>
<li class=""><strong class=code>quantization_encoding</strong> (<a class="" href=/max/api/python/graph/quantization#max.graph.quantization.QuantizationEncoding><em class=code>QuantizationEncoding</em></a>)  Quantization encoding of the weights.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for the outputs dense layer.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Value used to scale the results of the attention output.</li>
<li class=""><strong class=code>has_bias</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether to use an attention bias.</li>
<li class=""><strong class=code>clip_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  If provided, the QKV weights are clamped between
[-clip_qkv, clip_qkv]</li>
</ul>
</dl>
<section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope><code>rope</code><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope" title="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope" translate=no></a></h3>
<blockquote>
<p>rope: <a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding>RotaryEmbedding</a></p>
</blockquote>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv><code>wqkv</code><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv" title="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv" translate=no></a></h3>
<blockquote>
<p>property wqkv: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a></p>
</blockquote>
<p>The concatenation of q, k, and v weight vectors.</p>
</section><section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias><code>wqkv_bias</code><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias" title="Direct link to max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias" translate=no></a></h3>
<blockquote>
<p>property wqkv_bias: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a> | <a href=https://docs.python.org/3/library/constants.html#None target=_blank rel="noopener noreferrer" class="">None</a></p>
</blockquote>
<p>The concatenation of q, k, and v bias weight vectors.</p>
</section></section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.GPTQAttentionWithRope><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GPTQAttentionWithRope><code>GPTQAttentionWithRope</code><a href=#max.nn.attention.attention_with_rope.GPTQAttentionWithRope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GPTQAttentionWithRope" title="Direct link to max.nn.attention.attention_with_rope.GPTQAttentionWithRope" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.GPTQAttentionWithRope(quantization_config, rope, num_attention_heads, num_key_value_heads, hidden_size, kv_params, devices=None, dtype=float32, scale=None, linear_cls=&lt;class 'max.nn.linear.Linear'>)</p>
</blockquote>
<p>Implementation of the GPTQ attention layer.</p>
<p>Initializes the attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>sharding_strategy</strong>  Optional initial sharding strategy.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the QKV and output projection weights.</li>
<li class=""><strong class=code>devices</strong> (<a href=https://docs.python.org/3/library/stdtypes.html#list target=_blank rel="noopener noreferrer" class=""><em class=code>list</em></a><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. If multiple are
provided, the first device is used for weight placement here.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for projections.</li>
<li class=""><strong class=code>stacked_qkv</strong>  Whether Q/K/V weights are stacked in a single Weight.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Optional attention scale; defaults to sqrt(1/head_dim).</li>
<li class=""><strong class=code>has_bias</strong>  Whether Q/K/V have bias (stacked_qkv forbids bias).</li>
<li class=""><strong class=code>float8_config</strong>  Optional Float8 config (dynamic or static).</li>
<li class=""><strong class=code>clip_qkv</strong>  If provided, clamp Q/K/V weights to [-clip_qkv, clip_qkv].</li>
<li class=""><strong class=code>use_qk_norm</strong>  Whether to use RMSNorm on Q/K.</li>
<li class=""><strong class=code>rms_norm_eps</strong>  Value to use for numerical stability in RMSNorm.</li>
<li class=""><strong class=code>quantization_config</strong> (<a class="" href=/max/api/python/graph/quantization#max.graph.quantization.QuantizationConfig><em class=code>QuantizationConfig</em></a>)</li>
</ul>
</dl>
<section class=heading data-heading-rank=3 aria-labelledby=max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv><h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv><code>wqkv</code><a href=#max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv" title="Direct link to max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv" translate=no></a></h3>
<blockquote>
<p>property wqkv: <a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue>TensorValue</a></p>
</blockquote>
<p>The concatenation of q, k, and v weight vectors (packed + scales).</p>
</section></section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope><code>TensorParallelAttentionWithRope</code><a href=#max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope" title="Direct link to max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope" translate=no></a></h2>
<blockquote>
<p>class max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope(*, rope, num_attention_heads, num_key_value_heads, hidden_size, kv_params, devices=None, dtype=float32, linear_cls=&lt;class 'max.nn.linear.Linear'>, stacked_qkv=False, scale=None, has_bias=False, float8_config=None, clip_qkv=None, use_qk_norm=False, rms_norm_eps=1e-06)</p>
</blockquote>
<p>Tensor-parallel wrapper that delegates sharding to the base module.</p>
<p>Initializes the distributed (tensor parallel) attention layer.</p>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>rope</strong> (<a class="" href=/max/api/python/nn/rotary_embedding#max.nn.rotary_embedding.RotaryEmbedding><em class=code>RotaryEmbedding</em></a>)  The rope layer to borrow the freqs_cis value from.</li>
<li class=""><strong class=code>num_attention_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The number of attention heads.</li>
<li class=""><strong class=code>num_key_value_heads</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  Number of key/value heads.</li>
<li class=""><strong class=code>hidden_size</strong> (<a href=https://docs.python.org/3/library/functions.html#int target=_blank rel="noopener noreferrer" class=""><em class=code>int</em></a>)  The dimension of the hidden states.</li>
<li class=""><strong class=code>kv_params</strong> (<a class="" href=/max/api/python/nn/kv_cache/cache_params#max.nn.kv_cache.cache_params.KVCacheParams><em class=code>KVCacheParams</em></a>)  KV Cache params, including number of kv heads, head dim, and dtype.</li>
<li class=""><strong class=code>devices</strong> (<em class=code>Sequence</em><em class=code>[</em><a class="" href=/max/api/python/graph/ops#max.graph.ops.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em> <em class=code>|</em> <em class=code>None</em>)  Device(s) on which to place the weights and run the computation. Must
provide at least 2 devices for tensor parallel attention.</li>
<li class=""><strong class=code>dtype</strong> (<a class="" href=/max/api/python/dtype#max.dtype.DType><em class=code>DType</em></a>)  DType of the QKV and output projection weights.</li>
<li class=""><strong class=code>linear_cls</strong> (<a class="" href=/max/api/python/graph/ops#max.graph.ops.Callable><em class=code>Callable</em></a><em class=code>[</em><em class=code>...</em><em class=code>,</em> <a class="" href=/max/api/python/nn/linear#max.nn.linear.Linear><em class=code>Linear</em></a><em class=code>]</em>)  Linear class to use for the outputs dense layer.</li>
<li class=""><strong class=code>stacked_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether the weights are stacked together.</li>
<li class=""><strong class=code>scale</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  Value used to scale the results of the attention output.</li>
<li class=""><strong class=code>has_bias</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether to use an attention bias.</li>
<li class=""><strong class=code>float8_config</strong> (<a class="" href=/max/api/python/nn/float8_config#max.nn.float8_config.Float8Config><em class=code>Float8Config</em></a> <em class=code>|</em> <em class=code>None</em>)  Float8 configuration for quantization.</li>
<li class=""><strong class=code>clip_qkv</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a> <em class=code>|</em> <em class=code>None</em>)  If provided, the QKV weights are clamped between
[-clip_qkv, clip_qkv].</li>
<li class=""><strong class=code>use_qk_norm</strong> (<a href=https://docs.python.org/3/library/functions.html#bool target=_blank rel="noopener noreferrer" class=""><em class=code>bool</em></a>)  Whether to use RMSNorm on Q/K.</li>
<li class=""><strong class=code>rms_norm_eps</strong> (<a href=https://docs.python.org/3/library/functions.html#float target=_blank rel="noopener noreferrer" class=""><em class=code>float</em></a>)  Value to use for numerical stability in RMSNorm.</li>
</ul>
</dl>
</section><section class=heading data-heading-rank=2 aria-labelledby=max.nn.attention.attention_with_rope.distribute_value><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=max.nn.attention.attention_with_rope.distribute_value><code>distribute_value()</code><a href=#max.nn.attention.attention_with_rope.distribute_value class=hash-link aria-label="Direct link to max.nn.attention.attention_with_rope.distribute_value" title="Direct link to max.nn.attention.attention_with_rope.distribute_value" translate=no></a></h2>
<blockquote>
<p>max.nn.attention.attention_with_rope.distribute_value(v, devices)</p>
</blockquote>
<dl class=field-list><dt>
<p><strong>Parameters:</strong></p>
<dd>
<ul>
<li class=""><strong class=code>v</strong> (<a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue><em class=code>TensorValue</em></a>)</li>
<li class=""><strong class=code>devices</strong> (<a href=https://docs.python.org/3/library/stdtypes.html#list target=_blank rel="noopener noreferrer" class=""><em class=code>list</em></a><em class=code>[</em><a class="" href=/max/api/python/graph/type#max.graph.type.DeviceRef><em class=code>DeviceRef</em></a><em class=code>]</em>)</li>
</ul>
<dt>
<p><strong>Return type:</strong></p>
<dd>
<p><a href=https://docs.python.org/3/library/stdtypes.html#list target=_blank rel="noopener noreferrer" class="">list</a>[<a class="" href=/max/api/python/graph/TensorValue#max.graph.TensorValue><em class=code>TensorValue</em></a>]</p>
</dl>
</section><div class="hidden docs-desktop:block w-full docs-desktop:mt-11"><div style=--group-gap:0rem;--group-align:center;--group-justify:flex-start;--group-wrap:wrap class="relative transition-all duration-200 w-full justify-end docs-desktop:justify-center m_4081bf90 mantine-Group-root"><p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto mr-1 !text-sm docs-desktop:mr-3 docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Was this page helpful?</p><button style="--ai-bg:transparent;--ai-hover:color-mix(in srgb, var(--Elements-Twilight-60-50), transparent 88%);--ai-color:var(--Elements-Twilight-60-50);--ai-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent" class="mantine-focus-auto mantine-active w-8 docs-desktop:w-[42px] m_8d3f4000 mantine-ActionIcon-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle type=button><span class="m_8d3afb97 mantine-ActionIcon-icon"><svg viewBox="0 0 20 18" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))"><path d="M5 8.58v7.92M16.25 16.5H1.67V8.58H5L7.08 1.5h.75a3 3 0 0 1 3 3v2h7.5l-2.08 10Z" stroke=currentColor stroke-width=1.5 /></svg></span></button><button style="--ai-bg:transparent;--ai-hover:color-mix(in srgb, var(--Elements-Twilight-60-50), transparent 88%);--ai-color:var(--Elements-Twilight-60-50);--ai-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent" class="mantine-focus-auto mantine-active w-8 docs-desktop:w-[42px] m_8d3f4000 mantine-ActionIcon-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle type=button><span class="m_8d3afb97 mantine-ActionIcon-icon"><svg viewBox="0 0 20 18" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))" class=rotate-180><path d="M5 8.58v7.92M16.25 16.5H1.67V8.58H5L7.08 1.5h.75a3 3 0 0 1 3 3v2h7.5l-2.08 10Z" stroke=currentColor stroke-width=1.5 /></svg></span></button></div><p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto h-0 docs-desktop:translate-y-4 scale-y-0 opacity-0 relative m-auto transition-all duration-200 text-center !text-sm docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Thank you! We'll create more content like this.<p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto h-0 docs-desktop:translate-y-4 scale-y-0 opacity-0 relative m-auto transition-all duration-200 text-center !text-sm docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Thank you for helping us improve!<div style=--stack-gap:0rem;--stack-align:center;--stack-justify:flex-start;margin-top:var(--mantine-spacing-md) class="m_6d731127 mantine-Stack-root"><div style=--stack-gap:var(--mantine-spacing-md);--stack-align:stretch;--stack-justify:flex-start class="h-0 docs-desktop:translate-y-4 scale-y-0 opacity-0 m-auto w-60 relative m-auto transition-all duration-200 hidden docs-desktop:flex m_6d731127 mantine-Stack-root"><p style="font-size:calc(1.5rem * var(--mantine-scale));font-weight:400;line-height:calc(2rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root"> What went wrong?<div class="m_46b77525 mantine-InputWrapper-root mantine-RadioGroup-root"><div role=radiogroup aria-labelledby=mantine-R3ar5rcmlalleh-label><div style=--stack-gap:var(--mantine-spacing-md);--stack-align:stretch;--stack-justify:flex-start;margin-top:var(--mantine-spacing-xs) class="m_6d731127 mantine-Stack-root"><div style=--radio-icon-color:var(--White);--radio-color:var(--Elements-Neb-Ultra-Super) class="m_f3f1af94 mantine-Radio-root m_5f75b09e mantine-Radio-root" data-label-position=right><div class="m_5f6e695e mantine-Radio-body"><div class="m_89c4f5e4 mantine-Radio-inner" data-label-position=right><input class="mantine-focus-auto border-Elements-Twilight-60-50 m_8a3dbb89 mantine-Radio-radio" name=mantine-R1ar5rcmlalleh id=mantine-Rmnfar5rcmlalleh type=radio value=broken_code /><svg xmlns=http://www.w3.org/2000/svg fill=none viewBox="0 0 5 5" aria-hidden=true class="m_f3ed6b2b mantine-Radio-icon"><circle cx=2.5 cy=2.5 r=2.5 fill=currentColor /></svg></div><div class="m_d3ea56bb mantine-Radio-labelWrapper"><label class="m_8ee546b8 mantine-Radio-label" for=mantine-Rmnfar5rcmlalleh>Some code doesnt work</label></div></div></div><div style=--radio-icon-color:var(--White);--radio-color:var(--Elements-Neb-Ultra-Super) class="m_f3f1af94 mantine-Radio-root m_5f75b09e mantine-Radio-root" data-label-position=right><div class="m_5f6e695e mantine-Radio-body"><div class="m_89c4f5e4 mantine-Radio-inner" data-label-position=right><input class="mantine-focus-auto border-Elements-Twilight-60-50 m_8a3dbb89 mantine-Radio-radio" name=mantine-R1ar5rcmlalleh id=mantine-R16nfar5rcmlalleh type=radio value=factual_error /><svg xmlns=http://www.w3.org/2000/svg fill=none viewBox="0 0 5 5" aria-hidden=true class="m_f3ed6b2b mantine-Radio-icon"><circle cx=2.5 cy=2.5 r=2.5 fill=currentColor /></svg></div><div class="m_d3ea56bb mantine-Radio-labelWrapper"><label class="m_8ee546b8 mantine-Radio-label" for=mantine-R16nfar5rcmlalleh>It includes inaccurate information</label></div></div></div><div style=--radio-icon-color:var(--White);--radio-color:var(--Elements-Neb-Ultra-Super) class="m_f3f1af94 mantine-Radio-root m_5f75b09e mantine-Radio-root" data-label-position=right><div class="m_5f6e695e mantine-Radio-body"><div class="m_89c4f5e4 mantine-Radio-inner" data-label-position=right><input class="mantine-focus-auto border-Elements-Twilight-60-50 m_8a3dbb89 mantine-Radio-radio" name=mantine-R1ar5rcmlalleh id=mantine-R1mnfar5rcmlalleh type=radio value=missing_info /><svg xmlns=http://www.w3.org/2000/svg fill=none viewBox="0 0 5 5" aria-hidden=true class="m_f3ed6b2b mantine-Radio-icon"><circle cx=2.5 cy=2.5 r=2.5 fill=currentColor /></svg></div><div class="m_d3ea56bb mantine-Radio-labelWrapper"><label class="m_8ee546b8 mantine-Radio-label" for=mantine-R1mnfar5rcmlalleh>It's missing information I need</label></div></div></div><div style=--radio-icon-color:var(--White);--radio-color:var(--Elements-Neb-Ultra-Super) class="m_f3f1af94 mantine-Radio-root m_5f75b09e mantine-Radio-root" data-label-position=right><div class="m_5f6e695e mantine-Radio-body"><div class="m_89c4f5e4 mantine-Radio-inner" data-label-position=right><input class="mantine-focus-auto border-Elements-Twilight-60-50 m_8a3dbb89 mantine-Radio-radio" name=mantine-R1ar5rcmlalleh id=mantine-R26nfar5rcmlalleh type=radio value=confusing /><svg xmlns=http://www.w3.org/2000/svg fill=none viewBox="0 0 5 5" aria-hidden=true class="m_f3ed6b2b mantine-Radio-icon"><circle cx=2.5 cy=2.5 r=2.5 fill=currentColor /></svg></div><div class="m_d3ea56bb mantine-Radio-labelWrapper"><label class="m_8ee546b8 mantine-Radio-label" for=mantine-R26nfar5rcmlalleh>It was difficult to understand</label></div></div></div><div style=--radio-icon-color:var(--White);--radio-color:var(--Elements-Neb-Ultra-Super) class="m_f3f1af94 mantine-Radio-root m_5f75b09e mantine-Radio-root" data-label-position=right><div class="m_5f6e695e mantine-Radio-body"><div class="m_89c4f5e4 mantine-Radio-inner" data-label-position=right><input class="mantine-focus-auto border-Elements-Twilight-60-50 m_8a3dbb89 mantine-Radio-radio" name=mantine-R1ar5rcmlalleh id=mantine-R2mnfar5rcmlalleh type=radio value=other /><svg xmlns=http://www.w3.org/2000/svg fill=none viewBox="0 0 5 5" aria-hidden=true class="m_f3ed6b2b mantine-Radio-icon"><circle cx=2.5 cy=2.5 r=2.5 fill=currentColor /></svg></div><div class="m_d3ea56bb mantine-Radio-labelWrapper"><label class="m_8ee546b8 mantine-Radio-label" for=mantine-R2mnfar5rcmlalleh>Other</label></div></div></div><div style=--stack-gap:0rem;--stack-align:stretch;--stack-justify:flex-start class="m_6d731127 mantine-Stack-root"><a href="https://github.com/modular/modular/issues/new?assignees=&labels=documentation%2Cmodular-repo&projects=&template=doc_issue.yaml&title=%5BDocs%5D&url=https://docs.modular.com/max/api/python/nn/attention/attention_with_rope" target=_blank rel="noopener noreferrer" style="opacity:0.4;background:var(--Elements-Neb-100-Twilight-60);color:var(--Black);--button-height:calc(1.75rem * var(--mantine-scale));--button-padding-x:calc(0.875rem * var(--mantine-scale));--button-fz:calc(0.75rem * var(--mantine-scale));--button-color:var(--Elements-Twilight-100);--button-bg:var(--Elements-Neb-90-Ultra);--button-hover:var(--Elements-Neb-Ultra-Super);font-weight:400" class="mantine-focus-auto onActive_LK5j onHover_fkhK no-transition !font-normal m_77c9d27d mantine-Button-root m_87cf2631 mantine-UnstyledButton-root" data-size=xs data-disabled=true disabled=""><span class="m_80f1301b mantine-Button-inner"><span class="m_811560b9 mantine-Button-label">Submit</span></span></a></div></div></div></div></div></div></div></div></article></div></div><div class="col col--3 !mx-0"><div class="rightRail_g3t8 thin-scrollbar"><style data-mantine-styles=inline>.__m__-R36lalleh{flex-direction:row}@media (width>=997px){.__m__-R36lalleh{flex-direction:column}}</style><div class="hidden flex-col gap-4 pb-4 pt-1 docs-desktop:flex text-sm lg:text-base docs-desktop:mt-2 m_8bffd616 mantine-Flex-root __m__-R36lalleh"><div class=mantine-hidden-from-docs-desktop><a href=https://github.com/modular/modular/tree/main/max/python/max/nn/attention/attention_with_rope.py target=_blank rel="noopener noreferrer" style="--button-bg:transparent;--button-hover:var(--Elements-Twilight-5-80);--button-color:var(--Elements-Twilight-60-50);--button-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent;--button-height:calc(2.5rem * var(--mantine-scale));--button-padding-x:calc(1.375rem * var(--mantine-scale));--button-fz:calc(1rem * var(--mantine-scale));font-weight:400" class="mantine-focus-auto mantine-active onActive_LK5j onHover_fkhK no-transition !font-normal group my-auto px-4 hover:bg-Elements-Twilight-5-80 hover:no-underline m_77c9d27d mantine-Button-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle><span class="m_80f1301b mantine-Button-inner"><span class="m_811560b9 mantine-Button-label"><div style="--group-gap:calc(0.5rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="text-Elements-Twilight-60-40 m_4081bf90 mantine-Group-root"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" class=group-hover:text-black fill=currentColor><g clip-path=url(#:Rrdbbbb6lalleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rrdbbbb6lalleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg><p style="font-size:calc(0.875rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto group-hover:text-black m_b6d8b162 mantine-Text-root">View source</div></span></span></a></div><a href=https://github.com/modular/modular/tree/main/max/python/max/nn/attention/attention_with_rope.py target=_blank rel="noopener noreferrer" class="mantine-focus-auto my-auto hover:no-underline docs-desktop:-mt-2 m_87cf2631 mantine-UnstyledButton-root mantine-visible-from-docs-desktop"><div style="--group-gap:calc(0.5rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="group text-Elements-Twilight-60-40 hover:text-black m_4081bf90 mantine-Group-root"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" fill=currentColor><g clip-path=url(#:Rrdbb6lalleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rrdbb6lalleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg><p style="font-size:calc(0.875rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root">View source</div></a></div><div class="tableOfContents_otRY theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope class="table-of-contents__link toc-highlight"><code>AttentionWithRope</code></a><ul><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_input_scale class="table-of-contents__link toc-highlight"><code>qkv_input_scale</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.qkv_weight_scale class="table-of-contents__link toc-highlight"><code>qkv_weight_scale</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.rope class="table-of-contents__link toc-highlight"><code>rope</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.shard class="table-of-contents__link toc-highlight"><code>shard()</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.sharding_strategy class="table-of-contents__link toc-highlight"><code>sharding_strategy</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv class="table-of-contents__link toc-highlight"><code>wqkv</code></a><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRope.wqkv_bias class="table-of-contents__link toc-highlight"><code>wqkv_bias</code></a></ul><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque class="table-of-contents__link toc-highlight"><code>AttentionWithRopeNoOpaque</code></a><ul><li><a href=#max.nn.attention.attention_with_rope.AttentionWithRopeNoOpaque.rope class="table-of-contents__link toc-highlight"><code>rope</code></a></ul><li><a href=#max.nn.attention.attention_with_rope.DataParallelAttentionWithRope class="table-of-contents__link toc-highlight"><code>DataParallelAttentionWithRope</code></a><li><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope class="table-of-contents__link toc-highlight"><code>GGUFQAttentionWithRope</code></a><ul><li><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.rope class="table-of-contents__link toc-highlight"><code>rope</code></a><li><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv class="table-of-contents__link toc-highlight"><code>wqkv</code></a><li><a href=#max.nn.attention.attention_with_rope.GGUFQAttentionWithRope.wqkv_bias class="table-of-contents__link toc-highlight"><code>wqkv_bias</code></a></ul><li><a href=#max.nn.attention.attention_with_rope.GPTQAttentionWithRope class="table-of-contents__link toc-highlight"><code>GPTQAttentionWithRope</code></a><ul><li><a href=#max.nn.attention.attention_with_rope.GPTQAttentionWithRope.wqkv class="table-of-contents__link toc-highlight"><code>wqkv</code></a></ul><li><a href=#max.nn.attention.attention_with_rope.TensorParallelAttentionWithRope class="table-of-contents__link toc-highlight"><code>TensorParallelAttentionWithRope</code></a><li><a href=#max.nn.attention.attention_with_rope.distribute_value class="table-of-contents__link toc-highlight"><code>distribute_value()</code></a></ul><style data-mantine-styles=inline>.__m__-Rl6lalleh{flex-direction:row}@media (width>=997px){.__m__-Rl6lalleh{flex-direction:column}}</style><div style="gap:calc(0.75rem * var(--mantine-scale))" class="flex flex-col gap-4 border-0 border-l border-solid border-l-Elements-Twilight-20-70 pl-3 text-sm lg:text-base docs-desktop:pt-5 w-full hidden m_8bffd616 mantine-Flex-root __m__-Rl6lalleh"></div></div></div></div></div><div class="sticky bottom-0 z-[100] bg-Elements-Twilight-0-90 docs-desktop:hidden border-0 border-y border-solid border-y-Elements-Twilight-20-70 px-4"><div style="--group-gap:var(--mantine-spacing-md);--group-align:center;--group-justify:space-between;--group-wrap:nowrap;height:calc(4.125rem * var(--mantine-scale))" class="m_4081bf90 mantine-Group-root"><div style="--group-gap:calc(0.75rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:nowrap" class="grow justify-between md:justify-start m_4081bf90 mantine-Group-root"><style data-mantine-styles=inline>.__m__-R1lmqlalleh{flex-direction:row}@media (width>=997px){.__m__-R1lmqlalleh{flex-direction:column}}</style><div class="text-sm lg:text-base docs-desktop:mt-2 m_8bffd616 mantine-Flex-root __m__-R1lmqlalleh"><div class=mantine-hidden-from-docs-desktop><a href=https://github.com/modular/modular/tree/main/max/python/max/nn/attention/attention_with_rope.py target=_blank rel="noopener noreferrer" style="--button-bg:transparent;--button-hover:var(--Elements-Twilight-5-80);--button-color:var(--Elements-Twilight-60-50);--button-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent;--button-height:calc(2.5rem * var(--mantine-scale));--button-padding-x:calc(1.375rem * var(--mantine-scale));--button-fz:calc(1rem * var(--mantine-scale));font-weight:400" class="mantine-focus-auto mantine-active onActive_LK5j onHover_fkhK no-transition !font-normal group my-auto px-4 hover:bg-Elements-Twilight-5-80 hover:no-underline m_77c9d27d mantine-Button-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle><span class="m_80f1301b mantine-Button-inner"><span class="m_811560b9 mantine-Button-label"><div style="--group-gap:calc(0.5rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="text-Elements-Twilight-60-40 m_4081bf90 mantine-Group-root"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" class=group-hover:text-black fill=currentColor><g clip-path=url(#:Rdmlllllmqlalleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rdmlllllmqlalleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg><p style="font-size:calc(0.875rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto group-hover:text-black m_b6d8b162 mantine-Text-root">View source</div></span></span></a></div><a href=https://github.com/modular/modular/tree/main/max/python/max/nn/attention/attention_with_rope.py target=_blank rel="noopener noreferrer" class="mantine-focus-auto my-auto hover:no-underline docs-desktop:-mt-2 m_87cf2631 mantine-UnstyledButton-root mantine-visible-from-docs-desktop"><div style="--group-gap:calc(0.5rem * var(--mantine-scale));--group-align:center;--group-justify:flex-start;--group-wrap:wrap" class="group text-Elements-Twilight-60-40 hover:text-black m_4081bf90 mantine-Group-root"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(0.875rem * var(--mantine-scale));height:calc(0.875rem * var(--mantine-scale))" fill=currentColor><g clip-path=url(#:Rdmlllmqlalleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rdmlllmqlalleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg><p style="font-size:calc(0.875rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto m_b6d8b162 mantine-Text-root">View source</div></a></div><style data-mantine-styles=inline>.__m__-R2lmqlalleh{flex-direction:row}@media (width>=997px){.__m__-R2lmqlalleh{flex-direction:column}}</style><div style="gap:calc(0.75rem * var(--mantine-scale))" class="w-full sm:w-fit text-sm lg:text-base docs-desktop:pt-5 w-full hidden m_8bffd616 mantine-Flex-root __m__-R2lmqlalleh"></div></div><div class="min-w-60 mantine-visible-from-md"><div class="w-full docs-desktop:mt-11"><div style=--group-gap:0rem;--group-align:center;--group-justify:flex-start;--group-wrap:wrap class="relative transition-all duration-200 w-full justify-end docs-desktop:justify-center m_4081bf90 mantine-Group-root"><p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto mr-1 !text-sm docs-desktop:mr-3 docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Was this page helpful?</p><button style="--ai-bg:transparent;--ai-hover:color-mix(in srgb, var(--Elements-Twilight-60-50), transparent 88%);--ai-color:var(--Elements-Twilight-60-50);--ai-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent" class="mantine-focus-auto mantine-active w-8 docs-desktop:w-[42px] m_8d3f4000 mantine-ActionIcon-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle type=button><span class="m_8d3afb97 mantine-ActionIcon-icon"><svg viewBox="0 0 20 18" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))"><path d="M5 8.58v7.92M16.25 16.5H1.67V8.58H5L7.08 1.5h.75a3 3 0 0 1 3 3v2h7.5l-2.08 10Z" stroke=currentColor stroke-width=1.5 /></svg></span></button><button style="--ai-bg:transparent;--ai-hover:color-mix(in srgb, var(--Elements-Twilight-60-50), transparent 88%);--ai-color:var(--Elements-Twilight-60-50);--ai-bd:calc(0.0625rem * var(--mantine-scale)) solid transparent" class="mantine-focus-auto mantine-active w-8 docs-desktop:w-[42px] m_8d3f4000 mantine-ActionIcon-root m_87cf2631 mantine-UnstyledButton-root" data-variant=subtle type=button><span class="m_8d3afb97 mantine-ActionIcon-icon"><svg viewBox="0 0 20 18" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(1.25rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))" class=rotate-180><path d="M5 8.58v7.92M16.25 16.5H1.67V8.58H5L7.08 1.5h.75a3 3 0 0 1 3 3v2h7.5l-2.08 10Z" stroke=currentColor stroke-width=1.5 /></svg></span></button></div><p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto h-0 docs-desktop:translate-y-4 scale-y-0 opacity-0 relative m-auto transition-all duration-200 text-center !text-sm docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Thank you! We'll create more content like this.<p style="color:var(--Elements-Twilight-70-20);font-size:calc(1rem * var(--mantine-scale));line-height:calc(1.5rem * var(--mantine-scale))" class="mantine-focus-auto h-0 docs-desktop:translate-y-4 scale-y-0 opacity-0 relative m-auto transition-all duration-200 text-center !text-sm docs-desktop:!text-base m_b6d8b162 mantine-Text-root">Thank you for helping us improve!</div></div></div></div></div></main></div></div></div><div class=docsite-footer><div class="m_3eebeb36 mantine-Divider-root" data-orientation=horizontal role=separator></div><div class="page-footer mx-auto max-w-[1440px] font-inter"><img class="absolute left-0" referrerpolicy=no-referrer-when-downgrade src="https://static.scarf.sh/a.png?x-pxid=d240bcad-0bb5-4db6-8c37-9061bb991d8e" alt="" /><div class="my-6 grid grid-cols-1 gap-x-10 gap-y-6 px-5 docs-desktop:grid-cols-7 docs-desktop:gap-y-0 [&_p]:text-black"><a href=https://www.modular.com target=_self rel="noopener noreferrer" class=docs-desktop:col-span-2><svg style="width:calc(6rem * var(--mantine-scale));height:calc(1.25rem * var(--mantine-scale))" xmlns=http://www.w3.org/2000/svg viewBox="0 0 132 28" color=var(--Black)><path stroke=transparent fill=currentColor d="M42.5 7.5C37 7.5 33 11.6 33 17.7 33 24 37 28 42.5 28c5.3 0 9.4-4.1 9.4-10.3 0-6-4.1-10.2-9.4-10.2Zm0 17.7c-3.6 0-6.6-3-6.6-7.5s3-7.4 6.6-7.4c3.5 0 6.5 3 6.5 7.4 0 4.6-3 7.5-6.5 7.5Zm26.9-14.6h-.2a7.5 7.5 0 0 0-6.3-3.1c-5.2 0-9.1 4.1-9.1 10.2 0 6.2 3.9 10.3 9 10.3 2.9 0 4.8-1.1 6.4-3.2h.2v2.8h3V0h-3v10.6ZM63 25.2c-3.4 0-6.3-3-6.3-7.5s3-7.4 6.3-7.4 6.3 3 6.3 7.4c0 4.6-3 7.5-6.3 7.5ZM89.2 8h3v19.7h-3v-2.2H89a8 8 0 0 1-6 2.6c-4.4 0-7.8-3.4-7.8-8.3V8h3v11.8c0 3.2 2.4 5.5 5.3 5.5 3.2 0 5.7-2.5 5.7-5.5V8Zm6-7.9H98v27.6h-3V0Zm20.7 10.6h-.2a7.5 7.5 0 0 0-6.3-3.1c-5.2 0-9 4.1-9 10.2 0 6.2 3.8 10.3 9 10.3 2.8 0 4.7-1.1 6.3-3.2h.2v2.8h3V8h-3v2.7Zm-6.3 14.6c-3.4 0-6.3-3-6.3-7.5s3-7.4 6.3-7.4 6.3 3 6.3 7.4c0 4.6-3 7.5-6.3 7.5ZM132 8v2.7h-7c-.2 0-.3.1-.3.2v16.8h-3v-17h2.8l.2-.1V7.9h7.3ZM27.8 4h3v23.5h-3.2V4.3l-.2-.2H26l-8.3 23.5H13L4.7 4.1H3.2v23.5H0V0h6.5L15 24h.8l8.4-24h3.4v4l.2.1Z"/></svg></a><div style=--group-gap:var(--mantine-spacing-md);--group-align:center;--group-justify:flex-start;--group-wrap:wrap class="min-w-[450px] docs-desktop:col-span-3 docs-desktop:mx-auto m_4081bf90 mantine-Group-root"><a href="https://builds.modular.com/?category=models" target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Models</p></a><a href=https://github.com/modular/max-agentic-cookbook target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Cookbook</p></a><a href=https://puzzles.modular.com/ target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Puzzles</p></a><a href=https://www.modular.com/blog target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Blog</p></a><a href=https://www.modular.com/community target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Community</p></a><a href=https://www.modular.com/company/contact target=_self rel="noopener noreferrer"><p style=margin:0rem;padding:0rem class="body-14-light mantine-Text-root">Contact</p></a></div><div style=--group-gap:var(--mantine-spacing-md);--group-align:flex-start;--group-justify:space-between;--group-wrap:wrap class="docs-desktop:col-span-2 m_4081bf90 mantine-Group-root"><div style=flex:1 class="hidden docs-desktop:block"></div><div style=--group-gap:var(--mantine-spacing-xxs);--group-align:center;--group-justify:flex-start;--group-wrap:wrap class="my-auto m_4081bf90 mantine-Group-root"><a href=https://github.com/modular target=_self rel="noopener noreferrer" class="flex h-5 items-center"><svg viewBox="0 0 12 12" xmlns=http://www.w3.org/2000/svg style="width:calc(1.625rem * var(--mantine-scale));height:calc(1.625rem * var(--mantine-scale))" class=mr-1 color=var(--Elements-Twilight-40-60) fill=currentColor><g clip-path=url(#:Rdltlmleh:)><path fill-rule=evenodd clip-rule=evenodd d="M6 .8c2.9 0 5.2 2.4 5.2 5.3 0 2.4-1.5 4.4-3.6 5-.2.1-.3 0-.3-.2V9.5c0-.5-.2-.9-.4-1 1.2-.1 2.4-.6 2.4-2.6 0-.6-.2-1.1-.5-1.5 0-.1.2-.7 0-1.4 0 0-.5-.1-1.5.6a4.9 4.9 0 0 0-2.6 0c-1-.7-1.4-.6-1.4-.6a2 2 0 0 0 0 1.4A2 2 0 0 0 2.6 6c0 2 1.2 2.5 2.4 2.6-.2.1-.3.4-.4.7-.3.1-1 .4-1.5-.4 0 0-.3-.6-.8-.6 0 0-.5 0 0 .3 0 0 .3.2.6.8 0 0 .3 1 1.7.6v1c0 .2 0 .3-.3.3-2.1-.7-3.6-2.7-3.6-5C.8 3.1 3.1.7 6 .7Z"/></g><defs><clipPath id=:Rdltlmleh:><path fill=var(--White) transform="translate(.8 .8)" d="M0 0h10.4v10.4H0z"/></clipPath></defs></svg></a><a href=https://discord.gg/modular target=_self rel="noopener noreferrer" class="flex h-5 items-center"><svg viewBox="0 0 20 20" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(2rem * var(--mantine-scale));height:calc(2rem * var(--mantine-scale))"><path d="M15.2 4.97c-.96-.45-2-.78-3.09-.97-.13.24-.29.57-.4.82-1.15-.17-2.3-.17-3.42 0a8.8 8.8 0 0 0-.4-.82c-1.1.19-2.13.52-3.1.97a12.98 12.98 0 0 0-2.23 8.7c1.3.97 2.56 1.55 3.8 1.94.3-.42.58-.87.81-1.34a8 8 0 0 1-1.28-.62l.32-.25a8.75 8.75 0 0 0 7.58 0l.32.25c-.4.24-.84.45-1.28.62.23.47.5.92.8 1.34 1.25-.38 2.5-.97 3.8-1.94.32-3.3-.53-6.16-2.22-8.7Zm-7.7 6.95c-.73 0-1.34-.7-1.34-1.54 0-.84.6-1.53 1.35-1.53.75 0 1.36.69 1.35 1.53 0 .84-.6 1.54-1.35 1.54Zm5 0c-.75 0-1.36-.7-1.36-1.54 0-.84.6-1.53 1.35-1.53.76 0 1.36.69 1.35 1.53 0 .84-.6 1.54-1.35 1.54Z" fill=var(--Elements-Twilight-40-60) /></svg></a><a href=https://twitter.com/modular target=_self rel="noopener noreferrer" class="flex h-5 items-center"><svg viewBox="0 0 24 24" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(2rem * var(--mantine-scale));height:calc(2rem * var(--mantine-scale))" color=var(--Elements-Twilight-40-60)><path d="M13.14 11.09 17.61 6h-1.06l-3.88 4.42L9.57 6H6l4.69 6.68L6 18h1.06l4.1-4.66L14.42 18H18M7.44 6.78h1.63l7.48 10.49h-1.62" fill=currentColor /></svg></a><a href=https://www.youtube.com/@modularinc target=_self rel="noopener noreferrer" class="flex h-5 items-center"><svg viewBox="0 0 40 40" fill=none xmlns=http://www.w3.org/2000/svg style="width:calc(2rem * var(--mantine-scale));height:calc(2rem * var(--mantine-scale))"><g filter=url(#:R15ltlmleh:)><path fill-rule=evenodd clip-rule=evenodd d="M8.49 30.56A3.49 3.49 0 0 1 5 27.07V12.49A3.49 3.49 0 0 1 8.49 9H31.5A3.49 3.49 0 0 1 35 12.49v14.58a3.49 3.49 0 0 1-3.49 3.49H8.5Zm9.45-15.1 6.18 4.32-6.18 4.32v-8.64Z" fill=var(--Elements-Twilight-40-60) /></g><defs><filter id=:R15ltlmleh: x=4.86 y=9 width=30.28 height=21.84 filterUnits=userSpaceOnUse color-interpolation-filters=sRGB><feFlood flood-opacity=0 result=BackgroundImageFix /><feColorMatrix in=SourceAlpha values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0" result=hardAlpha /><feOffset dy=.14 /><feGaussianBlur stdDeviation=.07 /><feComposite in2=hardAlpha operator=out /><feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0"/><feBlend in2=BackgroundImageFix result=effect1_dropShadow_1082_489 /><feBlend in=SourceGraphic in2=effect1_dropShadow_1082_489 result=shape /></filter></defs></svg></a><a href=https://www.linkedin.com/company/modular-ai/ target=_self rel="noopener noreferrer" class="flex h-5 items-center"><svg viewBox="0 0 40 40" style="width:calc(2rem * var(--mantine-scale));height:calc(2rem * var(--mantine-scale))" fill=none xmlns=http://www.w3.org/2000/svg><path fill-rule=evenodd clip-rule=evenodd d="M29.33 32H10.67A2.67 2.67 0 0 1 8 29.33V10.67C8 9.19 9.2 8 10.67 8h18.66C30.81 8 32 9.2 32 10.67v18.66c0 1.48-1.2 2.67-2.67 2.67Zm-4.22-3.33h3.56v-7.32c0-3.1-1.76-4.6-4.2-4.6-2.46 0-3.5 1.92-3.5 1.92V17.1h-3.43v11.56h3.44V22.6c0-1.62.74-2.6 2.18-2.6 1.31 0 1.95.94 1.95 2.6v6.07Zm-13.78-15.2c0 1.17.95 2.13 2.12 2.13 1.17 0 2.12-.96 2.12-2.13 0-1.18-.95-2.14-2.12-2.14-1.17 0-2.12.96-2.12 2.14Zm3.93 15.2h-3.58V17.1h3.58v11.56Z" fill=var(--Elements-Twilight-40-60) /></svg></a></div></div></div></div></div></div></body>