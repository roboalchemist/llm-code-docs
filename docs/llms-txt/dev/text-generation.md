# Source: https://dev.writer.com/no-code/text-generation.md

# Source: https://dev.writer.com/home/text-generation.md

# Source: https://dev.writer.com/api-reference/completion-api/text-generation.md

> ## Documentation Index
> Fetch the complete documentation index at: https://dev.writer.com/llms.txt
> Use this file to discover all available pages before exploring further.

# Text generation

> Generate text completions using the specified model and prompt. This endpoint is useful for text generation tasks that don't require conversational context.



## OpenAPI

````yaml post /v1/completions
openapi: 3.0.3
info:
  title: API
  version: '1.0'
servers:
  - url: https://api.writer.com
security:
  - bearerAuth: []
paths:
  /v1/completions:
    post:
      tags:
        - Generation API
      summary: Text generation
      description: >-
        Generate text completions using the specified model and prompt. This
        endpoint is useful for text generation tasks that don't require
        conversational context.
      operationId: completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/completions_request'
        required: true
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/completions_response'
            text/event-stream:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/streaming_data'
      security:
        - bearerAuth: []
components:
  schemas:
    completions_request:
      required:
        - model
        - prompt
      type: object
      properties:
        model:
          type: string
          description: >-
            The [ID of the model](https://dev.writer.com/home/models) to use for
            generating text. Supports `palmyra-x5`, `palmyra-x4`, `palmyra-fin`,
            `palmyra-med`, `palmyra-creative`, and `palmyra-x-003-instruct`.
        prompt:
          type: string
          description: The input text that the model will process to generate a response.
        max_tokens:
          type: integer
          format: int64
          description: >-
            The maximum number of tokens that the model can generate in the
            response.
        temperature:
          type: number
          format: double
          description: >-
            Controls the randomness of the model's outputs. Higher values lead
            to more random outputs, while lower values make the model more
            deterministic.
        top_p:
          type: number
          format: double
          description: >-
            Used to control the nucleus sampling, where only the most probable
            tokens with a cumulative probability of top_p are considered for
            sampling, providing a way to fine-tune the randomness of
            predictions.
        stop:
          oneOf:
            - type: array
              items:
                type: string
            - type: string
          description: >-
            Specifies stopping conditions for the model's output generation.
            This can be an array of strings or a single string that the model
            will look for as a signal to stop generating further tokens.
        best_of:
          type: integer
          format: int32
          description: >-
            Specifies the number of completions to generate and return the best
            one. Useful for generating multiple outputs and choosing the best
            based on some criteria.
        random_seed:
          type: integer
          format: int32
          description: >-
            A seed used to initialize the random number generator for the model,
            ensuring reproducibility of the output when the same inputs are
            provided.
        stream:
          type: boolean
          description: >-
            Determines whether the model's output should be streamed. If true,
            the output is generated and sent incrementally, which can be useful
            for real-time applications.
      example:
        model: palmyra-x-003-instruct
        prompt: Write me an SEO article about...
        max_tokens: 150
        temperature: 0.7
        top_p: 0.9
        stop:
          - .
        best_of: 1
        random_seed: 42
        stream: false
    completions_response:
      required:
        - choices
      type: object
      properties:
        choices:
          type: array
          items:
            $ref: '#/components/schemas/completions_choice'
          minItems: 1
          description: >-
            A list of choices generated by the model, each containing the text
            of the completion and associated metadata such as log probabilities.
        model:
          type: string
          description: >-
            The identifier of the model that was used to generate the responses
            in the 'choices' array.
      example:
        choices:
          - text: Sure! Here's a search engine optimized article about...
            log_probs: null
        model: palmyra-x-003-instruct
    streaming_data:
      required:
        - value
      type: object
      properties:
        value:
          type: string
    completions_choice:
      required:
        - text
      type: object
      properties:
        text:
          type: string
          description: >-
            The generated text output from the model, which forms the main
            content of the response.
        log_probs:
          $ref: '#/components/schemas/logprobs'
    logprobs:
      type: object
      required:
        - content
        - refusal
      nullable: true
      properties:
        content:
          type: array
          items:
            $ref: '#/components/schemas/logprobs_token'
          nullable: true
        refusal:
          type: array
          items:
            $ref: '#/components/schemas/logprobs_token'
          nullable: true
    logprobs_token:
      title: logprobs_token
      required:
        - token
        - logprob
        - top_logprobs
      type: object
      properties:
        token:
          type: string
        logprob:
          type: number
          format: double
        bytes:
          type: array
          items:
            type: integer
            format: int32
        top_logprobs:
          type: array
          items:
            $ref: '#/components/schemas/top_log_prob'
    top_log_prob:
      title: top_log_prob
      description: >-
        An array of mappings for each token to its top log probabilities,
        showing detailed prediction probabilities.
      required:
        - token
        - logprob
      type: object
      properties:
        token:
          type: string
        logprob:
          type: number
          format: double
        bytes:
          type: array
          items:
            type: integer
            format: int32
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
      description: >-
        Bearer authentication header of the form `Bearer <token>`, where
        `<token>` is your [Writer API
        key](https://dev.writer.com/api-reference/api-keys).

````