# Source: https://docs.groq.com/docs/guides/speech-to-text/prompting

# Overview - GroqDocs

## Welcome

Fast LLM inference, OpenAI-compatible. Simple to integrate, easy to scale. Start building in minutes.

## External API Compatibility

- **gemma2-9b-it**
- **llama3-8b-8192**
- **llama3-70b-8192**
- **whisper-large-v3-turbo**
- **whisper-large-v3**
- **llama-guard-3-8b**
- **distil-whisper-large-v3-en**

## Chat Completion

- **Fast language models have gained significant attention in recent years due to their ability to process and generate human-like text quickly and efficiently. The importance of fast language models can be understood from their potential applications and benefits:**
  1. **Real-time Chatbots and Conversational Interfaces**: Fast language models enable the development of chatbots and conversational interfaces that can respond promptly to user queries, making them more engaging and useful.
  2. **Sentiment Analysis and Opinion Mining**: Fast language models can quickly analyze text data to identify sentiments, opinions, and emotions, allowing for improved customer service, market research, and opinion mining.
  3. **Language Translation and Localization**: Fast language models can quickly translate text between languages, facilitating global communication and enabling businesses to reach a broader audience.
  4. **Text Summarization and Generation**: Fast language models can summarize long documents or even generate new text on a given topic, improving information retrieval and processing efficiency.
  5. **Named Entity Recognition and Information Extraction**: Fast language models can rapidly recognize and extract specific entities, such as names, locations, and organizations, from unstructured text data.
  6. **Recommendation Systems**: Fast language models can analyze large amounts of text data to personalize product recommendations, improve customer experience, and increase sales.
  7. **Content Generation for Social Media**: Fast language models can quickly generate engaging content for social media platforms, helping businesses maintain a consistent online presence and increasing their online visibility.
  8. **Sentiment Analysis for Stock Market Analysis**: Fast language models can quickly analyze social media posts, news articles, and other text data to identify sentiment trends, enabling financial analysts to make more informed investment decisions.
  9. **Language Learning and Education**: Fast language models can provide instant feedback and adaptive language learning, making language education more effective and engaging.
  10. **Domain-Specific Knowledge Extraction**: Fast language models can quickly extract relevant information from vast amounts of text data, enabling domain experts to focus on high-level decision-making rather than manual information gathering.

The benefits of fast language models include:
- **Increased Efficiency**: Fast language models can process large amounts of text data quickly, reducing the time and effort required for tasks such as sentiment analysis, entity recognition, and text summarization.
- **Improved Accuracy**: Fast language models can analyze and learn from large datasets, leading to more accurate results and more informed decision-making.
- **Enhanced User Experience**: Fast language models can enable real-time interactions, personalized recommendations, and timely responses, improving the overall user experience.
- **Cost Savings**: Fast language models can automate many tasks, reducing the need for manual labor and minimizing costs associated with data processing and analysis.

In summary, fast language models have the potential to transform various industries and applications by providing fast, accurate, and efficient language processing capabilities.

## Chat Completion Request

- **Description**: A document that can be referenced by the model while generating responses.
- **Properties**:
  - **id**: Optional unique identifier that can be used for citations in responses.
  - **source**: Document containing the text content.

## Chat Completion Response

- **Description**: A chat completion message generated by the model.
- **Properties**:
  - **annotations**: A list of annotations providing citations and references for the content in the message.
  - **content**: The contents of the message.
  - **executed_tools**: Information about the tools that were executed during the chat completion for compound AI systems.
  - **function_call**: Controls which (if any) function is called by the model.
  - **reasoning**: The model's reasoning for a response. Only available for [models that support reasoning](https://console.groq.com/docs/reasoning) when request parameter reasoning_format has value `parsed`.
  - **role**: The role of the messages author, in this case `assistant`.
  - **tool_calls**: The tool calls generated by the model, such as function calls.

## Chat Completion Role

- **Description**: The role of the author of a message.
- **Values**:
  - `system`
  - `user`
  - `assistant`
  - `tool`
  - `developer`

## Chat Completion Stream

- **Description**: A chat completion delta generated by streamed model responses.
- **Properties**:
  - **annotations**: A list of annotations providing citations and references for the content in the message.
  - **content**: The contents of the chunk message.
  - **executed_tools**: Information about the tools that were executed during the chunk.
  - **reasoning**: The model's reasoning for a response. Only available for [models that support reasoning](https://console.groq.com/docs/reasoning) when request parameter reasoning_format has value `parsed`.
  - **role**: The role of the author of this message.
  - **tool_calls**: The tools that were available to the model.

## Chat Completion Token Logprob

- **Description**: A list of tokens with log probability information.
- **Properties**:
  - **bytes**: A list of integers representing the UTF-8 bytes representation of the token.
  - **logprob**: The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.

## Chat Completion Tool

- **Description**: Describes a tool that the model may generate JSON inputs for.
- **Properties**:
  - **name**: The name of the function to be called.
  - **parameters**: A JSON schema describing the function's input parameters.

## Chat Completion Response Message

- **Description**: A message input to the model with a role indicating instruction following hierarchy.
- **Properties**:
  - **content**: A list of one or many input content items.
  - **role**: The role of the message input.
  - **status**: The status of the message.
  - **type**: The type of the message input.

## Chat Completion Response FileCitation

- **Description**: A citation to a file.
- **Properties**:
  - **file_id**: The ID of the file.
  - **index**: The index of the citation in the text.
  - **type**: The type of the annotation. Always `file_citation`.
  - **url**: The URL of the file.

## Chat Completion Response TextCitation

- **Description**: A citation for a web resource.
- **Properties**:
  - **end_index**: The character index in the URL citation in the message.
  - **start_index**: The character index in the URL citation in the message.
  - **title**: The title of the web resource.
  - **type**: The type of the annotation. Always `url_citation`.
  - **url**: The URL of the web resource.

## Chat Completion Usage Breakdown

- **Description**: Usage statistics for compound AI completion requests.
- **Properties**:
  - **models**: List of models used in the request and their individual usage statistics.
  - **type**: The type of the response format being defined. Always `json_object`.

## Chat Completion Response

- **Description**: Represents a response returned by model, based on the provided input.
- **Properties**:
  - **background**: Whether the response was generated in the background.
  - **created_at**: The Unix timestamp (in seconds) of when the response was created.
  - **error**: An error object if the response failed.
  - **id**: A unique identifier for the response.
  - **incomplete_details**: Details about why the response is incomplete.
  - **instructions**: The system instructions used for the response.
  - **max_output_tokens**: An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.
  - **metadata**: Additional key-value pairs for storing additional information.
  - **model**: The model used for the response.
  - **object**: The object type, which is always `chat.completion`.
  - **output**: An array of content items generated by the model.
  - **parallel_tool_calls**: Whether the model can run tool calls in parallel.
  - **previous_response_id**: Not supported. Always null.
  - **reasoning**: Configuration options for [models that support reasoning](https://console.groq.com/docs/reasoning).
  - **response_format**: An object specifying the format that the model must output.
  - **stream**: Enable streaming mode to receive response data as server-sent events.
  - **temperature**: Controls randomness in the response generation.
  - **tool_choice**: Controls which (if any) tool is called by the model.
  - **tools**: List of tools available to the model.
  - **top_logprobs**: The number of top log probabilities returned.
  - **top_p**: The nucleus sampling parameter used.
  - **truncation**: The truncation strategy used.
  - **usage**: Usage information for the request.
  - **user**: Optional identifier for tracking end-user requests.

## Chat Completion Stream Response

- **Description**: Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
- **Properties**:
  - **annotations**: A list of annotations providing citations and references for the content in the message.
  - **content**: The contents of the chunk message.
  - **executed_tools**: Information about the tools that were executed during the chunk.
  - **reasoning**: The model's reasoning for a response. Only available for [models that support reasoning](https://console.groq.com/docs/reasoning) when request parameter reasoning_format has value `parsed`.
  - **role**: The role of the author of this message.
  - **tool_calls**: The tool calls generated by the model.

## Chat Completion Response Message

- **Description**: A message input to the model with explicit type field.
- **Properties**:
  - **content**: A list of one or many input content items.
  - **role**: The role of the message input.
  - **status**: The status of item. Populated when items are returned via API.
  - **type**: The type of the message input.

## Chat Completion Response TextCitation

- **Description**: A text input to the model.
- **Properties**:
  - **text**: The text input to the model.
  - **type**: The type of the input item. Always `input_text`.

## Chat Completion Response FileCitation

- **Description**: A citation to a file.
- **Properties**:
  - **file_id**: The ID of the file.
  - **index**: The index of the citation in the text.
  - **type**: The type of the annotation. Always `file_citation`.
  - **url**: The URL of the file.

## Chat Completion Response TextContent

- **Description**: A text output from the model.
- **Properties**:
  - **annotations**: The annotations of the text output.
  - **logprobs**: Log probability information for the output.
  - **text**: The text output from the model.
  - **type**: The type of the output text. Always `output_text`.

## Chat Completion Response FunctionCall

- **Description**: A function call generated by the model.
- **Properties**:
  - **arguments**: A JSON string of the arguments to pass to the function.
  - **call_id**: The unique ID of the function tool call generated by the model.
  - **id**: The unique ID of the function tool call.
  - **name**: The name of the function to call.
  - **status**: The status of the item. Populated when items are returned via API.

## Chat Completion Response FunctionCallOutput

- **Description**: The output of a function tool call.
- **Properties**:
  - **call_id**: The unique ID of the function tool call generated by the model.
  - **id**: The unique ID of the function tool call output.
  - **output**: A JSON string of the output of the function tool call.
  - **status**: The status of the item. Populated when items are returned via API.

## Chat Completion Response EasyInputMessage

- **Description**: A message input to the model with explicit type field.
- **Properties**:
  - **content**: A list of one or many input content items.
  - **role**: The role of the message input.
  - **status**: The status of item. Populated when items are returned via API.
  - **type**: The type of the message input. Always `message`.

## Chat Completion Response FileCitation

- **Description**: A citation to a file.
- **Properties**:
  - **end_index**: The character index in the URL citation in the message.
  - **start_index**: The character index in the URL citation in the message.
  - **title**: The title of the file.
  - **type**: The type of the annotation. Always `url_citation`.
  - **url**: The URL of the file.

## Chat Completion Response Usage

- **Description**: Usage statistics for the response request.
- **Properties**:
  - **input_tokens**: Number of tokens in the input.
  - **input_tokens_details**: Breakdown of input tokens.
  - **output_tokens**: Number of tokens in the generated output.
  - **output_tokens_details**: Breakdown of output tokens.
  - **total_tokens**: Total number of tokens used in the request (input + output).

## Text Response Format JsonSchema

- **Description**: JSON Schema response format. Used to generate structured JSON responses.
- **Properties**:
  - **description**: A description of what the response format is for, used by the model to determine how to respond in the format.
  - **name**: The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
  - **schema**: The schema for the response format, described as a JSON Schema object.
  - **strict**: Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the `schema` field. Only a subset of JSON Schema is supported when `strict` is `true`.

## Transcription Segment

- **Description**: A citation for a web resource.
- **Properties**:
  - **audio_text**: Transcribed text for the entire chunk.
  - **avg_logprob**: Average logprob of the segment. If the value is lower than -1, consider the logprobs failed.
  - **chunk_end**: End chunk timestamp.
  - **chunk_start**: Start chunk timestamp.
  - **compression_ratio**: Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed.
  - **end**: End time of the segment in seconds.
  - **id**: Unique identifier of the segment.
  - **no_speech_prob**: Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent.
  - **seek**: Seek offset of the segment.
  - **start**: Start time of the segment in seconds.
  - **temperature**: Temperature parameter used for generating the segment.
  - **text**: Text content of the segment.
  - **token_scores**: Token-level scores.
  - **tokens**: Array of token IDs for the text content.

## XGroq Metadata

- **Description**: Groq-specific metadata for streaming responses.
- **Properties**:
  - **debug**: An array of DebugData objects.
  - **error**: An error string indicating why a stream was stopped early.
  - **id**: A groq request ID which can be used to refer to a specific request to groq support.
  - **seed**: The seed used for the request.
  - **usage**: Additional Groq-specific usage metrics (hardware cache statistics).

## XGroq NonStreaming Metadata

- **Description**: Groq-specific metadata for non-streaming chat completion responses.
- **Properties**:
  - **debug**: An array of DebugData objects.
  - **id**: A groq request ID which can be used to refer to a specific request to groq support.
  - **seed**: The seed used for the request.
  - **usage**: Additional Groq-specific usage metrics (hardware cache statistics).

## Groq Cloud API Specification

- **Contact**: Support@groq.com
- **Description**: Specification of the Groq cloud API
- **Terms of Service**: https://groq.com/terms-of-use/
- **Title**: GroqCloud API
- **Version**: 2.1

## Groq API Endpoints

- **/openai/v1/audio/speech**
  - **Post**: Generates audio from the input text.
  - **Description**: OK
  - **Tags**: Audio

- **/openai/v1/audio/transcriptions**
  - **Post**: Transcribes audio into the input language.
  - **Description**: OK
  - **Tags**: Audio

- **/openai/v1/audio/translations**
  - **Post**: Translates audio into English.
  - **Description**: OK
  - **Tags**: Audio

- **/openai/v1/batches**
  - **Get**: List your organization's batches.
  - **Summary**: List your organization's batches.
  - **Tags**: Batch
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/batches/{batch_id}**
  - **Get**: Retrieves a batch.
  - **Summary**: Retrieves a batch.
  - **Tags**: Batch
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/batches/{batch_id}/cancel**
  - **Post**: Cancels a batch.
  - **Summary**: Cancels a batch.
  - **Tags**: Batch
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/chat/completions**
  - **Post**: Creates a model response for the given chat conversation.
  - **Description**: OK
  - **Tags**: Chat
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/embeddings**
  - **Post**: Creates an embedding vector representing the input text.
  - **Description**: OK
  - **Tags**: Embeddings

- **/openai/v1/files**
  - **Get**: Returns a list of files.
  - **Summary**: Returns a list of files.
  - **Tags**: Files
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/files/{file_id}**
  - **Delete**: Delete a file.
  - **Summary**: Delete a file.
  - **Tags**: Files
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/files/{file_id}/content**
  - **Get**: Returns the contents of the specified file.
  - **Summary**: Returns the contents of the specified file.
  - **Tags**: Files

- **/openai/v1/models**
  - **Get**: Get all available models.
  - **Summary**: Get all available models.
  - **Tags**: Models
  - **X-groq-metadata**: Examples: Default

- **/openai/v1/reranking**
  - **Post**: Given a query and a list of documents, returns the documents ranked by their relevance to the query.
  - **Description**: Reranks documents based on their relevance to a query.
  - **Tags**: Reranking
  - **X-groq-metadata**: Examples: Basic Reranking, Reranking with Custom Instruction

- **/openai/v1/responses**
  - **Post**: The input prompt and parameters.
  - **Description**: OK
  - **Tags**: Responses
  - **X-groq-metadata**: Examples: Default

- **/v1/fine_tunings**
  - **Get**: List all previously created fine tunings.
  - **Summary**: List all previously created fine tunings.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

- **/v1/fine_tunings/{id}**
  - **Delete**: Deletes an existing fine tuning by id.
  - **Summary**: Deletes an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses/{id}**
  - **Get**: Retrieves an existing fine tuning by id.
  - **Summary**: Retrieves an existing fine tuning by id.
  - **Tags**: Fine Tuning
  - **X-groq-metadata**: Examples: Default

## Groq API Endpoints

- **/openai/v1/responses