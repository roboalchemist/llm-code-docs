# 0 Documentation

Source: https://docs.0g.ai/llms-full.txt

---

# 0G Documentation

> 0G is a decentralized AI operating system (deAIOS) providing modular infrastructure for AI applications including decentralized storage, data availability, and GPU compute marketplace.

This file contains all documentation content in a single document following the llmstxt.org standard.

## AI Coding Context

# 0G AI Context for Coding Assistants

This page provides comprehensive context about 0G infrastructure to help AI coding assistants help developers build on 0G. All information is extracted from the official documentation at https://docs.0g.ai.

## Network Configurations

### Testnet (Galileo)
**Explorer**: [https://explorer.0g.ai/testnet/home](https://explorer.0g.ai/testnet/home)

| Parameter | Value |
|-----------|-------|
| **Network Name** | 0G-Galileo-Testnet |
| **Chain ID** | 16602 |
| **Token Symbol** | 0G |
| **RPC Endpoint** | https://evmrpc-testnet.0g.ai |
| **Block Explorer** | https://chainscan-galileo.0g.ai |
| **Storage Explorer** | https://storagescan-galileo.0g.ai |
| **Validator Dashboard** | https://testnet.0g.explorers.guru |
| **Faucet** | https://faucet.0g.ai (0.1 0G/day) |
| **Storage Start Block** | 1 |
| **DA Start Block** | 940000 |

**Documentation**: [https://docs.0g.ai/developer-hub/testnet/testnet-overview](https://docs.0g.ai/developer-hub/testnet/testnet-overview)

**Third-Party RPCs (Recommended for Production)**:
- QuickNode: https://www.quicknode.com/chains/0g
- ThirdWeb: https://thirdweb.com/0g-galileo-testnet-16601
- Ankr: https://www.ankr.com/rpc/0g/
- dRPC NodeCloud: https://drpc.org/chainlist/0g-galileo-testnet-rpc

### Mainnet (Aristotle)
**Explorer**: [https://explorer.0g.ai/mainnet/home](https://explorer.0g.ai/mainnet/home)

| Parameter | Value |
|-----------|-------|
| **Network Name** | 0G Mainnet |
| **Chain ID** | 16661 |
| **Token Symbol** | 0G |
| **RPC Endpoint** | https://evmrpc.0g.ai |
| **Storage Indexer** | https://indexer-storage-turbo.0g.ai |
| **Block Explorer** | https://chainscan.0g.ai |
| **Storage Start Block** | 2387557 |

**Documentation**: [https://docs.0g.ai/developer-hub/mainnet/mainnet-overview](https://docs.0g.ai/developer-hub/mainnet/mainnet-overview)

**Third-Party RPCs (Recommended for Production)**:
- QuickNode: https://www.quicknode.com/chains/0g
- ThirdWeb: https://thirdweb.com/0g-aristotle
- Ankr: https://www.ankr.com/rpc/0g/

## Smart Contract Addresses

### Testnet Contracts

| Contract | Address | Purpose |
|----------|---------|---------|
| **Flow** | `0x22E03a6A89B950F1c82ec5e74F8eCa321a105296` | Storage data flow management |
| **Mine** | `0x00A9E9604b0538e06b268Fb297Df333337f9593b` | Storage mining rewards |
| **Reward** | `0xA97B57b4BdFEA2D0a25e535bd849ad4e6C440A69` | Reward distribution |
| **DAEntrance** | `0xE75A073dA5bb7b0eC622170Fd268f35E675a957B` | DA blob submission |
| **DASigners** | `0x0000000000000000000000000000000000001000` | DA signer management (precompile) |
| **WrappedOGBase** | `0x0000000000000000000000000000000000001001` | Wrapped native token (precompile) |
| **Compute Ledger** | `0xE70830508dAc0A97e6c087c75f402f9Be669E406` | Compute network payment ledger |
| **Compute Inference** | `0xa79F4c8311FF93C06b8CfB403690cc987c93F91E` | Compute inference service |
| **Compute FineTuning** | `0xaC66eBd174435c04F1449BBa08157a707B6fa7b1` | Compute fine-tuning service |

### Mainnet Contracts

| Contract | Address | Purpose |
|----------|---------|---------|
| **Flow** | `0x62D4144dB0F0a6fBBaeb6296c785C71B3D57C526` | Storage data flow management |
| **Mine** | `0xCd01c5Cd953971CE4C2c9bFb95610236a7F414fe` | Storage mining rewards |
| **Reward** | `0x457aC76B58ffcDc118AABD6DbC63ff9072880870` | Reward distribution |
| **DASigners** | `0x0000000000000000000000000000000000001000` | DA signer management (precompile) |
| **WrappedOGBase** | `0x0000000000000000000000000000000000001001` | Wrapped native token (precompile) |
| **Compute Ledger** | `0x2dE54c845Cd948B72D2e32e39586fe89607074E3` | Compute network payment ledger |
| **Compute Inference** | `0x47340d900bdFec2BD393c626E12ea0656F938d84` | Compute inference service |
| **Compute FineTuning** | `0x4e3474095518883744ddf135b7E0A23301c7F9c0` | Compute fine-tuning service |

## 0G Services Overview

### 0G Chain
**Documentation**: [https://docs.0g.ai/concepts/chain](https://docs.0g.ai/concepts/chain)

Fastest modular AI chain with 11,000 TPS per Shard, sub-second finality, and full EVM compatibility.

**Key Features**:
- **Full EVM compatibility** - Use existing Ethereum tools (Hardhat, Foundry, Remix)
- **11,000 TPS per Shard** with sub-second finality
- **Same as Ethereum development** - just different RPC endpoint
- Optimized CometBFT consensus
- Native precompiled contracts for DA and wrapped tokens

**Deploy Smart Contracts**:

Using Hardhat:
```javascript
// hardhat.config.js
module.exports = {
  networks: {
    testnet: {
      url: "https://evmrpc-testnet.0g.ai",
      chainId: 16602,
      accounts: ["YOUR_PRIVATE_KEY"]
    },
    mainnet: {
      url: "https://evmrpc.0g.ai",
      chainId: 16661,
      accounts: ["YOUR_PRIVATE_KEY"]
    }
  },
  solidity: "0.8.20"
};
```

Using Foundry:
```bash
# Testnet
forge create --rpc-url https://evmrpc-testnet.0g.ai \
  --private-key YOUR_PRIVATE_KEY \
  src/MyContract.sol:MyContract

# Mainnet
forge create --rpc-url https://evmrpc.0g.ai \
  --private-key YOUR_PRIVATE_KEY \
  src/MyContract.sol:MyContract
```

Using Remix:
1. Open Remix IDE
2. Compile your contract
3. Go to Deploy & Run Transactions
4. Select "Injected Provider - MetaMask"
5. Ensure MetaMask is connected to 0G network
6. Deploy!

**Precompiled Contracts**:

DASigners (0x0000000000000000000000000000000000001000):
```solidity
// Query DA signers and epochs
function getEpochNumber(uint256 blockNumber) external view returns (uint256);
function getQuorum(uint256 epochNumber, uint256 quorumId) external view returns (Signer[] memory);
function isSigner(uint256 epochNumber, address account) external view returns (bool);
```

WrappedOGBase (0x0000000000000000000000000000000000001001):
```solidity
// Wrapped native token (like WETH)
function deposit() external payable;
function withdraw(uint256 amount) external;
function balanceOf(address account) external view returns (uint256);
```

**Verification & Indexing**:
- **Goldsky**: GraphQL indexing and real-time data streaming
  - Docs: https://docs.goldsky.com/chains/0g
  - Guide: [https://docs.0g.ai/developer-hub/building-on-0g/indexing/goldsky](https://docs.0g.ai/developer-hub/building-on-0g/indexing/goldsky)

**Documentation Links**:
- Deploy Contracts: [https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts](https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts)
- Precompiles: [https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/precompiles/overview](https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/precompiles/overview)
- Staking: [https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/staking-interfaces](https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/staking-interfaces)
- Validator Contracts: [https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/validator-contract-functions](https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/validator-contract-functions)

### 0G Storage
**Documentation**: [https://docs.0g.ai/concepts/storage](https://docs.0g.ai/concepts/storage)

Decentralized storage offering 95% lower costs than AWS with instant retrieval.

**Key Features**:
- 95% cheaper than centralized alternatives
- 200 MBPS retrieval speed
- Proven TB-scale operations
- Two storage layers: Log (immutable) + KV (mutable)
- Proof of Random Access (PoRA) consensus

**SDK Installation**:

TypeScript/JavaScript:
```bash
npm install @0glabs/0g-ts-sdk ethers
```

Python:
```bash
pip install 0g-storage-client
```

Go:
```bash
go get github.com/0gfoundation/0g-storage-client
```

**Quick Start Examples**:

TypeScript - Upload File:
```typescript
import { ZgFile, Indexer } from "@0glabs/0g-ts-sdk";
import { ethers } from "ethers";

const provider = new ethers.JsonRpcProvider("https://evmrpc-testnet.0g.ai");
const signer = new ethers.Wallet("YOUR_PRIVATE_KEY", provider);
const indexer = new Indexer("https://indexer-storage-testnet-turbo.0g.ai");

const file = await ZgFile.fromFilePath("/path/to/file");
const [tree, treeErr] = await file.merkleTree();
console.log("Root Hash:", tree?.rootHash());

const [tx, uploadErr] = await indexer.upload(file, "https://evmrpc-testnet.0g.ai", signer);
await file.close();
```

Python - Upload File:
```python
from storage_client import ZgStorageClient

client = ZgStorageClient(
    rpc_endpoint="https://evmrpc-testnet.0g.ai",
    contract_address="0x22E03a6A89B950F1c82ec5e74F8eCa321a105296",
    private_key="YOUR_PRIVATE_KEY"
)

root_hash = client.upload_file("/path/to/file")
```

**CLI Tool**:
```bash
# Install
git clone https://github.com/0gfoundation/0g-storage-client.git
cd 0g-storage-client
go build

# Upload file
0g-storage-client upload \
  --url https://evmrpc-testnet.0g.ai \
  --key YOUR_PRIVATE_KEY \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --file /path/to/file

# Download file
0g-storage-client download \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --root <ROOT_HASH> \
  --file output.dat

# Upload directory
0g-storage-client upload-dir \
  --url https://evmrpc-testnet.0g.ai \
  --key YOUR_PRIVATE_KEY \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --file /path/to/directory

# Download directory
0g-storage-client download-dir \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --root <DIRECTORY_ROOT_HASH> \
  --file /path/to/output
```

**Documentation Links**:
- SDK Guide: [https://docs.0g.ai/developer-hub/building-on-0g/storage/sdk](https://docs.0g.ai/developer-hub/building-on-0g/storage/sdk)
- CLI Guide: [https://docs.0g.ai/developer-hub/building-on-0g/storage/storage-cli](https://docs.0g.ai/developer-hub/building-on-0g/storage/storage-cli)

**GitHub Repositories**:
- Storage Node: https://github.com/0gfoundation/0g-storage-node
- Storage KV: https://github.com/0gfoundation/0g-storage-kv
- Storage Client/CLI: https://github.com/0gfoundation/0g-storage-client
- TypeScript SDK: https://github.com/0gfoundation/0g-ts-sdk
- Python SDK: https://github.com/0gfoundation/0g-storage-client
- Go SDK: https://github.com/0gfoundation/0g-storage-client

### 0G Compute
**Documentation**: [https://docs.0g.ai/concepts/compute](https://docs.0g.ai/concepts/compute)

Decentralized GPU marketplace offering 90% cheaper AI workloads with OpenAI SDK compatibility.

**Key Features**:
- 90% cost reduction vs traditional cloud (e.g., $0.003 vs $0.03 per 1K tokens)
- Pay-per-use pricing (no subscriptions or monthly minimums)
- OpenAI SDK compatible - drop-in replacement
- Smart contract escrow for trustless payments
- TEE (Trusted Execution Environment) for secure processing
- 50-100ms inference latency
- Supports: Chatbot (LLM), Text-to-Image, Speech-to-Text

**DePIN Partners**:
- **io.net**: 300,000+ GPUs across 139 countries
- **Aethir**: 43,000+ enterprise-grade GPUs, 3,000+ H100s/H200s

**Quick Start (5 minutes)**:

Install CLI:
```bash
pnpm add @0glabs/0g-serving-broker -g
```

Option 1 - Web UI (Easiest):
```bash
# Launch Web UI
0g-compute-cli ui start-web

# Open http://localhost:3090
# Connect wallet, deposit tokens, start using AI services
```

Option 2 - CLI:
```bash
# Setup network
0g-compute-cli setup-network

# Login with wallet
0g-compute-cli login

# Fund account
0g-compute-cli deposit --amount 10

# List available providers
0g-compute-cli inference list-providers

# Transfer funds to provider
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 5

# Acknowledge provider
0g-compute-cli inference acknowledge-provider --provider <PROVIDER_ADDRESS>

# Get API key for direct access
0g-compute-cli inference get-secret --provider <PROVIDER_ADDRESS>
```

Option 3 - Direct API (OpenAI Compatible):
```bash
curl <service_url>/v1/proxy/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer app-sk-<YOUR_SECRET>" \
  -d '{
    "model": "<model_name>",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

**OpenAI SDK Integration**:
```python
from openai import OpenAI

client = OpenAI(
    api_key="app-sk-<YOUR_SECRET>",
    base_url="<service_url>/v1/proxy"
)

response = client.chat.completions.create(
    model="<model_name>",
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)
```

**Fine-tuning Models**:
```bash
# Prepare dataset (JSONL format)
# Each line: {"prompt": "...", "completion": "..."}

# Upload dataset
0g-compute-cli fine-tuning upload-data --file dataset.jsonl

# Create fine-tuning task
0g-compute-cli fine-tuning create-task \
  --model Qwen2.5-0.5B-Instruct \
  --dataset <DATASET_ID> \
  --provider <PROVIDER_ADDRESS>

# Monitor progress
0g-compute-cli fine-tuning get-task --task-id <TASK_ID>
```

**Documentation Links**:
- Overview: [https://docs.0g.ai/developer-hub/building-on-0g/compute-network/overview](https://docs.0g.ai/developer-hub/building-on-0g/compute-network/overview)
- Inference: [https://docs.0g.ai/developer-hub/building-on-0g/compute-network/inference](https://docs.0g.ai/developer-hub/building-on-0g/compute-network/inference)
- Fine-tuning: [https://docs.0g.ai/developer-hub/building-on-0g/compute-network/fine-tuning](https://docs.0g.ai/developer-hub/building-on-0g/compute-network/fine-tuning)
- Account Management: [https://docs.0g.ai/developer-hub/building-on-0g/compute-network/account-management](https://docs.0g.ai/developer-hub/building-on-0g/compute-network/account-management)
- Provider Setup: [https://docs.0g.ai/developer-hub/building-on-0g/compute-network/inference-provider](https://docs.0g.ai/developer-hub/building-on-0g/compute-network/inference-provider)

### 0G DA (Data Availability)
**Documentation**: [https://docs.0g.ai/concepts/da](https://docs.0g.ai/concepts/da)

Scalable data availability layer for rollups with 50 Gbps throughput.

**Key Features**:
- 50 Gbps demonstrated throughput
- VRF-based node selection
- Inherits Ethereum security

**For Rollup Developers**:
- OP Stack Integration: [https://docs.0g.ai/developer-hub/building-on-0g/rollups-and-appchains/op-stack-on-0g-da](https://docs.0g.ai/developer-hub/building-on-0g/rollups-and-appchains/op-stack-on-0g-da)
  - Repo: https://github.com/0gfoundation/0g-da-op-plasma
- Arbitrum Nitro: [https://docs.0g.ai/developer-hub/building-on-0g/rollups-and-appchains/arbitrum-nitro-on-0g-da](https://docs.0g.ai/developer-hub/building-on-0g/rollups-and-appchains/arbitrum-nitro-on-0g-da)
  - Repo: https://github.com/0gfoundation/nitro
- Integration Guide: [https://docs.0g.ai/developer-hub/building-on-0g/da-integration](https://docs.0g.ai/developer-hub/building-on-0g/da-integration)

### INFT (Intelligent NFTs)
**Documentation**: [https://docs.0g.ai/concepts/inft](https://docs.0g.ai/concepts/inft)

NFT standard (ERC-7857) for tokenizing AI agents with complete intelligence.

**Key Features**:
- Extends ERC-721 standard
- Encrypted metadata storage via 0G Storage
- Secure re-encryption for ownership transfer
- Oracle verification
- True AI ownership transfer

**Use Cases**:
- AI Trading Bots
- Personal Assistants
- Game Characters
- Content Creation AI
- Research Tools

**Documentation Links**:
- INFT Overview: [https://docs.0g.ai/developer-hub/building-on-0g/inft/inft-overview](https://docs.0g.ai/developer-hub/building-on-0g/inft/inft-overview)
- ERC-7857 Standard: [https://docs.0g.ai/developer-hub/building-on-0g/inft/erc7857](https://docs.0g.ai/developer-hub/building-on-0g/inft/erc7857)
- Integration Guide: [https://docs.0g.ai/developer-hub/building-on-0g/inft/integration](https://docs.0g.ai/developer-hub/building-on-0g/inft/integration)

## Running Nodes

### Hardware Requirements

| Node Type | Memory | CPU | Disk | Bandwidth | Purpose |
|-----------|--------|-----|------|-----------|---------|
| **Validator (Mainnet)** | 64 GB | 8 cores | 1 TB NVMe | 100 Mbps | Transaction validation |
| **Validator (Testnet)** | 64 GB | 8 cores | 4 TB NVMe | 100 Mbps | Transaction validation |
| **Storage Node** | 32 GB | 8 cores | 500GB-1TB SSD | 100 Mbps | Data storage |
| **Storage KV** | 32 GB | 8 cores | Flexible | - | Key-value storage |
| **DA Node** | 16 GB | 8 cores | 1 TB NVMe | 100 Mbps | Blob verification |
| **Archival Node** | 64 GB | 8 cores | Large NVMe | 100 Mbps | Historical data |

### Validator Node Setup

**Mainnet (Aristotle)**:
```bash
# Install dependencies
sudo apt update && sudo apt install -y make gcc jq curl git lz4 build-essential

# Install Go
wget https://go.dev/dl/go1.22.0.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.22.0.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin

# Clone and build
git clone -b v1.0.4 https://github.com/0gfoundation/0gchain-Aristotle
cd 0gchain-Aristotle
make install

# Initialize
0gchaind init <YOUR_MONIKER> --chain-id zgtendermint_16661-1

# Configure
wget -O ~/.0gchain/config/genesis.json https://github.com/0gfoundation/0gchain-Aristotle/releases/download/v1.0.4/genesis.json
```

**Testnet (Galileo)**:
```bash
# Clone and build
git clone -b v3.0.4 https://github.com/0gfoundation/0gchain-NG
cd 0gchain-NG
make install

# Initialize
0gchaind init <YOUR_MONIKER> --chain-id zgtendermint_16602-1

# Configure
wget -O ~/.0gchain/config/genesis.json https://github.com/0gfoundation/0gchain-NG/releases/download/v3.0.4/genesis.json
```

**Documentation**: [https://docs.0g.ai/run-a-node/validator-node](https://docs.0g.ai/run-a-node/validator-node)

### Storage Node Setup

**Build from Source**:
```bash
# Install dependencies
sudo apt-get update
sudo apt-get install clang cmake build-essential pkg-config libssl-dev protobuf-compiler

# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Clone and build
git clone -b <latest_tag> https://github.com/0gfoundation/0g-storage-node.git
cd 0g-storage-node
cargo build --release
```

**Configuration (Testnet)**:
```toml
# config.toml
log_contract_address = "0x22E03a6A89B950F1c82ec5e74F8eCa321a105296"
mine_contract_address = "0x00A9E9604b0538e06b268Fb297Df333337f9593b"
reward_contract_address = "0xA97B57b4BdFEA2D0a25e535bd849ad4e6C440A69"
blockchain_rpc_endpoint = "https://evmrpc-testnet.0g.ai"
log_sync_start_block_number = 1
miner_key = "YOUR_PRIVATE_KEY"
```

**Configuration (Mainnet)**:
```toml
# config.toml
log_contract_address = "0x62D4144dB0F0a6fBBaeb6296c785C71B3D57C526"
mine_contract_address = "0xCd01c5Cd953971CE4C2c9bFb95610236a7F414fe"
reward_contract_address = "0x457aC76B58ffcDc118AABD6DbC63ff9072880870"
blockchain_rpc_endpoint = "https://evmrpc.0g.ai"
log_sync_start_block_number = 2387557
miner_key = "YOUR_PRIVATE_KEY"
```

**Sharding Configuration**:
```toml
# Format: shard_id/shard_number where shard_number is 2^n
# Only applies on first startup if no stored shard config in db
shard_position = "0/2"
```

Sharding allows controlling how much data your node stores:
- `"0/2"` or `"1/2"` = 50% of total data (each on specific ranges)
- `"0/4"` to `"3/4"` = 25% of total data each
- Initial setup is deterministic (shard_id maps to specific range)
- Auto-splitting is NOT deterministic (random assignment when capacity exceeded)

**Run Storage Node**:
```bash
cd run
../target/release/zgs_node --config config.toml --miner-key <your_private_key>
```

**Documentation**: [https://docs.0g.ai/run-a-node/storage-node](https://docs.0g.ai/run-a-node/storage-node)

## Developer Tools

### Indexing with Goldsky

**Website**: https://docs.goldsky.com/chains/0g

**Products**:
- **Subgraphs**: GraphQL indexing for smart contracts
- **Mirror**: Real-time data streaming to databases

**Documentation**: [https://docs.0g.ai/developer-hub/building-on-0g/indexing/goldsky](https://docs.0g.ai/developer-hub/building-on-0g/indexing/goldsky)

### Rollup-as-a-Service

**Caldera on 0G DA**: [https://docs.0g.ai/developer-hub/building-on-0g/rollup-as-a-service/caldera-on-0g-da](https://docs.0g.ai/developer-hub/building-on-0g/rollup-as-a-service/caldera-on-0g-da)

### Smart Contract Development

**Deploy with Hardhat**:
```javascript
// hardhat.config.js
module.exports = {
  networks: {
    testnet: {
      url: "https://evmrpc-testnet.0g.ai",
      chainId: 16602,
      accounts: ["YOUR_PRIVATE_KEY"]
    },
    mainnet: {
      url: "https://evmrpc.0g.ai",
      chainId: 16661,
      accounts: ["YOUR_PRIVATE_KEY"]
    }
  }
};
```

**Deploy with Foundry**:
```bash
# Testnet
forge create --rpc-url https://evmrpc-testnet.0g.ai \
  --private-key YOUR_PRIVATE_KEY \
  src/MyContract.sol:MyContract

# Mainnet
forge create --rpc-url https://evmrpc.0g.ai \
  --private-key YOUR_PRIVATE_KEY \
  src/MyContract.sol:MyContract
```

**Documentation**: [https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts](https://docs.0g.ai/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts)

## Key Concepts

### AI Alignment
**Documentation**: [https://docs.0g.ai/concepts/ai-alignment](https://docs.0g.ai/concepts/ai-alignment)

Monitor AI systems for proper behavior, safety, and alignment with human values.

**Functions**:
- Track model drift
- Verify outputs
- Monitor performance
- Flag anomalies

### DePIN (Decentralized Physical Infrastructure)
**Documentation**: [https://docs.0g.ai/concepts/depin](https://docs.0g.ai/concepts/depin)

Physical GPU infrastructure provided by decentralized partners.

**Partners**:
- **io.net**: 300,000+ verified GPUs, 139 countries, 90% cost savings
- **Aethir**: 43,000+ enterprise GPUs, 3,000+ H100s/H200s, 99.99% uptime

## Starter Kits & Examples

### Compute Starter Kit
**Quick Start (Recommended for Hackathons)**:
```bash
# Install global CLI
pnpm add @0glabs/0g-serving-broker -g

# Option 1: Web UI (fastest way to start)
0g-compute-cli ui start-web
# Open http://localhost:3090, connect wallet, start using AI

# Option 2: CLI for automation
0g-compute-cli setup-network  # Choose testnet/mainnet
0g-compute-cli login           # Connect your wallet
0g-compute-cli deposit --amount 10  # Fund account
0g-compute-cli inference list-providers  # See available services
```

**OpenAI SDK Drop-in Replacement**:
```python
from openai import OpenAI

# Just change base_url and api_key!
client = OpenAI(
    api_key="app-sk-<YOUR_SECRET>",
    base_url="<PROVIDER_URL>/v1/proxy"
)

# Same API as OpenAI
response = client.chat.completions.create(
    model="<model_name>",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

### Storage Starter Kit
**TypeScript Example**:
```bash
npm install @0glabs/0g-ts-sdk ethers
```
```typescript
import { ZgFile, Indexer } from "@0glabs/0g-ts-sdk";
import { ethers } from "ethers";

const provider = new ethers.JsonRpcProvider("https://evmrpc-testnet.0g.ai");
const signer = new ethers.Wallet("YOUR_PRIVATE_KEY", provider);
const indexer = new Indexer("https://indexer-storage-testnet-turbo.0g.ai");

// Upload file
const file = await ZgFile.fromFilePath("/path/to/file");
const [tree, treeErr] = await file.merkleTree();
console.log("Root Hash:", tree?.rootHash());
const [tx, uploadErr] = await indexer.upload(file, "https://evmrpc-testnet.0g.ai", signer);
await file.close();

// Download file
const err = await indexer.download(rootHash, "/path/to/output", true);
```

**Python Example**:
```bash
pip install 0g-storage-client
```
```python
from storage_client import ZgStorageClient

client = ZgStorageClient(
    rpc_endpoint="https://evmrpc-testnet.0g.ai",
    contract_address="0x22E03a6A89B950F1c82ec5e74F8eCa321a105296",
    private_key="YOUR_PRIVATE_KEY"
)

# Upload
root_hash = client.upload_file("/path/to/file")

# Download
client.download_file(root_hash, "/path/to/output")
```

### Chain/Smart Contract Starter Kit
**Hardhat Project**:
```bash
npm install --save-dev hardhat @nomicfoundation/hardhat-toolbox
npx hardhat init
```
```javascript
// hardhat.config.js
require("@nomicfoundation/hardhat-toolbox");

module.exports = {
  solidity: "0.8.20",
  networks: {
    testnet: {
      url: "https://evmrpc-testnet.0g.ai",
      chainId: 16602,
      accounts: [process.env.PRIVATE_KEY]
    }
  }
};
```
```bash
npx hardhat compile
npx hardhat run scripts/deploy.js --network testnet
```

**Foundry Project**:
```bash
forge init my-project
cd my-project
```
```bash
# Deploy
forge create --rpc-url https://evmrpc-testnet.0g.ai \
  --private-key $PRIVATE_KEY \
  src/Counter.sol:Counter

# Verify interaction
cast call <CONTRACT_ADDRESS> "number()" --rpc-url https://evmrpc-testnet.0g.ai
```

### SDK Examples
- TypeScript SDK: https://github.com/0gfoundation/0g-ts-sdk/tree/main/examples
- Go SDK: https://github.com/0gfoundation/0g-storage-client/tree/main/examples

### Community Projects
**Awesome 0G Repository**: https://github.com/0gfoundation/awesome-0g

Curated list of community projects, tools, and resources built on 0G.

## Quick Reference

### Add Network to MetaMask

**Testnet**:
```javascript
await window.ethereum.request({
  method: 'wallet_addEthereumChain',
  params: [{
    chainId: '0x40EA',
    chainName: '0G-Galileo-Testnet',
    nativeCurrency: { name: '0G', symbol: '0G', decimals: 18 },
    rpcUrls: ['https://evmrpc-testnet.0g.ai'],
    blockExplorerUrls: ['https://chainscan-galileo.0g.ai']
  }]
});
```

**Mainnet**:
```javascript
await window.ethereum.request({
  method: 'wallet_addEthereumChain',
  params: [{
    chainId: '0x4125',
    chainName: '0G Mainnet',
    nativeCurrency: { name: '0G', symbol: '0G', decimals: 18 },
    rpcUrls: ['https://evmrpc.0g.ai'],
    blockExplorerUrls: ['https://chainscan.0g.ai']
  }]
});
```

### Common Commands

**Storage Upload (CLI)**:
```bash
0g-storage-client upload \
  --url https://evmrpc-testnet.0g.ai \
  --key YOUR_PRIVATE_KEY \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --file /path/to/file
```

**Storage Download (CLI)**:
```bash
0g-storage-client download \
  --indexer https://indexer-storage-testnet-turbo.0g.ai \
  --root ROOT_HASH \
  --file output.dat
```

**Check Node Status**:
```bash
# Validator
0gchaind status 2>&1 | jq .

# Storage Node
curl http://localhost:5678/status

# DA Node
curl http://localhost:34000/health
```

## Community & Support

### Official Links
- **Documentation**: https://docs.0g.ai
- **Website**: https://0g.ai
- **GitHub**: https://github.com/0gfoundation
- **Discord**: https://discord.gg/0gLabs
- **Twitter/X**: https://x.com/0g_Labs

### Getting Help
- Documentation: [https://docs.0g.ai/developer-hub/getting-started](https://docs.0g.ai/developer-hub/getting-started)
- Discord Developer Channel: https://discord.gg/0gLabs
- GitHub Issues: Create issues in respective repositories

## Vision & Mission

**Mission**: Make AI a Public Good

**Vision**: Democratized, transparent, fair, and secure AI infrastructure

**Approach**:
- Open infrastructure
- Community ownership
- Economic alignment
- Technical excellence

**Documentation**: [https://docs.0g.ai/introduction/vision-mission](https://docs.0g.ai/introduction/vision-mission)

---

## Additional Resources

### Node Sale Information
**Documentation**: [https://docs.0g.ai/node-sale/node-sale-index](https://docs.0g.ai/node-sale/node-sale-index)

### Security
**Documentation**: [https://docs.0g.ai/resources/security](https://docs.0g.ai/resources/security)

### Contributing
**Documentation**: [https://docs.0g.ai/resources/how-to-contribute](https://docs.0g.ai/resources/how-to-contribute)

### Glossary
**Documentation**: [https://docs.0g.ai/resources/glossary](https://docs.0g.ai/resources/glossary)

---

*This context page is automatically maintained to provide AI coding assistants with comprehensive, up-to-date information about 0G infrastructure. All information is sourced from official documentation at https://docs.0g.ai.*

---

## AI Alignment Nodes

# AI Alignment Nodes: Ensuring Safe Decentralized AI

## What are AI Alignment Nodes?

AI Alignment Nodes are specialized network participants that monitor and ensure the proper behavior of AI systems and network protocols within the 0G ecosystem. They serve as the guardians of network integrity, verifying that all components operate according to their intended specifications.

:::success **Why AI Alignment Matters**
As AI becomes more powerful, ensuring it remains aligned with human values and operates safely becomes critical üõ°Ô∏è
:::

## The Problem with Centralized AI

Traditional AI systems face several alignment challenges:
- **Lack of Transparency**: Black box operations with no external oversight
- **Single Point of Control**: Centralized entities make all decisions about AI behavior
- **Limited Accountability**: No mechanism for community oversight or intervention
- **Potential for Misalignment**: AI systems may drift from their intended purpose without detection

## How AI Alignment Nodes Work

### AI Model Monitoring
As 0G's on-chain AI capabilities expand, Alignment Nodes will:
- **Track Model Drift**: Detect when AI models deviate from expected behavior
- **Verify Outputs**: Ensure AI-generated results meet quality and safety standards
- **Monitor Performance**: Track AI system efficiency and accuracy over time
- **Flag Anomalies**: Alert the network to unusual or potentially harmful AI behavior

### Network Security
Alignment Nodes contribute to overall network security by:
- **Identifying Protocol Violations**: Detecting when nodes fail to follow network rules
- **Reporting Malicious Behavior**: Flagging potential attacks or bad actors
- **Maintaining Ethical Standards**: Ensuring AI operations align with community values
- **Supporting Governance**: Providing data for network governance decisions

## The Future of Decentralized AI Safety

AI Alignment Nodes represent a critical innovation in ensuring that decentralized AI systems remain safe, transparent, and aligned with human values. As AI capabilities expand, these nodes will become increasingly important for:

### Scalable Oversight
- **Automated Monitoring**: AI-powered oversight that scales with network growth
- **Distributed Governance**: Community-driven decisions about AI behavior
- **Continuous Learning**: Alignment systems that improve over time
- **Global Participation**: Worldwide network of AI safety monitors

### Innovation Enablement
By providing robust safety guarantees, Alignment Nodes enable:
- **Faster AI Development**: Developers can build with confidence in safety systems
- **Greater Public Trust**: Transparent oversight builds user confidence
- **Regulatory Compliance**: Meeting emerging AI safety regulations
- **Ecosystem Growth**: Safe AI attracts more users and developers

## Getting Started

Interested in contributing to AI safety through Alignment Nodes?
- [AI Alignment Node ](/node-sale/intro) - Learn more about the AI Alignment Node.

---

*Building safe AI for everyone, together.*

---

## 0G Chain

# 0G Chain: The Fastest Modular AI Chain

## The Problem with AI on Blockchain

Try running an AI model on Ethereum today:
- **Cost**: $1M+ in gas fees for a simple model
- **Speed**: 15 transactions per second (AI needs thousands)
- **Data**: Can't handle AI's massive data requirements

## What is 0G Chain?

0G Chain is a blockchain built specifically for AI applications. Think of it as Ethereum, but optimized for AI workloads with significantly higher throughput.

:::success **EVM Compatibility**
Your existing Ethereum code works without changes ü§ù
:::

## How 0G Chain Works

### Modular Architecture
0G Chain features an advanced modular design that distinctly separates consensus from execution. This separation into independent, yet interconnected, layers is a cornerstone of 0G Chain's architecture, delivering enhanced flexibility, scalability, and a faster pace of innovation.

**Architecture Overview**:
- **Consensus Layer**: Dedicated to achieving network agreement. It manages validator coordination, block production, and ensures the overall security and finality of the chain.
- **Execution Layer**: Focused on state management. It handles smart contract execution, processes transactions, and maintains compatibility with the EVM (Ethereum Virtual Machine).

**Key Technical Advantages**:
- **Independent Upgradability**: The execution layer can rapidly incorporate new EVM features (such as EIP-4844, account abstraction, or novel opcodes) without requiring changes to the underlying consensus mechanism.
- **Focused Optimization**: Conversely, the consensus layer can be upgraded with critical performance or security enhancements without impacting the EVM or ongoing execution processes.
- **Accelerated Development**: This decoupling allows for parallel development and faster iteration cycles for both layers, leading to quicker adoption of new technologies and improvements in both performance and features.

This design makes 0G Chain flexible and fast. When new blockchain features come out, we can add them quickly without breaking anything. This keeps 0G optimized for AI while staying up-to-date with the latest technology.

### Optimized Consensus
0G Chain employs a highly optimized version of CometBFT (formerly Tendermint) as its consensus mechanism, with meticulously tuned parameters that achieve maximum performance while maintaining security. The system features carefully calibrated block production intervals and timeout configurations that work together to deliver high throughput, ensure network stability, and enable faster consensus rounds‚Äîall without compromising the fundamental safety guarantees.

These optimizations enable 0G Chain to achieve maximum performance:
- **11,000 TPS per Shard**: Current throughput significantly exceeds traditional blockchain networks
- **Sub-second Finality**: Near-instant transaction confirmation for AI applications
- **Consistent Performance**: Maintains high throughput even under heavy network load

### Scaling Roadmap
- **DAG-Based Consensus**: Transitioning to Directed Acyclic Graph (DAG) based consensus for exponentially higher efficiency
  - Parallel transaction processing capabilities
  - Elimination of sequential block limitations
  
- **Shared Security Model**: Implementing shared staking mechanisms to enhance network security
  - Validators can secure multiple services simultaneously
  - Increased capital efficiency for stakers

## Technical Deep Dive

<details>
<summary>**How does 0G achieve high throughput?**</summary>

Currently achieves 11,000 TPS per Shard through:

1. **Optimized CometBFT**: Highly efficient consensus based on Tendermind
2. **Efficient block production**: Tuned for AI-scale data processing
3. **Fast finality**: Sub-second transaction confirmation

**Future scaling** will add:
- Multiple parallel consensus networks
- Dynamic capacity expansion
- Automatic load balancing

</details>

<details>
<summary>**How does the validator system work?**</summary>

**Staking & Consensus**:
- Validators stake 0G tokens to participate
- CometBFT ensures Byzantine fault tolerance

**Rewards**:
- Block production rewards
- Transaction fee collection
- Staking yields proportional to stake size

**Node Selection**:
- VRF (Verifiable Random Function) for fair validator selection
- Prevents collusion and ensures decentralization

</details>

<details>
<summary>**What makes 0G different from other fast chains?**</summary>

Unlike general-purpose "fast" blockchains:

- **AI-First Design**: Data structures optimized for AI workloads
- **Modular Architecture**: Upgrade components independently
- **EVM + More**: Start with Ethereum compatibility, expand to other VMs
- **Purpose-Built**: Not retrofitted - designed from scratch for AI

</details>

  
  0G Chain's modular architecture enables seamless integration with storage, compute, and DA layers

## Validator Participation

Validators earn rewards through:
- **Block rewards**: For producing valid blocks
- **Transaction fees**: From network usage
- **Staking rewards**: Based on stake size and uptime

  
  Validator reward and penalty structure in the 0G network

## Frequently Asked Questions

<details>
<summary>**Is 0G Chain truly decentralized?**</summary>

Yes! 0G Chain operates with a permissionless, globally distributed validator set using proof-of-stake consensus. No single entity controls the network.

</details>

<details>
<summary>**Do I need to rewrite my Ethereum dApp?**</summary>

No! Full EVM compatibility means your Solidity code deploys without changes. The only differences you'll notice are speed and cost improvements.

</details>

<details>
<summary>**Why is it faster than Ethereum?**</summary>

0G Chain is purpose-built for AI workloads, while Ethereum is general-purpose. We achieve speed through:
- Optimized consensus mechanism (CometBFT)
- AI-specific data structures
- Focused use case optimization
</details>

## Next Steps

Ready to build? Start here:
- [Quick Start Guide](/developer-hub/getting-started) - Deploy in 5 minutes
- [Migration from Ethereum](/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts) - Move existing dApps
- [Technical Whitepaper](/resources/whitepaper) - Deep architecture details

---

*0G Chain: Where AI meets blockchain at scale.*

---

## 0G Compute Network

# 0G Compute Network: Decentralized AI Computing

In today's world, AI models are transforming industries, driving innovation, and powering new applications. However, running advanced AI models for your application faces several obstacles:

- **High Costs**: Enterprise AI services require significant monthly commitments
- **Complex Setup**: Cloud GPU configuration requires technical expertise
- **Vendor Lock-in**: Limited flexibility when switching providers

**The result?** AI computing remains inaccessible for many developers and startups.

## What is 0G Compute?

0G Compute is a decentralized framework that provides AI computing capabilities to our community. It forms a crucial part of deAIOS. 0G Compute is a decentralized marketplace where GPU owners sell computing power to developers who need it - think Uber for AI computing.

**Key difference**: Instead of renting from AWS/Google with high costs and lock-in, you access a global GPU network that's 90% cheaper with pay-per-use pricing.

## How It Works

### For AI Users

1. **Deposit Funds**: Pre-fund your account with pay-as-you-go credits
2. **Request Service**: Send your AI request (inference, training, etc.)
3. **Get Results**: Receive output from the best available GPU
4. **Automatic Payment**: Pay only for actual compute used

### For GPU Owners

1. **Register Hardware**: List your GPU specs and availability
2. **Set Your Price**: Competitive marketplace pricing
3. **Process Requests**: Automatic job allocation
4. **Instant Earnings**: Get paid immediately upon completion

### Technical Implementation

- **Smart Contract Escrow**: Funds secured until service delivery
- **Signed Transactions**: Cryptographic verification of all interactions
- **ZK-Proof Settlement**: 100x lower transaction costs through compressed proofs

<details>
<summary>**What makes it trustless?**</summary>

Like eBay with automatic escrow - the smart contract ensures:

- Payment only after service delivery
- Both parties must fulfill obligations
- No intermediary can interfere

This means no one can censor your AI usage, freeze your account, or change terms suddenly.

</details>

## Why Choose 0G Compute?

### üí∞ Key Advantages

| Feature          | Traditional Cloud   | 0G Compute         |
| ---------------- | ------------------- | ------------------ |
| Pricing Model    | Fixed monthly costs | Pay-per-use        |
| Provider Options | Limited vendors     | Global GPU network |

### üåê Access From Anywhere

- **Blockchains**: Direct integration with Ethereum, Solana, any chain
- **Traditional Apps**: Simple REST API using 0G SDK

### üîê Your Data, Your Control

- No data retention by providers
- Verifiable computation proofs - Supports TEEML, OPML & ZKML

## Common Questions

<details>
<summary>**What about reliability?**</summary>

Built-in redundancy:

- Automatic failover to next provider
- Thousands of providers globally

</details>

<details>
<summary>**Can I run proprietary models?**</summary>

Yes. Upload any model, set requirements and pricing, start serving requests. Perfect for specialized use cases.

</details>

<details>
<summary>**How does pricing work?**</summary>

Pure pay-per-use:

- No subscriptions
- Competitive market-driven pricing
- Transparent costs visible upfront

</details>

## Get Started

### üìö Technical Deep Dive

Architecture and implementation details  
‚Üí [Technical Documentation](/developer-hub/building-on-0g/compute-network/overview)

### üöÄ For Developers

Start using AI compute in 5 minutes  
‚Üí [Quick Start Guide](/developer-hub/building-on-0g/compute-network/inference)

### üíé For GPU Owners

Turn idle hardware into income  
‚Üí [Become a Provider](/developer-hub/building-on-0g/compute-network/inference-provider)

---

*0G Compute: Making AI accessible to everyone.*

---

## 0G DA

# 0G DA: Infinitely Scalable and Programmable Data Availability

## The Rise of Data Availability Layers

Data availability (DA) refers to proving that data is readily accessible, verifiable, and retrievable. For example, Layer 2 rollups such as Arbitrum or Base reduce the burden on Ethereum by handling transactions off-chain and then publishing the data back to Ethereum, thereby freeing up L1 throughput and reducing gas costs. The transaction data, however, still needs to be made available so that anyone can validate or challenge the transactions through fraud proofs during the challenge period.

As such, DA is crucial to blockchains as it allows for full validation of the blockchain's history and current state by any participant, thus maintaining the decentralized and trustless nature of the network. Without this, validators would not be able to independently verify the legitimacy of transactions and blocks, leading to potential issues like fraud or censorship.
 
This led to the emergence of Data Availability Layers (DALs), which provide a significantly more efficient manner of storing and verifying data than publishing directly to Ethereum. DALs are critical for several reasons:

- **Scalability**: DALs allow networks to process more transactions and larger datasets without overwhelming the system, reducing the burden on network nodes and significantly enhancing network scalability.
- **Increased Efficiency**: DALs optimize how and where data is stored and made available, increasing data throughput and reducing latency while also minimizing associated costs.
- **Interoperability & Innovation**: DALs that can interact with multiple ecosystems enable fast and highly secure interoperability for data and assets.

However, it's worth noting that not all DALs are built equally.

## The Challenge Today

Existing DALs tend to require that data be simultaneously sent to all of their network nodes, preventing horizontal scalability and limiting network speed to its slowest node. They also do not have built-in storage systems, requiring connectivity to external systems that impact throughput, latency, and cost. 

Additionally, 0G inherits Ethereum's security, while other systems rely upon their own security mechanisms that fall short. This is significant because Ethereum's network is secured by over 34 million ETH staked, representing approximately $80 billion in cryptoeconomic security at the time of writing. In contrast, competitors rely on security mechanisms that, at best, represent only a fraction of Ethereum's total security. This gives 0G a distinct advantage, as it leverages the vast economic incentives and decentralization of Ethereum's staking system, providing a level of protection that competitors cannot match.

Even more issues exist, including EigenDA's lack of randomization over its data committees. As data committees are core to a DA system's integrity, a lack of randomization means that collusion is theoretically possible for malicious nodes to predict when they might be on a committee together.

**0G's core differentiation is massive throughput and scalability.**

This is possible through 0G's unique design includes a built-in storage system and horizontally scalable consensus design, alongside other clever design mechanisms that we'll cover below.

The result is that 0G serves as the foundational layer for decentralized AI applications, bringing on-chain AI and more to life.

## Why 0G

There are 4 differentiators of 0G worth highlighting:

### 1. Infinitely Scalable DA
0G's infinitely scalable DAL can quickly query or confirm data as valid, whether data is held by 0G Storage, or external Web2 or Web3 databases. Infinite scalability comes from the ability to continuously add new consensus networks, supporting workloads that far surpass the capacity of existing systems.

### 2. Modular and Layered Architecture
0G's design decouples storage, data availability, and consensus, allowing each component to be optimized for its specific function. Data availability is ensured through redundancy, with data distributed across decentralized Storage Nodes. Cryptographic proofs (like Merkle trees and zk-proofs) verify data integrity at regular intervals, automatically replacing nodes that fail to produce valid proofs. And combined with 0G's ability to keep adding new consensus networks that scale with demand, 0G can scale efficiently and is ideal for complex AI workflows and large-scale data processing.

### 3. Decentralized AI Operating System & High Throughput
0G is the first decentralized AI operating system (deAIOS) designed to give users control over their data, while providing the infrastructure necessary to handle the massive throughput demands of AI applications. Beyond its modular architecture and infinite consensus layers, 0G achieves high throughput through parallel data processing, enabled by erasure coding, horizontally scalable consensus networks, and more. With a demonstrated throughput of 50 Gbps on the Galileo Testnet, 0G seamlessly supports AI workloads and other high-performance needs, including training large language models and managing AI agent networks.

These differentiators make 0G uniquely positioned to tackle the challenges of scaling AI on a decentralized platform, which is critical for the future of Web3 and decentralized intelligence.

## How Does This Work?

As covered in [0G Storage](./storage.md), data within the 0G ecosystem is first erasure-coded and split into "data chunks," which are then distributed across various Storage Nodes in the 0G Storage network. 

To ensure data availability, 0G uses **Data Availability Nodes** that are randomly chosen using a Verifiable Random Function (VRF). A VRF generates random values in a way that is unpredictable yet verifiable by others, which is important as it prevents potentially malicious nodes from collusion.

These DA nodes work together in small groups, called quorums, to check and verify the stored data. The system assumes that most nodes in each group will act honestly, known as an "honest majority" assumption. 

The consensus mechanism used by 0G is fast and efficient due to its sampling-based approach. Rather than verifying all data, DA nodes sample portions of it, drastically reducing the data they need to handle. Once enough nodes agree that the sampled data is available and correct, they submit availability proofs to the 0G Consensus network. This lightweight, sample-driven approach enables faster verification while maintaining strong security.

  
  Validators in the 0G Consensus network verify and finalize DA proofs

Validators in the 0G Consensus network, who are separate from the DA nodes, verify and finalize these proofs. Although DA nodes ensure data availability, they do not directly participate in the final consensus process, which is the responsibility of 0G validators. Validators use a shared staking mechanism where they stake 0G tokens on a primary network (likely Ethereum). Any slashable event across connected networks leads to slashing on the main network, securing the system's scalability while maintaining robust security. 

This is a key mechanism that allows for the system to scale infinitely while maintaining data availability. In return, validators engaged in shared staking receive 0G tokens on any network managed, which can then be burnt in return for 0G tokens on the mainnet.

  
  The lightweight, sample-driven consensus approach

## Use Cases

0G DA offers an infinitely scalable and high-performance DA solution for a wide range of applications across Web3, AI, and more.

### L1s / L2s

Layer 1 and Layer 2 chains can utilize 0G DA to handle data availability and storage requirements for decentralized AI models, large datasets, and on-chain applications. Existing partners include networks like **Polygon, Optimism, Arbitrum, Fuel, Manta Network**, **and countless more**, which leverage 0G's scalable infrastructure to store data more efficiently and support fast retrieval.

### Decentralized Shared Sequencers

Decentralized Shared Sequencers help order L2 transactions before final settlement on Ethereum. By integrating 0G DA, shared sequencers can streamline data across multiple networks in a decentralized manner, unlike existing sequencers which are often centralized. This also means fast and secure data transfers between L2s.

### Bridges

Cross-chain bridges benefit from 0G DA's scalable storage and data availability features. Networks can store and retrieve state data using 0G DA, making state migration between networks faster and more secure. For example, a network can confirm a user's assets and transfer them securely to another chain using 0G's highly efficient data verification.

### Rollups-as-a-Service (RaaS)

0G DA can serve as a reliable DA solution for RaaS providers like **Caldera and AltLayer**, enabling seamless configuration and deployment of rollups. With 0G DA's highly scalable infrastructure, RaaS providers can ensure the secure availability of data across multiple rollups without compromising performance.

### DeFi

0G's DA infrastructure is ideally suited for DeFi applications that require fast settlement and high-frequency trading. For example, by storing order book data on 0G, DeFi projects can achieve faster transaction throughput and enhanced scalability across L2s and L3s.

### On-Chain Gaming

On-chain gaming platforms rely on cryptographic proofs and metadata related to player assets, actions, and scores. 0G DA's ability to handle large volumes of data securely and efficiently makes it an optimal solution for gaming applications that require reliable data storage and fast retrieval.

### Data Markets

Web3 data markets can benefit from 0G DA by storing datasets on-chain. The decentralized storage and retrieval capabilities of 0G enable real-time updates and querying of data, providing a reliable solution for data market platforms.

### AI & Machine Learning

0G DA is particularly focused on supporting decentralized AI, allowing full AI models and vast datasets to be stored and accessed on-chain. This infrastructure is essential for advanced AI applications that demand high data throughput and availability, such as training large language models (LLMs) and managing entire AI agent Networks.

## Getting Started

Ready to integrate 0G DA into your project?

- **Run a DA Node**: [Node operator guide](/run-a-node/da-node)
- **Integration Guide**: [Developer documentation](/developer-hub/building-on-0g/da-integration)
- **Technical Deep Dive**: [DA architecture details](/developer-hub/building-on-0g/da-deep-dive)

---

*0G DA: Bringing infinite scalability to decentralized data availability.*

---

## DePIN Providers

# DePIN Providers: Decentralized Infrastructure Networks

## What is DePIN?

DePIN (Decentralized Physical Infrastructure Networks) represents a revolutionary approach to building and scaling infrastructure networks. By combining physical hardware with blockchain incentives, DePIN networks create more open, decentralized, and cost-effective infrastructure across various sectors.

:::success **Why DePIN Matters**
Traditional infrastructure is expensive and centralized. DePIN democratizes access to computing power by utilizing underutilized hardware worldwide üöÄ
:::

## How 0G Leverages DePIN Infrastructure

0G Compute utilizes DePIN infrastructure to provide scalable, cost-effective computing resources for AI and blockchain applications. Rather than building massive centralized data centers, 0G partners with decentralized networks that aggregate distributed computing resources.

### Key Benefits of DePIN Integration

**Cost Efficiency**: DePIN networks utilize existing underutilized hardware, reducing costs by up to 80% compared to traditional cloud providers.

**Global Reach**: Distributed nodes worldwide provide low-latency access to computing resources regardless of geographic location.

**Scalability**: New resources can be added to the network without physical infrastructure expansion, enabling rapid scaling.

**Resilience**: No single point of failure with resources distributed across thousands of independent nodes.

## 0G's DePIN Partners

### [io.net](https://io.net)

io.net operates the world's largest decentralized GPU network, specifically designed for machine learning and AI workloads. The network aggregates over 300,000 verified GPUs from independent data centers, crypto miners, and consumer hardware across 139 countries.

**Key Capabilities:**

- 6,000+ cluster-ready GPUs including NVIDIA H100s
- 90% cost savings compared to traditional cloud providers
- 90-second cluster deployment
- Built on Ray.io framework (same as OpenAI's GPT training)

### [Aethir](https://aethir.com)

Aethir provides enterprise-grade GPU-as-a-Service through its decentralized cloud infrastructure. Focused on AI, gaming, and virtualized computing, Aethir maintains over 43,000 enterprise-grade GPUs across 25 global locations.

**Key Capabilities:**

- 3,000+ NVIDIA H100s and H200s for advanced AI workloads
- 99.99% uptime with enterprise-grade reliability
- Ultra-low latency for real-time applications
- Proof of Rendering verification system

## Technical Deep Dive

<details>
<summary>**What makes DePIN different from traditional cloud?**</summary>

**Resource Utilization**: DePIN networks tap into idle hardware worldwide instead of building new data centers

**Economic Model**: Token incentives create sustainable participation without massive capital expenditure

**Geographic Distribution**: Resources are naturally distributed, reducing latency for global users

**Permissionless Access**: Anyone can contribute resources or access compute power without gatekeepers

</details>

<details>
<summary>**How do DePIN networks ensure quality?**</summary>

**Verification Systems**: Proof-of-Work, Proof-of-Capacity, and custom verification mechanisms

**Quality Scoring**: Real-time monitoring and automated scoring of network participants

**Economic Incentives**: Token rewards for good performance, slashing for poor performance

**Redundancy**: Multiple nodes can handle the same task to ensure reliability

</details>

## The Future of Decentralized Computing

The integration of 0G with DePIN infrastructure creates a comprehensive Web3 computing stack that addresses the growing demand for AI and blockchain applications. This partnership model enables:

- **Affordable AI**: Making advanced AI computing accessible to startups and developers worldwide
- **Scalable Infrastructure**: Meeting growing compute demands without massive capital investment
- **Global Accessibility**: Bringing high-performance computing to underserved regions
- **Sustainable Growth**: Utilizing existing hardware more efficiently

## Getting Started

Ready to build with decentralized infrastructure? Explore these resources:

- [0G Compute Network](/developer-hub/building-on-0g/compute-network/overview) - Learn about 0G's compute layer
- [Developer SDK](/developer-hub/building-on-0g/compute-network/inference) - Start building with 0G Compute
- [Developer Hub](/developer-hub/getting-started) - Get started building on 0G

---

_Powering the future of AI with decentralized infrastructure._

---

## INFT

# INFTs: Intelligent NFTs for AI

Traditional NFTs can't handle AI agents. When you "own" an AI agent NFT today, you only own a pointer to some metadata - not the actual intelligence. The AI doesn't transfer with the NFT.

## What are INFTs?

**INFTs (Intelligent Non-Fungible Tokens)** solve this problem. They're a new type of NFT specifically designed to tokenize AI agents with their complete intelligence intact.

<details>
<summary>New to AI tokenization?</summary>

Traditional approach:
- NFT points to AI metadata stored somewhere
- When you buy the NFT, you don't get the actual AI
- The intelligence stays with the original creator
- You can't actually use the AI agent

INFT approach:
- NFT contains encrypted AI intelligence
- When transferred, the AI moves with it
- New owner gets full access to the AI agent
- Complete ownership of AI capabilities
</details>

## Why INFTs Matter

### True AI Ownership
Unlike regular NFTs that just point to metadata, INFTs contain the actual AI agent. When you own an INFT, you own the complete intelligence, not just a certificate.

### Privacy-First Design
AI agents often contain sensitive data or proprietary algorithms. INFTs keep this data encrypted throughout the entire lifecycle - only the owner can access it.

### Secure Transfers
When an INFT changes hands, both the ownership AND the encrypted AI intelligence transfer together. The new owner gets a fully functional AI agent.

### Decentralized Storage
INFTs leverage 0G Storage to keep AI agents permanently available without relying on centralized servers that could go offline.

## Real-World Use Cases

| Use Case | How INFTs Help | Example |
|----------|---------------|---------|
| **AI Trading Bots** | Own and transfer profitable trading strategies | DeFi trading bot with proven track record |
| **Personal Assistants** | Trained AI agents that know your preferences | AI that learned your workflow and habits |
| **Game Characters** | Intelligent NPCs with unique personalities | AI companion that evolved through gameplay |
| **Content Creation** | AI models trained for specific styles | AI artist trained on your creative style |
| **Research Tools** | Specialized AI for domain-specific tasks | Medical AI trained on specific datasets |

## How It Works

1. **Create**: Build and train your AI agent
2. **Encrypt**: Secure the AI's intelligence with encryption
3. **Mint**: Create an INFT containing the encrypted AI
4. **Own**: Have complete ownership and control over the AI agent

## Technical Foundation

INFTs are built on **ERC-7857**, a new NFT standard that extends ERC-721 with:

- **Encrypted metadata storage** for protecting AI intelligence
- **Secure re-encryption** for safe ownership transfers  
- **Oracle verification** to ensure transfer integrity
- **Authorized usage** for AI-as-a-Service models

## Powered by 0G

INFTs leverage the complete 0G ecosystem:

| Component | Role | Benefit |
|-----------|------|---------|
| **0G Storage** | Encrypted AI storage | Permanent, decentralized availability |
| **0G Chain** | Smart contract execution | Fast, low-cost INFT operations |
| **0G Compute** | Secure AI inference | Private execution environment |
| **0G DA** | Transfer verification | Guaranteed data availability |

## Getting Started

### For AI Developers
Transform your AI agents into tradeable assets while maintaining privacy and control.

**[Build INFTs](../developer-hub/building-on-0g/inft/inft-overview)** - Complete development guide

---

:::tip Next Steps
Ready to dive deeper? Check out the **[complete INFT documentation](../developer-hub/building-on-0g/inft/inft-overview)** for technical details, implementation guides, and real-world examples.
:::

---

## 0G Storage

# 0G Storage: Built for Massive Data

Current storage options force impossible tradeoffs:
- **Cloud providers**: Fast but expensive with vendor lock-in
- **Decentralized options**: Either slow (IPFS), limited (Filecoin), or prohibitively expensive (Arweave)

## What is 0G Storage?

0G Storage breaks these tradeoffs - a decentralized storage network that's as fast as AWS S3 but built for Web3. Purpose-designed for AI workloads and massive datasets.

<details>
<summary>New to decentralized storage?</summary>

Traditional storage (like AWS):
- One company controls your data
- They can delete it, censor it, or change prices
- Single point of failure

Decentralized storage (like 0G):
- Data spread across thousands of nodes
- No single entity can delete or censor
- Always available, even if nodes go offline
</details>

## Why Choose 0G Storage?

### üöÄ The Complete Package

| What You Get | Why It Matters |
|--------------|----------------|
| **95% lower costs than AWS** | Sustainable for large datasets |
| **Instant retrieval** | No waiting for critical data |
| **Structured + unstructured data** | One solution for all storage needs |
| **Universal compatibility** | Works with any blockchain or Web2 app |
| **Proven scale** | Already handling TB-scale workloads |

## How It Works

0G Storage is a distributed data storage system designed with on-chain elements to incentivize storage nodes to store data on behalf of users. Anyone can run a storage node and receive rewards for maintaining one.

### Technical Architecture

0G Storage uses a two-lane system:

<details>
<summary>üì§ Data Publishing Lane</summary>

- Handles metadata and availability proofs
- Verified through 0G Consensus network
- Enables fast data discovery
</details>

<details>
<summary>üíæ Data Storage Lane</summary>

- Manages actual data storage
- Uses erasure coding: splits data into chunks with redundancy
- Even if 30% of nodes fail, your data remains accessible
- Automatic replication maintains availability
</details>

## Storage Layers for Different Needs

### üìÅ Log Layer (Immutable Storage)
**Perfect for**: AI training data, archives, backups
- Append-only (write once, read many)
- Optimized for large files
- Lower cost for permanent storage

**Use cases**:
- ML datasets
- Video/image archives  
- Blockchain history
- General Large file storage

### üîë Key-Value Layer (Mutable Storage)
**Perfect for**: Databases, dynamic content, state storage
- Update existing data
- Fast key-based retrieval
- Real-time applications

**Use cases**:
- On-chain databases
- User profiles
- Game state
- Collaborative documents

## How Storage Providers Earn
0G Storage is maintained by a network of miners incentivized to store and manage data through a unique consensus mechanism known as **Proof of Random Access (PoRA)**.

### How It Works

1. **Random Challenges**: System randomly asks miners to prove they have specific data
2. **Cryptographic Proof**: Miners must generate a valid hash (like Bitcoin mining)
3. **Quick Response**: Must respond fast to prove data is readily accessible
4. **Fair Rewards**: Successful proofs earn storage fees

<details>
<summary>What's PoRA in simple terms?</summary>

Imagine a teacher randomly checking if students did their homework:
1. Teacher picks a random student (miner)
2. Asks for a specific page (data chunk)
3. Student must show it quickly
4. If correct, student gets rewarded

This ensures miners actually store the data they claim to store.
</details>

### Fair Competition = Fair Reward
To promote fairness, the mining range is capped at 8 TB of data per mining operation.

**Why 8TB limit?**
- Small miners can compete with large operations
- Prevents centralization
- Lower barrier to entry

**For large operators**: Run multiple 8TB instances.

**For individuals**: Focus on single 8TB range, still profitable

## How 0G Compares

| Solution | Best For | Limitation |
|----------|----------|------------|
| **0G Storage** | AI/Web3 apps needing speed + scale | Newer ecosystem |
| **AWS S3** | Traditional apps | Centralized, expensive |
| **Filecoin** | Cold storage archival | Slow retrieval, unstructured only |
| **Arweave** | Permanent storage | Extremely expensive |
| **IPFS** | Small files, hobby projects | Very slow, no guarantees |

### 0G's Unique Position
- **Only solution** supporting both structured and unstructured data
- **Instant access** unlike other decentralized options
- **Built for AI** from the ground up

## Frequently Asked Questions

<details>
<summary>Is my data really safe if nodes go offline?</summary>

Yes! The erasure coding system ensures your data survives node failures. The network automatically maintains redundancy levels, so your data remains accessible even during significant outages.
</details>

<details>
<summary>How fast can I retrieve large files?</summary>

- Parallel retrieval from multiple nodes
- Bandwidth limited only by your connection
- 200 MBPS retrieval speed even at network congestion
- CDN-like performance through geographic distribution
</details>

<details>
<summary>What happens to pricing as the network grows?</summary>

The network fee is fixed. All pricing is transparent and on-chain, preventing hidden fees or sudden changes.
</details>

<details>
<summary>Can I migrate from existing storage?</summary>

Yes, easily:
1. Keep existing infrastructure
2. Use 0G as overflow or backup
3. Gradually migrate based on access patterns
</details>

## Get Started

### üßë‚Äçüíª For Developers
Integrate 0G Storage in minutes
‚Üí [SDK Documentation](/developer-hub/building-on-0g/storage/sdk)

### ‚õèÔ∏è For Storage Providers  
Earn by providing storage capacity
‚Üí [Run a Storage Node](/run-a-node/storage-node)

---

*0G Storage: Purpose-built for AI and Web3's massive data needs.*

---

## Babylon AVS on 0G DA


Under construction...

---

## EigenLayer AVS on 0G DA


Under construction...

---

## Account

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Account

The 0G Compute Network uses a unified account system for managing funds across services. This guide covers how to manage your accounts using different interfaces: Web UI, CLI, and SDK.

## Overview

The account system provides a secure and flexible way to manage funds across different AI service providers.

### Account Structure

- **Main Account**: Your primary wallet where funds are deposited. All deposits go here first, and you can withdraw funds from here back to your wallet.
- **Sub-Accounts**: Provider-specific accounts created automatically when you transfer funds to a provider. Each provider has a separate sub-account where funds are locked for their specific services.

### Fund Flow

1. **Deposit**: Transfer funds from your wallet to your Main Account
2. **Transfer**: Move funds from Main Account to Provider Sub-Accounts
3. **Usage**: Provider deducts from Sub-Account for services rendered
4. **Refund Request**: Initiate refund from Sub-Account (enters 24-hour lock period)
5. **Complete Refund**: After lock period expires, call retrieve-fund again to complete transfer back to Main Account
6. **Withdraw**: Transfer funds from Main Account back to your wallet

### Security Features

- **24-hour lock period** for refunds to protect providers from abuse
- **Single-use authentication** for each request to prevent replay attacks
- **On-chain verification** for all transactions ensuring transparency
- **Provider acknowledgment** required before first use of services

## Prerequisites

- Node.js >= 22.0.0
- A wallet with 0G tokens (for testnet or mainnet)
- EVM compatible wallet (for Web UI)

## Choose Your Interface

| Feature | Web UI | CLI | SDK |
|---------|--------|-----|-----|
| Setup time | ~1 min | ~2 min | ~5 min |
| Visual dashboard | ‚úÖ | ‚ùå | ‚ùå |
| Automation | ‚ùå | ‚úÖ | ‚úÖ |
| App integration | ‚ùå | ‚ùå | ‚úÖ |

<Tabs>
<TabItem value="web-ui" label="Web UI" default>

**Best for:** Quick account management with visual dashboard

### Installation

```bash
pnpm add @0glabs/0g-serving-broker -g
```

### Launch Web UI

```bash
0g-compute-cli ui start-web
```

Access the Web UI at `http://localhost:3090/wallet` where you can:

- View your account balance in real-time
- Deposit funds directly from your connected wallet
- Transfer funds to provider sub-accounts
- Monitor spending and usage
- Request refunds with a visual interface

</TabItem>
<TabItem value="cli" label="CLI">

**Best for:** Automation, scripting, and server environments

### Installation

```bash
pnpm add @0glabs/0g-serving-broker -g
```

### Setup Environment

#### Choose Network

```bash
0g-compute-cli setup-network
```

#### Login with Wallet

Enter your wallet private key when prompted. This will be used for account management and service payments.

```bash
0g-compute-cli login
```

### CLI Commands

#### Deposit Funds

Add funds to your main account:

```bash
0g-compute-cli deposit --amount 10
```

#### Check Balance

View your account overview:

```bash
0g-compute-cli get-account
```

Example output:

```
Overview
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Balance                                          ‚îÇ Value (0G)                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Total                                            ‚îÇ 8.822778129999999663                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Locked (transferred to sub-accounts)             ‚îÇ 8.257334240000000491                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Available for transfer to sub-accounts           ‚îÇ 0.265443889999999960                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Inference sub-accounts
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Provider               ‚îÇ Balance (0G)                 ‚îÇ Requested Return to Main Account (0G)          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0x924A2c71...          ‚îÇ 3.257334240000000047         ‚îÇ 0.000000000000000000                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0x960E74Fc...          ‚îÇ 3.000000000000000000         ‚îÇ 3.000000000000000000                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0x4f371f6e...          ‚îÇ 3.299999999999999822         ‚îÇ 0.000000000000000000                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Transfer to Provider

Before using a provider's service, transfer funds to their sub-account:

```bash
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 5
```

#### Request Refund

Withdraw unused funds from sub-accounts back to main account:

```bash
0g-compute-cli retrieve-fund
```

**Note**: Refunds have a 24-hour lock period for security. After the lock period expires, you need to call this function again to complete the refund and transfer the funds back to your main account. You can check the remaining lock time using the `get-sub-account` command:

```bash
0g-compute-cli get-sub-account --provider <PROVIDER_ADDRESS>
```

Example output showing refund details:
```
Details of Each Amount Applied for Return to Main Account
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Amount (0G)                                      ‚îÇ Remaining Locked Time                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0.099785050000000000                             ‚îÇ 23h 43min 15s                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Withdraw to Wallet

Withdraw funds from main account to your wallet:

```bash
0g-compute-cli refund --amount 5
```

</TabItem>
<TabItem value="sdk" label="SDK">

**Best for:** Application integration and programmatic access

### Installation

```bash
pnpm add @0glabs/0g-serving-broker
```

### Initialize Broker

```typescript
import { ethers } from "ethers";
import { createZGComputeNetworkBroker } from "@0glabs/0g-serving-broker";

const provider = new ethers.JsonRpcProvider("https://evmrpc-testnet.0g.ai");
const wallet = new ethers.Wallet(process.env.PRIVATE_KEY!, provider);
const broker = await createZGComputeNetworkBroker(wallet);
```

### Check Account Balance

```typescript
const account = await broker.ledger.getLedger();
console.log(`Total Balance: ${ethers.formatEther(account.totalBalance)} 0G`);
console.log(`Available: ${ethers.formatEther(account.availableBalance)} 0G`);
```

### Deposit Funds

```typescript
await broker.ledger.depositFund(10); // Deposit 10 0G
```

### Transfer to Provider

```typescript
const providerAddress = "<PROVIDER_ADDRESS>";
const amount = ethers.parseEther("5"); // 5 0G
await broker.ledger.transferFund(providerAddress, "inference", amount);
```

### Check Sub-Account Details

```typescript
const [subAccount, refunds] = await broker.inference.getAccountWithDetail(providerAddress);
console.log(`Sub-account balance: ${ethers.formatEther(subAccount.balance)} 0G`);

const { account: subAccount, refunds } = await broker.fineTuning.getAccountWithDetail(providerAddress);
console.log(`Sub-account balance: ${ethers.formatEther(subAccount.balance)} 0G`);
```

### Request Refund

```typescript
await broker.ledger.retrieveFund("inference");
await broker.ledger.retrieveFund("fine-tuning");
```

### Withdraw to Wallet

```typescript
await broker.ledger.refund(5); // Withdraw 5 0G
```

</TabItem>
</Tabs>

---

## Best Practices

### For Inference Services

1. Deposit enough funds for expected usage
2. Transfer funds to providers you plan to use frequently
3. Keep some balance in sub-accounts for better response times
4. Monitor usage regularly

### For Fine-tuning Services

1. Calculate dataset size before transferring funds
2. Transfer enough to cover the entire training job
3. Request refunds for unused funds after job completion

## Troubleshooting

<details>
<summary>Insufficient Balance Error</summary>

Check which account needs funds:

- Main account: Use `deposit`
- Sub-account: Use `transfer-fund`

```bash
# Check all balances
0g-compute-cli get-account

# Deposit to main account if needed
0g-compute-cli deposit --amount 10

# Transfer to provider if needed
0g-compute-cli transfer-fund --provider <ADDRESS> --amount 5
```

</details>

<details>
<summary>Refund Not Available</summary>

Refunds have a 24-hour lock period. After the lock period expires, you need to call the retrieve-fund function again to complete the refund. Check the status:

```bash
0g-compute-cli get-sub-account --provider <PROVIDER_ADDRESS>
```

Look for "Remaining Locked Time" in the output.

</details>

<details>
<summary>Transaction Failed</summary>

Common causes:

1. Network issues - Check your RPC endpoint
2. Gas price too low - Increase gas price
3. Insufficient gas - Ensure wallet has enough for gas fees

```bash
# Specify custom gas price
0g-compute-cli deposit --amount 10 --gas-price 20000000000
```

</details>

## Related Documentation

- [Inference Services](./inference) - Using AI inference with your funded accounts
- [Fine-tuning Services](./fine-tuning) - Training custom models with your funded accounts

---

## Fine-tuning Provider

# Become a Fine-tuning Provider

This guide provides a comprehensive walkthrough for setting up and offering computing power as a fine-tuning provider on the 0G Compute Network.

## Prerequisites

- Docker and Docker Compose
- TDX-enabled Intel CPU
- Compatible NVIDIA GPU (H100/H200 with TEE support)
- Wallet with 0G tokens for gas fees
- Publicly accessible server

## Preparation

### Download the Installation Package

- **Visit the Releases Page:** [0G Serving Broker Releases](https://github.com/0gfoundation/0g-serving-broker/releases)
- **Download and Extract:** Get the latest version of the fine-tuning installation package.

### Configuration Setup

**Copy the Config File:** Duplicate `config.example.yaml` to create `config.local.yaml`.

```bash
cp config.example.yaml config.local.yaml
```

**Modify Settings:**
- Set `servingUrl` to your publicly accessible URL.
- Set `privateKeys` using your wallet's private key for the 0G blockchain.

**Edit `docker-compose.yml`:** Replace `#PORT#` with the desired port, matching the port in `config.local.yaml`.

```bash
# Replace #PORT# with your service port
sed -i 's/#PORT#/8080/g' docker-compose.yml
```

### Supporting Custom Models from Providers

To include custom models, refer to the example configuration below and update your `config.local.yaml` file accordingly. Ensure that all required fields are properly defined to match your specific model setup.

```yaml
service:
  customizedModels:
    - name: "deepseek-r1-distill-qwen-1.5b"
      hash: "<MODEL_ROOT_HASH>"
      image: "deepseek:latest"
      dataType: "text"
      trainingScript: "/app/finetune.py"
      description: "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning."
      tokenizer: "<TOKENIZER_ROOT_HASH>"
      usageFile: "<ZIP_FILE>"
    - name: "mobilenet_v2"
      hash: "<MODEL_ROOT_HASH>"
      image: "mobilenetV2:latest"
      dataType: "image"
      trainingScript: "/app/finetune.py"
      description: "MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224."
      tokenizer: "<TOKENIZER_ROOT_HASH>"
      usageFile: "<ZIP_FILE>"
```

**Configuration Fields:**

- **name:** Model identifier
- **hash:** The root hash of the pre-trained model, obtained after uploading the model to 0G storage.
- **image:** The Docker image that encapsulates the fine-tuning execution environment.
- **dataType:** Specifies the type of dataset the model is intended to train on. Valid options include `text` or `image`.
- **trainingScript:** Specifies the path to the training script within the container. Fine-tuning will be executed using the command `python <trainingScript>`.
- **description:** A concise overview of the model, highlighting its key features and capabilities.
- **tokenizer:** The root hash of the tokenizer files used for dataset processing. This value is obtained after uploading the tokenizer files to 0G storage.
- **usageFile:** The ZIP file (referenced by its name, not the full path) contains detailed usage information for this model, including training configuration examples, build specifications, or sample datasets. Make sure the file is placed in the `./models` directory.

## Build the TDX Guest Image

### Prerequisites Installation

**Install Docker:**
```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

**Add User to Docker Group:**
```bash
sudo usermod -aG docker $USER
newgrp docker
```

**Verify Installation:**
```bash
docker --version
docker run hello-world
```

### Build CVM Image

To ensure secure and private execution of fine-tuning tasks, you will build an image suitable for running in a Confidential Virtual Machine (CVM). This process leverages NVIDIA's TEE GPU technology and Intel CPUs with TDX support, enhancing security by running model training in an isolated environment.

**Clone Repository:**

```bash
git clone https://github.com/nearai/private-ml-sdk --recursive
cd private-ml-sdk/
./build.sh
```

**Image Files Location:** Check out `private-ml-sdk/images/`. Available images include:
- `dstack-nvidia-0.3.0`: Production image without developer tools.
- `dstack-nvidia-dev-0.3.0`: Development image with tools like `sshd`, `strace`.

## Run Application

### Run the Local KMS

The Local KMS provides essential keys for CVM initialization, derived from local TEE hardware.

**Launch KMS:**
```bash
cd private-ml-sdk/meta-dstack-nvidia/dstack/key-provider-build/
./run.sh
```

### Run the TDX Guest Image

Ensure you have a TDX host machine with the TDX driver and a compatible NVIDIA GPU.

**Update PATH:**

```bash
pushd private-ml-sdk/meta-dstack-nvidia/scripts/bin
PATH=$PATH:`pwd`
popd
```

**List Available GPUs:**

```bash
dstack lsgpu
```

**Create CVM Instance:**

Replace `#PORT#` with your configured port:

```bash
dstack new docker-compose.yaml -o my-gpu-cvm \
       --local-key-provider \
       --gpu [GPU_ID] \
       --image images/dstack-nvidia-0.3.0 \
       -c 2 -m 4G -d 100G \
       --port tcp:0.0.0.0:#PORT#:#PORT#
```

### Run the CVM

**Copy Config File:**

```bash
cp config.local.yaml private-ml-sdk/my-gpu-cvm/shared/config.local.yaml
```

**Start the CVM:**
```bash
sudo -E dstack run my-gpu-cvm
```

## Troubleshooting

<details>
<summary>CVM fails to start</summary>

- Verify TDX is enabled in BIOS
- Check GPU compatibility and drivers
- Ensure sufficient resources allocated
- Review logs: `sudo dstack logs my-gpu-cvm`
</details>

<details>
<summary>Service not accessible</summary>

- Confirm firewall allows incoming connections
- Verify public IP/domain configuration
- Check port consistency between config and Docker
- Test local connectivity first
</details>

<details>
<summary>Model upload issues</summary>

- Ensure model files are uploaded to 0G storage
- Verify root hash is correctly configured
- Check tokenizer files are included
- Confirm Docker image exists and is accessible
</details>

---

*By following these steps, you will successfully set up your service as a fine-tuning provider on the 0G Compute Network, leveraging secure and verifiable computing environments.*

---

## Fine-tuning


Customize AI models with your own data using 0G's distributed GPU network.

## Quick Start

### Prerequisites
Node version >= 22.0.0

### Install CLI

```bash
pnpm install @0glabs/0g-serving-broker -g
```

### Set Environment

#### Choose Network
```bash
# Setup network
0g-compute-cli setup-network
```

#### Login with Wallet
Enter your wallet private key when prompted.
```bash
# Login with your wallet private key
0g-compute-cli login
```

### Create Account & Add Funds
The Fine-tuning CLI requires an account to pay for service fees via the 0G Compute Network.

**For detailed account management instructions, see [Account Management](./account-management).**

```bash
# Deposit funds to your account
0g-compute-cli deposit --amount 3

# Transfer funds to a provider for fine-tuning
# IMPORTANT: You must specify --service fine-tuning, otherwise funds go to the inference sub-account
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 2 --service fine-tuning
```

:::tip
If you see `MinimumDepositRequired` when creating a task, it means you haven't transferred funds to the provider's **fine-tuning** sub-account. Make sure to include `--service fine-tuning` in the `transfer-fund` command.
:::

### List Providers
```bash
0g-compute-cli fine-tuning list-providers
```
The output will be like:
```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Provider 1                                       ‚îÇ 0x940b4a101CaBa9be04b16A7363cafa29C1660B0d       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Available                                        ‚îÇ ‚úì                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- **Provider x:** The address of the provider.
- **Available:** Indicates if the provider is available. If `‚úì`, the provider is available. If `‚úó`, the provider is occupied.

### List Models

```bash
# List available models
0g-compute-cli fine-tuning list-models
```

<details>
<summary>üìã Available Models Summary</summary>

The CLI displays two categories of models: predefined models available across all providers and provider-specific models with unique capabilities.

#### Predefined Models
These are standard models available across all providers:

| Model Name | Type | Price per Million Tokens | Description |
|------------|------|--------------------------|-------------|
| `Qwen2.5-0.5B-Instruct` | Causal LM | 0.5 0G | Qwen 2.5 instruction-tuned model (0.5B parameters). More details: [HuggingFace](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct) |
| `Qwen3-32B` | Causal LM | 4 0G | Qwen 3 large language model (32B parameters). More details: [HuggingFace](https://huggingface.co/Qwen/Qwen3-32B) |

</details>

The output consists of two main sections:

- **Predefined Models:** Models provided by the system as predefined options. They are built-in, curated, and maintained to ensure quality and reliability.

- **Provider's Model:** Models offered by external service providers. Providers may customize or fine-tune models to address specific needs.

:::caution Model Name Format
Use model names **without** the `Qwen/` prefix when specifying the `--model` parameter. For example:
- ‚úÖ `--model "Qwen2.5-0.5B-Instruct"`
- ‚ùå `--model "Qwen/Qwen2.5-0.5B-Instruct"`
:::

### Prepare Configuration File

Use the standard configuration template below and **only modify the parameter values** as needed. Do not add additional parameters.

#### Standard Configuration Template

```json
{
  "neftune_noise_alpha": 5,
  "num_train_epochs": 1,
  "per_device_train_batch_size": 2,
  "learning_rate": 0.0002,
  "max_steps": 3
}
```

:::caution Important Configuration Rules
1. **Use the template above** - Copy the entire template
2. **Only modify parameter values** - Do not add or remove parameters
3. **Use decimal notation** - Write `0.0002` instead of `2e-4` for `learning_rate`

**Common mistakes to avoid:**
- ‚ùå Adding extra parameters (e.g., `"fp16": true`, `"bf16": false`)
- ‚ùå Removing existing parameters
- ‚ùå Using scientific notation like `2e-4`
:::

#### Adjustable Parameters

You can modify these parameter values based on your training needs:

| Parameter | Description | Notes |
|-----------|-------------|-------|
| `neftune_noise_alpha` | Noise injection for fine-tuning | 0-10 (0 = disabled), typical: 5 |
| `num_train_epochs` | Number of complete passes through the dataset | Positive integer, typical: 1-3 for fine-tuning |
| `per_device_train_batch_size` | Training batch size | 1-4, reduce to 1 if out of memory |
| `learning_rate` | Learning rate (use decimal notation) | 0.00001-0.001, typical: 0.0002 |
| `max_steps` | Maximum training steps | -1 (use epochs) or positive integer |

:::tip GPU Memory Management
- If you encounter out-of-memory errors, **reduce batch size to 1**
- The provider automatically handles mixed precision training with `bf16`
:::

*Note:* For custom models provided by third-party Providers, you can download the usage template including instructions on how to construct the dataset and training configuration using the following command:

```bash
0g-compute-cli fine-tuning model-usage --provider <PROVIDER_ADDRESS>  --model <MODEL_NAME>   --output <PATH_TO_SAVE_MODEL_USAGE>
```

### Prepare Your Data

Your dataset must be in **JSONL format** with a **`.jsonl` file extension**. Each line is a JSON object representing one training example.

#### Supported Dataset Formats

**Format 1: Instruction-Input-Output**
```json
{"instruction": "Translate to French", "input": "Hello world", "output": "Bonjour le monde"}
{"instruction": "Translate to French", "input": "Good morning", "output": "Bonjour"}
{"instruction": "Summarize the text", "input": "Long article...", "output": "Brief summary"}
```

**Format 2: Chat Messages**
```json
{"messages": [{"role": "user", "content": "What is 2+2?"}, {"role": "assistant", "content": "2+2 equals 4."}]}
{"messages": [{"role": "user", "content": "Hello"}, {"role": "assistant", "content": "Hi there! How can I help you?"}]}
```

**Format 3: Simple Text (for text completion)**
```json
{"text": "The quick brown fox jumps over the lazy dog."}
{"text": "Machine learning is a subset of artificial intelligence."}
```

#### Dataset Guidelines

- **File format**: Must be a `.jsonl` file (JSONL format)
- **Minimum examples**: At least 10 examples recommended for meaningful fine-tuning
- **Quality**: Ensure examples are accurate and representative of your use case
- **Consistency**: Use the same format throughout the dataset
- **Encoding**: UTF-8 encoding required

### Create Task

Create a fine-tuning task. The fee will be **automatically calculated** by the broker based on the actual token count of your dataset.

**Option A: Using local dataset file (Recommended)**

The CLI will automatically upload the dataset to 0G Storage and create the task in one step:

```bash
0g-compute-cli fine-tuning create-task \
  --provider <PROVIDER_ADDRESS> \
  --model <MODEL_NAME> \
  --dataset-path <PATH_TO_DATASET> \
  --config-path <PATH_TO_CONFIG_FILE>
```

**Option B: Using dataset root hash**

If you prefer to upload the dataset separately first, or need to reuse the same dataset:

1. Upload your dataset to 0G Storage:

```bash
0g-compute-cli fine-tuning upload --data-path <PATH_TO_DATASET>
```

Output:
```bash
Root hash: 0xabc123...
```

2. Create the task using the root hash:

```bash
0g-compute-cli fine-tuning create-task \
  --provider <PROVIDER_ADDRESS> \
  --model <MODEL_NAME> \
  --dataset <DATASET_ROOT_HASH> \
  --config-path <PATH_TO_CONFIG_FILE>
```

**Parameters:**

| Parameter | Description |
|-----------|-------------|
| `--provider` | Address of the service provider |
| `--model` | Name of the pretrained model (without `Qwen/` prefix) |
| `--dataset-path` | Path to local dataset file ‚Äî automatically uploads to 0G Storage (Option A) |
| `--dataset` | Root hash of the dataset on 0G Storage ‚Äî mutually exclusive with `--dataset-path` (Option B) |
| `--config-path` | Path to the training configuration file |
| `--gas-price` | Gas price (optional) |

The output will be like:

```bash
Verify provider...
Provider verified
Creating task (fee will be calculated automatically)...
Fee will be automatically calculated by the broker based on actual token count
Created Task ID: 6b607314-88b0-4fef-91e7-43227a54de57
```

*Note:* When creating a task for the same provider, you must wait for the previous task to be completed (status `Finished`) before creating a new task. If the provider is currently running other tasks, you will be prompted to choose between adding your task to the waiting queue or canceling the request.

### Fee Calculation

The fine-tuning service fee is **automatically calculated** based on your dataset size and training configuration. The fee consists of two components:

#### Formula

```
Total Fee = Training Fee + Storage Reserve Fee
```

Where:
- **Training Fee** = `(tokenSize / 1,000,000) √ó pricePerMillionTokens √ó trainEpochs`
- **Storage Reserve Fee** = Fixed amount based on model size

#### Components Explained

| Component | Description |
|-----------|-------------|
| `tokenSize` | Total number of tokens in your dataset (automatically counted) |
| `pricePerMillionTokens` | Price per million tokens (model-specific, see [Predefined Models](#predefined-models)) |
| `trainEpochs` | Number of training epochs (from your config) |
| `Storage Reserve Fee` | Fixed fee to reserve storage for the fine-tuned model:‚Ä¢ Qwen3-32B (~900 MB LoRA): 0.09 0G‚Ä¢ Qwen2.5-0.5B-Instruct (~100 MB LoRA): 0.01 0G |

#### Example

For a dataset with 10,000 tokens, trained for 3 epochs on Qwen2.5-0.5B-Instruct:
- Price per million tokens = 0.5 0G (see [Predefined Models](#predefined-models))
- Training Fee = (10,000 / 1,000,000) √ó 0.5 √ó 3 = 0.015 0G
- Storage Reserve Fee = 0.01 0G (for Qwen2.5-0.5B-Instruct)
- **Total Fee = 0.025 0G**

:::tip
The actual fee is calculated during the setup phase after your dataset is analyzed. You can view the final fee using the [`get-task`](#monitor-progress) command before training begins.
:::

### Monitor Progress
You can monitor the progress of your task by running the following command:

```bash
0g-compute-cli fine-tuning get-task --provider <PROVIDER_ADDRESS> --task <TASK_ID>
```

The output will be like:

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Field                             ‚îÇ Value                                                                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ID                                ‚îÇ beb6f0d8-4660-4c62-988d-00246ce913d2                                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Created At                        ‚îÇ 2025-03-11T01:20:07.644Z                                                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Pre-trained Model Hash            ‚îÇ 0xcb42b5ca9e998c82dd239ef2d20d22a4ae16b3dc0ce0a855c93b52c7c2bab6dc                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Dataset Hash                      ‚îÇ 0xaae9b4e031e06f84b20f10ec629f36c57719ea512992a6b7e2baea93f447a5fa                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Training Params                   ‚îÇ {......}                                                                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Fee (neuron)                      ‚îÇ 82                                                                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Progress                          ‚îÇ Delivered                                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Field Descriptions:**
- **ID**: Unique identifier for your fine-tuning task
- **Pre-trained Model Hash**: Hash identifier for the base model being fine-tuned
- **Dataset Hash**: Hash identifier for your training dataset (0G Storage root hash)
- **Training Params**: Configuration parameters used during fine-tuning
- **Fee (neuron)**: Total cost for the fine-tuning task (automatically calculated based on token count)
- **Progress**: Task status. Possible values are:
  - `Init`: Task submitted
  - `SettingUp`: Provider is preparing the environment (downloading dataset, etc.)
  - `SetUp`: Provider is ready to start training
  - `Training`: Provider is training the model
  - `Trained`: Provider has finished training
  - `Delivering`: Provider is encrypting and uploading the model to 0G Storage
  - `Delivered`: Fine-tuning result is ready for download
  - `UserAcknowledged`: User has downloaded and confirmed the result
  - `Finished`: Provider has settled fees and shared decryption key ‚Äî task is completed
  - `Failed`: Task failed

### View Task Logs

You can view the logs of your task by running the following command:

```bash
0g-compute-cli fine-tuning get-log --provider <PROVIDER_ADDRESS> --task <TASK_ID>
```

The output will be like:

```bash
creating task....
Step: 0, Logs: {'loss': ..., 'accuracy': ...}
...
Training model for task beb6f0d8-4660-4c62-988d-00246ce913d2 completed successfully
```

### Download and Acknowledge Model

Use the [Check Task](#monitor-progress) command to view task status. When the status changes to `Delivered`, the provider has completed fine-tuning and the encrypted model is ready. Download and acknowledge the model:

```bash
0g-compute-cli fine-tuning acknowledge-model \
  --provider <PROVIDER_ADDRESS> \
  --task-id <TASK_ID> \
  --data-path <PATH_TO_SAVE_MODEL_FILE>
```

The CLI will automatically download the encrypted model from 0G Storage. If 0G Storage download fails, it will fall back to downloading directly from the provider's TEE.

:::danger 48-Hour Deadline
**You must download and acknowledge the model within 48 hours after the task status changes to `Delivered`.**

If you fail to acknowledge within 48 hours:
- The provider will **force settlement** automatically
- You will **lose access to the fine-tuned model**
- **30% of the total task fee** will be deducted as compensation for the provider's compute resources

**Action required:** Monitor your task status and download promptly when it reaches `Delivered`.
:::

:::caution File Path Required
`--data-path` **must be a file path**, not a directory.

**Example:**
```bash
0g-compute-cli fine-tuning acknowledge-model \
  --provider <PROVIDER_ADDRESS> \
  --task-id 0e91ef3d-ac0d-422e-a38c-9d42a28c4412 \
  --data-path /workspace/output/encrypted_model.bin
```
:::

:::tip Data Integrity Verification
The `acknowledge-model` command performs automatic data integrity verification to ensure the downloaded model matches the root hash that the provider submitted to the blockchain contract. This guarantees you receive the authentic model without corruption or tampering.
:::

**Note:** The model file downloaded with the above command is encrypted, and additional steps are required for decryption.

### Decrypt Model

After acknowledging the model, the provider automatically settles the fees and uploads the decryption key to the contract (encrypted with your public key). Use the `get-task` command to check the task status. **When the status changes to `Finished`**, you can decrypt the model:

```bash
0g-compute-cli fine-tuning decrypt-model \
  --provider <PROVIDER_ADDRESS> \
  --task-id <TASK_ID> \
  --encrypted-model <PATH_TO_ENCRYPTED_MODEL_FILE> \
  --output <PATH_TO_SAVE_DECRYPTED_MODEL>
```

**Example:**
```bash
# Use the same file path you specified in acknowledge-model
0g-compute-cli fine-tuning decrypt-model \
  --provider <PROVIDER_ADDRESS> \
  --task-id 0e91ef3d-ac0d-422e-a38c-9d42a28c4412 \
  --encrypted-model /workspace/output/encrypted_model.bin \
  --output /workspace/output/model_output.zip
```

The above command performs the following operations:

- Gets the encrypted key from the contract uploaded by the provider
- Decrypts the key using the user's private key
- Decrypts the model with the decrypted key

:::caution Wait for Settlement
After `acknowledge-model`, the provider needs about **1 minute** to settle fees and upload the decryption key. If you decrypt too early (status is still `UserAcknowledged` instead of `Finished`), you may see an error like `second arg must be public key`. Simply wait and retry.
:::

**Note:** The decrypted result will be saved as a zip file. Ensure that the `<PATH_TO_SAVE_DECRYPTED_MODEL>` ends with .zip (e.g., model_output.zip). After downloading, unzip the file to access the decrypted model.

### Extract LoRA Adapter

After decryption, unzip the model to access the LoRA adapter files:

```bash
unzip model_output.zip -d ./lora_adapter/
```

The extracted folder will contain:

```
lora_adapter/
‚îú‚îÄ‚îÄ output_model/
‚îÇ   ‚îú‚îÄ‚îÄ adapter_config.json       # LoRA configuration
‚îÇ   ‚îú‚îÄ‚îÄ adapter_model.safetensors # LoRA weights
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json            # Tokenizer
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ   ‚îî‚îÄ‚îÄ README.md
```

## Using the Fine-tuned Model

After fine-tuning, you receive a **LoRA adapter** (Low-Rank Adaptation), not a full model. To use it, you need to:

1. Download the base model
2. Load the LoRA adapter on top of the base model
3. Run inference

### Step 1: Download Base Model

Download the same base model that was used for fine-tuning from HuggingFace:

```bash
# Install huggingface-cli if not already installed
pip install huggingface_hub

# For Qwen2.5-0.5B-Instruct
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir ./base_model

# For Qwen3-32B (requires ~65GB disk space)
# huggingface-cli download Qwen/Qwen3-32B --local-dir ./base_model
```

### Step 2: Load LoRA with Base Model

Use the following Python code to combine the LoRA adapter with the base model.

**For Qwen2.5-0.5B-Instruct:**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Paths
base_model_path = "./base_model"  # or "Qwen/Qwen2.5-0.5B-Instruct"
lora_adapter_path = "./lora_adapter/output_model"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(lora_adapter_path)

# Load base model
base_model = AutoModelForCausalLM.from_pretrained(
    base_model_path,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# Load LoRA adapter
model = PeftModel.from_pretrained(base_model, lora_adapter_path)

print("Model loaded successfully!")
```

**For Qwen3-32B (requires 40GB+ VRAM):**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Paths
base_model_path = "./base_model"  # or "Qwen/Qwen3-32B"
lora_adapter_path = "./lora_adapter/output_model"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(lora_adapter_path)

# Load base model with optimizations for large models
base_model = AutoModelForCausalLM.from_pretrained(
    base_model_path,
    torch_dtype=torch.float16,      # Use fp16 to reduce memory
    device_map="auto",               # Automatically distribute across GPUs
    low_cpu_mem_usage=True,          # Reduce CPU memory usage during loading
    trust_remote_code=True           # Required for some Qwen models
)

# Load LoRA adapter
model = PeftModel.from_pretrained(base_model, lora_adapter_path)

print("Model loaded successfully!")
```

:::tip Memory Optimization for Large Models
If you encounter out-of-memory errors with Qwen3-32B, you can use quantization:

```python
# 8-bit quantization (requires bitsandbytes)
from transformers import BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_8bit=True)

base_model = AutoModelForCausalLM.from_pretrained(
    base_model_path,
    quantization_config=quantization_config,
    device_map="auto",
    trust_remote_code=True
)
```
:::

### Step 3: Run Inference

```python
def generate_response(prompt, max_new_tokens=100):
    messages = [{"role": "user", "content": prompt}]
    
    # Apply chat template
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    # Tokenize
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    # Generate
    outputs = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.7,
        top_p=0.9
    )
    
    # Decode
    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
    return response

# Example usage
response = generate_response("Hello, how are you?")
print(response)
```

### Optional: Merge and Save Full Model

If you want to create a standalone model without needing to load the adapter separately:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Load base model and LoRA
base_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-0.5B-Instruct",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
model = PeftModel.from_pretrained(base_model, "./lora_adapter/output_model")

# Merge LoRA weights into base model
merged_model = model.merge_and_unload()

# Save the merged model
merged_model.save_pretrained("./merged_model")
tokenizer = AutoTokenizer.from_pretrained("./lora_adapter/output_model")
tokenizer.save_pretrained("./merged_model")

print("Merged model saved to ./merged_model")
```

### Requirements

Install the required Python packages:

#### For GPU Environments (Recommended)

If you have an NVIDIA GPU, install PyTorch with CUDA support. **Important:** Match the CUDA version to your environment.

```bash
# For CUDA 12.1 (check your CUDA version with: nvidia-smi)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# For CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other ML libraries
pip install transformers peft accelerate
```

#### For CPU-Only Environments

```bash
pip install torch transformers peft accelerate
```

#### Package Requirements

| Package | Minimum Version | Purpose |
|---------|-----------------|---------|
| `torch` | >= 2.0 | Deep learning framework |
| `transformers` | >= 4.40.0 | Model loading and inference |
| `peft` | >= 0.10.0 | LoRA adapter support |
| `accelerate` | >= 0.27.0 | Device management |

:::tip Verify GPU Support
After installation, verify that PyTorch can detect your GPU:
```bash
python3 -c "import torch; print('PyTorch version:', torch.__version__); print('CUDA available:', torch.cuda.is_available())"
```
If `CUDA available: False`, you may need to reinstall PyTorch with the correct CUDA version.
:::

### Account Management

For comprehensive account management, including viewing balances, managing sub-accounts, and handling refunds, see [Account Management](./account-management).

Quick CLI commands:
```bash
# Check balance
0g-compute-cli get-account

# View sub-account for a provider
0g-compute-cli get-sub-account --provider <PROVIDER_ADDRESS>

# Request refund from sub-accounts
0g-compute-cli retrieve-fund
```

### Other Commands

#### Upload Dataset Separately

You can upload a dataset to 0G Storage before creating a task:

```bash
0g-compute-cli fine-tuning upload --data-path <PATH_TO_DATASET>
```

#### Download Data

You can download previously uploaded datasets from 0G Storage:

```bash
0g-compute-cli fine-tuning download --data-path <PATH_TO_SAVE_DATASET> --data-root <DATASET_ROOT_HASH>
```

#### View Task List

You can view the list of tasks submitted to a specific provider using the following command:

```bash
0g-compute-cli fine-tuning list-tasks  --provider <PROVIDER_ADDRESS>
```

#### Cancel a Task

You can cancel a task before it starts running using the following command:

```bash
0g-compute-cli fine-tuning cancel-task --provider <PROVIDER_ADDRESS> --task <TASK_ID>
```

**Note:** Tasks that are already in progress or completed cannot be canceled.

## Troubleshooting

<details>
<summary>Error: MinimumDepositRequired</summary>

This means the provider's fine-tuning sub-account has insufficient funds. Make sure to include `--service fine-tuning` when transferring funds:

```bash
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 2 --service fine-tuning
```

</details>

<details>
<summary>Error: Provider busy</summary>

The provider is processing another task. Options:
1. Wait and retry later
2. Use a different provider: `0g-compute-cli fine-tuning list-providers`
3. Queue your task (you'll be prompted)
</details>

<details>
<summary>Error: Insufficient balance</summary>

Add more funds:
```bash
0g-compute-cli deposit --amount 3
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 2 --service fine-tuning
```
</details>

<details>
<summary>Error: "second arg must be public key" when decrypting</summary>

This means the provider hasn't finished settlement yet. Wait about 1 minute after `acknowledge-model`, then check the task status:

```bash
0g-compute-cli fine-tuning get-task --provider <PROVIDER_ADDRESS> --task <TASK_ID>
```

When `Progress` shows `Finished`, retry the `decrypt-model` command.
</details>

<details>
<summary>Error: "Unexpected non-whitespace character after JSON" when creating task</summary>

Check your training configuration JSON file:
- Ensure valid JSON format
- Use decimal notation for numbers (e.g., `0.0002` instead of `2e-4`)
- Verify no trailing commas
</details>

---

## Inference Provider

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Become an Inference Provider

Transform your AI services into verifiable, revenue-generating endpoints on the 0G Compute Network. This guide covers setting up your service and connecting it through the provider broker.

## Why Become a Provider?

- **Monetize Your Infrastructure**: Turn idle GPU resources into revenue
- **Automated Settlements**: The broker handles billing and payments automatically
- **Trust Through Verification**: Offer verifiable services for premium rates

## Prerequisites
- Docker Compose 1.27+
- OpenAI-compatible model service
- Wallet with 0G tokens for gas fees

## Setup Process

### Prepare Your Model Service

#### Service Interface Requirements
Your AI service must implement the [OpenAI API Interface](https://platform.openai.com/docs/api-reference/chat) for compatibility. This ensures consistent user experience across all providers.

#### Verification Interfaces
To ensure the integrity and trustworthiness of services, different verification mechanisms are employed. Each mechanism comes with its own specific set of protocols and requirements to ensure service verification and security.

<Tabs>
<TabItem value="teeml" label="TEE Verification (TeeML)" default>
TEE (Trusted Execution Environment) verification ensures your computations are tamper-proof. Services running in TEE:
- Generate signing keys within the secure environment
- Provide CPU and GPU attestations
- Sign all inference results

These attestations should include the public key of the signing key, verifying its creation within the TEE. All inference results must be signed with this signing key.

### Hardware Requirements

- **CPU**: Intel TDX (Trusted Domain Extensions) enabled
- **GPU**: NVIDIA H100 or H200 with TEE support

### TEE Node Setup

There are two ways to start a TEE node for your inference service:

#### Method 1: Using Dstack

Follow the [Dstack Getting Started Guide](https://github.com/Dstack-TEE/dstack?tab=readme-ov-file#-getting-started) to prepare your TEE node using Dstack.

#### Method 2: Using Cryptopilot

Follow the [0G-TAPP README](https://github.com/0gfoundation/0g-tapp/blob/main/README.md) to set up your TEE node using Cryptopilot.

### Download and Configure Inference Broker

To register and manage TEE services, handle user request proxies, and perform settlements, you need to use the Inference Broker.

Please visit the [releases page](https://github.com/0gfoundation/0g-serving-broker/releases) to download and extract the latest version of the installation package. After extracting, use the executable `config` file to generate the configuration file and docker-compose.yml file according to your setup.

```bash
# Download from releases page
tar -xzf inference-broker.tar.gz
cd inference-broker

# Generate configuration files
./config
```

</TabItem>
<TabItem value="future" label="OPML, ZKML (Coming Soon)">
Support for additional verification methods including:
- **OPML**: Optimistic Machine Learning proofs
- **ZKML**: Zero-knowledge ML verification

Stay tuned for updates.
</TabItem>
</Tabs>

### Launch Provider Broker

Follow the instructions in [Dstack](https://github.com/Dstack-TEE/dstack?tab=readme-ov-file#-getting-started) or [0G-TAPP](https://github.com/0gfoundation/0g-tapp/blob/main/README.md) documentation to start the service using the config file and docker-compose.yml file generated in the previous step.

The broker will:
- Register your service on the network
- Handle user authentication and request routing
- Manage automatic settlement of payments

## Troubleshooting

<details>
<summary>Broker fails to start</summary>

- Verify Docker Compose is installed correctly
- Check port availability
- Ensure config.local.yaml syntax is valid
- Review logs: `docker compose logs`
</details>

<details>
<summary>Service not accessible</summary>

- Confirm firewall allows incoming connections
- Verify public IP/domain is correct
- Test local service: `curl http://localhost:8000/chat/completions`
</details>

<details>
<summary>Settlement issues</summary>

The automatic settlement engine handles payments. If issues occur:
- Check wallet has sufficient gas
- Verify network connectivity
- Monitor settlement logs in broker output
</details>

## Next Steps
- **Join Community** ‚Üí [Discord](https://discord.gg/0glabs) for support
- **Explore Inference** ‚Üí [Inference Documentation](./inference) for integration details

---

## Inference

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 0G Compute Inference

0G Compute Network provides decentralized AI inference services, supporting various AI models including Large Language Models (LLM), text-to-image generation, and speech-to-text processing.

## Prerequisites

- Node.js >= 22.0.0
- A wallet with 0G tokens (either testnet or mainnet)
- EVM compatible wallet (for Web UI)

## Supported Service Types

- **Chatbot Services**: Conversational AI with models like GPT, DeepSeek, and others
- **Text-to-Image**: Generate images from text descriptions using Stable Diffusion and similar models
- **Speech-to-Text**: Transcribe audio to text using Whisper and other speech recognition models

## Available Services

:::info Testnet Services

<details>
<summary>View Testnet Services (2 Available)</summary>

| # | Model | Type | Provider | Input (per 1M tokens) | Output (per 1M tokens) |
|---|-------|------|----------|----------------------|------------------------|
| 1 | `qwen-2.5-7b-instruct` | Chatbot | `0xa48f01...` | 0.05 0G | 0.10 0G |
| 2 | `qwen-image-edit-2511` | Image-Edit | `0x4b2a9...` | - | 0.005 0G/image |

**Available Models by Type:**

**Chatbots (1 model):**
- **Qwen 2.5 7B Instruct**: Fast and efficient conversational model

**Image-Edit (1 model):**
- **Qwen Image Edit 2511**: Advanced image editing and manipulation model

All testnet services feature TeeML verifiability and are ideal for development and testing.

</details>

:::

:::tip Mainnet Services

<details>
<summary>View Mainnet Services (6 Available)</summary>

| # | Model | Type | Provider | Input (per 1M tokens) | Output (per 1M tokens) |
|---|-------|------|----------|----------------------|------------------------|
| 1 | `GLM-5-FP8` | Chatbot | `0xd9966e...` | 1 0G | 3.2 0G |
| 2 | `deepseek-chat-v3-0324` | Chatbot | `0x1B3AAe...` | 0.30 0G | 1.00 0G |
| 3 | `gpt-oss-120b` | Chatbot | `0xBB3f5b...` | 0.10 0G | 0.49 0G |
| 4 | `qwen3-vl-30b-a3b-instruct` | Chatbot | `0x4415ef...` | 0.49 0G | 0.49 0G |
| 5 | `whisper-large-v3` | Speech-to-Text | `0x36aCff...` | 0.05 0G | 0.11 0G |
| 6 | `z-image` | Text-to-Image | `0xE29a72...` | - | 0.003 0G/image |

**Available Models by Type:**

**Chatbots (4 models):**
- **GLM-5-FP8**: High-performance reasoning model (FP8 quantized)
- **GPT-OSS-120B**: Large-scale open-source GPT model
- **Qwen3 VL 30B A3B Instruct**: Vision-language multimodal model
- **DeepSeek Chat V3**: Optimized conversational model

**Speech-to-Text (1 model):**
- **Whisper Large V3**: OpenAI's state-of-the-art transcription model

**Text-to-Image (1 model):**
- **Z-Image**: Fast high-quality image generation

All mainnet services feature TeeML verifiability for trusted execution in production environments.

</details>

:::

## Choose Your Interface

| Feature | Web UI | CLI | SDK |
|---------|--------|-----|-----|
| Setup time | ~1 min | ~2 min | ~5 min |
| Interactive chat | ‚úÖ | ‚ùå | ‚ùå |
| Automation | ‚ùå | ‚úÖ | ‚úÖ |
| App integration | ‚ùå | ‚ùå | ‚úÖ |
| Direct API access | ‚ùå | ‚ùå | ‚úÖ |

<Tabs>
<TabItem value="web-ui" label="Web UI" default>

**Best for:** Quick testing, experimentation and direct frontend integration.

### Option 1: Use the Hosted Web UI

Visit the official 0G Compute Marketplace directly ‚Äî no installation required:

**[https://compute-marketplace.0g.ai/inference](https://compute-marketplace.0g.ai/inference)**

### Option 2: Run Locally

#### Installation

```bash
pnpm add @0glabs/0g-serving-broker -g
```

#### Launch Web UI

```bash
0g-compute-cli ui start-web
```

Open `http://localhost:3090` in your browser.

### Getting Started

#### 1. Connect & Fund

1. **Connect your wallet** (MetaMask recommended)
2. **Deposit some 0G tokens** using the account dashboard
3. **Browse available AI models** and their pricing

#### 2. Start Using AI Services

**Option A: Chat Interface**
- Click "Chat" on any chatbot provider
- Start conversations immediately
- Perfect for testing and experimentation

**Option B: Get API Integration**
- Click "Build" on any provider
- Get step-by-step integration guides
- Copy-paste ready code examples

</TabItem>
<TabItem value="cli" label="CLI">

**Best for:** Automation, scripting, and server environments

### Installation

```bash
pnpm add @0glabs/0g-serving-broker -g
```

### Setup Environment

#### Choose Network

```bash
0g-compute-cli setup-network
```

#### Login with Wallet

Enter your wallet private key when prompted. This will be used for account management and service payments.

```bash
0g-compute-cli login
```

### Create Account & Add Funds

Before using inference services, you need to fund your account. For detailed account management, see [Account Management](./account-management).

```bash
0g-compute-cli deposit --amount 10
0g-compute-cli get-account
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 5
```

### CLI Commands

#### List Providers
```bash
0g-compute-cli inference list-providers
```

#### Verify Provider
Check provider's TEE attestation and reliability before using:
```bash
0g-compute-cli inference verify --provider <PROVIDER_ADDRESS>
```

This command outputs the provider's report and verifies their Trusted Execution Environment (TEE) status.

#### Acknowledge Provider
Before using a provider, acknowledge them on-chain:
```bash
0g-compute-cli inference acknowledge-provider --provider <PROVIDER_ADDRESS>
```

#### Direct API Access
Generate an authentication token for direct API calls:
```bash
0g-compute-cli inference get-secret --provider <PROVIDER_ADDRESS>
```

This generates a Bearer token in the format `app-sk-<SECRET>` that you can use for direct API calls.

### API Usage Examples

<Tabs>
<TabItem value="chatbot" label="Chatbot" default>

Use for conversational AI and text generation.

<Tabs>
<TabItem value="curl-chat" label="cURL" default>

```bash
curl <service_url>/v1/proxy/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer app-sk-<YOUR_SECRET>" \
  -d '{
    "model": <service.model>,
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }`
```

</TabItem>
<TabItem value="js-chat" label="JavaScript">

```javascript
const OpenAI = require('openai');

const client = new OpenAI({
  baseURL: `${service.url}/v1/proxy`,
  apiKey: 'app-sk-<YOUR_SECRET>'
});

const completion = await client.chat.completions.create({
  model: service.model,
  messages: [
    {
      role: 'system',
      content: 'You are a helpful assistant.'
    },
    {
      role: 'user',
      content: 'Hello!'
    }
  ]
});

console.log(completion.choices[0].message);
```

</TabItem>
<TabItem value="python-chat" label="Python">

```python
from openai import OpenAI

client = OpenAI(
    base_url=`${service.url}/v1/proxy`,
    api_key='app-sk-<YOUR_SECRET>'
)

completion = client.chat.completions.create(
    model=service.model,
    messages=[
        {
            'role': 'system',
            'content': 'You are a helpful assistant.'
        },
        {
            'role': 'user',
            'content': 'Hello!'
        }
    ]
)

print(completion.choices[0].message)
```

</TabItem>
</Tabs>

</TabItem>
<TabItem value="text-to-image" label="Text-to-Image">

Generate images from text descriptions.

<Tabs>
<TabItem value="curl-image" label="cURL" default>

```bash
curl <service_url>/v1/proxy/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer app-sk-<YOUR_SECRET>" \
  -d '{
    "model": <service.model>,
    "prompt": "A cute baby sea otter playing in the water",
    "n": 1,
    "size": "1024x1024"
  }'
```

</TabItem>
<TabItem value="js-image" label="JavaScript">

```javascript
const OpenAI = require('openai');

const client = new OpenAI({
  baseURL: `${service.url}/v1/proxy`,
  apiKey: 'app-sk-<YOUR_SECRET>'
});

const response = await client.images.generate({
  model: service.model,
  prompt: 'A cute baby sea otter playing in the water',
  n: 1,
  size: '1024x1024'
});

console.log(response.data);
```

</TabItem>
<TabItem value="python-image" label="Python">

```python
from openai import OpenAI

client = OpenAI(
    base_url=`${service.url}/v1/proxy`,
    api_key='app-sk-<YOUR_SECRET>'
)

response = client.images.generate(
    model=service.model,
    prompt='A cute baby sea otter playing in the water',
    n=1,
    size='1024x1024'
)

print(response.data)
```

</TabItem>
</Tabs>

</TabItem>
<TabItem value="speech-to-text" label="Speech-to-Text">

Transcribe audio files to text.

<Tabs>
<TabItem value="curl-audio" label="cURL" default>

```bash
curl <service_url>/v1/proxy/audio/transcriptions \
  -H "Authorization: Bearer app-sk-<YOUR_SECRET>" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@audio.ogg" \
  -F "model=whisper-large-v3" \
  -F "response_format=json"
```

</TabItem>
<TabItem value="js-audio" label="JavaScript">

```javascript
const OpenAI = require('openai');
const fs = require('fs');

const client = new OpenAI({
  baseURL: `${service.url}/v1/proxy`,
  apiKey: 'app-sk-<YOUR_SECRET>'
});

const transcription = await client.audio.transcriptions.create({
  file: fs.createReadStream('audio.ogg'),
  model: 'whisper-large-v3',
  response_format: 'json'
});

console.log(transcription.text);
```

</TabItem>
<TabItem value="python-audio" label="Python">

```python
from openai import OpenAI

client = OpenAI(
    base_url=`${service.url}/v1/proxy`,
    api_key='app-sk-<YOUR_SECRET>'
)

with open('audio.ogg', 'rb') as audio_file:
    transcription = client.audio.transcriptions.create(
        file=audio_file,
        model='whisper-large-v3',
        response_format='json'
    )

print(transcription.text)
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

### Start Local Proxy Server

Run a local OpenAI-compatible server:
```bash
# Start server on port 3000 (default)
0g-compute-cli inference serve --provider <PROVIDER_ADDRESS>

# Custom port
0g-compute-cli inference serve --provider <PROVIDER_ADDRESS> --port 8080
```

Then use any OpenAI-compatible client to connect to `http://localhost:3000`.

</TabItem>
<TabItem value="sdk" label="SDK">

**Best for:** Application integration and programmatic access

### Installation

```bash
pnpm add @0glabs/0g-serving-broker
```

:::tip Starter Kits Available
Get up and running quickly with our comprehensive TypeScript starter kit within minutes.

- **[TypeScript Starter Kit](https://github.com/0gfoundation/0g-compute-ts-starter-kit)** - Complete examples with TypeScript and CLI tool
:::

### Initialize the Broker

<Tabs>
<TabItem value="nodejs" label="Node.js" default>

```typescript
import { ethers } from "ethers";
import { createZGComputeNetworkBroker } from "@0glabs/0g-serving-broker";

// Choose your network
const RPC_URL = process.env.NODE_ENV === 'production'
  ? "https://evmrpc.0g.ai"  // Mainnet
  : "https://evmrpc-testnet.0g.ai";  // Testnet

const provider = new ethers.JsonRpcProvider(RPC_URL);
const wallet = new ethers.Wallet(process.env.PRIVATE_KEY!, provider);
const broker = await createZGComputeNetworkBroker(wallet);
```

</TabItem>
<TabItem value="browser" label="Browser">

```typescript
import { BrowserProvider } from "ethers";
import { createZGComputeNetworkBroker } from "@0glabs/0g-serving-broker";

// Check if MetaMask is installed
if (typeof window.ethereum === "undefined") {
  throw new Error("Please install MetaMask");
}

const provider = new BrowserProvider(window.ethereum);
const signer = await provider.getSigner();
const broker = await createZGComputeNetworkBroker(signer);
```

:::caution Browser Compatibility
`@0glabs/0g-serving-broker` requires polyfills for Node.js built-in modules.

**Vite example:**
```bash
pnpm add -D vite-plugin-node-polyfills
```

```javascript
// vite.config.js
import { nodePolyfills } from 'vite-plugin-node-polyfills';

export default {
  plugins: [
    nodePolyfills({
      include: ['crypto', 'stream', 'util', 'buffer', 'process'],
      globals: { Buffer: true, global: true, process: true }
    })
  ]
};
```
:::

</TabItem>
</Tabs>

### Discover Services

```typescript
// List all available services
const services = await broker.inference.listService();

// Filter by service type
const chatbotServices = services.filter(s => s.serviceType === 'chatbot');
const imageServices = services.filter(s => s.serviceType === 'text-to-image');
const speechServices = services.filter(s => s.serviceType === 'speech-to-text');
```

### Account Management

For detailed account operations, see [Account Management](./account-management).

```typescript
const account = await broker.ledger.getLedger();
await broker.ledger.depositFund(10);
// Required before first use of a provider
await broker.inference.acknowledgeProviderSigner(providerAddress);
```

### Make Inference Requests

<Tabs>
<TabItem value="chatbot-sdk" label="Chatbot" default>

```typescript
const messages = [{ role: "user", content: "Hello!" }];

// Get service metadata
const { endpoint, model } = await broker.inference.getServiceMetadata(providerAddress);

// Generate auth headers
const headers = await broker.inference.getRequestHeaders(
  providerAddress
);

// Make request
const response = await fetch(`${endpoint}/chat/completions`, {
  method: "POST",
  headers: { "Content-Type": "application/json", ...headers },
  body: JSON.stringify({ messages, model })
});

const data = await response.json();
const answer = data.choices[0].message.content;
```

</TabItem>
<TabItem value="text-to-image-sdk" label="Text-to-Image">

```typescript
const prompt = "A cute baby sea otter";

const body = JSON.stringify({
    model,
    prompt,
    n: 1,
    size: "1024x1024"
  });

// Get service metadata
const { endpoint, model } = await broker.inference.getServiceMetadata(providerAddress);

// Generate auth headers
const headers = await broker.inference.getRequestHeaders(
  providerAddress,
  body
);

// Make request
const response = await fetch(`${endpoint}/images/generations`, {
  method: "POST",
  headers: { "Content-Type": "application/json", ...headers },
  body: JSON.stringify({
    model,
    prompt,
    n: 1,
    size: "1024x1024"
  })
});

const data = await response.json();
const imageUrl = data.data[0].url;
```

</TabItem>
<TabItem value="speech-to-text-sdk" label="Speech-to-Text">

```typescript
const formData = new FormData();
formData.append('file', audioFile); // audioFile is a File or Blob
formData.append('model', model);
formData.append('response_format', 'json');

// Get service metadata
const { endpoint, model } = await broker.inference.getServiceMetadata(providerAddress);

// Generate auth headers
const headers = await broker.inference.getRequestHeaders(
  providerAddress
);

// Make request
const response = await fetch(`${endpoint}/audio/transcriptions`, {
  method: "POST",
  headers: { ...headers },
  body: formData
});

const data = await response.json();
const transcription = data.text;
```

</TabItem>
</Tabs>

### Response Verification

The `processResponse` method handles response verification and automatic fee management. Both parameters are optional:

- **`receivedContent`**: The usage data from the service response. When provided, the SDK caches accumulated usage and automatically transfers funds from your main account to the provider's sub-account to prevent service interruptions.
- **`chatID`**: Response identifier for verifiable TEE services. Different service types handle this differently.

<Tabs>
<TabItem value="chatbot-verify" label="Chatbot" default>

For chatbot services, pass the usage data from the response to enable automatic fee management:

```typescript
// Standard chat completion
const response = await fetch(`${endpoint}/chat/completions`, {
  method: "POST",
  headers: { "Content-Type": "application/json", ...headers },
  body: JSON.stringify({ messages, model })
});

const data = await response.json();

// Process response for automatic fee management
if (data.usage) {
  await broker.inference.processResponse(
    providerAddress,
    undefined,              // chatID is undefined for non-verifiable responses
    JSON.stringify(data.usage)  // Pass usage data for fee calculation
  );
}

// For verifiable TEE services with chatID
// Check response headers first
let chatID = response.headers.get("ZG-Res-Key") || response.headers.get("zg-res-key");

// If not found in response headers, check response body
if (!chatID) {
  chatID = data.id || data.chatID;
}

if (chatID) {
  const isValid = await broker.inference.processResponse(
    providerAddress,
    chatID,           // Verify the response integrity
    JSON.stringify(data.usage)  // Also manage fees
  );
}
```

</TabItem>
<TabItem value="text-to-image-verify" label="Text-to-Image">

For text-to-image services, pass the original request data for input-based fee calculation:

```typescript
const requestBody = {
  model,
  prompt: "A cute baby sea otter",
  size: "1024x1024",
  n: 1
};

const response = await fetch(`${endpoint}/images/generations`, {
  method: "POST",
  headers: { "Content-Type": "application/json", ...headers },
  body: JSON.stringify(requestBody)
});

const data = await response.json();

// Get chatID from response headers for verification
const chatID = response.headers.get("ZG-Res-Key") || response.headers.get("zg-res-key");

if (chatID) {
  // Process response with chatID for verification and fee calculation
  const isValid = await broker.inference.processResponse(
    providerAddress,
    chatID                        // Verify the response integrity
  );
  console.log("Response valid:", isValid);
} else {
  // Fallback: process without verification if no chatID
  await broker.inference.processResponse(
    providerAddress,
    undefined                     // No chatID available
  );
}
```

</TabItem>
<TabItem value="speech-to-text-verify" label="Speech-to-Text">

For speech-to-text services, pass the usage data if available:

```typescript
const formData = new FormData();
formData.append('file', audioFile);
formData.append('model', model);

const response = await fetch(`${endpoint}/audio/transcriptions`, {
  method: "POST",
  headers: { ...headers },
  body: formData
});

const data = await response.json();

// Get chatID from response headers for verification
const chatID = response.headers.get("ZG-Res-Key") || response.headers.get("zg-res-key");

if (chatID) {
  // Process response with chatID for verification and fee calculation
  const isValid = await broker.inference.processResponse(
    providerAddress,
    chatID,                      // Verify the response integrity
    JSON.stringify(data.usage || {}) // Pass usage for fee calculation
  );
  console.log("Response valid:", isValid);
} else if (data.usage) {
  // Fallback: process without verification if no chatID but usage available
  await broker.inference.processResponse(
    providerAddress,
    undefined,                   // No chatID available
    JSON.stringify(data.usage)   // Pass usage for fee calculation
  );
}
```

</TabItem>
<TabItem value="streaming-verify" label="Streaming Responses">

For streaming responses, handle chatID differently based on service type:

<Tabs>
<TabItem value="chatbot-stream" label="Chatbot Streaming" default>

```typescript
// For chatbot streaming, first check headers then try to get ID from stream
let chatID = response.headers.get("ZG-Res-Key") || response.headers.get("zg-res-key");

let usage = null;
let streamChatID = null; // Will try to get from stream data
const decoder = new TextDecoder();
const reader = response.body.getReader();

// Process stream
let rawBody = '';
while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  rawBody += decoder.decode(value, { stream: true });
}

// Parse usage and chatID from stream data
for (const line of rawBody.split('\n')) {
  const trimmed = line.trim();
  if (!trimmed || trimmed === 'data: [DONE]') continue;

  try {
    const jsonStr = trimmed.startsWith('data:')
      ? trimmed.slice(5).trim()
      : trimmed;
    const message = JSON.parse(jsonStr);

    // For chatbot, try to get ID from stream data
    if (!streamChatID && (message.id || message.chatID)) {
      streamChatID = message.id || message.chatID;
    }

    if (message.usage) {
      usage = message.usage;
    }
  } catch {}
}

// Use chatID from header if available, otherwise use chatID from stream data
const finalChatID = chatID || streamChatID;

// Process with chatID for verification if available
if (finalChatID) {
  const isValid = await broker.inference.processResponse(
    providerAddress,
    finalChatID,
    JSON.stringify(usage || {})
  );
  console.log("Chatbot streaming response valid:", isValid);
} else if (usage) {
  // Fallback: process without verification
  await broker.inference.processResponse(
    providerAddress,
    undefined,
    JSON.stringify(usage)
  );
}
```

</TabItem>
<TabItem value="audio-stream" label="Speech-to-Text Streaming">

```typescript
// For speech-to-text streaming, get chatID from headers
const chatID = response.headers.get("ZG-Res-Key") || response.headers.get("zg-res-key");

let usage = null;
const decoder = new TextDecoder();
const reader = response.body.getReader();

// Process stream
let rawBody = '';
while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  rawBody += decoder.decode(value, { stream: true });
}

// Parse usage from stream data
for (const line of rawBody.split('\n')) {
  const trimmed = line.trim();
  if (!trimmed || trimmed === 'data: [DONE]') continue;

  try {
    const jsonStr = trimmed.startsWith('data:')
      ? trimmed.slice(5).trim()
      : trimmed;
    const message = JSON.parse(jsonStr);
    if (message.usage) {
      usage = message.usage;
    }
  } catch {}
}

// Process with chatID for verification if available
if (chatID) {
  const isValid = await broker.inference.processResponse(
    providerAddress,
    chatID,
    JSON.stringify(usage || {})
  );
  console.log("Audio streaming response valid:", isValid);
} else if (usage) {
  // Fallback: process without verification
  await broker.inference.processResponse(
    providerAddress,
    undefined,
    JSON.stringify(usage)
  );
}
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

**Key Points:**
- Always call `processResponse` after receiving responses to maintain proper fee management
- The SDK automatically handles fund transfers to prevent service interruptions
- For verifiable TEE services, the method also validates response integrity
- **chatID retrieval principle**: Always prioritize `ZG-Res-Key` from response headers. Only use fallback methods when header is not present.
- **chatID retrieval varies by service type:**
  - **Chatbot**: First try `ZG-Res-Key` header, then check `data.id` (completion ID from response body) as fallback
  - **Text-to-Image & Speech-to-Text**: Always get chatID from `ZG-Res-Key` response header
  - **Streaming responses**:
    - **Chatbot streaming**: Check headers first, then try to get `id` from stream data as fallback
    - **Speech-to-text streaming**: Get chatID from `ZG-Res-Key` header immediately
- Usage data format varies by service type but typically includes token counts or request metrics

</TabItem>
</Tabs>

---

## Troubleshooting

### Common Issues

<details>
<summary>Error: Insufficient balance</summary>

Your account doesn't have enough funds. Add more using CLI or SDK:

CLI:

#### Deposit to Main Account
```bash
0g-compute-cli deposit --amount 5
```

#### Transfer to Provider Sub-Account
```bash
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 5
```

SDK:
```typescript
await broker.ledger.depositFund(1);
```
</details>

<details>
<summary>Error: Provider not acknowledged</summary>

You need to acknowledge the provider before using their service:

CLI:
```bash
0g-compute-cli inference acknowledge-provider --provider <PROVIDER_ADDRESS>
```

SDK:
```typescript
await broker.inference.acknowledgeProviderSigner(providerAddress);
```
</details>

<details>
<summary>Error: No funds in provider sub-account</summary>

Transfer funds to the specific provider sub-account:
```bash
0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 5
```

Check your account balance:
```bash
0g-compute-cli get-account
```
</details>

<details>
<summary>Web UI not starting</summary>

If the web UI fails to start:

1. Check if another service is using port 3090:
```bash
0g-compute-cli ui start-web --port 3091
```

2. Ensure the package was installed globally:
```bash
pnpm add @0glabs/0g-serving-broker -g
```
</details>

## Next Steps

- **Manage Accounts** ‚Üí [Account Management Guide](./account-management)
- **Fine-tune Models** ‚Üí [Fine-tuning Guide](./fine-tuning)
- **Become a Provider** ‚Üí [Provider Setup](./inference-provider)
- **View Examples** ‚Üí [GitHub](https://github.com/0glabs/0g-compute-ts-starter-kit)

---

*Questions? Join our [Discord](https://discord.gg/0glabs) for support.*

---

## Marketplace (coming soon)

Coming soon

---

## Overview

# 0G Compute Network

Access affordable GPU computing power for AI workloads through a decentralized marketplace.

## AI Computing Costs Are Crushing Innovation

Running AI models today means choosing between:
- **Cloud Providers**: $5,000-50,000/month for dedicated GPUs
- **API Services**: $0.03+ per request, adding up to thousands monthly
- **Building Infrastructure**: Millions in hardware investment

**Result**: Only well-funded companies can afford AI at scale.

## Decentralized GPU Marketplace

0G Compute Network connects idle GPU owners with AI developers, creating a marketplace that's:
- **90% Cheaper**: Pay only for compute used, no monthly minimums
- **Instantly Available**: Access 1000s of GPUs globally
- **Verifiable**: Cryptographic proofs ensure computation integrity

Think of it as "Uber for GPUs" - matching supply with demand efficiently.

## Architecture Overview

![0G Compute Network Architecture](./architecture.png)

The network consists of:
1. **Smart Contracts**: Handle payments and verification
2. **Provider Network**: GPU owners running compute services
3. **Client SDKs**: Easy integration for developers
4. **Verification Layer**: Ensures computation integrity

## Key Components

### ü§ñ Supported Services

| Service Type | What It Does | Status |
|--------------|--------------|--------|
| **Inference** | Run pre-trained models (LLMs) | ‚úÖ Live |
| **Fine-tuning** | Fine-tune models with your data | ‚úÖ Live |
| **Training** | Train models from scratch | üîú Coming |

### üîê Trust & Verification

**Verifiable Computation**: Proof that work was done correctly
- TEE (Trusted Execution Environment) for secure processing
- Cryptographic signatures on all results
- Can't fake or manipulate outputs

<details>
<summary>What makes it trustworthy?</summary>

**Smart Contract Escrow**: Funds held until service delivered
- Like eBay's payment protection
- Automatic settlement on completion
- No payment disputes
</details>

## Quick Start Paths

### üë®‚Äçüíª "I want to use AI services"
Build AI-powered applications without infrastructure:
1. [Install SDK](./inference#sdk) - 5 minute setup
2. [Fund your account](./account-management) - Pre-pay for usage
3. [Send requests](./inference#direct-api-access) - **OpenAI SDK compatible**

### üñ•Ô∏è "I have GPUs to monetize"
Turn idle hardware into revenue:
1. Check [hardware requirements](./inference-provider#prerequisites)
2. [Set up provider software](./inference-provider#launch-provider-broker)

### üéØ "I need to fine-tune AI models"
Fine-tune models with your data:
1. [Install CLI tools](./fine-tuning#install-cli)
2. [Prepare your dataset](./fine-tuning#prepare-your-data)
3. [Start fine-tuning](./fine-tuning#create-task)

## Frequently Asked Questions

<details>
<summary>How much can I save compared to OpenAI?</summary>

Typically 90%+ savings:
- OpenAI GPT-4: ~$0.03 per 1K tokens
- 0G Compute: ~$0.003 per 1K tokens
- Bulk usage: Even greater discounts
</details>

<details>
<summary>Is my data secure?</summary>

Yes, through multiple layers:
- TEE (Trusted Execution Environment) processing
- No data retention by providers
- Verifiable computation proofs
</details>

<details>
<summary>How fast is it compared to centralized services?</summary>

- Inference: 50-100ms latency (comparable to centralized)
- Geographic distribution reduces latency
</details>

---

*0G Compute Network: Democratizing AI computing for everyone.*

---

## Deploy Contracts on 0G Chain

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Deploy Smart Contracts on 0G Chain

Deploy smart contracts on 0G Chain - an EVM-compatible blockchain with built-in AI capabilities.

## Why Deploy on 0G Chain?

### ‚ö° Performance Benefits

- **11,000 TPS per Shard**: Higher throughput than Ethereum
- **Low Fees**: Fraction of mainnet costs
- **Sub-second Finality**: Near-instant transaction confirmation

### üîß Latest EVM Compatibility

- **Pectra & Cancun-Deneb Support**: Leverage newest Ethereum capabilities
- **Future-Ready**: Architecture designed for quick integration of upcoming EVM upgrades
- **Familiar Tools**: Use Hardhat, Foundry, Remix
- **No Learning Curve**: Deploy like any EVM chain

## Prerequisites

Before deploying contracts on 0G Chain, ensure you have:

- Node.js 16+ installed (for Hardhat/Truffle)
- Rust installed (for Foundry)
- A wallet with testnet 0G tokens ([get from faucet](https://faucet.0g.ai))
- Basic Solidity knowledge

## Steps to Deploy Your Contract

### Step 1: Prepare Your Smart Contract Code

Write your contract code as you would for any Ethereum-compatible blockchain, ensuring that it meets the requirements for your specific use case.

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.19;

contract MyToken {
    mapping(address => uint256) public balances;
    uint256 public totalSupply;

    constructor(uint256 _initialSupply) {
        totalSupply = _initialSupply;
        balances[msg.sender] = _initialSupply;
    }

    function transfer(address to, uint256 amount) public returns (bool) {
        require(balances[msg.sender] >= amount, "Insufficient balance");
        balances[msg.sender] -= amount;
        balances[to] += amount;
        return true;
    }
}
```

### Step 2: Compile Your Smart Contract

Use `solc` or another compatible Solidity compiler to compile your smart contract.

**Important**: When compiling, specify `--evm-version cancun` to ensure compatibility with the latest EVM upgrades supported by 0G Chain.

**Using solc directly**:

```bash
solc --evm-version cancun --bin --abi MyToken.sol
```

**Using Hardhat**:

```javascript
// hardhat.config.js
module.exports = {
  solidity: {
    version: "0.8.19",
    settings: {
      evmVersion: "cancun",
      optimizer: {
        enabled: true,
        runs: 200,
      },
    },
  },
};
```

**Using Foundry**:

```toml
# foundry.toml
[profile.default]
evm_version = "cancun"
```

This step will generate the binary and ABI (Application Binary Interface) for your contract.

### Step 3: Deploy the Contract on 0G Chain

Once compiled, you can use your preferred Ethereum-compatible deployment tools, such as `web3.js`, `ethers.js`, or `hardhat`, to deploy the contract on 0G Chain.

**Configure Network Connection**:

```javascript
// For Hardhat
networks: {
  "testnet": {
    url: "https://evmrpc-testnet.0g.ai",
    chainId: 16602,
    accounts: [process.env.PRIVATE_KEY]
  },
  "mainnet": {
    url: "https://evmrpc.0g.ai",
    chainId: 16661,
    accounts: [process.env.PRIVATE_KEY]
  }
}

// For Foundry
[rpc_endpoints]
0g_testnet = "https://evmrpc-testnet.0g.ai"
0g_mainnet = "https://evmrpc.0g.ai"
```

**Deploy Using Your Preferred Tool**:

<details>
<summary>Hardhat Deployment</summary>

```javascript
// scripts/deploy.js
async function main() {
  const MyToken = await ethers.getContractFactory("MyToken");
  const token = await MyToken.deploy(1000000); // 1M initial supply
  await token.deployed();

  console.log("Token deployed to:", token.address);
}

main().catch((error) => {
  console.error(error);
  process.exitCode = 1;
});
```

Run: `npx hardhat run scripts/deploy.js --network 0g-testnet`

</details>

<details>
<summary>Foundry Deployment</summary>

```bash
forge create --rpc-url https://evmrpc-testnet.0g.ai \
  --private-key $PRIVATE_KEY \
  --evm-version cancun \
  src/MyToken.sol:MyToken \
  --constructor-args 1000000
```

</details>

<details>
<summary>Truffle Deployment</summary>

```javascript
// migrations/2_deploy_token.js
module.exports = function (deployer) {
  deployer.deploy(MyToken, 1000000);
};
```

Run: `truffle migrate --network 0g-testnet`

</details>

Follow the same deployment steps as you would on Ethereum, using your 0G Chain node or RPC endpoint.

> For complete working examples using different frameworks, check out the official deployment scripts repository: üîó **[0G Deployment Scripts](https://github.com/0gfoundation/0g-deployment-scripts)**

### Step 4: Verify Deployment Results on 0G Chain Scan

After deployment, you can verify your contract on 0G Chain Scan, the block explorer for **[0G Chain](https://chainscan.0g.ai)** or via the provided API below:

<Tabs>
  <TabItem value="verify-hardhat" label="Hardhat" default>
    <!-- Prerequisites -->
    Make sure you have the following plugins installed:
    ```bash
    npm install --save-dev @nomicfoundation/hardhat-verify @nomicfoundation/viem @nomicfoundation/hardhat-toolbox-viem dotenv 
    ```

    To verify your contract using Hardhat, please use the following settings in your `hardhat.config.js`:

    ```javascript
    solidity: {
      ...
      settings: {
        evmVersion: "cancun", // Make sure this matches your compiler setting
        optimizer: {
          enabled: true,
          runs: 200, // Adjust based on your optimization needs
        },
        viaIR: true, // Enable if your contract uses inline assembly
        metadata: {
          bytecodeHash: "none", // Optional: Set to "none" to exclude metadata hash
        },
      },
    }
    ```

    Add the network configuration:

    ```javascript
    networks: {
      "testnet": {
        url: "https://evmrpc-testnet.0g.ai",
        chainId: 16602,
        accounts: [process.env.PRIVATE_KEY]
      },
      "mainnet": {
        url: "https://evmrpc.0g.ai",
        chainId: 16661,
        accounts: [process.env.PRIVATE_KEY]
      }
    }
    ```

    and finally, add the etherscan configuration:

    ```javascript
    etherscan: {
      apiKey: {
        testnet: "YOUR_API_KEY", // Use a placeholder if you don't have one
        mainnet: "YOUR_API_KEY"  // Use a placeholder if you don't have one
      },
      customChains: [
        {
          // Testnet
          network: "testnet",
          chainId: 16602,
          urls: {
            apiURL: "https://chainscan-galileo.0g.ai/open/api",
            browserURL: "https://chainscan-galileo.0g.ai",
          },
        },
        {
          // Mainnet
          network: "mainnet",
          chainId: 16661,
          urls: {
            apiURL: "https://chainscan.0g.ai/open/api",
            browserURL: "https://chainscan.0g.ai",
          },
        },
      ],
    },
    ```

    To verify your contract, run the following command:

    ```bash
    npx hardhat verify DEPLOYED_CONTRACT_ADDRESS --network <Network>
    ```

    You should get a success message like this:

    ```bash
    Successfully submitted source code for contract
    contracts/Contract.sol:ContractName at DEPLOYED_CONTRACT_ADDRESS
    for verification on the block explorer. Waiting for verification result...

    Successfully verified contract TokenDist on the block explorer.
    https://chainscan.0g.ai/address/<DEPLOYED_CONTRACT_ADDRESS>#code
    ```

</TabItem>
<TabItem value="verify-forge" label="Forge">
On Foundry, you can verify your contract using the `forge verify-contract` command. Make sure to set your compiler settings in `foundry.toml` as needed.

| Precompile | Verifier URL                               |
| ---------- | ------------------------------------------ |
| Testnet    | `https://chainscan-galileo.0g.ai/open/api` |
| Mainnet    | `https://chainscan.0g.ai/open/api`         |

    ```bash
    forge verify-contract \
    --chain-id <CHAIN_ID> \
    --num-of-optimizations <NUM_OPTIMIZATIONS> \
    --verifier custom \
    --verifier-api-key "PLACEHOLDER" \
    --compiler-version <COMPILER_VERSION> \
    <CONTRACT_ADDRESS> \
    src/Counter.sol:Counter \
    --verifier-url <VERIFIER_URL> \
    ```

You should get a success message like this:

    ```bash
    Submitted contract for verification:
    Response: OK
    GUID: <GUID>
    URL: https://chainscan-galileo.0g.ai/open/address/<CONTRACT_ADDRESS>
    ```

</TabItem>
</Tabs>

## Using 0G Precompiles

### Available Precompiles

| Precompile                                               | Address     | Purpose                      |
| -------------------------------------------------------- | ----------- | ---------------------------- |
| [DASigners](./precompiles/precompiles-dasigners)         | `0x...1000` | Data availability signatures |
| [Wrapped0GBase](./precompiles/precompiles-wrappedogbase) | `0x...1002` | Wrapped 0G token operations  |

## Troubleshooting

<details>
<summary>Transaction failing with "invalid opcode"?</summary>

If you're using newer experimental opcodes from unreleased Ethereum upgrades and see "invalid opcode" errors, consider:

- Use `--evm-version cancun` in your compiler settings
- Downgrade to an earlier Solidity compiler version (e.g., from 0.8.26 to 0.8.19)
</details>

<details>
<summary>Can't connect to RPC?</summary>

Try alternative endpoints:

- QuikNode: [Get endpoint](https://www.quicknode.com/chains/0g)
- ThirdWeb: [Get endpoint](https://thirdweb.com/0g-galileo-testnet-16601)
</details>

## What's Next?

- **Learn Precompiles**: [Precompiles Overview](./precompiles/precompiles-overview)
- **Storage Integration**: [0G Storage SDK](/developer-hub/building-on-0g/storage/sdk)
- **Compute Integration**: [0G Compute Guide](/developer-hub/building-on-0g/compute-network/overview)

---

Need help? Join our [Discord](https://discord.gg/0glabs) for developer support.

---

## DASigners

# Overview

DAsigners is a wrapper for the `x/dasigners` module in the 0g chain, allowing querying the state of this module from EVM calls.

# Address

`0x0000000000000000000000000000000000001000`

# Interface

[https://github.com/0gfoundation/0g-chain/blob/dev/precompiles/interfaces/contracts/IDASigners.sol](https://github.com/0gfoundation/0g-chain/blob/dev/precompiles/interfaces/contracts/IDASigners.sol)

## Structs

### `SignerDetail`
```solidity
struct SignerDetail {
    address signer;
    string socket;
    BN254.G1Point pkG1;
    BN254.G2Point pkG2;
}
```
- **Description**: Contains details of a signer, including the address, socket, and bn254 public keys (G1 and G2 points).

- **Fields**:
  - `signer`: The address of the signer.
  - `socket`: The socket associated with the signer.
  - `pkG1`: The G1 public key of the signer.
  - `pkG2`: The G2 public key of the signer.

### `Params`
```solidity
struct Params {
    uint tokensPerVote;
    uint maxVotesPerSigner;
    uint maxQuorums;
    uint epochBlocks;
    uint encodedSlices;
}
```
- **Description**: Defines parameters for the DAsigners module.

- **Fields**:
  - `tokensPerVote`: The number of tokens required for one vote.
  - `maxVotesPerSigner`: The maximum number of votes a signer can cast.
  - `maxQuorums`: The maximum number of quorums allowed.
  - `epochBlocks`: The number of blocks in an epoch.
  - `encodedSlices`: The number of encoded slices in one DA blob.

---

## Functions

### `params()`
```solidity
function params() external view returns (Params memory);
```
- **Description**: Retrieves the current parameters of the DAsigners module.
- **Returns**: `Params` structure containing the current module parameters.

---

### `epochNumber()`
```solidity
function epochNumber() external view returns (uint);
```
- **Description**: Returns the current epoch number.
- **Returns**: `uint` representing the current epoch number.

---

### `quorumCount(uint _epoch)`
```solidity
function quorumCount(uint _epoch) external view returns (uint);
```
- **Description**: Returns the number of quorums for a given epoch.
- **Parameters**: 
  - `_epoch`: The epoch number.
- **Returns**: `uint` representing the quorum count for the given epoch.

---

### `isSigner(address _account)`
```solidity
function isSigner(address _account) external view returns (bool);
```
- **Description**: Checks if a given account is a registered signer.
- **Parameters**: 
  - `_account`: The address to check.
- **Returns**: `bool` indicating whether the account is a signer.

---

### `getSigner(address[] memory _account)`
```solidity
function getSigner(
    address[] memory _account
) external view returns (SignerDetail[] memory);
```
- **Description**: Retrieves details for the signers of the provided addresses.
- **Parameters**: 
  - `_account`: An array of addresses to fetch the signer details for.
- **Returns**: An array of `SignerDetail` structures for each signer.

---

### `getQuorum(uint _epoch, uint _quorumId)`
```solidity
function getQuorum(
    uint _epoch,
    uint _quorumId
) external view returns (address[] memory);
```
- **Description**: Returns the addresses of the members in a specific quorum for a given epoch.
- **Parameters**: 
  - `_epoch`: The epoch number.
  - `_quorumId`: The ID of the quorum.
- **Returns**: An array of addresses that are members of the quorum.

---

### `getQuorumRow(uint _epoch, uint _quorumId, uint32 _rowIndex)`
```solidity
function getQuorumRow(
    uint _epoch,
    uint _quorumId,
    uint32 _rowIndex
) external view returns (address);
```
- **Description**: Retrieves a specific address from a quorum's row for a given epoch and quorum ID.
- **Parameters**: 
  - `_epoch`: The epoch number.
  - `_quorumId`: The quorum ID.
  - `_rowIndex`: The row index within the quorum.
- **Returns**: The address at the specified row index in the quorum.

---

### `registerSigner(SignerDetail memory _signer, BN254.G1Point memory _signature)`
```solidity
function registerSigner(
    SignerDetail memory _signer,
    BN254.G1Point memory _signature
) external;
```
- **Description**: Registers a new signer with the provided details and signature.
- **Parameters**: 
  - `_signer`: The details of the signer to register.
  - `_signature`: The signature to verify the registration.

---

### `updateSocket(string memory _socket)`
```solidity
function updateSocket(string memory _socket) external;
```
- **Description**: Updates the socket used by the module.
- **Parameters**: 
  - `_socket`: The new socket address to update.

---

### `registeredEpoch(address _account, uint _epoch)`
```solidity
function registeredEpoch(
    address _account,
    uint _epoch
) external view returns (bool);
```
- **Description**: Checks if a specific account is registered in a given epoch.
- **Parameters**: 
  - `_account`: The address to check.
  - `_epoch`: The epoch number.
- **Returns**: `bool` indicating whether the account is registered for the specified epoch.

---

### `registerNextEpoch(BN254.G1Point memory _signature)`
```solidity
function registerNextEpoch(BN254.G1Point memory _signature) external;
```
- **Description**: Registers the next epoch using the provided signature.
- **Parameters**: 
  - `_signature`: The signature used to register the next epoch.

---

### `getAggPkG1(uint _epoch, uint _quorumId, bytes memory _quorumBitmap)`
```solidity
function getAggPkG1(
    uint _epoch,
    uint _quorumId,
    bytes memory _quorumBitmap
) external view returns (BN254.G1Point memory aggPkG1, uint total, uint hit);
```
- **Description**: Retrieves the aggregated public key for a given epoch and quorum ID.
- **Parameters**: 
  - `_epoch`: The epoch number.
  - `_quorumId`: The quorum ID.
  - `_quorumBitmap`: The quorum bitmap.
- **Returns**: 
  - `aggPkG1`: The aggregated public key.
  - `total`: The number of rows.
  - `hit`: The number of rows that contributed to the aggregation.
---

---

## Overview(Precompiles)

# 0G Chain Precompiles

Precompiled contracts that extend 0G Chain with powerful native features for AI and blockchain operations.

## What Are Precompiles?

Precompiles are special contracts deployed at fixed addresses that execute native code instead of EVM bytecode. They provide:
- **Gas Efficiency**: 10-100x cheaper than Solidity implementations
- **Native Features**: Access chain-level functionality
- **Complex Operations**: Cryptographic functions and state management

## 0G Chain Precompiles

Beyond standard Ethereum precompiles, 0G Chain adds specialized contracts for decentralized AI infrastructure:

### üîê [DASigners](./precompiles-dasigners)
`0x0000000000000000000000000000000000001000`

Manages data availability signatures for 0G's DA layer.

**Key Features**:
- Register and manage DA node signers
- Query quorum information
- Verify data availability proofs

**Common Use Case**: Building applications that need to verify data availability directly on-chain.

<!-- ### üí∞ Staking (`0x0000000000000000000000000000000000001001`)
Native staking operations for validators and delegators.

**Key Features**:
- Delegate tokens to validators
- Query staking rewards
- Manage validator operations

**Common Use Case**: Building staking interfaces or automated delegation strategies.

[Full Staking Documentation](./staking) -->

### ü™ô [Wrapped0GBase](./precompiles-wrappedogbase)
`0x0000000000000000000000000000000000001002`

Wrapped version of native 0G token for DeFi compatibility.

**Key Features**:
- Wrap/unwrap native 0G tokens
- ERC20-compatible interface
- Efficient gas operations

**Common Use Case**: Integrating 0G tokens with DEXs, lending protocols, or other DeFi applications.

---

Questions? Get help in our [Discord](https://discord.gg/0glabs) #dev-support channel.

---

## Wrapped 0G Base

# Overview

Wrapped0GBase is a wrapper for the `x/wrapped-og-base` module in the 0g chain. W0G is a wrapped ERC20 token for native 0G. It supports quota-based mint/burn functions based on native 0G transfers, on top of traditional wrapped token implementation. The minting/burning quota for each address will be determined through governance voting. `x/wrapped-og-base` is the module that supports and maintains the minting/burning quota.

In most cases this precompile should be only called by wrapped 0G contract.

# Address

`0x0000000000000000000000000000000000001002`

> **Wrapped 0G Token Contract Address**: `0x1Cd0690fF9a693f5EF2dD976660a8dAFc81A109c`
>
> This is the official address of the wrapped 0G (W0G) ERC20 token on the 0G chain. Use this address if you want to interact directly with the wrapped 0G token contract for transfers, approvals, or other ERC20 operations.

# Interface

[https://github.com/0gfoundation/0g-chain/blob/dev/precompiles/interfaces/contracts/IWrappedA0GIBase.sol](https://github.com/0gfoundation/0g-chain/blob/dev/precompiles/interfaces/contracts/IWrappedA0GIBase.sol)

## Structs

### `Supply`
```solidity
struct Supply {
    uint256 cap;
    uint256 initialSupply;
    uint256 supply;
}
```
- **Description**: Defines the supply details of a minter, including the cap, initial supply, and the current supply.
  
- **Fields**:
  - `cap`: The maximum allowed mint supply for the minter.
  - `initialSupply`: The initial mint supply to the minter, equivalent to the initial allowed burn amount.
  - `supply`: The current mint supply used by the minter, set to `initialSupply` at beginning.

---

## Functions

### `getWA0GI()`
```solidity
function getWA0GI() external view returns (address);
```
- **Description**: Retrieves the address of the wrapped 0G token from the wrapped 0G precompile.
- **Returns**: `address` of the W0G contract.

---

### `minterSupply(address minter)`
```solidity
function minterSupply(address minter) external view returns (Supply memory);
```
- **Description**: Retrieves the mint supply details for a given minter.
- **Parameters**: 
  - `minter`: The address of the minter.
- **Returns**: A `Supply` structure containing the mint cap, initial supply, and current supply of the specified minter.

---

### `mint(address minter, uint256 amount)`
```solidity
function mint(address minter, uint256 amount) external;
```
- **Description**: Mints 0G to WA0GI contract and adds the corresponding amount to the minter's mint supply. If the minter's final mint supply exceeds their mint cap, the transaction will revert.
- **Parameters**: 
  - `minter`: The address of the minter.
  - `amount`: The amount of 0G to mint.
- **Restrictions**: Can only be called by the WA0GI contract.

---

### `burn(address minter, uint256 amount)`
```solidity
function burn(address minter, uint256 amount) external;
```
- **Description**: Burns the specified amount of 0G in WA0GI contract on behalf of the minter and reduces the corresponding amount from the minter's mint supply.
- **Parameters**: 
  - `minter`: The address of the minter.
  - `amount`: The amount of 0G to burn.
- **Restrictions**: Can only be called by the W0G contract.

---

---

## Staking Interfaces


Welcome to the 0G Chain Staking Interfaces documentation. This guide provides comprehensive information about interacting with the 0G Chain staking system through smart contracts, enabling you to build applications that leverage validator operations and delegations.

:::tip **Running a Validator?**
If you want to set up and initialize a validator, see the [Validator Initialization Guide](#validator-initialization) below.
:::

## Quick Navigation

- **[Validator Initialization Guide](#validator-initialization)** - Complete step-by-step setup for becoming a validator
- **[Contract Interfaces](#contract-interfaces)** - Smart contract reference documentation
- **[Examples](#examples)** - Smart contract code examples

---

## Overview

The 0G Chain staking system enables 0G token holders to participate in network consensus and earn rewards through two primary mechanisms:

1. **Becoming a Validator**: Run infrastructure to validate transactions and produce blocks
2. **Delegating to Validators**: Stake tokens with existing validators to earn rewards without running infrastructure

The staking system is built on two core smart contract interfaces:

- **`IStakingContract`**: Central registry managing validators and global staking parameters
- **`IValidatorContract`**: Individual validator operations including delegations and reward distribution

## Prerequisites

Before working with the staking interfaces:

- Familiarity with Solidity and smart contract development
- Basic knowledge of consensus mechanisms and staking concepts

## Quick Start

```solidity
// Create a validator
IStakingContract staking = IStakingContract(0xea224dBB52F57752044c0C86aD50930091F561B9);
address validator = staking.createAndInitializeValidatorIfNecessary{value: msg.value}(
    description, commissionRate, withdrawalFee, pubkey, signature
);

// Delegate to validator
IValidatorContract(validator).delegate{value: msg.value}(msg.sender);
```

## Core Concepts

### Validators
Validators process transactions and produce blocks:
- **Unique Identity**: Identified by 48-byte consensus public key
- **Operator Control**: Managed by an Ethereum address
- **Commission**: Set their own reward commission rates
- **Self-Delegation**: Required minimum stake from operator

### Delegations
Token holders earn rewards by delegating to validators:
- **Share-Based**: Delegations represented as shares in validator pool
- **Proportional Rewards**: Earnings based on share percentage
- **Withdrawal Delay**: Undelegation subject to network delay period

### Reward Distribution
Rewards flow through multiple layers:
1. **Community Tax**: Applied to all rewards first
2. **Validator Commission**: Taken from remaining rewards
3. **Delegator Distribution**: Proportional to shares held

## Contract Interfaces

### IStakingContract
`0xea224dBB52F57752044c0C86aD50930091F561B9` (Mainnet)

Central registry for validators and global parameters.

#### Validator Management
```solidity
// Create validator contract
function createValidator(bytes calldata pubkey) external returns (address);

// Initialize validator with self-delegation
function initializeValidator(
    Description calldata description,
    uint32 commissionRate,
    uint96 withdrawalFeeInGwei,
    bytes calldata pubkey,
    bytes calldata signature
) external payable;

// Create and initialize in one call
function createAndInitializeValidatorIfNecessary(
    Description calldata description,
    uint32 commissionRate, 
    uint96 withdrawalFeeInGwei,
    bytes calldata pubkey,
    bytes calldata signature
) external payable;
```

#### Query Functions
```solidity
function getValidator(bytes memory pubkey) external view returns (address);
function computeValidatorAddress(bytes calldata pubkey) external view returns (address);
function validatorCount() external view returns (uint32);
function maxValidatorCount() external view returns (uint32);
```

### IValidatorContract
Individual validator operations and delegation management.

#### Delegation Management
```solidity
// Delegate tokens (msg.value = amount)
function delegate(address delegatorAddress) external payable returns (uint);

// Undelegate shares (msg.value = withdrawal fee)
function undelegate(address withdrawalAddress, uint shares) external payable returns (uint);

// Withdraw validator commission (only validator operator)
function withdrawCommission(address withdrawalAddress) external returns (uint);
```

:::info **Access Control**
The `withdrawCommission` function is restricted to the validator operator only - the address that originally created and manages the validator.
:::

#### Information Queries
```solidity
function tokens() external view returns (uint);           // Total tokens (delegated + rewards)
function delegatorShares() external view returns (uint);  // Total shares issued
function getDelegation(address delegator) external view returns (address, uint);
function commissionRate() external view returns (uint32);
function withdrawalFeeInGwei() external view returns (uint96);
```

:::tip **Understanding tokens()**
The `tokens()` function returns the complete validator balance, including both the original delegated amounts and any accumulated rewards that haven't been distributed yet.
:::

## Examples

### Creating a Validator

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "./IStakingContract.sol";

contract ValidatorExample {
    IStakingContract constant STAKING = IStakingContract(0xea224dBB52F57752044c0C86aD50930091F561B9);
    
    function createValidator(
        bytes calldata pubkey, 
        bytes calldata signature
    ) external payable {
        Description memory desc = Description({
            moniker: "My Validator",
            identity: "keybase-id", 
            website: "https://validator.example.com",
            securityContact: "security@example.com",
            details: "A reliable 0G Chain validator"
        });
        
        STAKING.createAndInitializeValidatorIfNecessary{value: msg.value}(
            desc,
            50000,  // 5% commission
            1,      // 1 Gwei withdrawal fee
            pubkey,
            signature
        );
    }
}
```

### Delegation Management

```solidity
contract DelegationHelper {
    IStakingContract constant STAKING = IStakingContract(0xea224dBB52F57752044c0C86aD50930091F561B9);
    
    function delegateToValidator(bytes calldata pubkey) external payable {
        address validator = STAKING.getValidator(pubkey);
        require(validator != address(0), "Validator not found");
        
        IValidatorContract(validator).delegate{value: msg.value}(msg.sender);
    }
    
    function getDelegationInfo(
        bytes calldata pubkey,
        address delegator
    ) external view returns (uint shares, uint estimatedTokens) {
        address validator = STAKING.getValidator(pubkey);
        IValidatorContract v = IValidatorContract(validator);
        
        (, shares) = v.getDelegation(delegator);
        
        uint totalTokens = v.tokens();
        uint totalShares = v.delegatorShares();
        
        if (totalShares > 0) {
            estimatedTokens = (shares * totalTokens) / totalShares;
        }
    }
}
```

## Validator Initialization

This section covers the complete workflow for setting up and initializing a validator on the 0G Chain.

### Step 1: Generate Validator Signature

The validator signature creation process is simplified with a single command:

```bash
# Set your environment variables
HOMEDIR={your data path}/0g-home/0gchaind-home
STAKING_ADDRESS=0xea224dBB52F57752044c0C86aD50930091F561B9
AMOUNT=500000000000  # Amount in wei (e.g., 500 for 500 0G tokens)

# Generate validator signature
./bin/0gchaind deposit create-delegation-validator \
    $STAKING_ADDRESS \
    $AMOUNT \
    $HOMEDIR/config/genesis.json \
    --home $HOMEDIR \
    --chaincfg.chain-spec=mainnet \
    --override-rpc-url \
    --rpc-dial-url https://evmrpc.0g.ai
```

**Output:**
```
‚úÖ Staking message created successfully!
Note: This is NOT a transaction receipt; use these values to create a validator initialize transaction by Staking Contract.

stakingAddress: 0xea224dBB52F57752044c0C86aD50930091F561B9
pubkey: 0x8497312cd37eef3a7a50017cfbebcb00a9bc400c5881ffb1011cba1c3f29e5d005a980880b7b919b558b95565bc1e628
validatorAddress: 0xA47171b1be26C75732766Ea3433a90A724b3590d
amount: 500000000000
signature: 0xb1dae1164d931c46178785246203eb1c4496b403a7c417bfb33bdfd3c26b552bdbec8e466ed6712ade0b99cc9b0ee8b004cc766687565ba5b0929a1382997a6cc548cf5e390b69f849933c7ac017fbddc612cb3de285fdf89e6fe32e0ccbfc43
```

### Step 2: Validate the Signature

Before submitting the validator initialization transaction, validate the signature:

```bash
# Validate the deposit message
./bin/0gchaind deposit validate-delegation \
    {pubkey} \
    {staking_address} \
    {amount} \
    {signature} \
    $HOMEDIR/config/genesis.json \
    --home $HOMEDIR \
    --chaincfg.chain-spec=mainnet \
    --override-rpc-url \
    --rpc-dial-url https://evmrpc.0g.ai
```

**Example:**
```bash
./bin/0gchaind deposit validate-delegation \
    0x8497312cd37eef3a7a50017cfbebcb00a9bc400c5881ffb1011cba1c3f29e5d005a980880b7b919b558b95565bc1e628 \
    0xea224dBB52F57752044c0C86aD50930091F561B9 \
    500000000000 \
    0xb1dae1164d931c46178785246203eb1c4496b403a7c417bfb33bdfd3c26b552bdbec8e466ed6712ade0b99cc9b0ee8b004cc766687565ba5b0929a1382997a6cc548cf5e390b69f849933c7ac017fbddc612cb3de285fdf89e6fe32e0ccbfc43 \
    $HOMEDIR/config/genesis.json \
    --home $HOMEDIR \
    --chaincfg.chain-spec=mainnet \
    --override-rpc-url \
    --rpc-dial-url https://evmrpc.0g.ai
```

**Output:**
```
‚úÖ Deposit message is valid!
```

### Step 3: Prepare Validator Description and Settings

#### Description Structure

The Description struct contains your validator's public information. All fields have character limits that must be respected:

| Field | Max Length | Description |
|-------|-----------|-------------|
| `moniker` | 70 chars | Your validator's display name |
| `identity` | 100 chars | **Optional:** Keybase identity |
| `website` | 140 chars | Your validator website URL |
| `securityContact` | 140 chars | Security contact email |
| `details` | 200 chars | Additional validator description |

**Example Description Object:**

```jsx
{
  moniker: "Your Validator Name",      // Max 70 chars
  identity: "keybase_id",              // Optional
  website: "https://yoursite.com",     // Max 140 chars
  securityContact: "security@you.com", // Max 140 chars
  details: "Professional validator"     // Max 200 chars
}
```

#### Commission Rate Configuration

The commission rate determines what percentage of staking rewards your validator keeps

| Value | Commission |
|-------|-----------|
| `100` | 0.01% |
| `1000` | 0.1% |
| `10000` | 1% |
| `50000` | 5% |
| `100000` | 10% |

#### Withdrawal Fee Configuration

The withdrawal fee (in Gwei) is charged when delegators undelegate from your validator.

**Recommended value:** `1` (equivalent to 1 Gneuron, ~1 Gwei)

### Step 4: Execute Initialization Transaction

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
  <TabItem value="chainscan" label="0G Chain Scan (Recommended)" default>

The easiest way to initialize your validator using the web interface:

1. Navigate to https://chainscan.0g.ai/address/0xea224dBB52F57752044c0C86aD50930091F561B9
2. Under **Contracts** Tab, click on the **Write As Proxy** button
3. Find and click on `createAndInitializeValidatorIfNecessary`
4. Fill in all the required parameters:
   - **description** (struct):
     - `moniker`: Your validator name (max 70 chars)
     - `identity`: Keybase ID (optional)
     - `website`: Your website URL
     - `securityContact`: Security contact email
     - `details`: Additional description
   - **commissionRate**: Commission percentage (e.g., 10000 for 1%)
   - **withdrawalFeeInGwei**: Withdrawal fee in Gwei (e.g.,1 Gneuron ~ 1 Gwei)
   - **pubkey**: The public key from Step 1
   - **signature**: The signature from Step 1
5. Set the `payable amount` to **500** OG tokens
6. Connect your wallet and execute the transaction

:::tip **Tip**
Using the Chain Scan interface requires no coding knowledge and is the safest option for most users.
:::

  </TabItem>
  <TabItem value="metamask" label="MetaMask / Web3 Wallet">

For users comfortable with wallet interactions:

1. Ensure your wallet is connected to **0G Chain Mainnet**
2. Go to the contract address: `0xea224dBB52F57752044c0C86aD50930091F561B9`
3. Use a contract interaction tool like:
   - [0G Chain Scan](https://chainscan.0g.ai)
   - Your wallet's built-in contract interaction features
4. Call `createAndInitializeValidatorIfNecessary` with:
   - `description`: Struct with all validator details
   - `commissionRate`: Commission percentage (e.g., 10000 for 1%)
   - `withdrawalFeeInGwei`: Withdrawal fee in Gwei (~1 Gneuron equivalent)
   - `pubkey`: Your validator's public key
   - `signature`: Your validator's signature
5. Set transaction value to **500 OG tokens** (500000000000000000000 wei)
6. Confirm the transaction in your wallet

:::warning **Important**
Ensure your wallet has sufficient funds:
- 500 OG tokens for initialization
- Additional gas fees for the transaction
:::

  </TabItem>
  <TabItem value="ethersjs" label="Ethers.js (Programmatic)">

For developers who want to automate the process:

```javascript
const { ethers } = require("ethers");

// Initialize provider and wallet
const provider = new ethers.JsonRpcProvider("https://evmrpc.0g.ai");
const wallet = new ethers.Wallet(process.env.PRIVATE_KEY, provider);

// Staking contract ABI (minimal)
const stakingABI = [
  {
    "inputs": [
      {
        "components": [
          { "internalType": "string", "name": "moniker", "type": "string" },
          { "internalType": "string", "name": "identity", "type": "string" },
          { "internalType": "string", "name": "website", "type": "string" },
          { "internalType": "string", "name": "securityContact", "type": "string" },
          { "internalType": "string", "name": "details", "type": "string" }
        ],
        "internalType": "struct IStakingContract.Description",
        "name": "description",
        "type": "tuple"
      },
      { "internalType": "uint32", "name": "commissionRate", "type": "uint32" },
      { "internalType": "uint96", "name": "withdrawalFeeInGwei", "type": "uint96" },
      { "internalType": "bytes", "name": "pubkey", "type": "bytes" },
      { "internalType": "bytes", "name": "signature", "type": "bytes" }
    ],
    "name": "createAndInitializeValidatorIfNecessary",
    "outputs": [{ "internalType": "address", "name": "", "type": "address" }],
    "stateMutability": "payable",
    "type": "function"
  }
];

async function initializeValidator() {
  const stakingContract = new ethers.Contract(
    "0xea224dBB52F57752044c0C86aD50930091F561B9",
    stakingABI,
    wallet
  );

  const description = {
    moniker: "Your Validator Name",
    identity: "keybase_id",
    website: "https://yourvalidator.com",
    securityContact: "security@yourvalidator.com",
    details: "Professional 0G Chain validator"
  };

  try {
    const tx = await stakingContract.createAndInitializeValidatorIfNecessary(
      description,
      10000,      // 1% commission
      1000000,    // 1 Gwei withdrawal fee
      "0x...",    // Your pubkey
      "0x...",    // Your signature
      { value: ethers.parseEther("500") }  // 500 OG tokens
    );

    console.log("Transaction hash:", tx.hash);
    const receipt = await tx.wait();
    console.log("Validator initialized successfully!");
    console.log("Transaction receipt:", receipt);
  } catch (error) {
    console.error("Error initializing validator:", error);
  }
}

initializeValidator();
```

:::note **Environment Setup**
Make sure to set `PRIVATE_KEY` in your `.env` file before running the script.
:::

</TabItem>
</Tabs>

### Step 5: Verify Initialization

After successful initialization, you can verify your validator status:

- Check the transaction on **0G Chain Scan**: https://chainscan.0g.ai
- Verify your validator status on **0G Explorer**: https://explorer.0g.ai/mainnet/validators

:::info **Activation Time**
Your validator may initially appear as **inactive** on the explorer. This is normal. Validators typically take **30-60 minutes** to activate on the network after successful initialization.

You can check the transaction status and logs to confirm the initialization was successful while waiting for activation.
:::

### Troubleshooting

<details>
<summary>Error: "Insufficient funds"</summary>

Ensure you have at least 500 OG tokens plus gas fees in your wallet.

```bash
# Check balance
cast balance $YOUR_ADDRESS --rpc-url https://evmrpc.0g.ai
```

</details>

<details>
<summary>Error: "Validator already exists"</summary>

Your validator has already been created. Use the `getValidator` function to retrieve your validator address:

```javascript
const validatorAddress = await stakingContract.getValidator("0x...");
```

</details>

<details>
<summary>Error: "Invalid signature"</summary>

Regenerate your signature using 0gchaind with the correct validator contract address and delegation amount:

```bash
./bin/0gchaind deposit create-delegation-validator \
    0xea224dBB52F57752044c0C86aD50930091F561B9 \
    500000000000 \
    $HOMEDIR/config/genesis.json \
    --home $HOMEDIR \
    --chaincfg.chain-spec=mainnet \
    --override-rpc-url \
    --rpc-dial-url https://evmrpc.0g.ai
```

</details>

<details>
<summary>Error: "Description field too long"</summary>

Ensure all Description fields are within character limits:
- `moniker`: max 70 chars
- `identity`: max 100 chars
- `website`: max 140 chars
- `securityContact`: max 140 chars
- `details`: max 200 chars

</details>

## Data Structures

<details>
<summary>Description Struct</summary>

```solidity
struct Description {
    string moniker;         // max 70 chars - Validator display name
    string identity;        // max 100 chars - Keybase identity  
    string website;         // max 140 chars - Website URL
    string securityContact; // max 140 chars - Security contact
    string details;         // max 200 chars - Additional details
}
```

</details>

<details>
<summary>Withdrawal Entry</summary>

```solidity
struct WithdrawEntry {
    uint completionHeight;  // Block height when withdrawal completes
    address delegatorAddress; // Address receiving withdrawal
    uint amount;            // Amount being withdrawn
}
```

</details>

## Configuration Parameters

| Parameter | Description |
|-----------|-------------|
| `maxValidatorCount` | Maximum validators allowed |
| `minActivationStakesInGwei` | Minimum stake for activation |
| `maxEffectiveStakesInGwei` | Maximum effective stake |
| `communityTaxRate` | Tax on all rewards |
| `minWithdrawabilityDelay` | Withdrawal delay blocks |

## General Troubleshooting

<details>
<summary>Error: "Validator not found"</summary>

The validator hasn't been created yet. Use `createValidator()` first:

```solidity
address validator = staking.createValidator(pubkey);
```

</details>

<details>
<summary>Error: "DelegationBelowMinimum"</summary>

Your delegation amount is below the minimum required. Check:

```solidity
uint96 minDelegation = staking.effectiveDelegationInGwei();
require(msg.value >= minDelegation * 1 gwei, "Insufficient delegation");
```

</details>

<details>
<summary>Error: "NotEnoughWithdrawalFee"</summary>

Include the withdrawal fee when undelegating:

```solidity
uint96 fee = validator.withdrawalFeeInGwei();
validator.undelegate{value: fee * 1 gwei}(recipient, shares);
```

</details>

## Contract Addresses

| Network | Staking Contract |
|---------|------------------|
| **Mainnet** | `0xea224dBB52F57752044c0C86aD50930091F561B9` |

## Resources

- **Run Validator Node**: [Validator Setup Guide](../../../run-a-node/validator-node)
- **GitHub Repository**: [0G Chain Contracts](https://github.com/0gfoundation/0g-chain-v2/blob/dev-v2.1/contracts/src/staking/)
- **Deploy Contracts**: [Contract Deployment](./deploy-contracts)

---

Need help? Join our [Discord](https://discord.gg/0glabs) for developer support.

---

## Validator Contract Functions


Complete function reference for individual validator contracts on 0G Chain.

:::info **Quick Links**
- **[Validator Initialization](./staking-interfaces#validator-initialization)** - Set up a new validator
- **[Staking Interfaces](./staking-interfaces)** - Main staking system overview
:::

## Function Types

### View Functions (Free to Call)

Query validator state without gas costs.

### Write Functions (Require Gas)

Modify validator state - cost gas to execute.

---

## View Functions

### Validator Information

#### `consensusPubkey()`
Returns the validator's BLS public key.

**Returns**: 48-byte BLS public key

---

#### `operatorAddress()`
Returns the validator operator's wallet address.

**Returns**: Operator address

---

#### `description()`
Returns validator metadata.

**Returns**:
- Moniker (name)
- Identity (verification key)
- Website
- Security contact
- Details

---

#### `commissionRate()`
Returns current commission rate.

**Returns**: Rate in parts per million (e.g., 100000 = 10%)

---

#### `withdrawalFeeInGwei()`
Returns fee charged for withdrawals.

**Returns**: Fee in Gwei

---

#### `bondStatus()`
Returns validator's current status.

**Returns**:
- `Unspecified` - Not activated
- `Bonded` - Active
- `Unbonding` - Exiting
- `Unbonded` - Fully exited

---

### Delegation Queries

#### `tokens()`
Returns total tokens delegated to this validator.

**Returns**: Total tokens in Wei

---

#### `delegatorShares()`
Returns total shares issued.

**Returns**: Total shares

---

#### `getDelegation(address delegator)`
Returns delegation info for a specific delegator.

**Parameters**:
- `delegator` - Delegator's address

**Returns**:
- Validator address
- Number of shares owned

---

#### `convertToTokens(uint shares)`
Converts shares to token amount.

**Parameters**:
- `shares` - Number of shares

**Returns**: Equivalent token amount

**Use Case**: Calculate token value of your shares

---

#### `convertToShares(uint tokens)`
Converts tokens to shares.

**Parameters**:
- `tokens` - Token amount

**Returns**: Equivalent shares

**Use Case**: Calculate shares you'll receive when delegating

---

### Rewards & Earnings

#### `rewards()`
Returns accumulated rewards pending distribution.

**Returns**: Reward amount in Wei

---

#### `commission()`
Returns accumulated commission earned by operator.

**Returns**: Commission in Wei

---

#### `tipFee()`
Returns withdrawable tip fees.

**Returns**: Tip fee amount in Wei

**Calculation**: Contract balance - (commission + rewards + stakes + pending withdrawals)

---

#### `stakes()`
Returns amount actively staked in beacon chain.

**Returns**: Staked amount in Wei

---

#### `annualPercentageYield()`
Returns current APY.

**Returns**: APY in basis points (e.g., 1500 = 15%)

---

### Withdrawal Queue

#### `withdrawCount()`
Returns number of pending withdrawals.

**Returns**: Count of pending withdrawals

---

#### `getWithdraw(uint64 index)`
Returns details of a specific withdrawal.

**Parameters**:
- `index` - Position in queue (0-based)

**Returns**:
- Completion height
- Delegator address
- Amount

---

#### `committedWithdrawAmount(uint blockHeight)`
Returns total withdrawal amount committed up to a block height.

**Parameters**:
- `blockHeight` - Block number

**Returns**: Total committed amount

---

#### `nextDepositAmount()`
Returns amount pending deposit to chain.

**Returns**: Pending deposit in Wei

---

#### `nextWithdrawalAmount()`
Returns amount pending withdrawal from chain.

**Returns**: Pending withdrawal in Wei

---

#### `failedWithdrawCount()`
Returns count of failed withdrawals.

**Returns**: Number of failed withdrawals

---

#### `failedWithdrawAmount()`
Returns total amount in failed withdrawals.

**Returns**: Failed withdrawal amount

---

## Write Functions

### Validator Configuration

#### `setCommissionRate(uint32 commissionRate_)`
Updates validator commission rate.

**Who Can Call**: Operator only

**Parameters**:
- `commissionRate_` - New rate (parts per million)

**Constraints**: Must be ‚â§ protocol maximum

---

#### `setWithdrawalFeeInGwei(uint96 withdrawalFeeInGwei_)`
Updates withdrawal fee.

**Who Can Call**: Operator only

**Parameters**:
- `withdrawalFeeInGwei_` - New fee in Gwei

**Constraints**: Must be ‚â§ protocol maximum

---

#### `setDescription(Description description_)`
Updates validator description.

**Who Can Call**: Operator only

**Parameters**:
- `description_` - New description struct

---

### Delegation Operations

#### `delegate(address delegatorAddress)`
Delegate tokens to this validator.

**Who Can Call**: Anyone

**Parameters**:
- `delegatorAddress` - Address to credit with shares

**Payment Required**: Yes (minimum 1 Gwei)

**Example**:
```solidity
validator.delegate{value: 100 ether}(msg.sender);
```

---

#### `undelegate(address withdrawalAddress, uint shares)`
Undelegate tokens from validator.

**Who Can Call**: Anyone with shares

**Parameters**:
- `withdrawalAddress` - Address to receive tokens
- `shares` - Number of shares to undelegate

**Payment Required**: Yes (must pay withdrawal fee)

**Constraints**:
- Must own enough shares
- Operator must maintain minimum self-delegation
- Tokens released after withdrawal delay

**Example**:
```solidity
uint96 fee = validator.withdrawalFeeInGwei();
validator.undelegate{value: fee * 1 gwei}(recipient, shares);
```

---

### Earnings Management

#### `withdrawCommission(address withdrawalAddress)`
Withdraw accumulated commission.

**Who Can Call**: Operator only

**Parameters**:
- `withdrawalAddress` - Address to receive commission

**Constraints**:
- Must have ‚â•1 Gwei commission
- Goes to withdrawal queue (not instant)

---

#### `withdrawTipFee(address withdrawalAddress)`
Withdraw accumulated tip fees.

**Who Can Call**: Operator only

**Parameters**:
- `withdrawalAddress` - Address to receive tips

**Constraints**:
- Only withdraws excess balance
- Immediate transfer (not queued)

---

### System Operations

#### `distributeRewards()`
Distribute rewards to delegators and commission to operator.

**Who Can Call**: Anyone (called by system)

**Process**:
1. Community tax deducted
2. Commission calculated
3. Remaining distributed to delegators

---

#### `processWithdrawQueue()`
Process pending withdrawals that are ready.

**Who Can Call**: Anyone

**When**: After withdrawal delay period

**Process**:
- Checks ready withdrawals
- Transfers funds
- Failed transfers go to failed stack

---

#### `processFailedWithdrawStack()`
Retry failed withdrawals.

**Who Can Call**: Anyone

**Process**:
- Retries all failed withdrawals
- Still-failed amounts sent to community pool

---

## Common Use Cases

### For Delegators

**Before Delegating:**
```solidity
// Check validator settings
uint32 commission = validator.commissionRate();
uint96 withdrawalFee = validator.withdrawalFeeInGwei();
uint bondStatus = validator.bondStatus(); // Should be 1 (Bonded)
uint apy = validator.annualPercentageYield();
```

**Delegate Tokens:**
```solidity
validator.delegate{value: amount}(yourAddress);
```

**Check Your Delegation:**
```solidity
(, uint shares) = validator.getDelegation(yourAddress);
uint tokens = validator.convertToTokens(shares);
```

**Undelegate:**
```solidity
uint96 fee = validator.withdrawalFeeInGwei();
validator.undelegate{value: fee * 1 gwei}(withdrawalAddress, shares);
// Wait for withdrawal delay, then call processWithdrawQueue()
```

---

### For Validator Operators

**Update Settings:**
```solidity
validator.setCommissionRate(50000); // 5%
validator.setWithdrawalFeeInGwei(1); // 1 Gwei
```

**Check Earnings:**
```solidity
uint commissionAmount = validator.commission();
uint tipFeeAmount = validator.tipFee();
```

**Withdraw Earnings:**
```solidity
// Withdraw commission (queued)
validator.withdrawCommission(yourAddress);

// Withdraw tips (immediate)
validator.withdrawTipFee(yourAddress);
```

**Monitor Status:**
```solidity
uint totalDelegated = validator.tokens();
uint activeStake = validator.stakes();
uint pendingWithdrawals = validator.withdrawCount();
```

---

## Important Notes

:::warning **Key Constraints**
- **Withdrawal Delays**: Undelegations enter a queue with delay period
- **Minimum Amounts**: Most operations require ‚â•1 Gwei
- **Fee Requirements**: Undelegation requires prepaid withdrawal fee
- **Self-Delegation**: Operators must maintain minimum or lose commission
:::

:::tip **Best Practices**
- Always check `bondStatus()` before delegating
- Use `convertToTokens()` to calculate delegation value
- Monitor `failedWithdrawCount()` and process if needed
- Operators should regularly claim commission and tips
:::

---

## Related Documentation

- **[Validator Initialization](./staking-interfaces#validator-initialization)** - Set up a new validator
- **[Staking Interfaces](./staking-interfaces)** - Full staking system guide
- **[Run Validator Node](../../../run-a-node/validator-node)** - Node setup guide

---

Need help? Join our [Discord](https://discord.gg/0glabs) for support.

---

## Technical Deep Dive

# 0G DA Technical Deep Dive

The Data Availability (DA) module allows users to submit a piece of data, referred to as a **DA blob**. This data is redundantly encoded by the client's proxy and divided into several slices, which are then sent to DA nodes. **DA nodes** gain eligibility to verify the correctness of DA slices by staking. Each DA node verifies the integrity and correctness of its slice and signs it. Once more than 2/3 of the aggregated signatures are on-chain, the data behind the related hash is considered to be published decentrally.

To incentivize DA nodes to store the signed data for a period, the signing process itself does not provide any rewards. Instead, rewards are distributed through a process called **DA Sampling**. During each DA Sample round, any DA slice within a certain timeframe can generate a lottery chance for a reward. DA nodes must store the corresponding slice to redeem the lottery chance and claim the reward.

The process of generating DA nodes is the same as the underlying chain's PoS process, both achieved through staking. During each DA epoch (approximately 8 hours), DA nodes are assigned to several quorums. Within each quorum, nodes are assigned numbers 0 through 3071. Each number is assigned to exactly one node, but a node may be assigned to multiple quorums, depending on its staking weight.

## DA Processing Flow

DA takes an input of data up to 32,505,852 bytes in length and processes it as follows:

1. **Padding and Size Encoding:**
   - Pad the data with zeros until it reaches 32,505,852 bytes
   - Add a little-endian format 4-byte integer at the end to indicate the original input size

2. **Matrix Formation:**
   - Slice the padded data into a 1024-row by 1024-column matrix, filling each row consecutively, with each element being 31 bytes
   - Pad each 31-byte element with an additional 1-byte zero, making it 32 bytes per element

3. **Redundant Encoding:**
   - Expand the data to a 3072-row by 1024-column matrix using redundancy coding
   - Calculate the **erasure commitment** and **data root** of the expanded matrix

4. **Submission to DA Contract:**
   - Submit the erasure commitment and data root to **the DA contract** and pay the fee
   - The DA contract will determine the epoch to which the data belongs and assign a quorum

5. **Data Distribution:**
   - Send the erasure commitment, data root, each row of the matrix, and necessary proofs of correctness to the corresponding DA nodes

6. **Signature Aggregation:**
   - More than 2/3 of the DA nodes sign the erasure commitment and data root
   - Aggregate the signatures using the BLS signature algorithm and submit the aggregated signature to the DA contract

### Details of Erasure Encoding

After matrix formation, each element is processed into a 32-byte data unit, which can be viewed interchangeably as either 32 bytes of data or a 256-bit little-endian integer. Denote the element in the $i$-th row and $j$-th column as $c_{i,j}$.

Let the finite field $\mathbb{F}$ be the scalar field of the [BN254 curve](https://docs.rs/ark-bn254/latest/ark_bn254/). Each element $c_{i,j}$ is also considered an integer within the finite field $\mathbb{F}$. Let $p$ be the order of $\mathbb{F}$, a known large number that can be expressed as $2^{28} \times A + 1$, where $A$ is an odd number. The number 3 is a generator of the multiplicative group of the $\mathbb{F}$. Define $u = 3^{2^6 \times A}$ and $w=3^{2^8\times A}$, so $w^{2^{20}} = 1$ and $u^4=w$.

Now we define a polynomial $f$ over $\mathbb{F}\rightarrow\mathbb{F}$ with degree $d=2^{20}-1$ satisfying

$\forall\, 0\le i< 1024,\, 0\le j< 1024,\,f\left(w^{1024j+i}\right)=c_{i,j}$

Then we extend the $1024\times1024$ matrix into $1024\times 3072$ matrix, where

$\forall\, 1024\le i< 2048,\, 0\le j< 1024,\,c_{i,j}=f\left(u^2\cdot w^{1024j+(i-1024)}\right)$

$\forall\, 2048\le i< 3072,\, 0\le j< 1024,\,c_{i,j}=f\left(u\cdot w^{1024j+(i-2048)}\right)$

The **erasure commitment** is the KZG commitment of $f$, defined as $f(\tau)\cdot G$, where $G$ is the starting point of BN254 G1 curve, and $\tau$ is a latent parameter from the [perpetual powers of tau trusted setup ceremony](https://github.com/privacy-scaling-explorations/perpetualpowersoftau).

The **data root** is defined as the input root by treating the 1024\*3072 32-byte elements as a continuous storage submission input. Specifically, according to the storage submission requirements, these data does not need to pad any zeros, and will be divided into a 16384-element sector array and an 8192-element sector array.

DA nodes need to verify two parts:

1. The consistency between the received slice and the data root, mainly achieved through Merkle proofs
2. The consistency between the received slice and the erasure commitment, verified using KZG proofs. Here, we use the AMT protocol optimization introduced in [LVMT](https://www.usenix.org/system/files/osdi23-li-chenxing.pdf) to reduce the proving overhead

## DA Sampling

The blockchain will periodically release DA Sampling tasks at preset height every `SAMPLE_PERIOD` blocks, with the parent block hash of these heights used as the `sampleSeed` for DA Sampling.

### List of Parameters

**Constant parameters**

| Parameter | Requirement | Default value |
|-----------|-------------|---------------|
| MAX_PODAS_TARGET | | 2^256 / 128 - 1 |

**Admin adjustable parameters**

| Parameter | Requirement | Default value | Code |
|-----------|-------------|---------------|------|
| TARGET_SUBMITS | | 20 | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L296) |
| EPOCH_WINDOW_SIZE | | 300 (about 3 months) | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L306) |
| SAMPLE_PERIOD | | 30 (about 1.5 minutes) | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L323) |

### Responses

During each period, each DA slice (one row) can be divided into 32 sub-lines. For each sub-line, the `podasQuality` will be computed using the `dataRoot` and assigned `epoch` and `quorumId` of its corresponding DA blob.

:::note
By default, all integers are in 256-bit big-endian format when computing hash values. `lineIndex` is the only exception, which is in 64-bit big-endian format.
:::

The hash value can be viewed interchangeably as either 32 bytes of data or a 256-bit big-endian integer.

```python
lineQuality = keccak256(sampleSeed, epoch, quorumId, dataRoot, lineIndex);
dataQuality = keccak256(lineQuality, sublineIndex, data);
podasQuality = lineQuality + dataQuality
```

If the `podasQuality` is less than the current `podasTarget` in the DA contract and the `epoch` falls within `[currentEpoch - EPOCH_WINDOW_SIZE, currentEpoch)`, then this sub-line is regarded as a **valid DAS response** and is eligible for the reward. The DA node assigned to this row can claim the reward.

During a sample period, at most `TARGET_SUBMITS √ó 2` DAS responses can be submitted and rewarded; any submissions exceeding this limit will be rejected.

### Difficulty Adjustment

`TARGET_SUBMITS` valid responses are expected in a sample period. If more or fewer responses are submitted during a sample period, the `podasTarget` will be adjusted as follows:

```python
podasTarget -= podasTarget * (actualSubmits - TARGET_SUBMITS) / TARGET_SUBMITS / 8
```

## Economic Model

### List of Parameters

**Admin adjustable parameters**

| Parameter | Requirement | Default value | Code |
|-----------|-------------|---------------|------|
| BASE_REWARD | | 0 | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L318) |
| BLOB_PRICE | | 0 | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L331) |
| SERVICE_FEE_RATE_BP | | 0 | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L336) |
| REWARD_RATIO | [1] | 1,200,000 | [Link](https://github.com/0gfoundation/0g-da-contract/blob/3951565fb6ad3096634da6493e9e863bb2846611/contracts/DAEntrance.sol#L312) |

[1] `TARGET_SUBMITS` √ó Time elapsed for `EPOCH_WINDOW_SIZE` epochs / Time elapsed in `SAMPLE_PERIOD` / `REWARD_RATIO` should be approximately 0.5 to 2.

### Pricing

When users submit the metadata for a DA blob, they need to pay a fee in amount of `BLOB_PRICE`.

### Reward

When a DA epoch ends, all the rewards from that DA epoch will be stored in the DA reward pool. Each time a valid response is submitted, `1 / REWARD_RATIO` of the reward pool will be distributed to the corresponding DA node.

### System Rewards

In the early stages of the ecosystem, the foundation can reserve a portion of tokens for system rewards. When the DA node submits a valid response, an additional reward of `BASE_REWARD` will be issued.

The funds for the base reward will be manually deposited into the reward contract and tracked separately. If the balance for the base reward is insufficient to cover a single base reward, miners will not be able to receive the full base reward.

### Service Fee

A system service fee is charged as a proportion of the DA fees paid by the user, according to the parameter `SERVICE_FEE_RATE_BP`.

## Run a Node

See [here](/run-a-node/da-node) for instructions to become DA signer and run your own node.

---

*Ready to dive deeper into 0G DA? Join our [Discord](https://discord.gg/0glabs) for technical discussions.*

---

## DA Client Nodes

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 0G Data Availability (DA): Integration

To submit data to the 0G DA, you must run a DA Client node and the Encoder node. The DA client interfaces with the Encoder for data encoding and the Retriever for data access.

## Overview

### Maximum Blob Size
Users can submit data blobs up to 32,505,852 bytes in length, which are then processed, encoded, and distributed across a network of DA nodes. The system employs a sophisticated data processing flow that includes padding, matrix formation, redundant encoding, and signature aggregation.

### Fee Market
As the DA user, you pay a fee which is the (BLOB_PRICE) when submitting DA blob data.

### Submitting Data
See example here: https://github.com/0gfoundation/0g-da-example-rust/blob/main/src/disperser.proto

## Hardware Requirements

The following table outlines the hardware requirements for different types of DA Client nodes:

| Node Type | Memory | CPU | Disk | Bandwidth | Additional Notes |
|-----------|--------|-----|------|-----------|------------------|
| DA Client | 8 GB | 2 cores | - | 100 MBps | For Download / Upload |
| DA Encoder | - | - | - | - | NVIDIA Drivers: 12.04 on the RTX 4090* |
| DA Retriever | 8 GB | 2 cores | - | 100 MBps | For Download / Upload |

## Standing up DA Client, Encoder, Retriever

<Tabs>
<TabItem value="binary" label="DA Client" default>

## DA Client Node Installation

**1. Clone the DA Client Node Repo**

```bash
git clone https://github.com/0gfoundation/0g-da-client.git
```

**2. Build the Docker Image**

```bash
cd 0g-da-client
docker build -t 0g-da-client -f combined.Dockerfile .
```

**3. Set Environment Variables**

Create a file named `envfile.env` with the following content. Be sure you paste in your private key.

```bash
# envfile.env
COMBINED_SERVER_CHAIN_RPC=https://evmrpc-testnet.0g.ai
COMBINED_SERVER_PRIVATE_KEY=YOUR_PRIVATE_KEY
ENTRANCE_CONTRACT_ADDR=0x857C0A28A8634614BB2C96039Cf4a20AFF709Aa9

COMBINED_SERVER_RECEIPT_POLLING_ROUNDS=180
COMBINED_SERVER_RECEIPT_POLLING_INTERVAL=1s
COMBINED_SERVER_TX_GAS_LIMIT=2000000
COMBINED_SERVER_USE_MEMORY_DB=true
COMBINED_SERVER_KV_DB_PATH=/runtime/
COMBINED_SERVER_TimeToExpire=2592000
DISPERSER_SERVER_GRPC_PORT=51001
BATCHER_DASIGNERS_CONTRACT_ADDRESS=0x0000000000000000000000000000000000001000
BATCHER_FINALIZER_INTERVAL=20s
BATCHER_CONFIRMER_NUM=3
BATCHER_MAX_NUM_RETRIES_PER_BLOB=3
BATCHER_FINALIZED_BLOCK_COUNT=50
BATCHER_BATCH_SIZE_LIMIT=500
BATCHER_ENCODING_INTERVAL=3s
BATCHER_ENCODING_REQUEST_QUEUE_SIZE=1
BATCHER_PULL_INTERVAL=10s
BATCHER_SIGNING_INTERVAL=3s
BATCHER_SIGNED_PULL_INTERVAL=20s
BATCHER_EXPIRATION_POLL_INTERVAL=3600
BATCHER_ENCODER_ADDRESS=DA_ENCODER_SERVER
BATCHER_ENCODING_TIMEOUT=300s
BATCHER_SIGNING_TIMEOUT=60s
BATCHER_CHAIN_READ_TIMEOUT=12s
BATCHER_CHAIN_WRITE_TIMEOUT=13s
```

**4. Run the Docker Node**

```bash
docker run -d --env-file envfile.env --name 0g-da-client -v ./run:/runtime -p 51001:51001 0g-da-client combined
```

## Configuration

| Field | Description |
|-------|-------------|
| `--chain.rpc` | JSON RPC node endpoint for the blockchain network. |
| `--chain.private-key` | Hex-encoded signer private key. |
| `--chain.receipt-wait-rounds` | Maximum retries to wait for transaction receipt. |
| `--chain.receipt-wait-interval` | Interval between retries when waiting for transaction receipt. |
| `--chain.gas-limit` | Transaction gas limit. |
| `--combined-server.use-memory-db` | Whether to use mem-db for blob storage. |
| `--combined-server.storage.kv-db-path` | Path for level db. |
| `--combined-server.storage.time-to-expire` | Expiration duration for blobs in level db. |
| `--combined-server.log.level-file` | File log level. |
| `--combined-server.log.level-std` | Standard output log level. |
| `--combined-server.log.path` | Log file path. |
| `--disperser-server.grpc-port` | Server listening port. |
| `--disperser-server.retriever-address` | GRPC host for retriever. |
| `--batcher.da-entrance-contract` | Hex-encoded da-entrance contract address. |
| `--batcher.da-signers-contract` | Hex-encoded da-signers contract address. |
| `--batcher.finalizer-interval` | Interval for finalizing operations. |
| `--batcher.finalized-block-count` | Default number of blocks between finalized block and latest block. |
| `--batcher.confirmer-num` | Number of Confirmer threads. |
| `--batcher.max-num-retries-for-sign` | Number of retries before signing fails. |
| `--batcher.batch-size-limit` | Maximum batch size in MiB. |
| `--batcher.encoding-request-queue-size` | Size of the encoding request queue. |
| `--batcher.encoding-interval` | Interval between blob encoding requests. |
| `--batcher.pull-interval` | Interval for pulling from the encoded queue. |
| `--batcher.signing-interval` | Interval between slice signing requests. |
| `--batcher.signed-pull-interval` | Interval for pulling from the signed queue. |
| `--encoder-socket` | GRPC host of the encoder. |
| `--encoding-timeout` | Total time to wait for a response from encoder. |
| `--signing-timeout` | Total time to wait for a response from signer. |

</TabItem>
<TabItem value="source" label="DA Encoder">

## Features

- `parallel`: Uses parallel algorithms for computations, maximizing CPU resource utilization.
- `cuda`: Uses GPU for computations, applicable only on platforms with NVIDIA GPUs.

:::note
GPU support is currently tested with NVIDIA 12.04 drivers on the RTX 4090. Other NVIDIA GPUs may require parameter adjustments and have not been tuned yet.
:::

## Preparation

### Install Rust

Ensure you have curl installed.

Run the following command to install Rust:

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

After installation, add the cargo bin directory to your PATH environment variable:

```bash
source $HOME/.cargo/env
```

Verify the installation:

```bash
rustc --version
```

### Install other dependencies

```bash
# Install Protocol Buffers Compiler
sudo apt-get install -y protobuf-compiler

# Install a specific nightly Rust toolchain and rustfmt
rustup toolchain install nightly-2024-02-04-x86_64-unknown-linux-gnu
rustup component add --toolchain nightly-2024-02-04-x86_64-unknown-linux-gnu rustfmt

# Add the necessary Rust target
rustup target add x86_64-unknown-linux-gnu
```

### Install CUDA (for GPU feature)

Ensure you have an NVIDIA GPU with the required drivers. Then follow the instructions from [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit).

Verify the installation:

```bash
nvidia-smi
nvcc --version
```

## Building Public Parameters

The public parameters for the cryptographic protocol are built in two steps:

### 1. Download and process the perpetual power of tau

We use the challenge_0084 file from the nearly most recent submission.

```bash
curl https://pse-trusted-setup-ppot.s3.eu-central-1.amazonaws.com/challenge_0084 -o challenge_0084
```

### 2. Build the AMT parameters

You can either construct these parameters yourself or download pre-built files.

#### Choice 1: Download the pre-built files

```bash
./dev-support/download_params.sh
```

#### Choice 2: Construct the parameters yourself

```bash
./dev_support/build_params.sh challenge_0084
```

## Running the Server

Run the server with the following command:

```bash
cargo run -r -p server --features grpc/parallel,grpc/cuda -- --config run/config.toml
```

:::note
If you do not have a CUDA environment, remove the cuda feature.
:::

DA Encoder will serve on port 34000 with specified gRPC interface.

## Using the Verification Logic

Add the following to `Cargo.toml` of your crate:

```toml
zg-encoder = { git = "https://github.com/0gfoundation/0g-da-encoder.git" }
```

Use the `zg_encoder::EncodedSlice::verify` function for verifying.

## Benchmark the Performance

Run the following task:

```bash
cargo bench -p grpc --features grpc/parallel,grpc/cuda --bench process_data --features zg-encoder/production_mode -- --nocapture
```

## Development and Testing

Run the following script for complete testing:

```bash
./dev_support/test.sh
```

</TabItem>
<TabItem value="docker" label="DA Retriever">

## DA Retriever Node Installation

**1. Clone the DA Retriever Node Repo**

```bash
git clone https://github.com/0gfoundation/0g-da-retriever.git
cd 0g-da-retriever
```

**2. Edit Files**

Add the following line to Dockerfile.dockerignore file:

```bash
!/run/config.toml
```

Replace Dockerfile with the following:

```dockerfile
# Dockerfile
FROM rust:alpine3.20 as builder

WORKDIR /0g-da-retriever
COPY . .

RUN apk update && apk add --no-cache make protobuf-dev musl-dev
RUN cargo build --release

FROM alpine:3.20

WORKDIR /0g-da-retriever

COPY --from=builder /0g-da-retriever/target/release/retriever /usr/local/bin/retriever
# Copy the config file into the container
COPY --from=builder /0g-da-retriever/run/config.toml ./run/config.toml

# Set the entrypoint to run the retriever binary
CMD ["/usr/local/bin/retriever"]
```

Replace the Config impl in `/retriever/src/config.rs` with the following:

```rust
impl Config {
    pub fn from_cli_file() -> Result<Self> {
        let matches = cli::cli_app().get_matches();
        let config_file = matches
            .get_one::<String>("config")
            .map(|s| s.as_str())
            .unwrap_or("/0g-da-retriever/run/config.toml");

        let c = RawConfig(
            config::Config::builder()
                .add_source(config::File::with_name(config_file))
                .build()?,
        );

        Ok(Self {
            log_level: c.get_string("log_level")?,
            eth_rpc_url: c.get_string("eth_rpc_endpoint")?,
            grpc_listen_address: c.get_string("grpc_listen_address")?,
            max_ongoing_retrieve_request: c.get_u64_opt("max_ongoing_retrieve_request")?,
        })
    }
}
```

**3. Update Configuration**

Update configuration file `run/config.toml` as needed with context below.

| Field | Description |
|-------|-------------|
| log_level | Set log level. |
| grpc_listen_address | Server listening address. |
| eth_rpc_endpoint | JSON RPC node endpoint for the blockchain network. |

**4. Build and Run the Docker Node**

```bash
docker build -t 0g-da-retriever . 
docker run -d --name 0g-da-retriever -p 34005:34005 0g-da-retriever
```

</TabItem>
</Tabs>

## Troubleshooting

<details>
<summary>DA Client connection issues</summary>

- Verify the RPC endpoint is accessible
- Check that your private key has sufficient funds for gas
- Ensure the contract addresses are correct for your network
- Review logs: `docker logs 0g-da-client`
</details>

<details>
<summary>Encoder GPU not detected</summary>

- Verify NVIDIA drivers are installed: `nvidia-smi`
- Check CUDA installation: `nvcc --version`
- Ensure Docker has GPU access if using containers
- Try running without cuda feature if GPU is not available
</details>

<details>
<summary>Retriever fails to start</summary>

- Check that port 34005 is not already in use
- Verify the Ethereum RPC endpoint is accessible
- Ensure config.toml is properly formatted
- Review container logs for specific errors
</details>

## Next Steps

- **Integration Examples** ‚Üí [DA Examples Repository](https://github.com/0gfoundation/0g-da-example-rust)
- **Join Community** ‚Üí [Discord](https://discord.gg/0glabs) for support
- **Run a DA Node** ‚Üí [DA Node Guide](/run-a-node/da-node)

---

*Ready to integrate 0G DA into your application? Start with the DA Client and connect to the network.*

---

## Goldsky Subgraphs

# Indexing 0G with Goldsky

Goldsky is Web3's real-time data platform, giving developers the fastest way to query, stream, and scale onchain data without worrying about maintaining infrastructure.

With resilient subgraphs and flexible data streaming pipelines, you can focus on building great user experiences while Goldsky handles the heavy lifting of indexing.

## Why Goldsky?

- **Reliable Performance**: Scalable infra built to handle data challenges as your app grows.
- **Intuitive Tools**: Easily integrate without being slowed down by complex data engineering.
- **24/7 Support**: Goldsky offers [support](https://docs.goldsky.com/getting-support) when you need to fix bugs or optimize deployments.

---

## Goldsky Products

### Subgraphs

**Subgraphs** make blockchain data queryable with GraphQL endpoints so you can easily fetch specifically only the data your app needs.

- **Fast Queries**: Optimized for low latency and high throughput.
- **Customizable**: Tailor indexing logic to your app's exact needs.
- **Organized & Scalable**: Tagging and versioning keep data clean as your project grows.

**Typical Use Cases**: dApps, NFT marketplaces, gaming, DAOs, or any app needing reliable onchain data.

### Mirror

**Mirror** streams decoded blockchain data directly into your database so you can own your data and have full control over what to do with it.

- **Realtime Streaming**: Stream onchain activity straight into your existing systems.
- **Combine Data Sources**: Access data across multiple chains and join it with your own offchain data.
- **Continuously Synced**: Automatic updates keep everything accurate and fresh.

**Typical Use Cases**: Advanced analytics, loyalty programs, points/leaderboards, user progress tracking, custom dashboards, or app requiring rich onchain data joined with other datasets.

---

## Getting Started

Check out the [Goldsky docs](https://docs.goldsky.com/chains/0g) to start indexing today. Build smarter, scale faster, and deliver seamless experiences to your users.

---

## ERC-7857 Standard

# ERC-7857: Technical Standard

## Overview

ERC-7857 extends ERC-721 to support encrypted metadata, specifically designed for tokenizing AI agents and sensitive digital assets.

:::info Prerequisites
- Understanding of ERC-721 NFT standard
- Basic cryptography knowledge (encryption, hashing)
- Smart contract development experience
- Familiarity with oracle systems
:::

### Document Purpose
This page provides the technical specification, implementation details, and security considerations for ERC-7857. For high-level concepts, see the **[INFT Overview](./inft-overview)**.

## Key Technical Features

| Feature | Description | Benefit |
|---------|-------------|--------|
| **Encrypted Metadata** | Store sensitive data securely | Protects proprietary AI models |
| **Secure Re-encryption** | Transfer without data exposure | Maintains privacy during ownership changes |
| **Oracle Verification** | TEE/ZKP proof validation | Ensures transfer integrity |
| **Authorized Usage** | Grant access without ownership | Enables AI-as-a-Service models |

## Technical Specification

### Core Interface

```solidity
interface IERC7857 is IERC721 {
    // Transfer with metadata re-encryption
    function transfer(
        address from,
        address to,
        uint256 tokenId,
        bytes calldata sealedKey,
        bytes calldata proof
    ) external;
    
    // Clone token with same metadata
    function clone(
        address to,
        uint256 tokenId,
        bytes calldata sealedKey,
        bytes calldata proof
    ) external returns (uint256 newTokenId);
    
    // Authorize usage without revealing data
    function authorizeUsage(
        uint256 tokenId,
        address executor,
        bytes calldata permissions
    ) external;
}
```

### Transfer Architecture

  

**Security Guarantees:**

‚úÖ Metadata remains encrypted throughout process  
‚úÖ Only new owner can decrypt transferred data  
‚úÖ Transfer integrity cryptographically verified  
‚úÖ No intermediary can access sensitive information  

## Oracle Implementations

ERC-7857 supports two oracle types for secure metadata re-encryption:

### TEE (Trusted Execution Environment)

**How it works:**
1. Sender transmits encrypted data + key to TEE
2. TEE securely decrypts data in isolated environment
3. TEE generates new key and re-encrypts metadata
4. TEE encrypts new key with receiver's public key
5. TEE outputs sealed key and hash values

**Advantages:**
- Hardware-level security guarantees
- TEE can generate cryptographically secure keys
- Attestation provides proof of secure execution

  

#### TEE Implementation Example

```javascript
class TEEOracle {
    async processTransfer(encryptedData, oldKey, receiverPublicKey) {
        // All operations happen inside secure enclave
        try {
            // Step 1: Decrypt original data
            const data = await this.decryptSecurely(encryptedData, oldKey);
            
            // Step 2: Generate new encryption key
            const newKey = await this.generateSecureKey();
            
            // Step 3: Re-encrypt with new key
            const newEncryptedData = await this.encryptSecurely(data, newKey);
            
            // Step 4: Seal key for receiver
            const sealedKey = await this.sealForReceiver(newKey, receiverPublicKey);
            
            // Step 5: Generate attestation proof
            const proof = await this.generateAttestation({
                originalHash: hash(encryptedData),
                newHash: hash(newEncryptedData),
                receiverKey: receiverPublicKey
            });
            
            return {
                newEncryptedData,
                sealedKey,
                proof
            };
        } catch (error) {
            throw new Error(`TEE processing failed: ${error.message}`);
        }
    }
}
```

### ZKP (Zero-Knowledge Proof)

**How it works:**
1. Sender provides old and new keys to ZKP system
2. ZKP circuit verifies correct re-encryption
3. Proof generated without revealing keys or data
4. Smart contract validates ZKP proof

**Considerations:**
- Cannot independently generate new keys
- Requires sender to handle key generation
- Receivers should rotate keys post-transfer
- Computationally intensive proof generation

  

#### ZKP Circuit Example

```rust
// ZKP circuit for verifying re-encryption
use ark_relations::r1cs::SynthesisError;

pub struct ReencryptionCircuit {
    // Public inputs (known to verifier)
    pub old_data_hash: Option<Fr>,
    pub new_data_hash: Option<Fr>,
    pub receiver_pubkey: Option<Fr>,
    
    // Private inputs (known only to prover)
    pub encrypted_data: Option<Vec<u8>>,
    pub old_key: Option<Vec<u8>>,
    pub new_key: Option<Vec<u8>>,
    pub plaintext_data: Option<Vec<u8>>,
}

impl ConstraintSynthesizer<Fr> for ReencryptionCircuit {
    fn generate_constraints(
        self,
        cs: ConstraintSystemRef<Fr>,
    ) -> Result<(), SynthesisError> {
        // Step 1: Verify decryption of original data
        let decrypted = decrypt_constraint(
            cs.clone(),
            &self.encrypted_data?,
            &self.old_key?
        )?;
        
        // Step 2: Verify plaintext matches decrypted data
        enforce_equal(
            cs.clone(),
            &decrypted,
            &self.plaintext_data?
        )?;
        
        // Step 3: Verify re-encryption with new key
        let reencrypted = encrypt_constraint(
            cs.clone(),
            &self.plaintext_data?,
            &self.new_key?
        )?;
        
        // Step 4: Verify hash consistency
        let computed_hash = hash_constraint(cs.clone(), &reencrypted)?;
        enforce_equal(
            cs,
            &computed_hash,
            &self.new_data_hash?
        )?;
        
        Ok(())
    }
}
```

## Implementation Guidelines

### Smart Contract Architecture

```solidity
pragma solidity ^0.8.19;

import "@openzeppelin/contracts/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/ReentrancyGuard.sol";

contract ERC7857 is ERC721, Ownable, ReentrancyGuard {
    // State variables
    mapping(uint256 => bytes32) private _metadataHashes;
    mapping(uint256 => string) private _encryptedURIs;
    mapping(uint256 => mapping(address => bytes)) private _authorizations;
    
    // Oracle configuration
    address public oracle;
    uint256 public constant PROOF_VALIDITY_PERIOD = 1 hours;
    
    // Events
    event MetadataUpdated(uint256 indexed tokenId, bytes32 newHash);
    event UsageAuthorized(uint256 indexed tokenId, address indexed executor);
    event OracleUpdated(address oldOracle, address newOracle);
    
    modifier validProof(bytes calldata proof) {
        require(oracle != address(0), "Oracle not set");
        require(IOracle(oracle).verifyProof(proof), "Invalid proof");
        _;
    }
    
    function transfer(
        address from,
        address to,
        uint256 tokenId,
        bytes calldata sealedKey,
        bytes calldata proof
    ) external nonReentrant validProof(proof) {
        require(ownerOf(tokenId) == from, "Not owner");
        require(to != address(0), "Invalid recipient");
        
        // Update metadata access for new owner
        _updateMetadataAccess(tokenId, to, sealedKey, proof);
        
        // Transfer NFT ownership
        _transfer(from, to, tokenId);
        
        emit MetadataUpdated(tokenId, keccak256(sealedKey));
    }
    
    function _updateMetadataAccess(
        uint256 tokenId,
        address newOwner,
        bytes calldata sealedKey,
        bytes calldata proof
    ) internal {
        // Verify proof contains correct metadata hash
        bytes32 expectedHash = _extractHashFromProof(proof);
        _metadataHashes[tokenId] = expectedHash;
        
        // Store new encrypted URI if provided
        string memory newURI = _extractURIFromProof(proof);
        if (bytes(newURI).length > 0) {
            _encryptedURIs[tokenId] = newURI;
        }
    }
}
```

### Metadata Management

```javascript
class MetadataManager {
    constructor(storageProvider, encryptionService, options = {}) {
        this.storage = storageProvider;
        this.encryption = encryptionService;
        this.options = {
            keySize: 256,
            algorithm: 'AES-GCM',
            ...options
        };
    }
    
    async storeMetadata(data, ownerPublicKey) {
        try {
            // Validate input data
            this._validateMetadata(data);
            
            // Generate encryption key
            const key = await this.encryption.generateKey({
                size: this.options.keySize,
                algorithm: this.options.algorithm
            });
            
            // Encrypt metadata
            const encrypted = await this.encryption.encrypt(data, key, {
                includeMac: true,
                version: '1.0'
            });
            
            // Store encrypted data on distributed storage
            const uri = await this.storage.store(encrypted, {
                redundancy: 3,
                availability: '99.9%'
            });
            
            // Seal key for owner using their public key
            const sealedKey = await this.encryption.sealForOwner(
                key,
                ownerPublicKey
            );
            
            // Generate metadata hash for verification
            const metadataHash = await this.encryption.hash(encrypted);
            
            return {
                uri,
                sealedKey,
                metadataHash,
                algorithm: this.options.algorithm,
                version: '1.0'
            };
        } catch (error) {
            throw new Error(`Metadata storage failed: ${error.message}`);
        }
    }
    
    async retrieveMetadata(uri, sealedKey, ownerPrivateKey) {
        try {
            // Fetch encrypted data from storage
            const encrypted = await this.storage.retrieve(uri);
            
            // Unseal the encryption key
            const key = await this.encryption.unsealKey(
                sealedKey,
                ownerPrivateKey
            );
            
            // Decrypt and return metadata
            const decrypted = await this.encryption.decrypt(encrypted, key);
            
            return decrypted;
        } catch (error) {
            throw new Error(`Metadata retrieval failed: ${error.message}`);
        }
    }
    
    _validateMetadata(data) {
        if (!data || typeof data !== 'object') {
            throw new Error('Invalid metadata format');
        }
        
        const maxSize = 10 * 1024 * 1024; // 10MB limit
        const serialized = JSON.stringify(data);
        if (serialized.length > maxSize) {
            throw new Error('Metadata exceeds size limit');
        }
    }
}
```

## Security Considerations

### üîë Key Management

**Best Practices:**
- Use hardware security modules (HSM) when available
- Implement automatic key rotation every 90 days
- Store private keys in secure enclaves or hardware wallets
- Never log or expose private keys in error messages

**Implementation:**
```javascript
class SecureKeyManager {
    constructor(hsmProvider) {
        this.hsm = hsmProvider;
        this.keyRotationInterval = 90 * 24 * 60 * 60 * 1000; // 90 days
    }
    
    async generateKey() {
        // Use HSM if available, fallback to secure random
        return this.hsm ? 
            await this.hsm.generateKey() : 
            await crypto.subtle.generateKey(/*...*/);;
    }
}
```

### üîÆ Oracle Security

**TEE Verification:**
- Always verify TEE attestations before accepting proofs
- Validate enclave signatures and measurement values
- Implement attestation freshness checks

**ZKP Auditing:**
- Audit circuit implementations thoroughly
- Verify trusted setup parameters
- Test edge cases and malformed inputs

**Fallback Mechanisms:**
```solidity
contract OracleManager {
    address[] public oracles;
    uint256 public minConfirmations = 2;
    
    function verifyWithFallback(bytes calldata proof) external view returns (bool) {
        uint256 confirmations = 0;
        for (uint i = 0; i < oracles.length; i++) {
            if (IOracle(oracles[i]).verifyProof(proof)) {
                confirmations++;
            }
        }
        return confirmations >= minConfirmations;
    }
}
```

### üõ°Ô∏è Metadata Privacy

**Encryption Standards:**
- Use AES-256-GCM for symmetric encryption
- Implement RSA-4096 or ECC-P384 for key sealing
- Always include authentication tags

**Storage Security:**
- Encrypt metadata before network transmission
- Use 0G Storage for decentralized, tamper-proof storage
- Implement zero-knowledge access controls

**Access Patterns:**
```javascript
// Secure metadata access pattern
async function accessMetadata(tokenId, requesterKey) {
    // 1. Verify ownership or authorization
    const isAuthorized = await verifyAccess(tokenId, requesterKey);
    if (!isAuthorized) throw new Error('Unauthorized');
    
    // 2. Retrieve encrypted metadata
    const encrypted = await storage.retrieve(getMetadataURI(tokenId));
    
    // 3. Decrypt only if authorized
    const decrypted = await decrypt(encrypted, requesterKey);
    
    return decrypted;
}
```

## Advanced Features

### Clone Functionality
The `clone()` function allows creating copies of INFTs while maintaining metadata security:

```solidity
function clone(
    address to,
    uint256 tokenId,
    bytes calldata sealedKey,
    bytes calldata proof
) external returns (uint256) {
    require(canClone(tokenId, msg.sender), "Not authorized");
    
    uint256 newTokenId = _mint(to);
    _copyMetadata(tokenId, newTokenId, sealedKey, proof);
    
    return newTokenId;
}
```

### Authorized Usage
Enable third parties to use INFT capabilities without ownership:

```solidity
function authorizeUsage(
    uint256 tokenId,
    address executor,
    bytes calldata permissions
) external {
    require(ownerOf(tokenId) == msg.sender, "Not owner");
    
    _authorizations[tokenId][executor] = permissions;
    
    emit UsageAuthorized(tokenId, executor);
}
```

## 0G Infrastructure Integration

### 0G Storage Integration
```javascript
// Store encrypted AI agent metadata
const metadata = {
    model: aiAgent.serializedModel,
    weights: aiAgent.trainedWeights,
    config: aiAgent.configuration
};

const encrypted = await encryptMetadata(metadata, ownerPublicKey);
const storageResult = await ogStorage.store(encrypted, {
    redundancy: 3,
    durability: '99.999%'
});

console.log(`Metadata stored at: ${storageResult.uri}`);
```

### 0G Compute Integration
```javascript
// Execute secure inference without exposing model
const inferenceResult = await ogCompute.executeSecure({
    tokenId: inftId,
    executor: authorizedExecutor,
    input: userQuery,
    verificationMode: 'TEE' // or 'ZKP'
});

// Result includes proof of correct execution
console.log(`Inference result: ${inferenceResult.output}`);
console.log(`Verification proof: ${inferenceResult.proof}`);
```

### 0G Chain Deployment
```javascript
// Deploy INFT contract to 0G Chain
const ERC7857Factory = await ethers.getContractFactory('ERC7857');
const inftContract = await ERC7857Factory.deploy(
    'AI Agent NFTs',
    'AINFT',
    oracleAddress,
    ogStorageAddress
);

await inftContract.deployed();
console.log(`INFT contract deployed at: ${inftContract.address}`);
```

## Resources & References

### Official Documentation
üìú **[EIP-7857 Specification](https://github.com/ethereum/EIPs/pull/7857)** - Official Ethereum standard proposal  
üíª **[Reference Implementation](https://github.com/0gfoundation/0g-agent-nft/tree/eip-7857-draft)** - Complete codebase with examples  
üîí **[Security Audit Reports](#)** - Third-party security assessments (coming soon)  

### Community & Support
üí¨ **[Developer Forum](https://discord.gg/0glabs)** - Technical discussions and Q&A  
üêõ **[GitHub Issues](https://github.com/0gfoundation/0g-agent-nft/issues)** - Bug reports and feature requests  
üìö **[Knowledge Base](https://kb.0g.ai)** - Common implementation patterns  

### Standards & Specifications
üìÑ **[ERC-721 Standard](https://eips.ethereum.org/EIPS/eip-721)** - Base NFT standard  
üîê **[Encryption Standards](https://csrc.nist.gov/projects/cryptographic-standards-and-guidelines)** - NIST cryptography guidelines  
üõ°Ô∏è **[TEE Specifications](https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions.html)** - Intel SGX documentation  

## Next Steps

### For Implementation
üöÄ **[Integration Guide](./integration)** - Step-by-step development guide  
üéØ **[Use Cases](./inft-overview#real-world-applications)** - Real-world implementation examples  
üìã **[Best Practices Guide](#)** - Production deployment guidelines (coming soon)  

### For Testing
üß™ **[Testnet Deployment](./integration#step-2-create-inft-smart-contract)** - Test your implementation  
üóóÔ∏è **[Oracle Testing](#)** - Verify TEE and ZKP implementations  
üîç **[Security Testing](#)** - Audit your contracts  

### Community
üí¨ **Join Discussions** - Share implementations and get feedback  
üöÄ **Contribute** - Help improve the standard and tooling  
üìö **Learn** - Explore advanced features and optimizations

---

## INFTs Overview

# INFTs: Tokenizing AI Agents

## What Are INFTs?

The rapid growth of AI agents necessitates new methods for managing their ownership, transfer, and capabilities within Web3 ecosystems. 

**INFTs (Intelligent Non-Fungible Tokens)** represent a significant advancement in this space, enabling the tokenization of AI agents with:

- **Transferability**: Move AI agents between owners securely
- **Decentralized control**: No single point of failure
- **Full asset ownership**: Complete control over AI capabilities
- **Royalty potential**: Monetize AI agent usage and transfers

:::tip Navigation Guide
- **This page**: High-level concepts and use cases
- **[ERC-7857 Standard](./erc7857)**: Technical implementation details
- **[Integration Guide](./integration)**: Step-by-step development guide
:::

## Why Traditional NFTs Don't Work for AI

Traditional NFT standards like ERC-721 and ERC-1155 have significant limitations when applied to AI agents:

### Key Problems

**üîì Static and Public Metadata**
- Existing standards link to static, publicly accessible metadata
- AI agents need dynamic metadata that reflects learning and evolution
- Sensitive AI data requires privacy protection

**üö´ Insecure Metadata Transfer**
- ERC-721 transfers only move ownership identifiers
- The underlying AI "intelligence" doesn't transfer
- New owners receive incomplete or non-functional agents

**üîí No Native Encryption**
- Current standards lack built-in encryption support
- Proprietary AI models remain exposed
- Sensitive user data can't be protected

## The INFT Solution: ERC-7857

ERC-7857 is a new NFT standard specifically designed to address AI agent requirements. It enables the creation, ownership, and secure transfer of INFTs with their complete intelligence intact.

### Revolutionary Features

**üõ°Ô∏è Privacy-Preserving Metadata**
- Encrypts sensitive AI "intelligence" data
- Protects proprietary information from exposure
- Maintains privacy throughout transfers

**üîÑ Secure Metadata Transfers**
- Both ownership AND encrypted metadata transfer together
- Verifiable transfer process ensures integrity
- New owners receive fully functional agents

**‚ö° Dynamic Data Management**
- Supports evolving AI agent capabilities
- Secure updates to agent state and behaviors
- Maintains functionality within NFT framework

**üåê Decentralized Storage Integration**
- Works with 0G Storage for permanent, tamper-proof storage
- Distributed access management
- No single point of failure

**‚úÖ Verifiable Ownership & Control**
- Cryptographic proofs validate all transfers
- Oracle-based verification ensures integrity
- Transparent ownership verification

**ü§ñ AI-Specific Functionality**
- Built-in agent lifecycle management
- Pre-execution ownership verification
- Specialized features for AI use cases

## How INFT Transfers Work

The transfer mechanism ensures both token ownership and encrypted metadata transfer securely together.

### Simple Transfer Flow

```
1. üì¶ Encrypt & Commit    ‚Üí  2. üîÑ Oracle Processing
          ‚Üì                           ‚Üì
6. ‚úÖ Access Granted     ‚Üê  3. üîê Re-encrypt for Receiver
          ‚Üë                           ‚Üì
5. ‚úì Verify & Finalize   ‚Üê  4. üóùÔ∏è Secure Key Delivery
```

<details>
<summary>Detailed Step-by-Step Process</summary>

1. **Encryption & Commitment**
   - AI agent metadata gets encrypted
   - Hash commitment created as authenticity proof
   - Content remains hidden

2. **Secure Transfer Initiation**
   - Trusted oracle (using TEEs) decrypts original metadata
   - Process happens in secure environment

3. **Re-encryption for Receiver**
   - Oracle generates new encryption key
   - Re-encrypts metadata with new key
   - Stores new encrypted metadata (e.g., on 0G Storage)

4. **Key Delivery**
   - New encryption key encrypted with receiver's public key
   - Only intended owner can access metadata key

5. **Verification & Finalization**
   - Smart contract verifies multiple proofs:
     - Sender's access rights
     - Oracle validation of metadata matching
     - Receiver's signed acknowledgment
   - If valid: ownership transfers + receiver gets encrypted key

6. **Access Granted**
   - Receiver uses private key to decrypt metadata key
   - Full access to agent's encrypted intelligence granted

</details>

  

:::note Technical Implementation
For detailed oracle implementations (TEE vs ZKP), security considerations, and code examples, see the **[ERC-7857 Technical Standard](./erc7857)**.
:::

### Additional Capabilities

**üß¨ Clone Function**
- Creates new token with same AI metadata
- Preserves original while enabling distribution
- Useful for AI agent templates

**üîê Authorized Usage**
- Grant usage rights without ownership transfer
- Sealed executor processes metadata securely
- Enable AI-as-a-Service models

## Real-World Applications

Secure AI agent tokenization opens up transformative possibilities:

### üè™ AI Agent Marketplaces
- Buy and sell trained AI agents with guaranteed capability transfer
- Secure marketplaces with verified agent functionality
- Transparent pricing and capability verification

### üéØ Personalized Automation
- Own AI agents tailored for specific tasks:
  - DeFi trading strategies
  - Airdrop claiming automation
  - Social media management
  - Research and analysis

### üè¢ Enterprise AI Solutions
- Build proprietary AI agents for internal use
- Securely transfer or lease agents to clients
- Maintain control over sensitive business logic

### üíº AI-as-a-Service (AIaaS)
- Tokenize AI agents for subscription models
- Granular usage permissions and billing
- Scalable service delivery

### ü§ù Agent Collaboration
- Combine multiple INFT agents for enhanced capabilities
- Create composite AI solutions
- Build AI agent ecosystems

### üí∞ IP Monetization
- AI developers monetize models as NFTs
- Maintain usage control and royalty collection
- Protect proprietary algorithms

## Powered by 0G Infrastructure

INFTs leverage the complete 0G ecosystem for optimal performance:

| Component | Role in INFTs | Key Benefits |
|-----------|---------------|-------------|
| **0G Storage** | Encrypted metadata storage | Secure, permanent, owner-only access |
| **0G DA** | Transfer proof verification | Guaranteed metadata availability |
| **0G Chain** | Smart contract execution | Fast, low-cost INFT operations |
| **0G Compute** | Secure AI inference | Private agent execution |

### Why This Matters

By combining INFTs with 0G's comprehensive AI infrastructure, developers can create sophisticated, transferable AI agents that maintain their intelligence, privacy, and functionality throughout their entire lifecycle.

:::info Complete AI Stack
0G provides the only complete infrastructure stack specifically designed for AI applications, making it the ideal foundation for INFT development.
:::

## Next Steps

### For Developers
üöÄ **[Integration Guide](./integration)** - Start building with INFTs  
üìã **[ERC-7857 Standard](./erc7857)** - Technical implementation details  
üíª **[GitHub Repository](https://github.com/0gfoundation/0g-agent-nft/tree/eip-7857-draft)** - Sample code and examples  

### For Users
üõí **[AI Agent Marketplace](#)** - Browse available AI agents (coming soon)  
üìö **[User Guide](#)** - How to buy, transfer, and use INFTs (coming soon)  

### Get Support
üí¨ **[Discord Community](https://discord.gg/0glabs)** - Ask questions and get help  
üìñ **[Documentation Hub](/)** - Complete 0G ecosystem guides  

:::tip Web3 Compatible
ERC-7857 is designed to be compatible with existing Web3 infrastructure while providing enhanced security and functionality for AI agent tokenization.
:::

---

## INFT Integration Guide


## Overview

This step-by-step guide shows you how to integrate INFTs into your applications using the 0G ecosystem. You'll learn to deploy contracts, manage metadata, and implement secure transfers.

:::tip Quick Navigation
- **New to INFTs?** Start with [INFT Overview](./inft-overview)
- **Need technical details?** See [ERC-7857 Standard](./erc7857)
- **Ready to build?** Continue with this guide
:::

## Prerequisites

### Knowledge Requirements
‚úÖ **NFT Standards** - Understanding of ERC-721 basics  
‚úÖ **Smart Contracts** - Solidity development experience  
‚úÖ **Cryptography** - Basic encryption and key management concepts  
‚úÖ **0G Ecosystem** - Familiarity with 0G infrastructure components  

### Technical Setup
‚úÖ **Development Environment** - Node.js 16+, Hardhat/Foundry  
‚úÖ **0G Testnet Account** - Wallet with testnet tokens  
‚úÖ **API Access** - Keys for 0G Storage and Compute services  

<details>
<summary>Quick Setup Checklist</summary>

```bash
# Install dependencies
npm install @0glabs/0g-ts-sdk ethers hardhat

# Set environment variables
export PRIVATE_KEY="your-private-key"
export OG_RPC_URL="https://evmrpc-testnet.0g.ai"
export OG_STORAGE_URL="https://storage-testnet.0g.ai"
export OG_COMPUTE_URL="https://compute-testnet.0g.ai"
```

</details>

## Understanding 0G Integration

INFTs work seamlessly with 0G's complete AI infrastructure:

| Component | Purpose | INFT Integration |
|-----------|---------|------------------|
| **0G Storage** | Encrypted metadata storage | Stores AI agent data securely |
| **0G DA** | Proof verification | Validates transfer integrity |
| **0G Chain** | Smart contract execution | Hosts INFT contracts |
| **0G Compute** | Secure AI inference | Runs agent computations privately |

:::note Why This Architecture Matters
This integration ensures that AI agents maintain their intelligence, privacy, and functionality throughout their entire lifecycle while remaining fully decentralized.
:::

## Step-by-Step Implementation

### Step 1: Initialize Your Project

```bash
# Create new project
mkdir my-inft-project && cd my-inft-project
npm init -y

# Install required dependencies
npm install @0glabs/0g-ts-sdk @openzeppelin/contracts ethers hardhat
npm install --save-dev @nomicfoundation/hardhat-toolbox

# Initialize Hardhat
npx hardhat init
```

**Configure environment:**
```bash
# Create .env file
cat > .env << EOF
PRIVATE_KEY=your_private_key_here
OG_RPC_URL=https://evmrpc-testnet.0g.ai
OG_STORAGE_URL=https://storage-testnet.0g.ai
OG_COMPUTE_URL=https://compute-testnet.0g.ai
EOF
```

### Step 2: Create INFT Smart Contract

```solidity
// contracts/INFT.sol
pragma solidity ^0.8.19;

import "@openzeppelin/contracts/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/ReentrancyGuard.sol";

interface IOracle {
    function verifyProof(bytes calldata proof) external view returns (bool);
}

contract INFT is ERC721, Ownable, ReentrancyGuard {
    // State variables
    mapping(uint256 => bytes32) private _metadataHashes;
    mapping(uint256 => string) private _encryptedURIs;
    mapping(uint256 => mapping(address => bytes)) private _authorizations;
    
    address public oracle;
    uint256 private _nextTokenId = 1;
    
    // Events
    event MetadataUpdated(uint256 indexed tokenId, bytes32 newHash);
    event UsageAuthorized(uint256 indexed tokenId, address indexed executor);
    
    constructor(
        string memory name,
        string memory symbol,
        address _oracle
    ) ERC721(name, symbol) {
        oracle = _oracle;
    }
    
    function mint(
        address to,
        string calldata encryptedURI,
        bytes32 metadataHash
    ) external onlyOwner returns (uint256) {
        uint256 tokenId = _nextTokenId++;
        _safeMint(to, tokenId);
        
        _encryptedURIs[tokenId] = encryptedURI;
        _metadataHashes[tokenId] = metadataHash;
        
        return tokenId;
    }
    
    function transfer(
        address from,
        address to,
        uint256 tokenId,
        bytes calldata sealedKey,
        bytes calldata proof
    ) external nonReentrant {
        require(ownerOf(tokenId) == from, "Not owner");
        require(IOracle(oracle).verifyProof(proof), "Invalid proof");
        
        // Update metadata access for new owner
        _updateMetadataAccess(tokenId, to, sealedKey, proof);
        
        // Transfer token ownership
        _transfer(from, to, tokenId);
        
        emit MetadataUpdated(tokenId, keccak256(sealedKey));
    }
    
    function authorizeUsage(
        uint256 tokenId,
        address executor,
        bytes calldata permissions
    ) external {
        require(ownerOf(tokenId) == msg.sender, "Not owner");
        _authorizations[tokenId][executor] = permissions;
        emit UsageAuthorized(tokenId, executor);
    }
    
    function _updateMetadataAccess(
        uint256 tokenId,
        address newOwner,
        bytes calldata sealedKey,
        bytes calldata proof
    ) internal {
        // Extract new metadata hash from proof
        bytes32 newHash = bytes32(proof[0:32]);
        _metadataHashes[tokenId] = newHash;
        
        // Update encrypted URI if provided in proof
        if (proof.length > 64) {
            string memory newURI = string(proof[64:]);
            _encryptedURIs[tokenId] = newURI;
        }
    }
    
    function getMetadataHash(uint256 tokenId) external view returns (bytes32) {
        return _metadataHashes[tokenId];
    }
    
    function getEncryptedURI(uint256 tokenId) external view returns (string memory) {
        return _encryptedURIs[tokenId];
    }
}
```

### Step 3: Deploy and Initialize Contract

**Create deployment script:**
```javascript
// scripts/deploy.js
const { ethers } = require("hardhat");

async function main() {
    const [deployer] = await ethers.getSigners();
    
    console.log("Deploying contracts with account:", deployer.address);
    
    // Deploy mock oracle for testing (replace with real oracle in production)
    const MockOracle = await ethers.getContractFactory("MockOracle");
    const oracle = await MockOracle.deploy();
    await oracle.deployed();
    
    // Deploy INFT contract
    const INFT = await ethers.getContractFactory("INFT");
    const inft = await INFT.deploy(
        "AI Agent NFTs",
        "AINFT",
        oracle.address
    );
    await inft.deployed();
    
    console.log("Oracle deployed to:", oracle.address);
    console.log("INFT deployed to:", inft.address);
}

main().catch((error) => {
    console.error(error);
    process.exitCode = 1;
});
```

**Deploy to 0G testnet:**
```bash
npx hardhat run scripts/deploy.js --network og-testnet
```

### Step 4: Implement Metadata Management

**Create metadata manager:**
```javascript
// lib/MetadataManager.js
const { ethers } = require('ethers');
const crypto = require('crypto');

class MetadataManager {
    constructor(ogStorage, encryptionService) {
        this.storage = ogStorage;
        this.encryption = encryptionService;
    }
    
    async createAIAgent(aiModelData, ownerPublicKey) {
        try {
            // Prepare AI agent metadata
            const metadata = {
                model: aiModelData.model,
                weights: aiModelData.weights,
                config: aiModelData.config,
                capabilities: aiModelData.capabilities,
                version: '1.0',
                createdAt: Date.now()
            };
            
            // Generate encryption key
            const encryptionKey = crypto.randomBytes(32);
            
            // Encrypt metadata
            const encryptedData = await this.encryption.encrypt(
                JSON.stringify(metadata),
                encryptionKey
            );
            
            // Store on 0G Storage
            const storageResult = await this.storage.store(encryptedData);
            
            // Seal key for owner
            const sealedKey = await this.encryption.sealKey(
                encryptionKey,
                ownerPublicKey
            );
            
            // Generate metadata hash
            const metadataHash = ethers.utils.keccak256(
                ethers.utils.toUtf8Bytes(JSON.stringify(metadata))
            );
            
            return {
                encryptedURI: storageResult.uri,
                sealedKey,
                metadataHash
            };
        } catch (error) {
            throw new Error(`Failed to create AI agent: ${error.message}`);
        }
    }
    
    async mintINFT(contract, recipient, aiAgentData) {
        const { encryptedURI, sealedKey, metadataHash } = aiAgentData;
        
        const tx = await contract.mint(
            recipient,
            encryptedURI,
            metadataHash
        );
        
        const receipt = await tx.wait();
        const tokenId = receipt.events[0].args.tokenId;
        
        return {
            tokenId,
            sealedKey,
            transactionHash: receipt.transactionHash
        };
    }
}

module.exports = MetadataManager;
```

### Step 5: Implement Secure Transfers

**Transfer preparation:**
```javascript
// lib/TransferManager.js
class TransferManager {
    constructor(oracle, metadataManager) {
        this.oracle = oracle;
        this.metadata = metadataManager;
    }
    
    async prepareTransfer(tokenId, fromAddress, toAddress, toPublicKey) {
        try {
            // Retrieve current metadata
            const currentURI = await this.metadata.getEncryptedURI(tokenId);
            const encryptedData = await this.storage.retrieve(currentURI);
            
            // Request oracle to re-encrypt for new owner
            const transferRequest = {
                tokenId,
                encryptedData,
                fromAddress,
                toAddress,
                toPublicKey
            };
            
            // Get oracle proof and new sealed key
            const oracleResponse = await this.oracle.processTransfer(transferRequest);
            
            return {
                sealedKey: oracleResponse.sealedKey,
                proof: oracleResponse.proof,
                newEncryptedURI: oracleResponse.newURI
            };
        } catch (error) {
            throw new Error(`Transfer preparation failed: ${error.message}`);
        }
    }
    
    async executeTransfer(contract, transferData) {
        const { from, to, tokenId, sealedKey, proof } = transferData;
        
        const tx = await contract.transfer(
            from,
            to,
            tokenId,
            sealedKey,
            proof
        );
        
        return await tx.wait();
    }
}
```

## Best Practices

### üîí Security Guidelines

**Key Management:**
- Store private keys in hardware wallets or HSMs
- Never expose keys in code or logs
- Implement automatic key rotation
- Use multi-signature wallets for critical operations

**Metadata Protection:**
```javascript
// Example: Secure metadata handling
class SecureMetadata {
    constructor() {
        this.encryptionAlgorithm = 'aes-256-gcm';
        this.keyDerivation = 'pbkdf2';
    }
    
    async encryptMetadata(data, password) {
        const salt = crypto.randomBytes(16);
        const key = crypto.pbkdf2Sync(password, salt, 100000, 32, 'sha512');
        const iv = crypto.randomBytes(16);
        
        const cipher = crypto.createCipher(this.encryptionAlgorithm, key, iv);
        // ... encryption logic
    }
}
```

### ‚ö° Performance Optimization

**Efficient Storage Patterns:**
- Compress metadata before encryption
- Use appropriate storage tiers based on access patterns
- Implement lazy loading for large AI models
- Cache frequently accessed data locally

**Batch Operations:**
```javascript
// Batch multiple operations
async function batchMintINFTs(agents, recipients) {
    const operations = agents.map((agent, i) => 
        metadataManager.createAIAgent(agent, recipients[i])
    );
    
    const results = await Promise.all(operations);
    return results;
}
```

### üß™ Testing Strategy

**Comprehensive Test Suite:**
```javascript
// test/INFT.test.js
describe('INFT Contract', function () {
    it('should mint INFT with encrypted metadata', async function () {
        const metadata = await createTestMetadata();
        const result = await inft.mint(owner.address, metadata.uri, metadata.hash);
        expect(result).to.emit(inft, 'Transfer');
    });
    
    it('should transfer with re-encryption', async function () {
        // Test secure transfer logic
    });
    
    it('should authorize usage without ownership transfer', async function () {
        // Test authorization functionality
    });
});
```

**Security Testing:**
- Test with malformed proofs
- Verify access controls
- Check for reentrancy vulnerabilities
- Validate oracle responses

## Real-World Use Cases

### üè™ AI Agent Marketplace

**Complete marketplace integration:**
```javascript
// marketplace/AgentMarketplace.js
class AgentMarketplace {
    constructor(inftContract, paymentToken) {
        this.inft = inftContract;
        this.payment = paymentToken;
        this.listings = new Map();
    }
    
    async listAgent(tokenId, price, description) {
        // Verify ownership
        const owner = await this.inft.ownerOf(tokenId);
        require(owner === msg.sender, 'Not owner');
        
        // Create listing
        const listing = {
            tokenId,
            price,
            description,
            seller: owner,
            isActive: true
        };
        
        this.listings.set(tokenId, listing);
        
        // Approve marketplace for transfer
        await this.inft.approve(this.address, tokenId);
        
        return listing;
    }
    
    async purchaseAgent(tokenId, buyerPublicKey) {
        const listing = this.listings.get(tokenId);
        require(listing && listing.isActive, 'Agent not for sale');
        
        // Prepare secure transfer
        const transferData = await this.prepareTransfer(
            tokenId,
            listing.seller,
            msg.sender,
            buyerPublicKey
        );
        
        // Execute payment
        await this.payment.transferFrom(msg.sender, listing.seller, listing.price);
        
        // Execute secure transfer
        await this.inft.transfer(
            listing.seller,
            msg.sender,
            tokenId,
            transferData.sealedKey,
            transferData.proof
        );
        
        // Remove listing
        this.listings.delete(tokenId);
    }
}
```

### üíº AI-as-a-Service Platform

**Usage authorization system:**
```javascript
// services/AIaaS.js
class AIaaSPlatform {
    async createSubscription(tokenId, subscriber, duration, permissions) {
        // Verify agent ownership
        const owner = await this.inft.ownerOf(tokenId);
        
        // Create usage authorization
        const authData = {
            subscriber,
            expiresAt: Date.now() + duration,
            permissions: {
                maxRequests: permissions.maxRequests,
                allowedOperations: permissions.operations,
                rateLimit: permissions.rateLimit
            }
        };
        
        // Grant usage rights
        await this.inft.authorizeUsage(
            tokenId,
            subscriber,
            ethers.utils.toUtf8Bytes(JSON.stringify(authData))
        );
        
        return authData;
    }
    
    async executeAuthorizedInference(tokenId, input, subscriber) {
        // Verify authorization
        const auth = await this.getAuthorization(tokenId, subscriber);
        require(auth && auth.expiresAt > Date.now(), 'Unauthorized');
        
        // Execute inference on 0G Compute
        const result = await this.ogCompute.executeSecure({
            tokenId,
            executor: subscriber,
            input,
            verificationMode: 'TEE'
        });
        
        // Update usage metrics
        await this.updateUsageMetrics(tokenId, subscriber);
        
        return result;
    }
}
```

### ü§ù Multi-Agent Collaboration

**Agent composition framework:**
```javascript
// collaboration/AgentComposer.js
class AgentComposer {
    async composeAgents(agentTokenIds, compositionRules) {
        // Verify ownership of all agents
        for (const tokenId of agentTokenIds) {
            const owner = await this.inft.ownerOf(tokenId);
            require(owner === msg.sender, `Not owner of agent ${tokenId}`);
        }
        
        // Create composite agent metadata
        const compositeMetadata = {
            type: 'composite',
            agents: agentTokenIds,
            rules: compositionRules,
            createdAt: Date.now()
        };
        
        // Encrypt and store composite metadata
        const encryptedComposite = await this.metadataManager.createAIAgent(
            compositeMetadata,
            msg.sender
        );
        
        // Mint new INFT for composite agent
        const result = await this.inft.mint(
            msg.sender,
            encryptedComposite.encryptedURI,
            encryptedComposite.metadataHash
        );
        
        return result.tokenId;
    }
    
    async executeCompositeInference(compositeTokenId, input) {
        // Retrieve composite metadata
        const metadata = await this.getDecryptedMetadata(compositeTokenId);
        
        // Execute inference on each component agent
        const agentResults = await Promise.all(
            metadata.agents.map(agentId => 
                this.executeAgentInference(agentId, input)
            )
        );
        
        // Apply composition rules to combine results
        const finalResult = this.applyCompositionRules(
            agentResults,
            metadata.rules
        );
        
        return finalResult;
    }
}
```

## Troubleshooting

### Common Issues & Solutions

<details>
<summary>Transfer Failures</summary>

**Problem**: INFT transfer transaction reverts

**Causes & Solutions**:
- **Invalid proof**: Verify oracle is online and proof is correctly formatted
- **Expired proof**: Generate new proof (proofs have limited validity)
- **Wrong owner**: Ensure `from` address matches actual token owner
- **Oracle unavailable**: Check oracle service status

```javascript
// Debug transfer issues
async function debugTransfer(tokenId, proof) {
    const owner = await inft.ownerOf(tokenId);
    console.log(`Token owner: ${owner}`);
    
    const isValidProof = await oracle.verifyProof(proof);
    console.log(`Proof valid: ${isValidProof}`);
    
    // Check oracle status
    const oracleStatus = await oracle.getStatus();
    console.log(`Oracle status: ${oracleStatus}`);
}
```

</details>

<details>
<summary>Metadata Access Issues</summary>

**Problem**: Cannot decrypt or access AI agent metadata

**Solutions**:
- Verify private key corresponds to sealed key
- Check storage URI accessibility
- Ensure metadata hasn't been corrupted
- Validate encryption algorithm compatibility

```javascript
// Test metadata access
async function testMetadataAccess(tokenId, privateKey) {
    try {
        const encryptedURI = await inft.getEncryptedURI(tokenId);
        const encryptedData = await storage.retrieve(encryptedURI);
        
        // Attempt decryption
        const sealedKey = await getSealedKey(tokenId);
        const key = await unsealKey(sealedKey, privateKey);
        const metadata = await decrypt(encryptedData, key);
        
        console.log('Metadata accessible:', !!metadata);
        return metadata;
    } catch (error) {
        console.error('Metadata access failed:', error.message);
    }
}
```

</details>

<details>
<summary>High Gas Costs</summary>

**Optimization strategies**:
- Compress proofs before submission
- Use batch operations for multiple transfers
- Optimize storage patterns
- Consider Layer 2 solutions

```javascript
// Optimize gas usage
async function optimizedTransfer(transfers) {
    // Batch multiple transfers
    const batchData = transfers.map(t => ({
        tokenId: t.tokenId,
        from: t.from,
        to: t.to,
        sealedKey: compressData(t.sealedKey),
        proof: compressProof(t.proof)
    }));
    
    return await inft.batchTransfer(batchData);
}
```

</details>

### Get Support

üêõ **[GitHub Issues](https://github.com/0gfoundation/0g-agent-nft/issues)** - Report bugs and feature requests  
üí¨ **[Discord Community](https://discord.gg/0glabs)** - Get help from developers  
üìñ **[Documentation](./erc7857)** - Technical reference  
üìö **[Knowledge Base](https://kb.0g.ai)** - Common solutions  

## Next Steps

### Continue Learning
üìã **[ERC-7857 Technical Standard](./erc7857)** - Deep dive into implementation details  
üéØ **[INFT Use Cases](./inft-overview#real-world-applications)** - Explore more applications  
üíª **[Example Implementations](https://github.com/0gfoundation/0g-agent-nft/tree/eip-7857-draft)** - Reference code  

### Production Deployment
üöÄ **Mainnet Migration** - Deploy to 0G mainnet when ready  
üîí **Security Audit** - Get your contracts audited  
üìä **Monitoring Setup** - Implement monitoring and alerts  

### Community
ü§ù **Developer Community** - Share your implementation  
üí¨ **Technical Discussions** - Join conversations about best practices  
üë• **Contribute** - Help improve the INFT ecosystem  

:::tip Ready to Deploy?
Once you've tested your implementation thoroughly, consider getting a security audit before deploying to mainnet. The 0G team can recommend trusted auditing partners.
:::

---

## Building on 0G


Build AI-powered applications using 0G's modular infrastructure - with or without migrating your existing code.

**Keep your current blockchain and add 0G services as needed.** Our infrastructure works with:
- ‚úÖ Any EVM chain (Ethereum, Polygon, BNB, Arbitrum)
- ‚úÖ Non-EVM chains (Solana, Near, Cosmos)
- ‚úÖ Traditional Web2 applications

## Prerequisites

Before building:
1. **Get testnet tokens** from the [faucet](https://faucet.0g.ai)
2. **Install relevant SDK** for your language
3. **Review service documentation** for your chosen components

## What's Next?

Based on your needs, dive into:

- **Dapp Migration?** ‚Üí [Deploy on 0G Chain](/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts)
- **Need Storage?** ‚Üí [Storage SDK Guide](/developer-hub/building-on-0g/storage/sdk)
- **Need Compute?** ‚Üí [Compute Integration](/developer-hub/building-on-0g/compute-network/inference)
- **Building a Rollup?** ‚Üí [DA Integration](/developer-hub/building-on-0g/da-integration)
- **Creating INFTs?** ‚Üí [INFT Overview](/developer-hub/building-on-0g/inft/inft-overview)

---

üí° **Pro Tip**: Start with one service, prove the value, then expand. Most successful projects begin with 0G Storage or Compute before exploring other services.

---

## Caldera on 0G DA


Under construction...

---

## Arbitrum Nitro on 0G DA

# Run an Arbitrum Nitro Rollup on 0G DA

Arbitrum Nitro is a high-performance Ethereum rollup that uses a new consensus mechanism called "Nitro" to achieve scalability and efficiency. 0G DA is a high-performance data availability layer that can be used for Arbitrum Nitro to provide a cost-effective and secure solution for storing transaction data.

## Overview

### DA Provider Implementation

The Arbitrum Nitro code includes a `DataAvailabilityProvider` interface, which is utilized throughout the codebase for storing and retrieving data from various providers, including EIP-4844 blobs, Anytrust, and now 0G.

This integration adds an implementation of the `DataAvailabilityProvider` interface specifically for 0G. The main functionality for posting and retrieving data is found in the `das/zerogravity.go` file, where the data is stored on 0G.

### GitHub Repository

Find the repository for this integration at: https://github.com/0gfoundation/nitro

## Prerequisites

Before setting up your Arbitrum Nitro rollup with 0G DA, ensure you have:

- [0G DA Client Node](../da-integration.md)
- [0G DA Encoder Node](../da-integration.md)
- [0G Arbitrum Nitro Rollup Kit](https://github.com/0gfoundation/nitro)

:::warning Beta Integration
This is a beta integration and we are working on resolving open issues. Please check the repository for the latest updates and known issues.
:::

## Next Steps

For detailed setup instructions and configuration:

1. **Set up DA infrastructure** ‚Üí Follow the [DA integration guide](../da-integration.md)
2. **Clone the integration** ‚Üí Visit the [0G Nitro repository](https://github.com/0gfoundation/nitro)
3. **Follow setup guide** ‚Üí Check the repository README for specific deployment steps

## Support

- **Technical Issues** ‚Üí [GitHub Issues](https://github.com/0gfoundation/nitro/issues)
- **Community Support** ‚Üí [Discord](https://discord.gg/0glabs)

---

*Stay tuned for more detailed documentation as this integration matures.*

---

## OP Stack on 0G DA

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Run an OP Stack Rollup on 0G DA

Optimism is a lightning-fast Ethereum L2 blockchain, built with the OP Stack. 0G DA is a high-performance data availability layer that can be used with Optimism to provide a cost-effective and secure solution for storing transaction data.

## Overview

To implement this server specification, 0G DA provides a `da-server` that runs as a sidecar process alongside the OP Stack rollup node. This server connects to a 0G DA client to securely communicate with the 0G DA network.

### Required Components

- [0G DA client node](/developer-hub/building-on-0g/da-integration)
- [0G DA encoder node](/developer-hub/building-on-0g/da-integration)
- 0G DA Server (deployment guide below)
- OP Stack components with configuration adjustments

### GitHub Repository

Find the repository for this integration at: https://github.com/0gfoundation/0g-da-op-plasma

The Optimism codebase has been extended to integrate with the 0G DA `da-server`. This server utilizes the 0G DA Open API to efficiently store and retrieve rollup data.

## Deployment Steps

### 1. Deploy DA Server

<Tabs>
<TabItem value="docker" label="Run with Docker" default>

**Build the Docker image:**

```bash
docker build -t 0g-da-op-plasma .
```

**Run the Docker container:**

Adjust commands and parameters as required for your setup:

```bash
docker run -p 3100:3100 0g-da-op-plasma:latest da-server \
  --addr 0.0.0.0 \
  --port 3100 \
  --zg.server rpc_to_a_da_client  # default: 127.0.0.1:51001
```

</TabItem>
<TabItem value="source" label="Build from Source">

**Build DA Server:**

```bash
git clone https://github.com/0gfoundation/0g-da-op-plasma.git
cd 0g-da-op-plasma
make da-server
```

**Run DA Server:**

```bash
./bin/da-server \
  --addr 127.0.0.1 \
  --port 3100 \
  --zg.server rpc_to_a_da_client  # default: 127.0.0.1:51001
```

</TabItem>
</Tabs>

**DA Server Configuration Flags:**

| Flag | Description | Default |
|------|-------------|---------|
| `--zg.server` | 0G DA client server endpoint | `localhost:51001` |
| `--addr` | Server listening address | - |
| `--port` | Server listening port | - |

### 2. Deploy DA Client and DA Encoder

For guidance on setting up a 0G DA client and DA Encoder, refer to the [DA integration documentation](../da-integration.md).

### 3. Deploy OP Stack

## Prerequisites

Ensure you have installed the following software:

| Software | Version |
|----------|---------|
| Git | OS default |
| Go | 1.21.6 |
| Node | ^20 |
| just | 1.34.0 |
| Make | OS default |
| jq | OS default |
| direnv | Latest |

**Required releases:**
- op-node/v1.9.1
- op-proposer/v1.9.1
- op-batcher/v1.9.1
- op-geth v1.101408.0

## Build the Optimism Monorepo

**1. Clone and navigate to the Optimism Monorepo:**

```bash
git clone https://github.com/ethereum-optimism/optimism.git
cd optimism
git fetch --tag --all
git checkout v1.9.1
git submodule update --init --recursive
```

**2. Check your dependencies:**

```bash
./packages/contracts-bedrock/scripts/getting-started/versions.sh
```

**3. Compile the necessary packages:**

```bash
make op-node op-batcher op-proposer
make build
```

## Build the Optimism Geth Source

**1. Clone and navigate to op-geth:**

```bash
git clone https://github.com/ethereum-optimism/op-geth.git
cd op-geth
git fetch --tag --all
git checkout v1.101408.0
```

**2. Compile op-geth:**

```bash
make geth
```

## Get Access to a Sepolia Node

For deploying to Sepolia, access an L1 node using a provider like [Alchemy](https://www.alchemy.com/) (easier) or run your own Sepolia node (harder).

## Configure Environment Variables

**1. Enter the Optimism Monorepo:**

```bash
cd ~/optimism
```

**2. Duplicate the sample environment variable file:**

```bash
cp .envrc.example .envrc
```

**3. Fill out the environment variables:**

| Variable Name | Description |
|---------------|-------------|
| `L1_RPC_URL` | URL for your L1 node (a Sepolia node in this case) |
| `L1_RPC_KIND` | Kind of L1 RPC you're connecting to (`alchemy`, `quicknode`, `infura`, `parity`, `nethermind`, `debug_geth`, `erigon`, `basic`, `any`) |

## Generate Addresses

You'll need four addresses and their private keys:

- **Admin**: Has the ability to upgrade contracts
- **Batcher**: Publishes Sequencer transaction data to L1
- **Proposer**: Publishes L2 transaction results (state roots) to L1
- **Sequencer**: Signs blocks on the p2p network

**1. Navigate to the contracts-bedrock package:**

```bash
cd ~/optimism/packages/contracts-bedrock
```

**2. Generate accounts:**

```bash
./scripts/getting-started/wallets.sh
```

you will get the following output:
```bash
Copy the following into your .envrc file:
  
# Admin address
export GS_ADMIN_ADDRESS=0x9625B9aF7C42b4Ab7f2C437dbc4ee749d52E19FC
export GS_ADMIN_PRIVATE_KEY=0xbb93a75f64c57c6f464fd259ea37c2d4694110df57b2e293db8226a502b30a34
# Batcher address
export GS_BATCHER_ADDRESS=0xa1AEF4C07AB21E39c37F05466b872094edcf9cB1
export GS_BATCHER_PRIVATE_KEY=0xe4d9cd91a3e53853b7ea0dad275efdb5173666720b1100866fb2d89757ca9c5a
  
# Proposer address
export GS_PROPOSER_ADDRESS=0x40E805e252D0Ee3D587b68736544dEfB419F351b
export GS_PROPOSER_PRIVATE_KEY=0x2d1f265683ebe37d960c67df03a378f79a7859038c6d634a61e40776d561f8a2
  
# Sequencer address
export GS_SEQUENCER_ADDRESS=0xC06566E8Ec6cF81B4B26376880dB620d83d50Dfb
export GS_SEQUENCER_PRIVATE_KEY=0x2a0290473f3838dbd083a5e17783e3cc33c905539c0121f9c76614dda8a38dca

```

**3. Save the addresses:**

Copy the output from the above command and paste it into your `.envrc` file. Fund the addresses with Sepolia ETH:
- Admin: 0.5 ETH
- Proposer: 0.2 ETH
- Batcher: 0.1 ETH

:::warning Production Note
Use secure hardware for key management in production environments. cast wallet is not designed for production deployments.
:::

## Load Environment Variables

**1. Enter the Optimism Monorepo:**

```bash
cd ~/optimism
```

**2. Load the variables with direnv:**

```bash
direnv allow
```

## Deploy Core Contracts

**1. Update the deployment configuration:**

```bash
cd packages/contracts-bedrock
./scripts/getting-started/config.sh
```

**2. Add 0G DA configuration:**

Add the following at the bottom of `getting_started.json`:

```json
{
  "useAltDA": true,
  "daCommitmentType": "GenericCommitment",
  "daChallengeWindow": 160,
  "daResolveWindow": 160,
  "daBondSize": 1000000,
  "daResolverRefundPercentage": 0
}
```

**3. Deploy contracts (this can take up to 15 minutes):**

```bash
DEPLOYMENT_OUTFILE=deployments/artifact.json \
DEPLOY_CONFIG_PATH=deploy-config/getting-started.json \
forge script scripts/deploy/Deploy.s.sol:Deploy \
  --broadcast --private-key $GS_ADMIN_PRIVATE_KEY \
  --rpc-url $L1_RPC_URL --slow
```

**4. Generate L2 allocations:**

```bash
CONTRACT_ADDRESSES_PATH=deployments/artifact.json \
DEPLOY_CONFIG_PATH=deploy-config/getting-started.json \
STATE_DUMP_PATH=deploy-config/statedump.json \
forge script scripts/L2Genesis.s.sol:L2Genesis \
  --sig 'runWithStateDump()' --chain <YOUR_L2_CHAINID>
```

## Set Up L2 Configuration

**1. Navigate to the op-node directory:**

```bash
cd ~/optimism/op-node
```

**2. Generate genesis and rollup configuration:**

```bash
go run cmd/main.go genesis l2 \
  --deploy-config ../packages/contracts-bedrock/deploy-config/getting-started.json \
  --l1-deployments ../packages/contracts-bedrock/deployments/artifact.json \
  --outfile.l2 genesis.json \
  --outfile.rollup rollup.json \
  --l1-rpc $L1_RPC_URL \
  --l2-allocs ../packages/contracts-bedrock/deploy-config/statedump.json
```

**3. Add alt_da configuration to rollup.json:**

```json
{
  "alt_da": {
    "da_challenge_contract_address": "0x0000000000000000000000000000000000000000",
    "da_commitment_type": "GenericCommitment",
    "da_challenge_window": 160,
    "da_resolve_window": 160
  }
}
```

**4. Generate JWT secret:**

```bash
openssl rand -hex 32 > jwt.txt
```

**5. Copy files to op-geth directory:**

```bash
cp genesis.json ~/op-geth
cp jwt.txt ~/op-geth
```

## Initialize and Run Components

### Initialize op-geth

```bash
cd ~/op-geth
mkdir datadir
build/bin/geth init --datadir=datadir genesis.json
```

### Run op-geth

```bash
cd ~/op-geth
./build/bin/geth \
  --datadir ./datadir \
  --http \
  --http.corsdomain="*" \
  --http.vhosts="*" \
  --http.addr=0.0.0.0 \
  --http.port=9545 \
  --http.api=web3,debug,eth,txpool,net,engine \
  --ws \
  --ws.addr=0.0.0.0 \
  --ws.port=9546 \
  --ws.origins="*" \
  --ws.api=debug,eth,txpool,net,engine \
  --syncmode=full \
  --nodiscover \
  --maxpeers=0 \
  --networkid=42069 \
  --authrpc.vhosts="*" \
  --authrpc.addr=0.0.0.0 \
  --authrpc.port=9551 \
  --authrpc.jwtsecret=./jwt.txt \
  --rollup.disabletxpoolgossip=true \
  --state.scheme=hash
```

### Run op-node

```bash
cd ~/optimism/op-node
./bin/op-node \
  --l2=http://localhost:9551 \
  --l2.jwt-secret=./jwt.txt \
  --sequencer.enabled \
  --sequencer.l1-confs=5 \
  --verifier.l1-confs=4 \
  --rollup.config=./rollup.json \
  --rpc.addr=0.0.0.0 \
  --rpc.port=8547 \
  --p2p.disable \
  --rpc.enable-admin \
  --p2p.sequencer.key=$GS_SEQUENCER_PRIVATE_KEY \
  --l1=$L1_RPC_URL \
  --l1.rpckind=$L1_RPC_KIND \
  --altda.enabled=true \
  --altda.da-server=<DA_SERVER_HTTP_URL> \
  --altda.da-service=true \
  --l1.beacon.ignore=true
```

### Run op-batcher

```bash
cd ~/optimism/op-batcher
./bin/op-batcher \
  --l2-eth-rpc=http://localhost:9545 \
  --rollup-rpc=http://localhost:8547 \
  --poll-interval=1s \
  --sub-safety-margin=6 \
  --num-confirmations=1 \
  --safe-abort-nonce-too-low-count=3 \
  --resubmission-timeout=30s \
  --rpc.addr=0.0.0.0 \
  --rpc.port=8548 \
  --rpc.enable-admin \
  --max-channel-duration=1 \
  --l1-eth-rpc=$L1_RPC_URL \
  --private-key=$GS_BATCHER_PRIVATE_KEY \
  --altda.enabled=true \
  --altda.da-service=true \
  --altda.da-server=<DA_SERVER_HTTP_URL>
```

:::tip Controlling Batcher Costs
The `--max-channel-duration=n` setting controls how often data is written to L1. Lower values mean faster synchronization but higher costs. Set to 0 to disable or increase for lower costs.
:::

### Run op-proposer

```bash
cd ~/optimism/op-proposer
./bin/op-proposer \
  --poll-interval=12s \
  --rpc.port=9560 \
  --rollup-rpc=http://localhost:8547 \
  --l2oo-address=$L2OO_ADDR \
  --private-key=$GS_PROPOSER_PRIVATE_KEY \
  --l1-eth-rpc=$L1_RPC_URL
```

## Acquire Sepolia ETH for Layer 2

**1. Navigate to contracts-bedrock:**

```bash
cd ~/optimism/packages/contracts-bedrock
```

**2. Find the L1 standard bridge contract address:**

```bash
cat deployments/artifact.json | jq -r .L1StandardBridgeProxy
```

**3. Send Sepolia ETH to the bridge contract address**

## Test Your Rollup

You now have a fully operational 0G DA-powered Optimism-based EVM Rollup. Experiment with it as you would with any other test blockchain.

:::important Notes
- This is a beta integration with active development ongoing
- Ensure all necessary ports are open in your firewall configuration
- Refer to the [Optimism documentation](https://docs.optimism.io/) for additional configuration options and troubleshooting
:::

---

*Congratulations on setting up your OP Stack rollup with 0G DA!*

---

## Storage SDK

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 0G Storage SDKs

Build decentralized storage into your applications with our powerful SDKs designed for modern development workflows.

## Available SDKs

- **Go SDK**: Ideal for backend systems and applications built with Go
- **TypeScript SDK**: Perfect for frontend development and JavaScript-based projects

## Core Features

Both SDKs provide a streamlined interface to interact with the 0G Storage network:

- **Upload and Download Files**: Securely store and retrieve data of various sizes and formats
- **Manage Data**: List uploaded files, check their status, and control access permissions
- **Leverage Decentralization**: Benefit from the 0G network's distributed architecture for enhanced data availability, immutability, and censorship resistance

## Quick Start Resources

:::tip Starter Kits Available
Get up and running quickly with our comprehensive starter kits:

- **[TypeScript Starter Kit](https://github.com/0gfoundation/0g-storage-ts-starter-kit)** - Complete examples with Express.js server and CLI tool
- **[Go Starter Kit](https://github.com/0gfoundation/0g-storage-go-starter-kit)** - Ready-to-use examples with Gin server and CLI tool

Both repositories include working examples, API documentation, and everything you need to start building.
:::

<Tabs>
<TabItem value="go" label="Go SDK" default>

## Installation

Install the 0G Storage Client library:

```bash
go get github.com/0gfoundation/0g-storage-client
```

## Setup

### Import Required Packages

```go
import (
    "context"
    "github.com/0gfoundation/0g-storage-client/common/blockchain"
    "github.com/0gfoundation/0g-storage-client/common"
    "github.com/0gfoundation/0g-storage-client/indexer"
    "github.com/0gfoundation/0g-storage-client/transfer"
    "github.com/0gfoundation/0g-storage-client/core"
)
```

### Initialize Clients

Create the necessary clients to interact with the network:

```go
// Create Web3 client for blockchain interactions
w3client := blockchain.MustNewWeb3(evmRpc, privateKey)
defer w3client.Close()

// Create indexer client for node management
indexerClient, err := indexer.NewClient(indRpc, indexer.IndexerClientOption{
    LogOption: common.LogOption{},
})
if err != nil {
    // Handle error
}
```

**Parameters:**
`evmRpc` is the chain RPC endpoint, `privateKey` is your signer key, and `indRpc` is the indexer RPC endpoint. Use the current values published in the network overview docs for your network.

## Core Operations

### Node Selection

Select storage nodes before performing file operations:

```go
nodes, err := indexerClient.SelectNodes(ctx, expectedReplicas, droppedNodes, method, fullTrusted)
if err != nil {
    // Handle error
}
```

**Parameters:**
`ctx` is the context for the operation. `expectedReplicas` is the number of replicas to maintain. `droppedNodes` is a list of nodes to exclude, `method` can be `min`, `max`, `random`, or a positive number string, and `fullTrusted` limits selection to trusted nodes.

### File Upload

Upload files to the network with the indexer client:

```go
file, err := core.Open(filePath)
if err != nil {
    // Handle error
}
defer file.Close()

fragmentSize := int64(4 * 1024 * 1024 * 1024)
opt := transfer.UploadOption{
    ExpectedReplica:  1,
    TaskSize:         10,
    SkipTx:           true,
    FinalityRequired: transfer.TransactionPacked,
    FastMode:         true,
    Method:           "min",
    FullTrusted:      true,
}

txHashes, roots, err := indexerClient.SplitableUpload(ctx, w3client, file, fragmentSize, opt)
if err != nil {
    // Handle error
}
```

`fragmentSize` controls the split size for large files. The returned `roots` contain the merkle root(s) to download later.

### File Hash Calculation

Calculate a file's Merkle root hash for identification:

```go
rootHash, err := core.MerkleRoot(filePath)
if err != nil {
    // Handle error
}
fmt.Printf("File hash: %s\n", rootHash.String())
```

:::info Important
Save the root hash - you'll need it to download the file later!
:::

### File Download

Download files from the network:

```go
rootHex := rootHash.String()
err = indexerClient.Download(ctx, rootHex, outputPath, withProof)
if err != nil {
    // Handle error
}
```

`withProof` enables merkle proof verification during download.

## Best Practices

1. **Error Handling**: Implement proper error handling and cleanup
2. **Context Management**: Use contexts for operation timeouts and cancellation
3. **Resource Cleanup**: Always close clients when done using `defer client.Close()`
4. **Verification**: Enable proof verification for sensitive files
5. **Monitoring**: Track transaction status for important uploads

## Additional Resources

- [Go SDK Repository](https://github.com/0gfoundation/0g-storage-client)
- [Go Starter Kit](https://github.com/0gfoundation/0g-storage-go-starter-kit)

</TabItem>
<TabItem value="typescript" label="TypeScript SDK">

## Installation

Install the SDK and its peer dependency:

```bash
npm install @0glabs/0g-ts-sdk ethers
```

:::note
`ethers` is a required peer dependency for blockchain interactions
:::

## Setup

### Import Required Modules

```javascript
import { ZgFile, Indexer, Batcher, KvClient } from '@0glabs/0g-ts-sdk';
import { ethers } from 'ethers';
```

### Initialize Configuration

```javascript
// Network Constants - Choose your network
// Use the current endpoints from the network overview docs
const RPC_URL = '<blockchain_rpc_endpoint>';
const INDEXER_RPC = '<storage_indexer_endpoint>';

// Initialize provider and signer
const privateKey = 'YOUR_PRIVATE_KEY'; // Replace with your private key
const provider = new ethers.JsonRpcProvider(RPC_URL);
const signer = new ethers.Wallet(privateKey, provider);

// Initialize indexer
const indexer = new Indexer(INDEXER_RPC);
```

## Core Operations

### File Upload

Complete upload workflow:

```javascript
async function uploadFile(filePath) {
  // Create file object from file path
  const file = await ZgFile.fromFilePath(filePath);

  // Generate Merkle tree for verification
  const [tree, treeErr] = await file.merkleTree();
  if (treeErr !== null) {
    throw new Error(`Error generating Merkle tree: ${treeErr}`);
  }

  // Get root hash for future reference
  console.log("File Root Hash:", tree?.rootHash());

  // Upload to network
  const [tx, uploadErr] = await indexer.upload(file, RPC_URL, signer);
  if (uploadErr !== null) {
    throw new Error(`Upload error: ${uploadErr}`);
  }

  console.log("Upload successful! Transaction:", tx);

  // Always close the file when done
  await file.close();

  return { rootHash: tree?.rootHash(), txHash: tx };
}
```

### File Download

Download with optional verification:

```javascript
async function downloadFile(rootHash, outputPath) {
  // withProof = true enables Merkle proof verification
  const err = await indexer.download(rootHash, outputPath, true);
  if (err !== null) {
    throw new Error(`Download error: ${err}`);
  }
  console.log("Download successful!");
}
```

### Key-Value Storage

Store and retrieve key-value data:

```javascript
// Upload data to 0G-KV
async function uploadToKV(streamId, key, value) {
  const [nodes, err] = await indexer.selectNodes(1);
  if (err !== null) {
    throw new Error(`Error selecting nodes: ${err}`);
  }

  const batcher = new Batcher(1, nodes, flowContract, RPC_URL);

  const keyBytes = Uint8Array.from(Buffer.from(key, 'utf-8'));
  const valueBytes = Uint8Array.from(Buffer.from(value, 'utf-8'));
  batcher.streamDataBuilder.set(streamId, keyBytes, valueBytes);

  const [tx, batchErr] = await batcher.exec();
  if (batchErr !== null) {
    throw new Error(`Batch execution error: ${batchErr}`);
  }

  console.log("KV upload successful! TX:", tx);
}

// Download data from 0G-KV
async function downloadFromKV(streamId, key) {
  const kvClient = new KvClient("http://3.101.147.150:6789");
  const keyBytes = Uint8Array.from(Buffer.from(key, 'utf-8'));
  const value = await kvClient.getValue(streamId, ethers.encodeBase64(keyBytes));
  return value;
}
```

### Browser Support

For browser environments, use the ESM build:

```html
<script type="module">
  import { Blob, Indexer } from "./dist/zgstorage.esm.js";

  // Create file object from blob
  const file = new Blob(blob);
  const [tree, err] = await file.merkleTree();
  if (err === null) {
    console.log("File Root Hash:", tree.rootHash());
  }
</script>
```

### Stream Support

Work with streams for efficient data handling:

```typescript
import { Readable } from 'stream';

// Upload from stream
async function uploadStream() {
  const stream = new Readable();
  stream.push('Hello, 0G Storage!');
  stream.push(null);

  const file = await ZgFile.fromStream(stream, 'hello.txt');
  const [tx, err] = await indexer.upload(file, RPC_URL, signer);

  if (err === null) {
    console.log("Stream uploaded!");
  }
}

// Download as stream
async function downloadStream(rootHash) {
  const stream = await indexer.downloadFileAsStream(rootHash);
  stream.pipe(fs.createWriteStream('output.txt'));
}
```

## Best Practices

1. **Initialize Once**: Create the indexer once and reuse it for multiple operations
2. **Handle Errors**: Always implement proper error handling for network issues
3. **Use Appropriate Methods**: Use `ZgFile.fromFilePath` for Node.js and `Blob` for browsers
4. **Secure Keys**: Never expose private keys in client-side code
5. **Close Resources**: Remember to call `file.close()` after operations

## Additional Resources

- [TypeScript SDK Repository](https://github.com/0gfoundation/0g-ts-sdk)
- [TypeScript Starter Kit](https://github.com/0gfoundation/0g-storage-ts-starter-kit)

</TabItem>
</Tabs>

---

*Need more control? Consider running your own [storage node](/run-a-node/storage-node) to participate in the network and earn rewards.*

---

## Storage CLI

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 0G Storage CLI

The 0G Storage CLI is your command-line gateway to interact directly with the 0G Storage network. It simplifies the process of uploading and downloading files while providing full control over your decentralized storage operations.

## Why Use the CLI?

- **Direct Control**: Manage data location and versioning with precision
- **Automation Ready**: Build scripts and cron jobs for regular operations
- **Full Feature Access**: Access all storage and KV operations from the terminal
- **Developer Friendly**: Perfect for integrating into your development workflow

:::tip Web-Based Alternative
For a quick and easy web interface, try the [0G Storage Web Tool](https://storagescan-galileo.0g.ai/tool) - perfect for one-off uploads and downloads.
:::

## Installation

### Prerequisites
- Go 1.18 or higher installed on your system
- Git for cloning the repository

### Setup Steps

**1. Clone the Repository**

```bash
git clone https://github.com/0gfoundation/0g-storage-client.git
cd 0g-storage-client
```

**2. Build the Binary**

```bash
go build
```

**3. Add to PATH** (Optional but recommended)

```bash
# Move binary to Go bin directory
mv 0g-storage-client ~/go/bin

# Add to PATH if not already configured
export PATH=~/go/bin:$PATH
```

## Command Overview

The CLI provides a comprehensive set of commands for storage operations:

```
0g-storage-client [command] [flags]

Available Commands:
  upload      Upload file to 0G Storage network
  download    Download file from 0G Storage network
  upload-dir  Upload directory to 0G Storage network
  download-dir Download directory from 0G Storage network
  diff-dir    Diff directory from 0G Storage network
  gen         Generate test files
  kv-write    Write to KV streams
  kv-read     Read KV streams
  gateway     Start gateway service
  indexer     Start indexer service
  deploy      Deploy storage contracts
  completion  Generate shell completion scripts
  help        Get help for any command

Global Flags:
  --gas-limit uint                Custom gas limit to send transaction
  --gas-price uint                Custom gas price to send transaction
  --log-level string              Log level (default "info")
  --log-color-disabled            Force to disable colorful logs
  --rpc-retry-count int           Retry count for rpc request (default 5)
  --rpc-retry-interval duration   Retry interval for rpc request (default 5s)
  --rpc-timeout duration          Timeout for single rpc request (default 30s)
  --web3-log-enabled              Enable Web3 RPC logging
```

## Core Operations

### File Upload

Upload files to the 0G Storage network using the indexer service or explicit nodes:

```bash
0g-storage-client upload \
  --url <blockchain_rpc_endpoint> \
  --key <private_key> \
  --indexer <storage_indexer_endpoint> \
  --file <file_path>
```

**Parameters:**
`--url` is the chain RPC endpoint, `--key` is your private key, and `--file` is the path to the file you want to upload. Use exactly one of `--indexer` or `--node`.

Common flags include `--tags`, `--submitter`, `--expected-replica`, `--skip-tx`, `--finality-required`, `--task-size`, `--fast-mode`, `--fragment-size`, `--routines`, `--fee`, `--nonce`, `--max-gas-price`, `--n-retries`, `--step`, `--method`, `--full-trusted`, `--timeout`, `--flow-address`, and `--market-address`.

Fee notes (turbo):
- `unitPrice = 11 / pricePerToken / 1024 * 256`. If `pricePerToken = 1`, then `unitPrice = 2.75` (tokens), or `2.75e18` a0gi.
- `pricePerSector(256B)/month = lifetimeMonth * unitPrice * 1e18 / 1024 / 1024 / 1024` (no `/12` since $11 is per TB per month).

### File Download

Download files from the network using the indexer or explicit nodes:

```bash
0g-storage-client download \
  --indexer <storage_indexer_endpoint> \
  --root <file_root_hash> \
  --file <output_file_path>
```

**Parameters:**
`--file` is the output path. Use exactly one of `--indexer` or `--node`. Use exactly one of `--root` or `--roots`.

### Download with Verification

Enable proof verification for enhanced security:

```bash
0g-storage-client download \
  --indexer <storage_indexer_endpoint> \
  --root <file_root_hash> \
  --file <output_file_path> \
  --proof
```

The `--proof` flag requests cryptographic proof of data integrity from the storage node.

### Directory Upload

Upload an entire directory using explicit storage nodes:

```bash
0g-storage-client upload-dir \
  --url <blockchain_rpc_endpoint> \
  --key <private_key> \
  --node <storage_node_endpoint> \
  --file <directory_path>
```

### Directory Download

Download a directory by root:

```bash
0g-storage-client download-dir \
  --indexer <storage_indexer_endpoint> \
  --root <directory_root_hash> \
  --file <output_directory>
```

### Directory Diff

Compare a local directory with the on-chain version:

```bash
0g-storage-client diff-dir \
  --indexer <storage_indexer_endpoint> \
  --root <directory_root_hash> \
  --file <local_directory>
```

## Practical Examples

### Upload Example

```bash
# Upload a document to 0G Storage
0g-storage-client upload \
  --url <blockchain_rpc_endpoint> \
  --key YOUR_PRIVATE_KEY \
  --indexer <storage_indexer_endpoint> \
  --file ./documents/report.pdf

# Output:
# ‚úì File uploaded successfully
# Root hash: 0xc5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470
# Transaction: 0x742d35cc6634c0532925a3b844bc454e8e4a0e3f...
```

### Download Example

```bash
# Download file using root hash
0g-storage-client download \
  --indexer <storage_indexer_endpoint> \
  --root 0xc5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470 \
  --file ./downloads/report.pdf

# With verification
0g-storage-client download \
  --indexer <storage_indexer_endpoint> \
  --root 0xc5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470 \
  --file ./downloads/report.pdf \
  --proof
```

## Key-Value Operations

### Write to KV Store (Batch Operations)

Write multiple key-value pairs in a single operation:

```bash
0g-storage-client kv-write \
  --url <blockchain_rpc_endpoint> \
  --key <private_key> \
  --indexer <storage_indexer_endpoint> \
  --stream-id <stream_id> \
  --stream-keys <comma_separated_keys> \
  --stream-values <comma_separated_values>
```

**Important:** `--stream-keys` and `--stream-values` are comma-separated string lists and their length must be equal.

You can use `--indexer` for node selection or pass storage nodes directly with `--node`. If `--indexer` is omitted, `--node` is required.

**Example:**
```bash
0g-storage-client kv-write \
  --url <blockchain_rpc_endpoint> \
  --key YOUR_PRIVATE_KEY \
  --indexer <storage_indexer_endpoint> \
  --stream-id 1 \
  --stream-keys "key1,key2,key3" \
  --stream-values "value1,value2,value3"
```

### Read from KV Store

```bash
0g-storage-client kv-read \
  --node <kv_node_rpc_endpoint> \
  --stream-id <stream_id> \
  --stream-keys <comma_separated_keys>
```

:::info KV Read Endpoint
Note that for KV read operations, you need to specify `--node` as the URL of a KV node, not the indexer endpoint.
:::

## RESTful API Gateway

The indexer service provides a RESTful API gateway for easy HTTP-based file access:

### File Downloads via HTTP

**By Transaction Sequence Number:**
```
GET /file?txSeq=7
```

**By File Merkle Root:**
```
GET /file?root=0x0376e0d95e483b62d5100968ed17fe1b1d84f0bc5d9bda8000cdfd3f39a59927
```

**With Custom Filename:**
```
GET /file?txSeq=7&name=foo.log
```

### Folder Support

Download specific files from within structured folders:

**By Transaction Sequence:**
```
GET /file/{txSeq}/path/to/file
```

**By Merkle Root:**
```
GET /file/{merkleRoot}/path/to/file
```

## Advanced Features

### Custom Gas Settings

Control transaction costs with custom gas parameters:

```bash
0g-storage-client upload \
  --gas-limit 3000000 \
  --gas-price 10000000000 \
  # ... other parameters
```

### RPC Configuration

Configure RPC retry behavior and timeouts:

```bash
0g-storage-client upload \
  --rpc-retry-count 10 \
  --rpc-retry-interval 3s \
  --rpc-timeout 60s \
  # ... other parameters
```

### Logging Configuration

Adjust logging for debugging:

```bash
# Verbose logging with Web3 details
0g-storage-client upload \
  --log-level debug \
  --web3-log-enabled \
  # ... other parameters

# Minimal logging
0g-storage-client download \
  --log-level error \
  --log-color-disabled \
  # ... other parameters
```

### Shell Completion

Enable tab completion for easier command entry:

```bash
# Bash
0g-storage-client completion bash > /etc/bash_completion.d/0g-storage-client

# Zsh
0g-storage-client completion zsh > "${fpath[1]}/_0g-storage-client"

# Fish
0g-storage-client completion fish > ~/.config/fish/completions/0g-storage-client.fish
```

## Indexer Service

The indexer service provides two types of storage node discovery:

### Trusted Nodes
Well-maintained nodes that provide stable and reliable service.

### Discovered Nodes
Nodes discovered automatically through the P2P network.

The indexer intelligently routes data to appropriate storage nodes based on their shard configurations, eliminating the need to manually specify storage nodes or contract addresses.

## Important Considerations

### Network Configuration

:::info Required Information
**RPC endpoints** and **indexer endpoints** are published in the network overview docs. Use the current values for your network. Keep private keys secure and never share them.
:::

### File Management

- **Root Hash Storage**: Save file root hashes after upload - they're required for downloads
- **Transaction Monitoring**: Track upload transactions on the blockchain explorer
- **Indexer Benefits**: The indexer automatically selects optimal storage nodes for better reliability

## Running Services

### Indexer Service

The indexer helps users find suitable storage nodes:

```bash
0g-storage-client indexer \
  --endpoint :12345 \
  --node <storage_node_endpoint>
```

Or start with a trusted node list:

```bash
0g-storage-client indexer \
  --endpoint :12345 \
  --trusted <node1,node2>
```

### Gateway Service

Run a gateway to provide HTTP access to storage:

```bash
0g-storage-client gateway \
  --nodes <storage_node_endpoint>
```

Optionally specify a local file repo:

```bash
0g-storage-client gateway \
  --nodes <storage_node_endpoint> \
  --repo <local_path>
```

## Automation Examples

### Backup Script

Create automated backup scripts:

```bash
#!/bin/bash
# backup.sh - Daily backup to 0G Storage

DATE=$(date +%Y%m%d)
BACKUP_FILE="/backups/daily-${DATE}.tar.gz"

# Create backup
tar -czf $BACKUP_FILE /important/data

# Upload to 0G
ROOT_HASH=$(0g-storage-client upload \
  --url $RPC_URL \
  --key $PRIVATE_KEY \
  --indexer $INDEXER_URL \
  --file $BACKUP_FILE | grep "root =" | awk '{print $NF}')

# Save root hash
echo "${DATE}: ${ROOT_HASH}" >> /backups/manifest.txt
```

### Monitoring Integration

Monitor uploads with logging:

```bash
# upload-with-monitoring.sh
0g-storage-client upload \
  --file $1 \
  --log-level info \
  # ... other parameters \
  2>&1 | tee -a /var/log/0g-uploads.log
```

## Troubleshooting

<details>
<summary>**Upload fails with "insufficient funds" error**</summary>

Ensure your wallet has enough tokens for:
- Gas fees on 0G Chain
- Storage fees for the file size

Check balance: Use a blockchain explorer or wallet to verify funds.
</details>

<details>
<summary>**"Indexer not found" error during upload/download**</summary>

This can happen if:
- The indexer service is offline
- The indexer endpoint URL is incorrect
- Network connectivity issues

Verify the indexer endpoint and try again.
</details>

<details>
<summary>**RPC timeout errors**</summary>

If you experience RPC timeouts, try adjusting the timeout settings:
```bash
--rpc-timeout 60s --rpc-retry-count 10 --rpc-retry-interval 3s
```
</details>

## Best Practices

1. **Security First**: Store private keys in environment variables, not command line
2. **Backup Root Hashes**: Always save file root hashes after uploads
3. **Use Verification**: Enable `--proof` for important downloads
4. **Monitor Transactions**: Track uploads on the blockchain explorer
5. **Test with Gen**: Use the `gen` command to create test files for development
6. **HTTP Access**: Leverage the RESTful API for web applications and integrations
7. **Batch KV Operations**: Use comma-separated lists for efficient key-value operations

---

*Need more control? Consider running your own [storage node](/run-a-node/storage-node) to participate in the network and earn rewards.*

---

## Getting Started

# Developer Hub

### üöÄ The Problem We Solve

Your AI application needs:

- **Massive storage** for training data (TBs of datasets)
- **GPU compute** for model inference ($10K+/month on centralized providers)
- **Fast data availability** for real-time responses
- **Decentralization** without sacrificing performance

:::success Modular Infrastructure
0G provides all of this in one integrated ecosystem - or use just the parts you need.
:::

## 0G Services

### ‚õìÔ∏è 0G Chain

EVM-compatible blockchain optimized for AI

- [Deploy Contracts](/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts)
- [Precompiles Reference](/developer-hub/building-on-0g/contracts-on-0g/precompiles/precompiles-overview)
- [Chain Architecture](/concepts/chain)

### 0G Compute

Decentralized GPU marketplace for AI workloads

- [Overview & Architecture](/developer-hub/building-on-0g/compute-network/overview)
- [SDK Reference](/developer-hub/building-on-0g/compute-network/inference)
- [Become a Provider](/developer-hub/building-on-0g/compute-network/inference-provider)

### üíæ 0G Storage

High-performance storage for massive datasets

- [SDK Integration](/developer-hub/building-on-0g/storage/sdk)
- [CLI Commands](/developer-hub/building-on-0g/storage/storage-cli)
- [Architecture Details](/concepts/storage)

### üìä 0G DA

Scalable data availability for any chain

- [Technical Deep Dive](/developer-hub/building-on-0g/da-deep-dive)
- [Integration Guide](/developer-hub/building-on-0g/da-integration)
- [Rollup Integrations](/developer-hub/building-on-0g/rollups-and-appchains/op-stack-on-0g-da)

## Community Projects

Explore our growing ecosystem of DeAI applications in the [awesome-0g](https://github.com/0gfoundation/awesome-0g) repository, which showcases community projects, tools, and resources built on 0G.

---

Ready to build? Pick a service above and start in minutes, or [join our Discord](https://discord.gg/0gLabs) for help.

---

## Mainnet Overview

import OKXButton from '@site/src/components/OKXButton';
import MetaMaskButton from '@site/src/components/MetaMaskButton';
import React from 'react';

# 0G Mainnet

Build and run production workloads on the 0G Mainnet.

:::tip Mainnet Explorer
üîç **[Explore Mainnet Activity](https://explorer.0g.ai/mainnet/home)**
:::

## Network Details

| Parameters | Network Details |
|----------------|---|
| **Network Name** | 0G Mainnet |
| **Chain ID** | 16661 |
| **Token Symbol** | 0G |
| **RPC URL** | `https://evmrpc.0g.ai` |
| **Storage Indexer** | `https://indexer-storage-turbo.0g.ai` |
| **Block Explorer** | `https://chainscan.0g.ai` |

#### ‚úÖ 3rd Party RPCs (Recommended for production)
- [QuickNode](https://www.quicknode.com/chains/0g)
- [ThirdWeb](https://thirdweb.com/0g-aristotle)
- [Ankr](https://www.ankr.com/rpc/0g/)

### Add Network to Wallet

  <MetaMaskButton
    label="Add 0G Mainnet"
    chainId={16661}
    chainName="0G Mainnet"
    tokenName="0G"
    tokenSymbol="0G"
    tokenDecimals={18}
    rpcUrls={["https://evmrpc.0g.ai"]}
    blockExplorerUrls={["https://chainscan.0g.ai/"]}
  />
  <OKXButton
    label="Add 0G Mainnet"
    chainId={16661}
    chainName="0G Mainnet"
    tokenName="0G"
    tokenSymbol="0G"
    tokenDecimals={18}
    rpcUrls={["https://evmrpc.0g.ai"]}
    blockExplorerUrls={["https://chainscan.0g.ai/"]}
  />

:::info Alternative RPC Providers
For redundancy in production apps, consider adding multiple RPC providers where available.
:::

## Contract Addresses

**0G Storage**
- Flow: `0x62D4144dB0F0a6fBBaeb6296c785C71B3D57C526`
- Mine: `0xCd01c5Cd953971CE4C2c9bFb95610236a7F414fe`
- Reward: `0x457aC76B58ffcDc118AABD6DbC63ff9072880870`

## Developer Tools
- **Chain Explorer**: `https://chainscan.0g.ai (https://chainscan.0g.ai)`

---

## Testnet Overview

import OKXButton from '@site/src/components/OKXButton';
import MetaMaskButton from '@site/src/components/MetaMaskButton';
import RemoveNewtonModal from '@site/src/components/RemoveNewtonModal';
import React, { useState } from 'react';

# 0G Testnet (Galileo)

Test your applications on 0G's infrastructure without real costs or risks.

:::tip Testnet Explorer
üîç **[Explore Testnet Activity](https://explorer.0g.ai/testnet/home)**
:::

## Network Details

| Parameters | Network Details |
|----------------|---|
| **Network Name** | 0G-Galileo-Testnet |
| **Chain ID** | 16602 |
| **Token Symbol** | 0G |
| **Block Explorer** | ```https://chainscan-galileo.0g.ai``` |
| **Faucet** | https://faucet.0g.ai |

#### ‚úÖ 3rd Party RPCs (Recommended for production)
- [QuickNode](https://www.quicknode.com/chains/0g)
- [ThirdWeb](https://thirdweb.com/0g-galileo-testnet-16601)
- [Ankr](https://www.ankr.com/rpc/0g/)
- [dRPC NodeCloud](https://drpc.org/chainlist/0g-galileo-testnet-rpc)

## Getting Started

### Step 1: Add Network to Wallet

export const AddNetworkSection = () => {
  const [isModalOpen, setIsModalOpen] = useState(false);

  return (
    <>
      
        
          
            Remove any old 0G testnet configurations before adding Galileo. 
             { e.preventDefault(); setIsModalOpen(true); }} style={{marginLeft: '5px'}}>
              Need help?
            
          
        
      

      
        <MetaMaskButton label="Add to MetaMask" />
        <OKXButton label="Add to OKX Wallet" />
      

      <RemoveNewtonModal isOpen={isModalOpen} onClose={() => setIsModalOpen(false)} />
    </>
  );
};

<AddNetworkSection />

<style>
  {`
    .wallet-buttons {
      display: flex;
      gap: 16px;
      margin: 16px 0;
    }
    
    @media (max-width: 768px) {
      .wallet-buttons {
        flex-direction: column;
      }
    }
  `}
</style>

### Step 2: Get Test Tokens

Visit the [0G Faucet](https://faucet.0g.ai) to receive free testnet tokens. **Daily Limit**: 0.1 0G per wallet.

### Step 3: Start Building

Choose your integration:
- [Deploy Smart Contracts](/developer-hub/building-on-0g/contracts-on-0g/deploy-contracts)
- [Use Storage SDK](/developer-hub/building-on-0g/storage/sdk)
- [Access Compute Network](/developer-hub/building-on-0g/compute-network/inference)
- [Integrate DA Layer](/developer-hub/building-on-0g/da-integration)

### Contract Addresses

:::caution
Addresses may change during testnet.
:::

**0G Storage**
- Flow: `0x22E03a6A89B950F1c82ec5e74F8eCa321a105296`
- Mine: `0x00A9E9604b0538e06b268Fb297Df333337f9593b`
- Reward: `0xA97B57b4BdFEA2D0a25e535bd849ad4e6C440A69`

**0G DA**
- DAEntrance: `0xE75A073dA5bb7b0eC622170Fd268f35E675a957B`

<!-- **Deployment Block**: `326165` -->

## Developer Tools

### Block Explorers
- **[Chain Explorer](https://chainscan-galileo.0g.ai)**: View transactions, blocks, and smart contracts
- **[Storage Explorer](https://storagescan-galileo.0g.ai)**: Track storage operations and metrics
- **[Validator Dashboard](https://testnet.0g.explorers.guru)**: Monitor network validators

<details>
<summary>Development RPC</summary>

:::warning Development Only
This endpoint is for development purposes and should not be used in production applications.
:::

`https://evmrpc-testnet.0g.ai`

</details>

## Faucet
- Use the [official Faucet](https://faucet.0g.ai) to request tokens. Each user can receive up to 0.1 0G token per day, which is sufficient for most testing needs.

- If you require more than 0.1 0G token per day, please reach out in our vibrant [discord](https://discord.com/invite/0glabs) community to request additional tokens.

---

## 0G Documentation

import Link from '@docusaurus/Link';
import SocialProofSection from '@site/src/components/SocialProofSection';

  
    Build the Future of Decentralized AI
    
      <Link className="button button--primary button--lg hero-primary-btn" to="/developer-hub/getting-started">
        Quick Start
      </Link>
      <Link className="button button--outline button--primary button--lg hero-secondary-btn" to="/concepts/chain">
        Learn Concepts
      </Link>
    
  

  
    
    <Link to="/developer-hub/testnet/testnet-overview" className="resource-card">
      
      
        
          Join Testnet
        
        Connect to Galileo testnet and start building your first dApp on 0G
        
          Connect to Testnet ‚Üí
        
      
    </Link>

    <Link to="/node-sale/ai-alignment-node-user-guide" className="resource-card">
      
      
        
          AI Alignment Node
        
        Learn more about the AI Alignment Node operation
        
          Learn More ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/compute-network/inference" className="resource-card">
      
      
        
          Inference
        
        Integrate AI inference into your applications with SDKs
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/storage/sdk" className="resource-card">
      
      
        
          Storage SDK
        
        Store and retrieve massive datasets with Go and TypeScript client libraries
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/compute-network/fine-tuning" className="resource-card">
      
      
        
          Fine-tuning
        
        Customize AI models for your specific use case with our command-line tools
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/run-a-node/validator-node" className="resource-card">
      
      
        
          Run a Validator
        
        Secure the network and earn rewards by running a validator node
        
          Setup Guide ‚Üí
        
      
    </Link>
  

<SocialProofSection />

  
  Ready to Build?
  Join thousands of developers building the future of decentralized AI
  
    <Link className="button button--primary button--lg cta-primary-btn" to="/developer-hub/getting-started">
      View Full Documentation
    </Link>
  

<style>{`
  /* Hide sidebar toggle on mobile for landing page */
  @media screen and (max-width: 996px) {
    .navbar__toggle {
      display: none !important;
      visibility: hidden !important;
    }
  }

  /* Global font family for landing page */
  .landing-page-custom,
  .landing-page-custom * {
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Global button styling for consistency */
  .landing-page-custom .button {
    border-radius: 12px;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Hide sidebar on landing page */
  .new-landing {
    --doc-sidebar-width: 0 !important;
  }
  
  /* Hide page title */
  .landing-page-custom h1:first-child,
  .landing-page-custom .theme-doc-markdown > h1:first-child,
  .landing-page-custom header h1,
  article > h1:first-child,
  main h1:first-child:not(.hero-title),
  .hide-title-wrapper ~ h1,
  h1:has(+ .hide-title-wrapper),
  .markdown > h1:first-child {
    display: none !important;
  }
  
  /* More aggressive title hiding */
  .landing-page-custom .markdown > *:first-child:is(h1) {
    display: none !important;
  }
  
  /* Hero Section */
  .landing-hero {
    text-align: center;
    padding: 6rem 2rem 4rem;
    margin-left: calc(-50vw + 50%);
    margin-right: calc(-50vw + 50%);
    margin-top: -2rem;
    margin-bottom: 3rem;
    width: 100vw;
    position: relative;
    overflow: hidden;
    background: linear-gradient(180deg, 
      rgba(146, 0, 225, 0.08) 0%, 
      rgba(183, 95, 255, 0.05) 50%, 
      transparent 100%);
  }
  
  .landing-hero::before {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    background: radial-gradient(ellipse at 20% 50%, rgba(146, 0, 225, 0.25) 0%, transparent 40%),
                radial-gradient(ellipse at 80% 50%, rgba(227, 193, 255, 0.2) 0%, transparent 40%);
    animation: float 20s ease-in-out infinite;
  }
  
  @keyframes float {
    0%, 100% { transform: translate(0, 0) rotate(0deg); }
    33% { transform: translate(30px, -30px) rotate(120deg); }
    66% { transform: translate(-20px, 20px) rotate(240deg); }
  }
  
  .hero-content {
    position: relative;
    z-index: 1;
  }
  
  .hero-title {
    font-size: 4rem;
    font-weight: 400; /* Book weight */
    margin-bottom: 1.5rem;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
    letter-spacing: -0.02em;
    line-height: 1.1;
  }
  
  /* Light mode hero title */
  [data-theme='light'] .hero-title {
    color: #1A1A1F;
  }
  
  /* Dark mode hero title */
  [data-theme='dark'] .hero-title {
    color: #F5F5F7;
  }
  
  .gradient-text {
    background: linear-gradient(135deg, #9200E1 0%, #B75FFF 50%, #CB8AFF 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }

  .text-purple{
    color: #B75FFF;
  }
  
  .hero-subtitle {
    font-size: 1.25rem;
    color: var(--ifm-color-secondary-darkest);
    max-width: 800px;
    margin: 0 auto 2.5rem;
    line-height: 1.6;
    opacity: 0.9;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .hero-buttons {
    display: flex;
    gap: 1rem;
    justify-content: center;
    flex-wrap: wrap;
  }
  
  .hero-primary-btn,
  .hero-secondary-btn,
  .cta-primary-btn,
  .cta-secondary-btn {
    line-height: 1.2;
    display: inline-flex;
    align-items: center;
  }
  
  .hero-primary-btn p,
  .hero-secondary-btn p,
  .cta-primary-btn p,
  .cta-secondary-btn p,
  .button p {
    margin: 0 !important;
  }
  
  /* Primary Button - Black with rounded corners */
  .hero-primary-btn {
    background: #1A1A1F;
    border: none;
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    color: #FFFFFF !important;
    box-shadow: 0 4px 14px rgba(26, 26, 31, 0.25);
  }
  
  .hero-primary-btn:hover {
    background: #2A2A2F;
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(26, 26, 31, 0.35);
    text-decoration: none;
    color: #FFFFFF !important;
  }
  
  /* Secondary Button Base - Soft purple/gray with rounded corners */
  .hero-secondary-btn {
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    border: 2px solid transparent;
  }
  
  .hero-secondary-btn:hover {
    transform: translateY(-2px);
    text-decoration: none;
  }
  
  /* Light mode secondary button - Gray */
  [data-theme='light'] .hero-secondary-btn {
    background: #F5F5F7;
    color: #5A5A6E !important;
    border-color: #E8E8F0;
  }
  
  [data-theme='light'] .hero-secondary-btn:hover {
    background: #EAEAEC;
    color: #3A3A4A !important;
    border-color: #D0D0D5;
    box-shadow: 0 4px 14px rgba(0, 0, 0, 0.1);
  }
  
  /* Dark mode secondary button - Soft purple */
  [data-theme='dark'] .hero-secondary-btn {
    background: rgba(183, 95, 255, 0.12);
    color: #E3C1FF !important;
    border-color: rgba(183, 95, 255, 0.3);
  }
  
  [data-theme='dark'] .hero-secondary-btn:hover {
    background: rgba(183, 95, 255, 0.2);
    color: #FFFFFF !important;
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 4px 14px rgba(183, 95, 255, 0.25);
  }
  
  /* Container adjustments */
  .landing-page-custom .theme-doc-markdown {
    max-width: 100%;
  }
  
  .landing-page-custom .container {
    max-width: 100%;
    padding: 0;
  }
  
  .landing-page-custom article {
    padding: 0;
  }
  
  /* Developer Section */
  .landing-section {
    margin: 2rem auto 4rem;
    max-width: 1200px;
    padding: 0 2rem;
  }
  
  .section-title {
    text-align: center;
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .section-subtitle {
    text-align: center;
    color: var(--ifm-color-secondary-darkest);
    margin-bottom: 3rem;
    font-size: 1.1rem;
    opacity: 0.9;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(340px, 1fr));
    gap: 1.5rem;
    max-width: 1200px;
    margin: 0 auto;
  }
  
  .resource-card {
    position: relative;
    border-radius: 16px;
    overflow: hidden;
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1), 
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1);
    text-decoration: none;
    color: inherit;
    display: block;
    will-change: transform;
    transform: translateZ(0); /* Force GPU acceleration */
    backface-visibility: hidden; /* Prevent flickering */
  }
  
  .card-glow {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: radial-gradient(circle at 50% 0%, rgba(183, 95, 255, 0.15) 0%, transparent 70%);
    opacity: 0;
    transition: opacity 0.2s ease;
    pointer-events: none;
    will-change: opacity;
  }
  
  .resource-card:hover .card-glow {
    opacity: 1;
  }
  
  .resource-card:hover {
    transform: translate3d(0, -4px, 0); /* Use 3D transform for GPU */
    text-decoration: none;
  }
  
  .resource-card * {
    text-decoration: none !important;
  }
  
  .card-content {
    position: relative;
    padding: 2rem;
    z-index: 1;
  }
  
  .card-header {
    margin-bottom: 1rem;
  }
  
  .card-header h3 {
    margin: 0;
    font-size: 1.5rem;
    font-weight: 400; /* Book weight */
    color: var(--ifm-heading-color);
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-card p {
    color: var(--ifm-color-secondary-darkest);
    margin-bottom: 1.5rem;
    line-height: 1.6;
    opacity: 0.9;
    min-height: 3.2em;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .card-footer {
    margin-top: auto;
  }
  
  .card-link {
    color: #B75FFF;
    font-weight: 600;
    font-size: 0.875rem;
    text-transform: uppercase;
    letter-spacing: 0.75px;
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
    transition: gap 0.3s ease;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-card:hover .card-link {
    gap: 0.5rem;
  }
  
  /* Social Proof Section */
  .social-proof-section {
    padding: 6rem 2rem;
    text-align: center;
    position: relative;
    overflow: hidden;
  }
  
  .social-proof-section::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 1px;
    background: linear-gradient(90deg, 
      transparent 0%, 
      rgba(183, 95, 255, 0.3) 50%, 
      transparent 100%);
  }
  
  .stats-container {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 4rem;
    max-width: 800px;
    margin: 0 auto;
  }
  
  .stat-item {
    flex: 1;
    text-align: center;
  }
  
  .stat-number {
    font-size: 3.5rem;
    font-weight: 400; /* Book weight */
    background: linear-gradient(135deg, #9200E1 0%, #B75FFF 50%, #CB8AFF 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    line-height: 1.2;
    margin-bottom: 0.5rem;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Fade in animation for stats */
  @keyframes fadeInUp {
    from {
      opacity: 0;
      transform: translateY(30px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }
  
  /* Initial state - hidden */
  .stat-item {
    opacity: 0;
    transform: translateY(30px);
    transition: opacity 0.8s ease-out, transform 0.8s ease-out;
  }
  
  /* Visible state - animated in */
  .stat-item.animate {
    opacity: 1;
    transform: translateY(0);
  }
  
  /* Stagger the animations */
  .stat-item:nth-child(1) {
    transition-delay: 0.2s;
  }
  
  .stat-item:nth-child(3) {
    transition-delay: 0.4s;
  }
  
  .stat-item:nth-child(5) {
    transition-delay: 0.6s;
  }
  
  .stat-label {
    font-size: 1.125rem;
    color: var(--ifm-color-secondary-darkest);
    opacity: 0.8;
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .stat-divider {
    width: 1px;
    height: 60px;
    background: linear-gradient(180deg, 
      transparent 0%, 
      rgba(183, 95, 255, 0.3) 50%, 
      transparent 100%);
  }
  
  /* Light mode adjustments */
  [data-theme='light'] .stat-label {
    color: #5A5A6E;
  }
  
  /* Dark mode adjustments */
  [data-theme='dark'] .stat-label {
    color: #C0B8D0;
  }
  
  /* Responsive stats */
  @media (max-width: 768px) {
    .stats-container {
      flex-direction: column;
      gap: 2rem;
    }
    
    .stat-divider {
      width: 60px;
      height: 1px;
    }
    
    .stat-number {
      font-size: 2.5rem;
    }
  }
  
  /* CTA Section */
  .landing-cta {
    text-align: center;
    padding: 4rem 3rem;
    margin: 6rem auto 2rem;
    max-width: 1200px;
    position: relative;
    border-radius: 16px;
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1), 
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1);
  }
  
  .cta-glow {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: radial-gradient(circle at 50% 0%, rgba(183, 95, 255, 0.15) 0%, transparent 70%);
    opacity: 0;
    transition: opacity 0.2s ease;
    pointer-events: none;
    border-radius: 16px;
  }
  
  .landing-cta:hover .cta-glow {
    opacity: 1;
  }
  
  .landing-cta:hover {
    transform: translate3d(0, -4px, 0);
  }
  
  .landing-cta h2 {
    font-size: 2.5rem;
    margin-bottom: 1rem;
    position: relative;
    z-index: 2;
    color: var(--ifm-heading-color);
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .landing-cta > p {
    font-size: 1.25rem;
    margin-bottom: 2rem;
    position: relative;
    z-index: 2;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* CTA text colors for purple background */
  [data-theme='light'] .landing-cta > p,
  [data-theme='dark'] .landing-cta > p {
    color: #4A4A5A;
    opacity: 0.95;
  }
  
  /* CTA heading colors for purple background */
  [data-theme='light'] .landing-cta h2,
  [data-theme='dark'] .landing-cta h2 {
    color: #2A2A3A;
  }
  
  /* Ensure button text is not affected */
  .landing-cta .button p {
    color: inherit !important;
    opacity: 1 !important;
  }
  
  .cta-buttons {
    display: flex;
    gap: 1rem;
    justify-content: center;
    flex-wrap: wrap;
    position: relative;
    z-index: 2;
  }
  
  /* CTA Primary Button - Black with rounded corners */
  .cta-primary-btn {
    background: #1A1A1F;
    border: none;
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2.5rem;
    border-radius: 12px;
    color: #FFFFFF !important;
    transition: all 0.3s ease;
    box-shadow: 0 4px 14px rgba(26, 26, 31, 0.25);
  }
  
  .cta-primary-btn:hover {
    background: #2A2A2F;
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(26, 26, 31, 0.35);
    text-decoration: none;
    color: #FFFFFF !important;
  }
  
  /* CTA Secondary Button Base - Matching hero secondary */
  .cta-secondary-btn {
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2.5rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    border: 2px solid transparent;
  }
  
  .cta-secondary-btn:hover {
    transform: translateY(-2px);
    text-decoration: none;
  }
  
  /* CTA Secondary Button - Light Mode (Gray) */
  [data-theme='light'] .cta-secondary-btn {
    background: #F5F5F7;
    color: #5A5A6E !important;
    border-color: #E8E8F0;
  }
  
  [data-theme='light'] .cta-secondary-btn:hover {
    background: #EAEAEC;
    color: #3A3A4A !important;
    border-color: #D0D0D5;
    box-shadow: 0 4px 14px rgba(0, 0, 0, 0.1);
  }
  
  /* CTA Secondary Button - Dark Mode (Soft purple) */
  [data-theme='dark'] .cta-secondary-btn {
    background: rgba(183, 95, 255, 0.12);
    color: #E3C1FF !important;
    border-color: rgba(183, 95, 255, 0.3);
  }
  
  [data-theme='dark'] .cta-secondary-btn:hover {
    background: rgba(183, 95, 255, 0.2);
    color: #FFFFFF !important;
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 4px 14px rgba(183, 95, 255, 0.25);
  }
  
  /* Override any inherited styles - Force button colors */
  .landing-page-custom .button {
    --ifm-link-color: currentColor !important;
    --ifm-link-hover-color: currentColor !important;
  }
  
  /* Force primary button colors (black) */
  .hero-primary-btn,
  .hero-primary-btn:visited,
  .hero-primary-btn:active,
  .hero-primary-btn:focus,
  .cta-primary-btn,
  .cta-primary-btn:visited,
  .cta-primary-btn:active,
  .cta-primary-btn:focus {
    color: #FFFFFF !important;
    background:rgb(46, 46, 47) !important;
  }
  
  .hero-primary-btn:hover,
  .cta-primary-btn:hover {
    color: #FFFFFF !important;
    background: #2A2A2F !important;
  }
  
  /* Force secondary button colors */
  [data-theme='light'] .hero-secondary-btn,
  [data-theme='light'] .hero-secondary-btn:visited,
  [data-theme='light'] .hero-secondary-btn:active,
  [data-theme='light'] .hero-secondary-btn:focus,
  [data-theme='light'] .cta-secondary-btn,
  [data-theme='light'] .cta-secondary-btn:visited,
  [data-theme='light'] .cta-secondary-btn:active,
  [data-theme='light'] .cta-secondary-btn:focus {
    color: #5A5A6E !important;
  }
  
  [data-theme='light'] .hero-secondary-btn:hover,
  [data-theme='light'] .cta-secondary-btn:hover {
    color: #3A3A4A !important;
  }
  
  [data-theme='dark'] .hero-secondary-btn,
  [data-theme='dark'] .hero-secondary-btn:visited,
  [data-theme='dark'] .hero-secondary-btn:active,
  [data-theme='dark'] .hero-secondary-btn:focus,
  [data-theme='dark'] .cta-secondary-btn,
  [data-theme='dark'] .cta-secondary-btn:visited,
  [data-theme='dark'] .cta-secondary-btn:active,
  [data-theme='dark'] .cta-secondary-btn:focus {
    color: #E3C1FF !important;
  }
  
  [data-theme='dark'] .hero-secondary-btn:hover,
  [data-theme='dark'] .cta-secondary-btn:hover {
    color: #FFFFFF !important;
  }
  
  /* Light mode card styles - optimized without glassmorphism */
  [data-theme='light'] .resource-card {
    background: #FFFFFF;
    border: 1px solid #E8E8F0;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
  }
  
  [data-theme='light'] .resource-card:hover {
    border-color: #B75FFF;
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.12);
  }
  
  [data-theme='light'] .card-glow {
    display: none; /* Disable glow in light mode for performance */
  }
  
  /* Dark mode - optimized without backdrop-filter */
  [data-theme='dark'] .resource-card {
    background: rgba(30, 30, 35, 0.6);
    border: 1px solid rgba(183, 95, 255, 0.15);
    box-shadow: 0 2px 12px rgba(0, 0, 0, 0.3);
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                background-color 0.15s ease,
                border-color 0.15s ease;
  }
  
  [data-theme='dark'] .resource-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: linear-gradient(135deg, 
      rgba(183, 95, 255, 0.08) 0%, 
      transparent 60%);
    opacity: 0;
    transition: opacity 0.15s ease;
    pointer-events: none;
  }
  
  [data-theme='dark'] .resource-card:hover {
    background: rgba(40, 40, 45, 0.7);
    border-color: rgba(183, 95, 255, 0.4);
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.2);
  }
  
  [data-theme='dark'] .resource-card:hover::before {
    opacity: 1;
  }
  
  /* Light mode CTA styling with solid purple background */
  [data-theme='light'] .landing-cta {
    background: #DDC2FB;
    border: 1px solid rgba(183, 95, 255, 0.3);
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
  }
  

  
  [data-theme='light'] .landing-cta .cta-glow {
    display: none; /* Disable glow in light mode for consistency */
  }
  
  /* Dark mode CTA styling with solid purple background */
  [data-theme='dark'] .landing-cta {
    background: #DDC2FB;
    border: 1px solid rgba(183, 95, 255, 0.3);
    box-shadow: 0 2px 12px rgba(0, 0, 0, 0.3);
  }
  
  /* Hover effects for both themes with purple background */
  [data-theme='light'] .landing-cta:hover,
  [data-theme='dark'] .landing-cta:hover {
    background: #D4B8F8; /* Slightly darker purple on hover */
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.15);
  }
  
  /* Responsive design */
  @media (max-width: 996px) {
    .landing-hero {
      padding: 4rem 1.5rem;
      margin: -1.5rem -1.5rem 3rem -1.5rem;
    }
    
    .hero-title {
      font-size: 3rem;
    }
    
    .resource-grid {
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    }
  }
  
  @media (max-width: 768px) {
    .hero-title {
      font-size: 2.5rem;
    }
    
    .hero-subtitle {
      font-size: 1.1rem;
      padding: 0 1rem;
    }
    
    .section-title {
      font-size: 2rem;
      font-weight: 400; /* Book weight */
    }
    
    .resource-grid {
      grid-template-columns: 1fr;
      gap: 1rem;
      padding: 0 1rem;
    }
    
    .card-content {
      padding: 1.5rem;
    }
    
    .landing-cta {
      margin: 4rem 1rem 2rem;
      padding: 3rem 1.5rem;
      border-radius: 16px;
    }
    
    .hero-buttons {
      flex-direction: column;
      align-items: stretch;
      width: 100%;
      max-width: 280px;
      margin: 0 auto;
    }
    
    .hero-buttons .button {
      width: 100%;
      text-align: center;
      justify-content: center;
      min-height: 48px;
      display: flex;
      align-items: center;
    }
  }
  
  /* Monospace for technical elements */
  .resource-card code {
    font-family: 'Geist Mono', 'Consolas', monospace;
  }
`}</style>

---

## How to Get 0G Token


:::info Network Details
- **Token**: Native gas token (EVM-compatible)
- **Chain ID**: 16661
- **Explorer**: [https://chainscan.0g.ai](https://chainscan.0g.ai)
- **Mainnet Launch**: September 2025
:::

## Centralized Exchanges

The most straightforward way to acquire $0G is through centralized exchanges. After purchasing, withdraw directly to the **0G Mainnet** (select "0G Chain" or "0G Mainnet" as the withdrawal network).

### Spot Trading

| Exchange | Trading Pairs |
|----------|---------------|
| **[HTX](https://www.htx.com/trade/0g_usdt)** | 0G/USDT |
| **[Binance](https://www.binance.com/en/trade/0G_USDT)** | 0G/USDT, 0G/USDC, 0G/BNB, 0G/FDUSD, 0G/TRY |
| **[Bybit](https://www.bybit.com/en/trade/spot/0G/USDT)** | 0G/USDT |
| **[MEXC](https://www.mexc.com/exchange/0G_USDT)** | 0G/USDT, 0G/USDC |
| **[KuCoin](https://www.kucoin.com/trade/0G-USDT)** | 0G/USDT |
| **[Gate.io](https://www.gate.io/trade/0G_USDT)** | 0G/USDT |
| **[Bitget](https://www.bitget.com/spot/0GUSDT)** | 0G/USDT |
| **[HashKey Exchange](https://global.hashkey.com/en-US/spot/0G_USDT)** | 0G/USDT |
| **[LBank](https://www.lbank.com/trade/0g_usdt)** | 0G/USDT |
| **[Upbit](https://upbit.com/exchange?code=CRIX.UPBIT.USDT-0G)** | 0G/USDT |
| **[Kraken](https://www.kraken.com/prices/0g)** | 0G/USDT |

## Bridge to 0G Chain

Use **[XSwap](https://xswap.link/)**, the official bridge for the 0G network, powered by [Chainlink CCIP](https://docs.chain.link/ccip/directory/mainnet/chain/0g-mainnet).

### XSwap Bridge

- **URL**: [https://xswap.link/bridge?toChain=16661](https://xswap.link/bridge?toChain=16661)
- **Supported Assets**: USDC and other tokens
- **Networks**: Ethereum ‚Üî 0G (with more chains coming)
- **Security**: Powered by [Chainlink CCIP](https://docs.chain.link/ccip/directory/mainnet/chain/0g-mainnet) with enterprise-grade security

**How to Bridge:**

1. Visit [xswap.link/bridge?toChain=16661](https://xswap.link/bridge?toChain=16661)
2. Connect your wallet (MetaMask, SafePal, etc.)
3. Select source chain (e.g., Ethereum) and 0G as destination
4. Choose asset to bridge (e.g., USDC)
5. Confirm transaction and wait for bridging to complete
6. Once bridged, swap your assets to $0G on the 0G Hub

## Swap on 0G Chain

Once you have assets on the 0G network, swap them for native $0G tokens.

### 0G Hub (Recommended)

- **URL**: [https://hub.0g.ai/swap](https://hub.0g.ai/swap)
- **Features**: Official swap interface for the 0G ecosystem
- **Powered by**: [Jaine](https://jaine.app/)
- **Available Pairs**: Multiple trading pairs including ETH, USDT, USDC

The 0G Hub provides seamless token swapping, portfolio tracking, and access to the entire 0G ecosystem.

## Wallet Setup

To receive and hold $0G, you need a wallet that supports the 0G network.

### Supported Wallets

- **[MetaMask](https://metamask.io/)** - Add 0G network manually via [Mainnet Overview](/developer-hub/mainnet/mainnet-overview)
- **[SafePal](https://www.safepal.com/)** - Native support for 0G chain
- **[OKX Wallet](https://www.okx.com/web3)** - Native support for 0G network
- **[Rabby](https://rabby.io/)** - Add 0G network manually

### Adding 0G Network

For detailed instructions on adding the 0G network to your wallet, including RPC endpoints and network configuration, visit the [Mainnet Overview](/developer-hub/mainnet/mainnet-overview) page.

---

For more information about the 0G network and its features, see [Understanding 0G](/introduction/understanding-0g).

---

## New Landing

import Link from '@docusaurus/Link';
import SocialProofSection from '@site/src/components/SocialProofSection';

  
    Build the Future of Decentralized AI
    
      <Link className="button button--primary button--lg hero-primary-btn" to="/developer-hub/getting-started">
        Quick Start
      </Link>
      <Link className="button button--outline button--primary button--lg hero-secondary-btn" to="/introduction/understanding-0g">
        Learn Concepts
      </Link>
    
  

  
    
    <Link to="/developer-hub/testnet/testnet-overview" className="resource-card">
      
      
        
          Join Testnet
        
        Connect to Galileo testnet and start building your first dApp on 0G
        
          Connect to Testnet ‚Üí
        
      
    </Link>

    <Link to="/concepts/chain" className="resource-card">
      
      
        
          New to 0G? Start Here
        
        Learn the basics of 0G's AI infrastructure and get oriented quickly
        
          Get Started ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/compute-network/inference" className="resource-card">
      
      
        
          Inference
        
        Integrate AI inference into your applications with SDKs
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/storage/sdk" className="resource-card">
      
      
        
          Storage SDK
        
        Store and retrieve massive datasets with Go and TypeScript client libraries
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/developer-hub/building-on-0g/compute-network/fine-tuning" className="resource-card">
      
      
        
          Fine-tuning
        
        Customize AI models for your specific use case with our command-line tools
        
          View Docs ‚Üí
        
      
    </Link>
    
    <Link to="/run-a-node/validator-node" className="resource-card">
      
      
        
          Run a Validator
        
        Secure the network and earn rewards by running a validator node
        
          Setup Guide ‚Üí
        
      
    </Link>
  

<SocialProofSection />

  
  Ready to Build?
  Join thousands of developers building the future of decentralized AI
  
    <Link className="button button--primary button--lg cta-primary-btn" to="/developer-hub/getting-started">
      View Full Documentation
    </Link>
  

<style>{`
  /* Global font family for landing page */
  .landing-page-custom,
  .landing-page-custom * {
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Global button styling for consistency */
  .landing-page-custom .button {
    border-radius: 12px;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Hide sidebar on landing page */
  .new-landing {
    --doc-sidebar-width: 0 !important;
  }
  
  /* Hide page title */
  .landing-page-custom h1:first-child,
  .landing-page-custom .theme-doc-markdown > h1:first-child,
  .landing-page-custom header h1,
  article > h1:first-child,
  main h1:first-child:not(.hero-title),
  .hide-title-wrapper ~ h1,
  h1:has(+ .hide-title-wrapper),
  .markdown > h1:first-child {
    display: none !important;
  }
  
  /* More aggressive title hiding */
  .landing-page-custom .markdown > *:first-child:is(h1) {
    display: none !important;
  }
  
  /* Hero Section */
  .landing-hero {
    text-align: center;
    padding: 6rem 2rem 4rem;
    margin-left: calc(-50vw + 50%);
    margin-right: calc(-50vw + 50%);
    margin-top: -2rem;
    margin-bottom: 3rem;
    width: 100vw;
    position: relative;
    overflow: hidden;
    background: linear-gradient(180deg, 
      rgba(146, 0, 225, 0.08) 0%, 
      rgba(183, 95, 255, 0.05) 50%, 
      transparent 100%);
  }
  
  .landing-hero::before {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    background: radial-gradient(ellipse at 20% 50%, rgba(146, 0, 225, 0.25) 0%, transparent 40%),
                radial-gradient(ellipse at 80% 50%, rgba(227, 193, 255, 0.2) 0%, transparent 40%);
    animation: float 20s ease-in-out infinite;
  }
  
  @keyframes float {
    0%, 100% { transform: translate(0, 0) rotate(0deg); }
    33% { transform: translate(30px, -30px) rotate(120deg); }
    66% { transform: translate(-20px, 20px) rotate(240deg); }
  }
  
  .hero-content {
    position: relative;
    z-index: 1;
  }
  
  .hero-title {
    font-size: 4rem;
    font-weight: 400; /* Book weight */
    margin-bottom: 1.5rem;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
    letter-spacing: -0.02em;
    line-height: 1.1;
  }
  
  /* Light mode hero title */
  [data-theme='light'] .hero-title {
    color: #1A1A1F;
  }
  
  /* Dark mode hero title */
  [data-theme='dark'] .hero-title {
    color: #F5F5F7;
  }
  
  .gradient-text {
    background: linear-gradient(135deg, #9200E1 0%, #B75FFF 50%, #CB8AFF 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }

  .text-purple{
    color: #B75FFF;
  }
  
  .hero-subtitle {
    font-size: 1.25rem;
    color: var(--ifm-color-secondary-darkest);
    max-width: 800px;
    margin: 0 auto 2.5rem;
    line-height: 1.6;
    opacity: 0.9;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .hero-buttons {
    display: flex;
    gap: 1rem;
    justify-content: center;
    flex-wrap: wrap;
  }
  
  .hero-primary-btn,
  .hero-secondary-btn,
  .cta-primary-btn,
  .cta-secondary-btn {
    line-height: 1.2;
    display: inline-flex;
    align-items: center;
  }
  
  .hero-primary-btn p,
  .hero-secondary-btn p,
  .cta-primary-btn p,
  .cta-secondary-btn p,
  .button p {
    margin: 0 !important;
  }
  
  /* Primary Button - Black with rounded corners */
  .hero-primary-btn {
    background: #1A1A1F;
    border: none;
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    color: #FFFFFF !important;
    box-shadow: 0 4px 14px rgba(26, 26, 31, 0.25);
  }
  
  .hero-primary-btn:hover {
    background: #2A2A2F;
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(26, 26, 31, 0.35);
    text-decoration: none;
    color: #FFFFFF !important;
  }
  
  /* Secondary Button Base - Soft purple/gray with rounded corners */
  .hero-secondary-btn {
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    border: 2px solid transparent;
  }
  
  .hero-secondary-btn:hover {
    transform: translateY(-2px);
    text-decoration: none;
  }
  
  /* Light mode secondary button - Gray */
  [data-theme='light'] .hero-secondary-btn {
    background: #F5F5F7;
    color: #5A5A6E !important;
    border-color: #E8E8F0;
  }
  
  [data-theme='light'] .hero-secondary-btn:hover {
    background: #EAEAEC;
    color: #3A3A4A !important;
    border-color: #D0D0D5;
    box-shadow: 0 4px 14px rgba(0, 0, 0, 0.1);
  }
  
  /* Dark mode secondary button - Soft purple */
  [data-theme='dark'] .hero-secondary-btn {
    background: rgba(183, 95, 255, 0.12);
    color: #E3C1FF !important;
    border-color: rgba(183, 95, 255, 0.3);
  }
  
  [data-theme='dark'] .hero-secondary-btn:hover {
    background: rgba(183, 95, 255, 0.2);
    color: #FFFFFF !important;
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 4px 14px rgba(183, 95, 255, 0.25);
  }
  
  /* Container adjustments */
  .landing-page-custom .theme-doc-markdown {
    max-width: 100%;
  }
  
  .landing-page-custom .container {
    max-width: 100%;
    padding: 0;
  }
  
  .landing-page-custom article {
    padding: 0;
  }
  
  /* Developer Section */
  .landing-section {
    margin: 2rem auto 4rem;
    max-width: 1200px;
    padding: 0 2rem;
  }
  
  .section-title {
    text-align: center;
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .section-subtitle {
    text-align: center;
    color: var(--ifm-color-secondary-darkest);
    margin-bottom: 3rem;
    font-size: 1.1rem;
    opacity: 0.9;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(340px, 1fr));
    gap: 1.5rem;
    max-width: 1200px;
    margin: 0 auto;
  }
  
  .resource-card {
    position: relative;
    border-radius: 16px;
    overflow: hidden;
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1), 
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1);
    text-decoration: none;
    color: inherit;
    display: block;
    will-change: transform;
    transform: translateZ(0); /* Force GPU acceleration */
    backface-visibility: hidden; /* Prevent flickering */
  }
  
  .card-glow {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: radial-gradient(circle at 50% 0%, rgba(183, 95, 255, 0.15) 0%, transparent 70%);
    opacity: 0;
    transition: opacity 0.2s ease;
    pointer-events: none;
    will-change: opacity;
  }
  
  .resource-card:hover .card-glow {
    opacity: 1;
  }
  
  .resource-card:hover {
    transform: translate3d(0, -4px, 0); /* Use 3D transform for GPU */
    text-decoration: none;
  }
  
  .resource-card * {
    text-decoration: none !important;
  }
  
  .card-content {
    position: relative;
    padding: 2rem;
    z-index: 1;
  }
  
  .card-header {
    margin-bottom: 1rem;
  }
  
  .card-header h3 {
    margin: 0;
    font-size: 1.5rem;
    font-weight: 400; /* Book weight */
    color: var(--ifm-heading-color);
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-card p {
    color: var(--ifm-color-secondary-darkest);
    margin-bottom: 1.5rem;
    line-height: 1.6;
    opacity: 0.9;
    min-height: 3.2em;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .card-footer {
    margin-top: auto;
  }
  
  .card-link {
    color: #B75FFF;
    font-weight: 600;
    font-size: 0.875rem;
    text-transform: uppercase;
    letter-spacing: 0.75px;
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
    transition: gap 0.3s ease;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .resource-card:hover .card-link {
    gap: 0.5rem;
  }
  
  /* Social Proof Section */
  .social-proof-section {
    padding: 6rem 2rem;
    text-align: center;
    position: relative;
    overflow: hidden;
  }
  
  .social-proof-section::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 1px;
    background: linear-gradient(90deg, 
      transparent 0%, 
      rgba(183, 95, 255, 0.3) 50%, 
      transparent 100%);
  }
  
  .stats-container {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 4rem;
    max-width: 800px;
    margin: 0 auto;
  }
  
  .stat-item {
    flex: 1;
    text-align: center;
  }
  
  .stat-number {
    font-size: 3.5rem;
    font-weight: 400; /* Book weight */
    background: linear-gradient(135deg, #9200E1 0%, #B75FFF 50%, #CB8AFF 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    line-height: 1.2;
    margin-bottom: 0.5rem;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* Fade in animation for stats */
  @keyframes fadeInUp {
    from {
      opacity: 0;
      transform: translateY(30px);
    }
    to {
      opacity: 1;
      transform: translateY(0);
    }
  }
  
  /* Initial state - hidden */
  .stat-item {
    opacity: 0;
    transform: translateY(30px);
    transition: opacity 0.8s ease-out, transform 0.8s ease-out;
  }
  
  /* Visible state - animated in */
  .stat-item.animate {
    opacity: 1;
    transform: translateY(0);
  }
  
  /* Stagger the animations */
  .stat-item:nth-child(1) {
    transition-delay: 0.2s;
  }
  
  .stat-item:nth-child(3) {
    transition-delay: 0.4s;
  }
  
  .stat-item:nth-child(5) {
    transition-delay: 0.6s;
  }
  
  .stat-label {
    font-size: 1.125rem;
    color: var(--ifm-color-secondary-darkest);
    opacity: 0.8;
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .stat-divider {
    width: 1px;
    height: 60px;
    background: linear-gradient(180deg, 
      transparent 0%, 
      rgba(183, 95, 255, 0.3) 50%, 
      transparent 100%);
  }
  
  /* Light mode adjustments */
  [data-theme='light'] .stat-label {
    color: #5A5A6E;
  }
  
  /* Dark mode adjustments */
  [data-theme='dark'] .stat-label {
    color: #C0B8D0;
  }
  
  /* Responsive stats */
  @media (max-width: 768px) {
    .stats-container {
      flex-direction: column;
      gap: 2rem;
    }
    
    .stat-divider {
      width: 60px;
      height: 1px;
    }
    
    .stat-number {
      font-size: 2.5rem;
    }
  }
  
  /* CTA Section */
  .landing-cta {
    text-align: center;
    padding: 4rem 3rem;
    margin: 6rem auto 2rem;
    max-width: 1200px;
    position: relative;
    border-radius: 16px;
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1), 
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1);
  }
  
  .cta-glow {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: radial-gradient(circle at 50% 0%, rgba(183, 95, 255, 0.15) 0%, transparent 70%);
    opacity: 0;
    transition: opacity 0.2s ease;
    pointer-events: none;
    border-radius: 16px;
  }
  
  .landing-cta:hover .cta-glow {
    opacity: 1;
  }
  
  .landing-cta:hover {
    transform: translate3d(0, -4px, 0);
  }
  
  .landing-cta h2 {
    font-size: 2.5rem;
    margin-bottom: 1rem;
    position: relative;
    z-index: 2;
    color: var(--ifm-heading-color);
    font-weight: 400; /* Book weight */
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  .landing-cta > p {
    font-size: 1.25rem;
    margin-bottom: 2rem;
    position: relative;
    z-index: 2;
    font-family: 'Regola Pro', system-ui, -apple-system, sans-serif;
  }
  
  /* CTA text colors for purple background */
  [data-theme='light'] .landing-cta > p,
  [data-theme='dark'] .landing-cta > p {
    color: #4A4A5A;
    opacity: 0.95;
  }
  
  /* CTA heading colors for purple background */
  [data-theme='light'] .landing-cta h2,
  [data-theme='dark'] .landing-cta h2 {
    color: #2A2A3A;
  }
  
  /* Ensure button text is not affected */
  .landing-cta .button p {
    color: inherit !important;
    opacity: 1 !important;
  }
  
  .cta-buttons {
    display: flex;
    gap: 1rem;
    justify-content: center;
    flex-wrap: wrap;
    position: relative;
    z-index: 2;
  }
  
  /* CTA Primary Button - Black with rounded corners */
  .cta-primary-btn {
    background: #1A1A1F;
    border: none;
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2.5rem;
    border-radius: 12px;
    color: #FFFFFF !important;
    transition: all 0.3s ease;
    box-shadow: 0 4px 14px rgba(26, 26, 31, 0.25);
  }
  
  .cta-primary-btn:hover {
    background: #2A2A2F;
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(26, 26, 31, 0.35);
    text-decoration: none;
    color: #FFFFFF !important;
  }
  
  /* CTA Secondary Button Base - Matching hero secondary */
  .cta-secondary-btn {
    font-weight: 400; /* Book weight */
    padding: 0.875rem 2.5rem;
    border-radius: 12px;
    transition: all 0.3s ease;
    border: 2px solid transparent;
  }
  
  .cta-secondary-btn:hover {
    transform: translateY(-2px);
    text-decoration: none;
  }
  
  /* CTA Secondary Button - Light Mode (Gray) */
  [data-theme='light'] .cta-secondary-btn {
    background: #F5F5F7;
    color: #5A5A6E !important;
    border-color: #E8E8F0;
  }
  
  [data-theme='light'] .cta-secondary-btn:hover {
    background: #EAEAEC;
    color: #3A3A4A !important;
    border-color: #D0D0D5;
    box-shadow: 0 4px 14px rgba(0, 0, 0, 0.1);
  }
  
  /* CTA Secondary Button - Dark Mode (Soft purple) */
  [data-theme='dark'] .cta-secondary-btn {
    background: rgba(183, 95, 255, 0.12);
    color: #E3C1FF !important;
    border-color: rgba(183, 95, 255, 0.3);
  }
  
  [data-theme='dark'] .cta-secondary-btn:hover {
    background: rgba(183, 95, 255, 0.2);
    color: #FFFFFF !important;
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 4px 14px rgba(183, 95, 255, 0.25);
  }
  
  /* Override any inherited styles - Force button colors */
  .landing-page-custom .button {
    --ifm-link-color: currentColor !important;
    --ifm-link-hover-color: currentColor !important;
  }
  
  /* Force primary button colors (black) */
  .hero-primary-btn,
  .hero-primary-btn:visited,
  .hero-primary-btn:active,
  .hero-primary-btn:focus,
  .cta-primary-btn,
  .cta-primary-btn:visited,
  .cta-primary-btn:active,
  .cta-primary-btn:focus {
    color: #FFFFFF !important;
    background:rgb(46, 46, 47) !important;
  }
  
  .hero-primary-btn:hover,
  .cta-primary-btn:hover {
    color: #FFFFFF !important;
    background: #2A2A2F !important;
  }
  
  /* Force secondary button colors */
  [data-theme='light'] .hero-secondary-btn,
  [data-theme='light'] .hero-secondary-btn:visited,
  [data-theme='light'] .hero-secondary-btn:active,
  [data-theme='light'] .hero-secondary-btn:focus,
  [data-theme='light'] .cta-secondary-btn,
  [data-theme='light'] .cta-secondary-btn:visited,
  [data-theme='light'] .cta-secondary-btn:active,
  [data-theme='light'] .cta-secondary-btn:focus {
    color: #5A5A6E !important;
  }
  
  [data-theme='light'] .hero-secondary-btn:hover,
  [data-theme='light'] .cta-secondary-btn:hover {
    color: #3A3A4A !important;
  }
  
  [data-theme='dark'] .hero-secondary-btn,
  [data-theme='dark'] .hero-secondary-btn:visited,
  [data-theme='dark'] .hero-secondary-btn:active,
  [data-theme='dark'] .hero-secondary-btn:focus,
  [data-theme='dark'] .cta-secondary-btn,
  [data-theme='dark'] .cta-secondary-btn:visited,
  [data-theme='dark'] .cta-secondary-btn:active,
  [data-theme='dark'] .cta-secondary-btn:focus {
    color: #E3C1FF !important;
  }
  
  [data-theme='dark'] .hero-secondary-btn:hover,
  [data-theme='dark'] .cta-secondary-btn:hover {
    color: #FFFFFF !important;
  }
  
  /* Light mode card styles - optimized without glassmorphism */
  [data-theme='light'] .resource-card {
    background: #FFFFFF;
    border: 1px solid #E8E8F0;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
  }
  
  [data-theme='light'] .resource-card:hover {
    border-color: #B75FFF;
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.12);
  }
  
  [data-theme='light'] .card-glow {
    display: none; /* Disable glow in light mode for performance */
  }
  
  /* Dark mode - optimized without backdrop-filter */
  [data-theme='dark'] .resource-card {
    background: rgba(30, 30, 35, 0.6);
    border: 1px solid rgba(183, 95, 255, 0.15);
    box-shadow: 0 2px 12px rgba(0, 0, 0, 0.3);
    transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                background-color 0.15s ease,
                border-color 0.15s ease;
  }
  
  [data-theme='dark'] .resource-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: linear-gradient(135deg, 
      rgba(183, 95, 255, 0.08) 0%, 
      transparent 60%);
    opacity: 0;
    transition: opacity 0.15s ease;
    pointer-events: none;
  }
  
  [data-theme='dark'] .resource-card:hover {
    background: rgba(40, 40, 45, 0.7);
    border-color: rgba(183, 95, 255, 0.4);
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.2);
  }
  
  [data-theme='dark'] .resource-card:hover::before {
    opacity: 1;
  }
  
  /* Light mode CTA styling with solid purple background */
  [data-theme='light'] .landing-cta {
    background: #DDC2FB;
    border: 1px solid rgba(183, 95, 255, 0.3);
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
  }
  

  
  [data-theme='light'] .landing-cta .cta-glow {
    display: none; /* Disable glow in light mode for consistency */
  }
  
  /* Dark mode CTA styling with solid purple background */
  [data-theme='dark'] .landing-cta {
    background: #DDC2FB;
    border: 1px solid rgba(183, 95, 255, 0.3);
    box-shadow: 0 2px 12px rgba(0, 0, 0, 0.3);
  }
  
  /* Hover effects for both themes with purple background */
  [data-theme='light'] .landing-cta:hover,
  [data-theme='dark'] .landing-cta:hover {
    background: #D4B8F8; /* Slightly darker purple on hover */
    border-color: rgba(183, 95, 255, 0.5);
    box-shadow: 0 8px 24px rgba(146, 0, 225, 0.15);
  }
  
  /* Responsive design */
  @media (max-width: 996px) {
    .landing-hero {
      padding: 4rem 1.5rem;
      margin: -1.5rem -1.5rem 3rem -1.5rem;
    }
    
    .hero-title {
      font-size: 3rem;
    }
    
    .resource-grid {
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    }
  }
  
  @media (max-width: 768px) {
    .hero-title {
      font-size: 2.5rem;
    }
    
    .hero-subtitle {
      font-size: 1.1rem;
      padding: 0 1rem;
    }
    
    .section-title {
      font-size: 2rem;
      font-weight: 400; /* Book weight */
    }
    
    .resource-grid {
      grid-template-columns: 1fr;
      gap: 1rem;
      padding: 0 1rem;
    }
    
    .card-content {
      padding: 1.5rem;
    }
    
    .landing-cta {
      margin: 4rem 1rem 2rem;
      padding: 3rem 1.5rem;
      border-radius: 16px;
    }
    
    .hero-buttons {
      flex-direction: column;
      align-items: stretch;
      width: 100%;
      max-width: 280px;
      margin: 0 auto;
    }
    
    .hero-buttons .button {
      width: 100%;
      text-align: center;
      justify-content: center;
      min-height: 48px;
      display: flex;
      align-items: center;
    }
  }
  
  /* Monospace for technical elements */
  .resource-card code {
    font-family: 'Geist Mono', 'Consolas', monospace;
  }
`}</style>

---

## Understanding 0G


import LottieAnimation from '@site/src/components/lottieAnimation';

## Why 0G Exists

AI (Artificial Intelligence) is rapidly advancing, but its powerful capabilities are largely confined to centralized systems & limited to a few large companies. Bringing AI onto the blockchain unlocks transformative potential: truly verifiable AI, user-owned data powering AI applications, and open, censorship-resistant AI development.

However, a fundamental challenge has held back this vision:
- **AI's Data Hunger:** AI models and datasets are massive. Existing blockchains make storing and accessing this data impossibly expensive and slow.
- **Intense Compute Demands:** AI requires significant processing power, far beyond what traditional blockchains can offer efficiently.
- **Need for Speed:** Real-time AI applications demand high throughput and low latency

Without overcoming these hurdles, the dream of decentralized AI remains out of reach.

**0G is built to break these barriers.** We provide the foundational infrastructure like high-performance storage, scalable compute, and a fast, modular blockchain‚Äîdesigned from the ground up to power the future of on-chain AI.

## What is 0G?

0G (Zero Gravity) is the first decentralized AI L1 chain that orchestrates hardware resources (storage, compute) and software assets (data, models) to handle AI workloads at scale. It bridges the gap between Web2 AI capabilities and Web3 decentralization.

:::info 0G is building the global foundation for a better, fairer, and more open AI ecosystem, where power is distributed and innovation thrives
:::

**How it works**: 0G provides four independent services that solve different pieces of the AI + blockchain puzzle:
- **Storage** ‚Üí Where to keep massive AI datasets
- **Compute** ‚Üí How to run AI models economically  
- **Chain** ‚Üí Where to execute AI transactions quickly
- **Data Availability** ‚Üí How to ensure data is always accessible

  

## Modular Architecture

:::tip Key Benefit of Modular Architecture: You DON'T need to use all of 0G!
**Pick only what you need:**
- **Already on Ethereum, Polygon, or any EVM chain?** Use 0G Storage and Compute directly from your existing smart contracts, no need to migrate.
- **Building on Solana or other non-EVM chains?** Our SDKs support cross-chain integration
- **Just need one service?** Use only 0G Storage or only 0G Compute
:::

## The 4 Components of 0G

| Component             | Works Independently?                                   | Key Features & Use Cases                                                          | Cost Highlight                        |
|-----------------------|--------------------------------------------------------|-----------------------------------------------------------------------------------|---------------------------------------|
| **0G Chain**        | ‚úÖ Yes (Optional for other services)             | Fastest modular EVM L1 for AI agents, DeFi with AI logic        | Low gas fees in 0G token              |
| **0G Storage**     | ‚úÖ Yes (Any app/chain can access)                       | Store AI models (GBs-TBs), training datasets, user files, game assets            | 10-100x cheaper than alternatives     |
| **0G Compute**     | ‚úÖ Yes (Any app/chain can access)                     | Run AI inference, model training, verifiable compute, ML pipelines               | Pay-only-for-what-you-use             |
| **0G DA**          | ‚úÖ Yes (Works with any rollup/L1/L2)                  | Power gaming chains, AI rollups, high-frequency trading chains                   | Economical for high-volume DA         |

*\*0G Storage can be used completely standalone without any blockchain integration - perfect for traditional apps needing decentralized storage.*

## Key Concepts Explained Simply

<details>
<summary>**What is decentralized storage?**</summary>

Instead of storing your files on one company's computer (like Google Drive), they're split and stored across hundreds of computers worldwide.

**Why it matters**: If Google's servers crash, you lose access. With decentralized storage, even if 50 computers fail, your data is still safe and accessible.
</details>

<details>
<summary>**What is data availability?**</summary>

It's a guarantee that your data can always be accessed when needed, like having multiple backup generators for your house.

**Why it matters**: In blockchain, if data isn't available, the whole system can freeze. 0G ensures this never happens.
</details>

<details>
<summary>**What is an AI compute network?**</summary>

It's like Uber for computing power - connect to available GPUs when you need to run AI models, pay only for what you use.

**Why it matters**: Instead of buying expensive GPUs or relying on big tech companies, access computing power on-demand from a global network.
</details>

<details>
<summary>**What is a modular blockchain?**</summary>

Like LEGO blocks, each part of the blockchain (storing data, processing transactions, reaching agreement) is separate and can be upgraded independently.

**Why it matters**: Traditional blockchains are like old phones where you can't upgrade just the camera. Modular blockchains let you improve each part without rebuilding everything.
</details>

## Why "Zero Gravity"?

"0G" represents "Zero Gravity" - the state where everything flows effortlessly. Just as astronauts move freely in zero gravity, data and AI computations flow seamlessly through our network without the heavy "gravity" of:
- High costs
- Slow speeds  
- Technical barriers
- Platform lock-in

## What Can You Build?

With 0G's technology, previously impossible use cases are now within reach:

- **On-chain AI agents** that learn and evolve
- **Decentralized ChatGPT** alternatives
- **AI-powered DeFi** trading systems
- **Medical AI** with patient-owned data
- **Large-scale ML training** without AWS bills

And this is just the beginning.

## Where to Go Next

Now that you understand what 0G is and why it exists, here's how to dive deeper:

**For Learners** ‚Üí Read more about [Concepts](/concepts/chain) to understand how each component works  
**For Builders** ‚Üí Jump into the [Developer Hub](/developer-hub/getting-started) to start building  
**For Operators** ‚Üí Learn how to [Run a Node](/run-a-node/overview) and earn rewards

## Join the 0G Community

- [Discord](https://discord.gg/0gLabs) - Get help and chat with builders
- [X(Twitter)](https://x.com/0g_Labs) - Latest updates and announcements
- [GitHub](https://github.com/0gfoundation/0g-doc) - Contribute to the project

We're excited to have you on board as we build the future of Web3 √ó AI together!

<LottieAnimation />

---

## Vision & Mission


## Our Mission: Make AI a Public Good

At 0G, our mission is clear: **To Make AI a Public Good**.

We believe that AI technology should be accessible, transparent, and beneficial to everyone, not just a select few. By building a decentralized AI operating system, we're creating the infrastructure that will enable this vision.

## Our Vision

We envision a world where:

- **AI is democratized**: Anyone can access and contribute to AI development without gatekeepers
- **AI is transparent**: The models, data, and processes are open and verifiable
- **AI is fair**: Resources and benefits are distributed equitably across the network
- **AI is secure**: Decentralization ensures no single point of failure or control

## How We Achieve This

Every component of our ecosystem contributes toward this goal:

1. **Open Infrastructure**: By providing decentralized storage, compute, and data availability, we remove the barriers to AI development
2. **Community Ownership**: Through our node network and governance model, the community owns and operates the infrastructure
3. **Economic Alignment**: Our tokenomics ensure that contributors are fairly rewarded for their participation
4. **Technical Excellence**: We build the fastest, most efficient infrastructure to make decentralized AI competitive with centralized alternatives

## Join Our Mission

We invite you to join us in building the foundation for a decentralized AI future. Whether you're a developer, node operator, or community member, there's a place for you in the 0G ecosystem.

Together, we're not just building technology ‚Äì we're shaping the future of AI for the benefit of all humanity.

## Join the 0G Community

- [Discord](https://discord.gg/0gLabs)
- [X(Twitter)](https://x.com/0g_Labs)
- [GitHub](https://github.com/0gfoundation/0g-doc)

---

## 0G AI Alignment Node - Guide

---

::::info **Who this is for & what you'll learn**
- Run your own Alignment Node or delegate to a NAAS provider
- Understand system requirements, setup steps, and monitoring
- Learn NAAS models (commission vs prepaid) and how to delegate/undelegate
::::

## Overview

The 0G AI Alignment Node system allows license holders to participate in the network either by running their own nodes or delegating to Node as a Service (NAAS) providers. This guide covers both options to help you choose the best approach for your needs.

## Choose Your Path

### Quick decision summary

| Option | Best for | Setup time | Rewards | Maintenance |
|-------|----------|-----------|---------|-------------|
| **Option 1: [Delegate to NAAS](#option-1-delegating-to-naas-providers)** | Non-technical users | 2-3 Minutes | 100% (prepaid) or minus commission | Provider handles |
| **Option 2: [Run your own](#option-2-running-your-own-node)** | Technical users | 1-2 Hours | 100% | You handle |

---

## Option 1: Delegating to NAAS Providers

### Understanding NAAS Models

NAAS providers offer two delegation models:

#### Commission-Based Model
- **How it works:** NAAS provider takes a percentage of your rewards as commission
- **Payment:** No upfront payment required
- **Status:** Nodes start as "Active" immediately
- **Best for:** Users who prefer sharing rewards over upfront payments

#### Prepaid Model
- **How it works:** Pay a fixed fee upfront for node operation
- **Payment:** One-time or recurring prepaid fee
- **Status:** Nodes start as "Expired" until payment is confirmed
- **Best for:** Users who want predictable costs

### How to Delegate

#### Step 1: Choose a NAAS Provider

1. Access the [0G Claim Portal](https://claim.0gfoundation.ai)
2. Navigate to the NAAS Providers section
3. Review available providers:
   - **Name & Description**: Provider details
   - **Commission Rate**: Percentage for commission-based model
   - **Prepaid Price**: Cost for prepaid nodes
   - **Reputation**: Community ratings and uptime statistics

   ![NAAS Providers](../../static/img/naas.png)

#### Step 2: Complete Provider Onboarding

1. Visit the selected NAAS provider's platform (URL provided in portal)
2. Complete their onboarding process:
   - Create an account
   - Choose delegation model (commission or prepaid)
   - If prepaid, complete payment
3. Receive your **Target NAAS Node Address** from the provider

**Important:** Save this address - you'll need it for delegation.

#### Step 3: Delegate Your Licenses

1. Return to the 0G Portal
2. Login with your wallet containing licenses
3. Navigate to "My Licenses"
4. Select license(s) to delegate
5. Choose "Delegate" action
6. Enter the **Target NAAS Node Address** provided by your NAAS provider
7. Confirm the transaction

![Delegate Licenses](../../static/img/delegate.png)

#### Step 4: Monitor Delegation Status

Your delegation will show different statuses:

| Status | Description |
|--------|------------|
| **Inactive** | License not delegated |
| **Pending** | Delegation submitted, awaiting NAAS approval |
| **Delegated** | Active and earning rewards |
| **Expired** | Prepaid period ended or payment issue |

### Managing Your Delegation

#### Checking Status
1. Access the 0G Portal
2. Navigate to "My Licenses"
3. View delegation status for each license

#### Undelegating
To reclaim your licenses:

1. Select delegated license(s)
2. Choose "Undelegate"
3. Confirm the transaction
4. Licenses immediately return to "Inactive" status

**Note:** Undelegation is immediate and doesn't require NAAS approval.

#### Switching Providers
1. First undelegate from current provider
2. Wait for transaction confirmation
3. Follow delegation steps with new provider

### NAAS Payment Management

#### For Commission-Based:
- Rewards automatically distributed after commission deduction
- No action required from you
- Monitor earnings in the portal

#### For Prepaid:
- Track expiration dates
- Renew before expiration to avoid downtime
- Provider will update status upon payment
- Node shows "Expired" if payment lapses

---

## Option 2: Running Your Own Node

### System Requirements

Before setting up your node, ensure your system meets these minimum specifications:

| Component | Minimum Requirement |
|-----------|-------------------|
| **RAM** | 64 MB |
| **CPU** | 1 x86 Core @ 2.1GHz |
| **Disk Space** | 10 GB |
| **Internet** | 10 Mbps connection |
| **Network** | Port must be externally accessible (configure in firewall) |

### Installation & Setup

#### Step 1: Download the Node Binary

Download the latest 0G alignment node binary from the official repository:

```bash
# Download the binary (replace with actual URL)
wget https://github.com/0gfoundation/alignment-node-release/releases/download/v1.0.0/alignment-node.tar.gz

tar -xzf alignment-node.tar.gz

cd alignment-node

chmod +x 0g-alignment-node
```

#### Step 2: Configure Environment

1. Copy the example environment file:
```bash
cp .env.example .env
```

2. Edit the `.env` file with your configuration:
```bash
nano .env
```

3. Configure the following parameters:

```bash
export ZG_ALIGNMENT_NODE_LOG_LEVEL=debug
export ZG_ALIGNMENT_NODE_SERVICE_IP="http://127.0.0.1:34567"  # Full URL endpoint
export ZG_ALIGNMENT_NODE_SERVICE_PRIVATEKEY=your_private_key_here
```

:::note
The private key is the private key of the wallet you used to purchase the NFT. If the wallet doesn't have any NFTs, the wallet is not eligible to register as operator.
:::

**Important Configuration Notes:**
- **LOG_LEVEL**: Set to `debug` for troubleshooting, `info` for normal operation
- **SERVICE_IP**: The ip of the service you are running. You need to add the external ip of the node to the `.env` file. The external ip is the ip of the node that is accessible from the internet.
- **PRIVATEKEY**: Your wallet's private key that holds the alignment node license(s)

#### Step 3: Network Configuration

::::warning **Open your service port**
The port specified in your configuration must be accessible externally for consensus communication.

Make sure this port is open in:
- Cloud security groups/firewalls (AWS, Azure, GCP, etc.)
- VPS provider firewalls
- Local server firewall rules

Steps vary by provider; consult your host's docs.
::::

#### Step 4: Start Your Node

1. Load environment variables:
```bash
source .env
```

2. Register the operator:
```bash
./0g-alignment-node registerOperator --key <your_private_key> --token-id <your_token_id> --chain-id <chain_id> --rpc <rpc_url> --contract <contract_address>
```

:::note
The token id is the token id of the NFT you purchased. The private key is the private key of the wallet you used to purchase the NFT. If the wallet doesn't have any NFTs, the wallet is not eligible to register as operator.
:::

**Configuration Details:**
- **Chain ID**: `42161` (Arbitrum Mainnet)
- **RPC URL**: Use a reliable Arbitrum RPC endpoint such as:
  - `https://arb1.arbitrum.io/rpc` (Public endpoint)
  - Or your preferred Arbitrum RPC provider
- **Alignment manager contract address**: `0xdD158B8A76566bC0c342893568e8fd3F08A9dAac` (Arbitrum Mainnet)

3. Start the node:
```bash
./0g-alignment-node start --mainnet
```

4. To run in background (recommended for production):
```bash
nohup ./0g-alignment-node start --mainnet > node.log 2>&1 &
```

### Monitoring Your Node

View logs:
```bash
tail -f node.log
```

### Node command help
```bash
./0g-alignment-node --help

./0g-alignment-node <command> --help
```

::::tip **Healthy node checklist**
- Status reports without errors
- Logs show steady activity, no repeated crashes
::::

### Troubleshooting

**Node not connecting:**
- Verify port is open and accessible externally
- Check your firewall/security group settings
- Ensure private key has associated licenses

**Node crashes:**
- Check logs for errors
- Verify system requirements are met
- Ensure stable internet connection

---

## Best Practices

### For Self-Hosted Nodes
1. **Regular Updates**: Keep node binary updated
2. **Monitoring**: Set up alerts for downtime
3. **Backup**: Keep secure backup of private keys
4. **Security**: Use dedicated wallet for node operation
5. **Network**: Ensure stable internet connection

### For NAAS Delegation
1. **Research Providers**: Check reputation and uptime history
2. **Understand Terms**: Read commission rates and prepaid terms
3. **Monitor Status**: Regularly check delegation status
4. **Payment Tracking**: Set reminders for prepaid renewals
5. **Diversification**: Consider splitting licenses across providers

---

---

## Compliance and Regulatory Requirements

## Regulation S Compliance
The sale follows Regulation S guidelines, restricting U.S. persons from participating. The sale website, promotional content, and user interface clearly indicate these restrictions, and KYC verification is mandatory for claiming rewards to maintain regulatory adherence. Prospective participants are advised to review these conditions and understand that resale of node licenses is not permitted within the first 12 months.
## Information Disclosure
All communications related to the sale are made with transparency but exclude any directed selling to U.S. persons. Information shared in marketing materials, promotional activities, and social media avoids U.S.-targeted content, aligning with compliance requirements to mitigate any regulatory risks.

---

## Incentives & Rewards

# Incentives, Rewards, and Vesting Mechanisms

## Rebate/Commission Portal Tutorial
<iframe
    width="100%"
    height="400"
    src="https://www.youtube.com/embed/poc3NPiFGi0"
    title="Rebate/Commission Portal Tutorial"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen
></iframe>

## How can node buyers create a referral code?
Node buyers will be able to share their wallet address as the referral code after they made a purchase, it would give a 10% rebate to their referrals. 

## What rebate is available when using a referral code?
If you enter a referral code when purchasing a node, you'll receive a 10% rebate on the total price. 

## How will I receive my commission? (For Referrers)‚Äã
You will be able to claim the commission of any successful node purchased through the node on the reward claim site, which will be available after the public sale. Please refer to the 0G X for access to the claim site closer to the sale date.

## Vesting Terms
Rewards from node operation vest over a three-year schedule, promoting consistent and long-term engagement. Vesting reduces the likelihood of short-term sales, fostering network stability and growth.

## Additional Community Incentives
Partnerships, 0G ecosystem communities, and referrals provide extra benefits, such as rebates or promotional whitelist access. All promotional activities adhere to [regulatory guidelines](https://0gfoundation.ai/disclaimer), and any reward or referral payments are conditional upon KYC eligibility.

---

## KYC Verification Guide


## Introduction

The 0G Alignment Node Portal requires users to complete a Know Your Customer (KYC) verification process to ensure secure and compliant participation. This comprehensive guide will walk you through each step of the verification process using Blockpass, our current KYC provider.

:::info Additional KYC Providers Coming Soon
Additional KYC provider options will be available soon to provide more flexibility for users.
:::

---

## Eligibility Requirements

Before starting the KYC process, please ensure you meet the following requirements:

### Age Requirement

You must be at least 18 years old to participate in the 0G Alignment Node Portal.

### Geographic Restrictions

Due to regulatory requirements, users from the following countries and regions are **not eligible** to participate:

**Restricted Countries:**
- Belarus, the Central African Republic, The Democratic Republic of Congo, the Democratic People's Republic of Korea, Cuba, Iran, Libya, Russia, Somalia, Sudan, South Sudan, Venezuela, Yemen, Zimbabwe. 

**Restricted Regions:**
- Ukraine: Crimea region, Donetsk People's Republic (DNR), Luhansk People's Republic (LNR), Kherson region, and Zaporizhia region 

:::important Geographic Restrictions
If you reside in any of these restricted locations, you will not be able to complete the KYC process. This restriction is in place to comply with international regulations and sanctions.
:::

---

## Pre-Verification Checklist

Before starting your KYC verification, ensure you have:

- Valid government-issued ID
- Recent proof of address document
- Good lighting for selfie verification
- Stable internet connection (disable VPN)
- Desktop/laptop for wallet signing
- Compatible browser (Chrome/Firefox recommended)
- 15-20 minutes of uninterrupted time

---

## Getting Started

<details>
<summary>Video Guide</summary>

Step by step video guide to complete the KYC process.

### Step 1: Start the KYC Process

Go to the [KYC page](https://claim.0gfoundation.ai/kyc). Connect your wallet and click on "Start KYC" button.

  <iframe width="560" height="315" src="https://www.youtube.com/embed/5LohD5xwl8k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Step 2: Submit Documents

Upload the required documents, complete the selfie verification. This submission can also be done on mobile for easier document upload.Make sure to close the mobile browser tab after submitting the documents before opening new session on desktop.

  <iframe width="560" height="315" src="https://www.youtube.com/embed/97dwcNCs6Lg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Step 3: Complete Wallet Verification

This step is critical and must be completed on desktop. Even if you submitted documents on mobile, you must complete this step on desktop so trigger the magic link again from portal (like the step 1), open the link in desktop browser and continue from there.

  <iframe width="560" height="315" src="https://www.youtube.com/embed/FzySS1S2HpE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</details>

### Step 1: Connect Your Wallet

Before beginning the KYC process, you'll need to connect your wallet to the 0G platform:

1. Navigate to the KYC section in your dashboard
2. Click **"Connect Wallet"** to initiate the verification process
3. Wait for the wallet connection to be confirmed
4. Click "Start KYC" to get started

![kyc-flow-1](/img/kyc-flow-1.png)
![kyc-flow-2](/img/kyc-flow-2.png)

### Step 2: Choose Your KYC Provider

Currently, **Blockpass** is integrated as our primary KYC verification service

- Select **"Blockpass (Recommended)"**
- Click **"Continue"** to proceed

![kyc-flow-3](/img/kyc-flow-3.png)

---

## Creating Your Blockpass Account

### Email Registration Process

1. Enter your email address in the Blockpass modal
2. Choose whether to:
    - Create a new account, or
    - Use an existing Blockpass account
3. For new users:
    - A magic link will be sent to your email
    - Check your inbox and click the link, This will take you to the document upload interface

:::tip Progress Saving
If you've already started the process, Blockpass will remember your progress and allow you to continue where you left off.
:::

---

## Document Upload Process

![kyc-flow-4](/img/kyc-flow-4.png)

### Required Documents Checklist

You'll need to provide the following three types of verification:

### 1. Government-Issued ID (Choose One)

- Passport
- National ID
- Driving License

### 2. Proof of Address

- Utility bill
- Bank statement
- Other supported documents

### 3. Liveness Verification

- Selfie verification with liveness check

### Document Upload Guidelines

### For ID Documents:

- **Preparation:**
    - Open your document to the data page
    - Find good lighting conditions
    - Clean your camera lens
- **Capture Requirements:**
    - All four corners must be visible
    - Avoid glare and shadows
    - Ensure text is clear and readable
    - Document should fill most of the frame

  

:::important Data Extraction Accuracy
Even if the automatic data extraction shows incorrect information, proceed with submission. Our verification team will handle corrections during the manual review process.
:::

  

### For Address Proof:

- Upload a document from the supported list
- Ensure your current residential address is clearly visible
- Document should be recent (typically within 3 months)

### For Selfie Verification:

1. **Setup:**
    - Find a well-lit room
    - Remove glasses if they cause glare
    - Position yourself at arm's length from camera
2. **Process:**
    - The system will auto-capture your face
    - Follow on-screen prompts:
        - Look straight ahead
        - Turn your head left when prompted
        - Turn your head right when prompted
    - Complete all requested movements

  

<details>
<summary>Cross-Device Flexibility</summary>

One of Blockpass's convenient features is seamless cross-device compatibility:

- Use the **"Email me a link"** button on any page
- Continue your KYC process on any device
- All progress is automatically saved
- Switch between mobile and desktop as needed

**Recommended Workflow:**
1. **Mobile:** Upload documents using your phone's camera
2. **Desktop:** Complete wallet verification for better experience
3. **Either:** Check status and make corrections
</details>

---

## Wallet Verification (Critical Step)

### Desktop Strongly Recommended

While you can complete most steps on mobile, **we strongly recommend using a desktop or laptop for wallet verification**.

### Benefits of Desktop Verification

- Better signing experience
- More stable connection to wallet extensions
- Smoother completion of mandatory signing

### How to Switch to Desktop

1. **Complete initial steps on mobile (if preferred):**
    - Upload all documents
    - Complete selfie verification
    - Close the mobile browser tab
2. **Continue on desktop:**
    - Open Blockpass on your desktop browser
    - Log in using the same email address
    - Use magic link or password to access your account
3. **Resume verification:**
    - Select **"Register with document"**
    
      
    
    - Choose the same ID type you selected earlier
    - All your information will be pre-filled from the last session
    
      
    

4. **Complete wallet verification:**
    - Connect your wallet (MetaMask, WalletConnect, or Coinbase)
    - Sign the verification message when prompted
    - Confirm the signature in your wallet app

:::important Mandatory Wallet Signing
The wallet signing step is mandatory. Submissions without proper signing will NOT be approved due to KYC compliance requirements.
:::

---

## Final Submission

### Before Submitting:

- Review all uploaded documents
- Ensure wallet is properly connected and verified
- Check that all sections show "completed" status

### To Submit:

1. Once all steps Completed
2. The **"Register"** button will become active
3. Click **"Register"** to submit for KYC verification
4. You'll see a confirmation screen, You can set password on this screen for future changes

  

  

---

## Verification Timeline

| Stage | Timeframe |
| --- | --- |
| Initial Review | 24-36 hours |
| Additional Checks (if needed) | 12-24 hours |
| Final Approval | Email notification |

### What to Expect:

- Email notifications at each stage
- Clear feedback if any issues arise
- Direct communication for any clarifications needed

---

## Handling Rejections

If your KYC application is rejected, don't worry! Here's what to do:

### Steps to Resubmit:

1. **Check your email** for specific rejection reasons
2. **Log back in** using the same email address
3. **Navigate** to the rejected document section
4. **Update** only the required documents or information
5. **Resubmit** for re-verification

---

## Frequently Asked Questions

<details>
<summary>How can I ensure my documents are accepted on first submission?</summary>

- Use good lighting and steady hands when taking photos
- Ensure all documents show matching details
- Use valid, non-expired identification
- Clean your camera lens before capturing documents
- Make sure all four corners of documents are visible
- Avoid glare and shadows
</details>

<details>
<summary>What's the best way to complete the KYC process?</summary>

- Complete the process in one session if possible
- Have all documents ready before starting
- Use Chrome, Safari or Firefox browsers for best compatibility
- Disable VPN during verification
- Use desktop for wallet signing, mobile for document photos
- Don't log in to the same account on multiple devices simultaneously
</details>

<details>
<summary>Is my personal information secure?</summary>

Yes, your KYC information is protected with:
- End-to-end encryption for all uploads
- Secure storage in compliance with GDPR
- Information used only for verification purposes
- No sharing with third parties without consent
</details>

<details>
<summary>My camera won't activate, what should I do?</summary>

Check browser permissions for camera access and ensure your browser allows camera usage for the KYC site.
</details>

<details>
<summary>I can't connect my wallet, how do I fix this?</summary>

Try using a different wallet or browser. Make sure pop-ups are enabled and you're using a desktop for the best wallet connection experience.
</details>

<details>
<summary>My document upload keeps failing, what's wrong?</summary>

Check that your file size is under 10MB and you have a stable internet connection. Try refreshing the page and uploading again.
</details>

<details>
<summary>The verification message won't sign, what should I do?</summary>

Switch to desktop and try a different browser. The wallet signing step works best on desktop computers.
</details>

<details>
<summary>My email link expired, how do I get a new one?</summary>

Request a new magic link from the login page. Wait at least 5 minutes before requesting another link.
</details>

<details>
<summary>What are common reasons for KYC rejection?</summary>

Common reasons for KYC rejection include:
- Blurry or unclear document images
- Expired identification documents
- Address mismatch between documents
- Incomplete wallet signature
- Poor selfie quality or failed liveness check

If your KYC application is rejected, check your email for specific rejection reasons and resubmit the corrected documents.
</details>

---

## Need Help?

**Discord Community:** Join our [Discord](https://discord.gg/0glabs) for peer support and quick answers from the team.

**Support:** Contact us on Discord with screenshots and clear steps to reproduce any issues.

---

**Disclaimer:** This guide is for informational purposes. KYC requirements may vary by jurisdiction. Always ensure you comply with your local regulations.

---

## How to Purchase Nodes

# Purchasing Nodes: Steps and Payment Options
**Supported Blockchains and Payment Methods**: The sale will be conducted in USDC on Arbitrum, but we provide a live bridging gateway at checkout that supports multiple blockchains (ETH, Arbitrum, BNB) and tokens. All purchases require a compatible wallet, and the resulting node licenses are issued as non-transferable ERC-721 NFTs.

## Video Tutorial 
:::important
Please note: Initially, the Public Sale was intended to use wETH on Arbitrum, but after the community‚Äôs feedback, it will be USDC on Arbitrum. Please note this correction to USDC on Arbitrum as the video says wETH.
:::

<iframe
    width="100%"
    height="400"
    src="https://www.youtube.com/embed/Z2QHJfjqCtM"
    title="Node Purchase Tutorial"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen
></iframe>

Note that this video is for demonstrative purposes only, may not reflect exact details and have different prices or tokens than the actual sale.

## Step-by-Step Purchase Process:
### Step 1 - Go to https://node.0gfoundation.ai and connect your wallet
### Step 2 - Select the chain and token you want to purchase  
### Step 3 - View the tiers available and purchase
In total there are 32 available for purchase. If you hold a whitelisted address, the Tier that you are entitled to will be shown on the top. Sold out tiers will be moved to the bottom of the page.
### Step 4 - Set the quantity
Start by inputting the number of node(s) that you will be purchasing.
### Step 5 - Input Promo Code (Optional)
If you have a Promo Code, input before your purchase. The discount rate will be applied directly to your checkout price.
Additionally, if you have already purchased a node, you can provide your wallet address as a referral promo code too! This will provide a 10% rebate to the referral, and 10% commission if they purchase successfully. 
### Step 6 - Approve transaction
Once you are confirmed on the final price, click the "Approve" button. You are then required to approve the transaction via your wallet.
### Step 7 - Complete purchase
Continue by clicking "Purchase". You will need to confirm the transaction via your wallet.
After confirming your purchase, you will receive a notification on the top right of the page to inform you of the successful purchase.

---

## Node Disclaimer


PLEASE READ THE ENTIRETY OF THIS "LEGAL DISCLAIMER" SECTION CAREFULLY. NOTHING HEREIN CONSTITUTES LEGAL, FINANCIAL, BUSINESS, OR TAX ADVICE AND YOU ARE STRONGLY ADVISED TO CONSULT YOUR OWN LEGAL, FINANCIAL, TAX, OR OTHER PROFESSIONAL ADVISOR(S) BEFORE ENGAGING IN ANY ACTIVITY IN CONNECTION HEREWITH. NEITHER  0G FOUNDATION (‚ÄúTHE COMPANY‚Äù), ANY OF THE PROJECT CONTRIBUTORS WHO HAVE WORKED ON THE ZEROGRAVITY NETWORK (AS DEFINED HEREIN) OR ANY PROJECT TO DEVELOP THE ZEROGRAVITY NETWORK IN ANY WAY WHATSOEVER, ANY DISTRIBUTOR AND/OR VENDOR OF NODE LICENSE (OR SUCH OTHER RE-NAMED OR SUCCESSOR TICKER CODE OR NAME OF SUCH TOKENS) (THE ‚ÄúDISTRIBUTOR‚Äù), NOR ANY RELATED SERVICE PROVIDER SHALL BE LIABLE FOR ANY KIND OF DIRECT OR INDIRECT DAMAGE OR LOSS WHATSOEVER WHICH YOU MAY SUFFER IN CONNECTION WITH ACCESSING ANY MATERIAL RELATING TO NODE LICENSE NFT (THE TOKEN DOCUMENTATION) AVAILABLE ON THE WEBSITE AT https://0g.ai/node-sale (THE WEBSITE, INCLUDING ANY SUB-DOMAINS THEREON) OR ANY OTHER WEBSITES OR MATERIALS PUBLISHED OR COMMUNICATED BY THE COMPANY OR ITS REPRESENTATIVES FROM TIME TO TIME.

1. **Project purpose**: You agree that you are acquiring Node License NFT to participate in the ZeroGravity Network and to obtain services on the ecosystem thereon. The Company, the Distributor, and their respective affiliates would develop and contribute to the underlying source code for the ZeroGravity Network. The Company is acting solely as an arms‚Äô length third party in relation to the Node License NFT distribution and is not acting in the capacity as a financial advisor or fiduciary of any person with regard to the distribution of Node License NFT.
2. **Eligibility**: To be eligible to use the Website (including services thereon) or participate in the Node License NFT distribution you must be at least eighteen (18) years of age or older. The Website, interface and services thereon is strictly NOT offered to persons or entities who reside in, are citizens of, are incorporated in, or have a registered office in any Restricted Territory, as defined below (any such person or entity from a Restricted Territory shall be a Restricted Person). If you are a Restricted Person, then do not attempt to access or use the Website. Use of a virtual private network (e.g., a VPN) or other means by Restricted Persons to access or use the Website, interface or services is prohibited. For the purpose of these Terms, Restricted Territory shall mean Belarus, Canada, Cuba, North Korea, Iran, Russia, Syria, the United States, the United Kingdom, Venezuela, Yemen, and specific regions in Ukraine and Russia, namely the Crimea region, Donetsk People‚Äôs Republic (DNR), Luhansk People‚Äôs Republic (LNR), as well as the Kherson and Zaporizhia regions.
3. **Validity of Token Documentation and Website**: Nothing in the Token Documentation or the Website constitutes any offer by the Company, the Distributor, or the ZeroGravity Network team to sell any Node License NFT (as defined herein) nor shall it or any part of it nor the fact of its presentation form the basis of, or be relied upon in connection with, any contract or purchase decision. Nothing contained in the Token Documentation or the Website is or may be relied upon as a promise, representation or undertaking as to the future performance of the ZeroGravity Network. The agreement between the Distributor (or any third party) and you, in relation to any distribution or transfer of Node License NFT, is to be governed only by the separate terms and conditions of such agreement.
4. **Deemed Representations and Warranties**: By accessing the Token Documentation or the Website (or any part thereof), you shall be deemed to represent and warrant to the Company, the Distributor, their respective affiliates, and the ZeroGravity Network team as follows:
    * in any decision to acquire any Node License NFT, you have not relied and shall not rely on any statement set out in the Token Documentation or the Website.
    * you shall at your own expense ensure compliance with all laws, regulatory requirements, and restrictions applicable to you (as the case may be).
    * you acknowledge, understand and agree that Node License NFT may have no value, there is no guarantee or representation of value or liquidity for Node License NFT, and Node License NFT is not an investment product nor is it intended for any investment purposes, speculative or otherwise.
    * none of the Company, the Distributor, their respective affiliates, and/or the ZeroGravity Network team shall be responsible for or liable for the value of Node License NFT, the transferability and/or liquidity of Node License NFT, and/or the availability of any market for Node License NFT through third parties or otherwise.
5. The Company, the Distributor, and the ZeroGravity Network team do not and do not purport to make, and hereby disclaims, all representations, warranties or undertaking to any entity or person (including without limitation warranties as to the accuracy, completeness, timeliness, or reliability of the contents of the Token Documentation or the Website, or any other materials published by the Company or the Distributor). To the maximum extent permitted by law, the Company, the Distributor, their respective affiliates, and service providers shall not be liable for any indirect, special, incidental, consequential, or other losses of any kind, in tort, contract, or otherwise (including, without limitation, any liability arising from default or negligence on the part of any of them, or any loss of revenue, income or profits, and loss of use or data) arising from the use of the Token Documentation or the Website, or any other materials published, or its contents (including without limitation any errors or omissions) or otherwise arising in connection with the same. Prospective acquirors of Node License NFT should carefully consider and evaluate all risks and uncertainties (including financial and legal risks and uncertainties) associated with the distribution of Node License NFT, the Company, the Distributor, and the ZeroGravity Network team.
6. **Node License NFT**: Node License NFT are designed to be utilized, and that is the goal of the Node License NFT distribution. In particular, it is highlighted that Node License NFT:
    * does not have any tangible or physical manifestation and does not have any intrinsic value/pricing (nor does any person make any representation or give any commitment as to its value).
    * is non-refundable, not redeemable for any assets of any entity or organization, and cannot be exchanged for cash (or its equivalent value in any other digital asset) or any payment obligation by the Company, the Distributor, or any of their respective affiliates.
    * does not represent or confer on the token holder any right of any form with respect to the Company, the Distributor (or any of their respective affiliates), or their revenues or assets, including without limitation any right to receive future dividends, revenue, shares, ownership right or stake, share or security, any voting, distribution, redemption, liquidation, proprietary (including all forms of intellectual property or license rights), right to receive accounts, financial statements or other financial data, the right to requisition or participate in shareholder meetings, the right to nominate a director, or other financial or legal rights, equivalent rights, or intellectual property rights, or any other form of participation in or relating to the ZeroGravity Network, the Company, the Distributor, and/or their service providers.
    * is not intended to represent any rights under a contract for differences or under any other contract the purpose or intended purpose of which is to secure a profit or avoid a loss.
    * is not intended to be a representation of money (including electronic money), payment instrument, security, commodity, bond, debt instrument, unit in a collective investment, managed investment scheme, or any other kind of financial instrument or investment.
    * is not a loan to the Company, the Distributor or any of their respective affiliates, is not intended to represent a debt owed by the Company, the Distributor, or any of their respective affiliates, and there is no expectation of profit nor interest payment.
    * does not provide the token holder with any ownership or other interest in the Company, the Distributor, or any of their respective affiliates.
7. Notwithstanding the Node License NFT distribution, users have no economic or legal right over or beneficial interest in the assets of the Company, the Distributor, or any of their affiliates after the token distribution. To the extent any secondary market or exchange for trading Node License NFT does develop, it would be run and operated wholly independently of the Company, the Distributor, and the distribution of Node License NFT. Neither the Company nor the Distributor will create such secondary markets nor will either entity act as an exchange for Node License NFT.
8. **English language**: The Token Documentation and the Website may be translated into a language other than English for reference purpose only and in the event of conflict or ambiguity between the English language version and translated versions of the Token Documentation or the Website, the English language versions shall prevail. You acknowledge that you have read and understood the English language version of the Token Documentation and the Website.
9. **No Distribution**: No part of the Token Documentation or the Website is to be copied, reproduced, distributed, or disseminated in any way without the prior written consent of the Company or the Distributor. By attending any presentation on this Token Documentation or by accepting any hard or soft copy of the Token Documentation, you agree to be bound by the foregoing limitations.

---

## FAQ

# Frequently Asked Questions

### Where do I purchase AI Alignment Nodes?
https://node.0gfoundation.ai/
### How do I purchase AI Alignment Nodes?
See the step by step guide [here](docs/node-sale/details/purchasing-nodes.md).
### Who can participate in the Node Sale?
The 0G AI Alignment Node Sale is open to community members in eligible regions who meet the necessary criteria. Please review all disclaimers and important details regarding the 0G Node Sale by visiting our disclaimer [here](https://0gfoundation.ai/disclaimer). Only persons who meet the requirements for the sale are allowed to participate. KYC will be required from the purchaser before any receipt of rewards. 
### Are Whitelist and Public Allocations Separate?
The whitelist allocation is independent and will not be rolled over to the public sale. The **Whitelist Sale** opens November 11, 2024, at 12 PM UTC. The sale will be denominated in USDC on Arbitrum, and only whitelisted participants may purchase nodes during this phase. The **Public Sale** opens November 13, 2024, at 12 PM UTC, is denominated in USDC on Arbitrum, and is available to all users, subject to geographic and regulatory restrictions. Please see our disclaimer for more information.
![0g-node-sale-timeline-1600x900px](https://github.com/user-attachments/assets/dd6746d7-a102-43f3-9a1f-ae33d0ca7f72)
### What price will the sale be pegged to?
Both the Whitelist and Public Sales are denominated in USDC on Arbitrum. Node pricing will be pegged to a snapshot price of wETH of $3,130. 
### When Can I Operate My Node?
Node operations will commence after the mainnet launch, projected for Q1 2025. License holders will receive further instructions for operation and delegation options if preferred.
### How Do Rewards for Alignment Nodes Compare with Other Nodes?
Alignment Nodes are expected to offer higher reward rates due to their unique responsibilities, limited supply, and operational requirements compared to storage or validator nodes.
### Are Multiple NFTs Supported per Server?
Yes, users may operate multiple NFTs on a single server, with allowances for connecting and managing several nodes under one setup.

## Whitelist & Node Sale
### What is the whitelist (WL)?‚Äã
Whitelist is a pre-approved list of participants who are given exclusive access to certain privileges during a sale event. This system is used to reward and incentivize key contributors, partners, or early supporters of a project.

### Does entering the whitelist guarantee that I can definitely purchase a node?‚Äã
Your whitelist guarantees an allocation during the Whitelist sale period (starting Nov 11). If a purchase is not made within this period, your allocation will be released.

### How to join the whitelist?‚Äã
To get a whitelist spot for the 0G Foundation Node Sale, community members and ecosystem participants are eligible for allocations, please visit 0G X and Discord for ways to receive a whitelist. You can also apply for a whitelist spot by filling out the whitelist form [here](https://docs.google.com/forms/d/e/1FAIpQLScZSiIn3WBEdztzCObFBnLa0c6f1YoRwlN_eI8NxGPuG4w-zg/viewform).

## Payment & Licenses
### What payment methods will be accepted for purchasing a node?‚Äã
The nodes will be priced in USDC for both the Whitelist Sale and Public Sale, both on Arbitrum. However, to facilitate payment for users on different chains, the AI Alignment Node Sale will be accepting multiple tokens across multiple networks through a live bridging aggregator that accepts multichain payment including but not limited to BTC, ETH, ARB, SOL, etc. More info [here](https://docs.li.fi/list-chains-bridges-dex-aggregators-solvers).

### How will the node licenses be distributed?‚Äã
After the node sale period is completed, node licenses will be distributed as an NFT to the purchase wallet of the user.

### What will I receive from participating in the node sale?‚Äã
You will receive a soulbound NFT (ERC-721) which represents your Node License. The NFTs can be minted and transferred to your wallet via claim.0gfoundation.ai after the conclusion of the node sale. You will be able to operate the node after 0G Mainnet is live.

### Will the NFTs be transferable?
The Alignment Node license gives buyers lifetime access. The NFTs will be non-transferable for the first year after the node sale.

## Node Operations
### What are the hardware requirements?‚Äã
0G Foundation‚Äôs AI Alignment nodes are designed for adoption - they can be run on community member's laptops, desktops, mobiles, or even on cloud instances.
As for device requirements, the configuration needed is very minimal:
- 64MB RAM
- 1 x86 CPU Core @2.1GHz
- 10GB Disk Space
- 10Mbps Internet Connection

### When can I begin operating my node?‚Äã
AI Alignment utility will go live in 2025, after 0G Mainnet Launch.

### How many nodes can I purchase?‚Äã
The number of purchasable nodes will be capped per tier. Please refer to the [Node Sale Tier documentation](https://docs.google.com/spreadsheets/d/16dgdbrs0LA_mSSYB7cSEWmQPMJvok0FjqAHX-nLxEzs/edit?gid=2031834824#gid=2031834824) for reference.

### How do I run a node? Is it complicated?‚Äã
Running a node can be quite straightforward and easy, typically involving just a few steps. Here's a video tutorial to guide you through the process:

<iframe
    width="100%"
    height="400"
    src="https://www.youtube.com/embed/Z2QHJfjqCtM"
    title="Node Setup Tutorial"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen
></iframe>

If you prefer not to manage the node yourself, you can delegate to other node operators with just a single click through our explorer, which will be available shortly.

### Will the sale be accessible from other platforms?‚Äã
Both Public and Whitelist sale will be available [here](https://node.0gfoundation.ai/) except for Partnered Launchpads, in which case the front end will be on 0G Partners' website.

### What will happen to any unsold node rewards? 
Rewards from unsold nodes will be reallocated to the sold node runners. 

### What is your tokenomics?
![token table-v4 (1)](https://github.com/user-attachments/assets/125b812b-cd4f-4f8f-bb95-a1933d70b84b)
![token pie chart-v4](https://github.com/user-attachments/assets/814b1112-7ed6-47de-bf95-582cd55569d9)

### What is the % unlocked at TGE? 
33% of node rewards will be initially claimable on TGE. In order to encourage long term participation in the 0G ecosystem, there will be a penalty based on duration in which a participant chooses to receive this initial reward. The remaining 67% of alignment rewards are linearly unlocked (daily) over 36 months. This penalty mechanism is subject to community vote, further showcasing the "community first approach" of 0G.

### When is KYC required? How is it conducted? 
KYC is required before claiming rewards. It will be provided by a third-party provider. No refund will be offered if the node purchaser does not meet KYC requirements. 

### How many nodes can I purchase? 
Each individual can purchase up to a certain amount of nodes per tier. See [here](https://docs.google.com/spreadsheets/d/16dgdbrs0LA_mSSYB7cSEWmQPMJvok0FjqAHX-nLxEzs/edit?gid=2031834824#gid=2031834824) for the caps per tier.

### What happened to unsold nodes? 
Unsold alignment node NFT licenses will be burned. The rewards from the unsold nodes will be re-allocated to the sold verified node buyers. 

### What are the launchpad partners working on the 0G Foundation Node Sale? 
![Launchpads-1600x900px](https://github.com/user-attachments/assets/4b4d98d8-c480-407d-89fa-530e66fe2328)

---

## Eligibility & Disclaimer

# Eligibility and Whitelist Participation
- **Whitelist Access**: Community engagement, role-based eligibility, and participation in 0G‚Äôs Discord or X channels provide pathways to secure a whitelist spot. Please be aware that joining the whitelist does not guarantee a purchase; it only ensures allocation access during the whitelist phase.
- **Special Roles and Partnerships**: Selected community members, project partners, and Key Opinion Leaders (KOLs) may receive additional access or promotional privileges, subject to guidelines for eligible users and without guarantees for resale or transferability of whitelist spots.

## Disclaimer‚Äã
Please review the full details and terms of the 0G Node Sale by visiting our [disclaimer](https://0gfoundation.ai/disclaimer).

---

## Introduction

## Purpose and Benefits of the 0G AI Alignment Node Sale
The objective of 0G Foundation: The 0G Foundation‚Äôs node sale aims to create a decentralized AI operating system (deAIOS) that operates transparently, safely, and under community influence. Centralized AI structures may lack these attributes, creating potential risks for data integrity and security. The 0G Foundation‚Äôs goal is to develop AI as a public good, fostering an ecosystem that prioritizes transparency and reduces reliance on central authorities, making it suitable for broad public utility.

## What is an AI Alignment Node?
Alignment nodes provide the key utility of monitoring whether the other kinds of decentralized nodes in the 0G network - validator nodes, storage nodes, security nodes - faithfully follow network protocols. To start, the nodes will have certain utility, and in the near future, AI Alignment Nodes will have additional utility to monitor on-chain AI model drift and to ensure that 0G‚Äôs on-chain AI is behaving as intended.

To sustain the node utility operation and allow the network to be further secured, Alignment Node owners may receive a portion of the fees collected by the network by operating the nodes and contributing work to the 0G network. Node sale participants and stakers (i.e., long term believers who secure the ecosystem) may get additional rewards from the 0G ecosystem over time. The 0G node sale will be a launch that enables the community to participate on an equal playing field with entry points within multiple tiers.

## Why Run a Node?

Running a node on the 0G network offers participants a chance to directly contribute to the growth and security of our decentralized AI ecosystem. Nodes are the backbone of our network, enabling the following:
- **Decentralization**: Ensure the network remains decentralized and resilient.
- **Network Security**: Enhance the security and reliability of the network by verifying transactions.
- **AI Processing Power**: Support AI computations, thereby contributing to the network's ability to deliver on-chain AI services.
- **Reward Opportunities**: Node operators can earn rewards in the form of native tokens or other incentives for their contribution to the network.

## What are the specific use cases for AI Alignment Nodes?
- **Protocol Monitoring**: Ensuring that validator, storage, and security nodes comply with network protocols.
- **AI Model Monitoring**: Tracking AI model alignment and checking for any unintended behavior.
- **Network Security**: Safeguarding the ecosystem by flagging deviations and ensuring consistent ethical standards.
- **Economic and Governance Roles**: Node holders may earn rewards and participate in governance decisions, influencing the network‚Äôs direction.

---

## Node Holder Benefits

As an alignment node operator in 0G's ecosystem, users have the opportunity to earn up to 15% of the total 0G ecosystem supply allocated over the next 3 years by helping to secure the network. Nodes are rewarded for assisting in checking and verifying the correct behavior of storage, DA, and serving nodes within the network, playing a crucial role in ensuring data integrity for the AI and other supported workloads. Additional rewards will be provided from 0G‚Äôs vibrant and growing ecosystem as a coordinated effort to maintain the AI integrity and security of the platform.

The Alignment Node sale offers holders the chance to join the network and contribute to the development and security of a decentralized ecosystem for the largest collection of decentralized AI computing and data processing power, without requiring every regular user to be prepared for intensive computational tasks from day one.

---

## Sale Structure & Timeline

# Sale Structure, Dates, and Tiers

## Sale Phases
The sale is structured into two phases:
- **Whitelist Sale**: Whitelist Sale opens November 11, 2024, at 12 PM UTC and remains open for two days. The sale will be denominated in USDC on Arbitrum, and only whitelisted participants may purchase nodes during this phase. 
- **Public Sale** opens November 13, 2024, at 12 PM UTC, is denominated in USDC on Arbitrum, and is available to all users, subject to geographic and regulatory restrictions. Please see our disclaimer for more information.
  
![0g-node-sale-timeline-1600x900px (1)](https://github.com/user-attachments/assets/395a233d-d39f-4d3f-a7cc-9244dcb6df6a)

## Tier Pricing
The node sale is segmented into 32 pricing tiers, beginning at 0.05 ETH per node, allowing for varied entry points that cater to diverse participant levels. While pegged to an ETH snapshot price of $3,130, both sales are conducted in USDC on Arbitrum. See [here](https://docs.google.com/spreadsheets/d/16dgdbrs0LA_mSSYB7cSEWmQPMJvok0FjqAHX-nLxEzs/edit?gid=2031834824#gid=2031834824) for more details.

![Node Sale Table](https://github.com/user-attachments/assets/a3bedcd9-41ea-45a7-a804-4309b971881c)

---

## AI Alignment node

# Welcome to the 0G Foundation AI Alignment Node Sale

In this section, learn more about the 0G Foundation AI Alignment Node Sale.

- [What is the 0G Foundation AI Alignment Node Sale?](/node-sale/intro)
- [Why should I participate?](/node-sale/intro/node-holder-benefits)
- [Who can participate?](/node-sale/intro/eligibility)
- [How do I purchase nodes?](/node-sale/details/purchasing-nodes)
- [Frequently Asked Questions](/node-sale/faq)
  
![Launchpads-1600x900px](https://github.com/user-attachments/assets/f034673b-d04f-4006-893c-51a5e9a4d172)

---

## Blog



---

## Glossary


A comprehensive list of technical terms used throughout the 0G documentation.

## A

**AI Agent**: An autonomous software program that can perceive its environment, make decisions, and take actions to achieve specific goals.

**AVS (Actively Validated Services)**: Services that require active validation from operators, commonly used in restaking protocols like EigenLayer and Babylon.

## C

**Chain**: In the context of 0G, refers to the 0G blockchain that serves as the foundational layer for transactions and smart contracts.

**Compute Network**: The distributed network of nodes that provide computational resources for AI workloads including inference and training.

## D

**DA (Data Availability)**: A layer that ensures data required by blockchain applications is available when needed, crucial for scalability and security.

**deAIOS**: Decentralized AI Operating System - 0G's comprehensive infrastructure for decentralized AI applications.

**Decentralized Storage**: A storage system that distributes data across multiple nodes rather than relying on centralized servers.

## E

**ERC-721**: The standard interface for non-fungible tokens (NFTs) on Ethereum and EVM-compatible chains.

**ERC-7857**: An extension of ERC-721 that adds support for encrypted metadata, enabling secure transfer of AI agents as NFTs.

**Erasure Coding**: A data protection method that breaks data into fragments and encodes it with redundant pieces to ensure recovery even if some parts are lost.

## I

**Inference**: The process of using a trained AI model to make predictions or decisions based on new input data.

**INFT (Intelligent Non-Fungible Token)**: NFTs that can encapsulate AI agents with their intelligence and capabilities intact.

## M

**Modular Blockchain**: A blockchain architecture where different functions (consensus, execution, data availability) are separated into specialized layers.

## O

**Oracle**: In the context of INFTs, a service that verifies the integrity of metadata transfers using either TEE or ZKP technology.

## P

**Precompile**: Built-in functions in a blockchain that are implemented at the protocol level for optimal performance.

**Proof of Random Access (PoRA)**: 0G's consensus mechanism that ensures data availability by requiring nodes to prove they can access random data samples.

## Q

**Quorum**: A minimum number of nodes required to reach consensus on a decision in a distributed system.

## R

**RaaS (Rollup as a Service)**: Platforms that provide infrastructure and tools to easily deploy and manage blockchain rollups.

**Rollup**: A scaling solution that processes transactions off the main chain while posting transaction data back to it.

## S

**Sharding**: A scaling technique that divides a network into smaller parts (shards) to process transactions in parallel.

**Storage Node**: A node in the 0G network that stores and serves data to the network.

## T

**TEE (Trusted Execution Environment)**: A secure area of a processor that ensures code and data loaded inside are protected with respect to confidentiality and integrity.

**Testnet**: A test network that mimics the main network but uses test tokens, allowing developers to experiment without real value at risk.

## V

**Validator Node**: A node that participates in consensus by validating transactions and proposing new blocks.

## W

**Web3**: The vision of a decentralized internet built on blockchain technology, emphasizing user ownership and control.

## Z

**Zero Gravity (0G)**: The name representing the weightless state where transactions and data exchanges occur effortlessly in the 0G ecosystem.

**Zero-Knowledge Proof (ZKP)**: A cryptographic method where one party can prove to another that a statement is true without revealing any information beyond the validity of the statement.

---

*This glossary is continuously updated as the 0G ecosystem evolves. If you encounter a term not listed here, please contribute by submitting a pull request to our [documentation repository](https://github.com/0gfoundation/0g-docs).*

---

## How to Contribute?

# Contribute to 0G Blockchain
We welcome and encourage you to contribute to our open-source project! 

Whether you're a seasoned developer or new to the community, your participation helps us push decentralized AI forward. Every contribution, no matter the size, makes a difference. Please check out our [Contribution Guidelines](https://github.com/0gfoundation/0g-doc/blob/main/CONTRIBUTING.md) to learn more about our criteria and how you can get involved. All submissions will be reviewed by a team member to ensure they meet our standards. 

Let's build the future of decentralized AI together.

---

## Security

# Security at 0G

At 0G, we prioritize the security and integrity of our platform. Our commitment to security is reflected in our rigorous audit processes and our active bug bounty program.

## Audits

We regularly conduct thorough security audits of our smart contracts, protocols, and infrastructure to ensure the highest level of security for our users.

### Recent Audits 

| Date | Auditor | Scope | Report |
|------|---------|-------|--------|
| Aug 2024 - Sept 2024 | Halborn | 0G Storage | [Report](https://github.com/0gfoundation/0g-doc/blob/main/audit/Halborn%200G%20Storage%20Node%20Audit.pdf) |
| Aug 2024 | Zellic | 0G Storage and 0G DA | [Report](https://github.com/0gfoundation/0g-doc/blob/main/audit/Zellic%200G%20Storage%20and%200G%20DA%20Audit.pdf) |
| Aug 2025 | Octane | 0G Chain | [Report](https://drive.google.com/file/d/1SgL-PDL_8jzDTUMQ9pO28OQVCP2IeqHR/view) |

For a complete list of our audits and their detailed reports, please visit our [GitHub repository](https://github.com/0gfoundation/0g-doc/tree/main/audit).

## [0G Labs Bug Bounty Program with Hackenproof](https://hackenproof.com/programs/0g-labs-smart-contracts)

At 0G, we believe in the power of **community-driven security**. Our bug bounty program invites security researchers and developers to help us identify and resolve potential vulnerabilities, ensuring the robustness of our systems. 

### Scope of the Bug Bounty Program
Our bug bounty program covers:
- Smart Contracts
- Infrastructure
- Protocol
  
## Focus Area

### In-Scope Vulnerabilities: 
We are interested in vulnerabilities that result in incorrect behavior of the smart contract and could lead to unintended functionality, including:

- Stealing or loss of funds
- Unauthorized transactions
- Transaction manipulation
- Attacks on logic (behavior that deviates from the intended business logic)
- Reentrancy attacks
- Reordering transactions
- Overflows and underflows

### Out-of-Scope Vulnerabilities: 
The following are out of scope for the bug bounty program:

- Theoretical vulnerabilities without proof or demonstration
- Old compiler versions
- Unlocked compiler version
- Vulnerabilities in imported contracts
- Code style guide violations
- Redundant code
- Gas optimizations
- Best practice issues
- Vulnerabilities exploitable through front-run attacks only

Additionally, the following contracts are out of scope for 0g-storage-contract:
- `cashier`
- `token`
- `reward/OnePoolReward`
- `reward/ChunkDecayReward`
- `uploadMarket`
- `utils/Exponent.sol`

### Rewards

Rewards are based on the severity of the discovered vulnerability:

| Severity | Reward Range |
|----------|--------------|
| Critical | $35,000 |
| High     | $8000 |
| Medium   | $2000 |
| Low      | $500 |

### Program Rules

- Avoid using web application scanners for automatic vulnerability searching which generates massive traffic
- Make every effort not to damage or restrict the availability of products, services, or infrastructure
- Avoid compromising any personal data, interruption, or degradation of any service
- Don‚Äôt access or modify other user data, localize all tests to your accounts
- Perform testing only within the scope
- Don‚Äôt exploit any DoS/DDoS vulnerabilities, social engineering attacks, or spam
- Don‚Äôt spam forms or account creation flows using automated scanners
- In case you find chain vulnerabilities we‚Äôll pay only for vulnerability with the highest severity.
- Don‚Äôt break any law and stay in the defined scope
- Any details of found vulnerabilities must not be communicated to anyone who is not a HackenProof Team or an authorized employee of this Company without appropriate permission

### Disclosure Guidelines
:::important
- Do not discuss this program or any vulnerabilities (even resolved ones) outside of the program without express consent from the organization
- No vulnerability disclosure, including partial is allowed for the moment.
- Please do NOT publish/discuss bugs
:::

### Eligibility and Coordinated Disclosure

We are happy to thank everyone who submits valid reports which help us improve the security. However, only those that meet the following eligibility requirements may receive a monetary reward:

- You must be the first reporter of a vulnerability.
- The vulnerability must be a qualifying vulnerability
- Any vulnerability found must be reported no later than 24 hours after discovery and exclusively through hackenproof.com
- You must send a clear textual description of the report along with steps to reproduce the issue, include attachments such as screenshots or proof of concept code as necessary.
- You must not be a former or current employee of us or one of its contractors.
- ONLY USE the EMAIL under which you registered your HackenProof account (in case of violation, no bounty can be awarded)
- Provide detailed but to-the point reproduction steps

We look forward to working with the community to enhance 0G's security!

---

## 0G Whitepaper

<iframe 
      src="/whitepaper.pdf" 
      className="whitepaper-iframe"
      title="0G Whitepaper"
    >
      If you're unable to view the PDF, please click here to download it.
    </iframe>
  
  
    
      Download PDF

---

## Archival Node

---

Running an Archival node for the **0G-Galileo-Testnet** means providing complete historical data storage and access for the network, maintaining the full blockchain history and state.

:::info **What You'll Need**
- Linux system with sufficient disk space for archive data
- `lz4` compression tool installed
- Public IP address for node connectivity
- Stable internet connection
:::

## Hardware Requirements

| Component  | Requirement |
|------------|-------------|
| Memory     | 64 GB       |
| CPU        | 8 cores     |
| Disk       | Large NVME SSD (for full archive data) |
| Bandwidth  | 100 MBps for Download / Upload |

## Prerequisites

### Required Files

1. **Node Package**: [galileo-archive.tar.gz](/binaries/galileo-archive.tar.gz)
2. **Archive Snapshot**: Download from https://chain-snapshot.oss-cn-hongkong.aliyuncs.com/snapshot/galileo/archive/20250717.tar.lz4

### System Requirements

- Linux system with sufficient disk space for archive data
- `lz4` compression tool installed
- Public IP address for node connectivity

## Setup Guide

### 1. Download Node Package

Download the node package: [galileo-archive.tar.gz](/binaries/galileo-archive.tar.gz)

### 2. Extract Node Package

Unzip the file to your home directory

### 3. Download Archive Snapshot

Download the archive node snapshot from:

```
https://chain-snapshot.oss-cn-hongkong.aliyuncs.com/snapshot/galileo/archive/20250717.tar.lz4
```

### 4. Extract Snapshot

```bash
lz4 -d 20250717.tar.lz4 | tar -xvf - -C /your/snapshot/directory
```

## Deployment Steps

### 1. Copy Files and Set Permissions

```bash
cd galileo-v1.2.0
cp -r 0g-home {your data path}
sudo chmod 777 ./bin/geth
sudo chmod 777 ./bin/0gchaind
```

### 2. Initialize Geth

```bash
./bin/geth init --state.scheme=hash --db.engine=pebble --datadir /{your data path}/0g-home/geth-home ./genesis.json
```

### 3. Initialize 0gchaind with Temporary Directory

```bash
./bin/0gchaind init {node name} --home /{your data path}/tmp
```

### 4. Copy Node Files to 0gchaind Home

```bash
cp /{your data path}/tmp/data/priv_validator_state.json /{your data path}/0g-home/0gchaind-home/data/
cp /{your data path}/tmp/config/node_key.json /{your data path}/0g-home/0gchaind-home/config/
cp /{your data path}/tmp/config/priv_validator_key.json /{your data path}/0g-home/0gchaind-home/config/
```

### 5. Copy Data from Snapshot

```bash
cp -r /your/snapshot/directory/0g-home/geth-home/geth/chaindata /{your data path}/0g-home/geth-home/geth/
cp -r /your/snapshot/directory/0g-home/0gchaind-home/data /{your data path}/0g-home/0gchaind-home/
```

### 6. Start 0gchaind

```bash
cd galileo-v1.2.0
nohup ./bin/0gchaind start \
    --rpc.laddr tcp://0.0.0.0:26657 \
    --chaincfg.chain-spec devnet \
    --chaincfg.kzg.trusted-setup-path=kzg-trusted-setup.json \
    --chaincfg.engine.jwt-secret-path=jwt-secret.hex \
    --chaincfg.kzg.implementation=crate-crypto/go-kzg-4844 \
    --chaincfg.block-store-service.enabled \
    --chaincfg.node-api.enabled \
    --chaincfg.node-api.logging \
    --chaincfg.node-api.address 0.0.0.0:3500 \
    --pruning=nothing \
    --home /{your data path}/0g-home/0gchaind-home \
    --p2p.seeds 85a9b9a1b7fa0969704db2bc37f7c100855a75d9@8.218.88.60:26656 \
    --p2p.external_address {your node ip}:26656 > /{your data path}/0g-home/log/0gchaind.log 2>&1 &
```

### 7. Start Geth

```bash
cd galileo-v1.2.0
nohup ./bin/geth \
    --config geth-archive-config.toml \
    --nat extip:{your node ip} \
    --bootnodes enode://de7b86d8ac452b1413983049c20eafa2ea0851a3219c2cc12649b971c1677bd83fe24c5331e078471e52a94d95e8cde84cb9d866574fec957124e57ac6056699@8.218.88.60:30303 \
    --datadir /{your data path}/0g-home/geth-home \
    --state.scheme=hash \
    --gcmode archive \
    --networkid 16601 > /{your data path}/0g-home/log/geth.log 2>&1 &
```

### 8. Verify Setup

Check the logs to ensure the node is running properly:

```bash
# Check Geth logs
tail -f /{your data path}/0g-home/log/geth.log

# Check 0gchaind logs
tail -f /{your data path}/0g-home/log/0gchaind.log
```

:::success **Success Indicators**
- 0gchaind should show "Committed state" messages
- Geth should show archive mode synchronization
- No error messages in either log
:::

## Important Configuration Notes

### Variables to Replace

- `{your data path}`: Your chosen data directory path
- `{node name}`: Your chosen node name
- `{your node ip}`: Your server's public IP address
- `/your/snapshot/directory`: Path where you extracted the snapshot

### Directory Structure

After setup, your directory structure should look like:

```
{your data path}/
‚îî‚îÄ‚îÄ 0g-home/
    ‚îú‚îÄ‚îÄ geth-home/
    ‚îú‚îÄ‚îÄ 0gchaind-home/
    ‚îÇ   ‚îú‚îÄ‚îÄ config/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ node_key.json
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ priv_validator_key.json
    ‚îÇ   ‚îî‚îÄ‚îÄ data/
    ‚îÇ       ‚îî‚îÄ‚îÄ priv_validator_state.json
    ‚îî‚îÄ‚îÄ log/
        ‚îú‚îÄ‚îÄ 0gchaind.log
        ‚îî‚îÄ‚îÄ geth.log
```

### Network Ports

Ensure the following ports are open:

- **26657**: 0gchaind RPC
- **26656**: 0gchaind P2P
- **3500**: Node API
- **30303**: Geth network

## Archive Node Benefits

Archive nodes provide several key benefits to the 0G network:

- **Complete Historical Data**: Full access to all historical blockchain data and state
- **Enhanced Query Capabilities**: Support for complex historical queries and analytics
- **Network Resilience**: Backup and redundancy for the network's historical data
- **Developer Support**: Essential for applications requiring historical blockchain data

:::warning **Storage Requirements**
Archive nodes require significantly more storage space than regular nodes as they maintain the complete blockchain history. Ensure adequate disk space before setup.
:::

---

## Community Docker Repository

---

This section provides a list of Docker images üê≥ for 0G DA from the community. For instructions on running 0G nodes via binary installation, please visit the node pages directly.

For most users, Docker offers the simplest method to get 0G nodes up and running. Docker is a platform for containerization, allowing 0G nodes to operate in an isolated environment. This approach enables you to run 0G nodes on your system without needing to install and configure all the necessary dependencies manually.

Most of the officially endorsed 0G Docker implementations can be found under the documentation page for each 0G node type. 

Below is a list of community-maintained Docker images for 0G DA. Please note that these images are not officially endorsed by 0G, and users should proceed with caution.

### All Node Types
[Ember Stake](https://docs.emberstake.xyz/networks/zero-gravity/nodes-guide/getting-started)

### Validator Node
[CryptoWarden](https://medium.com/@CryptoWarden/guide-to-running-a-node-in-the-0g-labs-project-0g-ai-1bee56ea53ca)

---

## Data Availability Node

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Data Availability Node
---
While there are various approaches to running a DA (Data Availability) node, this guide outlines our recommended method and the necessary hardware specifications. DA Nodes perform the core functions of verifying, signing, and storing encoded blob data. 

To operate effectively, your DA signer needs to run a DA node to verify encoded blob data, sign it, and store it for future farming and rewards. Currently, to run a DA Node on Testnet, users must stake 10 OG tokens. These can be obtained through our [faucet](https://faucet.0g.ai/) or via rewards from running Storage Nodes or Validator Nodes. You can also reach out to our technical moderators on [Discord](https://discord.com/invite/0glabs).

## Hardware Requirements

| Node Type | Memory | CPU | Disk | Bandwidth | Additional Notes |
|-----------|--------|-----|------|-----------|------------------|
| DA Node | 16 GB | 8 cores | 1 TB NVMe SSD | 100 MBps | For Download/Upload |

## Standing up a DA Node and DA Signer
<Tabs>

  <TabItem value="Da-node-docker" label="Run with Docker" default>

**1. Clone the DA Node Repo:** 

   ```
   git clone https://github.com/0gfoundation/0g-da-node.git
   cd 0g-da-node
   ```

**2. Generate BLS Private Key (if needed):**

If you don't have a BLS private key, generate one:

```
cargo run --bin key-gen
```

Keep the generated BLS private key secure.

**3. Set up config.toml:**

1. Create a configuration file named `config.toml` in the project root directory.
2. Add the following content to the file, adjusting values as needed:

   ```toml
   log_level = "info"

   data_path = "/data"

   # path to downloaded params folder
   encoder_params_dir = "/params"

   # grpc server listen address
   grpc_listen_address = "0.0.0.0:34000"
   # chain eth rpc endpoint
   eth_rpc_endpoint = "https://evmrpc-testnet.0g.ai"
   # public grpc service socket address to register in DA contract
   # ip:34000 (keep same port as the grpc listen address)
   # or if you have dns, fill your dns
   socket_address = "<public_ip/dns>:34000"

   # data availability contract to interact with
   da_entrance_address = "0x857C0A28A8634614BB2C96039Cf4a20AFF709Aa9" # testnet config
   # deployed block number of da entrance contract
   start_block_number = 940000 # testnet config

   # signer BLS private key
   signer_bls_private_key = ""
   # signer eth account private key
   signer_eth_private_key = ""
   # miner eth account private key, (could be the same as `signer_eth_private_key`, but not recommended)
   miner_eth_private_key = ""

   # whether to enable data availability sampling
   enable_das = "true"
   ```

   Make sure to fill in the `signer_bls_private_key`, `signer_eth_private_key`, and `miner_eth_private_key` fields with your actual private keys.

**4. Build and Start the Docker Container:**

   ```
   docker build -t 0g-da-node .
   docker run -d --name 0g-da-node 0g-da-node
   ```
**5. Verify the Node is Running**

On the first run, the DA node will register the signer information in the DA contract. You can monitor the console output to ensure the node is running correctly and has successfully registered.

### Node Operations

As a DA node operator, your node will perform the following tasks:
- Encoded blob data verification
- Signing of verified data
- Storing blob data for further farming
- Receiving rewards for these operations

### Troubleshooting

- If you encounter any issues, check the console output for error messages.
- Ensure that the ports specified in your `config.toml` file are not being used by other applications.
- Verify that you have the latest stable version of Rust installed.
- Make sure your system meets the minimum hardware requirements.

### Conclusion

You have now successfully set up and run a 0g DA node as a DA Signer. For more advanced configuration options and usage instructions, please refer to the [Official GitHub repository](https://github.com/0gfoundation/0g-da-node).

Remember to keep your private keys secure and regularly update your node software to ensure optimal performance and security.

  </TabItem>

<TabItem value="Da-node" label="Build from Source" default>

## Step 1: Clone and Build the Repository

1. Install dependencies:

   ```
   sudo apt-get update && sudo apt-get install clang cmake build-essential pkg-config libssl-dev protobuf-compiler llvm llvm-dev
   ```

2. Clone the repository and checkout the specific version:

   ```
   git clone https://github.com/0gfoundation/0g-da-node.git
   cd 0g-da-node
   ```

3. Build the project:

   ```
   cargo build --release
   ```

4. Download necessary parameters:

   ```
   ./dev_support/download_params.sh
   ```

## Step 2: Generate BLS Private Key (if needed)

If you don't have a BLS private key, generate one:

```
cargo run --bin key-gen
```

**Keep the generated BLS private key secure.**

## Step 3: Configure the Node

1. Create a configuration file named `config.toml` in the project root directory.
2. Add the following content to the file, adjusting values as needed:

   ```toml
   log_level = "info"

   data_path = "./db/"

   # path to downloaded params folder
   encoder_params_dir = "params/" 

   # grpc server listen address
   grpc_listen_address = "0.0.0.0:34000"
   # chain eth rpc endpoint
   eth_rpc_endpoint = "https://evmrpc-testnet.0g.ai"
   # public grpc service socket address to register in DA contract
   # ip:34000 (keep same port as the grpc listen address)
   # or if you have dns, fill your dns
   socket_address = "<public_ip/dns>:34000"

   # data availability contract to interact with
   da_entrance_address = "0x857C0A28A8634614BB2C96039Cf4a20AFF709Aa9" # testnet config and see testnet page for the latest info

   # deployed block number of da entrance contract
   start_block_number = 940000 # testnet config

   # signer BLS private key
   signer_bls_private_key = ""
   # signer eth account private key
   signer_eth_private_key = ""
   # miner eth account private key, (could be the same as `signer_eth_private_key`, but not recommended)
   miner_eth_private_key = ""

   # whether to enable data availability sampling
   enable_das = "true"
   ```

   Make sure to fill in the `signer_bls_private_key`, `signer_eth_private_key`, and `miner_eth_private_key` fields with your actual private keys.

## Step 4: Run the Node

Start the 0g DA node using the following command:

```
./target/release/server --config config.toml
```

This will start the node using the configuration file you created.

## Step 5: Verify the Node is Running

On the first run, the DA node will register the signer information in the DA contract. You can monitor the console output to ensure the node is running correctly and has successfully registered.

## Node Operations

As a DA node operator, your node will perform the following tasks:
- Encoded blob data verification
- Signing of verified data
- Storing blob data for further farming
- Receiving rewards for these operations

## Troubleshooting

- If you encounter any issues, check the console output for error messages.
- Ensure that the ports specified in your `config.toml` file are not being used by other applications.
- Verify that you have the latest stable version of Rust installed.
- Make sure your system meets the minimum hardware requirements.

## Conclusion

You have now successfully set up and run a 0g DA node as a DA Signer. For more advanced configuration options and usage instructions, please refer to the [Official GitHub repository](https://github.com/0gfoundation/0g-da-node).

Remember to keep your private keys secure and regularly update your node software to ensure optimal performance and security.
  </TabItem>

<TabItem value="signer" label="Become a Signer">

## Overview

The DASigners contract is an interface through which Solidity contracts can interact with the 0G chain module DASigners. It is registered as a precompiled contract, similar to other precompiled EVM extensions.

## Becoming a DA Signer

To become a DA signer, you must meet the following requirements:

1. Delegation Requirement: To become a signer, an address must receive enough delegations, equivalent to at least the TokensPerVote amount of OG tokens (30 tokens per vote in the testnet), registered in the DASigners module.

2. Node Operation: Each signer needs to run a DA (Data Availability) node that verifies blob encoding and generates BLS signatures for signed blobs.

3. Registration: Signers must register their information using the registerSigner function. This includes providing their address, node socket address, BLS public key, and a signature signed by their BLS private key.

4. Epoch Participation: Signers must submit a registration message (using the registerNextEpoch function) with a signature for each epoch they wish to participate in. This is necessary for joining quorums in the next epoch.

5. Voting Power: Each signer‚Äôs voting power is determined by the number of tokens delegated to them. Signers can have up to 1024 votes, and the votes are distributed randomly into quorums.

6. Quorum Responsibilities: Each signer in a quorum is responsible for validating, signing, and storing a specific row of encoded blob data during an epoch.

## Prerequisites

Ensure you have the following installed on your system:

- Git
- Rust (latest stable version)
- Cargo (comes with Rust)

## Contract Details

**Address**: `0x0000000000000000000000000000000000001000`

### Contract Params (Testnet)

```
TokensPerVote = 30
MaxVotesPerSigner = 1024
MaxQuorums = 10
EpochBlocks = 5760
EncodedSlices = 3072
```

## Terminology

### Signer

A Signer is an address with sufficient delegations (at least `TokensPerVote` OG) registered in the DASigners module. Each signer should run a DA node to verify DA blob encoding and generate BLS signatures for signed blobs. The BLS curve used is BN254, and the public keys of signers are registered in the contract.

**Note**: For accounts with delegations to more than 10 validators, only 10 of these delegations are counted and accumulated.

### Epoch

The consecutive blocks in the 0g chain are divided into groups of `EpochBlocks`, and each group is an epoch.

### Quorum

In an epoch, there can be up to `MaxQuorums` quorums. Each quorum is a list of signer addresses with size `EncodedSlices`. The i-th signer in the quorum is responsible for validating, signing, and storing the i-th row of the encoded blob data assigned to this quorum.

### Vote

Signers can submit their signatures on a registration message to request joining the quorums in the next epoch. At the start of each epoch, the DASigners module calculates the voting power for registered signers based on their delegated token amounts. Each delegated `TokensPerVote` OG counts as one vote, and each signer can have up to `MaxVotesPerSigner` votes. All votes are then randomly ordered and distributed into quorums.

## Interface

Find the Solidity interface in the [0g-da-contract repo](https://github.com/0gfoundation/0g-da-contract).

## ABI

Find the ABI in the [0g-chain repo](https://github.com/0gfoundation/0g-chain).

## Transactions

### registerSigner

Register signer's information, including signer address, DA node service socket address, signer BLS public key on G1 and G2 group, and a signature signed by the BLS private key of the following message:

```
Keccak256(signerAddress, chainID, "0G_BN254_Pubkey_Registration")
```

Here `chainID` is left-padded to 32 bytes by zeros.

```solidity
function registerSigner(
    SignerDetail memory _signer, 
    BN254.G1Point memory _signature
) external;
```

### updateSocket

Update signer's socket address.

```solidity
function updateSocket(string memory _socket) external;
```

### registerNextEpoch

Register to join the quorums in the next epoch. The signer needs to submit a signature signed by their BLS private key:

```
Keccak256(signerAddress, epoch, chainID)
```

Here `chainID` is left-padded to 32 bytes by zeros and `epoch` is an unsigned 64-bit number in big-endian format.

```solidity
function registerNextEpoch(BN254.G1Point memory _signature) external;
```

## Queries

### epochNumber

Get the current epoch number.

```solidity
function epochNumber() external view returns (uint);
```

### quorumCount

Get the number of quorums for a given epoch.

```solidity
function quorumCount(uint _epoch) external view returns (uint);
```

### isSigner

Check if a given address is a registered signer.

```solidity
function isSigner(address _account) external view returns (bool);
```

### getSigner

Get the information of given signers.

```solidity
function getSigner(address[] memory _account) external view returns (SignerDetail[] memory);
```

### getQuorum

Get the signer list of a given epoch and quorum id.

```solidity
function getQuorum(uint _epoch, uint _quorumId) external view returns (address[] memory);
```

### getQuorumRow

Get the signer of a specific row in a given epoch and quorum id.

```solidity
function getQuorumRow(uint _epoch, uint _quorumId, uint32 _rowIndex) external view returns (address);
```

### registeredEpoch

Check if a given address is registered to join the given epoch.

```solidity
function registeredEpoch(address _account, uint _epoch) external view returns (bool);
```

### getAggPkG1

Get the aggregated G1 public key for a given signers set. The signers set is specified by the epoch, quorum id, and a bitmap. The bitmap has `EncodedSlices` bits, and each bit denotes whether the row is chosen or not.

```solidity
function getAggPkG1(
    uint _epoch,
    uint _quorumId,
    bytes memory _quorumBitmap
) external view returns (BN254.G1Point memory aggPkG1, uint total, uint hit);
```
  </TabItem>
</Tabs>

---

## Overview(Run-a-node)

---
Want to become an active participant in the 0G network and earn rewards while you're at it? üëá

Each node type plays a crucial role in maintaining the 0G network's functionality, from transaction validation and data storage to ensuring data availability and retrieval. Here, we'll introduce you to the various types of nodes you can run, each contributing to the network's health and security.

### What Nodes Can I Run?

##### **Validator Nodes**
The guardians of the network, validator nodes are responsible for verifying transactions, ensuring consensus, and maintaining the blockchain. They're essential for keeping the 0G blockchain secure and running smoothly.

##### **Storage Nodes**
Unlike Validator Nodes that focus on securing the blockchain itself, Storage Nodes focus on managing and serving data. They are the backbone of the network's data storage capabilities, ensuring persistence and availability for long-term data storage (e.g., training datasets, large AI models). By running a storage node, you'll contribute to the decentralized storage of 0G data, making it accessible and resilient.

##### **Data Availability Services**
DA Nodes are similar to Storage Nodes but focus on immediacy and short-term accessibility to support real-time operations. This data is typically used by Layer 2 and rollup solutions for data availability and is not typically stored long-term. Think of these nodes as the network's librarians, ensuring that data can be quickly retrieved when needed.

##### **Archival Nodes**
Archival Nodes maintain complete historical blockchain data and state, providing comprehensive access to the network's entire history. These nodes are essential for applications requiring historical data analysis, compliance, and serving as reliable backups for the network's complete transaction history.

### Why Run a Node?

Running a node isn't just about supporting the network; it's also a way to earn rewards for your contribution. By actively participating in the 0G ecosystem, you'll be eligible to receive rewards that incentivize your efforts.

#### Ready to Dive In?

We've made it easy to get started. The table below outlines the hardware requirements for each type of node, so you can choose the one that best suits your setup. Once you're ready, head over to the 0G documentation for detailed instructions on how to set up and run your chosen node.

| Node Type | Description | Memory | CPU | Disk | Bandwidth |
|-----------|-------------|--------|-----|------|-----------|
| Validator Node | Validates transactions and maintains network consensus | 64 GB | 8 cores | 1 TB NVME SSD (4 TB on Testnet) | 100 MBps |
| Storage Node | Stores data within the 0g network | 16 GB | 4 cores | 500GB / 1T NVME SSD | 500 MBps |
| Storage KV | Handles key-value storage operations | 4 GB | 2 cores | Matches KV streams size | - |
| DA Node | Performs blob data verification, signing, and storage | 16 GB | 8 cores | 1 TB NVME SSD | 100 MBps |
| DA Retriever | Retrieves data availability information | 8 GB | 2 cores | - | 100 MBps |
| DA Encoder* | Encodes data for availability purposes | - | - | - | - |
| DA Client | Interacts with the Data Availability layer | 8 GB | 2 cores | - | 100 MBps |

*Note: For DA Encoder, GPU support is currently tested with NVIDIA 12.04 drivers on the RTX 4090. Other NVIDIA GPUs may require parameter adjustments and have not been tuned yet.*

#### Next Steps
Ready to set up your node? Check out our detailed guides:

- [Validator Node Setup Guide](validator-node.md)
- [Storage Node Setup Guide](storage-node.md)
- [Data Availability Service Setup Guide](da-node.md)
- [Archival Node Setup Guide](archival-node.md)

---

## Storage Node

---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

In the 0G network, storage nodes play a vital role in maintaining the system's decentralized storage layer. They are responsible for storing and serving data, ensuring data availability and reliability across the network. By running a storage node, you actively contribute to the network and earn rewards for your participation.
This guide details the process of running a storage node, including hardware specifications and interaction with on-chain contracts.

### Hardware Requirements

| Component | Storage Node | Storage KV |
|-----------|--------------|------------|
| Memory    | 32 GB RAM    | 32 GB RAM  |
| CPU       | 8 cores      | 8 cores    |
| Disk      | 500GB / 1TB SSD | Size matches the KV streams it maintains |
| Bandwidth | 100 Mbps (Download / Upload) | - |

:::note
- For Storage Node: The SSD ensures fast read/write operations, critical for efficient blob storage and retrieval.
- For Storage KV: The disk size requirement is flexible and should be adjusted based on the volume of KV streams you intend to maintain.
:::
### Next Steps
For detailed instructions on setting up and operating your Storage Node or Storage KV, please refer to our comprehensive setup guides below:

<Tabs>
  <TabItem value="binary" label="Storage Node" default>

## Prerequisites

Before setting up your storage node:

- Understand that 0G Storage interacts with on-chain contracts for blob root confirmation and PoRA mining.
- Choose your network: [Testnet](../developer-hub/testnet/testnet-overview.md) or [Mainnet](../developer-hub/mainnet/mainnet-overview.md)
- Check the respective network overview pages for deployed contract addresses and RPC endpoints.
- **For mainnet deployment**: Ensure you have real 0G tokens for transaction fees and mining rewards.

## Install Dependencies
Start by installing all the essential tools and libraries required to build the 0G storage node software.

<Tabs
  defaultValue="linux"
  values={[
    {label: 'Linux', value: 'linux'},
    {label: 'Mac', value: 'mac'},
    ]}>
  <TabItem value="linux">

        ```bash
        sudo apt-get update
        sudo apt-get install clang cmake build-essential pkg-config libssl-dev protobuf-compiler
        ```
</TabItem>
  <TabItem value="mac">
        ```bash
        brew install llvm cmake
        ```
</TabItem>
</Tabs>
**Install `rustup`**: rustup is the Rust toolchain installer, necessary as the 0G node software is written in Rust.

    ```bash
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
    ```

 **Download the Source Code**:

    ```bash
    git clone -b <latest_tag> https://github.com/0gfoundation/0g-storage-node.git
    ```

**Build the Source Code**

    ```bash
    cd 0g-storage-node

    # Build in release mode
    cargo build --release
    ```

This compiles the Rust code into an executable binary. The `--release` flag optimizes the build for performance.

## Setup and Configuration

Navigate to the run directory and configure your storage node for either testnet or mainnet.

:::info Config File References
The official configuration files are in the `run/` directory. Currently only `turbo` is available:
```
run/config-testnet-turbo.toml
run/config-mainnet-turbo.toml
```

Always use the latest versions from the repository as they contain the most up-to-date network parameters.
:::

**Turbo vs Standard**
Both `turbo` and `standard` configs are identical in structure and fields. The only difference is pricing; choose the file that matches the pricing tier you want to run.

**Where The Full Config Is Explained**
The most detailed, up-to-date comments for every field live in `run/config-testnet-turbo.toml` (and the corresponding `run/config-testnet-standard.toml`). Use those files as the authoritative field-by-field explanation.

**Key Fields (Same Wording As `run/config-testnet-turbo.toml`)**
`network_boot_nodes`
Note: List of nodes to bootstrap UDP discovery. Note, `network_enr_address` should be configured as well to enable UDP discovery.

`log_contract_address`
Note: Flow contract address to sync event logs.

`mine_contract_address`
Note: Mine contract address for incentive.

`reward_contract_address`
Note: Reward contract address.

`db_max_num_sectors`
Note: The max number of chunk entries to store in db. Each entry is 256B, so the db size is roughly limited to `256 * db_max_num_sectors` Bytes. If this limit is reached, the node will update its `shard_position` and store only half data.

`chunk_pool_write_window_size`
Note: Maximum number of threads to upload segments of a single file simultaneously.

`chunk_pool_max_writings`
Note: Maximum number of threads to upload segments for all files simultaneously.

`auto_sync_enabled`
Note: Enable file sync among peers automatically. When enabled, each node will store all files, and sufficient disk space is required.

`neighbors_only`
Note: Indicates whether to sync file from neighbor nodes only. This is to avoid flooding file announcements in the whole network, which leads to high latency or even timeout to sync files.

**CLI Options**
CLI flags override values in `config.toml`.
- `-c`, `--config <FILE>`: Sets a custom config file.
- `--log-config-file [FILE]`: Sets log configuration file (Default: `log_config`).
- `--miner-key [KEY]`: Sets miner private key (Default: None).
- `--blockchain-rpc-endpoint [URL]`: Sets blockchain RPC endpoint (Default: `http://127.0.0.1:8545`).
- `--db-max-num-chunks [NUM]`: Sets the max number of chunks to store in DB (Default: None).
- `--network-enr-address [URL]`: Sets the network ENR address (Default: None).

**Configuration Reference**
Full configuration keys are defined in `node/src/config/mod.rs` and log sync behavior is implemented in `node/log_entry_sync/src/sync_manager/config.rs`.

**Network**
- `network_dir`: Directory for node keyfile and network data (Default: `network`).
- `network_listen_address`: IP address to listen on (Default: `0.0.0.0`).
- `network_enr_address`: Public address advertised in ENR (Default: None).
- `network_enr_tcp_port`: TCP port advertised in ENR (Default: `1234`).
- `network_enr_udp_port`: UDP port advertised in ENR (Default: `1234`).
- `network_libp2p_port`: Libp2p TCP port (Default: `1234`).
- `network_discovery_port`: Discovery UDP port (Default: `1234`).
- `network_target_peers`: Target number of connected peers (Default: `50`).
- `network_boot_nodes`: ENR boot nodes list for discovery (Default: empty list).
- `network_libp2p_nodes`: Initial libp2p peers to connect to (Default: empty list).
- `network_private`: Enable private mode (Default: `false`).
- `network_disable_discovery`: Disable discovery protocol (Default: `false`).
- `network_find_chunks_enabled`: Enable find-chunks behavior (Default: `false`).

**Discv5**
- `discv5_request_timeout_secs`: Timeout per UDP request (Default: `5`).
- `discv5_query_peer_timeout_secs`: Timeout to mark a query peer unresponsive (Default: `2`).
- `discv5_request_retries`: Retry count for UDP requests (Default: `1`).
- `discv5_query_parallelism`: Parallelism per query (Default: `5`).
- `discv5_report_discovered_peers`: Emit discovered ENRs during traversal (Default: `false`).
- `discv5_disable_packet_filter`: Disable incoming packet filter (Default: `false`).
- `discv5_disable_ip_limit`: Disable /24 subnet limit in kbuckets (Default: `false`).
- `discv5_disable_enr_network_id`: Disable ENR network ID checks (Default: `false`).

**Log Sync**
- `blockchain_rpc_endpoint`: RPC endpoint to sync EVM logs (Default: `http://127.0.0.1:8545`).
- `log_contract_address`: Flow contract address to sync logs from (Default: empty).
- `log_sync_start_block_number`: Block number to start syncing logs (Default: `0`).
- `force_log_sync_from_start_block_number`: Force sync from start block even if progress exists (Default: `false`).
- `confirmation_block_count`: Blocks required for confirmation to handle reorgs (Default: `3`).
- `log_page_size`: Max number of logs per poll (Default: `999`).
- `max_cache_data_size`: Max cached data size in bytes (Default: `104857600`).
- `cache_tx_seq_ttl`: Cache TTL for tx sequence entries (Default: `500`).
- `rate_limit_retries`: Retries after RPC timeouts (Default: `100`).
- `timeout_retries`: Retries for rate-limited responses (Default: `100`).
- `initial_backoff`: Initial backoff in ms before retry (Default: `500`).
- `recover_query_delay`: Delay in ms between paginated getLogs calls (Default: `50`).
- `default_finalized_block_count`: Finality lag assumed behind latest block (Default: `100`).
- `remove_finalized_block_interval_minutes`: Interval in minutes to prune finalized blocks (Default: `30`).
- `watch_loop_wait_time_ms`: Watch loop delay in ms (Default: `500`).
- `blockchain_rpc_timeout_secs`: RPC connect/read timeout in seconds (Default: `120`).

**Chunk Pool**
- `chunk_pool_write_window_size`: Max threads per file upload (Default: `4`).
- `chunk_pool_max_cached_chunks_all`: Max cached chunk bytes across all files (Default: `4194304`).
- `chunk_pool_max_writings`: Max concurrent file uploads (Default: `16`).
- `chunk_pool_expiration_time_secs`: Cached chunk expiration in seconds (Default: `300`).

**Database**
- `db_dir`: Directory to store data (Default: `db`).
- `db_max_num_sectors`: Max number of chunk entries to store (Default: None).
- `prune_check_time_s`: Interval to check prune conditions in seconds (Default: `60`).
- `prune_batch_size`: Number of entries per prune batch (Default: `16384`).
- `prune_batch_wait_time_ms`: Wait between prune batches in ms (Default: `1000`).
- `merkle_node_cache_capacity`: Merkle node cache capacity in bytes (Default: `33554432`).

**Misc**
- `log_config_file`: Log configuration file name (Default: `log_config`).
- `log_directory`: Directory for log output (Default: `log`).

**Mining**
- `mine_contract_address`: Mine contract address (Default: empty).
- `miner_id`: Optional miner ID (Default: None).
- `miner_key`: Miner private key (Default: None).
- `miner_cpu_percentage`: CPU usage percentage for mining (Default: `100`).
- `mine_iter_batch_size`: Mining iteration batch size (Default: `100`).
- `reward_contract_address`: Reward contract address (Default: empty).
- `shard_position`: Shard selector in `<shard_id>/<shard_number>` format (Default: None).
- `mine_context_query_seconds`: Interval to query mine context in seconds (Default: `5`).

<Tabs>
  <TabItem value="testnet" label="Testnet">

### Configuration

1. Copy the testnet configuration:

```bash
cd run
cp config-testnet-turbo.toml config.toml
```

2. Update the following fields in `config.toml`:

```toml
# Contract addresses for testnet
log_contract_address = "FLOW_CONTRACT_ADDRESS"
mine_contract_address = "MINE_CONTRACT_ADDRESS"

# Testnet RPC endpoint
blockchain_rpc_endpoint = "https://evmrpc-testnet.0g.ai"

# Start sync block number for testnet
log_sync_start_block_number = 1

# Reward contract for testnet
reward_contract_address = "REWARD_CONTRACT_ADDRESS"

# Your private key for mining (64 chars, no '0x' prefix)
miner_key = "YOUR_PRIVATE_KEY"
```

3. Optional: Configure network settings if needed:

```toml
# Target number of connected peers (can be increased for better connectivity)
network_target_peers = 50
```

### Sharding Configuration

Sharding allows you to control how much data your storage node stores. This is particularly useful when disk space is limited.

#### Understanding Shard Position

The `shard_position` parameter determines which portion of the total network data your node stores:

```toml
# Format: shard_id/shard_number where shard_number is 2^n
# This only applies if there is no stored shard config in db
shard_position = "0/2"
```

**Format**: `<shard_id>/<shard_number>`
- `shard_id`: Which shard this node stores (0, 1, 2, 3, etc.)
- `shard_number`: Total number of shards (must be a power of 2: 2, 4, 8, 16, etc.)

**Examples**:
- `shard_position = "0/2"` ‚Üí Store 50% of data (shard 0 of 2 total shards)
- `shard_position = "1/2"` ‚Üí Store 50% of data (shard 1 of 2 total shards)
- `shard_position = "0/4"` ‚Üí Store 25% of data (shard 0 of 4 total shards)
- `shard_position = "2/4"` ‚Üí Store 25% of data (shard 2 of 4 total shards)

Each shard stores a **specific range** of the total data. For example, with `0/2` and `1/2`, both store 50% of data but on different, non-overlapping ranges.

#### How Sharding Works

Consider a scenario with 128 GB total network data and a 100 GB disk:

1. **Initial Setup** (`shard_position = "0/2"`):
   - Your node stores 64 GB (50% of 128 GB)
   - Stores a specific, deterministic data range
   - Fits comfortably on your 100 GB disk

2. **Network Growth** (total data becomes 256 GB):
   - Your node would be responsible for 128 GB (50% of 256 GB)
   - This exceeds your 100 GB disk capacity
   - **Automatic adjustment**: Node automatically splits to `x/4`
   - Now stores 64 GB (25% of 256 GB)
   - `shard_id` changes: `0` ‚Üí `0 or 2`, `1` ‚Üí `1 or 3` (randomly assigned by the node, you cannot control which)

#### Automatic Shard Division

When network data exceeds your disk capacity, the node automatically:
- Doubles the shard number (2 ‚Üí 4 ‚Üí 8 ‚Üí 16, etc.)
- Randomly reassigns to a new shard within the split (you cannot control which)
- Maintains storage within disk limits

:::warning Important Notes
- **Initial setup is deterministic**: When you first configure `shard_position`, the shard_id deterministically maps to a specific data range
- This setting only applies on **first startup** if no shard config exists in the database
- **Auto-splitting is NOT deterministic**: When the node automatically splits shards due to capacity limits, you cannot control which new shard_id you get - it's randomly assigned
- Once shard config is stored in the database, the node manages all future shard adjustments automatically
:::

#### Choosing Your Shard Configuration

To determine the right shard configuration:

1. **Estimate network data size**: Check current total data on the network
2. **Consider disk capacity**: Leave headroom for growth (e.g., use 70-80% of disk)
3. **Calculate shard number**: `shard_number = total_data / (disk_capacity * 0.75)`
4. **Round up to nearest power of 2**: 2, 4, 8, 16, 32, etc.

**Example**:
- Network data: 500 GB
- Your disk: 200 GB
- Safe storage: 150 GB (75% of disk)
- Calculation: 500 / 150 ‚âà 3.33 ‚Üí Round up to 4
- Configuration: `shard_position = "0/4"` (stores ~125 GB)

### Running the Node

1. Check configuration options:
```bash
../target/release/zgs_node -h
```

2. Run the testnet storage service:
```bash
cd run
../target/release/zgs_node --config config.toml --miner-key <your_private_key>
```

  </TabItem>
  <TabItem value="mainnet" label="Mainnet">

### Configuration

1. Copy the mainnet configuration:

```bash
cd run
cp config-mainnet-turbo.toml config.toml
```

2. Update the following fields in `config.toml`:

```toml
# Contract addresses for mainnet
log_contract_address = "FLOW_CONTRACT_ADDRESS"
mine_contract_address = "MINE_CONTRACT_ADDRESS"
reward_contract_address = "REWARD_CONTRACT_ADDRESS"

# Mainnet RPC endpoint
blockchain_rpc_endpoint = "https://evmrpc.0g.ai"

# Start sync block number for mainnet
log_sync_start_block_number = 2387557

# Your private key for mining (64 chars, no '0x' prefix)
miner_key = "YOUR_PRIVATE_KEY"
```

3. The mainnet configuration includes predefined boot nodes for network connectivity:

```toml
network_boot_nodes = ["/ip4/34.66.131.173/udp/1234/p2p/16Uiu2HAmG81UgZ1JJLx9T2HqELgJNP36ChHzYkCdA9HdxvAbb5jQ","/ip4/34.60.163.4/udp/1234/p2p/16Uiu2HAmL3DoA7e7mbxs7CkeCPtNrAcfJFFtLpJDr2HWuR6QwJ8k","/ip4/34.169.236.186/udp/1234/p2p/16Uiu2HAm489RdhEgZUFmNTR4jdLEE4HjrvwaPCkEpSYSgvqi1CbR","/ip4/34.71.110.60/udp/1234/p2p/16Uiu2HAmBfGfbLNRegcqihiuXhgSXWNpgiGm6EwW2SYexfPUNUHQ"]
```

### Sharding Configuration

Sharding allows you to control how much data your storage node stores. This is particularly useful when disk space is limited.

#### Understanding Shard Position

The `shard_position` parameter determines which portion of the total network data your node stores:

```toml
# Format: shard_id/shard_number where shard_number is 2^n
# This only applies if there is no stored shard config in db
shard_position = "0/2"
```

**Format**: `<shard_id>/<shard_number>`
- `shard_id`: Which shard this node stores (0, 1, 2, 3, etc.)
- `shard_number`: Total number of shards (must be a power of 2: 2, 4, 8, 16, etc.)

**Examples**:
- `shard_position = "0/2"` ‚Üí Store 50% of data (shard 0 of 2 total shards)
- `shard_position = "1/2"` ‚Üí Store 50% of data (shard 1 of 2 total shards)
- `shard_position = "0/4"` ‚Üí Store 25% of data (shard 0 of 4 total shards)
- `shard_position = "2/4"` ‚Üí Store 25% of data (shard 2 of 4 total shards)

Each shard stores a **specific range** of the total data. For example, with `0/2` and `1/2`, both store 50% of data but on different, non-overlapping ranges.

#### How Sharding Works

Consider a scenario with 128 GB total network data and a 100 GB disk:

1. **Initial Setup** (`shard_position = "0/2"`):
   - Your node stores 64 GB (50% of 128 GB)
   - Stores a specific, deterministic data range
   - Fits comfortably on your 100 GB disk

2. **Network Growth** (total data becomes 256 GB):
   - Your node would be responsible for 128 GB (50% of 256 GB)
   - This exceeds your 100 GB disk capacity
   - **Automatic adjustment**: Node automatically splits to `x/4`
   - Now stores 64 GB (25% of 256 GB)
   - `shard_id` changes: `0` ‚Üí `0 or 2`, `1` ‚Üí `1 or 3` (randomly assigned by the node, you cannot control which)

#### Automatic Shard Division

When network data exceeds your disk capacity, the node automatically:
- Doubles the shard number (2 ‚Üí 4 ‚Üí 8 ‚Üí 16, etc.)
- Randomly reassigns to a new shard within the split (you cannot control which)
- Maintains storage within disk limits

:::warning Important Notes
- **Initial setup is deterministic**: When you first configure `shard_position`, the shard_id deterministically maps to a specific data range
- This setting only applies on **first startup** if no shard config exists in the database
- **Auto-splitting is NOT deterministic**: When the node automatically splits shards due to capacity limits, you cannot control which new shard_id you get - it's randomly assigned
- Once shard config is stored in the database, the node manages all future shard adjustments automatically
:::

#### Choosing Your Shard Configuration

To determine the right shard configuration:

1. **Estimate network data size**: Check current total data on the network
2. **Consider disk capacity**: Leave headroom for growth (e.g., use 70-80% of disk)
3. **Calculate shard number**: `shard_number = total_data / (disk_capacity * 0.75)`
4. **Round up to nearest power of 2**: 2, 4, 8, 16, 32, etc.

**Example**:
- Network data: 500 GB
- Your disk: 200 GB
- Safe storage: 150 GB (75% of disk)
- Calculation: 500 / 150 ‚âà 3.33 ‚Üí Round up to 4
- Configuration: `shard_position = "0/4"` (stores ~125 GB)

### Running the Node

1. Check configuration options:
```bash
../target/release/zgs_node -h
```

2. Run the mainnet storage service:
```bash
cd run
../target/release/zgs_node --config config.toml --miner-key <your_private_key>
```

**Important Mainnet Notes**:
- Ensure your miner key has sufficient 0G tokens for transaction fees
- Mainnet nodes should have stable internet connectivity and sufficient bandwidth
- Monitor your node's performance and logs regularly

</TabItem>
</Tabs>

## Snapshot
Make sure to only include `flow_db` and delete `data_db` under `db` folder when you use a snapshot from a 3rd party !
> Using others' `data_db` will make the node mine for others!

**Additional Notes**
*   **Security:** Keep your private key (`miner_key`) safe and secure. Anyone with access to it can control your node and potentially claim your mining rewards.

*   **Network Connectivity:** Ensure your node has a stable internet connection and that the necessary ports are open for communication with other nodes.

*   **Monitoring:** Monitor your node's logs and resource usage to ensure it's running smoothly.

*   **Updates:** Stay informed about updates to the 0G storage node software and follow the project's documentation for any changes in the setup process.

**Remember:** Running a storage node is a valuable contribution to the 0G network. You'll be helping to maintain its decentralization and robustness while earning rewards for your efforts.

  </TabItem>
  <TabItem value="docker" label="Storage KV Node">

## Overview
  0G Storage KV is a key-value store built on top of the 0G Storage system. This guide provides detailed steps to deploy and run a 0G Storage KV node.

## Prerequisites

Before setting up your 0G Storage KV node:

- Understand that 0G KV interacts with on-chain contracts and storage nodes to simulate KV data streams.
- For official deployed contract addresses, visit the [testnet information page](../developer-hub/testnet/testnet-overview.md).

## Install Dependencies

Follow the same steps to install dependencies and Rust as in the storage node setup:
<Tabs>
  <TabItem value="linux">

        ```bash
        sudo apt-get update
        sudo apt-get install clang cmake build-essential pkg-config libssl-dev protobuf-compiler
        ```
</TabItem>
  <TabItem value="mac">
        ```bash
        brew install llvm cmake
        ```
</TabItem>
</Tabs>
**Install `rustup`**: rustup is the Rust toolchain installer, necessary as the 0G node software is written in Rust.

    ```bash
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
    ```

#### 1. Download the Source Code

```bash
git clone -b <latest_tag> https://github.com/0gfoundation/0g-storage-kv.git
```

#### 2. Build the Source Code

```bash
cd 0g-storage-kv

# Build in release mode
cargo build --release
```

## Configuration

1. Copy the example configuration file and update it:

```bash
cp config_example.toml config.toml
nano config.toml
```

2. Update the following fields in `config.toml`:

```toml
#######################################################################
###                   Key-Value Stream Options                      ###
#######################################################################

# Streams to monitor.
stream_ids = ["000000000000000000000000000000000000000000000000000000000000f2bd", "000000000000000000000000000000000000000000000000000000000000f009", "0000000000000000000000000000000000000000000000000000000000016879", "0000000000000000000000000000000000000000000000000000000000002e3d"]

#######################################################################
###                     DB Config Options                           ###
#######################################################################

# Directory to store data.
db_dir = "db"
# Directory to store KV Metadata.
kv_db_dir = "kv.DB"

#######################################################################
###                     Log Sync Config Options                     ###
#######################################################################

blockchain_rpc_endpoint = "BLOCKCHAIN_RPC_ENDPOINT" #rpc endpoint, see testnet information
log_contract_address = "LOG_CONTRACT_ADDRESS" #flow contract address, see testnet information
# log_sync_start_block_number should be earlier than the block number of the first transaction that writes to the stream being monitored.
log_sync_start_block_number = 0

#######################################################################
###                     RPC Config Options                          ###
#######################################################################

# Whether to provide RPC service.
rpc_enabled = true

# HTTP server address to bind for public RPC.
rpc_listen_address = "0.0.0.0:6789"

# Zerog storage nodes to download data from.
zgs_node_urls = "http://127.0.0.1:5678,http://127.0.0.1:5679"

#######################################################################
###                     Misc Config Options                         ###
#######################################################################

log_config_file = "log_config"
```

## Running the Storage KV Node

1. Navigate to the `run` directory:
```bash
cd run
```

2. Run the KV service:
```bash
../target/release/zgs_kv --config config.toml
```

For long-running sessions, consider using `tmux` or `screen` to run the node in the background.

## Monitoring and Maintenance

1. Check logs:
   The node outputs logs based on the `log_config` file specified in your configuration.

2. Updating the node:

 To update to the latest version, pull the latest changes from the repository and rebuild:

 ```bash
   git pull
   cargo build --release
   ```

## Troubleshooting

If you encounter issues:

1. Check the logs for any error messages.
2. Ensure your node meets the hardware requirements.
3. Verify that your `config.toml` file is correctly formatted and contains valid settings.
4. Check your internet connection and firewall settings.
5. Ensure the specified blockchain RPC endpoint and contract addresses are correct and accessible.

## Getting Help

If you need assistance:

1. Check the [GitHub Issues](https://github.com/0gfoundation/0g-storage-kv/issues) for known problems and solutions.
2. Join the 0G community channels (Discord, Telegram, etc.) for community support.
3. For critical issues, consider reaching out to the 0G team directly.

## Conclusion

Running a 0G Storage KV node is an important part of the 0G ecosystem, providing key-value storage capabilities. By following this guide, you should be able to set up and operate your node successfully. Remember to keep your node updated and monitor its performance regularly to ensure optimal operation.
</TabItem>
</Tabs>

---

## Validator Node

---

Running a Validator node means providing validator services for the network, processing transactions and maintaining consensus.

:::info **What You'll Need**
- Linux/macOS system with adequate hardware
- Stable internet connection
- Ethereum RPC endpoint (mainnet for Aristotle, HoleSky testnet for Galileo)
:::

## Hardware Requirements

| Component  | Mainnet (Aristotle) | Testnet (Galileo) |
|------------|---------|----------|
| Memory     | 64 GB   | 64 GB    |
| CPU        | 8 cores | 8 cores  |
| Disk       | 1 TB NVME SSD | 4 TB NVME SSD |
| Bandwidth  | 100 MBps for Download / Upload | 100 MBps for Download / Upload |

## Restaking RPC Configuration

- **Validator Nodes**: When running your consensus client, add the following flags to enable restaking and configure the Symbiotic RPC:

```bash
--chaincfg.restaking.enabled \
--chaincfg.restaking.symbiotic-rpc-dial-url ${ETH_RPC_URL} \
--chaincfg.restaking.symbiotic-get-logs-block-range ${BLOCK_NUM}
```

- **ETH_RPC_URL**: The RPC endpoint for the Symbiotic network.
  - **Mainnet (Aristotle)**: Use an Ethereum Mainnet RPC endpoint (e.g., https://eth-mainnet.g.alchemy.com/v2/YOUR_API_KEY)
  - **Testnet (Galileo)**: Use an Ethereum HoleSky RPC endpoint
- **BLOCK_NUM**: The maximum block number range per call when syncing restaking events. Default is 1. Adjust based on your RPC provider limits.

- **Non-Validator Nodes**: No restaking-related configuration is required; you can keep your current startup parameters unchanged.

This enables staking in Symbiotic contracts on Ethereum (mainnet: Ethereum, testnet: HoleSky) to participate in 0G Chain consensus. Validators must be able to read the Ethereum contract state to generate and verify new blocks. You can run your own node or use a third-party RPC provider such as QuickNode or Infura for `${ETH_RPC_URL}`.

:::tip Non-Validator Nodes
Restaking configuration is NOT required for non-validator nodes. Do not add the `--chaincfg.restaking.*` flags when running non-validator nodes.
:::

---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
  <TabItem value="mainnet" label="Mainnet (Aristotle)" default>

## Mainnet (Aristotle) Setup Guide

### 1. Download Package

Download the latest Aristotle mainnet package:

```bash
wget -O aristotle.tar.gz https://github.com/0gfoundation/0gchain-Aristotle/releases/download/v1.0.4/Aristotle-v1.0.4.tar.gz
```

:::note Version Information
Latest Aristotle mainnet release: v1.0.4. Check [releases page](https://github.com/0gfoundation/0gchain-Aristotle/releases) for newer versions.
:::

### 2. Extract Package

Extract the Aristotle node package to your home directory:

```bash
tar -xzvf Aristotle-v1.0.4.tar.gz -C ~
```

### 3. Create Data Directory and Copy Configuration

Create your data directory and copy the default configuration:

```bash
cd Aristotle-v1.0.4

cp -r 0g-home {your data path}
sudo chmod 777 ./bin/geth
sudo chmod 777 ./bin/0gchaind
```

### 4. Initialize Geth

Initialize the Geth execution client with the genesis configuration:

```bash
./bin/geth init --datadir {your data path}/0g-home/geth-home ./geth-genesis.json
```

**Expected output:** "Successfully wrote genesis state"

### 5. Initialize 0gchaind for Mainnet

Create a temporary initialization with the mainnet chain specification:

```bash
./bin/0gchaind init {node name} --home {your data path}/tmp --chaincfg.chain-spec mainnet
```

‚ö†Ô∏è **Important:** The `--chaincfg.chain-spec mainnet` flag is REQUIRED for validators

### 6. Copy Node Keys and Validator Keys

Copy all necessary keys to the permanent directory:

```bash
cp {your data path}/tmp/data/priv_validator_state.json {your data path}/0g-home/0gchaind-home/data/
cp {your data path}/tmp/config/node_key.json {your data path}/0g-home/0gchaind-home/config/
cp {your data path}/tmp/config/priv_validator_key.json {your data path}/0g-home/0gchaind-home/config/
```

### 7. Generate JWT Authentication Token

Generate a JWT token with mainnet specification for secure communication:

```bash
./bin/0gchaind jwt generate --home {your data path}/0g-home/0gchaind-home --chaincfg.chain-spec mainnet

cp -f {your data path}/0g-home/0gchaind-home/config/jwt.hex ./
```

### 8. Configure Node Name

Update the node moniker in the configuration file:

```bash
sed -i 's/moniker = "0G-mainnet-aristotle-node"/moniker = "{your node name}"/' {your data path}/0g-home/0gchaind-home/config/config.toml
```

### 9. Verify Configuration Files

Ensure all required configuration files are present:

```bash
ls -la {your data path}/0g-home/0gchaind-home/config/
```

**Should display:**
- `app.toml`
- `client.toml`
- `config.toml`
- `genesis.json`
- `jwt.hex`
- `node_key.json`
- `priv_validator_key.json`

### 10. Set Environment Variables

Configure required environment variables for Symbiotic restaking:

```bash
# Set your Ethereum RPC endpoint (mainnet)
export ETH_RPC_URL="https://eth-mainnet.g.alchemy.com/v2/YOUR_API_KEY"

# Set block range for syncing (adjust based on your RPC limits)
export BLOCK_NUM=1
```

### 11. Start 0gchaind

Launch the 0gchaind consensus client with validator-specific parameters:

```bash
cd Aristotle-v1.0.4

nohup ./bin/0gchaind start \
    --rpc.laddr tcp://0.0.0.0:26657 \
    --chaincfg.kzg.trusted-setup-path=kzg-trusted-setup.json \
    --chaincfg.engine.jwt-secret-path=jwt.hex \
    --chaincfg.block-store-service.enabled \
    --chaincfg.restaking.enabled \
    --chaincfg.restaking.symbiotic-rpc-dial-url ${ETH_RPC_URL} \
    --chaincfg.restaking.symbiotic-get-logs-block-range ${BLOCK_NUM} \
    --home {your data path}/0g-home/0gchaind-home \
    --p2p.external_address {your node ip}:26656 > {your data path}/0g-home/log/0gchaind.log 2>&1 &
```

**Validator-Specific Parameters:**
- `--chaincfg.restaking.enabled`: Enables restaking functionality
- `--chaincfg.restaking.symbiotic-rpc-dial-url`: Ethereum RPC for Symbiotic protocol
- `--chaincfg.restaking.symbiotic-get-logs-block-range`: Block range per sync call

### 12. Start Geth

Launch the Geth execution client:

```bash
cd Aristotle-v1.0.4

nohup ./bin/geth \
    --config geth-config.toml \
    --nat extip:{your node ip} \
    --datadir {your data path}/0g-home/geth-home \
    --networkid 16661 > {your data path}/0g-home/log/geth.log 2>&1 &
```

### 13. Verify Node Status

Check that both services are running correctly:

```bash
# Check 0gchaind logs
tail -f {your data path}/0g-home/log/0gchaind.log

# Check geth logs
tail -f {your data path}/0g-home/log/geth.log
```

  </TabItem>
  <TabItem value="testnet" label="Testnet (Galileo)">

## Testnet (Galileo) Setup Guide

### 1. Download Package

Download the latest Galileo testnet package:

```bash
wget -O galileo.tar.gz https://github.com/0gfoundation/0gchain-NG/releases/download/v3.0.4/Galileo-v3.0.4.tar.gz
```

:::note Version Information
Latest Galileo testnet release: v3.0.4. Check [releases page](https://github.com/0gfoundation/0gchain-NG/releases) for newer versions.
:::

### 2. Extract Package

Extract the package to your home directory:

```bash
tar -xzvf Galileo-v3.0.4.tar.gz -C ~
```

### 3. Create Data Directory and Copy Configuration

Copy the configuration files and set proper permissions:

```bash
cd Galileo-v3.0.4

cp -r 0g-home {your data path}
sudo chmod 777 ./bin/geth
sudo chmod 777 ./bin/0gchaind
```

### 4. Initialize Geth

Initialize the Geth execution client with the genesis file:

```bash
./bin/geth init --datadir {your data path}/0g-home/geth-home ./geth-genesis.json
```

**Expected output:** "Successfully wrote genesis state"

### 5. Initialize 0gchaind for Testnet

Create a temporary directory for initial configuration with testnet chain specification:

```bash
./bin/0gchaind init {node name} --home {your data path}/tmp --chaincfg.chain-spec testnet
```

‚ö†Ô∏è **Important:** The `--chaincfg.chain-spec testnet` flag is REQUIRED for testnet validators

### 6. Generate JWT Authentication Token

Generate a JWT token with testnet specification for secure communication:

```bash
./bin/0gchaind jwt generate --home {your data path}/0g-home/0gchaind-home --chaincfg.chain-spec testnet

cp -f {your data path}/0g-home/0gchaind-home/config/jwt.hex ./
```

### 7. Copy Node Files

Move the generated keys to the proper location:

```bash
cp {your data path}/tmp/data/priv_validator_state.json {your data path}/0g-home/0gchaind-home/data/
cp {your data path}/tmp/config/node_key.json {your data path}/0g-home/0gchaind-home/config/
cp {your data path}/tmp/config/priv_validator_key.json {your data path}/0g-home/0gchaind-home/config/
```

> Note: The temporary directory can be deleted after this step.

### 8. Set Environment Variables

Configure required environment variables for Symbiotic restaking:

```bash
# Set your Ethereum HoleSky RPC endpoint (testnet)
export ETH_RPC_URL="https://holesky-rpc.g.alchemy.com/v2/YOUR_API_KEY"

# Set block range for syncing (adjust based on your RPC limits)
export BLOCK_NUM=1
```

### 9. Start 0gchaind

Launch the 0gchaind consensus client with testnet parameters:

```bash
cd ~/Galileo-v3.0.4

nohup ./bin/0gchaind start \
    --rpc.laddr tcp://0.0.0.0:26657 \
    --chaincfg.chain-spec testnet \
    --chaincfg.kzg.trusted-setup-path=kzg-trusted-setup.json \
    --chaincfg.engine.jwt-secret-path=jwt.hex \
    --chaincfg.block-store-service.enabled \
    --chaincfg.restaking.enabled \
    --chaincfg.restaking.symbiotic-rpc-dial-url ${ETH_RPC_URL} \
    --chaincfg.restaking.symbiotic-get-logs-block-range ${BLOCK_NUM} \
    --home {your data path}/0g-home/0gchaind-home \
    --p2p.external_address {your node ip}:26656 > {your data path}/0g-home/log/0gchaind.log 2>&1 &
```

### 10. Start Geth

Launch the Geth execution client:

```bash
cd ~/Galileo-v3.0.4

nohup ./bin/geth \
    --config geth-config.toml \
    --nat extip:{your node ip} \
    --datadir {your data path}/0g-home/geth-home \
    --networkid 16602 > {your data path}/0g-home/log/geth.log 2>&1 &
```

### 11. Verify Setup

Check the logs to confirm your node is running properly:

```bash
# Check 0gchaind logs
tail -f {your data path}/0g-home/log/0gchaind.log

# Check geth logs
tail -f {your data path}/0g-home/log/geth.log
```

:::success **Success Indicators**
- 0gchaind should show "Committed state" messages
- No error messages in either log
- Validator is participating in consensus
:::

  </TabItem>
</Tabs>

---

## Validator Operations

### Initialize Your Validator

Once your validator node is running and fully synced (`catching_up: false`), you need to initialize your validator on the blockchain to start validating transactions.

**Next Step:** Follow the **[Validator Initialization Guide](../developer-hub/building-on-0g/contracts-on-0g/staking-interfaces#validator-initialization)** to:
1. Generate validator signature
2. Prepare validator description and settings
3. Execute the initialization transaction
4. Verify your validator activation (typically 30-60 minutes)

---

### Monitor Consensus Participation

```bash
# Check if your validator is in the active set
curl http://localhost:26657/validators | jq
```

### Check Sync Status

```bash
# Should show "catching_up": false when fully synced
curl http://localhost:26657/status | jq '.result.sync_info'
```

### Key Management

‚ö†Ô∏è **Critical Security Notice:**

- **Backup your validator keys immediately**: `priv_validator_key.json` and `node_key.json`
- **Never share your private validator key** with anyone
- Store backups in multiple secure locations
- Test recovery process in a non-production environment first

<details>
<summary>Backup & Recovery</summary>

These files are essential for validator recovery and must be backed up securely:

```bash
# Essential validator keys
/{your data path}/0g-home/0gchaind-home/config/
```

#### Recovery Process

To restore your validator from backup:

1. **Stop running services**:
   ```bash
   pkill 0gchaind
   pkill geth
   ```

2. **Restore key files**:
   ```bash
   cp ~/validator-backup/node_key.json /{your data path}/0g-home/0gchaind-home/config/
   cp ~/validator-backup/priv_validator_key.json /{your data path}/0g-home/0gchaind-home/config/
   ```

3. **Restart services** following the appropriate setup guide steps.

</details>

<details>
<summary>Upgrade Validator</summary>

### Step 1: Extract New Release

```bash
# For Testnet (Galileo)
wget -O galileo.tar.gz https://github.com/0gfoundation/0gchain-NG/releases/download/v3.0.4/Galileo-v3.0.4.tar.gz
tar -xzvf Galileo-v3.0.4.tar.gz -C ~

# For Mainnet (Aristotle)
wget -O aristotle.tar.gz https://github.com/0gfoundation/0gchain-Aristotle/releases/download/v1.0.4/Aristotle-v1.0.4.tar.gz
tar -xzvf Aristotle-v1.0.4.tar.gz -C ~

# Verify extraction
ls -la {network}-v{version}/
```

### Step 2: Stop Services

```bash
# Stop consensus layer (0gchaind)
pkill 0gchaind

# Stop execution layer (geth)
pkill geth
```

### Step 3: Backup Your Data

```bash
# Create backup directory with timestamp
BACKUP_DIR="backup-$(date +%Y%m%d-%H%M%S)"
mkdir -p $BACKUP_DIR

# Backup execution layer data (geth-home)
cp -r {your_geth_datadir} $BACKUP_DIR/geth-backup

# Backup consensus layer data (0gchaind-home)
cp -r {your_0gchaind_home} $BACKUP_DIR/0gchaind-backup
```

### Step 4: Start Node 

If you get error while starting node due to missing `priv_validator_state.json`, create an empty `priv_validator_state.json` file in that directory with `{}`.

For testnet (Galileo), use `--chaincfg.chain-spec testnet`:

```bash
nohup ./bin/0gchaind start \
    --rpc.laddr tcp://0.0.0.0:26657 \
    --chaincfg.chain-spec testnet \
    --chaincfg.restaking.enabled \
    --chaincfg.restaking.symbiotic-rpc-dial-url ${ETH_RPC_URL} \
    --chaincfg.restaking.symbiotic-get-logs-block-range ${BLOCK_NUM} \
    --chaincfg.kzg.trusted-setup-path=kzg-trusted-setup.json \
    --chaincfg.engine.jwt-secret-path=jwt.hex \
    --chaincfg.block-store-service.enabled \
    --home {your_cl_home} \
    --p2p.external_address {your_node_ip}:26656 > {your_log_path}/0gchaind.log 2>&1 &
```

For mainnet (Aristotle), use `--chaincfg.chain-spec mainnet`:

```bash
nohup ./bin/0gchaind start \
    --rpc.laddr tcp://0.0.0.0:26657 \
    --chaincfg.chain-spec mainnet \
    --chaincfg.restaking.enabled \
    --chaincfg.restaking.symbiotic-rpc-dial-url ${ETH_RPC_URL} \
    --chaincfg.restaking.symbiotic-get-logs-block-range ${BLOCK_NUM} \
    --chaincfg.kzg.trusted-setup-path=kzg-trusted-setup.json \
    --chaincfg.engine.jwt-secret-path=jwt.hex \
    --chaincfg.block-store-service.enabled \
    --home {your_cl_home} \
    --p2p.external_address {your_node_ip}:26656 > {your_log_path}/0gchaind.log 2>&1 &
```

Then start Geth:

```bash
nohup ./bin/geth --config geth-config.toml \
     --nat extip:{your_node_ip} \
     --datadir {your_geth_datadir} \
     --networkid {network_id} > {your_log_path}/geth.log 2>&1 &
```

### Step 5: Verify Upgrade Success

```bash
# Monitor consensus layer logs
tail -f {your_log_path}/0gchaind.log

# Monitor execution layer logs
tail -f {your_log_path}/geth.log
```

</details>

## Next Steps

### Staking Integration

Once your validator node is running, you can interact with the staking system programmatically using smart contracts:

- **[Staking Interfaces Guide](../developer-hub/building-on-0g/contracts-on-0g/staking-interfaces)** - Complete documentation for integrating with 0G Chain staking smart contracts
