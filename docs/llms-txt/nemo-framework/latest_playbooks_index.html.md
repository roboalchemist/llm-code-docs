# Source: https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md

Title: Tutorials — NVIDIA NeMo Framework User Guide

URL Source: https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html

Published Time: Fri, 05 Sep 2025 19:00:43 GMT

Markdown Content:
Tutorials[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#tutorials "Link to this heading")
----------------------------------------------------------------------------------------------------------------------------

The best way to get started with NeMo is to start with one of our tutorials. They cover various domains and provide both introductory and advanced topics.

These tutorials can be run from inside the [NeMo Framework Docker Container](https://docs.nvidia.com/nemo-framework/user-guide/latest/installation.html.md#install-nemo-framework).

Large Language Models[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#large-language-models "Link to this heading")
----------------------------------------------------------------------------------------------------------------------------------------------------

### Data Curation[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#data-curation "Link to this heading")

Explore examples of data curation techniques using NeMo Curator:

| Title with Link | Description |
| --- | --- |
| [Distributed Data Classification](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/distributed_data_classification) | The notebook showcases how to use NeMo Curator with two distinct classifiers: one for evaluating data quality and another for identifying data domains. Integrating these classifiers streamlines the annotation process, enhancing the combination of diverse datasets essential for training foundational models. |
| [PEFT Curation](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/peft-curation) | The tutorial demonstrates how to use the NeMo Curator Python API to curate a dataset for Parameter Efficient Fine-Tuning (PEFT). Specifically, it uses the Enron dataset, which contains emails along with classification labels. Each email entry includes a subject, body, and category (class label). The tutorial showcases various filtering and processing operations that can be applied to each record. |
| [Single Node Data Curation Pipeline](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/single_node_tutorial) | The notebook provides a typical data curation pipeline using NeMo Curator, with the Thai Wikipedia dataset as an example. It demonstrates how to download Wikipedia data using NeMo Curator, perform language separation with FastText, apply GPU-based exact and fuzzy deduplication, and utilize CPU-based heuristic filtering. |
| [NeMo Curator Python API with Tinystories](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/tinystories) | The tutorial shows how to use the NeMo Curator Python API to curate the TinyStories dataset. TinyStories is a dataset of short stories generated by GPT-3.5 and GPT-4, featuring words that are understood by 3 to 4-year-olds. The small size of this dataset makes it ideal for creation and validation. |
| [Curating Datasets for Parameter Efficient Fine-tuning (PEFT) with Synthetic Data Generation (SDG)](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/peft-curation-with-sdg) | The tutorial demonstrates how to use the NeMo Curator Python API for data curation, as well as synthetic data generation and qualitative score assignment to prepare a dataset for PEFT of LLMs. |
| [Custom Tokenization for Domain Adaptive Pre-Training (DAPT)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/llama/domain-adaptive-pretraining/code/custom_tokenization.ipynb) | This notebook walks through the custom tokenization workflow required for DAPT, including training a customized tokenizer, dataset preprocessing, and checkpoints embedding table altering. |

### Training and Customization[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#training-and-customization "Link to this heading")

| Title with Link | Description |
| --- | --- |
| [Quickstart with NeMo 2.0 API](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html.md#nemo-2-quickstart-api) | The example shows how to run a simple training loop using NeMo 2.0. It uses the train API from the NeMo Framework LLM collection. |
| [Pre-training & PEFT Quickstart with NeMo Run](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html.md#nemo-2-quickstart-nemo-run) | This tutorial introduces how to run any of the supported [NeMo 2.0 Recipes](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes) using [NeMo-Run](https://github.com/NVIDIA/NeMo-Run). It also takes a pretraining and fine-tuning recipe and shows how to run it locally, as well as remotely, on a Slurm-based cluster. |
| [Long-Context LLM Training with NeMo Run](https://docs.nvidia.com/nemo-framework/user-guide/latest/longcontext/index.html.md#long-context-recipes) | This example demonstrates how to use [NeMo 2.0 Recipes](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes) with NeMo-Run for long-context model training, as well as extending the context length of an existing pretrained model. |
| [Llama 3 Supervised Fine-Tuning and Parameter Efficient Fine-Tuning with NeMo 2.0](https://github.com/NVIDIA/NeMo/tree/main/tutorials/llm/llama/nemo2-sft-peft) | This example shows how to perform Llama 3 Supervised Fine-Tuning and Parameter Efficient Fine-Tuning using SFT and LoRA notebooks with NeMo 2.0 and NeMo-Run. |
| [Parameter Efficient Fine-Tuning with NeMo AutoModel](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/automodel/peft.ipynb) | This example shows how to perform Parameter Efficient Fine-Tuning on Hugging Face Hub-available models with NeMo AutoModel. |
| [Supervised Fine-Tuning with NeMo AutoModel](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/automodel/sft.ipynb) | This example shows how to perform Supervised Fine-Tuning on Hugging Face Hub-available models with NeMo AutoModel. |
| [NeMo SlimPajama Data Pipeline and Pretraining Tutorial](https://github.com/NVIDIA/NeMo/tree/main/tutorials/llm/llama-3/slimpajama) | This tutorial provides step-by-step instructions for preprocessing the SlimPajama dataset and pretraining a Llama-based model using the NeMo 2.0 library. |
| [Domain Adaptive Pre-Training (DAPT) with Llama2 7B](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/llama/domain-adaptive-pretraining/code/domain_adaptive_pretraining_nemo2.0.ipynb) | This tutorial demonstrates how to perform DAPT on Pre-trained models such as Llama2-7B using [NeMo 2.0 Recipes](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes) with [NeMo-Run](https://github.com/NVIDIA/NeMo-Run). |
| [Finetuning Llama 3.2 Model into Embedding Model](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/embedding/llama_embedding.ipynb) | This tutorial provides a detailed walkthrough of fine-tuning a Llama 3.2 model into an embedding model using NeMo 2.0. |

World Foundation Models[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#world-foundation-models "Link to this heading")
--------------------------------------------------------------------------------------------------------------------------------------------------------

### Post Training[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#post-training "Link to this heading")

Explore examples of post-training techniques using World Foundation Models:

| Title with Link | Description |
| --- | --- |
| [Cosmos Diffusion Models](https://github.com/NVIDIA/Cosmos/blob/main/cosmos1/models/diffusion/nemo/post_training/README.md) | This example shows how to post-train Cosmos Diffusion-based World Foundation Models using the NeMo Framework for your custom physical AI tasks. |
| [Cosmos Autoregressive Models](https://github.com/NVIDIA/Cosmos/blob/main/cosmos1/models/autoregressive/nemo/post_training/README.md) | This example shows how to post-train Cosmos Autoregressive-based World Foundation Models using the NeMo Framework for your custom physical AI tasks. |

Speech AI[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#speech-ai "Link to this heading")
----------------------------------------------------------------------------------------------------------------------------

Most NeMo Speech AI tutorials can be run on [Google’s Colab](https://colab.research.google.com/notebooks/intro.ipynb).

### Running Tutorials on Colab[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#running-tutorials-on-colab "Link to this heading")

To run a tutorial:

1.   Click the **Colab** link associated with the tutorial you are interested in from the table below.

2.   Once in Colab, connect to an instance with a GPU by clicking **Runtime**>**Change runtime type** and selecting **GPU** as the hardware accelerator.

### Speech AI Fundamentals[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#speech-ai-fundamentals "Link to this heading")

| Title | GitHub / Colab URL |
| --- | --- |
| Getting Started: NeMo Fundamentals | [NeMo Fundamentals](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/00_NeMo_Primer.ipynb) |
| Getting Started: Audio translator example | [Audio translator example](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/AudioTranslationSample.ipynb) |
| Getting Started: Voice swap example | [Voice swap example](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/VoiceSwapSample.ipynb) |
| Getting Started: NeMo Models | [NeMo Models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/01_NeMo_Models.ipynb) |
| Getting Started: NeMo Adapters | [NeMo Adapters](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/02_NeMo_Adapters.ipynb) |
| Getting Started: NeMo Models on Hugging Face Hub | [NeMo Models on HF Hub](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/Publish_NeMo_Model_On_Hugging_Face_Hub.ipynb) |

### Automatic Speech Recognition (ASR) Tutorials[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#automatic-speech-recognition-asr-tutorials "Link to this heading")

| Title | GitHub / Colab URL |
| --- | --- |
| ASR with NeMo | [ASR with NeMo](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_NeMo.ipynb) |
| ASR with Subword Tokenization | [ASR with Subword Tokenization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_Subword_Tokenization.ipynb) |
| Offline ASR | [Offline ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Offline_ASR.ipynb) |
| Online ASR Microphone Cache Aware Streaming | [Online ASR Microphone Cache Aware Streaming](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_ASR_Microphone_Demo_Cache_Aware_Streaming.ipynb) |
| Online ASR Microphone Buffered Streaming | [Online ASR Microphone Buffered Streaming](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_ASR_Microphone_Demo_Buffered_Streaming.ipynb) |
| ASR CTC Language Fine-Tuning | [ASR CTC Language Fine-Tuning](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_CTC_Language_Finetuning.ipynb) |
| Intro to Transducers | [Intro to Transducers](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Intro_to_Transducers.ipynb) |
| ASR with Transducers | [ASR with Transducers](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_Transducers.ipynb) |
| ASR with Adapters | [ASR with Adapters](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/asr_adapters/ASR_with_Adapters.ipynb) |
| Speech Commands | [Speech Commands](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Speech_Commands.ipynb) |
| Online Offline Microphone Speech Commands | [Online Offline Microphone Speech Commands](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Offline_Speech_Commands_Demo.ipynb) |
| Voice Activity Detection | [Voice Activity Detection](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Voice_Activity_Detection.ipynb) |
| Online Offline Microphone VAD | [Online Offline Microphone VAD](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Offline_Microphone_VAD_Demo.ipynb) |
| Speaker Recognition and Verification | [Speaker Recognition and Verification](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/Speaker_Identification_Verification.ipynb) |
| Speaker Diarization Inference | [Speaker Diarization Inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/Speaker_Diarization_Inference.ipynb) |
| ASR with Speaker Diarization | [ASR with Speaker Diarization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/ASR_with_SpeakerDiarization.ipynb) |
| Online Noise Augmentation | [Online Noise Augmentation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Noise_Augmentation.ipynb) |
| ASR for Telephony Speech | [ASR for Telephony Speech](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_for_telephony_speech.ipynb) |
| Streaming inference | [Streaming inference](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Streaming_ASR.ipynb) |
| Buffered Transducer inference | [Buffered Transducer inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Buffered_Transducer_Inference.ipynb) |
| Buffered Transducer inference with LCS Merge | [Buffered Transducer inference with LCS Merge](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Buffered_Transducer_Inference_with_LCS_Merge.ipynb) |
| Offline ASR with VAD for CTC models | [Offline ASR with VAD for CTC models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Offline_ASR_with_VAD_for_CTC_models.ipynb) |
| Self-supervised Pre-training for ASR | [Self-supervised Pre-training for ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Self_Supervised_Pre_Training.ipynb) |
| Multi-lingual ASR | [Multi-lingual ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Multilang_ASR.ipynb) |
| Hybrid ASR-TTS Models | [Hybrid ASR-TTS Models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_TTS_Tutorial.ipynb) |
| ASR Confidence Estimation | [ASR Confidence Estimation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_Confidence_Estimation.ipynb) |
| Confidence-based Ensembles | [Confidence-based Ensembles](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Confidence_Ensembles.ipynb) |

### Text-to-Speech (TTS) Tutorials[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#text-to-speech-tts-tutorials "Link to this heading")

| Title | GitHub / Colab URL |
| --- | --- |
| Basic and Advanced: NeMo TTS Primer | [NeMo TTS Primer](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/NeMo_TTS_Primer.ipynb) |
| Basic and Advanced: TTS Speech/Text Aligner Inference | [TTS Speech/Text Aligner Inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Aligner_Inference_Examples.ipynb) |
| Basic and Advanced: FastPitch and MixerTTS Model Training | [FastPitch and MixerTTS Model Training](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_MixerTTS_Training.ipynb) |
| Basic and Advanced: FastPitch Finetuning | [FastPitch Finetuning](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_Finetuning.ipynb) |
| Basic and Advanced: FastPitch and HiFiGAN Model Training for German | [FastPitch and HiFiGAN Model Training for German](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_GermanTTS_Training.ipynb) |
| Basic and Advanced: Tacotron2 Model Training | [Tacotron2 Model Training](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Tacotron2_Training.ipynb) |
| Basic and Advanced: FastPitch Duration and Pitch Control | [FastPitch Duration and Pitch Control](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Inference_DurationPitchControl.ipynb) |
| Basic and Advanced: FastPitch Speaker Interpolation | [FastPitch Speaker Interpolation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_Speaker_Interpolation.ipynb) |
| Basic and Advanced: TTS Inference and Model Selection | [TTS Inference and Model Selection](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Inference_ModelSelect.ipynb) |
| Basic and Advanced: TTS Pronunciation Customization | [TTS Pronunciation Customization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Pronunciation_customization.ipynb) |

### Tools and Utilities[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#tools-and-utilities "Link to this heading")

| Title | GitHub / Colab URL |
| --- | --- |
| Utility Tools for Speech and Text: NeMo Forced Aligner | [NeMo Forced Aligner](https://colab.research.google.com/github/NVIDIA/NeMo/blob/main/tutorials/tools/NeMo_Forced_Aligner_Tutorial.ipynb) |
| Utility Tools for Speech and Text: Speech Data Explorer | [Speech Data Explorer](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tools/SDE_HowTo_v2.ipynb) |
| Utility Tools for Speech and Text: CTC Segmentation | [CTC Segmentation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tools/CTC_Segmentation_Tutorial.ipynb) |

### Text Processing (TN/ITN) Tutorials[#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#text-processing-tn-itn-tutorials "Link to this heading")

| Title | GitHub / Colab URL |
| --- | --- |
| Text Normalization Techniques: Text Normalization | [Text Normalization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/text_processing/Text_(Inverse)_Normalization.ipynb) |
| Text Normalization Techniques: Inverse Text Normalization with Thutmose Tagger | [Inverse Text Normalization with Thutmose Tagger](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/nlp/ITN_with_Thutmose_Tagger.ipynb) |
| Text Normalization Techniques: WFST Tutorial | [WFST Tutorial](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/text_processing/WFST_Tutorial.ipynb) |

Links/Buttons:
- [#](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html.md#text-processing-tn-itn-tutorials)
- [NeMo Framework Docker Container](https://docs.nvidia.com/nemo-framework/user-guide/latest/installation.html.md#install-nemo-framework)
- [Distributed Data Classification](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/distributed_data_classification)
- [PEFT Curation](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/peft-curation)
- [Single Node Data Curation Pipeline](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/single_node_tutorial)
- [NeMo Curator Python API with Tinystories](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/tinystories)
- [Curating Datasets for Parameter Efficient Fine-tuning (PEFT) with Synthetic Data Generation (SDG)](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/peft-curation-with-sdg)
- [Custom Tokenization for Domain Adaptive Pre-Training (DAPT)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/llama/domain-adaptive-pretraining/code/custom_tokenization.ipynb)
- [Quickstart with NeMo 2.0 API](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html.md#nemo-2-quickstart-api)
- [Pre-training & PEFT Quickstart with NeMo Run](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html.md#nemo-2-quickstart-nemo-run)
- [NeMo 2.0 Recipes](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes)
- [NeMo-Run](https://github.com/NVIDIA/NeMo-Run)
- [Long-Context LLM Training with NeMo Run](https://docs.nvidia.com/nemo-framework/user-guide/latest/longcontext/index.html.md#long-context-recipes)
- [Llama 3 Supervised Fine-Tuning and Parameter Efficient Fine-Tuning with NeMo 2.0](https://github.com/NVIDIA/NeMo/tree/main/tutorials/llm/llama/nemo2-sft-peft)
- [Parameter Efficient Fine-Tuning with NeMo AutoModel](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/automodel/peft.ipynb)
- [Supervised Fine-Tuning with NeMo AutoModel](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/automodel/sft.ipynb)
- [NeMo SlimPajama Data Pipeline and Pretraining Tutorial](https://github.com/NVIDIA/NeMo/tree/main/tutorials/llm/llama-3/slimpajama)
- [Domain Adaptive Pre-Training (DAPT) with Llama2 7B](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/llama/domain-adaptive-pretraining/code/domain_adaptive_pretraining_nemo2.0.ipynb)
- [Finetuning Llama 3.2 Model into Embedding Model](https://github.com/NVIDIA/NeMo/blob/main/tutorials/llm/embedding/llama_embedding.ipynb)
- [Cosmos Diffusion Models](https://github.com/NVIDIA/Cosmos/blob/main/cosmos1/models/diffusion/nemo/post_training/README.md)
- [Cosmos Autoregressive Models](https://github.com/NVIDIA/Cosmos/blob/main/cosmos1/models/autoregressive/nemo/post_training/README.md)
- [Google’s Colab](https://colab.research.google.com/notebooks/intro.ipynb)
- [NeMo Fundamentals](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/00_NeMo_Primer.ipynb)
- [Audio translator example](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/AudioTranslationSample.ipynb)
- [Voice swap example](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/VoiceSwapSample.ipynb)
- [NeMo Models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/01_NeMo_Models.ipynb)
- [NeMo Adapters](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/02_NeMo_Adapters.ipynb)
- [NeMo Models on HF Hub](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/Publish_NeMo_Model_On_Hugging_Face_Hub.ipynb)
- [ASR with NeMo](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_NeMo.ipynb)
- [ASR with Subword Tokenization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_Subword_Tokenization.ipynb)
- [Offline ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Offline_ASR.ipynb)
- [Online ASR Microphone Cache Aware Streaming](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_ASR_Microphone_Demo_Cache_Aware_Streaming.ipynb)
- [Online ASR Microphone Buffered Streaming](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_ASR_Microphone_Demo_Buffered_Streaming.ipynb)
- [ASR CTC Language Fine-Tuning](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_CTC_Language_Finetuning.ipynb)
- [Intro to Transducers](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Intro_to_Transducers.ipynb)
- [ASR with Transducers](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_Transducers.ipynb)
- [ASR with Adapters](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/asr_adapters/ASR_with_Adapters.ipynb)
- [Speech Commands](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Speech_Commands.ipynb)
- [Online Offline Microphone Speech Commands](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Offline_Speech_Commands_Demo.ipynb)
- [Voice Activity Detection](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Voice_Activity_Detection.ipynb)
- [Online Offline Microphone VAD](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Offline_Microphone_VAD_Demo.ipynb)
- [Speaker Recognition and Verification](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/Speaker_Identification_Verification.ipynb)
- [Speaker Diarization Inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/Speaker_Diarization_Inference.ipynb)
- [ASR with Speaker Diarization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/speaker_tasks/ASR_with_SpeakerDiarization.ipynb)
- [Online Noise Augmentation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Online_Noise_Augmentation.ipynb)
- [ASR for Telephony Speech](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_for_telephony_speech.ipynb)
- [Streaming inference](https://github.com/NVIDIA/NeMo/blob/stable/tutorials/asr/Streaming_ASR.ipynb)
- [Buffered Transducer inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Buffered_Transducer_Inference.ipynb)
- [Buffered Transducer inference with LCS Merge](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Buffered_Transducer_Inference_with_LCS_Merge.ipynb)
- [Offline ASR with VAD for CTC models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Offline_ASR_with_VAD_for_CTC_models.ipynb)
- [Self-supervised Pre-training for ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Self_Supervised_Pre_Training.ipynb)
- [Multi-lingual ASR](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Multilang_ASR.ipynb)
- [Hybrid ASR-TTS Models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_TTS_Tutorial.ipynb)
- [ASR Confidence Estimation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_Confidence_Estimation.ipynb)
- [Confidence-based Ensembles](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/Confidence_Ensembles.ipynb)
- [NeMo TTS Primer](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/NeMo_TTS_Primer.ipynb)
- [TTS Speech/Text Aligner Inference](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Aligner_Inference_Examples.ipynb)
- [FastPitch and MixerTTS Model Training](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_MixerTTS_Training.ipynb)
- [FastPitch Finetuning](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_Finetuning.ipynb)
- [FastPitch and HiFiGAN Model Training for German](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_GermanTTS_Training.ipynb)
- [Tacotron2 Model Training](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Tacotron2_Training.ipynb)
- [FastPitch Duration and Pitch Control](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Inference_DurationPitchControl.ipynb)
- [FastPitch Speaker Interpolation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/FastPitch_Speaker_Interpolation.ipynb)
- [TTS Inference and Model Selection](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Inference_ModelSelect.ipynb)
- [TTS Pronunciation Customization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Pronunciation_customization.ipynb)
- [NeMo Forced Aligner](https://colab.research.google.com/github/NVIDIA/NeMo/blob/main/tutorials/tools/NeMo_Forced_Aligner_Tutorial.ipynb)
- [Speech Data Explorer](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tools/SDE_HowTo_v2.ipynb)
- [CTC Segmentation](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tools/CTC_Segmentation_Tutorial.ipynb)
- [Text Normalization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/text_processing/Text_(Inverse)_Normalization.ipynb)
- [Inverse Text Normalization with Thutmose Tagger](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/nlp/ITN_with_Thutmose_Tagger.ipynb)
- [WFST Tutorial](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/text_processing/WFST_Tutorial.ipynb)
