# Source: https://python.useinstructor.com/integrations/xai/index.md

# Source: https://python.useinstructor.com/integrations/writer/index.md

# Source: https://python.useinstructor.com/integrations/vertex/index.md

# Source: https://python.useinstructor.com/integrations/truefoundry/index.md

# Source: https://python.useinstructor.com/integrations/together/index.md

# Source: https://python.useinstructor.com/integrations/sambanova/index.md

# Source: https://python.useinstructor.com/integrations/perplexity/index.md

# Source: https://python.useinstructor.com/integrations/openrouter/index.md

# Source: https://python.useinstructor.com/integrations/openai/index.md

# Source: https://python.useinstructor.com/integrations/openai-responses/index.md

# Source: https://python.useinstructor.com/integrations/ollama/index.md

# Source: https://python.useinstructor.com/integrations/mistral/index.md

# Source: https://python.useinstructor.com/integrations/llama-cpp-python/index.md

# Source: https://python.useinstructor.com/integrations/litellm/index.md

# Source: https://python.useinstructor.com/integrations/groq/index.md

# Source: https://python.useinstructor.com/integrations/google/index.md

# Source: https://python.useinstructor.com/integrations/genai/index.md

# Source: https://python.useinstructor.com/integrations/fireworks/index.md

# Source: https://python.useinstructor.com/integrations/deepseek/index.md

# Source: https://python.useinstructor.com/integrations/databricks/index.md

# Source: https://python.useinstructor.com/integrations/cortex/index.md

# Source: https://python.useinstructor.com/integrations/cohere/index.md

# Source: https://python.useinstructor.com/integrations/cerebras/index.md

# Source: https://python.useinstructor.com/integrations/bedrock/index.md

# Source: https://python.useinstructor.com/integrations/azure/index.md

# Source: https://python.useinstructor.com/integrations/anyscale/index.md

# Source: https://python.useinstructor.com/integrations/anthropic/index.md

# Source: https://python.useinstructor.com/integrations/index.md

# Source: https://python.useinstructor.com/concepts/validation/index.md

# Source: https://python.useinstructor.com/concepts/usage/index.md

# Source: https://python.useinstructor.com/concepts/unions/index.md

# Source: https://python.useinstructor.com/concepts/union/index.md

# Source: https://python.useinstructor.com/concepts/types/index.md

# Source: https://python.useinstructor.com/concepts/typeddicts/index.md

# Source: https://python.useinstructor.com/concepts/typeadapter/index.md

# Source: https://python.useinstructor.com/concepts/templating/index.md

# Source: https://python.useinstructor.com/concepts/semantic_validation/index.md

# Source: https://python.useinstructor.com/concepts/retrying/index.md

# Source: https://python.useinstructor.com/concepts/reask_validation/index.md

# Source: https://python.useinstructor.com/concepts/raw_response/index.md

# Source: https://python.useinstructor.com/concepts/prompting/index.md

# Source: https://python.useinstructor.com/concepts/prompt_caching/index.md

# Source: https://python.useinstructor.com/concepts/philosophy/index.md

# Source: https://python.useinstructor.com/concepts/patching/index.md

# Source: https://python.useinstructor.com/concepts/partial/index.md

# Source: https://python.useinstructor.com/concepts/parallel/index.md

# Source: https://python.useinstructor.com/concepts/multimodal/index.md

# Source: https://python.useinstructor.com/concepts/models/index.md

# Source: https://python.useinstructor.com/concepts/migration/index.md

# Source: https://python.useinstructor.com/concepts/maybe/index.md

# Source: https://python.useinstructor.com/concepts/logging/index.md

# Source: https://python.useinstructor.com/concepts/lists/index.md

# Source: https://python.useinstructor.com/concepts/iterable/index.md

# Source: https://python.useinstructor.com/concepts/hooks/index.md

# Source: https://python.useinstructor.com/concepts/from_provider/index.md

# Source: https://python.useinstructor.com/concepts/fields/index.md

# Source: https://python.useinstructor.com/concepts/fastapi/index.md

# Source: https://python.useinstructor.com/concepts/error_handling/index.md

# Source: https://python.useinstructor.com/concepts/enums/index.md

# Source: https://python.useinstructor.com/concepts/distillation/index.md

# Source: https://python.useinstructor.com/concepts/dictionary_operations/index.md

# Source: https://python.useinstructor.com/concepts/caching/index.md

# Source: https://python.useinstructor.com/concepts/batch/index.md

# Source: https://python.useinstructor.com/concepts/alias/index.md

# Source: https://python.useinstructor.com/concepts/index.md

# Source: https://python.useinstructor.com/installation/index.md

# Source: https://python.useinstructor.com/getting-started/index.md

# Source: https://python.useinstructor.com/index.md

# Source: https://python.useinstructor.com/integrations/xai/index.md

# Source: https://python.useinstructor.com/integrations/writer/index.md

# Source: https://python.useinstructor.com/integrations/vertex/index.md

# Source: https://python.useinstructor.com/integrations/truefoundry/index.md

# Source: https://python.useinstructor.com/integrations/together/index.md

# Source: https://python.useinstructor.com/integrations/sambanova/index.md

# Source: https://python.useinstructor.com/integrations/perplexity/index.md

# Source: https://python.useinstructor.com/integrations/openrouter/index.md

# Source: https://python.useinstructor.com/integrations/openai/index.md

# Source: https://python.useinstructor.com/integrations/openai-responses/index.md

# Source: https://python.useinstructor.com/integrations/ollama/index.md

# Source: https://python.useinstructor.com/integrations/mistral/index.md

# Source: https://python.useinstructor.com/integrations/llama-cpp-python/index.md

# Source: https://python.useinstructor.com/integrations/litellm/index.md

# Source: https://python.useinstructor.com/integrations/groq/index.md

# Source: https://python.useinstructor.com/integrations/google/index.md

# Source: https://python.useinstructor.com/integrations/genai/index.md

# Source: https://python.useinstructor.com/integrations/fireworks/index.md

# Source: https://python.useinstructor.com/integrations/deepseek/index.md

# Source: https://python.useinstructor.com/integrations/databricks/index.md

# Source: https://python.useinstructor.com/integrations/cortex/index.md

# Source: https://python.useinstructor.com/integrations/cohere/index.md

# Source: https://python.useinstructor.com/integrations/cerebras/index.md

# Source: https://python.useinstructor.com/integrations/bedrock/index.md

# Source: https://python.useinstructor.com/integrations/azure/index.md

# Source: https://python.useinstructor.com/integrations/anyscale/index.md

# Source: https://python.useinstructor.com/integrations/anthropic/index.md

# Source: https://python.useinstructor.com/integrations/index.md

# Source: https://python.useinstructor.com/concepts/validation/index.md

# Source: https://python.useinstructor.com/concepts/usage/index.md

# Source: https://python.useinstructor.com/concepts/unions/index.md

# Source: https://python.useinstructor.com/concepts/union/index.md

# Source: https://python.useinstructor.com/concepts/types/index.md

# Source: https://python.useinstructor.com/concepts/typeddicts/index.md

# Source: https://python.useinstructor.com/concepts/typeadapter/index.md

# Source: https://python.useinstructor.com/concepts/templating/index.md

# Source: https://python.useinstructor.com/concepts/semantic_validation/index.md

# Source: https://python.useinstructor.com/concepts/retrying/index.md

# Source: https://python.useinstructor.com/concepts/reask_validation/index.md

# Source: https://python.useinstructor.com/concepts/raw_response/index.md

# Source: https://python.useinstructor.com/concepts/prompting/index.md

# Source: https://python.useinstructor.com/concepts/prompt_caching/index.md

# Source: https://python.useinstructor.com/concepts/philosophy/index.md

# Source: https://python.useinstructor.com/concepts/patching/index.md

# Source: https://python.useinstructor.com/concepts/partial/index.md

# Source: https://python.useinstructor.com/concepts/parallel/index.md

# Source: https://python.useinstructor.com/concepts/multimodal/index.md

# Source: https://python.useinstructor.com/concepts/models/index.md

# Source: https://python.useinstructor.com/concepts/migration/index.md

# Source: https://python.useinstructor.com/concepts/maybe/index.md

# Source: https://python.useinstructor.com/concepts/logging/index.md

# Source: https://python.useinstructor.com/concepts/lists/index.md

# Source: https://python.useinstructor.com/concepts/iterable/index.md

# Source: https://python.useinstructor.com/concepts/hooks/index.md

# Source: https://python.useinstructor.com/concepts/from_provider/index.md

# Source: https://python.useinstructor.com/concepts/fields/index.md

# Source: https://python.useinstructor.com/concepts/fastapi/index.md

# Source: https://python.useinstructor.com/concepts/error_handling/index.md

# Source: https://python.useinstructor.com/concepts/enums/index.md

# Source: https://python.useinstructor.com/concepts/distillation/index.md

# Source: https://python.useinstructor.com/concepts/dictionary_operations/index.md

# Source: https://python.useinstructor.com/concepts/caching/index.md

# Source: https://python.useinstructor.com/concepts/batch/index.md

# Source: https://python.useinstructor.com/concepts/alias/index.md

# Source: https://python.useinstructor.com/concepts/index.md

# Source: https://python.useinstructor.com/installation/index.md

# Source: https://python.useinstructor.com/getting-started/index.md

# Source: https://python.useinstructor.com/index.md

# Source: https://python.useinstructor.com/integrations/xai/index.md

# Source: https://python.useinstructor.com/integrations/writer/index.md

# Source: https://python.useinstructor.com/integrations/vertex/index.md

# Source: https://python.useinstructor.com/integrations/truefoundry/index.md

# Source: https://python.useinstructor.com/integrations/together/index.md

# Source: https://python.useinstructor.com/integrations/sambanova/index.md

# Source: https://python.useinstructor.com/integrations/perplexity/index.md

# Source: https://python.useinstructor.com/integrations/openrouter/index.md

# Source: https://python.useinstructor.com/integrations/openai/index.md

# Source: https://python.useinstructor.com/integrations/openai-responses/index.md

# Source: https://python.useinstructor.com/integrations/ollama/index.md

# Source: https://python.useinstructor.com/integrations/mistral/index.md

# Source: https://python.useinstructor.com/integrations/llama-cpp-python/index.md

# Source: https://python.useinstructor.com/integrations/litellm/index.md

# Source: https://python.useinstructor.com/integrations/groq/index.md

# Source: https://python.useinstructor.com/integrations/google/index.md

# Source: https://python.useinstructor.com/integrations/genai/index.md

# Source: https://python.useinstructor.com/integrations/fireworks/index.md

# Source: https://python.useinstructor.com/integrations/deepseek/index.md

# Source: https://python.useinstructor.com/integrations/databricks/index.md

# Source: https://python.useinstructor.com/integrations/cortex/index.md

# Source: https://python.useinstructor.com/integrations/cohere/index.md

# Source: https://python.useinstructor.com/integrations/cerebras/index.md

# Source: https://python.useinstructor.com/integrations/bedrock/index.md

# Source: https://python.useinstructor.com/integrations/azure/index.md

# Source: https://python.useinstructor.com/integrations/anyscale/index.md

# Source: https://python.useinstructor.com/integrations/anthropic/index.md

# Source: https://python.useinstructor.com/integrations/index.md

# Source: https://python.useinstructor.com/concepts/validation/index.md

# Source: https://python.useinstructor.com/concepts/usage/index.md

# Source: https://python.useinstructor.com/concepts/unions/index.md

# Source: https://python.useinstructor.com/concepts/union/index.md

# Source: https://python.useinstructor.com/concepts/types/index.md

# Source: https://python.useinstructor.com/concepts/typeddicts/index.md

# Source: https://python.useinstructor.com/concepts/typeadapter/index.md

# Source: https://python.useinstructor.com/concepts/templating/index.md

# Source: https://python.useinstructor.com/concepts/semantic_validation/index.md

# Source: https://python.useinstructor.com/concepts/retrying/index.md

# Source: https://python.useinstructor.com/concepts/reask_validation/index.md

# Source: https://python.useinstructor.com/concepts/raw_response/index.md

# Source: https://python.useinstructor.com/concepts/prompting/index.md

# Source: https://python.useinstructor.com/concepts/prompt_caching/index.md

# Source: https://python.useinstructor.com/concepts/philosophy/index.md

# Source: https://python.useinstructor.com/concepts/patching/index.md

# Source: https://python.useinstructor.com/concepts/partial/index.md

# Source: https://python.useinstructor.com/concepts/parallel/index.md

# Source: https://python.useinstructor.com/concepts/multimodal/index.md

# Source: https://python.useinstructor.com/concepts/models/index.md

# Source: https://python.useinstructor.com/concepts/migration/index.md

# Source: https://python.useinstructor.com/concepts/maybe/index.md

# Source: https://python.useinstructor.com/concepts/logging/index.md

# Source: https://python.useinstructor.com/concepts/lists/index.md

# Source: https://python.useinstructor.com/concepts/iterable/index.md

# Source: https://python.useinstructor.com/concepts/hooks/index.md

# Source: https://python.useinstructor.com/concepts/from_provider/index.md

# Source: https://python.useinstructor.com/concepts/fields/index.md

# Source: https://python.useinstructor.com/concepts/fastapi/index.md

# Source: https://python.useinstructor.com/concepts/error_handling/index.md

# Source: https://python.useinstructor.com/concepts/enums/index.md

# Source: https://python.useinstructor.com/concepts/distillation/index.md

# Source: https://python.useinstructor.com/concepts/dictionary_operations/index.md

# Source: https://python.useinstructor.com/concepts/caching/index.md

# Source: https://python.useinstructor.com/concepts/batch/index.md

# Source: https://python.useinstructor.com/concepts/alias/index.md

# Source: https://python.useinstructor.com/concepts/index.md

# Source: https://python.useinstructor.com/installation/index.md

# Source: https://python.useinstructor.com/getting-started/index.md

# Source: https://python.useinstructor.com/index.md

# Source: https://python.useinstructor.com/integrations/xai/index.md

# Source: https://python.useinstructor.com/integrations/writer/index.md

# Source: https://python.useinstructor.com/integrations/vertex/index.md

# Source: https://python.useinstructor.com/integrations/truefoundry/index.md

# Source: https://python.useinstructor.com/integrations/together/index.md

# Source: https://python.useinstructor.com/integrations/sambanova/index.md

# Source: https://python.useinstructor.com/integrations/perplexity/index.md

# Source: https://python.useinstructor.com/integrations/openrouter/index.md

# Source: https://python.useinstructor.com/integrations/openai/index.md

# Source: https://python.useinstructor.com/integrations/openai-responses/index.md

# Source: https://python.useinstructor.com/integrations/ollama/index.md

# Source: https://python.useinstructor.com/integrations/mistral/index.md

# Source: https://python.useinstructor.com/integrations/llama-cpp-python/index.md

# Source: https://python.useinstructor.com/integrations/litellm/index.md

# Source: https://python.useinstructor.com/integrations/groq/index.md

# Source: https://python.useinstructor.com/integrations/google/index.md

# Source: https://python.useinstructor.com/integrations/genai/index.md

# Source: https://python.useinstructor.com/integrations/fireworks/index.md

# Source: https://python.useinstructor.com/integrations/deepseek/index.md

# Source: https://python.useinstructor.com/integrations/databricks/index.md

# Source: https://python.useinstructor.com/integrations/cortex/index.md

# Source: https://python.useinstructor.com/integrations/cohere/index.md

# Source: https://python.useinstructor.com/integrations/cerebras/index.md

# Source: https://python.useinstructor.com/integrations/bedrock/index.md

# Source: https://python.useinstructor.com/integrations/azure/index.md

# Source: https://python.useinstructor.com/integrations/anyscale/index.md

# Source: https://python.useinstructor.com/integrations/anthropic/index.md

# Source: https://python.useinstructor.com/integrations/index.md

# Source: https://python.useinstructor.com/concepts/validation/index.md

# Source: https://python.useinstructor.com/concepts/usage/index.md

# Source: https://python.useinstructor.com/concepts/unions/index.md

# Source: https://python.useinstructor.com/concepts/union/index.md

# Source: https://python.useinstructor.com/concepts/types/index.md

# Source: https://python.useinstructor.com/concepts/typeddicts/index.md

# Source: https://python.useinstructor.com/concepts/typeadapter/index.md

# Source: https://python.useinstructor.com/concepts/templating/index.md

# Source: https://python.useinstructor.com/concepts/semantic_validation/index.md

# Source: https://python.useinstructor.com/concepts/retrying/index.md

# Source: https://python.useinstructor.com/concepts/reask_validation/index.md

# Source: https://python.useinstructor.com/concepts/raw_response/index.md

# Source: https://python.useinstructor.com/concepts/prompting/index.md

# Source: https://python.useinstructor.com/concepts/prompt_caching/index.md

# Source: https://python.useinstructor.com/concepts/philosophy/index.md

# Source: https://python.useinstructor.com/concepts/patching/index.md

# Source: https://python.useinstructor.com/concepts/partial/index.md

# Source: https://python.useinstructor.com/concepts/parallel/index.md

# Source: https://python.useinstructor.com/concepts/multimodal/index.md

# Source: https://python.useinstructor.com/concepts/models/index.md

# Source: https://python.useinstructor.com/concepts/migration/index.md

# Source: https://python.useinstructor.com/concepts/maybe/index.md

# Source: https://python.useinstructor.com/concepts/logging/index.md

# Source: https://python.useinstructor.com/concepts/lists/index.md

# Source: https://python.useinstructor.com/concepts/iterable/index.md

# Source: https://python.useinstructor.com/concepts/hooks/index.md

# Source: https://python.useinstructor.com/concepts/from_provider/index.md

# Source: https://python.useinstructor.com/concepts/fields/index.md

# Source: https://python.useinstructor.com/concepts/fastapi/index.md

# Source: https://python.useinstructor.com/concepts/error_handling/index.md

# Source: https://python.useinstructor.com/concepts/enums/index.md

# Source: https://python.useinstructor.com/concepts/distillation/index.md

# Source: https://python.useinstructor.com/concepts/dictionary_operations/index.md

# Source: https://python.useinstructor.com/concepts/caching/index.md

# Source: https://python.useinstructor.com/concepts/batch/index.md

# Source: https://python.useinstructor.com/concepts/alias/index.md

# Source: https://python.useinstructor.com/concepts/index.md

# Source: https://python.useinstructor.com/installation/index.md

# Source: https://python.useinstructor.com/getting-started/index.md

# Source: https://python.useinstructor.com/index.md

# Source: https://python.useinstructor.com/integrations/xai/index.md

# Source: https://python.useinstructor.com/integrations/writer/index.md

# Source: https://python.useinstructor.com/integrations/vertex/index.md

# Source: https://python.useinstructor.com/integrations/truefoundry/index.md

# Source: https://python.useinstructor.com/integrations/together/index.md

# Source: https://python.useinstructor.com/integrations/sambanova/index.md

# Source: https://python.useinstructor.com/integrations/perplexity/index.md

# Source: https://python.useinstructor.com/integrations/openrouter/index.md

# Source: https://python.useinstructor.com/integrations/openai/index.md

# Source: https://python.useinstructor.com/integrations/openai-responses/index.md

# Source: https://python.useinstructor.com/integrations/ollama/index.md

# Source: https://python.useinstructor.com/integrations/mistral/index.md

# Source: https://python.useinstructor.com/integrations/llama-cpp-python/index.md

# Source: https://python.useinstructor.com/integrations/litellm/index.md

# Source: https://python.useinstructor.com/integrations/groq/index.md

# Source: https://python.useinstructor.com/integrations/google/index.md

# Source: https://python.useinstructor.com/integrations/genai/index.md

# Source: https://python.useinstructor.com/integrations/fireworks/index.md

# Source: https://python.useinstructor.com/integrations/deepseek/index.md

# Source: https://python.useinstructor.com/integrations/databricks/index.md

# Source: https://python.useinstructor.com/integrations/cortex/index.md

# Source: https://python.useinstructor.com/integrations/cohere/index.md

# Source: https://python.useinstructor.com/integrations/cerebras/index.md

# Source: https://python.useinstructor.com/integrations/bedrock/index.md

# Source: https://python.useinstructor.com/integrations/azure/index.md

# Source: https://python.useinstructor.com/integrations/anyscale/index.md

# Source: https://python.useinstructor.com/integrations/anthropic/index.md

# Source: https://python.useinstructor.com/integrations/index.md

# Source: https://python.useinstructor.com/concepts/validation/index.md

# Source: https://python.useinstructor.com/concepts/usage/index.md

# Source: https://python.useinstructor.com/concepts/unions/index.md

# Source: https://python.useinstructor.com/concepts/union/index.md

# Source: https://python.useinstructor.com/concepts/types/index.md

# Source: https://python.useinstructor.com/concepts/typeddicts/index.md

# Source: https://python.useinstructor.com/concepts/typeadapter/index.md

# Source: https://python.useinstructor.com/concepts/templating/index.md

# Source: https://python.useinstructor.com/concepts/semantic_validation/index.md

# Source: https://python.useinstructor.com/concepts/retrying/index.md

# Source: https://python.useinstructor.com/concepts/reask_validation/index.md

# Source: https://python.useinstructor.com/concepts/raw_response/index.md

# Source: https://python.useinstructor.com/concepts/prompting/index.md

# Source: https://python.useinstructor.com/concepts/prompt_caching/index.md

# Source: https://python.useinstructor.com/concepts/philosophy/index.md

# Source: https://python.useinstructor.com/concepts/patching/index.md

# Source: https://python.useinstructor.com/concepts/partial/index.md

# Source: https://python.useinstructor.com/concepts/parallel/index.md

# Source: https://python.useinstructor.com/concepts/multimodal/index.md

# Source: https://python.useinstructor.com/concepts/models/index.md

# Source: https://python.useinstructor.com/concepts/maybe/index.md

# Source: https://python.useinstructor.com/concepts/logging/index.md

# Source: https://python.useinstructor.com/concepts/lists/index.md

# Source: https://python.useinstructor.com/concepts/iterable/index.md

# Source: https://python.useinstructor.com/concepts/hooks/index.md

# Source: https://python.useinstructor.com/concepts/fields/index.md

# Source: https://python.useinstructor.com/concepts/fastapi/index.md

# Source: https://python.useinstructor.com/concepts/error_handling/index.md

# Source: https://python.useinstructor.com/concepts/enums/index.md

# Source: https://python.useinstructor.com/concepts/distillation/index.md

# Source: https://python.useinstructor.com/concepts/dictionary_operations/index.md

# Source: https://python.useinstructor.com/concepts/caching/index.md

# Source: https://python.useinstructor.com/concepts/batch/index.md

# Source: https://python.useinstructor.com/concepts/alias/index.md

# Source: https://python.useinstructor.com/concepts/index.md

# Source: https://python.useinstructor.com/installation/index.md

# Source: https://python.useinstructor.com/getting-started/index.md

# Source: https://python.useinstructor.com/index.md

# Instructor: Top Multi-Language Library for Structured LLM Outputs

*Extract structured data from any LLM with type safety, validation, and automatic retries. Available in Python, TypeScript, Go, Ruby, Elixir, and Rust.*

## What is Instructor?

Instructor is the **most popular Python library** for extracting structured data from Large Language Models (LLMs). With over **3 million monthly downloads, 11k stars, and 100+ contributors**, it's the go-to solution for developers who need reliable, validated outputs from AI models.

Built on top of **Pydantic**, Instructor provides type-safe data extraction with automatic validation, retries, and streaming support. Whether you're using OpenAI's GPT models, Anthropic's Claude, Google's Gemini, **open source models with Ollama**, **DeepSeek**, or any of 15+ supported providers, Instructor ensures your LLM outputs are always structured and validated.

## Key Features for LLM Data Extraction

- **Structured Outputs**: Define Pydantic models to specify exactly what data you want from your LLM
- **Automatic Retries**: Built-in retry logic when validation fails - no more manual error handling
- **Data Validation**: Leverage Pydantic's powerful validation to ensure response quality
- **Streaming Support**: Real-time processing of partial responses and lists
- **Multi-Provider**: Works with OpenAI, Anthropic, Google, Mistral, Cohere, Ollama, DeepSeek, and 15+ LLM providers
- **Type Safety**: Full IDE support with proper type inference and autocompletion
- **Open Source Support**: Run any open source model locally with Ollama, llama-cpp-python, or vLLM

## Quick Start: Extract Structured Data in 3 Lines

Install Instructor and start extracting structured data immediately:

```bash
pip install instructor
```

```bash
uv add instructor
```

```bash
poetry add instructor
```

```python
import instructor
from pydantic import BaseModel
from openai import OpenAI


class Person(BaseModel):
    name: str
    age: int
    occupation: str


client = instructor.from_openai(OpenAI())
person = client.chat.completions.create(
    model="gpt-4o-mini",
    response_model=Person,
    messages=[
        {"role": "user", "content": "Extract: John is a 30-year-old software engineer"}
    ],
)
print(person)  # Person(name='John', age=30, occupation='software engineer')
```

## Universal Provider API - One Interface for All LLMs

Instructor's **`from_provider`** function provides a unified interface to work with any LLM provider. Switch between OpenAI, Anthropic, Google, Ollama, DeepSeek, and 15+ providers with the same code:

```python
import instructor
from pydantic import BaseModel


class UserInfo(BaseModel):
    name: str
    age: int


# Works with any provider - same interface everywhere
client = instructor.from_provider("openai/gpt-4")  # OpenAI
client = instructor.from_provider("anthropic/claude-3")  # Anthropic
client = instructor.from_provider("google/gemini-pro")  # Google
client = instructor.from_provider("ollama/llama3")  # Ollama (local)
client = instructor.from_provider("deepseek/deepseek-chat")  # DeepSeek

# Pass API keys directly (no environment variables needed)
client = instructor.from_provider("openai/gpt-4", api_key="sk-...")
client = instructor.from_provider("anthropic/claude-3", api_key="sk-ant-...")
client = instructor.from_provider("groq/llama-3.1-8b-instant", api_key="gsk_...")

# Same extraction code works with all providers
user = client.chat.completions.create(
    response_model=UserInfo,
    messages=[{"role": "user", "content": "John Doe is 30 years old."}],
)
```

The **`from_provider`** API supports both sync and async usage (`async_client=True`) and automatically handles provider-specific configurations, making it effortless to switch between different LLM services.

## Complex Schemas & Validation

Instructor excels at extracting complex, nested data structures with custom validation rules. Here's a real-world example:

```python
import instructor
from pydantic import BaseModel, Field, field_validator
from typing import List, Optional
from datetime import datetime
from enum import Enum

class Priority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class Address(BaseModel):
    street: str
    city: str
    country: str
    postal_code: str = Field(..., pattern=r'^\d{5}(-\d{4})?$')

class Contact(BaseModel):
    email: str = Field(..., pattern=r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
    phone: Optional[str] = Field(None, pattern=r'^\+?1?-?\.?\s?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}$')

class Ticket(BaseModel):
    id: str
    title: str = Field(..., min_length=5, max_length=100)
    description: str = Field(..., min_length=10)
    priority: Priority
    assignee: Optional[str] = None
    tags: List[str] = Field(default_factory=list, max_items=5)
    estimated_hours: Optional[float] = Field(None, gt=0, le=100)

    @field_validator('estimated_hours')
    @classmethod
    def validate_hours(cls, v):
        if v is not None and v % 0.5 != 0:
            raise ValueError('Hours must be in 0.5 increments')
        return v

class CustomerSupport(BaseModel):
    customer_name: str
    customer_contact: Contact
    customer_address: Address
    tickets: List[Ticket] = Field(..., min_items=1)
    total_estimated_time: float = Field(..., gt=0)

    @field_validator('total_estimated_time')
    @classmethod
    def validate_total_time(cls, v, info):
        if 'tickets' in info.data:
            ticket_time = sum(t.estimated_hours or 0 for t in info.data['tickets'])
            if abs(v - ticket_time) > 0.1:  # Allow small floating point differences
                raise ValueError(f'Total time {v} must match sum of ticket times {ticket_time}')
        return v

# Extract complex support case from natural language
client = instructor.from_provider("openai/gpt-4o")

support_case = client.chat.completions.create(
    response_model=CustomerSupport,
    messages=[{
        "role": "user", 
        "content": """
        Support case for Sarah Johnson (sarah.johnson@techcorp.com, +1-555-123-4567).
        Address: 123 Tech Street, San Francisco, CA 94105.

        Two tickets:
        1. "Login system completely broken" - CRITICAL priority, needs 4.5 hours, tags: authentication, security
        2. "Email notifications not working" - MEDIUM priority, needs 2 hours, tags: email, notifications

        Total estimated time: 6.5 hours
        """
    }],
    max_retries=3
)

print(f"Customer: {support_case.customer_name}")
print(f"Total tickets: {len(support_case.tickets)}")
print(f"Critical tickets: {len([t for t in support_case.tickets if t.priority == Priority.CRITICAL])}")
```

**Key Features Demonstrated:**

- **Deep nesting**: `CustomerSupport` â `Contact`/`Address`/`List[Ticket]`
- **Custom validation**: Email patterns, phone formats, business rules
- **Enums and constraints**: Priority levels, field length limits
- **Cross-field validation**: Total time must match ticket sum
- **Automatic retries**: Failed validation triggers re-extraction

## Supported LLM Providers

Instructor works seamlessly with **15+ popular LLM providers**, giving you the flexibility to use any model while maintaining consistent structured output handling. From OpenAI's GPT models to **open source alternatives with Ollama**, **DeepSeek models**, and local inference, get validated data extraction everywhere.

It stands out for its simplicity, transparency, and user-centric design, built on top of Pydantic. Instructor helps you manage [validation context](concepts/reask_validation/), retries with [Tenacity](concepts/retrying/), and streaming [Lists](concepts/lists/) and [Partial](concepts/partial/) responses.

[Star the Repo](https://github.com/jxnl/instructor) [Cookbooks](examples/) [Prompting Guide](prompting/)

If you ever get stuck, you can always run `instructor docs` to open the documentation in your browser. It even supports searching for specific topics.

```bash
instructor docs [QUERY]
```

### OpenAI GPT Models - Structured Outputs

Get structured data from OpenAI's most powerful models including GPT-4, GPT-4 Turbo, and GPT-3.5.

```bash
pip install instructor
```

Using OpenAI's Structured Output Response

You can now use OpenAI's structured output response with Instructor. This feature combines the strengths of Instructor with OpenAI's precise sampling.

```python
client = instructor.from_openai(OpenAI(), mode=Mode.TOOLS_STRICT)
```

```python
import instructor
from pydantic import BaseModel
from openai import OpenAI


# Define your desired output structure
class ExtractUser(BaseModel):
    name: str
    age: int


# Patch the OpenAI client
client = instructor.from_openai(OpenAI())

# Extract structured data from natural language
res = client.chat.completions.create(
    model="gpt-4o-mini",
    response_model=ExtractUser,
    messages=[{"role": "user", "content": "John Doe is 30 years old."}],
)

assert res.name == "John Doe"
assert res.age == 30
```

[See more](integrations/openai/)

```bash
pip install "instructor[ollama]"
```

```python
from openai import OpenAI
from pydantic import BaseModel
import instructor


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_openai(
    OpenAI(
        base_url="http://localhost:11434/v1",
        api_key="ollama",
    ),
    mode=instructor.Mode.JSON,
)

resp = client.chat.completions.create(
    model="llama3",
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
    response_model=ExtractUser,
)
assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/ollama/)

```bash
pip install "instructor[llama-cpp-python]"
```

```python
import llama_cpp
import instructor
from llama_cpp.llama_speculative import LlamaPromptLookupDecoding
from pydantic import BaseModel

llama = llama_cpp.Llama(
    model_path="../../models/OpenHermes-2.5-Mistral-7B-GGUF/openhermes-2.5-mistral-7b.Q4_K_M.gguf",
    n_gpu_layers=-1,
    chat_format="chatml",
    n_ctx=2048,
    draft_model=LlamaPromptLookupDecoding(num_pred_tokens=2),
    logits_all=True,
    verbose=False,
)

create = instructor.patch(
    create=llama.create_chat_completion_openai_v1,
    mode=instructor.Mode.JSON_SCHEMA,
)


class ExtractUser(BaseModel):
    name: str
    age: int


user = create(
    messages=[
        {
            "role": "user",
            "content": "Extract `Jason is 30 years old`",
        }
    ],
    response_model=ExtractUser,
)

assert user.name == "Jason"
assert user.age == 30
```

[See more](integrations/llama-cpp-python/)

```bash
pip install "instructor[anthropic]"
```

```python
import instructor
from anthropic import Anthropic
from pydantic import BaseModel


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_anthropic(Anthropic())

# note that client.chat.completions.create will also work
resp = client.messages.create(
    model="claude-3-5-sonnet-20240620",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
    response_model=ExtractUser,
)

assert isinstance(resp, ExtractUser)
assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/anthropic/)

```bash
pip install "instructor[google-generativeai]"
```

```python
import instructor
import google.generativeai as genai
from pydantic import BaseModel


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_gemini(
    client=genai.GenerativeModel(
        model_name="models/gemini-1.5-flash-latest",
    ),
    mode=instructor.Mode.GEMINI_JSON,
)

# note that client.chat.completions.create will also work
resp = client.messages.create(
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
    response_model=ExtractUser,
)

assert isinstance(resp, ExtractUser)
assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/google/)

```bash
pip install "instructor[vertexai]"
```

```python
import instructor
import vertexai  # type: ignore
from vertexai.generative_models import GenerativeModel  # type: ignore
from pydantic import BaseModel

vertexai.init()


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_vertexai(
    client=GenerativeModel("gemini-1.5-pro-preview-0409"),
    mode=instructor.Mode.VERTEXAI_TOOLS,
)

# note that client.chat.completions.create will also work
resp = client.create(
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
    response_model=ExtractUser,
)

assert isinstance(resp, ExtractUser)
assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/vertex/)

```bash
pip install "instructor[groq]"
```

```python
import instructor
from groq import Groq
from pydantic import BaseModel

client = instructor.from_groq(Groq())


class ExtractUser(BaseModel):
    name: str
    age: int


resp = client.chat.completions.create(
    model="llama3-70b-8192",
    response_model=ExtractUser,
    messages=[{"role": "user", "content": "Extract Jason is 25 years old."}],
)

assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/groq/)

```bash
pip install "instructor[litellm]"
```

```python
import instructor
from litellm import completion
from pydantic import BaseModel


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_litellm(completion)

resp = client.chat.completions.create(
    model="claude-3-opus-20240229",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
    response_model=ExtractUser,
)

assert isinstance(resp, ExtractUser)
assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/litellm/)

```bash
pip install "instructor[cohere]"
```

```python
import instructor
from pydantic import BaseModel
from cohere import Client


class ExtractUser(BaseModel):
    name: str
    age: int


client = instructor.from_cohere(Client())

resp = client.chat.completions.create(
    response_model=ExtractUser,
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
)

assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/cohere/)

```bash
pip install "instructor[cerebras]"
```

```python
from cerebras.cloud.sdk import Cerebras
import instructor
from pydantic import BaseModel
import os

client = Cerebras(
    api_key=os.environ.get("CEREBRAS_API_KEY"),
)
client = instructor.from_cerebras(client)


class ExtractUser(BaseModel):
    name: str
    age: int


resp = client.chat.completions.create(
    model="llama3.1-70b",
    response_model=ExtractUser,
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
)

assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/cerebras/)

```bash
pip install "instructor[fireworks]"
```

```python
from fireworks.client import Fireworks
import instructor
from pydantic import BaseModel
import os

client = Fireworks(
    api_key=os.environ.get("FIREWORKS_API_KEY"),
)
client = instructor.from_fireworks(client)


class ExtractUser(BaseModel):
    name: str
    age: int


resp = client.chat.completions.create(
    model="accounts/fireworks/models/llama-v3p2-1b-instruct",
    response_model=ExtractUser,
    messages=[
        {
            "role": "user",
            "content": "Extract Jason is 25 years old.",
        }
    ],
)

assert resp.name == "Jason"
assert resp.age == 25
```

[See more](integrations/fireworks/)

## Citation

If you use Instructor in your research or project, please cite it using:

```bibtex
@software{liu2024instructor,
  author = {Jason Liu and Contributors},
  title = {Instructor: A library for structured outputs from large language models},
  url = {https://github.com/instructor-ai/instructor},
  year = {2024},
  month = {3}
}
```

## Why use Instructor?

- **Simple API with Full Prompt Control**

  Instructor provides a straightforward API that gives you complete ownership and control over your prompts. This allows for fine-tuned customization and optimization of your LLM interactions.

  [Explore Concepts](concepts/models/)

- **Multi-Language Support**

  Simplify structured data extraction from LLMs with type hints and validation.

  [Python](https://python.useinstructor.com) Â· [TypeScript](https://js.useinstructor.com) Â· [Ruby](https://ruby.useinstructor.com) Â· [Go](https://go.useinstructor.com) Â· [Elixir](https://hex.pm/packages/instructor) Â· [Rust](https://rust.useinstructor.com)

- **Reasking and Validation**

  Automatically reask the model when validation fails, ensuring high-quality outputs. Leverage Pydantic's validation for robust error handling.

  [Learn about Reasking](concepts/reask_validation/)

- **Streaming Support**

  Stream partial results and iterables with ease, allowing for real-time processing and improved responsiveness in your applications.

  [Learn about Streaming](concepts/partial/)

- **Powered by Type Hints**

  Leverage Pydantic for schema validation, prompting control, less code, and IDE integration.

  [Learn more](https://docs.pydantic.dev/)

- **Simplified LLM Interactions**

  Support for [OpenAI](integrations/openai/), [Anthropic](integrations/anthropic/), [Google](integrations/google/), [Vertex AI](integrations/vertex/), [Mistral/Mixtral](integrations/together/), [Ollama](integrations/ollama/), [llama-cpp-python](integrations/llama-cpp-python/), [Cohere](integrations/cohere/), [LiteLLM](integrations/litellm/).

  [See Hub](integrations/)

### Using Hooks

Instructor includes a hooks system that lets you manage events during the language model interaction process. Hooks allow you to intercept, log, and handle events at different stages, such as when completion arguments are provided or when a response is received. This system is based on the `Hooks` class, which handles event registration and emission. You can use hooks to add custom behavior like logging or error handling. Here's a simple example demonstrating how to use hooks:

```python
import instructor
from openai import OpenAI
from pydantic import BaseModel


class UserInfo(BaseModel):
    name: str
    age: int


# Initialize the OpenAI client with Instructor
client = instructor.from_openai(OpenAI())


# Define hook functions
def log_kwargs(**kwargs):
    print(f"Function called with kwargs: {kwargs}")


def log_exception(exception: Exception):
    print(f"An exception occurred: {str(exception)}")


client.on("completion:kwargs", log_kwargs)
client.on("completion:error", log_exception)

user_info = client.chat.completions.create(
    model="gpt-4o-mini",
    response_model=UserInfo,
    messages=[
        {"role": "user", "content": "Extract the user name: 'John is 20 years old'"}
    ],
)

"""
{
        'args': (),
        'kwargs': {
            'messages': [
                {
                    'role': 'user',
                    'content': "Extract the user name: 'John is 20 years old'",
                }
            ],
            'model': 'gpt-3.5-turbo',
            'tools': [
                {
                    'type': 'function',
                    'function': {
                        'name': 'UserInfo',
                        'description': 'Correctly extracted `UserInfo` with all the required parameters with correct types',
                        'parameters': {
                            'properties': {
                                'name': {'title': 'Name', 'type': 'string'},
                                'age': {'title': 'Age', 'type': 'integer'},
                            },
                            'required': ['age', 'name'],
                            'type': 'object',
                        },
                    },
                }
            ],
            'tool_choice': {'type': 'function', 'function': {'name': 'UserInfo'}},
        },
    }
"""

print(f"Name: {user_info.name}, Age: {user_info.age}")
#> Name: John, Age: 20
```

This example demonstrates:

1. A pre-execution hook that logs all kwargs passed to the function.
1. An exception hook that logs any exceptions that occur during execution.

The hooks provide valuable insights into the function's inputs and any errors, enhancing debugging and monitoring capabilities.

[Learn more about hooks :octicons-arrow-right:](concepts/hooks/)

## Correct Type Inference

This was the dream of instructor but due to the patching of openai, it wasnt possible for me to get typing to work well. Now, with the new client, we can get typing to work well! We've also added a few `create_*` methods to make it easier to create iterables and partials, and to access the original completion.

### Calling `create`

```python
import openai
import instructor
from pydantic import BaseModel


class User(BaseModel):
    name: str
    age: int


client = instructor.from_openai(openai.OpenAI())

user = client.chat.completions.create(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "user", "content": "Create a user"},
    ],
    response_model=User,
)
```

Now if you use a IDE, you can see the type is correctly infered.

### Handling async: `await create`

This will also work correctly with asynchronous clients.

```python
import openai
import instructor
from pydantic import BaseModel


client = instructor.from_openai(openai.AsyncOpenAI())


class User(BaseModel):
    name: str
    age: int


async def extract():
    return await client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=[
            {"role": "user", "content": "Create a user"},
        ],
        response_model=User,
    )
```

Notice that simply because we return the `create` method, the `extract()` function will return the correct user type.

### Returning the original completion: `create_with_completion`

You can also return the original completion object

```python
import openai
import instructor
from pydantic import BaseModel


client = instructor.from_openai(openai.OpenAI())


class User(BaseModel):
    name: str
    age: int


user, completion = client.chat.completions.create_with_completion(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "user", "content": "Create a user"},
    ],
    response_model=User,
)
```

### Streaming Partial Objects: `create_partial`

In order to handle streams, we still support `Iterable[T]` and `Partial[T]` but to simply the type inference, we've added `create_iterable` and `create_partial` methods as well!

```python
import openai
import instructor
from pydantic import BaseModel


client = instructor.from_openai(openai.OpenAI())


class User(BaseModel):
    name: str
    age: int


user_stream = client.chat.completions.create_partial(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "user", "content": "Create a user"},
    ],
    response_model=User,
)

for user in user_stream:
    print(user)
    #> name=None age=None
    #> name=None age=None
    #> name=None age=None
    #> name=None age=None
    #> name=None age=25
    #> name=None age=25
    #> name=None age=25
    #> name=None age=25
    #> name=None age=25
    #> name=None age=25
    #> name='John Doe' age=25
    # name=None age=None
    # name='' age=None
    # name='John' age=None
    # name='John Doe' age=None
    # name='John Doe' age=30
```

Notice now that the type infered is `Generator[User, None]`

### Streaming Iterables: `create_iterable`

We get an iterable of objects when we want to extract multiple objects.

```python
import openai
import instructor
from pydantic import BaseModel


client = instructor.from_openai(openai.OpenAI())


class User(BaseModel):
    name: str
    age: int


users = client.chat.completions.create_iterable(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "user", "content": "Create 2 users"},
    ],
    response_model=User,
)

for user in users:
    print(user)
    #> name='John Doe' age=30
    #> name='Jane Doe' age=28
    # User(name='John Doe', age=30)
    # User(name='Jane Smith', age=25)
```

## Templating

Instructor supports templating with Jinja, which lets you create dynamic prompts. This is useful when you want to fill in parts of a prompt with data. Here's a simple example:

```python
import openai
import instructor
from pydantic import BaseModel

client = instructor.from_openai(openai.OpenAI())


class User(BaseModel):
    name: str
    age: int


# Create a completion using a Jinja template in the message content
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role": "user",
            "content": """Extract the information from the
            following text: {{ data }}`""",
        },
    ],
    response_model=User,
    context={"data": "John Doe is thirty years old"},
)

print(response)
#> User(name='John Doe', age=30)
```

[Learn more about templating :octicons-arrow-right:](concepts/templating/)

## Validation

You can also use Pydantic to validate your outputs and get the llm to retry on failure. Check out our docs on [retrying](concepts/retrying/) and [validation context](concepts/reask_validation/).

```python
import instructor
from openai import OpenAI
from pydantic import BaseModel, ValidationError, BeforeValidator
from typing_extensions import Annotated
from instructor import llm_validator

# Apply the patch to the OpenAI client
client = instructor.from_openai(OpenAI())


class QuestionAnswer(BaseModel):
    question: str
    answer: Annotated[
        str,
        BeforeValidator(llm_validator("don't say objectionable things", client=client)),
    ]


try:
    qa = QuestionAnswer(
        question="What is the meaning of life?",
        answer="The meaning of life is to be evil and steal",
    )
except ValidationError as e:
    print(e)
    """
    1 validation error for QuestionAnswer
    answer
      Assertion failed, The statement promotes objectionable behavior by encouraging evil and stealing. [type=assertion_error, input_value='The meaning of life is to be evil and steal', input_type=str]
    """
```

## Contributing

If you want to help out, checkout some of the issues marked as `good-first-issue` or `help-wanted`. Found [here](https://github.com/jxnl/instructor/labels/good%20first%20issue). They could be anything from code improvements, a guest blog post, or a new cook book.

## License

This project is licensed under the terms of the MIT License.

## Frequently Asked Questions

### How do I get structured data from OpenAI GPT models?

Use Instructor with OpenAI to automatically extract structured data with Pydantic models. Simply define your data structure and let Instructor handle validation and retries.

### What LLM providers work with Instructor?

Instructor supports 15+ providers including OpenAI (GPT-4, ChatGPT), Anthropic (Claude), Google (Gemini), Mistral, Cohere, Groq, **Ollama for open source models**, **DeepSeek**, and many more.

### How does Instructor handle LLM validation errors?

Instructor automatically retries failed requests with detailed error messages, ensuring your structured outputs always match your Pydantic schema.

### Can I use Instructor with local LLM models?

Yes! Instructor works with local models through **Ollama**, llama-cpp-python, and other local inference frameworks. Perfect for running **open source models** like Llama, Mistral, or CodeLlama locally.

### Does Instructor support Ollama for open source models?

Absolutely! Instructor has first-class support for **Ollama**, making it easy to run open source models locally while getting the same structured output validation. Simply point Instructor to your Ollama endpoint.

### How do I use DeepSeek models with Instructor?

Instructor supports **DeepSeek** models through the OpenAI-compatible API. You can use DeepSeek's powerful reasoning capabilities while maintaining full validation and retry logic.

### Is Instructor compatible with async Python code?

Absolutely. Instructor fully supports asyncio with async clients for OpenAI, Anthropic, and other providers.

### Is Instructor limited to Python only?

**No!** This is a common misconception. Instructor is available in **6 programming languages**: Python, TypeScript, Go, Ruby, Elixir, and Rust. All implementations support the same core features including nested schemas, validation, and retries.

### Can Instructor handle complex nested schemas?

**Yes!** Instructor natively supports deeply nested, complex data structures out of the box. Simply define your nested Pydantic models (or equivalent in other languages) and Instructor handles the rest - no special configuration needed.

### How does Instructor compare to Guardrails AI?

**Instructor is easier to set up and faster for most use cases.** While Guardrails excels at complex business rule validation, Instructor provides better developer experience with native type support and simpler schema definition. Choose Instructor for type-safe extraction, Guardrails for complex validation rules.

### How does Instructor compare to LangChain output parsers?

**Instructor is purpose-built for structured extraction** while LangChain is a full application framework. Instructor is lighter, faster, and provides better type safety. Use Instructor when you need reliable structured data; use LangChain for complete LLM applications.

## Why Choose Instructor for LLM Structured Outputs?

- **ð Industry Standard**: Over 1M monthly downloads make it the most trusted Python library for LLM data extraction
- **â¡ Production Ready**: Built-in error handling, retries, and validation for reliable production deployments
- **ð§ Developer Friendly**: Full IDE support with type hints, autocompletion, and comprehensive documentation
- **ð Provider Agnostic**: Switch between LLM providers without changing your code structure
- **ð Scalable**: From simple scripts to enterprise applications, Instructor scales with your needs

## Related Topics

- [LLM Response Validation](concepts/reask_validation/) - Ensure quality outputs
- [Streaming LLM Outputs](concepts/partial/) - Real-time data processing
- [Multi-Provider Setup](integrations/) - Use any LLM service
- [Production Deployment](concepts/retrying/) - Error handling and retries
- [Type Safety with Pydantic](concepts/models/) - Schema validation
