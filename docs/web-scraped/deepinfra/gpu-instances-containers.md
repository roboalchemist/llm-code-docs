# Source: https://deepinfra.com/docs/gpu-instances/containers

We use essential cookies to make our site work. With your consent, we may also
use non-essential cookies to improve user experience and analyze website
traffic…

AcceptReject

[FLUX.2 is live!](https://deepinfra.com/models?q=flux-2) High-fidelity image
generation made simple.

[](/)

[Models](/models)

By Category

* * *

[Automatic Speech Recognition](/models/automatic-speech-
recognition)[Embeddings](/models/embeddings)[Reranker](/models/reranker)[Text
Generation](/models/text-generation)[Text To Image](/models/text-to-
image)[Text To Speech](/models/text-to-speech)[Text To Video](/models/text-to-
video)[Zero Shot Image Classification](/models/zero-shot-image-classification)

[View all models](/models)

By Family

* * *

[![anthropic
logo](/_next/static/media/anthropic.c6636fa8.svg)/Claude](/claude)[![deepseek-
ai
logo](/_next/static/media/deepseek.b1ec6c4e.svg)/DeepSeek](/deepseek)[![black-
forest-labs logo](/_next/static/media/bfl.7e050ff6.svg)/Flux](/flux)[![google
logo](/_next/static/media/google.09551b71.svg)/Gemini](/gemini)[![meta-llama
logo](/_next/static/media/meta.56a2e6fd.svg)/Llama](/llama)[![mistralai
logo](/_next/static/media/mistralai.ecbe51d4.svg)/Mistral](/mistral)[![nvidia
logo](/_next/static/media/nvidia.2165073d.svg)/Nemotron](/nemotron)[![qwen
logo](/_next/static/media/qwen.d6d74288.svg)/Qwen](/qwen)

[Docs](/docs)[Pricing](/pricing)[GPUs](/gpu-
instances)[Chat](/chat)[DeepStart](/deepstart)[Blog](/blog)

[Contact Sales](/contact-sales)[Log In](/login)

[Models](/models)

[Automatic Speech Recognition](/models/automatic-speech-
recognition)[Embeddings](/models/embeddings)[Reranker](/models/reranker)[Text
Generation](/models/text-generation)[Text To Image](/models/text-to-
image)[Text To Speech](/models/text-to-speech)[Text To Video](/models/text-to-
video)[Zero Shot Image Classification](/models/zero-shot-image-classification)

[Docs](/docs)

[Pricing](/pricing)

[GPUs](/gpu-instances)

[Chat](/chat)

[DeepStart](/deepstart)

[Blog](/blog)

Feedback

[Contact Sales](/contact-sales)

[Log In](/login)

  1. [Getting Started](/docs)

     1. [Quick Start Guide](/docs/getting-started)

     2. [Available Models](/docs/models)

     3. [Running Inference](/docs/inference)

     4. [Data Privacy & Security](/docs/data)

  2. [API Reference](/docs/api-reference)

     1. [OpenAI-Compatible API](/docs/openai_api)

     2. [DeepInfra Native API](/docs/deep_infra_api)

     3. [Rate Limits](/docs/advanced/rate-limits)

     4. [Webhooks](/docs/advanced/webhooks)

     5. [Authentication & Tokens](/docs/advanced/scoped_jwt)

  3. [Model Features](/docs/model-features)

     1. [Function Calling](/docs/advanced/function_calling)

     2. [JSON Mode](/docs/advanced/json_mode)

     3. [Multimodal Models](/docs/advanced/multimodal)

     4. [Log Probabilities](/docs/advanced/log_probs)

     5. [Max Output Tokens](/docs/advanced/max_tokens_limit)

  4. [GPU Instances](/docs/gpu-instances)

     1. Containers

  5. [Custom Deployments](/docs/custom-deployments)

     1. [Custom LLMs](/docs/advanced/custom_llms)

     2. [LoRA Adapter Models](/docs/advanced/lora)

     3. [LoRA Image Adapters](/docs/advanced/lora_text_to_image)

  6. [Integrations](/docs/integrations)

     1. [LangChain](/docs/advanced/langchain)

     2. [LlamaIndex](/docs/advanced/llama-index)

     3. [AI SDK](/docs/advanced/aisdk)

     4. [AutoGen](/docs/advanced/autogen)

     5. [Okta SSO](/docs/advanced/okta)

  7. [Tutorials & Examples](/docs/tutorials)

     1. [Stable Diffusion (Text to Image)](/docs/tutorials/stable-diffusion)

     2. [Whisper (Speech to Text)](/docs/tutorials/whisper)

     3. [Deprecated Models](/docs/advanced/deprecated)

  8. [Miscellaneous](/docs/misc)

     1. [Data Subprocessors](/docs/misc/subprocessors)

Documentation

  1. [Getting Started](/docs)

     1. [Quick Start Guide](/docs/getting-started)

     2. [Available Models](/docs/models)

     3. [Running Inference](/docs/inference)

     4. [Data Privacy & Security](/docs/data)

  2. [API Reference](/docs/api-reference)

     1. [OpenAI-Compatible API](/docs/openai_api)

     2. [DeepInfra Native API](/docs/deep_infra_api)

     3. [Rate Limits](/docs/advanced/rate-limits)

     4. [Webhooks](/docs/advanced/webhooks)

     5. [Authentication & Tokens](/docs/advanced/scoped_jwt)

  3. [Model Features](/docs/model-features)

     1. [Function Calling](/docs/advanced/function_calling)

     2. [JSON Mode](/docs/advanced/json_mode)

     3. [Multimodal Models](/docs/advanced/multimodal)

     4. [Log Probabilities](/docs/advanced/log_probs)

     5. [Max Output Tokens](/docs/advanced/max_tokens_limit)

  4. [GPU Instances](/docs/gpu-instances)

     1. Containers

  5. [Custom Deployments](/docs/custom-deployments)

     1. [Custom LLMs](/docs/advanced/custom_llms)

     2. [LoRA Adapter Models](/docs/advanced/lora)

     3. [LoRA Image Adapters](/docs/advanced/lora_text_to_image)

  6. [Integrations](/docs/integrations)

     1. [LangChain](/docs/advanced/langchain)

     2. [LlamaIndex](/docs/advanced/llama-index)

     3. [AI SDK](/docs/advanced/aisdk)

     4. [AutoGen](/docs/advanced/autogen)

     5. [Okta SSO](/docs/advanced/okta)

  7. [Tutorials & Examples](/docs/tutorials)

     1. [Stable Diffusion (Text to Image)](/docs/tutorials/stable-diffusion)

     2. [Whisper (Speech to Text)](/docs/tutorials/whisper)

     3. [Deprecated Models](/docs/advanced/deprecated)

  8. [Miscellaneous](/docs/misc)

     1. [Data Subprocessors](/docs/misc/subprocessors)

# Containers

## Overview

GPU Containers provide on-demand access to high-performance GPU compute
resources in the cloud. With GPU Containers, you can quickly spin up
containers with dedicated GPU access for machine learning training, inference,
data processing, and other compute-intensive workloads.

Key features:

  * **On-demand GPU access** : Launch containers with dedicated GPU resources when you need them
  * **Flexible configurations** : Choose from various GPU configurations based on your performance and budget requirements
  * **SSH access** : Connect directly to your containers via SSH for full control over your environment
  * **Pay-per-use** : Only pay for the time your containers are running
  * **Quick setup** : Get started in minutes with our streamlined creation process

GPU Containers are ideal for:

  * Machine learning model training and fine-tuning
  * Running inference workloads that require GPU acceleration
  * Data processing and analysis tasks
  * Development and testing of GPU-accelerated applications
  * Prototyping and experimentation with different GPU configurations

## Usage

### Web UI

#### Starting a New Container

  1. **Navigate to GPU Instances**
     * Go to your [Dashboard](/dash) and select "Instances" from the sidebar
     * Click the "New Container" button

[![GPU Instances Web UI](/docs/instances.webp)](/dash/instances)

  2. **Select GPU Configuration**
     * Choose from available GPU configurations based on your needs
     * Each configuration shows: 
       * GPU type, quantity and memory (e.g., "1xB100-180GB", "2xB200-180GB")
       * Hourly pricing
       * Current availability status
     * Configurations marked "Out of capacity" are temporarily unavailable

![Select GPU config](/docs/new-container-1.webp)

  3. **Enter Container Details**
     * **Container Name** : Provide a descriptive name for your container
     * **SSH Key** : Paste your public SSH key for secure access 
       * Use the format: `ssh-rsa AAAAB3NzaC1yc2E...`
       * This key will be added to the `ubuntu` user account

![Enter container name and SSH key](/docs/new-container-2.webp)

  4. **Accept License Agreements**
     * Review and accept the NVIDIA software license agreements
     * Acknowledge the cryptocurrency mining prohibition policy
     * Click "I agree to the above" to create your container

#### Connecting to a Running Container

**Access and Connect**

  * Wait for your container status to show "running" in the GPU Instances list
  * Click on SSH login field
  * Open your terminal and run: `ssh ubuntu@<ip-address>`
  * Your container is ready to use with GPU access configured

![Copy SSH Login](/docs/instance-copy-ssh-login.webp)

#### Stopping a Container

**Terminate Container**

  * Click on the container you want to stop from the instances list
  * Click the "Terminate" button
  * Type "confirm" in the dialog and click "Terminate"
  * Warning: All container data will be permanently lost

### HTTP API

#### Starting a New Container

**Create Container**

    
    
    curl -X POST https://api.deepinfra.com/v1/containers \
      -H "Authorization: Bearer $DEEPINFRA_TOKEN" \
      -H "Content-Type: application/json" \
      -d '{
        "name": "my-container",
        "gpu_config": "8xB200-180GB",
        "container_image": "di-cont-ubuntu-torch:latest",
        "cloud_init_user_data": "#cloud-config\nusers:\n- name: ubuntu\n  shell: /bin/bash\n  sudo: '\''ALL=(ALL) NOPASSWD:ALL'\''\n  ssh_authorized_keys:\n  - ssh-rsa AAAAB3NzaC1yc2E..."
      }'
    
    
    copy

#### Connecting to a Running Container

**Get Container Details**

    
    
    curl -X GET https://api.deepinfra.com/v1/containers/{container_id} \
      -H "Authorization: Bearer $DEEPINFRA_TOKEN"
    
    
    copy

Once the container state is "running" and an IP address is assigned, connect
via SSH:

    
    
    ssh ubuntu@<container-ip>
    
    
    copy

#### Listing Containers

    
    
    curl -X GET https://api.deepinfra.com/v1/containers \
      -H "Authorization: Bearer $DEEPINFRA_TOKEN"
    
    
    copy

#### Terminating a Container

    
    
    curl -X DELETE https://api.deepinfra.com/v1/containers/{container_id} \
      -H "Authorization: Bearer $DEEPINFRA_TOKEN"
    
    
    copy

### Container States

Containers progress through several states during their lifecycle:

  * **creating** : Container is being initialized
  * **starting** : Container is booting up
  * **running** : Container is active and accessible
  * **shutting_down** : Container is being terminated
  * **failed** : Container failed to start or encountered an error
  * **deleted** : Container has been permanently removed

[GPU Instances](/docs/gpu-instances)[Custom Deployments](/docs/custom-
deployments)

![Footer Logo](/_next/static/media/footer_logo.b3e9d8d3.svg)

![SOC 2
Certified](https://static.sprinto.com/_next/static/images/framework/soc2.png)![ISO
27001
Certified](https://static.sprinto.com/_next/static/images/framework/iso-27001.png)

Have questions or need a custom solution?

[Contact Sales](/contact-sales)

Company

[Pricing](/pricing)

[Docs](/docs)

[Compare](/compare)

[DeepStart](/deepstart)

[About](/about_us)

[Careers](https://jobs.gem.com/deep-infra)

[Contact us](/contact-sales)

[Trust Center](https://trust.deepinfra.com)

[DeepGPT](https://deepgpt.com)

Latest Models

[zai-org/GLM-4.6](/zai-org/GLM-4.6)[deepseek-ai/DeepSeek-V3.1](/deepseek-
ai/DeepSeek-V3.1)[deepseek-ai/DeepSeek-V3.2-Exp](/deepseek-
ai/DeepSeek-V3.2-Exp)[anthropic/claude-3-7-sonnet-
latest](/anthropic/claude-3-7-sonnet-
latest)[moonshotai/Kimi-K2-Instruct-0905](/moonshotai/Kimi-K2-Instruct-0905)

Featured Models

[Qwen/Qwen3-14B](/Qwen/Qwen3-14B)[microsoft/phi-4](/microsoft/phi-4)[openai/whisper-
large-v3-turbo](/openai/whisper-
large-v3-turbo)[anthropic/claude-4-sonnet](/anthropic/claude-4-sonnet)[sesame/csm-1b](/sesame/csm-1b)

![Built With Love in Palo Alto](/_next/static/media/love.ce60156e.svg)

[](https://linkedin.com/company/deep-
infra)[](https://x.com/DeepInfra)[](https://github.com/DeepInfra)[](https://discord.gg/x88dCvhqYq)

© 2026 Deep Infra. All rights reserved.

[Privacy Policy](/privacy)[Terms of Service](/terms)

