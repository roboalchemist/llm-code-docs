# Using Multi-Instance GPU (MIG) -

Source: https://docs.lambda.ai/education/using-mig/

---

[docker ](../../tags/#tag:docker)[llama ](../../tags/#tag:llama)[llm ](../../tags/#tag:llm)[on-demand cloud ](../../tags/#tag:on-demand-cloud)
# Using Multi-Instance GPU (MIG) [# ](#using-multi-instance-gpu-mig)

[See our video tutorial on using Multi-Instance GPU (MIG). ](https://youtu.be/KbB5e_V6THw)

[NVIDIA Multi-Instance GPU ](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/), or MIG, allows you to partition your GPUs into isolated instances. MIG enables you to run simultaneous workloads on a single GPU. For example, you can run inference on multiple models at the same time. 

Tip 

[See NVIDIA's MIG User Guide to learn more about MIG ](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/).
