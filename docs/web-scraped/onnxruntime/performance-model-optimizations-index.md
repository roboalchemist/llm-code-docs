# Source: https://onnxruntime.ai/docs/performance/model-optimizations/

# [![](data:image/svg+xml;base64,PHN2ZyB2aWV3Ym94PSIwIDAgMTYgMTYiIGFyaWEtaGlkZGVuPSJ0cnVlIj48dXNlIHhsaW5rOmhyZWY9IiNzdmctbGluayIgLz48L3N2Zz4=)](#model-optimizations) Model Optimizations

In addition to [tuning performance](/docs/performance/tune-performance/) using ONNX Runtime configurations, there are techniques that can be applied to reduce model size and/or complexity to improve performance.

------------------------------------------------------------------------

## Table of contents 

- [Quantize ONNX models](/docs/performance/model-optimizations/quantization.html)
- [Float16 and mixed precision models](/docs/performance/model-optimizations/float16.html)
- [Graph optimizations](/docs/performance/model-optimizations/graph-optimizations.html)
- [ORT model format](/docs/performance/model-optimizations/ort-format-models.html)
- [ORT model format runtime optimization](/docs/performance/model-optimizations/ort-format-model-runtime-optimization.html)