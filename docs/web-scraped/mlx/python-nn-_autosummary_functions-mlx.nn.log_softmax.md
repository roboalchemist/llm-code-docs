# Source: https://ml-explore.github.io/mlx/build/html/python/nn/_autosummary_functions/mlx.nn.log_softmax.html

[]

[[ ]](https://github.com/ml-explore/mlx "Source repository")

- [[ ] [.rst]](../../../_sources/python/nn/_autosummary_functions/mlx.nn.log_softmax.rst "Download source file")
- [ ] [.pdf]

[ ]

[]

# mlx.nn.log_softmax

## Contents

- [[`log_softmax`]](#mlx.nn.log_softmax)

# mlx.nn.log_softmax[\#](#mlx-nn-log-softmax "Link to this heading")

*[class][ ]*[[log_softmax]][(]*[[x]]*, *[[axis]][[=]][[-1]]*[)][\#](#mlx.nn.log_softmax "Link to this definition")

:   Applies the Log Softmax function.

    Applies [\\(x + \\log \\sum_i e\^\\)] element wise.

[](mlx.nn.log_sigmoid.html "previous page")

previous

mlx.nn.log_sigmoid

[](mlx.nn.mish.html "next page")

next

mlx.nn.mish

Contents

- [[`log_softmax`]](#mlx.nn.log_softmax)

By MLX Contributors

Â© Copyright 2023, Apple.\