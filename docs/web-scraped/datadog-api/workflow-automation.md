Workflow AutomationRead the 2025 State of Containers and Serverless Report!
Read the State of Containers and Serverless Report!

Home

Docs

API- 
- Agent
- API
- APM Tracing
- ContainersAutodiscovery
- Datadog Operator
- Dashboards
- Database Monitoring
- Datadog
- Datadog Site
- DevSecOps
- Incident Management
- IntegrationsAWS
- Azure
- Google Cloud
- Terraform
- Internal Developer Portal
- Logs
- Monitors
- Notebooks
- OpenTelemetry
- Profiler
- SearchProduct-Specific Search
- Session Replay
- SecurityApp and API Protection
- Cloud Security
- Cloud SIEM
- Code Security
- Serverless for AWS Lambda
- Software DeliveryCI Visibility
- Feature Flags
- Test Optimization
- Test Impact Analysis
- Synthetic Monitoring and TestingAPI Tests
- Browser Tests
- Mobile App Tests
- Continuous Testing
- Private Locations
- TagsAssigning Tags
- Unified Service Tagging
- Using Tags
- Workflow Automation
- Learning Center
- Support
- 
- 
- 
- Architecture
- IoT
- Supported PlatformsAIX
- Linux
- Ansible
- Chef
- Heroku
- MacOS
- Puppet
- SaltStack
- SCCM
- Windows
- From Source
- Log CollectionLog Agent tags
- Advanced Configurations
- Proxy
- Transport
- Multi-Line Detection
- ConfigurationCommands
- Configuration Files
- Log Files
- Status Page
- Network Traffic
- Proxy Configuration
- FIPS Compliance
- Dual Shipping
- Secrets Management
- Fleet AutomationRemote Agent Management
- TroubleshootingContainer Hostname Detection
- Debug Mode
- Agent Flare
- Agent Check Status
- NTP Issues
- Permission Issues
- Integrations Issues
- Site Issues
- Autodiscovery Issues
- Windows Container Issues
- Agent Runtime Configuration
- High CPU or Memory Consumption
- Guides
- Data Security
- Guides
- AuthorizationOAuth2 in Datadog
- Authorization Endpoints
- DogStatsDDatagram Format
- Unix Domain Socket
- High Throughput Data
- Data Aggregation
- DogStatsD Mapper
- Custom ChecksWriting a Custom Agent Check
- Writing a Custom OpenMetrics Check
- IntegrationsBuild an Integration with Datadog
- Create an Agent-based Integration
- Create an API-based Integration
- Create a Log Pipeline
- Integration Assets Reference
- Build a Marketplace Offering
- Create an Integration Dashboard
- Create a Monitor Template
- Create a Cloud SIEM Detection Rule
- Install Agent Integration Developer Tool
- Service ChecksSubmission - Agent Check
- Submission - DogStatsD
- Submission - API
- IDE PluginsJetBrains IDEs
- VS Code & Cursor
- CommunityLibraries
- Guides
- Getting StartedDatadog Example Application
- OpenTelemetry Demo Application
- Feature Compatibility
- Instrument Your ApplicationsOTel SDKs
- OTel APIs with Datadog SDKs
- OTel Instrumentation Libraries
- Configuration
- Send Data to DatadogDDOT Collector (Recommended)
- Other Setup Options
- Semantic MappingResource Attribute Mapping
- Metrics Mapping
- Infrastructure Host Mapping
- Hostname Mapping
- Service-entry Spans Mapping
- Ingestion Sampling
- Correlate DataLogs and Traces
- Metrics and Traces
- RUM and Traces
- DBM and Traces
- IntegrationsApache Metrics
- Apache Spark Metrics
- Collector Health Metrics
- Datadog Extension
- Docker Metrics
- HAProxy Metrics
- Host Metrics
- IIS Metrics
- Kafka Metrics
- Kubernetes Metrics
- MySQL Metrics
- NGINX Metrics
- Podman Metrics
- Runtime Metrics
- Trace Metrics
- Troubleshooting
- Guides and ResourcesProduce Delta Temporality Metrics
- Visualize Histograms as Heatmaps
- Migration Guides
- ReferenceTerms and Concepts
- Trace Context Propagation
- Trace IDs
- OTLP Metric Types
- Getting Started
- Plan
- Build
- Run
- 
- 
- Enterprise Configuration
- Datadog for Intune
- Shortcut Configurations
- Push Notifications
- Widgets
- Guides
- Data Directory
- Troubleshooting
- Install
- Using CoTerm
- Configuration Rules
- 
- Getting Started
- Account Management
- Components: Common
- Components: Azure
- Components: AWS
- Advanced
- FAQ
- APIAWS Accounts
- Azure Accounts
- Blueprints
- Budgets
- Teams
- Users
- Configure
- Dashboard List
- WidgetsConfiguration
- Widget Types
- Querying
- FunctionsAlgorithms
- Arithmetic
- Count
- Exclusion
- Interpolation
- Rank
- Rate
- Regression
- Rollup
- Smoothing
- Timeshift
- Beta
- Graph InsightsMetric Correlations
- Watchdog Explains
- Template Variables
- Overlays
- Annotations
- Guides
- SharingShared Dashboards
- Share Graphs
- Scheduled Reports
- Analysis FeaturesGetting Started
- Guides
- 
- 
- Functions and Operators
- Guides
- Draft Monitors
- Configure Monitors
- Monitor Templates
- Monitor TypesHost
- Metric
- Analysis
- Anomaly
- APM
- Audit Trail
- Change
- CI/CD & Test
- Cloud Cost
- Composite
- Database Monitoring
- Error Tracking
- Event
- Forecast
- Integration
- Live Process
- Logs
- Network
- Cloud Network Monitoring
- NetFlow
- Outlier
- Process Check
- Real User Monitoring
- Service Check
- SLO Alerts
- Synthetic Monitoring
- Watchdog
- NotificationsNotification Rules
- Variables
- DowntimesExamples
- Manage MonitorsSearch Monitors
- Check Summary
- Monitor StatusStatus Graphs
- Status Events
- Monitor Settings
- Monitor Quality
- Guides
- Monitor-based SLOs
- Metric-based SLOs
- Time Slice SLOs
- Error Budget Alerts
- Burn Rate Alerts
- Guides
- Custom MetricsMetric Type Modifiers
- Historical Metrics Ingestion
- Submission - Agent Check
- Submission - DogStatsD
- Submission - Powershell
- Submission - API
- OpenTelemetry MetricsOTLP Metric Types
- Query OpenTelemetry Metrics
- Metrics Types
- Distributions
- Overview
- ExplorerMetrics Units
- Summary
- Volume
- Advanced Filtering
- Nested Queries
- Composite Metrics Queries
- Derived Metrics
- Metrics Without Limits™
- Guides
- Alerts
- Impact Analysis
- RCA
- Insights
- Faulty Deployment Detection
- Faulty Cloud & SaaS API Detection
- Bits AI SREInvestigate issues
- Remediate issues
- Bits AI SRE integrations and settings
- Help Bits learn
- Chat with Bits AI SRE
- Bits AI Dev AgentSetup
- Chat with Bits AI
- MCP Server
- Software CatalogSet Up
- Entity Model
- Troubleshooting
- ScorecardsScorecard Configuration
- Custom Rules
- Using Scorecards
- Self-Service ActionsSoftware Templates
- Engineering ReportsReliability Overview
- Scorecards Performance
- DORA Metrics
- Custom Reports
- Developer Homepage
- Campaigns
- External Provider Status
- Plugins
- Integrations
- Use CasesAPI Management
- Cloud Cost Management
- App and API Protection
- Developer Onboarding
- Dependency Management
- Production Readiness
- Incident Response
- CI Pipeline Visibility
- Onboarding Guide
- Explorer
- Issue States
- Regression Detection
- Suspected Causes
- Error Grouping
- Bits AI Dev Agent
- Monitors
- Issue Correlation
- Identify Suspect Commits
- Auto Assign
- Issue Team Ownership
- Track Browser and Mobile ErrorsBrowser Error Tracking
- Collecting Browser Errors
- Mobile Crash Tracking
- Replay Errors
- Real User Monitoring
- Logs
- Track Backend ErrorsGetting Started
- Exception Replay
- Capturing Handled Errors
- APM
- Logs
- Manage Data Collection
- Troubleshooting
- Guides
- Feature Flags
- Ingest Events
- Pipelines and ProcessorsAggregation Key Processor
- Arithmetic Processor
- Date Remapper
- Category Processor
- Grok Parser
- Lookup Processor
- Remapper
- Service Remapper
- Status Remapper
- String Builder Processor
- ExplorerSearching
- Navigate the Explorer
- Customization
- Facets
- Attributes
- Notifications
- Analytics
- Saved Views
- Triage Inbox
- CorrelationConfiguration
- Triaging & Notifying
- Analytics
- Guides
- Declare an Incident
- Describe an Incident
- Response Team
- Notification
- Investigate an IncidentTimeline
- Follow-ups
- Incident AI
- Incident SettingsInformation
- Property Fields
- Responder Types
- Integrations
- Notification Rules
- Templates
- Incident Analytics
- IntegrationsSlack
- Microsoft Teams
- Jira
- ServiceNow
- Status Pages
- Atlassian Statuspage
- Datadog Clipboard
- Onboard a Team
- Trigger a PageLive Call Routing
- Routing Rules
- Escalation Policies
- Schedules
- Automations
- Profile Settings
- Guides
- 
- ProjectsSettings
- Create a Case
- Customization
- View and Manage Cases
- Notifications and Integrations
- Case Automation Rules
- Troubleshooting
- 
- Build Workflows
- Access and Authentication
- Trigger Workflows
- Variables and parameters
- ActionsWorkflow Logic
- Save and Reuse Actions
- Test and Debug
- JavaScript Expressions
- Track Workflows
- Limits
- Build Apps
- Access and Authentication
- Queries
- Variables
- Events
- ComponentsCustom Charts
- React Renderer
- Tables
- Reusable Modules
- JavaScript Expressions
- Embedded AppsInput Parameters
- Save and Reuse Actions
- Create and Manage Datastores
- Use Datastores with Apps and Workflows
- Automation Rules
- Access and Authentication
- 
- ConnectionsAWS Integration
- HTTP Request
- Private ActionsUse Private Actions
- Run a Script
- Update the Private Action Runner
- Private Action Credentials
- OverlaysInfrastructure
- Observability
- Security
- Cloud Cost Management
- Cloud Resources Schema
- Policies
- Resource Changes
- Setup
- Guides
- Setup
- Host List
- Monitoring ContainersConfiguration
- Container Images View
- Orchestrator Explorer
- Kubernetes Resource Utilization
- Kubernetes Autoscaling
- Amazon Elastic Container Explorer
- Autoscaling
- Docker and other runtimesAPM
- Log collection
- Tag extraction
- Integrations
- Prometheus
- Data Collected
- KubernetesInstallation
- Further Configuration
- Distributions
- APM
- Log collection
- Tag extraction
- Integrations
- Prometheus & OpenMetrics
- Control plane monitoring
- Data collected
- kubectl Plugin
- Datadog CSI Driver
- Data security
- Cluster AgentSetup
- Commands & Options
- Cluster Checks
- Endpoint Checks
- Admission Controller
- Amazon ECSAPM
- Log collection
- Tag extraction
- Data collected
- Managed Instances
- AWS Fargate with ECS
- Datadog OperatorAdvanced Install
- Configuration
- Custom Checks
- Data Collected
- Secret Management
- DatadogDashboard CRD
- DatadogMonitor CRD
- DatadogSLO CRD
- TroubleshootingDuplicate hosts
- Cluster Agent
- Cluster Checks
- HPA and Metrics Provider
- Admission Controller
- Log Collection
- Guides
- Increase Process Retention
- AWS LambdaInstrumentation
- Managed Instances
- Lambda Metrics
- Distributed Tracing
- Log Collection
- Remote Instrumentation
- Advanced Configuration
- Continuous Profiler
- Securing Functions
- Deployment Tracking
- OpenTelemetry
- Troubleshooting
- Lambda Web Adapter
- FIPS Compliance
- AWS Step FunctionsInstallation
- Merge Step Functions and Lambda Traces
- Enhanced Metrics
- Redrive Executions
- Distributed Map States
- Troubleshooting
- AWS Fargate
- Azure App ServiceLinux - Code
- Linux - Container
- Windows - Code
- Azure Container AppsIn-Container
- Sidecar
- Azure Functions
- Google Cloud RunContainers
- Functions
- Functions (1st generation)
- Libraries & Integrations
- Glossary
- Guides
- Cloud Network MonitoringSetup
- Network Health
- Network Analytics
- Network Map
- Guides
- Supported Cloud Services
- Terms and Concepts
- DNS Monitoring
- Network Device MonitoringSetup
- Integrations
- Profiles
- Configuration Management
- Maps
- SNMP Metrics Reference
- Troubleshooting
- Guides
- Terms and Concepts
- NetFlow MonitoringMonitors
- Network PathSetup
- List View
- Path View
- Guides
- Terms and Concepts
- Amazon S3
- Google Cloud Storage
- Azure Blob Storage
- Datadog Costs
- SetupAWS
- Azure
- Google Cloud
- Oracle
- SaaS Integrations
- Custom
- TagsTag Explorer
- Multisource Querying
- AllocationTag Pipelines
- Container Cost Allocation
- BigQuery Costs
- Custom Allocation Rules
- ReportingExplorer
- Scheduled Reports
- RecommendationsCustom Recommendations
- PlanningBudgets
- Commitment Programs
- Cost ChangesMonitors
- Anomalies
- Real-Time Costs
- APM Terms and Concepts
- Application InstrumentationSingle Step Instrumentation
- Manually managed SDKs
- Code-based Custom Instrumentation
- Dynamic Instrumentation
- Library Compatibility
- Library Configuration
- Configuration at Runtime
- Trace Context Propagation
- Serverless Application Tracing
- Proxy Tracing
- Span Tag Semantics
- Span Links
- APM Metrics CollectionTrace Metrics
- Runtime Metrics
- Trace Pipeline ConfigurationIngestion Mechanisms
- Ingestion Controls
- Adaptive Sampling
- Generate Metrics
- Trace Retention
- Usage Metrics
- Correlate Traces with Other TelemetryCorrelate DBM and Traces
- Correlate Logs and Traces
- Correlate RUM and Traces
- Correlate Synthetics and Traces
- Correlate Profiles and Traces
- Trace ExplorerSearch Spans
- Query Syntax
- Trace Queries
- Span Tags and Attributes
- Span Visualizations
- Trace View
- Tag Analysis
- Recommendations
- Code Origin for Spans
- Service ObservabilitySoftware Catalog
- Service Page
- Resource Page
- Deployment Tracking
- Service Map
- Inferred Services
- Remapping Rules for Inferred Entities
- Service Remapping Rules
- Service Override Removal
- APM Monitors
- Endpoint ObservabilityExplore Endpoints
- Monitor Endpoints
- Live Debugger
- Error TrackingIssue States
- Error Tracking Explorer
- Error Grouping
- Monitors
- Identify Suspect Commits
- Exception Replay
- Troubleshooting
- Data Security
- Guides
- TroubleshootingAgent Rate Limits
- Agent APM metrics
- Agent Resource Usage
- Correlated Logs
- PHP 5 Deep Call Stacks
- .NET diagnostic tool
- APM Quantization
- Go Compile-Time Instrumentation
- Tracer Startup Logs
- Tracer Debug Logs
- Connection Errors
- Enabling the ProfilerSupported Language and Tracer Versions
- Java
- Python
- Go
- Ruby
- Node.js
- .NET
- PHP
- C/C++/Rust
- Profile Types
- Profile Visualizations
- Investigate Slow Traces or Endpoints
- Compare Profiles
- Automated Analysis
- Profiler TroubleshootingJava
- Python
- Go
- Ruby
- Node.js
- .NET
- PHP
- C/C++/Rust
- Guides
- Agent Integration Overhead
- Setup Architectures
- Setting Up PostgresSelf-hosted
- RDS
- Aurora
- Google Cloud SQL
- AlloyDB
- Azure
- Supabase
- Heroku
- Advanced Configuration
- Troubleshooting
- Setting Up MySQLSelf-hosted
- RDS
- Aurora
- Google Cloud SQL
- Azure
- Advanced Configuration
- Troubleshooting
- Setting Up SQL ServerSelf-hosted
- RDS
- Azure
- Google Cloud SQL
- Troubleshooting
- Setting Up OracleSelf-hosted
- RDS
- RAC
- Exadata
- Autonomous Database
- Troubleshooting
- Setting Up Amazon DocumentDBAmazon DocumentDB
- Setting Up MongoDBSelf-hosted
- MongoDB Atlas
- Troubleshooting
- Connecting DBM and Traces
- Data Collected
- Exploring Database Hosts
- Exploring Query Metrics
- Exploring Query Samples
- Exploring Database Schemas
- Exploring Recommendations
- Troubleshooting
- Guides
- Setup
- Kafka Messages
- Schema Tracking
- Dead Letter Queues
- Metrics and Tags
- 
- Data WarehousesSnowflake
- Databricks
- BigQuery
- Business Intelligence IntegrationsTableau
- Sigma
- Metabase
- Power BI
- Databricks
- Airflow
- dbt
- Spark on Kubernetes
- Spark on Amazon EMR
- Spark on Google Dataproc
- Custom Jobs (OpenLineage)Datadog Agent for OpenLineage Proxy
- Application MonitoringBrowser
- Android and Android TV
- iOS and tvOS
- Flutter
- Kotlin Multiplatform
- React Native
- Roku
- Unity
- PlatformDashboards
- Monitors
- Generate Custom Metrics
- Exploring RUM DataSearch RUM Events
- Search Syntax
- Group
- Visualize
- Events
- Export
- Saved Views
- Watchdog Insights for RUM
- Correlate RUM with Other TelemetryCorrelate LLM with RUM
- Correlate Logs with RUM
- Correlate Profiling with RUM
- Correlate Synthetics with RUM
- Correlate Traces with RUM
- Feature Flag TrackingSetup
- Using Feature Flags
- Error TrackingExplorer
- Issue States
- Track Browser Errors
- Track Mobile Errors
- Error Grouping
- Monitors
- Identify Suspect Commits
- Troubleshooting
- RUM Without LimitsMetrics
- Retention Filters
- Operations Monitoring
- Ownership of Views
- Guides
- Data Security
- API TestingHTTP
- SSL
- DNS
- WebSocket
- TCP
- UDP
- ICMP
- GRPC
- Error codes
- Multistep API Testing
- Browser TestingRecording Steps
- Browser Testing Results
- Advanced Options for Steps
- Authentication in Browser Testing
- Network Path TestingTerms and Concepts
- Mobile Application TestingTesting Steps
- Testing Results
- Advanced Options for Steps
- Supported Devices
- Restricted Networks
- Settings
- Test Suites
- PlatformDashboards
- Metrics
- Test Coverage
- Private Locations
- Connect APM
- Settings
- Exploring Synthetics DataSaved Views
- Results Explorer
- Guides
- NotificationsTemplate Variables
- Conditional Alerting
- Advanced Notifications
- Integrate with Statuspage
- Troubleshooting
- Data Security
- Local and Staging EnvironmentsTesting Multiple Environments
- Testing With Proxy, Firewall, or VPN
- CI/CD IntegrationsConfiguration
- Azure DevOps Extension
- CircleCI Orb
- GitHub Actions
- GitLab
- Jenkins
- Bitrise (Upload Application)
- Bitrise (Run Tests)
- Settings
- Results Explorer
- Metrics
- Guides
- Troubleshooting
- Vizualizing with ChartsChart Basics
- Pathways Diagram
- Funnel Analysis
- Retention Analysis
- Analytics Explorer
- Dashboards
- Segments
- Managing Profiles
- ExperimentsDefine Metrics
- Reading Experiment Results
- Minimum Detectable Effects
- Guides
- Troubleshooting
- BrowserSetup
- Privacy Options
- Developer Tools
- Troubleshooting
- MobileSetup and Configuration
- Privacy Options
- Developer Tools
- Impact on App Performance
- Troubleshooting
- Playlists
- Heatmaps
- Pipeline VisibilityAWS CodePipeline
- Azure Pipelines
- Buildkite
- CircleCI
- Codefresh
- GitHub Actions
- GitLab
- Jenkins
- TeamCity
- Other CI Providers
- Custom Commands
- Custom Tags and Measures
- Search and Manage
- ExplorerSearch Syntax
- Search Pipeline Executions
- Export
- Saved Views
- [Monitors](https://docs.datadoghq.com/monitors/types/ci/?tab=pipelines)
- Guides
- Troubleshooting
- Deployment VisibilityArgo CD
- CI Providers
- Explore DeploymentsSearch Syntax
- Facets
- Saved Views
- FeaturesCode Changes Detection
- Rollback Detection
- [Monitors](https://docs.datadoghq.com/monitors/types/ci/?tab=deployments)
- Setup
- Explore
- Setup.NET
- Java and JVM Languages
- JavaScript and TypeScript
- Python
- Ruby
- Swift
- Go
- JUnit Report Uploads
- Network Settings
- Tests in Containers
- Repositories
- ExplorerSearch Syntax
- Search Test Runs
- Export
- Saved Views
- [Monitors](https://docs.datadoghq.com/monitors/types/ci/?tab=tests)
- Test Health
- Flaky Test Management
- Working with Flaky TestsEarly Flake Detection
- Auto Test Retries
- Test Impact AnalysisSetup
- How It Works
- Troubleshooting
- Developer Workflows
- Code Coverage
- Instrument Browser Tests with RUM
- Instrument Swift Tests with RUM
- Correlate Logs and Tests
- Guides
- Troubleshooting
- Setup
- Data Collected
- Setup
- SetupDeployment Data Sources
- Failure Data Sources
- Change Failure Detection
- Data Collected
- Client SDKsAndroid and Android TV
- iOS and tvOS
- JavaScript
- React
- Server SDKsGo
- Java
- Node.js
- Python
- Ruby
- MCP Server
- Guides
- Detection RulesOOTB Rules
- NotificationsRules
- Variables
- Suppressions
- Automation PipelinesMute
- Add to Security Inbox
- Set Due Date Rules
- Security Inbox
- Threat Intelligence
- Audit Trail
- Access Control
- Account Takeover Protection
- Ticketing Integrations
- Research Feed
- Guides
- Ingest and EnrichContent Packs
- Bring Your Own Threat Intelligence
- Open Cybersecurity Schema Framework
- Detect and MonitorOOTB Rules
- Custom Detection Rules
- Version History
- Suppressions
- Historical Jobs
- MITRE ATT&CK Map
- Triage and InvestigateInvestigate Security Signals
- Risk Insights
- IOC Explorer
- Investigator
- Respond and ReportSecurity Operational Metrics
- Guides
- Data Security
- Static Code Analysis (SAST)Setup
- GitHub Actions
- Generic CI Providers
- AI-Enhanced Static Code Analysis
- SAST Custom Rule Creation Tutorial
- SAST Custom Rules
- SAST Custom Rules Guide
- Static Code Analysis (SAST) rules
- Software Composition Analysis (SCA)Static Setup
- Runtime Setup
- Library Inventory
- Secret ScanningGitHub Actions
- Generic CI Providers
- Secret Validation
- Runtime Code Analysis (IAST)Setup
- Security Controls
- Infrastructure as Code (IaC) SecuritySetup
- Exclusions
- Rules
- Developer Tool IntegrationsPull Request Comments
- PR Gates
- IDE Plugins
- Git Hooks
- Troubleshooting
- Guides
- SetupSupported Deployment Types
- Agentless Scanning
- Deploy the Agent
- Set Up CloudTrail Logs
- Set Up without Infrastructure Monitoring
- Deploy via Cloud Integrations
- Security Graph
- MisconfigurationsManage Compliance Rules
- Create Custom Rules
- Manage Compliance Posture
- Explore Misconfigurations
- Kubernetes Security Posture Management
- Identity Risks
- VulnerabilitiesHosts and Containers Compatibility
- OOTB Rules
- Review and RemediateMute Issues
- Automate Security Workflows
- Create Jira Issues
- Severity Scoring
- Guides
- TroubleshootingVulnerabilities
- Terms and Concepts
- How It WorksThreat Intelligence
- Trace Qualification
- User Monitoring and Protection
- Setup
- Overview
- Security SignalsAttackers Explorer
- Attacker Fingerprint
- Attacker Clustering
- Users Explorer
- PoliciesCustom Rules
- OOTB Rules
- In-App WAF Rules
- Tracing Library Configuration
- Exploit Prevention
- WAF Integrations
- API Security Inventory
- Guides
- Troubleshooting
- SetupDeploy the Agent
- Workload Protection Agent Variables
- Detection RulesOOTB Rules
- Custom Rules
- Investigate Security Signals
- Investigate Agent Events
- Creating Agent Rule ExpressionsWriting Custom Rule Expressions
- Linux Syntax
- Windows Syntax
- Coverage and Posture ManagementHosts and Containers
- Serverless
- Coverage
- Guides
- Troubleshooting
- SetupTelemetry Data
- Cloud Storage
- Scanning RulesLibrary Rules
- Custom Rules
- Guides
- Quickstart
- InstrumentationAutomatic
- SDK Reference
- HTTP API
- OpenTelemetry
- MonitoringQuerying spans and traces
- Correlate with APM
- Cluster Map
- Agent Monitoring
- MCP Clients
- Prompt Tracking
- Metrics
- Cost
- EvaluationsManaged Evaluations
- Custom LLM-as-a-Judge
- External Evaluations
- Compatibility
- Export API
- Experiments
- Data Security and RBAC
- Terms and Concepts
- Guides
- ConfigurationExplore Templates
- Set Up Pipelines
- Install the Worker
- Live Capture
- Update Existing Pipelines
- Access Control
- SourcesAkamai DataStream
- Amazon Data Firehose
- Amazon S3
- Azure Event Hubs
- Datadog Agent
- Datadog Lambda Extension
- Datadog Lambda Forwarder
- Filebeat
- Fluent
- Google Pub/Sub
- HTTP Client
- HTTP Server
- OpenTelemetry
- Kafka
- Logstash
- Socket
- Splunk HEC
- Splunk TCP
- Sumo Logic Hosted Collector
- Syslog
- ProcessorsAdd Environment Variables
- Add hostname
- Custom Processor
- Deduplicate
- Edit fields
- Enrichment Table
- Filter
- Generate Metrics
- Grok Parser
- Parse JSON
- Parse XML
- Quota
- Reduce
- Remap to OCSF
- Sample
- Sensitive Data Scanner
- Split Array
- Tag Control
- Throttle
- DestinationsAmazon OpenSearch
- Amazon S3
- Amazon Security Lake
- Azure Storage
- CrowdStrike NG-SIEM
- Datadog CloudPrem
- Datadog Logs
- Datadog Metrics
- Elasticsearch
- Google Cloud Storage
- Google Pub/Sub
- Google SecOps
- HTTP Client
- Kafka
- Microsoft Sentinel
- New Relic
- OpenSearch
- SentinelOne
- Socket
- Splunk HEC
- Sumo Logic Hosted Collector
- Syslog
- PacksAkamai CDN
- Amazon CloudFront
- Amazon VPC Flow Logs
- AWS CloudTrail
- Cisco ASA
- Cloudflare
- F5
- Fastly
- Fortinet Firewall
- HAProxy Ingress
- Istio Proxy
- Netskope
- NGINX
- Okta
- Palo Alto Firewall
- Windows XML
- ZScaler ZIA DNS
- Zscaler ZIA Firewall
- Zscaler ZIA Tunnel
- Zscaler ZIA Web Logs
- Search Syntax
- Scaling and PerformanceHandling Load and Backpressure
- Scaling Best Practices
- Monitoring and TroubleshootingWorker CLI Commands
- Monitoring Pipelines
- Pipeline Usage Metrics
- Troubleshooting
- Guides and ResourcesUpgrade Worker Guide
- Log Collection & IntegrationsBrowser
- Android
- iOS
- Flutter
- React Native
- Roku
- Kotlin Multiplatform
- C#
- Go
- Java
- Node.js
- PHP
- Python
- Ruby
- OpenTelemetry
- Agent Integrations
- Other Integrations
- Log ConfigurationPipelines
- Processors
- Parsing
- Pipeline Scanner
- Attributes and Aliasing
- Generate Metrics
- Indexes
- Flex Logs
- Archives
- Rehydrate from Archives
- Archive Search
- Forwarding
- Log ExplorerLive Tail
- Search Logs
- Search Syntax
- Advanced Search
- Facets
- Calculated Fields
- Analytics
- Patterns
- Transactions
- Visualize
- Log Side Panel
- Export
- Watchdog Insights for Logs
- Saved Views
- Error TrackingError Tracking Explorer
- Issue States
- Track Browser and Mobile Errors
- Track Backend Errors
- Error Grouping
- Manage Data Collection
- Dynamic Sampling
- Monitors
- Identify Suspect Commits
- Troubleshooting
- Reports
- Guides
- Data Security
- TroubleshootingLive Tail
- Quickstart
- Architecture
- InstallationAWS EKS
- Azure AKS
- Install Locally with Docker
- Log IngestionDatadog Agent
- Observability Pipelines
- REST API
- ConfigurationDatadog Account
- AWS Configuration
- Azure Configuration
- Cluster Sizing
- Ingress
- Processing
- Reverse Connection
- Management
- Supported Features
- Troubleshooting
- Switching Between Orgs
- Organization SettingsUser Management
- Login Methods
- OAuth Apps
- Custom Organization Landing Page
- Service Accounts
- IP Allowlist
- Domain Allowlist
- Cross-Organization Visibility
- Access ControlGranular Access
- Permissions
- Data Access
- SSO with SAMLConfiguring SAML
- User Group Mapping
- Active Directory
- Auth0
- Entra ID
- Google
- LastPass
- Okta
- SafeNet
- Troubleshooting
- SCIMOkta
- Microsoft Entra ID
- API and Application Keys
- TeamsTeam Management
- Provision with GitHub
- Governance Console
- Multi-Factor Authentication
- Audit TrailEvents
- Forwarding
- Guides
- Safety Center
- Plan and UsageCost Details
- Usage Details
- BillingPricing
- Credit Card
- Product Allotments
- Usage Metrics
- Usage Attribution
- Custom Metrics
- Containers
- Log Management
- APM
- Serverless
- Real User Monitoring
- CI Visibility
- Incident Response
- AWS Integration
- Azure Integration
- Google Cloud Integration
- Alibaba Integration
- vSphere Integration
- Workflow Automation
- Multi-org Accounts
- Guides
- Cloud-based Authentication
- Agent
- Cloud SIEM
- Kubernetes
- Log Management
- Real User Monitoring
- Synthetic Monitoring
- Tracing
- PCI Compliance
- HIPAA Compliance
- Data Retention Periods
- Guides
- 
Docs > 
API Reference > 
Workflow AutomationLanguage

English[English](https://docs.datadoghq.com/api/latest/workflow-automation/?lang_pref=en)
[Français](https://docs.datadoghq.com/fr/api/latest/workflow-automation/?lang_pref=fr)
[日本語](https://docs.datadoghq.com/ja/api/latest/workflow-automation/?lang_pref=ja)
[한국어](https://docs.datadoghq.com/ko/api/latest/workflow-automation/?lang_pref=ko)
[Español](https://docs.datadoghq.com/es/api/latest/workflow-automation/?lang_pref=es)Datadog Site

US1
US3
US5
EU
AP1
AP2
US1-FEDThis product is not supported for your selected Datadog site. ().# Workflow AutomationDatadog Workflow Automation allows you to automate your end-to-end processes by connecting Datadog with the rest of your tech stack. Build workflows to auto-remediate your alerts, streamline your incident and security processes, and reduce manual toil. Workflow Automation supports over 1,000+ OOTB actions, including AWS, JIRA, ServiceNow, GitHub, and OpenAI. Learn more in our Workflow Automation docs here.
## Get an existing Workflow- v2 (latest)
GET https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}https://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}https://api.datadoghq.eu/api/v2/workflows/{workflow_id}https://api.ddog-gov.com/api/v2/workflows/{workflow_id}https://api.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}
### OverviewGet a workflow by ID. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_read` permission.### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
### Response- 200
- 400
- 403
- 404
- 429
Successfully got a workflow.
- Model
- Example
The response object after getting a workflow.
Expand All
Field
Type
Description
data
object
Data related to the workflow.
attributes [*required*]
object
The definition of `WorkflowDataAttributes` object.
createdAt
date-time
When the workflow was created.
description
string
Description of the workflow.
name [*required*]
string
Name of the workflow.
published
boolean
Set the workflow to published or unpublished. Workflows in an unpublished state will only be executable via manual runs. Automatic triggers such as Schedule will not execute the workflow until it is published.
spec [*required*]
object
The spec defines what the workflow does.
annotations
[object]
A list of annotations used in the workflow. These are like sticky notes for your workflow!
display [*required*]
object
The definition of `AnnotationDisplay` object.
bounds
object
The definition of `AnnotationDisplayBounds` object.
height
double
The `bounds` `height`.
width
double
The `bounds` `width`.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
id [*required*]
string
The `Annotation` `id`.
markdownTextAnnotation [*required*]
object
The definition of `AnnotationMarkdownTextAnnotation` object.
text
string
The `markdownTextAnnotation` `text`.
connectionEnvs
[object]
A list of connections or connection groups used in the workflow.
connectionGroups
[object]
The `ConnectionEnv` `connectionGroups`.
connectionGroupId [*required*]
string
The `ConnectionGroup` `connectionGroupId`.
label [*required*]
string
The `ConnectionGroup` `label`.
tags [*required*]
[string]
The `ConnectionGroup` `tags`.
connections
[object]
The `ConnectionEnv` `connections`.
connectionId [*required*]
string
The `Connection` `connectionId`.
label [*required*]
string
The `Connection` `label`.
env [*required*]
enum
The definition of `ConnectionEnvEnv` object.
Allowed enum values: `default`handle
string
Unique identifier used to trigger workflows automatically in Datadog.
inputSchema
object
A list of input parameters for the workflow. These can be used as dynamic runtime values in your workflow.
parameters
[object]
The `InputSchema` `parameters`.
defaultValue

The `InputSchemaParameters` `defaultValue`.
description
string
The `InputSchemaParameters` `description`.
label
string
The `InputSchemaParameters` `label`.
name [*required*]
string
The `InputSchemaParameters` `name`.
type [*required*]
enum
The definition of `InputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT` outputSchema
object
A list of output parameters for the workflow.
parameters
[object]
The `OutputSchema` `parameters`.
defaultValue

The `OutputSchemaParameters` `defaultValue`.
description
string
The `OutputSchemaParameters` `description`.
label
string
The `OutputSchemaParameters` `label`.
name [*required*]
string
The `OutputSchemaParameters` `name`.
type [*required*]
enum
The definition of `OutputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT`value

The `OutputSchemaParameters` `value`.
steps
[object]
A `Step` is a sub-component of a workflow. Each `Step` performs an action.
actionId [*required*]
string
The unique identifier of an action.
completionGate
object
Used to create conditions before running subsequent actions.
completionCondition [*required*]
object
The definition of `CompletionCondition` object.
operand1 [*required*]

The `CompletionCondition` `operand1`.
operand2

The `CompletionCondition` `operand2`.
operator [*required*]
enum
The definition of `CompletionConditionOperator` object.
Allowed enum values: `OPERATOR_EQUAL,OPERATOR_NOT_EQUAL,OPERATOR_GREATER_THAN,OPERATOR_LESS_THAN,OPERATOR_GREATER_THAN_OR_EQUAL_TO,OPERATOR_LESS_THAN_OR_EQUAL_TO,OPERATOR_CONTAINS,OPERATOR_DOES_NOT_CONTAIN,OPERATOR_IS_NULL,OPERATOR_IS_NOT_NULL,OPERATOR_IS_EMPTY,OPERATOR_IS_NOT_EMPTY` retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
connectionLabel
string
The unique identifier of a connection defined in the spec.
display
object
The definition of `StepDisplay` object.
bounds
object
The definition of `StepDisplayBounds` object.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
errorHandlers
[object]
The `Step` `errorHandlers`.
fallbackStepName [*required*]
string
The `ErrorHandler` `fallbackStepName`.
retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
name [*required*]
string
Name of the step.
outboundEdges
[object]
A list of subsequent actions to run.
branchName [*required*]
string
The `OutboundEdge` `branchName`.
nextStepName [*required*]
string
The `OutboundEdge` `nextStepName`.
parameters
[object]
A list of inputs for an action.
name [*required*]
string
The `Parameter` `name`.
value [*required*]

The `Parameter` `value`.
readinessGate
object
Used to merge multiple branches into a single branch.
thresholdType [*required*]
enum
The definition of `ReadinessGateThresholdType` object.
Allowed enum values: `ANY,ALL` triggers
[ <oneOf>]
The list of triggers that activate this workflow. At least one trigger is required, and each trigger type may appear at most once.
Option 1
object
Schema for an API-based trigger.
apiTrigger [*required*]
object
Trigger a workflow from an API request. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 2
object
Schema for an App-based trigger.
appTrigger [*required*]
object
Trigger a workflow from an App.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 3
object
Schema for a Case-based trigger.
caseTrigger [*required*]
object
Trigger a workflow from a Case. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 4
object
Schema for a Change Event-based trigger.
changeEventTrigger [*required*]
object
Trigger a workflow from a Change Event.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 5
object
Schema for a Database Monitoring-based trigger.
databaseMonitoringTrigger [*required*]
object
Trigger a workflow from Database Monitoring.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 6
object
Schema for a Datastore-based trigger.
datastoreTrigger [*required*]
object
Trigger a workflow from a Datastore. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 7
object
Schema for a Dashboard-based trigger.
dashboardTrigger [*required*]
object
Trigger a workflow from a Dashboard.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 8
object
Schema for a GitHub webhook-based trigger.
githubWebhookTrigger [*required*]
object
Trigger a workflow from a GitHub webhook. To trigger a workflow from GitHub, you must set a `webhookSecret`. In your GitHub Webhook Settings, set the Payload URL to "base_url"/api/v2/workflows/"workflow_id"/webhook?orgId="org_id", select application/json for the content type, and be highly recommend enabling SSL verification for security. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 9
object
Schema for an Incident-based trigger.
incidentTrigger [*required*]
object
Trigger a workflow from an Incident. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 10
object
Schema for a Monitor-based trigger.
monitorTrigger [*required*]
object
Trigger a workflow from a Monitor. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 11
object
Schema for a Notebook-based trigger.
notebookTrigger [*required*]
object
Trigger a workflow from a Notebook.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 12
object
Schema for a Schedule-based trigger.
scheduleTrigger [*required*]
object
Trigger a workflow from a Schedule. The workflow must be published.
rruleExpression [*required*]
string
Recurrence rule expression for scheduling.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 13
object
Schema for a Security-based trigger.
securityTrigger [*required*]
object
Trigger a workflow from a Security Signal or Finding. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 14
object
Schema for a Self Service-based trigger.
selfServiceTrigger [*required*]
object
Trigger a workflow from Self Service.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 15
object
Schema for a Slack-based trigger.
slackTrigger [*required*]
object
Trigger a workflow from Slack. The workflow must be published.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 16
object
Schema for a Software Catalog-based trigger.
softwareCatalogTrigger [*required*]
object
Trigger a workflow from Software Catalog.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 17
object
Schema for a Workflow-based trigger.
startStepNames
[string]
A list of steps that run first after a trigger fires.
workflowTrigger [*required*]
object
Trigger a workflow from the Datadog UI. Only required if no other trigger exists.
tags
[string]
Tags of the workflow.
updatedAt
date-time
When the workflow was last updated.
webhookSecret
string
If a Webhook trigger is defined on this workflow, a webhookSecret is required and should be provided here.
id
string
The workflow identifier
relationships
object
The definition of `WorkflowDataRelationships` object.
creator
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users` owner
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users`type [*required*]
enum
The definition of `WorkflowDataType` object.
Allowed enum values: `workflows````
{
"data": {
"attributes": {
"createdAt": "2019-09-19T10:00:00.000Z",
"description": "string",
"name": "",
"published": false,
"spec": {
"annotations": [
{
"display": {
"bounds": {
"height": "number",
"width": "number",
"x": "number",
"y": "number"
}
},
"id": "",
"markdownTextAnnotation": {
"text": "string"
}
}
],
"connectionEnvs": [
{
"connectionGroups": [
{
"connectionGroupId": "",
"label": "",
"tags": [
""
]
}
],
"connections": [
{
"connectionId": "",
"label": ""
}
],
"env": "default"
}
],
"handle": "string",
"inputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING",
"value": "undefined"
}
]
},
"steps": [
{
"actionId": "",
"completionGate": {
"completionCondition": {
"operand1": "undefined",
"operand2": "undefined",
"operator": "OPERATOR_EQUAL"
},
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
},
"connectionLabel": "string",
"display": {
"bounds": {
"x": "number",
"y": "number"
}
},
"errorHandlers": [
{
"fallbackStepName": "",
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
}
],
"name": "",
"outboundEdges": [
{
"branchName": "",
"nextStepName": ""
}
],
"parameters": [
{
"name": "",
"value": "undefined"
}
],
"readinessGate": {
"thresholdType": "ANY"
}
}
],
"triggers": [
{
"apiTrigger": {
"rateLimit": {
"count": "integer",
"interval": "string"
}
},
"startStepNames": [
""
]
}
]
},
"tags": [],
"updatedAt": "2019-09-19T10:00:00.000Z",
"webhookSecret": "string"
},
"id": "string",
"relationships": {
"creator": {
"data": {
"id": "",
"type": "users"
}
},
"owner": {
"data": {
"id": "",
"type": "users"
}
}
},
"type": "workflows"
}
}
```Bad request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Not found
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Get an existing WorkflowCopy```

# Path parametersexport workflow_id="CHANGE_ME"# Curl commandcurl -X GET "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}" \
-H "Accept: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}"

```
Get an existing Workflow```
"""
Get an existing Workflow returns "Successfully got a workflow." response
"""

from os import environ
from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = environ["WORKFLOW_DATA_ID"]

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.get_workflow(
workflow_id=WORKFLOW_DATA_ID,
)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" python3 "example.py"`
```
Get an existing Workflow```
# Get an existing Workflow returns "Successfully got a workflow." response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = ENV["WORKFLOW_DATA_ID"]
p api_instance.get_workflow(WORKFLOW_DATA_ID)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" rb "example.rb"`
```
Get an existing Workflow```
// Get an existing Workflow returns "Successfully got a workflow." response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	// there is a valid "workflow" in the system
	WorkflowDataID := os.Getenv("WORKFLOW_DATA_ID")

	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.GetWorkflow(ctx, WorkflowDataID)

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.GetWorkflow`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.GetWorkflow`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" go run "main.go"`
```
Get an existing Workflow```
// Get an existing Workflow returns "Successfully got a workflow." response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.GetWorkflowResponse;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

// there is a valid "workflow" in the system
String WORKFLOW_DATA_ID = System.getenv("WORKFLOW_DATA_ID");

try {
GetWorkflowResponse result = apiInstance.getWorkflow(WORKFLOW_DATA_ID);
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#getWorkflow");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" java "Example.java"`
```
Get an existing Workflow```
// Get an existing Workflow returns "Successfully got a workflow." response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;

#[tokio::main]
async fn main() {
// there is a valid "workflow" in the system
let workflow_data_id = std::env::var("WORKFLOW_DATA_ID").unwrap();
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api.get_workflow(workflow_data_id.clone()).await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" cargo run`
```
Get an existing Workflow```
/**
* Get an existing Workflow returns "Successfully got a workflow." response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

// there is a valid "workflow" in the system
const WORKFLOW_DATA_ID = process.env.WORKFLOW_DATA_ID as string;

const params: v2.WorkflowAutomationApiGetWorkflowRequest = {
workflowId: WORKFLOW_DATA_ID,
};

apiInstance
.getWorkflow(params)
.then((data: v2.GetWorkflowResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" tsc "example.ts"`
```## Create a Workflow- v2 (latest)
POST https://api.ap1.datadoghq.com/api/v2/workflowshttps://api.ap2.datadoghq.com/api/v2/workflowshttps://api.datadoghq.eu/api/v2/workflowshttps://api.ddog-gov.com/api/v2/workflowshttps://api.datadoghq.com/api/v2/workflowshttps://api.us3.datadoghq.com/api/v2/workflowshttps://api.us5.datadoghq.com/api/v2/workflows
### OverviewCreate a new workflow, returning the workflow ID. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_write` permission.### Request#### Body Data (required)
- Model
- Example
Expand All
Field
Type
Description
data [*required*]
object
Data related to the workflow.
attributes [*required*]
object
The definition of `WorkflowDataAttributes` object.
createdAt
date-time
When the workflow was created.
description
string
Description of the workflow.
name [*required*]
string
Name of the workflow.
published
boolean
Set the workflow to published or unpublished. Workflows in an unpublished state will only be executable via manual runs. Automatic triggers such as Schedule will not execute the workflow until it is published.
spec [*required*]
object
The spec defines what the workflow does.
annotations
[object]
A list of annotations used in the workflow. These are like sticky notes for your workflow!
display [*required*]
object
The definition of `AnnotationDisplay` object.
bounds
object
The definition of `AnnotationDisplayBounds` object.
height
double
The `bounds` `height`.
width
double
The `bounds` `width`.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
id [*required*]
string
The `Annotation` `id`.
markdownTextAnnotation [*required*]
object
The definition of `AnnotationMarkdownTextAnnotation` object.
text
string
The `markdownTextAnnotation` `text`.
connectionEnvs
[object]
A list of connections or connection groups used in the workflow.
connectionGroups
[object]
The `ConnectionEnv` `connectionGroups`.
connectionGroupId [*required*]
string
The `ConnectionGroup` `connectionGroupId`.
label [*required*]
string
The `ConnectionGroup` `label`.
tags [*required*]
[string]
The `ConnectionGroup` `tags`.
connections
[object]
The `ConnectionEnv` `connections`.
connectionId [*required*]
string
The `Connection` `connectionId`.
label [*required*]
string
The `Connection` `label`.
env [*required*]
enum
The definition of `ConnectionEnvEnv` object.
Allowed enum values: `default`handle
string
Unique identifier used to trigger workflows automatically in Datadog.
inputSchema
object
A list of input parameters for the workflow. These can be used as dynamic runtime values in your workflow.
parameters
[object]
The `InputSchema` `parameters`.
defaultValue

The `InputSchemaParameters` `defaultValue`.
description
string
The `InputSchemaParameters` `description`.
label
string
The `InputSchemaParameters` `label`.
name [*required*]
string
The `InputSchemaParameters` `name`.
type [*required*]
enum
The definition of `InputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT` outputSchema
object
A list of output parameters for the workflow.
parameters
[object]
The `OutputSchema` `parameters`.
defaultValue

The `OutputSchemaParameters` `defaultValue`.
description
string
The `OutputSchemaParameters` `description`.
label
string
The `OutputSchemaParameters` `label`.
name [*required*]
string
The `OutputSchemaParameters` `name`.
type [*required*]
enum
The definition of `OutputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT`value

The `OutputSchemaParameters` `value`.
steps
[object]
A `Step` is a sub-component of a workflow. Each `Step` performs an action.
actionId [*required*]
string
The unique identifier of an action.
completionGate
object
Used to create conditions before running subsequent actions.
completionCondition [*required*]
object
The definition of `CompletionCondition` object.
operand1 [*required*]

The `CompletionCondition` `operand1`.
operand2

The `CompletionCondition` `operand2`.
operator [*required*]
enum
The definition of `CompletionConditionOperator` object.
Allowed enum values: `OPERATOR_EQUAL,OPERATOR_NOT_EQUAL,OPERATOR_GREATER_THAN,OPERATOR_LESS_THAN,OPERATOR_GREATER_THAN_OR_EQUAL_TO,OPERATOR_LESS_THAN_OR_EQUAL_TO,OPERATOR_CONTAINS,OPERATOR_DOES_NOT_CONTAIN,OPERATOR_IS_NULL,OPERATOR_IS_NOT_NULL,OPERATOR_IS_EMPTY,OPERATOR_IS_NOT_EMPTY` retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
connectionLabel
string
The unique identifier of a connection defined in the spec.
display
object
The definition of `StepDisplay` object.
bounds
object
The definition of `StepDisplayBounds` object.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
errorHandlers
[object]
The `Step` `errorHandlers`.
fallbackStepName [*required*]
string
The `ErrorHandler` `fallbackStepName`.
retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
name [*required*]
string
Name of the step.
outboundEdges
[object]
A list of subsequent actions to run.
branchName [*required*]
string
The `OutboundEdge` `branchName`.
nextStepName [*required*]
string
The `OutboundEdge` `nextStepName`.
parameters
[object]
A list of inputs for an action.
name [*required*]
string
The `Parameter` `name`.
value [*required*]

The `Parameter` `value`.
readinessGate
object
Used to merge multiple branches into a single branch.
thresholdType [*required*]
enum
The definition of `ReadinessGateThresholdType` object.
Allowed enum values: `ANY,ALL` triggers
[ <oneOf>]
The list of triggers that activate this workflow. At least one trigger is required, and each trigger type may appear at most once.
Option 1
object
Schema for an API-based trigger.
apiTrigger [*required*]
object
Trigger a workflow from an API request. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 2
object
Schema for an App-based trigger.
appTrigger [*required*]
object
Trigger a workflow from an App.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 3
object
Schema for a Case-based trigger.
caseTrigger [*required*]
object
Trigger a workflow from a Case. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 4
object
Schema for a Change Event-based trigger.
changeEventTrigger [*required*]
object
Trigger a workflow from a Change Event.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 5
object
Schema for a Database Monitoring-based trigger.
databaseMonitoringTrigger [*required*]
object
Trigger a workflow from Database Monitoring.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 6
object
Schema for a Datastore-based trigger.
datastoreTrigger [*required*]
object
Trigger a workflow from a Datastore. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 7
object
Schema for a Dashboard-based trigger.
dashboardTrigger [*required*]
object
Trigger a workflow from a Dashboard.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 8
object
Schema for a GitHub webhook-based trigger.
githubWebhookTrigger [*required*]
object
Trigger a workflow from a GitHub webhook. To trigger a workflow from GitHub, you must set a `webhookSecret`. In your GitHub Webhook Settings, set the Payload URL to "base_url"/api/v2/workflows/"workflow_id"/webhook?orgId="org_id", select application/json for the content type, and be highly recommend enabling SSL verification for security. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 9
object
Schema for an Incident-based trigger.
incidentTrigger [*required*]
object
Trigger a workflow from an Incident. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 10
object
Schema for a Monitor-based trigger.
monitorTrigger [*required*]
object
Trigger a workflow from a Monitor. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 11
object
Schema for a Notebook-based trigger.
notebookTrigger [*required*]
object
Trigger a workflow from a Notebook.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 12
object
Schema for a Schedule-based trigger.
scheduleTrigger [*required*]
object
Trigger a workflow from a Schedule. The workflow must be published.
rruleExpression [*required*]
string
Recurrence rule expression for scheduling.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 13
object
Schema for a Security-based trigger.
securityTrigger [*required*]
object
Trigger a workflow from a Security Signal or Finding. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 14
object
Schema for a Self Service-based trigger.
selfServiceTrigger [*required*]
object
Trigger a workflow from Self Service.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 15
object
Schema for a Slack-based trigger.
slackTrigger [*required*]
object
Trigger a workflow from Slack. The workflow must be published.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 16
object
Schema for a Software Catalog-based trigger.
softwareCatalogTrigger [*required*]
object
Trigger a workflow from Software Catalog.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 17
object
Schema for a Workflow-based trigger.
startStepNames
[string]
A list of steps that run first after a trigger fires.
workflowTrigger [*required*]
object
Trigger a workflow from the Datadog UI. Only required if no other trigger exists.
tags
[string]
Tags of the workflow.
updatedAt
date-time
When the workflow was last updated.
webhookSecret
string
If a Webhook trigger is defined on this workflow, a webhookSecret is required and should be provided here.
id
string
The workflow identifier
relationships
object
The definition of `WorkflowDataRelationships` object.
creator
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users` owner
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users`type [*required*]
enum
The definition of `WorkflowDataType` object.
Allowed enum values: `workflows````
{
"data": {
"attributes": {
"description": "A sample workflow.",
"name": "Example Workflow",
"published": true,
"spec": {
"connectionEnvs": [
{
"connections": [
{
"connectionId": "11111111-1111-1111-1111-111111111111",
"label": "INTEGRATION_DATADOG"
}
],
"env": "default"
}
],
"inputSchema": {
"parameters": [
{
"defaultValue": "default",
"name": "input",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"name": "output",
"type": "ARRAY_OBJECT",
"value": "outputValue"
}
]
},
"steps": [
{
"actionId": "com.datadoghq.dd.monitor.listMonitors",
"connectionLabel": "INTEGRATION_DATADOG",
"name": "Step1",
"outboundEdges": [
{
"branchName": "main",
"nextStepName": "Step2"
}
],
"parameters": [
{
"name": "tags",
"value": "service:monitoring"
}
]
},
{
"actionId": "com.datadoghq.core.noop",
"name": "Step2"
}
],
"triggers": [
{
"monitorTrigger": {
"rateLimit": {
"count": 1,
"interval": "3600s"
}
},
"startStepNames": [
"Step1"
]
},
{
"startStepNames": [
"Step1"
],
"githubWebhookTrigger": {}
}
]
},
"tags": [
"team:infra",
"service:monitoring",
"foo:bar"
]
},
"type": "workflows"
}
}
```### Response- 201
- 400
- 403
- 429
Successfully created a workflow.
- Model
- Example
The response object after creating a new workflow.
Expand All
Field
Type
Description
data [*required*]
object
Data related to the workflow.
attributes [*required*]
object
The definition of `WorkflowDataAttributes` object.
createdAt
date-time
When the workflow was created.
description
string
Description of the workflow.
name [*required*]
string
Name of the workflow.
published
boolean
Set the workflow to published or unpublished. Workflows in an unpublished state will only be executable via manual runs. Automatic triggers such as Schedule will not execute the workflow until it is published.
spec [*required*]
object
The spec defines what the workflow does.
annotations
[object]
A list of annotations used in the workflow. These are like sticky notes for your workflow!
display [*required*]
object
The definition of `AnnotationDisplay` object.
bounds
object
The definition of `AnnotationDisplayBounds` object.
height
double
The `bounds` `height`.
width
double
The `bounds` `width`.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
id [*required*]
string
The `Annotation` `id`.
markdownTextAnnotation [*required*]
object
The definition of `AnnotationMarkdownTextAnnotation` object.
text
string
The `markdownTextAnnotation` `text`.
connectionEnvs
[object]
A list of connections or connection groups used in the workflow.
connectionGroups
[object]
The `ConnectionEnv` `connectionGroups`.
connectionGroupId [*required*]
string
The `ConnectionGroup` `connectionGroupId`.
label [*required*]
string
The `ConnectionGroup` `label`.
tags [*required*]
[string]
The `ConnectionGroup` `tags`.
connections
[object]
The `ConnectionEnv` `connections`.
connectionId [*required*]
string
The `Connection` `connectionId`.
label [*required*]
string
The `Connection` `label`.
env [*required*]
enum
The definition of `ConnectionEnvEnv` object.
Allowed enum values: `default`handle
string
Unique identifier used to trigger workflows automatically in Datadog.
inputSchema
object
A list of input parameters for the workflow. These can be used as dynamic runtime values in your workflow.
parameters
[object]
The `InputSchema` `parameters`.
defaultValue

The `InputSchemaParameters` `defaultValue`.
description
string
The `InputSchemaParameters` `description`.
label
string
The `InputSchemaParameters` `label`.
name [*required*]
string
The `InputSchemaParameters` `name`.
type [*required*]
enum
The definition of `InputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT` outputSchema
object
A list of output parameters for the workflow.
parameters
[object]
The `OutputSchema` `parameters`.
defaultValue

The `OutputSchemaParameters` `defaultValue`.
description
string
The `OutputSchemaParameters` `description`.
label
string
The `OutputSchemaParameters` `label`.
name [*required*]
string
The `OutputSchemaParameters` `name`.
type [*required*]
enum
The definition of `OutputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT`value

The `OutputSchemaParameters` `value`.
steps
[object]
A `Step` is a sub-component of a workflow. Each `Step` performs an action.
actionId [*required*]
string
The unique identifier of an action.
completionGate
object
Used to create conditions before running subsequent actions.
completionCondition [*required*]
object
The definition of `CompletionCondition` object.
operand1 [*required*]

The `CompletionCondition` `operand1`.
operand2

The `CompletionCondition` `operand2`.
operator [*required*]
enum
The definition of `CompletionConditionOperator` object.
Allowed enum values: `OPERATOR_EQUAL,OPERATOR_NOT_EQUAL,OPERATOR_GREATER_THAN,OPERATOR_LESS_THAN,OPERATOR_GREATER_THAN_OR_EQUAL_TO,OPERATOR_LESS_THAN_OR_EQUAL_TO,OPERATOR_CONTAINS,OPERATOR_DOES_NOT_CONTAIN,OPERATOR_IS_NULL,OPERATOR_IS_NOT_NULL,OPERATOR_IS_EMPTY,OPERATOR_IS_NOT_EMPTY` retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
connectionLabel
string
The unique identifier of a connection defined in the spec.
display
object
The definition of `StepDisplay` object.
bounds
object
The definition of `StepDisplayBounds` object.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
errorHandlers
[object]
The `Step` `errorHandlers`.
fallbackStepName [*required*]
string
The `ErrorHandler` `fallbackStepName`.
retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
name [*required*]
string
Name of the step.
outboundEdges
[object]
A list of subsequent actions to run.
branchName [*required*]
string
The `OutboundEdge` `branchName`.
nextStepName [*required*]
string
The `OutboundEdge` `nextStepName`.
parameters
[object]
A list of inputs for an action.
name [*required*]
string
The `Parameter` `name`.
value [*required*]

The `Parameter` `value`.
readinessGate
object
Used to merge multiple branches into a single branch.
thresholdType [*required*]
enum
The definition of `ReadinessGateThresholdType` object.
Allowed enum values: `ANY,ALL` triggers
[ <oneOf>]
The list of triggers that activate this workflow. At least one trigger is required, and each trigger type may appear at most once.
Option 1
object
Schema for an API-based trigger.
apiTrigger [*required*]
object
Trigger a workflow from an API request. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 2
object
Schema for an App-based trigger.
appTrigger [*required*]
object
Trigger a workflow from an App.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 3
object
Schema for a Case-based trigger.
caseTrigger [*required*]
object
Trigger a workflow from a Case. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 4
object
Schema for a Change Event-based trigger.
changeEventTrigger [*required*]
object
Trigger a workflow from a Change Event.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 5
object
Schema for a Database Monitoring-based trigger.
databaseMonitoringTrigger [*required*]
object
Trigger a workflow from Database Monitoring.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 6
object
Schema for a Datastore-based trigger.
datastoreTrigger [*required*]
object
Trigger a workflow from a Datastore. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 7
object
Schema for a Dashboard-based trigger.
dashboardTrigger [*required*]
object
Trigger a workflow from a Dashboard.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 8
object
Schema for a GitHub webhook-based trigger.
githubWebhookTrigger [*required*]
object
Trigger a workflow from a GitHub webhook. To trigger a workflow from GitHub, you must set a `webhookSecret`. In your GitHub Webhook Settings, set the Payload URL to "base_url"/api/v2/workflows/"workflow_id"/webhook?orgId="org_id", select application/json for the content type, and be highly recommend enabling SSL verification for security. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 9
object
Schema for an Incident-based trigger.
incidentTrigger [*required*]
object
Trigger a workflow from an Incident. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 10
object
Schema for a Monitor-based trigger.
monitorTrigger [*required*]
object
Trigger a workflow from a Monitor. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 11
object
Schema for a Notebook-based trigger.
notebookTrigger [*required*]
object
Trigger a workflow from a Notebook.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 12
object
Schema for a Schedule-based trigger.
scheduleTrigger [*required*]
object
Trigger a workflow from a Schedule. The workflow must be published.
rruleExpression [*required*]
string
Recurrence rule expression for scheduling.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 13
object
Schema for a Security-based trigger.
securityTrigger [*required*]
object
Trigger a workflow from a Security Signal or Finding. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 14
object
Schema for a Self Service-based trigger.
selfServiceTrigger [*required*]
object
Trigger a workflow from Self Service.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 15
object
Schema for a Slack-based trigger.
slackTrigger [*required*]
object
Trigger a workflow from Slack. The workflow must be published.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 16
object
Schema for a Software Catalog-based trigger.
softwareCatalogTrigger [*required*]
object
Trigger a workflow from Software Catalog.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 17
object
Schema for a Workflow-based trigger.
startStepNames
[string]
A list of steps that run first after a trigger fires.
workflowTrigger [*required*]
object
Trigger a workflow from the Datadog UI. Only required if no other trigger exists.
tags
[string]
Tags of the workflow.
updatedAt
date-time
When the workflow was last updated.
webhookSecret
string
If a Webhook trigger is defined on this workflow, a webhookSecret is required and should be provided here.
id
string
The workflow identifier
relationships
object
The definition of `WorkflowDataRelationships` object.
creator
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users` owner
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users`type [*required*]
enum
The definition of `WorkflowDataType` object.
Allowed enum values: `workflows````
{
"data": {
"attributes": {
"createdAt": "2019-09-19T10:00:00.000Z",
"description": "string",
"name": "",
"published": false,
"spec": {
"annotations": [
{
"display": {
"bounds": {
"height": "number",
"width": "number",
"x": "number",
"y": "number"
}
},
"id": "",
"markdownTextAnnotation": {
"text": "string"
}
}
],
"connectionEnvs": [
{
"connectionGroups": [
{
"connectionGroupId": "",
"label": "",
"tags": [
""
]
}
],
"connections": [
{
"connectionId": "",
"label": ""
}
],
"env": "default"
}
],
"handle": "string",
"inputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING",
"value": "undefined"
}
]
},
"steps": [
{
"actionId": "",
"completionGate": {
"completionCondition": {
"operand1": "undefined",
"operand2": "undefined",
"operator": "OPERATOR_EQUAL"
},
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
},
"connectionLabel": "string",
"display": {
"bounds": {
"x": "number",
"y": "number"
}
},
"errorHandlers": [
{
"fallbackStepName": "",
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
}
],
"name": "",
"outboundEdges": [
{
"branchName": "",
"nextStepName": ""
}
],
"parameters": [
{
"name": "",
"value": "undefined"
}
],
"readinessGate": {
"thresholdType": "ANY"
}
}
],
"triggers": [
{
"apiTrigger": {
"rateLimit": {
"count": "integer",
"interval": "string"
}
},
"startStepNames": [
""
]
}
]
},
"tags": [],
"updatedAt": "2019-09-19T10:00:00.000Z",
"webhookSecret": "string"
},
"id": "string",
"relationships": {
"creator": {
"data": {
"id": "",
"type": "users"
}
},
"owner": {
"data": {
"id": "",
"type": "users"
}
}
},
"type": "workflows"
}
}
```Bad request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Create a Workflow returns "Successfully created a workflow." responseCopy```

# Curl commandcurl -X POST "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows" \
-H "Accept: application/json" \
-H "Content-Type: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
-d @- << EOF
{
"data": {
"attributes": {
"description": "A sample workflow.",
"name": "Example Workflow",
"published": true,
"spec": {
"connectionEnvs": [
{
"connections": [
{
"connectionId": "11111111-1111-1111-1111-111111111111",
"label": "INTEGRATION_DATADOG"
}
],
"env": "default"
}
],
"inputSchema": {
"parameters": [
{
"defaultValue": "default",
"name": "input",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"name": "output",
"type": "ARRAY_OBJECT",
"value": "outputValue"
}
]
},
"steps": [
{
"actionId": "com.datadoghq.dd.monitor.listMonitors",
"connectionLabel": "INTEGRATION_DATADOG",
"name": "Step1",
"outboundEdges": [
{
"branchName": "main",
"nextStepName": "Step2"
}
],
"parameters": [
{
"name": "tags",
"value": "service:monitoring"
}
]
},
{
"actionId": "com.datadoghq.core.noop",
"name": "Step2"
}
],
"triggers": [
{
"monitorTrigger": {
"rateLimit": {
"count": 1,
"interval": "3600s"
}
},
"startStepNames": [
"Step1"
]
},
{
"startStepNames": [
"Step1"
],
"githubWebhookTrigger": {}
}
]
},
"tags": [
"team:infra",
"service:monitoring",
"foo:bar"
]
},
"type": "workflows"
}
}
EOF

```
Create a Workflow returns "Successfully created a workflow." response```
// Create a Workflow returns "Successfully created a workflow." response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	body := datadogV2.CreateWorkflowRequest{
		Data: datadogV2.WorkflowData{
			Attributes: datadogV2.WorkflowDataAttributes{
				Description: datadog.PtrString("A sample workflow."),
				Name: "Example Workflow",
				Published: datadog.PtrBool(true),
				Spec: datadogV2.Spec{
					ConnectionEnvs: []datadogV2.ConnectionEnv{
						{
							Connections: []datadogV2.Connection{
								{
									ConnectionId: "11111111-1111-1111-1111-111111111111",
									Label: "INTEGRATION_DATADOG",
								},
							},
							Env: datadogV2.CONNECTIONENVENV_DEFAULT,
						},
					},
					InputSchema: &datadogV2.InputSchema{
						Parameters: []datadogV2.InputSchemaParameters{
							{
								DefaultValue: "default",
								Name: "input",
								Type: datadogV2.INPUTSCHEMAPARAMETERSTYPE_STRING,
							},
						},
					},
					OutputSchema: &datadogV2.OutputSchema{
						Parameters: []datadogV2.OutputSchemaParameters{
							{
								Name: "output",
								Type: datadogV2.OUTPUTSCHEMAPARAMETERSTYPE_ARRAY_OBJECT,
								Value: "outputValue",
							},
						},
					},
					Steps: []datadogV2.Step{
						{
							ActionId: "com.datadoghq.dd.monitor.listMonitors",
							ConnectionLabel: datadog.PtrString("INTEGRATION_DATADOG"),
							Name: "Step1",
							OutboundEdges: []datadogV2.OutboundEdge{
								{
									BranchName: "main",
									NextStepName: "Step2",
								},
							},
							Parameters: []datadogV2.Parameter{
								{
									Name: "tags",
									Value: "service:monitoring",
								},
							},
						},
						{
							ActionId: "com.datadoghq.core.noop",
							Name: "Step2",
						},
					},
					Triggers: []datadogV2.Trigger{
						datadogV2.Trigger{
							MonitorTriggerWrapper: &datadogV2.MonitorTriggerWrapper{
								MonitorTrigger: datadogV2.MonitorTrigger{
									RateLimit: &datadogV2.TriggerRateLimit{
										Count: datadog.PtrInt64(1),
										Interval: datadog.PtrString("3600s"),
									},
								},
								StartStepNames: []string{
									"Step1",
								},
							}},
						datadogV2.Trigger{
							GithubWebhookTriggerWrapper: &datadogV2.GithubWebhookTriggerWrapper{
								StartStepNames: []string{
									"Step1",
								},
								GithubWebhookTrigger: datadogV2.GithubWebhookTrigger{},
							}},
					},
				},
				Tags: []string{
					"team:infra",
					"service:monitoring",
					"foo:bar",
				},
			},
			Type: datadogV2.WORKFLOWDATATYPE_WORKFLOWS,
		},
	}
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.CreateWorkflow(ctx, body)

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.CreateWorkflow`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.CreateWorkflow`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" go run "main.go"`
```
Create a Workflow returns "Successfully created a workflow." response```
// Create a Workflow returns "Successfully created a workflow." response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.Connection;
import com.datadog.api.client.v2.model.ConnectionEnv;
import com.datadog.api.client.v2.model.ConnectionEnvEnv;
import com.datadog.api.client.v2.model.CreateWorkflowRequest;
import com.datadog.api.client.v2.model.CreateWorkflowResponse;
import com.datadog.api.client.v2.model.GithubWebhookTrigger;
import com.datadog.api.client.v2.model.GithubWebhookTriggerWrapper;
import com.datadog.api.client.v2.model.InputSchema;
import com.datadog.api.client.v2.model.InputSchemaParameters;
import com.datadog.api.client.v2.model.InputSchemaParametersType;
import com.datadog.api.client.v2.model.MonitorTrigger;
import com.datadog.api.client.v2.model.MonitorTriggerWrapper;
import com.datadog.api.client.v2.model.OutboundEdge;
import com.datadog.api.client.v2.model.OutputSchema;
import com.datadog.api.client.v2.model.OutputSchemaParameters;
import com.datadog.api.client.v2.model.OutputSchemaParametersType;
import com.datadog.api.client.v2.model.Parameter;
import com.datadog.api.client.v2.model.Spec;
import com.datadog.api.client.v2.model.Step;
import com.datadog.api.client.v2.model.Trigger;
import com.datadog.api.client.v2.model.TriggerRateLimit;
import com.datadog.api.client.v2.model.WorkflowData;
import com.datadog.api.client.v2.model.WorkflowDataAttributes;
import com.datadog.api.client.v2.model.WorkflowDataType;
import java.util.Arrays;
import java.util.Collections;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

CreateWorkflowRequest body =
new CreateWorkflowRequest()
.data(
new WorkflowData()
.attributes(
new WorkflowDataAttributes()
.description("A sample workflow.")
.name("Example Workflow")
.published(true)
.spec(
new Spec()
.connectionEnvs(
Collections.singletonList(
new ConnectionEnv()
.connections(
Collections.singletonList(
new Connection()
.connectionId(
"11111111-1111-1111-1111-111111111111")
.label("INTEGRATION_DATADOG")))
.env(ConnectionEnvEnv.DEFAULT)))
.inputSchema(
new InputSchema()
.parameters(
Collections.singletonList(
new InputSchemaParameters()
.defaultValue("default")
.name("input")
.type(InputSchemaParametersType.STRING))))
.outputSchema(
new OutputSchema()
.parameters(
Collections.singletonList(
new OutputSchemaParameters()
.name("output")
.type(
OutputSchemaParametersType.ARRAY_OBJECT)
.value("outputValue"))))
.steps(
Arrays.asList(
new Step()
.actionId("com.datadoghq.dd.monitor.listMonitors")
.connectionLabel("INTEGRATION_DATADOG")
.name("Step1")
.outboundEdges(
Collections.singletonList(
new OutboundEdge()
.branchName("main")
.nextStepName("Step2")))
.parameters(
Collections.singletonList(
new Parameter()
.name("tags")
.value("service:monitoring"))),
new Step()
.actionId("com.datadoghq.core.noop")
.name("Step2")))
.triggers(
Arrays.asList(
new Trigger(
new MonitorTriggerWrapper()
.monitorTrigger(
new MonitorTrigger()
.rateLimit(
new TriggerRateLimit()
.count(1L)
.interval("3600s")))
.startStepNames(
Collections.singletonList("Step1"))),
new Trigger(
new GithubWebhookTriggerWrapper()
.startStepNames(
Collections.singletonList("Step1"))
.githubWebhookTrigger(
new GithubWebhookTrigger())))))
.tags(Arrays.asList("team:infra", "service:monitoring", "foo:bar")))
.type(WorkflowDataType.WORKFLOWS));

try {
CreateWorkflowResponse result = apiInstance.createWorkflow(body);
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#createWorkflow");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" java "Example.java"`
```
Create a Workflow returns "Successfully created a workflow." response```
"""
Create a Workflow returns "Successfully created a workflow." response
"""

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi
from datadog_api_client.v2.model.connection import Connection
from datadog_api_client.v2.model.connection_env import ConnectionEnv
from datadog_api_client.v2.model.connection_env_env import ConnectionEnvEnv
from datadog_api_client.v2.model.create_workflow_request import CreateWorkflowRequest
from datadog_api_client.v2.model.github_webhook_trigger import GithubWebhookTrigger
from datadog_api_client.v2.model.github_webhook_trigger_wrapper import GithubWebhookTriggerWrapper
from datadog_api_client.v2.model.input_schema import InputSchema
from datadog_api_client.v2.model.input_schema_parameters import InputSchemaParameters
from datadog_api_client.v2.model.input_schema_parameters_type import InputSchemaParametersType
from datadog_api_client.v2.model.monitor_trigger import MonitorTrigger
from datadog_api_client.v2.model.monitor_trigger_wrapper import MonitorTriggerWrapper
from datadog_api_client.v2.model.outbound_edge import OutboundEdge
from datadog_api_client.v2.model.output_schema import OutputSchema
from datadog_api_client.v2.model.output_schema_parameters import OutputSchemaParameters
from datadog_api_client.v2.model.output_schema_parameters_type import OutputSchemaParametersType
from datadog_api_client.v2.model.parameter import Parameter
from datadog_api_client.v2.model.spec import Spec
from datadog_api_client.v2.model.step import Step
from datadog_api_client.v2.model.trigger_rate_limit import TriggerRateLimit
from datadog_api_client.v2.model.workflow_data import WorkflowData
from datadog_api_client.v2.model.workflow_data_attributes import WorkflowDataAttributes
from datadog_api_client.v2.model.workflow_data_type import WorkflowDataType

body = CreateWorkflowRequest(
data=WorkflowData(
attributes=WorkflowDataAttributes(
description="A sample workflow.",
name="Example Workflow",
published=True,
spec=Spec(
connection_envs=[
ConnectionEnv(
connections=[
Connection(
connection_id="11111111-1111-1111-1111-111111111111",
label="INTEGRATION_DATADOG",
),
],
env=ConnectionEnvEnv.DEFAULT,
),
],
input_schema=InputSchema(
parameters=[
InputSchemaParameters(
default_value="default",
name="input",
type=InputSchemaParametersType.STRING,
),
],
),
output_schema=OutputSchema(
parameters=[
OutputSchemaParameters(
name="output",
type=OutputSchemaParametersType.ARRAY_OBJECT,
value="outputValue",
),
],
),
steps=[
Step(
action_id="com.datadoghq.dd.monitor.listMonitors",
connection_label="INTEGRATION_DATADOG",
name="Step1",
outbound_edges=[
OutboundEdge(
branch_name="main",
next_step_name="Step2",
),
],
parameters=[
Parameter(
name="tags",
value="service:monitoring",
),
],
),
Step(
action_id="com.datadoghq.core.noop",
name="Step2",
),
],
triggers=[
MonitorTriggerWrapper(
monitor_trigger=MonitorTrigger(
rate_limit=TriggerRateLimit(
count=1,
interval="3600s",
),
),
start_step_names=[
"Step1",
],
),
GithubWebhookTriggerWrapper(
start_step_names=[
"Step1",
],
github_webhook_trigger=GithubWebhookTrigger(),
),
],
),
tags=[
"team:infra",
"service:monitoring",
"foo:bar",
],
),
type=WorkflowDataType.WORKFLOWS,
),
)

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.create_workflow(body=body)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" python3 "example.py"`
```
Create a Workflow returns "Successfully created a workflow." response```
# Create a Workflow returns "Successfully created a workflow." response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new

body = DatadogAPIClient::V2::CreateWorkflowRequest.new({
data: DatadogAPIClient::V2::WorkflowData.new({
attributes: DatadogAPIClient::V2::WorkflowDataAttributes.new({
description: "A sample workflow.",
name: "Example Workflow",
published: true,
spec: DatadogAPIClient::V2::Spec.new({
connection_envs: [
DatadogAPIClient::V2::ConnectionEnv.new({
connections: [
DatadogAPIClient::V2::Connection.new({
connection_id: "11111111-1111-1111-1111-111111111111",
label: "INTEGRATION_DATADOG",
}),
],
env: DatadogAPIClient::V2::ConnectionEnvEnv::DEFAULT,
}),
],
input_schema: DatadogAPIClient::V2::InputSchema.new({
parameters: [
DatadogAPIClient::V2::InputSchemaParameters.new({
default_value: "default",
name: "input",
type: DatadogAPIClient::V2::InputSchemaParametersType::STRING,
}),
],
}),
output_schema: DatadogAPIClient::V2::OutputSchema.new({
parameters: [
DatadogAPIClient::V2::OutputSchemaParameters.new({
name: "output",
type: DatadogAPIClient::V2::OutputSchemaParametersType::ARRAY_OBJECT,
value: "outputValue",
}),
],
}),
steps: [
DatadogAPIClient::V2::Step.new({
action_id: "com.datadoghq.dd.monitor.listMonitors",
connection_label: "INTEGRATION_DATADOG",
name: "Step1",
outbound_edges: [
DatadogAPIClient::V2::OutboundEdge.new({
branch_name: "main",
next_step_name: "Step2",
}),
],
parameters: [
DatadogAPIClient::V2::Parameter.new({
name: "tags",
value: "service:monitoring",
}),
],
}),
DatadogAPIClient::V2::Step.new({
action_id: "com.datadoghq.core.noop",
name: "Step2",
}),
],
triggers: [
DatadogAPIClient::V2::MonitorTriggerWrapper.new({
monitor_trigger: DatadogAPIClient::V2::MonitorTrigger.new({
rate_limit: DatadogAPIClient::V2::TriggerRateLimit.new({
count: 1,
interval: "3600s",
}),
}),
start_step_names: [
"Step1",
],
}),
DatadogAPIClient::V2::GithubWebhookTriggerWrapper.new({
start_step_names: [
"Step1",
],
github_webhook_trigger: DatadogAPIClient::V2::GithubWebhookTrigger.new({}),
}),
],
}),
tags: [
"team:infra",
"service:monitoring",
"foo:bar",
],
}),
type: DatadogAPIClient::V2::WorkflowDataType::WORKFLOWS,
}),
})
p api_instance.create_workflow(body)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" rb "example.rb"`
```
Create a Workflow returns "Successfully created a workflow." response```
// Create a Workflow returns "Successfully created a workflow." response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;
use datadog_api_client::datadogV2::model::Connection;
use datadog_api_client::datadogV2::model::ConnectionEnv;
use datadog_api_client::datadogV2::model::ConnectionEnvEnv;
use datadog_api_client::datadogV2::model::CreateWorkflowRequest;
use datadog_api_client::datadogV2::model::GithubWebhookTrigger;
use datadog_api_client::datadogV2::model::GithubWebhookTriggerWrapper;
use datadog_api_client::datadogV2::model::InputSchema;
use datadog_api_client::datadogV2::model::InputSchemaParameters;
use datadog_api_client::datadogV2::model::InputSchemaParametersType;
use datadog_api_client::datadogV2::model::MonitorTrigger;
use datadog_api_client::datadogV2::model::MonitorTriggerWrapper;
use datadog_api_client::datadogV2::model::OutboundEdge;
use datadog_api_client::datadogV2::model::OutputSchema;
use datadog_api_client::datadogV2::model::OutputSchemaParameters;
use datadog_api_client::datadogV2::model::OutputSchemaParametersType;
use datadog_api_client::datadogV2::model::Parameter;
use datadog_api_client::datadogV2::model::Spec;
use datadog_api_client::datadogV2::model::Step;
use datadog_api_client::datadogV2::model::Trigger;
use datadog_api_client::datadogV2::model::TriggerRateLimit;
use datadog_api_client::datadogV2::model::WorkflowData;
use datadog_api_client::datadogV2::model::WorkflowDataAttributes;
use datadog_api_client::datadogV2::model::WorkflowDataType;
use serde_json::Value;

#[tokio::main]
async fn main() {
let body = CreateWorkflowRequest::new(WorkflowData::new(
WorkflowDataAttributes::new(
"Example Workflow".to_string(),
Spec::new()
.connection_envs(vec![ConnectionEnv::new(ConnectionEnvEnv::DEFAULT)
.connections(vec![Connection::new(
"11111111-1111-1111-1111-111111111111".to_string(),
"INTEGRATION_DATADOG".to_string(),
)])])
.input_schema(InputSchema::new().parameters(vec![
InputSchemaParameters::new(
"input".to_string(),
InputSchemaParametersType::STRING,
).default_value(Value::from("default"))
]))
.output_schema(OutputSchema::new().parameters(vec![
OutputSchemaParameters::new(
"output".to_string(),
OutputSchemaParametersType::ARRAY_OBJECT,
).value(Value::from("outputValue"))
]))
.steps(vec![
Step::new(
"com.datadoghq.dd.monitor.listMonitors".to_string(),
"Step1".to_string(),
)
.connection_label("INTEGRATION_DATADOG".to_string())
.outbound_edges(vec![OutboundEdge::new(
"main".to_string(),
"Step2".to_string(),
)])
.parameters(vec![Parameter::new(
"tags".to_string(),
Value::from("service:monitoring"),
)]),
Step::new("com.datadoghq.core.noop".to_string(), "Step2".to_string()),
])
.triggers(vec![
Trigger::MonitorTriggerWrapper(Box::new(
MonitorTriggerWrapper::new(
MonitorTrigger::new().rate_limit(
TriggerRateLimit::new()
.count(1)
.interval("3600s".to_string()),
),
)
.start_step_names(vec!["Step1".to_string()]),
)),
Trigger::GithubWebhookTriggerWrapper(Box::new(
GithubWebhookTriggerWrapper::new(GithubWebhookTrigger::new())
.start_step_names(vec!["Step1".to_string()]),
)),
]),
)
.description("A sample workflow.".to_string())
.published(true)
.tags(vec![
"team:infra".to_string(),
"service:monitoring".to_string(),
"foo:bar".to_string(),
]),
WorkflowDataType::WORKFLOWS,
));
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api.create_workflow(body).await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" cargo run`
```
Create a Workflow returns "Successfully created a workflow." response```
/**
* Create a Workflow returns "Successfully created a workflow." response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

const params: v2.WorkflowAutomationApiCreateWorkflowRequest = {
body: {
data: {
attributes: {
description: "A sample workflow.",
name: "Example Workflow",
published: true,
spec: {
connectionEnvs: [
{
connections: [
{
connectionId: "11111111-1111-1111-1111-111111111111",
label: "INTEGRATION_DATADOG",
},
],
env: "default",
},
],
inputSchema: {
parameters: [
{
defaultValue: "default",
name: "input",
type: "STRING",
},
],
},
outputSchema: {
parameters: [
{
name: "output",
type: "ARRAY_OBJECT",
value: "outputValue",
},
],
},
steps: [
{
actionId: "com.datadoghq.dd.monitor.listMonitors",
connectionLabel: "INTEGRATION_DATADOG",
name: "Step1",
outboundEdges: [
{
branchName: "main",
nextStepName: "Step2",
},
],
parameters: [
{
name: "tags",
value: "service:monitoring",
},
],
},
{
actionId: "com.datadoghq.core.noop",
name: "Step2",
},
],
triggers: [
{
monitorTrigger: {
rateLimit: {
count: 1,
interval: "3600s",
},
},
startStepNames: ["Step1"],
},
{
startStepNames: ["Step1"],
githubWebhookTrigger: {},
},
],
},
tags: ["team:infra", "service:monitoring", "foo:bar"],
},
type: "workflows",
},
},
};

apiInstance
.createWorkflow(params)
.then((data: v2.CreateWorkflowResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" tsc "example.ts"`
```## Update an existing Workflow- v2 (latest)
PATCH https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}https://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}https://api.datadoghq.eu/api/v2/workflows/{workflow_id}https://api.ddog-gov.com/api/v2/workflows/{workflow_id}https://api.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}
### OverviewUpdate a workflow by ID. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_write` permission.### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
### Request#### Body Data (required)
- Model
- Example
Expand All
Field
Type
Description
data [*required*]
object
Data related to the workflow being updated.
attributes [*required*]
object
The definition of `WorkflowDataUpdateAttributes` object.
createdAt
date-time
When the workflow was created.
description
string
Description of the workflow.
name
string
Name of the workflow.
published
boolean
Set the workflow to published or unpublished. Workflows in an unpublished state will only be executable via manual runs. Automatic triggers such as Schedule will not execute the workflow until it is published.
spec
object
The spec defines what the workflow does.
annotations
[object]
A list of annotations used in the workflow. These are like sticky notes for your workflow!
display [*required*]
object
The definition of `AnnotationDisplay` object.
bounds
object
The definition of `AnnotationDisplayBounds` object.
height
double
The `bounds` `height`.
width
double
The `bounds` `width`.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
id [*required*]
string
The `Annotation` `id`.
markdownTextAnnotation [*required*]
object
The definition of `AnnotationMarkdownTextAnnotation` object.
text
string
The `markdownTextAnnotation` `text`.
connectionEnvs
[object]
A list of connections or connection groups used in the workflow.
connectionGroups
[object]
The `ConnectionEnv` `connectionGroups`.
connectionGroupId [*required*]
string
The `ConnectionGroup` `connectionGroupId`.
label [*required*]
string
The `ConnectionGroup` `label`.
tags [*required*]
[string]
The `ConnectionGroup` `tags`.
connections
[object]
The `ConnectionEnv` `connections`.
connectionId [*required*]
string
The `Connection` `connectionId`.
label [*required*]
string
The `Connection` `label`.
env [*required*]
enum
The definition of `ConnectionEnvEnv` object.
Allowed enum values: `default`handle
string
Unique identifier used to trigger workflows automatically in Datadog.
inputSchema
object
A list of input parameters for the workflow. These can be used as dynamic runtime values in your workflow.
parameters
[object]
The `InputSchema` `parameters`.
defaultValue

The `InputSchemaParameters` `defaultValue`.
description
string
The `InputSchemaParameters` `description`.
label
string
The `InputSchemaParameters` `label`.
name [*required*]
string
The `InputSchemaParameters` `name`.
type [*required*]
enum
The definition of `InputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT` outputSchema
object
A list of output parameters for the workflow.
parameters
[object]
The `OutputSchema` `parameters`.
defaultValue

The `OutputSchemaParameters` `defaultValue`.
description
string
The `OutputSchemaParameters` `description`.
label
string
The `OutputSchemaParameters` `label`.
name [*required*]
string
The `OutputSchemaParameters` `name`.
type [*required*]
enum
The definition of `OutputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT`value

The `OutputSchemaParameters` `value`.
steps
[object]
A `Step` is a sub-component of a workflow. Each `Step` performs an action.
actionId [*required*]
string
The unique identifier of an action.
completionGate
object
Used to create conditions before running subsequent actions.
completionCondition [*required*]
object
The definition of `CompletionCondition` object.
operand1 [*required*]

The `CompletionCondition` `operand1`.
operand2

The `CompletionCondition` `operand2`.
operator [*required*]
enum
The definition of `CompletionConditionOperator` object.
Allowed enum values: `OPERATOR_EQUAL,OPERATOR_NOT_EQUAL,OPERATOR_GREATER_THAN,OPERATOR_LESS_THAN,OPERATOR_GREATER_THAN_OR_EQUAL_TO,OPERATOR_LESS_THAN_OR_EQUAL_TO,OPERATOR_CONTAINS,OPERATOR_DOES_NOT_CONTAIN,OPERATOR_IS_NULL,OPERATOR_IS_NOT_NULL,OPERATOR_IS_EMPTY,OPERATOR_IS_NOT_EMPTY` retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
connectionLabel
string
The unique identifier of a connection defined in the spec.
display
object
The definition of `StepDisplay` object.
bounds
object
The definition of `StepDisplayBounds` object.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
errorHandlers
[object]
The `Step` `errorHandlers`.
fallbackStepName [*required*]
string
The `ErrorHandler` `fallbackStepName`.
retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
name [*required*]
string
Name of the step.
outboundEdges
[object]
A list of subsequent actions to run.
branchName [*required*]
string
The `OutboundEdge` `branchName`.
nextStepName [*required*]
string
The `OutboundEdge` `nextStepName`.
parameters
[object]
A list of inputs for an action.
name [*required*]
string
The `Parameter` `name`.
value [*required*]

The `Parameter` `value`.
readinessGate
object
Used to merge multiple branches into a single branch.
thresholdType [*required*]
enum
The definition of `ReadinessGateThresholdType` object.
Allowed enum values: `ANY,ALL` triggers
[ <oneOf>]
The list of triggers that activate this workflow. At least one trigger is required, and each trigger type may appear at most once.
Option 1
object
Schema for an API-based trigger.
apiTrigger [*required*]
object
Trigger a workflow from an API request. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 2
object
Schema for an App-based trigger.
appTrigger [*required*]
object
Trigger a workflow from an App.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 3
object
Schema for a Case-based trigger.
caseTrigger [*required*]
object
Trigger a workflow from a Case. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 4
object
Schema for a Change Event-based trigger.
changeEventTrigger [*required*]
object
Trigger a workflow from a Change Event.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 5
object
Schema for a Database Monitoring-based trigger.
databaseMonitoringTrigger [*required*]
object
Trigger a workflow from Database Monitoring.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 6
object
Schema for a Datastore-based trigger.
datastoreTrigger [*required*]
object
Trigger a workflow from a Datastore. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 7
object
Schema for a Dashboard-based trigger.
dashboardTrigger [*required*]
object
Trigger a workflow from a Dashboard.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 8
object
Schema for a GitHub webhook-based trigger.
githubWebhookTrigger [*required*]
object
Trigger a workflow from a GitHub webhook. To trigger a workflow from GitHub, you must set a `webhookSecret`. In your GitHub Webhook Settings, set the Payload URL to "base_url"/api/v2/workflows/"workflow_id"/webhook?orgId="org_id", select application/json for the content type, and be highly recommend enabling SSL verification for security. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 9
object
Schema for an Incident-based trigger.
incidentTrigger [*required*]
object
Trigger a workflow from an Incident. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 10
object
Schema for a Monitor-based trigger.
monitorTrigger [*required*]
object
Trigger a workflow from a Monitor. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 11
object
Schema for a Notebook-based trigger.
notebookTrigger [*required*]
object
Trigger a workflow from a Notebook.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 12
object
Schema for a Schedule-based trigger.
scheduleTrigger [*required*]
object
Trigger a workflow from a Schedule. The workflow must be published.
rruleExpression [*required*]
string
Recurrence rule expression for scheduling.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 13
object
Schema for a Security-based trigger.
securityTrigger [*required*]
object
Trigger a workflow from a Security Signal or Finding. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 14
object
Schema for a Self Service-based trigger.
selfServiceTrigger [*required*]
object
Trigger a workflow from Self Service.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 15
object
Schema for a Slack-based trigger.
slackTrigger [*required*]
object
Trigger a workflow from Slack. The workflow must be published.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 16
object
Schema for a Software Catalog-based trigger.
softwareCatalogTrigger [*required*]
object
Trigger a workflow from Software Catalog.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 17
object
Schema for a Workflow-based trigger.
startStepNames
[string]
A list of steps that run first after a trigger fires.
workflowTrigger [*required*]
object
Trigger a workflow from the Datadog UI. Only required if no other trigger exists.
tags
[string]
Tags of the workflow.
updatedAt
date-time
When the workflow was last updated.
webhookSecret
string
If a Webhook trigger is defined on this workflow, a webhookSecret is required and should be provided here.
id
string
The workflow identifier
relationships
object
The definition of `WorkflowDataRelationships` object.
creator
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users` owner
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users`type [*required*]
enum
The definition of `WorkflowDataType` object.
Allowed enum values: `workflows````
{
"data": {
"attributes": {
"description": "A sample workflow.",
"name": "Example Workflow",
"published": true,
"spec": {
"connectionEnvs": [
{
"connections": [
{
"connectionId": "11111111-1111-1111-1111-111111111111",
"label": "INTEGRATION_DATADOG"
}
],
"env": "default"
}
],
"inputSchema": {
"parameters": [
{
"defaultValue": "default",
"name": "input",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"name": "output",
"type": "ARRAY_OBJECT",
"value": "outputValue"
}
]
},
"steps": [
{
"actionId": "com.datadoghq.dd.monitor.listMonitors",
"connectionLabel": "INTEGRATION_DATADOG",
"name": "Step1",
"outboundEdges": [
{
"branchName": "main",
"nextStepName": "Step2"
}
],
"parameters": [
{
"name": "tags",
"value": "service:monitoring"
}
]
},
{
"actionId": "com.datadoghq.core.noop",
"name": "Step2"
}
],
"triggers": [
{
"monitorTrigger": {
"rateLimit": {
"count": 1,
"interval": "3600s"
}
},
"startStepNames": [
"Step1"
]
},
{
"startStepNames": [
"Step1"
],
"githubWebhookTrigger": {}
}
]
},
"tags": [
"team:infra",
"service:monitoring",
"foo:bar"
]
},
"id": "22222222-2222-2222-2222-222222222222",
"type": "workflows"
}
}
```### Response- 200
- 400
- 403
- 404
- 429
Successfully updated a workflow.
- Model
- Example
The response object after updating a workflow.
Expand All
Field
Type
Description
data
object
Data related to the workflow being updated.
attributes [*required*]
object
The definition of `WorkflowDataUpdateAttributes` object.
createdAt
date-time
When the workflow was created.
description
string
Description of the workflow.
name
string
Name of the workflow.
published
boolean
Set the workflow to published or unpublished. Workflows in an unpublished state will only be executable via manual runs. Automatic triggers such as Schedule will not execute the workflow until it is published.
spec
object
The spec defines what the workflow does.
annotations
[object]
A list of annotations used in the workflow. These are like sticky notes for your workflow!
display [*required*]
object
The definition of `AnnotationDisplay` object.
bounds
object
The definition of `AnnotationDisplayBounds` object.
height
double
The `bounds` `height`.
width
double
The `bounds` `width`.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
id [*required*]
string
The `Annotation` `id`.
markdownTextAnnotation [*required*]
object
The definition of `AnnotationMarkdownTextAnnotation` object.
text
string
The `markdownTextAnnotation` `text`.
connectionEnvs
[object]
A list of connections or connection groups used in the workflow.
connectionGroups
[object]
The `ConnectionEnv` `connectionGroups`.
connectionGroupId [*required*]
string
The `ConnectionGroup` `connectionGroupId`.
label [*required*]
string
The `ConnectionGroup` `label`.
tags [*required*]
[string]
The `ConnectionGroup` `tags`.
connections
[object]
The `ConnectionEnv` `connections`.
connectionId [*required*]
string
The `Connection` `connectionId`.
label [*required*]
string
The `Connection` `label`.
env [*required*]
enum
The definition of `ConnectionEnvEnv` object.
Allowed enum values: `default`handle
string
Unique identifier used to trigger workflows automatically in Datadog.
inputSchema
object
A list of input parameters for the workflow. These can be used as dynamic runtime values in your workflow.
parameters
[object]
The `InputSchema` `parameters`.
defaultValue

The `InputSchemaParameters` `defaultValue`.
description
string
The `InputSchemaParameters` `description`.
label
string
The `InputSchemaParameters` `label`.
name [*required*]
string
The `InputSchemaParameters` `name`.
type [*required*]
enum
The definition of `InputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT` outputSchema
object
A list of output parameters for the workflow.
parameters
[object]
The `OutputSchema` `parameters`.
defaultValue

The `OutputSchemaParameters` `defaultValue`.
description
string
The `OutputSchemaParameters` `description`.
label
string
The `OutputSchemaParameters` `label`.
name [*required*]
string
The `OutputSchemaParameters` `name`.
type [*required*]
enum
The definition of `OutputSchemaParametersType` object.
Allowed enum values: `STRING,NUMBER,BOOLEAN,OBJECT,ARRAY_STRING,ARRAY_NUMBER,ARRAY_BOOLEAN,ARRAY_OBJECT`value

The `OutputSchemaParameters` `value`.
steps
[object]
A `Step` is a sub-component of a workflow. Each `Step` performs an action.
actionId [*required*]
string
The unique identifier of an action.
completionGate
object
Used to create conditions before running subsequent actions.
completionCondition [*required*]
object
The definition of `CompletionCondition` object.
operand1 [*required*]

The `CompletionCondition` `operand1`.
operand2

The `CompletionCondition` `operand2`.
operator [*required*]
enum
The definition of `CompletionConditionOperator` object.
Allowed enum values: `OPERATOR_EQUAL,OPERATOR_NOT_EQUAL,OPERATOR_GREATER_THAN,OPERATOR_LESS_THAN,OPERATOR_GREATER_THAN_OR_EQUAL_TO,OPERATOR_LESS_THAN_OR_EQUAL_TO,OPERATOR_CONTAINS,OPERATOR_DOES_NOT_CONTAIN,OPERATOR_IS_NULL,OPERATOR_IS_NOT_NULL,OPERATOR_IS_EMPTY,OPERATOR_IS_NOT_EMPTY` retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
connectionLabel
string
The unique identifier of a connection defined in the spec.
display
object
The definition of `StepDisplay` object.
bounds
object
The definition of `StepDisplayBounds` object.
x
double
The `bounds` `x`.
y
double
The `bounds` `y`.
errorHandlers
[object]
The `Step` `errorHandlers`.
fallbackStepName [*required*]
string
The `ErrorHandler` `fallbackStepName`.
retryStrategy [*required*]
object
The definition of `RetryStrategy` object.
kind [*required*]
enum
The definition of `RetryStrategyKind` object.
Allowed enum values: `RETRY_STRATEGY_LINEAR` linear
object
The definition of `RetryStrategyLinear` object.
interval [*required*]
string
The `RetryStrategyLinear` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
maxRetries [*required*]
double
The `RetryStrategyLinear` `maxRetries`.
name [*required*]
string
Name of the step.
outboundEdges
[object]
A list of subsequent actions to run.
branchName [*required*]
string
The `OutboundEdge` `branchName`.
nextStepName [*required*]
string
The `OutboundEdge` `nextStepName`.
parameters
[object]
A list of inputs for an action.
name [*required*]
string
The `Parameter` `name`.
value [*required*]

The `Parameter` `value`.
readinessGate
object
Used to merge multiple branches into a single branch.
thresholdType [*required*]
enum
The definition of `ReadinessGateThresholdType` object.
Allowed enum values: `ANY,ALL` triggers
[ <oneOf>]
The list of triggers that activate this workflow. At least one trigger is required, and each trigger type may appear at most once.
Option 1
object
Schema for an API-based trigger.
apiTrigger [*required*]
object
Trigger a workflow from an API request. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 2
object
Schema for an App-based trigger.
appTrigger [*required*]
object
Trigger a workflow from an App.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 3
object
Schema for a Case-based trigger.
caseTrigger [*required*]
object
Trigger a workflow from a Case. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 4
object
Schema for a Change Event-based trigger.
changeEventTrigger [*required*]
object
Trigger a workflow from a Change Event.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 5
object
Schema for a Database Monitoring-based trigger.
databaseMonitoringTrigger [*required*]
object
Trigger a workflow from Database Monitoring.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 6
object
Schema for a Datastore-based trigger.
datastoreTrigger [*required*]
object
Trigger a workflow from a Datastore. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 7
object
Schema for a Dashboard-based trigger.
dashboardTrigger [*required*]
object
Trigger a workflow from a Dashboard.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 8
object
Schema for a GitHub webhook-based trigger.
githubWebhookTrigger [*required*]
object
Trigger a workflow from a GitHub webhook. To trigger a workflow from GitHub, you must set a `webhookSecret`. In your GitHub Webhook Settings, set the Payload URL to "base_url"/api/v2/workflows/"workflow_id"/webhook?orgId="org_id", select application/json for the content type, and be highly recommend enabling SSL verification for security. The workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 9
object
Schema for an Incident-based trigger.
incidentTrigger [*required*]
object
Trigger a workflow from an Incident. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 10
object
Schema for a Monitor-based trigger.
monitorTrigger [*required*]
object
Trigger a workflow from a Monitor. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 11
object
Schema for a Notebook-based trigger.
notebookTrigger [*required*]
object
Trigger a workflow from a Notebook.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 12
object
Schema for a Schedule-based trigger.
scheduleTrigger [*required*]
object
Trigger a workflow from a Schedule. The workflow must be published.
rruleExpression [*required*]
string
Recurrence rule expression for scheduling.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 13
object
Schema for a Security-based trigger.
securityTrigger [*required*]
object
Trigger a workflow from a Security Signal or Finding. For automatic triggering a handle must be configured and the workflow must be published.
rateLimit
object
Defines a rate limit for a trigger.
count
int64
The `TriggerRateLimit` `count`.
interval
string
The `TriggerRateLimit` `interval`. The expected format is the number of seconds ending with an s. For example, 1 day is 86400s
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 14
object
Schema for a Self Service-based trigger.
selfServiceTrigger [*required*]
object
Trigger a workflow from Self Service.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 15
object
Schema for a Slack-based trigger.
slackTrigger [*required*]
object
Trigger a workflow from Slack. The workflow must be published.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 16
object
Schema for a Software Catalog-based trigger.
softwareCatalogTrigger [*required*]
object
Trigger a workflow from Software Catalog.
startStepNames
[string]
A list of steps that run first after a trigger fires.
Option 17
object
Schema for a Workflow-based trigger.
startStepNames
[string]
A list of steps that run first after a trigger fires.
workflowTrigger [*required*]
object
Trigger a workflow from the Datadog UI. Only required if no other trigger exists.
tags
[string]
Tags of the workflow.
updatedAt
date-time
When the workflow was last updated.
webhookSecret
string
If a Webhook trigger is defined on this workflow, a webhookSecret is required and should be provided here.
id
string
The workflow identifier
relationships
object
The definition of `WorkflowDataRelationships` object.
creator
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users` owner
object
The definition of `WorkflowUserRelationship` object.
data
object
The definition of `WorkflowUserRelationshipData` object.
id [*required*]
string
The user identifier
type [*required*]
enum
The definition of `WorkflowUserRelationshipType` object.
Allowed enum values: `users`type [*required*]
enum
The definition of `WorkflowDataType` object.
Allowed enum values: `workflows````
{
"data": {
"attributes": {
"createdAt": "2019-09-19T10:00:00.000Z",
"description": "string",
"name": "string",
"published": false,
"spec": {
"annotations": [
{
"display": {
"bounds": {
"height": "number",
"width": "number",
"x": "number",
"y": "number"
}
},
"id": "",
"markdownTextAnnotation": {
"text": "string"
}
}
],
"connectionEnvs": [
{
"connectionGroups": [
{
"connectionGroupId": "",
"label": "",
"tags": [
""
]
}
],
"connections": [
{
"connectionId": "",
"label": ""
}
],
"env": "default"
}
],
"handle": "string",
"inputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"defaultValue": "undefined",
"description": "string",
"label": "string",
"name": "",
"type": "STRING",
"value": "undefined"
}
]
},
"steps": [
{
"actionId": "",
"completionGate": {
"completionCondition": {
"operand1": "undefined",
"operand2": "undefined",
"operator": "OPERATOR_EQUAL"
},
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
},
"connectionLabel": "string",
"display": {
"bounds": {
"x": "number",
"y": "number"
}
},
"errorHandlers": [
{
"fallbackStepName": "",
"retryStrategy": {
"kind": "RETRY_STRATEGY_LINEAR",
"linear": {
"interval": "",
"maxRetries": 0
}
}
}
],
"name": "",
"outboundEdges": [
{
"branchName": "",
"nextStepName": ""
}
],
"parameters": [
{
"name": "",
"value": "undefined"
}
],
"readinessGate": {
"thresholdType": "ANY"
}
}
],
"triggers": [
{
"apiTrigger": {
"rateLimit": {
"count": "integer",
"interval": "string"
}
},
"startStepNames": [
""
]
}
]
},
"tags": [],
"updatedAt": "2019-09-19T10:00:00.000Z",
"webhookSecret": "string"
},
"id": "string",
"relationships": {
"creator": {
"data": {
"id": "",
"type": "users"
}
},
"owner": {
"data": {
"id": "",
"type": "users"
}
}
},
"type": "workflows"
}
}
```Bad request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Not found
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Update an existing Workflow returns "Successfully updated a workflow." responseCopy```

# Path parametersexport workflow_id="CHANGE_ME"# Curl commandcurl -X PATCH "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}" \
-H "Accept: application/json" \
-H "Content-Type: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
-d @- << EOF
{
"data": {
"attributes": {
"description": "A sample workflow.",
"name": "Example Workflow",
"published": true,
"spec": {
"connectionEnvs": [
{
"connections": [
{
"connectionId": "11111111-1111-1111-1111-111111111111",
"label": "INTEGRATION_DATADOG"
}
],
"env": "default"
}
],
"inputSchema": {
"parameters": [
{
"defaultValue": "default",
"name": "input",
"type": "STRING"
}
]
},
"outputSchema": {
"parameters": [
{
"name": "output",
"type": "ARRAY_OBJECT",
"value": "outputValue"
}
]
},
"steps": [
{
"actionId": "com.datadoghq.dd.monitor.listMonitors",
"connectionLabel": "INTEGRATION_DATADOG",
"name": "Step1",
"outboundEdges": [
{
"branchName": "main",
"nextStepName": "Step2"
}
],
"parameters": [
{
"name": "tags",
"value": "service:monitoring"
}
]
},
{
"actionId": "com.datadoghq.core.noop",
"name": "Step2"
}
],
"triggers": [
{
"monitorTrigger": {
"rateLimit": {
"count": 1,
"interval": "3600s"
}
},
"startStepNames": [
"Step1"
]
},
{
"startStepNames": [
"Step1"
],
"githubWebhookTrigger": {}
}
]
},
"tags": [
"team:infra",
"service:monitoring",
"foo:bar"
]
},
"id": "22222222-2222-2222-2222-222222222222",
"type": "workflows"
}
}
EOF

```
Update an existing Workflow returns "Successfully updated a workflow." response```
// Update an existing Workflow returns "Successfully updated a workflow." response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	// there is a valid "workflow" in the system
	WorkflowDataID := os.Getenv("WORKFLOW_DATA_ID")

	body := datadogV2.UpdateWorkflowRequest{
		Data: datadogV2.WorkflowDataUpdate{
			Attributes: datadogV2.WorkflowDataUpdateAttributes{
				Description: datadog.PtrString("A sample workflow."),
				Name: datadog.PtrString("Example Workflow"),
				Published: datadog.PtrBool(true),
				Spec: &datadogV2.Spec{
					ConnectionEnvs: []datadogV2.ConnectionEnv{
						{
							Connections: []datadogV2.Connection{
								{
									ConnectionId: "11111111-1111-1111-1111-111111111111",
									Label: "INTEGRATION_DATADOG",
								},
							},
							Env: datadogV2.CONNECTIONENVENV_DEFAULT,
						},
					},
					InputSchema: &datadogV2.InputSchema{
						Parameters: []datadogV2.InputSchemaParameters{
							{
								DefaultValue: "default",
								Name: "input",
								Type: datadogV2.INPUTSCHEMAPARAMETERSTYPE_STRING,
							},
						},
					},
					OutputSchema: &datadogV2.OutputSchema{
						Parameters: []datadogV2.OutputSchemaParameters{
							{
								Name: "output",
								Type: datadogV2.OUTPUTSCHEMAPARAMETERSTYPE_ARRAY_OBJECT,
								Value: "outputValue",
							},
						},
					},
					Steps: []datadogV2.Step{
						{
							ActionId: "com.datadoghq.dd.monitor.listMonitors",
							ConnectionLabel: datadog.PtrString("INTEGRATION_DATADOG"),
							Name: "Step1",
							OutboundEdges: []datadogV2.OutboundEdge{
								{
									BranchName: "main",
									NextStepName: "Step2",
								},
							},
							Parameters: []datadogV2.Parameter{
								{
									Name: "tags",
									Value: "service:monitoring",
								},
							},
						},
						{
							ActionId: "com.datadoghq.core.noop",
							Name: "Step2",
						},
					},
					Triggers: []datadogV2.Trigger{
						datadogV2.Trigger{
							MonitorTriggerWrapper: &datadogV2.MonitorTriggerWrapper{
								MonitorTrigger: datadogV2.MonitorTrigger{
									RateLimit: &datadogV2.TriggerRateLimit{
										Count: datadog.PtrInt64(1),
										Interval: datadog.PtrString("3600s"),
									},
								},
								StartStepNames: []string{
									"Step1",
								},
							}},
						datadogV2.Trigger{
							GithubWebhookTriggerWrapper: &datadogV2.GithubWebhookTriggerWrapper{
								StartStepNames: []string{
									"Step1",
								},
								GithubWebhookTrigger: datadogV2.GithubWebhookTrigger{},
							}},
					},
				},
				Tags: []string{
					"team:infra",
					"service:monitoring",
					"foo:bar",
				},
			},
			Id: datadog.PtrString("22222222-2222-2222-2222-222222222222"),
			Type: datadogV2.WORKFLOWDATATYPE_WORKFLOWS,
		},
	}
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.UpdateWorkflow(ctx, WorkflowDataID, body)

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.UpdateWorkflow`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.UpdateWorkflow`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" go run "main.go"`
```
Update an existing Workflow returns "Successfully updated a workflow." response```
// Update an existing Workflow returns "Successfully updated a workflow." response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.Connection;
import com.datadog.api.client.v2.model.ConnectionEnv;
import com.datadog.api.client.v2.model.ConnectionEnvEnv;
import com.datadog.api.client.v2.model.GithubWebhookTrigger;
import com.datadog.api.client.v2.model.GithubWebhookTriggerWrapper;
import com.datadog.api.client.v2.model.InputSchema;
import com.datadog.api.client.v2.model.InputSchemaParameters;
import com.datadog.api.client.v2.model.InputSchemaParametersType;
import com.datadog.api.client.v2.model.MonitorTrigger;
import com.datadog.api.client.v2.model.MonitorTriggerWrapper;
import com.datadog.api.client.v2.model.OutboundEdge;
import com.datadog.api.client.v2.model.OutputSchema;
import com.datadog.api.client.v2.model.OutputSchemaParameters;
import com.datadog.api.client.v2.model.OutputSchemaParametersType;
import com.datadog.api.client.v2.model.Parameter;
import com.datadog.api.client.v2.model.Spec;
import com.datadog.api.client.v2.model.Step;
import com.datadog.api.client.v2.model.Trigger;
import com.datadog.api.client.v2.model.TriggerRateLimit;
import com.datadog.api.client.v2.model.UpdateWorkflowRequest;
import com.datadog.api.client.v2.model.UpdateWorkflowResponse;
import com.datadog.api.client.v2.model.WorkflowDataType;
import com.datadog.api.client.v2.model.WorkflowDataUpdate;
import com.datadog.api.client.v2.model.WorkflowDataUpdateAttributes;
import java.util.Arrays;
import java.util.Collections;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

// there is a valid "workflow" in the system
String WORKFLOW_DATA_ID = System.getenv("WORKFLOW_DATA_ID");

UpdateWorkflowRequest body =
new UpdateWorkflowRequest()
.data(
new WorkflowDataUpdate()
.attributes(
new WorkflowDataUpdateAttributes()
.description("A sample workflow.")
.name("Example Workflow")
.published(true)
.spec(
new Spec()
.connectionEnvs(
Collections.singletonList(
new ConnectionEnv()
.connections(
Collections.singletonList(
new Connection()
.connectionId(
"11111111-1111-1111-1111-111111111111")
.label("INTEGRATION_DATADOG")))
.env(ConnectionEnvEnv.DEFAULT)))
.inputSchema(
new InputSchema()
.parameters(
Collections.singletonList(
new InputSchemaParameters()
.defaultValue("default")
.name("input")
.type(InputSchemaParametersType.STRING))))
.outputSchema(
new OutputSchema()
.parameters(
Collections.singletonList(
new OutputSchemaParameters()
.name("output")
.type(
OutputSchemaParametersType.ARRAY_OBJECT)
.value("outputValue"))))
.steps(
Arrays.asList(
new Step()
.actionId("com.datadoghq.dd.monitor.listMonitors")
.connectionLabel("INTEGRATION_DATADOG")
.name("Step1")
.outboundEdges(
Collections.singletonList(
new OutboundEdge()
.branchName("main")
.nextStepName("Step2")))
.parameters(
Collections.singletonList(
new Parameter()
.name("tags")
.value("service:monitoring"))),
new Step()
.actionId("com.datadoghq.core.noop")
.name("Step2")))
.triggers(
Arrays.asList(
new Trigger(
new MonitorTriggerWrapper()
.monitorTrigger(
new MonitorTrigger()
.rateLimit(
new TriggerRateLimit()
.count(1L)
.interval("3600s")))
.startStepNames(
Collections.singletonList("Step1"))),
new Trigger(
new GithubWebhookTriggerWrapper()
.startStepNames(
Collections.singletonList("Step1"))
.githubWebhookTrigger(
new GithubWebhookTrigger())))))
.tags(Arrays.asList("team:infra", "service:monitoring", "foo:bar")))
.id("22222222-2222-2222-2222-222222222222")
.type(WorkflowDataType.WORKFLOWS));

try {
UpdateWorkflowResponse result = apiInstance.updateWorkflow(WORKFLOW_DATA_ID, body);
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#updateWorkflow");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" java "Example.java"`
```
Update an existing Workflow returns "Successfully updated a workflow." response```
"""
Update an existing Workflow returns "Successfully updated a workflow." response
"""

from os import environ
from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi
from datadog_api_client.v2.model.connection import Connection
from datadog_api_client.v2.model.connection_env import ConnectionEnv
from datadog_api_client.v2.model.connection_env_env import ConnectionEnvEnv
from datadog_api_client.v2.model.github_webhook_trigger import GithubWebhookTrigger
from datadog_api_client.v2.model.github_webhook_trigger_wrapper import GithubWebhookTriggerWrapper
from datadog_api_client.v2.model.input_schema import InputSchema
from datadog_api_client.v2.model.input_schema_parameters import InputSchemaParameters
from datadog_api_client.v2.model.input_schema_parameters_type import InputSchemaParametersType
from datadog_api_client.v2.model.monitor_trigger import MonitorTrigger
from datadog_api_client.v2.model.monitor_trigger_wrapper import MonitorTriggerWrapper
from datadog_api_client.v2.model.outbound_edge import OutboundEdge
from datadog_api_client.v2.model.output_schema import OutputSchema
from datadog_api_client.v2.model.output_schema_parameters import OutputSchemaParameters
from datadog_api_client.v2.model.output_schema_parameters_type import OutputSchemaParametersType
from datadog_api_client.v2.model.parameter import Parameter
from datadog_api_client.v2.model.spec import Spec
from datadog_api_client.v2.model.step import Step
from datadog_api_client.v2.model.trigger_rate_limit import TriggerRateLimit
from datadog_api_client.v2.model.update_workflow_request import UpdateWorkflowRequest
from datadog_api_client.v2.model.workflow_data_type import WorkflowDataType
from datadog_api_client.v2.model.workflow_data_update import WorkflowDataUpdate
from datadog_api_client.v2.model.workflow_data_update_attributes import WorkflowDataUpdateAttributes

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = environ["WORKFLOW_DATA_ID"]

body = UpdateWorkflowRequest(
data=WorkflowDataUpdate(
attributes=WorkflowDataUpdateAttributes(
description="A sample workflow.",
name="Example Workflow",
published=True,
spec=Spec(
connection_envs=[
ConnectionEnv(
connections=[
Connection(
connection_id="11111111-1111-1111-1111-111111111111",
label="INTEGRATION_DATADOG",
),
],
env=ConnectionEnvEnv.DEFAULT,
),
],
input_schema=InputSchema(
parameters=[
InputSchemaParameters(
default_value="default",
name="input",
type=InputSchemaParametersType.STRING,
),
],
),
output_schema=OutputSchema(
parameters=[
OutputSchemaParameters(
name="output",
type=OutputSchemaParametersType.ARRAY_OBJECT,
value="outputValue",
),
],
),
steps=[
Step(
action_id="com.datadoghq.dd.monitor.listMonitors",
connection_label="INTEGRATION_DATADOG",
name="Step1",
outbound_edges=[
OutboundEdge(
branch_name="main",
next_step_name="Step2",
),
],
parameters=[
Parameter(
name="tags",
value="service:monitoring",
),
],
),
Step(
action_id="com.datadoghq.core.noop",
name="Step2",
),
],
triggers=[
MonitorTriggerWrapper(
monitor_trigger=MonitorTrigger(
rate_limit=TriggerRateLimit(
count=1,
interval="3600s",
),
),
start_step_names=[
"Step1",
],
),
GithubWebhookTriggerWrapper(
start_step_names=[
"Step1",
],
github_webhook_trigger=GithubWebhookTrigger(),
),
],
),
tags=[
"team:infra",
"service:monitoring",
"foo:bar",
],
),
id="22222222-2222-2222-2222-222222222222",
type=WorkflowDataType.WORKFLOWS,
),
)

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.update_workflow(workflow_id=WORKFLOW_DATA_ID, body=body)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" python3 "example.py"`
```
Update an existing Workflow returns "Successfully updated a workflow." response```
# Update an existing Workflow returns "Successfully updated a workflow." response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = ENV["WORKFLOW_DATA_ID"]

body = DatadogAPIClient::V2::UpdateWorkflowRequest.new({
data: DatadogAPIClient::V2::WorkflowDataUpdate.new({
attributes: DatadogAPIClient::V2::WorkflowDataUpdateAttributes.new({
description: "A sample workflow.",
name: "Example Workflow",
published: true,
spec: DatadogAPIClient::V2::Spec.new({
connection_envs: [
DatadogAPIClient::V2::ConnectionEnv.new({
connections: [
DatadogAPIClient::V2::Connection.new({
connection_id: "11111111-1111-1111-1111-111111111111",
label: "INTEGRATION_DATADOG",
}),
],
env: DatadogAPIClient::V2::ConnectionEnvEnv::DEFAULT,
}),
],
input_schema: DatadogAPIClient::V2::InputSchema.new({
parameters: [
DatadogAPIClient::V2::InputSchemaParameters.new({
default_value: "default",
name: "input",
type: DatadogAPIClient::V2::InputSchemaParametersType::STRING,
}),
],
}),
output_schema: DatadogAPIClient::V2::OutputSchema.new({
parameters: [
DatadogAPIClient::V2::OutputSchemaParameters.new({
name: "output",
type: DatadogAPIClient::V2::OutputSchemaParametersType::ARRAY_OBJECT,
value: "outputValue",
}),
],
}),
steps: [
DatadogAPIClient::V2::Step.new({
action_id: "com.datadoghq.dd.monitor.listMonitors",
connection_label: "INTEGRATION_DATADOG",
name: "Step1",
outbound_edges: [
DatadogAPIClient::V2::OutboundEdge.new({
branch_name: "main",
next_step_name: "Step2",
}),
],
parameters: [
DatadogAPIClient::V2::Parameter.new({
name: "tags",
value: "service:monitoring",
}),
],
}),
DatadogAPIClient::V2::Step.new({
action_id: "com.datadoghq.core.noop",
name: "Step2",
}),
],
triggers: [
DatadogAPIClient::V2::MonitorTriggerWrapper.new({
monitor_trigger: DatadogAPIClient::V2::MonitorTrigger.new({
rate_limit: DatadogAPIClient::V2::TriggerRateLimit.new({
count: 1,
interval: "3600s",
}),
}),
start_step_names: [
"Step1",
],
}),
DatadogAPIClient::V2::GithubWebhookTriggerWrapper.new({
start_step_names: [
"Step1",
],
github_webhook_trigger: DatadogAPIClient::V2::GithubWebhookTrigger.new({}),
}),
],
}),
tags: [
"team:infra",
"service:monitoring",
"foo:bar",
],
}),
id: "22222222-2222-2222-2222-222222222222",
type: DatadogAPIClient::V2::WorkflowDataType::WORKFLOWS,
}),
})
p api_instance.update_workflow(WORKFLOW_DATA_ID, body)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" rb "example.rb"`
```
Update an existing Workflow returns "Successfully updated a workflow." response```
// Update an existing Workflow returns "Successfully updated a workflow." response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;
use datadog_api_client::datadogV2::model::Connection;
use datadog_api_client::datadogV2::model::ConnectionEnv;
use datadog_api_client::datadogV2::model::ConnectionEnvEnv;
use datadog_api_client::datadogV2::model::GithubWebhookTrigger;
use datadog_api_client::datadogV2::model::GithubWebhookTriggerWrapper;
use datadog_api_client::datadogV2::model::InputSchema;
use datadog_api_client::datadogV2::model::InputSchemaParameters;
use datadog_api_client::datadogV2::model::InputSchemaParametersType;
use datadog_api_client::datadogV2::model::MonitorTrigger;
use datadog_api_client::datadogV2::model::MonitorTriggerWrapper;
use datadog_api_client::datadogV2::model::OutboundEdge;
use datadog_api_client::datadogV2::model::OutputSchema;
use datadog_api_client::datadogV2::model::OutputSchemaParameters;
use datadog_api_client::datadogV2::model::OutputSchemaParametersType;
use datadog_api_client::datadogV2::model::Parameter;
use datadog_api_client::datadogV2::model::Spec;
use datadog_api_client::datadogV2::model::Step;
use datadog_api_client::datadogV2::model::Trigger;
use datadog_api_client::datadogV2::model::TriggerRateLimit;
use datadog_api_client::datadogV2::model::UpdateWorkflowRequest;
use datadog_api_client::datadogV2::model::WorkflowDataType;
use datadog_api_client::datadogV2::model::WorkflowDataUpdate;
use datadog_api_client::datadogV2::model::WorkflowDataUpdateAttributes;
use serde_json::Value;

#[tokio::main]
async fn main() {
// there is a valid "workflow" in the system
let workflow_data_id = std::env::var("WORKFLOW_DATA_ID").unwrap();
let body = UpdateWorkflowRequest::new(
WorkflowDataUpdate::new(
WorkflowDataUpdateAttributes::new()
.description("A sample workflow.".to_string())
.name("Example Workflow".to_string())
.published(true)
.spec(
Spec::new()
.connection_envs(vec![ConnectionEnv::new(ConnectionEnvEnv::DEFAULT)
.connections(vec![Connection::new(
"11111111-1111-1111-1111-111111111111".to_string(),
"INTEGRATION_DATADOG".to_string(),
)])])
.input_schema(InputSchema::new().parameters(vec![
InputSchemaParameters::new(
"input".to_string(),
InputSchemaParametersType::STRING,
).default_value(Value::from("default"))
]))
.output_schema(OutputSchema::new().parameters(vec![
OutputSchemaParameters::new(
"output".to_string(),
OutputSchemaParametersType::ARRAY_OBJECT,
).value(Value::from("outputValue"))
]))
.steps(vec![
Step::new(
"com.datadoghq.dd.monitor.listMonitors".to_string(),
"Step1".to_string(),
)
.connection_label("INTEGRATION_DATADOG".to_string())
.outbound_edges(vec![OutboundEdge::new(
"main".to_string(),
"Step2".to_string(),
)])
.parameters(vec![Parameter::new(
"tags".to_string(),
Value::from("service:monitoring"),
)]),
Step::new("com.datadoghq.core.noop".to_string(), "Step2".to_string()),
])
.triggers(vec![
Trigger::MonitorTriggerWrapper(Box::new(
MonitorTriggerWrapper::new(
MonitorTrigger::new().rate_limit(
TriggerRateLimit::new()
.count(1)
.interval("3600s".to_string()),
),
)
.start_step_names(vec!["Step1".to_string()]),
)),
Trigger::GithubWebhookTriggerWrapper(Box::new(
GithubWebhookTriggerWrapper::new(GithubWebhookTrigger::new())
.start_step_names(vec!["Step1".to_string()]),
)),
]),
)
.tags(vec![
"team:infra".to_string(),
"service:monitoring".to_string(),
"foo:bar".to_string(),
]),
WorkflowDataType::WORKFLOWS,
)
.id("22222222-2222-2222-2222-222222222222".to_string()),
);
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api.update_workflow(workflow_data_id.clone(), body).await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" cargo run`
```
Update an existing Workflow returns "Successfully updated a workflow." response```
/**
* Update an existing Workflow returns "Successfully updated a workflow." response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

// there is a valid "workflow" in the system
const WORKFLOW_DATA_ID = process.env.WORKFLOW_DATA_ID as string;

const params: v2.WorkflowAutomationApiUpdateWorkflowRequest = {
body: {
data: {
attributes: {
description: "A sample workflow.",
name: "Example Workflow",
published: true,
spec: {
connectionEnvs: [
{
connections: [
{
connectionId: "11111111-1111-1111-1111-111111111111",
label: "INTEGRATION_DATADOG",
},
],
env: "default",
},
],
inputSchema: {
parameters: [
{
defaultValue: "default",
name: "input",
type: "STRING",
},
],
},
outputSchema: {
parameters: [
{
name: "output",
type: "ARRAY_OBJECT",
value: "outputValue",
},
],
},
steps: [
{
actionId: "com.datadoghq.dd.monitor.listMonitors",
connectionLabel: "INTEGRATION_DATADOG",
name: "Step1",
outboundEdges: [
{
branchName: "main",
nextStepName: "Step2",
},
],
parameters: [
{
name: "tags",
value: "service:monitoring",
},
],
},
{
actionId: "com.datadoghq.core.noop",
name: "Step2",
},
],
triggers: [
{
monitorTrigger: {
rateLimit: {
count: 1,
interval: "3600s",
},
},
startStepNames: ["Step1"],
},
{
startStepNames: ["Step1"],
githubWebhookTrigger: {},
},
],
},
tags: ["team:infra", "service:monitoring", "foo:bar"],
},
id: "22222222-2222-2222-2222-222222222222",
type: "workflows",
},
},
workflowId: WORKFLOW_DATA_ID,
};

apiInstance
.updateWorkflow(params)
.then((data: v2.UpdateWorkflowResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" tsc "example.ts"`
```## Delete an existing Workflow- v2 (latest)
DELETE https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}https://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}https://api.datadoghq.eu/api/v2/workflows/{workflow_id}https://api.ddog-gov.com/api/v2/workflows/{workflow_id}https://api.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}https://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}
### OverviewDelete a workflow by ID. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_write` permission.### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
### Response- 204
- 403
- 404
- 429
Successfully deleted a workflow.
Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Not found
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[object]
A list of errors.
detail
string
A human-readable explanation specific to this occurrence of the error.
meta
object
Non-standard meta-information about the error
source
object
References to the source of the error.
header
string
A string indicating the name of a single request header which caused the error.
parameter
string
A string indicating which URI query parameter caused the error.
pointer
string
A JSON pointer to the value in the request document that caused the error.
status
string
Status code of the response.
title
string
Short human-readable summary of the error.
```
{
"errors": [
{
"detail": "Missing required attribute in body",
"meta": {},
"source": {
"header": "Authorization",
"parameter": "limit",
"pointer": "/data/attributes/title"
},
"status": "400",
"title": "Bad Request"
}
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Delete an existing WorkflowCopy```

# Path parametersexport workflow_id="CHANGE_ME"# Curl commandcurl -X DELETE "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}"

```
Delete an existing Workflow```
"""
Delete an existing Workflow returns "Successfully deleted a workflow." response
"""

from os import environ
from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = environ["WORKFLOW_DATA_ID"]

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
api_instance.delete_workflow(
workflow_id=WORKFLOW_DATA_ID,
)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" python3 "example.py"`
```
Delete an existing Workflow```
# Delete an existing Workflow returns "Successfully deleted a workflow." response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new

# there is a valid "workflow" in the system
WORKFLOW_DATA_ID = ENV["WORKFLOW_DATA_ID"]
api_instance.delete_workflow(WORKFLOW_DATA_ID)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" rb "example.rb"`
```
Delete an existing Workflow```
// Delete an existing Workflow returns "Successfully deleted a workflow." response

package main

import (
	"context"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	// there is a valid "workflow" in the system
	WorkflowDataID := os.Getenv("WORKFLOW_DATA_ID")

	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	r, err := api.DeleteWorkflow(ctx, WorkflowDataID)

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.DeleteWorkflow`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" go run "main.go"`
```
Delete an existing Workflow```
// Delete an existing Workflow returns "Successfully deleted a workflow." response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

// there is a valid "workflow" in the system
String WORKFLOW_DATA_ID = System.getenv("WORKFLOW_DATA_ID");

try {
apiInstance.deleteWorkflow(WORKFLOW_DATA_ID);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#deleteWorkflow");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" java "Example.java"`
```
Delete an existing Workflow```
// Delete an existing Workflow returns "Successfully deleted a workflow." response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;

#[tokio::main]
async fn main() {
// there is a valid "workflow" in the system
let workflow_data_id = std::env::var("WORKFLOW_DATA_ID").unwrap();
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api.delete_workflow(workflow_data_id.clone()).await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" cargo run`
```
Delete an existing Workflow```
/**
* Delete an existing Workflow returns "Successfully deleted a workflow." response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

// there is a valid "workflow" in the system
const WORKFLOW_DATA_ID = process.env.WORKFLOW_DATA_ID as string;

const params: v2.WorkflowAutomationApiDeleteWorkflowRequest = {
workflowId: WORKFLOW_DATA_ID,
};

apiInstance
.deleteWorkflow(params)
.then((data: any) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" tsc "example.ts"`
```## List workflow instances- v2 (latest)
GET https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.datadoghq.eu/api/v2/workflows/{workflow_id}/instanceshttps://api.ddog-gov.com/api/v2/workflows/{workflow_id}/instanceshttps://api.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}/instances
### OverviewList all instances of a given workflow. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_read` permission.OAuth apps require the `workflows_read` authorization scope to access this endpoint.
### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
#### Query StringsName
Type
Description
page[size]
integer
Size for a given page. The maximum allowed value is 100.
page[number]
integer
Specific page number to return.
### Response- 200
- 400
- 403
- 429
OK
- Model
- Example
Response returned when listing workflow instances.
Expand All
Field
Type
Description
<any-key>

```
{
"data": [
{
"id": "string"
}
],
"meta": {
"page": {
"totalCount": "integer"
}
}
}
```Bad Request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

List workflow instancesCopy```

# Path parametersexport workflow_id="CHANGE_ME"# Curl commandcurl -X GET "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}/instances" \
-H "Accept: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}"

```
List workflow instances```
"""
List workflow instances returns "OK" response
"""

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.list_workflow_instances(
workflow_id="ccf73164-1998-4785-a7a3-8d06c7e5f558",
)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" python3 "example.py"`
```
List workflow instances```
# List workflow instances returns "OK" response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new
p api_instance.list_workflow_instances("ccf73164-1998-4785-a7a3-8d06c7e5f558")

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" rb "example.rb"`
```
List workflow instances```
// List workflow instances returns "OK" response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.ListWorkflowInstances(ctx, "ccf73164-1998-4785-a7a3-8d06c7e5f558", *datadogV2.NewListWorkflowInstancesOptionalParameters())

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.ListWorkflowInstances`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.ListWorkflowInstances`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" go run "main.go"`
```
List workflow instances```
// List workflow instances returns "OK" response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.WorkflowListInstancesResponse;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

try {
WorkflowListInstancesResponse result =
apiInstance.listWorkflowInstances("ccf73164-1998-4785-a7a3-8d06c7e5f558");
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#listWorkflowInstances");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" java "Example.java"`
```
List workflow instances```
// List workflow instances returns "OK" response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::ListWorkflowInstancesOptionalParams;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;

#[tokio::main]
async fn main() {
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api
.list_workflow_instances(
"ccf73164-1998-4785-a7a3-8d06c7e5f558".to_string(),
ListWorkflowInstancesOptionalParams::default(),
)
.await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" cargo run`
```
List workflow instances```
/**
* List workflow instances returns "OK" response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

const params: v2.WorkflowAutomationApiListWorkflowInstancesRequest = {
workflowId: "ccf73164-1998-4785-a7a3-8d06c7e5f558",
};

apiInstance
.listWorkflowInstances(params)
.then((data: v2.WorkflowListInstancesResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" tsc "example.ts"`
```## Execute a workflow- v2 (latest)
POST https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.datadoghq.eu/api/v2/workflows/{workflow_id}/instanceshttps://api.ddog-gov.com/api/v2/workflows/{workflow_id}/instanceshttps://api.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}/instanceshttps://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}/instances
### OverviewExecute the given workflow. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_run` permission.OAuth apps require the `workflows_run` authorization scope to access this endpoint.
### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
### Request#### Body Data (required)
- Model
- Example
Expand All
Field
Type
Description
meta
object
Additional information for creating a workflow instance.
payload
object
The input parameters to the workflow.
```
{
"meta": {
"payload": {
"input": "value"
}
}
}
```### Response- 200
- 400
- 403
- 429
Created
- Model
- Example
Response returned upon successful workflow instance creation.
Expand All
Field
Type
Description
<any-key>

```
{
"data": {
"id": "string"
}
}
```Bad Request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Execute a workflow returns "Created" responseCopy```

# Path parametersexport workflow_id="CHANGE_ME"# Curl commandcurl -X POST "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}/instances" \
-H "Accept: application/json" \
-H "Content-Type: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
-d @- << EOF
{
"meta": {
"payload": {
"input": "value"
}
}
}
EOF

```
Execute a workflow returns "Created" response```
// Execute a workflow returns "Created" response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	body := datadogV2.WorkflowInstanceCreateRequest{
		Meta: &datadogV2.WorkflowInstanceCreateMeta{
			Payload: map[string]interface{}{
				"input": "value",
			},
		},
	}
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.CreateWorkflowInstance(ctx, "ccf73164-1998-4785-a7a3-8d06c7e5f558", body)

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.CreateWorkflowInstance`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.CreateWorkflowInstance`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" go run "main.go"`
```
Execute a workflow returns "Created" response```
// Execute a workflow returns "Created" response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.WorkflowInstanceCreateMeta;
import com.datadog.api.client.v2.model.WorkflowInstanceCreateRequest;
import com.datadog.api.client.v2.model.WorkflowInstanceCreateResponse;
import java.util.Map;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

WorkflowInstanceCreateRequest body =
new WorkflowInstanceCreateRequest()
.meta(
new WorkflowInstanceCreateMeta()
.payload(Map.ofEntries(Map.entry("input", "value"))));

try {
WorkflowInstanceCreateResponse result =
apiInstance.createWorkflowInstance("ccf73164-1998-4785-a7a3-8d06c7e5f558", body);
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#createWorkflowInstance");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" java "Example.java"`
```
Execute a workflow returns "Created" response```
"""
Execute a workflow returns "Created" response
"""

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi
from datadog_api_client.v2.model.workflow_instance_create_meta import WorkflowInstanceCreateMeta
from datadog_api_client.v2.model.workflow_instance_create_request import WorkflowInstanceCreateRequest

body = WorkflowInstanceCreateRequest(
meta=WorkflowInstanceCreateMeta(
payload=dict([("input", "value")]),
),
)

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.create_workflow_instance(workflow_id="ccf73164-1998-4785-a7a3-8d06c7e5f558", body=body)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" python3 "example.py"`
```
Execute a workflow returns "Created" response```
# Execute a workflow returns "Created" response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new

body = DatadogAPIClient::V2::WorkflowInstanceCreateRequest.new({
meta: DatadogAPIClient::V2::WorkflowInstanceCreateMeta.new({
payload: {
"input": "value",
},
}),
})
p api_instance.create_workflow_instance("ccf73164-1998-4785-a7a3-8d06c7e5f558", body)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" rb "example.rb"`
```
Execute a workflow returns "Created" response```
// Execute a workflow returns "Created" response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;
use datadog_api_client::datadogV2::model::WorkflowInstanceCreateMeta;
use datadog_api_client::datadogV2::model::WorkflowInstanceCreateRequest;
use serde_json::Value;
use std::collections::BTreeMap;

#[tokio::main]
async fn main() {
let body =
WorkflowInstanceCreateRequest::new().meta(WorkflowInstanceCreateMeta::new().payload(
BTreeMap::from([("input".to_string(), Value::from("value"))]),
));
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api
.create_workflow_instance("ccf73164-1998-4785-a7a3-8d06c7e5f558".to_string(), body)
.await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" cargo run`
```
Execute a workflow returns "Created" response```
/**
* Execute a workflow returns "Created" response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

const params: v2.WorkflowAutomationApiCreateWorkflowInstanceRequest = {
body: {
meta: {
payload: {
input: "value",
},
},
},
workflowId: "ccf73164-1998-4785-a7a3-8d06c7e5f558",
};

apiInstance
.createWorkflowInstance(params)
.then((data: v2.WorkflowInstanceCreateResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" tsc "example.ts"`
```## Get a workflow instance- v2 (latest)
GET https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.datadoghq.eu/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.ddog-gov.com/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}https://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}
### OverviewGet a specific execution of a given workflow. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_read` permission.OAuth apps require the `workflows_read` authorization scope to access this endpoint.
### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
instance_id [*required*]
string
The ID of the workflow instance.
### Response- 200
- 400
- 403
- 404
- 429
OK
- Model
- Example
The state of the given workflow instance.
Expand All
Field
Type
Description
<any-key>

```
{
"data": {
"attributes": {
"id": "string"
}
}
}
```Bad Request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Not Found
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Get a workflow instanceCopy```

# Path parametersexport workflow_id="CHANGE_ME"export instance_id="CHANGE_ME"# Curl commandcurl -X GET "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}/instances/${instance_id}" \
-H "Accept: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}"

```
Get a workflow instance```
"""
Get a workflow instance returns "OK" response
"""

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.get_workflow_instance(
workflow_id="ccf73164-1998-4785-a7a3-8d06c7e5f558",
instance_id="305a472b-71ab-4ce8-8f8d-75db635627b5",
)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" python3 "example.py"`
```
Get a workflow instance```
# Get a workflow instance returns "OK" response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new
p api_instance.get_workflow_instance("ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5")

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" rb "example.rb"`
```
Get a workflow instance```
// Get a workflow instance returns "OK" response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.GetWorkflowInstance(ctx, "ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5")

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.GetWorkflowInstance`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.GetWorkflowInstance`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" go run "main.go"`
```
Get a workflow instance```
// Get a workflow instance returns "OK" response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.WorklflowGetInstanceResponse;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

try {
WorklflowGetInstanceResponse result =
apiInstance.getWorkflowInstance(
"ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5");
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#getWorkflowInstance");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" java "Example.java"`
```
Get a workflow instance```
// Get a workflow instance returns "OK" response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;

#[tokio::main]
async fn main() {
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api
.get_workflow_instance(
"ccf73164-1998-4785-a7a3-8d06c7e5f558".to_string(),
"305a472b-71ab-4ce8-8f8d-75db635627b5".to_string(),
)
.await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" cargo run`
```
Get a workflow instance```
/**
* Get a workflow instance returns "OK" response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

const params: v2.WorkflowAutomationApiGetWorkflowInstanceRequest = {
workflowId: "ccf73164-1998-4785-a7a3-8d06c7e5f558",
instanceId: "305a472b-71ab-4ce8-8f8d-75db635627b5",
};

apiInstance
.getWorkflowInstance(params)
.then((data: v2.WorklflowGetInstanceResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<DD_API_KEY>" DD_APP_KEY="<DD_APP_KEY>" tsc "example.ts"`
```## Cancel a workflow instance- v2 (latest)
PUT https://api.ap1.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.ap2.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.datadoghq.eu/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.ddog-gov.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.us3.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancelhttps://api.us5.datadoghq.com/api/v2/workflows/{workflow_id}/instances/{instance_id}/cancel
### OverviewCancels a specific execution of a given workflow. This API requires a registered application key. Alternatively, you can configure these permissions in the UI.
This endpoint requires the `workflows_run` permission.### Arguments#### Path ParametersName
Type
Description
workflow_id [*required*]
string
The ID of the workflow.
instance_id [*required*]
string
The ID of the workflow instance.
### Response- 200
- 400
- 403
- 404
- 429
OK
- Model
- Example
Information about the canceled instance.
Expand All
Field
Type
Description
data
object
Data about the canceled instance.
id
string
The id of the canceled instance
```
{
"data": {
"id": "string"
}
}
```Bad Request
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Forbidden
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Not Found
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```Too many requests
- Model
- Example
API error response.
Expand All
Field
Type
Description
errors [*required*]
[string]
A list of errors.
```
{
"errors": [
"Bad Request"
]
}
```### Code Example- [Curl](?code-lang=curl#)
- [Python](?code-lang=python#)
- [Ruby](?code-lang=ruby#)
- [Go](?code-lang=go#)
- [Java](?code-lang=java#)
- [Rust](?code-lang=rust#)
- [Typescript](?code-lang=typescript#)

Cancel a workflow instanceCopy```

# Path parametersexport workflow_id="CHANGE_ME"export instance_id="CHANGE_ME"# Curl commandcurl -X PUT "https://api.ap1.datadoghq.com"https://api.ap2.datadoghq.com"https://api.datadoghq.eu"https://api.ddog-gov.com"https://api.datadoghq.com"https://api.us3.datadoghq.com"https://api.us5.datadoghq.com/api/v2/workflows/${workflow_id}/instances/${instance_id}/cancel" \
-H "Accept: application/json" \
-H "DD-API-KEY: ${DD_API_KEY}" \
-H "DD-APPLICATION-KEY: ${DD_APP_KEY}"

```
Cancel a workflow instance```
"""
Cancel a workflow instance returns "OK" response
"""

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v2.api.workflow_automation_api import WorkflowAutomationApi

configuration = Configuration()
with ApiClient(configuration) as api_client:
api_instance = WorkflowAutomationApi(api_client)
response = api_instance.cancel_workflow_instance(
workflow_id="ccf73164-1998-4785-a7a3-8d06c7e5f558",
instance_id="305a472b-71ab-4ce8-8f8d-75db635627b5",
)

print(response)

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=python) and then save the example to `example.py` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" python3 "example.py"`
```
Cancel a workflow instance```
# Cancel a workflow instance returns "OK" response

require "datadog_api_client"
api_instance = DatadogAPIClient::V2::WorkflowAutomationAPI.new
p api_instance.cancel_workflow_instance("ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5")

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=ruby) and then save the example to `example.rb` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" rb "example.rb"`
```
Cancel a workflow instance```
// Cancel a workflow instance returns "OK" response

package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"

	"github.com/DataDog/datadog-api-client-go/v2/api/datadog"
	"github.com/DataDog/datadog-api-client-go/v2/api/datadogV2"
)

func main() {
	ctx := datadog.NewDefaultContext(context.Background())
	configuration := datadog.NewConfiguration()
	apiClient := datadog.NewAPIClient(configuration)
	api := datadogV2.NewWorkflowAutomationApi(apiClient)
	resp, r, err := api.CancelWorkflowInstance(ctx, "ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5")

	if err != nil {
		fmt.Fprintf(os.Stderr, "Error when calling `WorkflowAutomationApi.CancelWorkflowInstance`: %v\n", err)
		fmt.Fprintf(os.Stderr, "Full HTTP response: %v\n", r)
	}

	responseContent, _ := json.MarshalIndent(resp, "", " ")
	fmt.Fprintf(os.Stdout, "Response from `WorkflowAutomationApi.CancelWorkflowInstance`:\n%s\n", responseContent)
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=go) and then save the example to `main.go` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" go run "main.go"`
```
Cancel a workflow instance```
// Cancel a workflow instance returns "OK" response

import com.datadog.api.client.ApiClient;
import com.datadog.api.client.ApiException;
import com.datadog.api.client.v2.api.WorkflowAutomationApi;
import com.datadog.api.client.v2.model.WorklflowCancelInstanceResponse;

public class Example {
public static void main(String[] args) {
ApiClient defaultClient = ApiClient.getDefaultApiClient();
WorkflowAutomationApi apiInstance = new WorkflowAutomationApi(defaultClient);

try {
WorklflowCancelInstanceResponse result =
apiInstance.cancelWorkflowInstance(
"ccf73164-1998-4785-a7a3-8d06c7e5f558", "305a472b-71ab-4ce8-8f8d-75db635627b5");
System.out.println(result);
} catch (ApiException e) {
System.err.println("Exception when calling WorkflowAutomationApi#cancelWorkflowInstance");
System.err.println("Status code: " + e.getCode());
System.err.println("Reason: " + e.getResponseBody());
System.err.println("Response headers: " + e.getResponseHeaders());
e.printStackTrace();
}
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=java) and then save the example to `Example.java` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" java "Example.java"`
```
Cancel a workflow instance```
// Cancel a workflow instance returns "OK" response
use datadog_api_client::datadog;
use datadog_api_client::datadogV2::api_workflow_automation::WorkflowAutomationAPI;

#[tokio::main]
async fn main() {
let configuration = datadog::Configuration::new();
let api = WorkflowAutomationAPI::with_config(configuration);
let resp = api
.cancel_workflow_instance(
"ccf73164-1998-4785-a7a3-8d06c7e5f558".to_string(),
"305a472b-71ab-4ce8-8f8d-75db635627b5".to_string(),
)
.await;
if let Ok(value) = resp {
println!("{:#?}", value);
} else {
println!("{:#?}", resp.unwrap_err());
}
}

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=rust) and then save the example to `src/main.rs` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" cargo run`
```
Cancel a workflow instance```
/**
* Cancel a workflow instance returns "OK" response
*/

import { client, v2 } from "@datadog/datadog-api-client";

const configuration = client.createConfiguration();
const apiInstance = new v2.WorkflowAutomationApi(configuration);

const params: v2.WorkflowAutomationApiCancelWorkflowInstanceRequest = {
workflowId: "ccf73164-1998-4785-a7a3-8d06c7e5f558",
instanceId: "305a472b-71ab-4ce8-8f8d-75db635627b5",
};

apiInstance
.cancelWorkflowInstance(params)
.then((data: v2.WorklflowCancelInstanceResponse) => {
console.log(
"API called successfully. Returned data: " + JSON.stringify(data)
);
})
.catch((error: any) => console.error(error));

```#### InstructionsFirst [install the library and its dependencies](https://docs.datadoghq.com/api/latest/?code-lang=typescript) and then save the example to `example.ts` and run following commands:
```

`DD_SITE="datadoghq.comus3.datadoghq.comus5.datadoghq.comdatadoghq.euap1.datadoghq.comap2.datadoghq.comddog-gov.com" DD_API_KEY="<API-KEY>" DD_APP_KEY="<APP-KEY>" tsc "example.ts"`
```###### Request a personalized demo×##### Get Started with Datadog