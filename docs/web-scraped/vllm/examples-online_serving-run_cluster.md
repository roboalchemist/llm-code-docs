# Source: https://docs.vllm.ai/en/stable/examples/online_serving/run_cluster/

[![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdib3g9IjAgMCAyNCAyNCI+PHBhdGggZD0iTTEwIDIwSDZWNGg3djVoNXYzLjFsMi0yVjhsLTYtNkg2Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDR6bTEwLjItN2MuMSAwIC4zLjEuNC4ybDEuMyAxLjNjLjIuMi4yLjYgMCAuOGwtMSAxLTIuMS0yLjEgMS0xYy4xLS4xLjItLjIuNC0uMm0wIDMuOUwxNC4xIDIzSDEydi0yLjFsNi4xLTYuMXoiPjwvcGF0aD48L3N2Zz4=)](https://github.com/vllm-project/vllm/edit/main/docs/examples/online_serving/run_cluster.md "Edit this page")

# Run Cluster[Â¶](#run-cluster "Permanent link")

Source <https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh>.

    #!/bin/bash
    #
    # Launch a Ray cluster inside Docker for vLLM inference.
    #
    # This script can start either a head node or a worker node, depending on the
    # --head or --worker flag provided as the third positional argument.
    #
    # Usage:
    # 1. Designate one machine as the head node and execute:
    #    bash run_cluster.sh \
    #         vllm/vllm-openai \
    #         <head_node_ip> \
    #         --head \
    #         /abs/path/to/huggingface/cache \
    #         -e VLLM_HOST_IP=<head_node_ip>
    #
    # 2. On every worker machine, execute:
    #    bash run_cluster.sh \
    #         vllm/vllm-openai \
    #         <head_node_ip> \
    #         --worker \
    #         /abs/path/to/huggingface/cache \
    #         -e VLLM_HOST_IP=<worker_node_ip>
    #
    # Each worker requires a unique VLLM_HOST_IP value.
    # Keep each terminal session open. Closing a session stops the associated Ray
    # node and thereby shuts down the entire cluster.
    # Every machine must be reachable at the supplied IP address.
    #
    # The container is named "node-<random_suffix>". To open a shell inside
    # a container after launch, use:
    #       docker exec -it node-<random_suffix> /bin/bash
    #
    # Then, you can execute vLLM commands on the Ray cluster as if it were a
    # single machine, e.g. vllm serve ...
    #
    # To stop the container, use:
    #       docker stop node-<random_suffix>

    # Check for minimum number of required arguments.
    if [ $# -lt 4 ]; then
        echo "Usage: $0 docker_image head_node_ip --head|--worker path_to_hf_home [additional_args...]"
        exit 1
    fi

    # Extract the mandatory positional arguments and remove them from $@.
    DOCKER_IMAGE="$1"
    HEAD_NODE_ADDRESS="$2"
    NODE_TYPE="$3"  # Should be --head or --worker.
    PATH_TO_HF_HOME="$4"
    shift 4

    # Preserve any extra arguments so they can be forwarded to Docker.
    ADDITIONAL_ARGS=("$@")

    # Validate the NODE_TYPE argument.
    if [ "$" != "--head" ] && [ "$" != "--worker" ]; then
        echo "Error: Node type must be --head or --worker"
        exit 1
    fi

    # Extract VLLM_HOST_IP from ADDITIONAL_ARGS (e.g. "-e VLLM_HOST_IP=...").
    VLLM_HOST_IP=""
    for ((i = 0; i < $; i++)); do
        arg="$"
        case "$" in
            -e)
                next="$"
                if [[ "$" == VLLM_HOST_IP=* ]]; then
                    VLLM_HOST_IP="$"
                    break
                fi
                ;;
            -eVLLM_HOST_IP=* | VLLM_HOST_IP=*)
                VLLM_HOST_IP="$"
                break
                ;;
        esac
    done

    # For the head node, HEAD_NODE_ADDRESS and VLLM_HOST_IP should be consistent.
    if [[ "$" == "--head" && -n "$" ]]; then
        if [[ "$" != "$" ]]; then
            echo "Warning: VLLM_HOST_IP ($) differs from head_node_ip ($)."
            echo "Using VLLM_HOST_IP as the head node address."
            HEAD_NODE_ADDRESS="$"
        fi
    fi

    # Generate a unique container name with random suffix.
    # Docker container names must be unique on each host.
    # The random suffix allows multiple Ray containers to run simultaneously on the same machine,
    # for example, on a multi-GPU machine.
    CONTAINER_NAME="node-$"

    # Define a cleanup routine that removes the container when the script exits.
    # This prevents orphaned containers from accumulating if the script is interrupted.
    cleanup() "
        docker rm "$"
    }
    trap cleanup EXIT

    # Build the Ray start command based on the node role.
    # The head node manages the cluster and accepts connections on port 6379,
    # while workers connect to the head's address.
    RAY_START_CMD="ray start --block"
    if [ "$" == "--head" ]; then
        RAY_START_CMD+=" --head --node-ip-address=$ --port=6379"
    else

        RAY_START_CMD+=" --address=$:6379"
        if [ -n "$" ]; then
            RAY_START_CMD+=" --node-ip-address=$"
        fi
    fi

    # Launch the container with the assembled parameters.
    # --network host: Allows Ray nodes to communicate directly via host networking
    # --shm-size 10.24g: Increases shared memory
    # --gpus all: Gives container access to all GPUs on the host
    # -v HF_HOME: Mounts HuggingFace cache to avoid re-downloading models
    docker run \
        --entrypoint /bin/bash \
        --network host \
        --name "$" \
        --shm-size 10.24g \
        --gpus all \
        -v "$:/root/.cache/huggingface" \
        "$" \
        "$" -c "$"